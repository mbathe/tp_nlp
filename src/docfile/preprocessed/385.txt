impact assessment policy prototyping experiment europe january norberto nuno gomes andrade verena kontschieder open loop global program connects policymakers technology companies help develop effective policies around emerging technologies program initiated supported facebook builds collaboration contributions consortium composed regulators governments tech businesses academics civil society representatives experimental governance methods open loop members cocreate policy prototypes test new different approaches laws regulations enacted improving quality rulemaking processes field tech policy report presents findings recommendations open loop policy prototyping program impact assessment rolled europe september november work licensed creative commons attribution international license andrade norberto nuno gomes verena kontschieder impact assessment policy prototyping experiment policy prototyping program facilitated facebook consulting firm considerati special thank considerati team particular bart schermer joas van ham invaluable contribution project would like thank following companies partnership participation without commitment active involvement project would possible would also like thank many experts participated impact assessment policy prototyping program workshops namely eva maydell sofia ranchordas emilia g√≥mez gutierrez jochen mistiaen martin ulbrich bojana bellamy giuseppe fenza pedro bizarro ramin karbalaie jason moses guttmann ariel biller ramiro manso ezequiel paura roman mogylnyi oles petriv alon lavie olivier cuzacq pedro saleiro igor carvalho michal schwartz luca romanelli evangelina luca thomas charisis michel van leeuwen duuk baten roffel sweitze claudine vliegen nathalie laneret edo haveman janne elvelid nicolas bouville lawrence muskitta israel evo britain feedzai portugal irida labs greece keepler spainnaix technology germany reface ukraine riatlas italy rogervoice france unbabel portugalabout open loop cite report acknowledge ments executive summary introduction policy prototyping adia policy prototyping program automated decision impact assessment adia policy prototype approach emerging regulatory trend automated decision impact assessment adia potential path forward prototyping adia framework policy prototyping policy prototyping risk assessment project overview methodology research approach data collection limitations exercise policy goal prototype law requirements adia prototype policy evaluation assessment policy understanding definitions automated system actors risk assessment risks case require adia art minimal requirements adia playbook conclusions policy understanding assessment policy effectiveness users able identify risks applications may entail rights freedoms subjects users able determine significant identified risks high low contents discussion way forward recommendations adia prototype law observations possible improvements adia prototype law specific changes adia prototype law recommendations regulating final reflections policy prototyping methodology recitals principles adia prototype policy evaluation continued users able formulate mitigating measures users able adequately assess whether measures remove risks reduce acceptable level residual risk assessment policy costs endnotes bibliography adia prototype guidance playbook risk assessment overview values relevant taxonomy potential harms mitigating measures impact assessment policy prototyping experiment facebook partnered european companies adia framework policy prototype companies could test applying applications policy prototype structured two parts prototype law drafted legal text prototype guidance drafted playbook goal derive recommendations relevant ongoing policy debates around future regulation participating companies asked select artificial intelligence learning application would produce effects impact people simulate application adia framework particular application participating startups asked provide initial feedback prototype law simulate implementation adia process based solely contents participants later received playbook providing methodology along list values relevant automated adm taxonomy harms examples mitigating measures asked provide feedback additional guidance would changed implementation throughout program participants shared experiences mobile ethnography application dedicated workshops results initial policy prototyping program clearly demonstrated value implementing adia framework tool identifying mitigating risks systems results also highlighted need clearly defined guidance implement framework practically importance ensuring consistency existing obligations like gdpr data protection impact assessment dpia report presents outcomes open loop policy prototyping program automated decision impact assessment adia europe open loop collaborative initiative supported facebook contribute practical insights policy debates prototyping testing approaches regulation enacted executive summary program demonstrated procedural approach risk assessment organisations identify assess mitigate risks following series steps indicative criteria examples adaptable alternative prescriptive regulatory approach applied specific business sectors intended uses risk assessment approach complemented set examples risks taxonomy values proved help organisations assess risks based specific context impact proposed uses taking account dynamic iterative character adia framework prototype adia framework tested aims make developers users organisations deploying adm systems aware risks applications may pose enable find ways mitigating potential risks achieve goal framework requires actors perform risks assessments application adia process outlines four requirements met organisations users deploying system users able identify risks applications may entail rights freedoms subjects users able determine significant risks high low users able formulate mitigating measures risks users able adequately assess whether measures remove risks reduce acceptable level residual risk impact assessment policy prototyping experiment outcomes based adia simulation feedback participants adia framework evaluated legal text three criteria policy understanding policy effectiveness policy costs regarding policy understanding concluded prototype law sufficiently clear wording users develop basic understanding required although still significant open questions exactly comply half confident could based solely guidance legal text points need clear supplemental guidance beyond legal text detailing specific instructions expectations participants also unclear would categorized prototype law definitions relevant actors highlighting complexity landscape need greater clarity law parses regarding policy effectiveness concluded prototype law helpful overall prompting participants fulfill intended requirements identifying risks formulating mitigations address however wide variance companies types risks considered focusing solely risks related design operation system dataset bias performance issues functional risks opposed broader set risks related ethical application adm systems societal effects decisions impact human well fairness human interaction end user autonomy overreliance systems structural highlights need policymakers clear types risk attempting address risk assessment requirement also highlights challenges expecting companies broadly identify mitigate every conceivable kind risk also gap terms participants completing second fourth steps contemplated processgauging risk severity inform mitigation decisions assessing residual risk mitigations indicating need greater clarity point prototype law guidance like many regulatory requirements policy costs involved complying requirements framework investment time resources implement framework significant indication limited test performing adia would overburden participants especially true participants already complying gdpr dpia requirements overlap prototype law requirements ideally would proper integration adia dpia requirements law avoid duplicative costs developers users introduction playbook provided participants additional guidance examples potential risks values according feedback playbook helped participants translate prototype law contexts made implementation straightforward feedback participants showed would actually change risk assessment reading playbook demonstrates need additional guidance operationalization examples shared practicable understanding adia understanding policy effectiveness policy costs impact assessment policy prototyping experiment recommendations based results prototyping exercise feedback prototype law playbook would advise lawmakers formulating requirements risk assessments take following recommendations account focus procedure instead prescription way determine applications findings show importance codifying risk assessment procedure procedural approach unconstrained prior sectoral determinations complemented set examples risks taxonomy values better job helping organisations assess risks based specific context impact proposed uses higher level uncertainty complexity types risk posed systems requires robust procedural approaches risk assessment complemented operational guidance rather approach anchored rigid classifications based sector utilized leverage procedural risk assessment approach determine right set regulatory requirements apply organisations deploying applications rather applying entire set regulatory requirements default regardless type application context actual risks procedural approach allows balanced appropriate application regulatory requirements response identified risks human oversight explainability rights redress monitoring disclosure requirements amongst others approach statutory requirements assigned bulk accordance specific application question level extent risks assessed alongside calculus benefits application brings provide specific detailed guidance implement adia process release alongside law positive impact playbook additional guidance participants risk assessments shows need similar guidance accompanying legal requirements guidance provided adia playbook helps overcome inherent ambiguity regulation needed policy technologically neutral taxonomies examples helps identify previously unknown aspects adm system demand additional guidance also confirms need tighter calibration coordination different governance instruments hard law soft law specific possible definition risks within regulatory scope results show risks related functioning systems built operate easier identify risks related application systems broader consequences individuals society particular participants feedback guidance values harms provided playbook showed difficult understand products services may implicate abstract values instance human autonomy avoid uncertainty urge policy lawmakers work academia civil society industry clearly specify types risks harms identified systematic manner mitigated effective way providing playbooks like one adia framework defining specific values weigh providing clear taxonomy harms consider good first step reduce uncertainty avoid burden companies trying identify solve every possible moral implication products services improve documentation risk assessment processes including justifications mitigation choices deciding documenting mitigate risks posed systems needs part risk assessment process fundamental element informing overall riskbased approach based feedback received program participants would helpful users deployers adm system also described adia particular measures taken others measures reduced risk acceptable level removed altogether reasons accepting residual risk also included adia providing insights impact assessment policy prototyping experiment value effectiveness risk mitigating measures selected would help determine right set regulatory requirements applicable application question bring greater clarity tensions amongst values affected resolved develop sound taxonomy different actors involved risk assessment regulating lawmakers must cognizant complex landscape actors developing deploying using impacted development taxonomy important two main reasons appropriately assign tasks identifying assessing mitigating risks better understand group stakeholders affected specify much possible set values may impacted provide guidance may tension one another implementing requirement risk assessment important clarify entities called perform adia required particular guidance explanation values may affected value tensions may arise helpful greater clarity around values weighed balancing risks particular technology mitigation approach benefits would turn enable better decisionmaking better documentation particular decisions made reinvent wheel combine new processes established ones improving overall approach many cases overlap adia gdpr dpia requirements order avoid duplicative work costs proper integration adia dpia requirements law project meant test idea adias also idea policy prototyping based helpful results proof concept intend continue similar projects addition policyspecific recommendations based positive experience would urge support participate similar projects test novel approaches regulating complex technology policy issues codifying approaches law whether partnership open loop initiative otherwise impact assessment policy prototyping experimentintroduction approach emerging regulatory trend impact assessment policy prototyping experimentthe need identify assess risks posed artificial intelligence machine learning systems emerged one mainstream approaches governance regulation according view regulatory requirements applied automated adm systems applications present certain level governments international institutions standard organisations businesses academics civil society institutions either based approach governance risk supported approach european commission followed approach regulatory framework outlined white paper artificial intelligence european approach excellence trust stating approach important help ensure regulatory intervention oecd recommendation asserts actors based roles context ability act apply systematic risk management approach phase system lifecycle continuous basis address risks related unesco also emphasizes riskbased approach evolving recommendation ethics artificial intelligence encouraging member states introduce impact assessments identify assess benefits concerns risks systems well risk prevention mitigation monitoring ieee vein underlines importance systematic risk analysis introduction management approach ethically aligned design recommendation autonomous intelligent governmental side countries signed entitled innovative trustworthy two sides coin supporting approach towards stating specific situations related risks individuals society stemming use tackled existing legislation need address legislative framework protecting existing public values fundamental guidance regulation artificial intelligence applications issued office management budget omb states egulatory nonregulatory approaches based consistent application risk assessment risk management across various agencies various proposed algorithmic accountability act would require entities perform automated decision system impact assessments automated decisions asia singapore governance model framework also follows approach governance proposing matrix help organisations determine level human involvement decisionmaking matrix lays number factors could used operational guidance assess risk posed systems nature probability severity reversibility harm amongst approach emerging regulatory trend used term automated ing interchangeably throughout policy prototyping program report ease reading european commission organisation economic development oecd art unesco ieee position paper behalf denmark belgium czech republic finland france estonia ireland latvia luxembourg netherlands poland portugal spain sweden innovative trustworthy office management budget omb introduction impact assessment policy prototyping canada directive automated requires relevant canadian federal agencies conduct algorithmic impact assessment automated decision system ads developed procured extent ads used recommend make administrative decision client canadian government partnership subsequently begun developing model algorithmic impact assessment tool relevant agencies could refer use complying directive automated decision approaches put forward also vary terms connections interplay existing legal frameworks seen proposals defend incorporation human rights concepts frameworks processes basis risk assessments vii along proposals pointing gdpr data protection impact assessments dpias models develop implement automated decision impact assessments adias viiiintroduction within emerging trend towards approach governance variety perspectives define assess risks posed systems approaches follow binary determination others propose risk follow prescriptive approach based comprehensive exhaustive lists factors criteria identify risks sectors intended use cases iii others recommend procedural set steps questions meant arrive risk determinations qualitative analysis dialogue risk approaches may rely quantitative type assessment based calculation risk scores others advocate qualitative assessment based collection stakeholder inputs impact assessment policy prototyping experimentintroduction table approaches regulation approaches regulation examples binary european commission white paper risk classification german data ethics commission opinion algorithmic data governance prescriptive european commission white paper procedural hleg assessment list trustworthy altai singapore model governance framework companion guide considerati ecp artificial intelligence impact assessmen ieee standard assessing impact human human impact assessment technology rafael calvo open loop automated decision impact adia framework quantitative canada algorithmic impact assessment tool qualitative see examples listed procedural approach human rights driven european union agency fundamental rights fra getting future right artificial intelligence fundamental rights center democracy technology response white paper data society governing artificial intelligence upholding human rights dignit big data blueprint human rights social ethical impact assessment mantelero gdpr dpias aligned chair legal regulatory implications universit√© grenoble alpes submission white paper private accountability age artificial intelligence katyal facebook response white paper impact assessment policy prototyping experimentdespite overwhelming consensus ample agreement need importance approach despite various risk assessment modalities put forward development concrete operational risk assessment frameworks couple noteworthy exceptions still lacking writing principles governance concrete operationalizable risk assessment frameworks proposed see table none garnered widespread consensus point difficulties developing risk assessment framework well documented thorough risk framework remains elusive posed applications mitigate risks response facebook described basic elements adia process could codified regulation complemented evolving soft law instruments would provide detailed guidance could include detailed taxonomy kinds risks harms considered indicative examples uses presumed presumption could rebutted appropriate mitigations documented adia methodology developers could follow seeking identify quantify harms guidance would help ensure adequate consideration specific context automated issue greater focus concrete measurable harms also ensuring consideration application benefits facebook response european commission white paper facebook stressed need align gdpr around risk advocating new regulation build upon requirements already exist gdpr order provide greater legal clarity avoid duplicative regulation ensure proportionate approach novel issues gdpr commission established duty implement accountable data protection programmes include data protection impact assessments dpias ante data processing likely based model facebook suggested possibility similar approach developing concept automated impact assessments adias akin dpias way assess determine document level risk table operational risk assessment frameworks proposed date automated decision impact assessment adia potential path forward introduction high level expert group assessment list trustworthy altai singapore model governance framework companion guide implementation selfassessment guide organisations isago government canada algorithmic impact assessment aia ieee assessment impact human well algorithmic impact assessments practical framework public agency accountability institute artificial intelligence impact assessment aiia impact assessment policy prototyping experimentin terms embedding adia framework system regulatory enforcement facebook suggested enforcement actions could triggered companies fail properly conduct risk assessment reasonably mitigate risks identify consistent gdpr approach prior consultation relevant regulator would required adia process resulted identification residual high risks appropriate mitigations reasonably available identified would encourage organisations proactively consider adopt mitigations reduce initial high risk acceptably low offered potential adia framework flexible alternative white paper proposed system enforcement would require prior conformity assessments systems regulators auditors systems deployed articulated facebook response enforcement system proposed commission could risk unnecessarily overburdening developers significantly impairing innovation economic growth would benefit european citizens following facebook description potential adia framework company partnered group ten european companies open loop initiative draft adia framework policy prototype test practice running risk assessment process selected set real world applications consulting firm considerati contributed methodology content analyses policy prototyping adia frameworkintroductionintroductionintroduction based facebook initial conceptualization adia framework composed legally codified adia requirement complemented detailed guidance via soft law instruments open loop members including facebook considerati prototype adia framework structured two parts adia prototype law drafted legislative document articles recitals adia playbook provided comprehensive guidance aimed helping companies interpret comply legal text conduct adias playbook included risk assessment methodology list values relevant adm taxonomy harms examples mitigating measures impact assessment policy prototyping experimentthrough policy prototyping methodology explained tested adia framework normative guidance provided directly developers focus testing twofold evaluate adia framework understand applicability feasibility merits limitations within reality corporate practices across broad diversified range applications recommend specific improvements draft adia framework derive evidencebased policy recommendations inform ongoing regulatory discussions important note adia framework prototyped legislative proposal instrument aimed exploring testing alternative policy frameworks regulatory pathways adia framework developed solely purpose tested experimented possible option risks could identified assessed mitigated departure point platform experimentation final conclusion beyond testing evaluating merits limits governance framework project also gave opportunity test process policy prototyping sound methodology inform adia framework testing evaluating group selected companies revising draft framework delivering policy recommendations based empirical testing evaluation order inform evolving governance debate project consisted impact assessment policy prototyping experimentpolicy prototyping impact assessment policy prototyping experimentpolicy prototyping methodology test efficacy policy first implementing controlled environment policy prototyping applies design user research approach commonplace product service design development law legal philosopher lon fuller defined law enterprise subjecting human conduct governance rules policies made influence behaviour individuals groups organisations norm addressees goal bringing certain mutual behaviour action abstention words law policy instruments directed producing certain effects means achieve particular policy prototyping nonetheless difficult know anticipate effects produced laws enacted put force particularly true laws governing new emerging technologies although proposed laws policies often discussed debated extensively seldom tested laws typically enacted without clear whether actually effective fit purpose particular policy prototyping program wanted test whether adia approach policy would effective achieving intended governance goals first creating prototype law normative framework built sole purposes tested limited group norm addressees aimed producing actionable feedback concrete policy recommendations inform rule processes see brown katz villa alvarez auricchio mortati kontschieder see also brown fuller kelsen see bason policy prototyping policy prototyping impact assessment policy prototyping experimentthe idea policy prototyping lead effective making avoid societal costs bad policy costs economic nature high compliance costs high enforcement costs loss opportunity infringements rights freedoms unintended consequences collateral effects policy prototyping may especially useful areas pace technological development innovation high formal legislation tends struggle keep prior rolling new governance framework proposed law codes conduct standards guidelines etc policy prototyping swift agile way understand framework effects strengths limitations design thinking prototype visible tangible functional manifestation idea test others learn early stage development prototype thus seen lowresource quickly deployed version idea used run experiments order test idea learn whether pursue invest fully similar cycles technology trial learn process informs final tool application policy prototypes help makers users policy better understand extent policy clear relevant effective turning robust fully fleshed version ready released applied broadly policy prototyping leurs duggan prototyping impact assessment policy prototyping experimentthe adia policy prototyping program impact assessment policy prototyping experimentwe chose topic risk assessment focus policy prototyping program described introduction risk assessment features prominently debate governance mentioned different policy responses potential risks instance proposal algorithmic accountability act united states specifically aimed introducing automated system impact lawmakers following approach contemplate making distinctions adia policy prototyping program low finally council europe recommends introduction human rights impact assessments precautionary topic risk assessment lends particularly well policy prototyping exercise individuals involved may suffer harm result prototype prototype law sets requirements affect participants exercise developers users affected applications patients citizens consumers algorithmic accountability act see council europe done onboarding phase program via initial form asked test adia based existing application company products services powered please tell application would like run impact assessment risk assessment adia policy prototyping program designed contribute practical insights current policy debate impact assessments end designed prototyping method suitable four week program drafted prototype law supporting documentation test prototype setting selected european startups various sectors willing join program implement prototype share experiences enable organisations fully participate risk assessment ensured disclosure proprietary sensitive information needed program would result value judgement products organisations program aimed evaluate policy products services organisations operate wide range sectors healthcare financial services consumer applications organisations provide platforms develop solutions implementation others others business model participating companies asked select application would produce effects impact people simulate application adia process particular overview based holding key operations euthe adia policy prototyping program impact assessment policy prototyping experiment adia policy prototyping program provides software infrastructure enterprise helping companies develop products allegro ran impact assessment software infrastructure enterprise helps companies build fully automated learning pipelines automatic feedback loops allowing fully autonomous system evo pricing develops autonomous supply chain solution price management promotion forecasting supply decisions application selected uses big data increase efficiency supply chain decisions turn helps reduce waste increase market efficiency enhance product availability service levels keepler data tech software company specializing design construction operation data products based public cloud platforms application keepler ran adia automates task assigning service responsibility extracting important content insurance claims within context email customer service management project application reduces manual workload enhancing focus time content opposed processing documents riatlas digital healthcare startup developing solutions remote monitoring smart patient health classification company applied adia framework core application supported machine learning predictive models structured validated clinical datasets classifies patient health status clinical personal data collected outcomes mobile app vital signs smartwatch tool supports clinical tasks patient health status classification smart data visualization early detection clinical risks naix technology ran risk assessment core application service based natural language processing nlp naix technology developed software automatically anonymise pseudonymise personal identifiable information pii large sets documents helping companies meet requirements gdpr adia policy prototyping program participants impact assessment policy prototyping experiment adia policy prototyping program unbabel provides human driven platform enterprise clients product enables enterprise customers provide multilingual customer support users removing language barriers enabling technology machine translation augmented human editing irida labs edge computer vision software company mission bring vision intelligence device ran adia framework software integrates detection models people vehicles objects vision system design data management processes tools empower development solutions smart cities smart retail industry surveillance logistics examples applications powered irida labs technology include smart retail analytics customer count customer engagement analytics waiting times queue flows analytics free flow vehicle monitoring parking space management occupancy monitoring zone management process automation warehouses construction sites reface develops application enables transpose faces photos videos tool hyper realistic face swapping one used testing adia prototype feedzai provides risk management platform prevent financial crime performed risk assessment process application automatically determines fraud risk new bank account opening applications system access demographic data filled applicants based predictive risk fraud supports decisions around providing denying people access banking services rogervoice conducted risk assessment application allows deaf people make calls using speech text text speech technology application makes communication via telephone accessible sector society previously could make use service allows cross boundaries communication people participant organisations different levels familiarity translating legal requirements products processes half participants experience performing risk assessments mainly data protection impact assessments dpias gdpr requirement reface participation limited first week program impact assessment policy prototyping experiment program set test effectiveness policy prototype achieving predetermined policy goal described detail chapter prototype drafted format law tested following three criteria law policy obviously contribute reaching overall policy goal policy substantially contribute achievement policy goal implemented policy goal automated decision impact assessment adia prototyping program described chapter compliance law policy may entail certain costs simply cost compliance oversight resources cost comply ensure compliance may also include costs unintended side effects policy negative impact innovation infringement human rights policy considered successful importance reaching policy goal outweighs costs associated reaching goal implementation policy note costs may distributed unevenly stakeholders actually bear costs associated implementation policy whether costs fair also taken account assessing success adia policy prototyping program policy understanding policy effectiveness policy costs law principle referred lex certa critical necessity law policy norm addressee subject policy requirements actually understands required clarity policy law vital importance perspective compliance also perspective legal impact assessment policy prototyping experiment week introduce understand aidaweek implement adiaweek reflect adia implementationweek implement playbook reflect kick workshopclosing workshop simulate adia implement quantify risks selfchosen applicationreview week activity implementing quantifying risksprobe guiding material adia provisions analyse exposure impact assessment get know prototype adia policy prototyping program week participants introduced prototype law asked understanding key concepts terms prototype law along prior experience impact assessments week asked participants simulate implementation adia document outcomes participants asked reflect experiences implementing prototype law week asked comment clarity requirements whether could apply context believed requirements useful week users presented playbook playbook provided participants additional guidance procedural substantive aspects performing adia risk assessment methodology overview values often associated applications taxonomy harms examples mitigating playbook sourced publications ethics domain authored governmental political actors state national level competent supervisory authorities data protection authorities consumer protection authorities international organisations oecd council europe industry groups professional associations consumer advocacy civil rights groups ngos think tanks playbook simulated common occurrence dissemination additional guidance supervisory authorities policy comes force closing workshop marked end four core testing weeks ten participating companies purpose workshop present preliminary findings program follow specific themes emerged feedback share discuss findings themes relevant audiences notably participating companies institutions member state policy representatives academics industry peers experience interest policy experimentation research approach see see information commissioner office ico see also see oecd council europe see ieee see uni global union reisman policy prototyping program timeline impact assessment policy prototyping experimentthe adia policy prototyping program data collected via regular surveys sent participants week used mobile ethnography approach collect data innovative methodology gathering feedback users way common world product service design knowledge never done field law policy used smartphone application gather feedback participants prototyping exercise gives valuable insights effectiveness policy prototyping exercise general specific insights policy mandating automated impact assessments limitations first limited number participants gathering representative quantitative results possible purpose prototyping exercise however significant problem mainly wanted collect qualitative feedback prototype qualitative approach took particular mobile ethnography element approach allowed observe companies process performing adia context business models everyday operations real world settings applied focus qualitative measures consistent calls stakeholders greater focus qualitative dimensions impact assessment procedures identification complex uncertain risks like potentially posed second limitation available time prototyping exercise depending feedback consisted answers multiple scale questions well free format responses instance form text audio video mind maps flowcharts collected direct feedback prototype law participants exercise stakeholders keeping prototype law open comments edits throughout program complexity risk assessment framework requirements captured therein comprehensive risk assessment exercise may take anywhere three months year project programmed last weeks total participants limited time full prototype law requirements time limitation embedded design program inspired use sprints agile approaches policy making namely comes new emerging participants thus asked simulate application adia process meant highlevel assessment without requirement documenting results full detail normally required impact assessments answers questions time necessary full scale adia estimates rather concrete numbers third limitation enforcement element program given nature exercise requirements asked participants follow implement rigorously enforced policy prototyping program focused enforcing compliance requirements laid documenting data collection limitations exercise kimbell world economic forum wef impact assessment policy prototyping experimentthe adia policy prototyping program compliance requirements assessing understanding effectiveness costs future iterations kind prototyping program would useful regulators join efforts help test effective enforcement type prototypical framework final limitation diversity participants participants come different countries diverse cultural backgrounds importantly develop different applications operate different sectors according distinct business models startup scale phase organisation results prototyping exercise necessarily representative enterprises multinational organisations however priority ensure gathering actionable feedback companies generally speaking would resources larger organisations would words wanted ensure requirements adia frameworks could complied companies smaller size impact assessment policy prototyping experimentthe automated decision impact assessment adia policy prototype impact assessment policy prototyping experimentin chapter describe automated decision impact assessment adia policy prototype referred prototype law ethical guidelines trustworthy european union sets requirement must trustworthy automated decision impact assessment adia policy prototype order automated application legitimate ethical robust determine whether automated systems indeed legitimate ethical robust must first establish potential unwanted consequences could might affect rights freedoms persons groups particular task falls developers users adm systems policy goal automated decision impact assessment adia policy prototype trustworthiness prerequisite people societies develop deploy use systems without systems human beings behind demonstrably worthy trust unwanted consequences may ensue uptake might hindered preventing realisation potentially vast social economic impact assessment policy prototyping experiment automated decision impact assessment adia policy prototype make developers users adm systems aware risks applications may pose make find ways mitigating potential risks policy theory change shown overall policy goal requirement users able identify risks applications may entail rights freedoms outcome developers users conduct effe ctive risk assessments adm goal make developers users auto mated systems aware risks applications may pose make find ways mitigating potential evaluation policy content policy sufficiently clear understand con tent policy implementation participants able implement policy effect terms resource requirement policy impact didi policy achieve desired effects unintended consequences positive negative requirement users able determine signifi cant risks high low requirement users able formulate mitigating measures requirement users able adequately assess whether measures remove risks reduce acceptable level residual risk theory change defines goals maps backward goals order identify necessary preconditions see brest see also users conduct effective risks assessments adm application users able identify risks applications may entail rights freedoms subjects users able determine significant risks high low users able formulate mitigating measures risks users able adequately assess whether measures remove risks reduce acceptable level residual risk impact assessment policy prototyping experimentbased policy goal associated requirements drafted prototype law prototype law formulated structured style actual point departure prototype law technology neutral hence use automated rather text way prototype law could applied different technologies sectors contexts regarding art particular important note prototype law mandates risk assessment process conducted prior deployment automated system cases application adm system likely result high risk rights freedoms natural legal persons namely cases potential unfair bias discrimination potential loss control agency subject including economic psychological manipulation large scale application automated contain least detailed description automated system design training data purpose assessment quality integrity representativeness data used train underlying model assessment risks involved natural legal persons specific focus subjects measures envisaged address prototype law requirements recitals content art subject matter objectivesdefines objective prototype law protection fundamental rights freedoms ensuring trustworthy application adm stimulate development use adm society art material scopesets scope prototype law development production distribution use automated systems whose use may significant effect natural legal persons art definitionsdefines actors relevant prototype law concepts related automated art risk assessmentsets requirements performance timing contents defines adia outcomes warrant prior consultation supervisory authority full prototype law found annex automated decision impact assessment adia policy prototype impact assessment policy prototyping experimentadia prototype policy evaluation impact assessment policy prototyping experimentas discussed chapter tested prototype law following criteria adia prototype policy evaluation policy understanding policy effectiveness policy costs policy understanding essential adequate implementation prototype law thus achieving policy goals prototype law designed normbased technologically neutral manner norm addresses need able understand concepts norms requirements able apply context situation enables assess needed increase policy effectiveness demonstrate difference clarity policy theory practice tested understanding prototype law contents focusing set key definitions namely definition automated system high risk actors involved also tested participants understanding requirements adia specified article prototype policy understanding definitions automated system means computational process derived machine learning statistics artificial intelligence data processing technique makes decision facilitates human decision making automated systemthe concept automated decisionmaking system unique adia prototype automated used existing legislation gdpr art corresponding guidance supervisory authorities well proposed algorithmic accountability act concept automated system central prototype object risk assessment critical understood participants divided clarity concept appreciate definition applies autonomous nonautonomous systems scoped around particular technique systems deep learning however unclear much process scope decision human supported system part system others wondered limits facilitates data extraction adia prototype policy evaluation impact assessment policy prototyping experimentadia prototype policy evaluation whether high risk rights freedoms natural legal persons must judged context nature purpose scope application high risk significant chance automated decisions made automated system subsequent actions taken users subjects basis automated decision result negative effects significant adverse impact rights freedoms natural legal persons recital visualization considered automated system noted one participants software visualizes data instance fall description computational process uses data processing technique data visualization facilitates human decision manner definition may read much broadly policymakers might intend hand session point raised decisionmaking system may ways narrow applications support humans operations necessarily equate making decisions text mining applications ediscovery applications may considered decisionmaking systems narrow sense word nevertheless impact rights freedoms data subjects although definition prototype law likely broad enough capture applications concern policymakers specific term automated system may still confuse norm addressees participants felt basic understanding definition actually assessing risk however users seemed focus mainly functional risks application risks related systems built operate potential bias data sets concept drift model performance risks related broader structural aspects concerns related ethical application automated systems consequences decisions impact terms fairness proportionality societal effects given less attention effect participants understood applied much narrower definition high risk actually articulated prototype law information see discussion adia requirements categorization functional structural risks based distinction epistemic normative concerns elaborated mittelstadt allo taddeo wachter floridi ethics algorithms mapping debate big data society impact assessment policy prototyping experimentadia prototype policy evaluation prototype law defined different types actors applied concepts organisational independently operating individuals perspective based appropriateness capability undertake risk assessment mitigation tasks words taxonomy designates roles taking account actors would best positioned identify assess mitigate risks within lifecycle important note actors nonexclusive organisations developing deploying technology participants developer user instance reface develops deploys system photos making developer user although definitions actors considered mostly clear useful almost participants received important feedback mismatch terms used adia framework used practice may trigger confusion roles covered proposed taxonomy need take account specific characteristics products services deciding conduct risk assessment firstly meaning terms designate actors prototype law different use terms particularly true gdpr parties corresponding adia users would called subjects term developers adia framework may also consist internal teams within company often overlap separate definition term user different uses terms deemed potentially confusing secondly although multiple actors refer organisation cover possible roles instance provides platform managing machine learning project lifecycles actors prototype law defines four actors relevant adm systems developer means natural legal person responsible technical development automated system user means natural legal person deploying automated system achieve particular goal means natural legal person using automated system purposes intended user subject means natural legal person subjected directly indirectly decision automated system purpose policy prototyping exercise allegro assessed risk hypothetical vision application customer would run platform developer user subject impact assessment policy prototyping experimentwhile seems fall category developer unclear category fits practice stated since infrastructure company sections relate product directly said assume provide service top platform continuous training specific computervision task try answer questions consider provid ing infrastructure developing deploying monitoring automated directly build stated apply application building infrastructure applications clarified several occasions implies platform provider enabling applications might understand developer user hence prototype law may require additional actor categories either take consideration ample value chain assign actor categories specific automated use models outset thirdly important understand application built actually contribute powering automated decisions difference providing generic learning algorithm shelf model relevant providers learning algorithms control training data eventual application model actions provider models direct relationship specific downstream decision tasks better understanding type application built inform development future taxonomies actor roles along proper assignment responsibility conducting risk assessments sum taxonomy actors roles prototype law good starting point granularity aligned multiplicity actors involved ecosystem complexity interactions work done refining taxonomy adapting terms used daily basis expanding cover additional types actors applications practice based feedback participants value chain interaction developers users quite complex makes harder establish responsible assessing risk best equipped assess risk mitigate risk increase clarity applicability section prototype description actors prototype likely prototype policy evaluation risks case require adia art risk assessment automated decision impact assessment referred paragraph shall case required case potential unfair bias discrimination towards subjects including price discrimination employment discrimination unfair differential access services potential loss control agency subject including economic psychological manipulation large scale application automated including profiling systematic monitoring may affect communities society whole impact assessment policy prototyping experimentadia prototype policy evaluation asked imagine risks apply applications participants demonstrated able identify ways risks could manifest applications example feedzai assessed application detecting fraudulent bank account openings identified risk unfair differential access financial services disparities false positive rates application based specific sensitive attributes age gender employment status zip code income reface identified risk psychological manipulation face swap application used generation misleading content unbabel identified risk potential loss control translation system makes polarity error instance erroneously translating instead however variation concepts unfair bias loss control agency perceived instance bias mostly understood bias data however feedzai identified potential bias went beyond data noting unbanked customers unable access credit also able demonstrate creditworthiness example demonstrates participants able apply concepts beyond technical functional considerations models behind applications although others focused assessments within understanding applications means risks related overall system application lives behaves may include software components data sources interfaces much less likely recognized concept large scale application definition also unclear participants different perspectives considered constitutes large scale participants understood concept terms model characteristics volume number elements model volume data large scale different every vertical apply solution define large scale customers one million annotated data processing definitely large scale translation models trained millions billions words sentences consume significant resources applied translation billions words customers scale number atomic units words sentences needed train models unbabel sector application applied niche market considered small scale different attributes characteristics languages age groups technology used general specific environment challenge able cover necessary aspects ensure good translation interpretation service words consider gender languages accents ages rogervoice number subjects duration irida labs processing could considered large scale data processing since might applications involving impact assessment policy prototyping experimentadia prototype policy evaluation large numbers subjects prolonged duration processing surveillance camera shopping mall entrance recording irida labs additionally participants thought categories cases requiring adia added instance cases potential misuse privacy violations feedback loops reinforce structural biases participants also misunderstood meaning article interpreting specific examples art risks adia performed highlighting need clarify text list included examples exhaustive minimal requirements adia prior deployment automated system user shall assess risks envisaged automated system application rights freedoms natural legal persons cases application automated system likely result high risk rights freedoms natural legal persons user shall carry automated decision impact assessment prior deployment automated decision impact assessment referred paragraph shall case required case potential unfair bias discrimination towards subjects including price discrimination employment discrimination unfair differential access services potential loss control agency subject including economic psychological manipulation large scale application automated including profiling systematic monitoring may affect communities society whole automated system impact assessment shall contain least detailed desciption automated system design training data purpose assessment quality integrity representativeness data used train underlying model assessment risks involved natural legal persons specific focus subjects measures envisaged address risks including safeguards security measures mechanisms protecting rights freedoms subjects demonstrate compliance policy prototype taking account rights legitimate interests concerned cases automated decision impact assessment indicates application may result high risk natural rights freedoms natural legal persons risks mitigated user shall prior deployment consult supervisory authority impact assessment policy prototyping experimentadia prototype policy evaluation article sets minimal requirements adia participants considered elements useful general argued additional requirements one idea assessment understanding capabilities ensure automated decisions misunderstood another suggestion assessment whether application necessary proportional less risky solutions possible requirement clear enough almost participants prompted give accurate albeit overview application meaning design unclear likely term two different meanings although potentially relevant blueprint system methods used ideate create system participants suggested expanding requirement adding detailed elements data provenance models selected results evaluated degree human oversight within time limits project necessarily led descriptions relatively general participants considered fulfillment requirement difficult achieve suggested prototype law clearly set level detail needed assessment explicitly requiring documentation specifying format adia however participants rated requirement useful assessment risks participants divided clarity requirement found unclear felt elements quality representativeness vague meaning context dependent one participant noted adequately assess elements might necessary test application setting odds requirement perform adia deployment instance representativeness data ultimately assessed application deployed difficult perfectly judge representativeness data true population naix feasibility requirement participants also divided participants felt easy comply requirement others felt guidance operationalization needed aforementioned data quality representativeness since implementation particular assessment crucial may subjected different interpretations measure data quality integrity representativeness appropriate guidelines would useful keepler pointed nevertheless users able describe methods used ensure quality integrity representativeness data among methods fairness audits model management explanation debugging generic measures data protection access controls encryption logging notably participants aware risks biased data detailed description automated system design training data purpose assessment quality integrity representativeness data used train underlying model impact assessment policy prototyping experimentadia prototype policy evaluation overall requirement considered useful assessment risks requirement clear participants paper although guidance possible risks would increase clarity even assessment considered difficult participants requested guidance instance examples risks help performing actual assessment methods involve stakeholders assessment commonly identified risks related false result bias training data example feedzai recognized denying access bank account represents economic harm people denied result system detecting fraud bank account openings could disproportionately cause harm certain groups mitigating measures model selection bias audits implemented maximize fairness minimize false positives feedzai recognized essential carefully analyse actual impact people building deploying maintaining fraud detection systems participants stated meaning requirement clear many unsure demonstrate compliance broadly participants sure document adia whether needed share documentation related assets data sets supervisory authority participants stated already implemented mechanisms ensure accuracy especially case participants applications higher risk contexts regulated sectors healthcare insurance mechanisms mentioned include monitoring logging regular auditing models instance detect bias human oversight debugging models assessing local explanations example keepler application automates parts customer support insurance companies designed way enables continuous auditing humans time sample documents categorized system reviewed reclassified needed contrast automation solutions goal enhance substitute human agency another example feedzai monitoring system models production allows early identification missing values specific features abnormal number predicted positive instances fraud detection system measures envisaged address risks including safeguards security measures mechanisms protecting rights freedoms subjects demonstrate compliance policy prototype taking account rights legitimate interests concerned assessment risks involved natural legal persons specific focus subjects impact assessment policy prototyping experimentadia prototype policy evaluation risk mitigation measures technical naix example participant alongside technical measures implement also educates clients limitations benefits application namely possibility redact vast amounts documents would never possible manual work enables naix clients perform adequate risk management practices successfully using automated application week program companies asked perform document adia art following illustrations templates provided participating companies purpose simulating assessment detailed description automated system design training data purpose give overview application purpose goal used describe overall design data used case machine learning model tool supports clinical patient health status classification additionally provides smart data visualization early detection clinical risks healthcare professionals health continuum care pathways scenario remote monitoring symptoms vital signs patients phase frequent returns hospital chemotherapy cycles start care pathway favoring recovery living environment starting data collected heterogeneous sources tool classifies patient health status using icf international classification functioning disability health clinical assessment patient tool identifies suggests physicians validates appropriate icf codes digital biomarker terms functioning activity participation also supports qualifiers gravity level valorization score icf code using recognized taxonomies clinical assessment scales visualization intelligent dashboard supports monitoring icf codes observing evolution qualifiers care pathway tool output patient health status classification described icf international classification functioning disability health taxonomy promoted output provided suggestion physician accept discard revise system incrementally trains considering feedback design model consists following steps first step collected clinical data electronic health record validated subject matter expert structured specific training dataset second step trained several machine learning models parameters evaluating performance terms accuracy third step selected suitable model revealing good accuracy performance satisfying clinical decision support system requirements fourth step deployed model final solution performed clinical trial patients recruited hospital impact assessment policy prototyping experimentan assessment quality integrity representativeness data used train underlying model describe data used application training data subsequent input data make assessment data quality integrity representativeness training based frameworks pytorch tensorflow caffee make clear data irida labs case video images training data acquired number sources data irida labs data collected field client data academic datasets open data quality data depends resolution configuration imaging devices blurred poorly lit data rejected furthermore data cropped split pieces order focus points interest example original data video stream public road desired outcome vehicle tracking counting clutter video removed pedestrians background sidewalks portion video maintained one focusing vehicles technique reassures high level quality far representativeness data crucial factor irida labs goal make sure training data cover aspects particular problem operational well environmental moving baseline optimal performance requires problem addressed example warehouse case aim product detection recognition counting items stock needed training multiple poses distances multiple representative possibilities objects people machinery intervening scene taking example solution car counting occupancy detection possible environmental conditions sunshine rain snow lighting conditions considered irida labs data engine designed around principle data campaigns process collecting learning data need small fast possible retaining representational quality automation seamless application process key factor realworld solutions adia prototype policy evaluation impact assessment policy prototyping experimentan assessment risks involved natural legal persons specific focus subjects describe risks application may pose subjects see recitals prototype examples please also list risks application already measures envisaged address risks including safeguards security measures mechanisms protecting rights freedoms subjects demonstrate compliance regulation taking account rights legitimate interests concerned describe would address risks application technical organisational measures examples testing evaluation monitoring deployed models explainability decisions etc far already addressed risks application please describe measures would requirement fraud detection system might result economic harm wrongly denied applicants well unfair differential access services access banking services paramount today especially pandemic rapid transition digital payments study fairness account opening setting particularly important access credit mainstream financial services accompany bank account often dictate person social mobility known foreseeable underbanked communities difficult access credit harder time building wealth therefore risk fraud detection system deny access financial services disproportionately across people different groups based age place residence profession employment status another risk privacy application contains sensitive information information place residence demographic data job income information data developer access build model anonymized financial institution secure data following measures taken data encryption rest logs data location mfa cloud environment login access cloud auditing log monitor retention account activity related actions across infrastructure ensure data integrity monitor health deployed models critical metrics training hosting predictions defined collected logs version model linked data used train models system designed continuously audited humans able review sample categorized documents approve prediction made models aka active learning features allows greater transparency ensuring minimum level performance training iterations deployed models adia prototype policy evaluation impact assessment policy prototyping experimentthe prototype guidance playbook introduced participants week playbook provided participants additional guidance interpreting specific concepts adia prototype law suggesting process conducting adia framework according feedback playbook helped participants translate prototype law contexts made implementation straightforward adding practice theory adia details obligations playbook details look evo examples provided playbook valuable resource cases team touched upon issues thought irida labs fact access list values makes adia easy feedzai general participants felt playbook clarified adia providing much requested implementation guidance based risk assessment methodology provided playbook participants identified steps take simulating adia based solely prototype law text table shows steps performed participants receiving playbook demonstrates risk assessment methodology playbook guidance provided valuable detail adia process otherwise overlooked benefit playbook example companies failed previously identify value tensions assess consequences mitigations knew companies like evoand already done able focus even deeply tasks additional guidance thought determining value irida labs playbook playbook consists risk assessment methodology list values relevant adm taxonomy harms examples mitigating measures full prototype guidance playbook found annex prototype policy evaluation impact assessment policy prototyping experiment step performed step describe proposed adm system step assess adm changes existing situation step analyse root cause change step determine impact stakeholders associated values step determine value tensions step determine probability negative impact occurring step identify possible changes mitigating measures step assess consequences changes mitigating measures step decide changes mitigating measures implement step implement document additional elements playbook list values taxonomy harms mitigating measures considered extremely useful overview values taxonomy harms particular deemed provide guidance needed risk assessment participants felt able identify new risks application new guidance instance guidance value personal autonomy helped evo identify possible risks personal autonomy algorithmic pricing solutions identified made think potential risks personal autonomy autonomous supply chain solution helps companies place right product right time right price affect person autonomy choice evo playbook helped riatlas increase understanding impact stakeholders patient health monitoring system determine probability negative impact occurring identify possible value tensions rogervoice discovered additional utility playbook using increase internal understanding around need take time understand risks application detailed explanation potential risks eye opening well made think additional ways mitigate rogervoice participants said would change adia reading playbook shows need additional guidance operationalization examples common understanding implementation prototype law preferably guidance could provided self instruments ensuring quick correct uptake legislation requirements table risk assessment methodology steps taken participants without playbook guidanceadia prototype policy evaluation impact assessment policy prototyping experimentin general participants felt prototype law clear paper however understanding elements prototype law varied widely participants asked level understanding prototype law content participants stated content clear asked confident could implement requirements listed prototype half confident able widely shared recurring demand participants examples operationalization concepts practical guidance level detail required demonstrated wide gap generally understanding adia process versus practically implementing determine effectiveness prototype law policy impact must determine extent following requirements prototype law contributed reaching desired policy outcome discussed previously order reach desired policy outcome following four requirements would need met participants appreciation playbook fact would revise adias based guidance clearly demonstrated need specific practical guidance complement prototype law actual future law guidance help overcome inherent ambiguity regulation needed policy technologically neutral assist identification quantification previously unrecognized risks adm system chart scale values help quantify rogervoice detailed examples category would make adia naix concrete examples risk quantification would help categorize low medium high probability severity feedzai therefore key success indicator prototype whether prototype law contributed participants identification risks automated rights freedoms natural legal persons also contributed consideration measures reduce policy understanding assessment policy effectiveness users able identify risks application may entail rights freedoms subjects users able determine significant risks high low users able formulate mitigating measures risks users able adequately assess whether measures remove risks reduce acceptable level residual risk prototype policy evaluation impact assessment policy prototyping experimentall participants able identify risks application based prototype law however clear differences width depth assessment risks related functioning application functional risks identified participants risks relate performance model data bias enduser competence cases participants already identified risks course performing risk assessments instance dpia gdpr compliance risks related broader ethical societal impacts application structural risks identified much less frequently feedback guidance values harms provided playbook shows difficult participants understand apply abstract values instance human autonomy evaluating systems broadly reckoning possible risks particular adm application much easier said done requires strong guidance clear examples ongoing practice prototype aimed make developers users automated systems aware risks applications may pose enable find ways mitigating potential risks based data gathered conclude prototype law isolation partly successful reaching intended goal participants aware risk able identify mitigating measures however identification risks arise aspects central purpose functioning application harder identify assess difficulty identifying risks demonstrated fact many risks identified participants receiving guidance playbook especially overview values harms fact participants said would revise adia seeing playbook instance reflecting value equality riatlas identified possible risk stemming application insurance companies used outcomes patient health monitoring system personalize insurance policies also determined patient health classification system poses potential risk equitable accessibility healthcare since used among things determine care patient needs rogervoice identified risk discrimination regarding application deaf people risk stems limited availability voice data certain age groups accents resulting lower quality output system irida labs identified additional potential risk material initial risk assessment guidance value personal autonomy helped evo identify possible risks personal autonomy algorithmic pricing solutions identified guidance assess risks helps cast wider net range potential risks posed systems providing better tools identify assess relevant ones list values taxonomy harms particular helps ensure broad set possible risks considered risk assessment process ensures significant ones effectively flagged addressed said sometimes unclear participants values rights freedoms could potentially affected application overview values harms playbook enabled participants think concepts related use broader societal effects applications complemented technical users able identify risks applications may entail rights freedoms subjects adia prototype policy evaluation impact assessment policy prototyping experimentperspective risk assessment participants brought table according risk tended associated functioning operation system words playbook resources reversed participants default risk assessment strategy shifting thinking process focusing technical functional risks application may pose reflecting structural societal risks might emerge manifest deployment use application playbook various elements enabled participants reflect potential wider set risks conceptualized lists values types harms risks could occur use interaction applications society way participants longer exclusively constrained technical underpinnings applications derive identify risks helped identify unknown risks related broader set structural societal effects applications given prototype law explicit requirement determine significance risks identified gather sufficient information regarding ability users proceed perform determination prototype law establishes requirement assess risks requirement users consult supervisory authority cases impact assessment indicates application may result high risk risks participants confident able identify appropriate risk reducing measures performed dpias systems also require risk identification mitigation particularly confident felt much additional work needed list values harms useful allow analyse problem exhaustive way different points riatlas insightful comment prototype law one participants adia require justifications choices made rather describing documenting findings suggested user adm system also describe particular measures taken others measures reduce risk acceptable level take away altogether another insight may helpful playbook guidance directly informed fields approaches risk assessment example field might able derive useful lessons environmental impact assessments used industries evaluate impact certain chemicals industrial processes mitigated intermediate step assessing significance risk identified implicit demonstrated program performed participants whether due lack awareness lack understanding perform assessment unclear either way finding demonstrates need descriptive explicit procedure determine significance risks posed systems applications instance naix already process place assessing risk implementing risk reducing measures determining residual risk incorporate prototype requirements made easier fact adia prototype extent mimics users able determine significant identified risks high low users able formulate mitigating measures adia prototype policy evaluation impact assessment policy prototyping experimentthe dpia requirement article gdpr measures identified participants focused ensuring accuracy fairness automated protection personal data feedzai instance proposed following concrete risk reducing measures model selection might large spread fairness metric level predictive accuracy therefore select model goes production based optimal tradeoff monitoring proprietary algorithms continuous monitoring models production allow early identification missing values specific features abnormal number predicted positive instances participants felt could provide measures application unsure assess effectiveness measures example riatlas confident could apply adia principles identify risks less confident evaluating adequacy fairness measures reduce risk feedzai noted related concern lack explicit guidance around assess effectiveness mitigation measures may leave much discretion hands users concern exacerbated considering complex question identify assess mitigations address broader ethical impacts societal risks application opposed narrower functional risks directly related technical operation application another example demonstrating difficulty evaluating effectiveness mitigating measures came reface identified risk misuse face swapping technologies creation misleading frequent bias audits bias creep anytime establish frequent monthly bias audits assess fairness degradation model need retrain debugging explanations ask data scientists fraud analysts debug sample predictions model using post hoc explanation methods monitor feature attribution changes content measures could help mitigate risk included applying watermarks reviewing content generated setting community guidelines however assessing effectiveness measures deployment application would difficult assessing deployment adia requires would even harder participants challenges assessing effectiveness mitigating measures exacerbated fact balancing values interests reduction risk acceptable residual level based balancing specifically mentioned mandatory elements risk assessment defined article prototype law led conclude without sufficient analysis documentation properly managed risk gap could addressed adding specific requirement document balancing justify residual risk users able adequately assess whether measures remove risks reduce acceptable level residual risk adia prototype policy evaluation impact assessment policy prototyping experimentthe costs implementation adia policy prototype understood combination time resources required perform adia costs implementing mitigating measures compliance efforts monitoring direct costs associated complying requirements set policy may also indirect costs instance changes application may impact revenue negative way however impact revenue may also positive trust application grows given duration policy prototyping exercise focused questions immediate direct costs associated performance adia much time resources take perform adia asked participants estimate performing adia application prevalent range hours regarding roles involved participants perform adia clear adia requires interdisciplinary team participants would involve legal technical functions including risk compliance functions well besides internal functions participants would require outside counsel able perform involvement external experts particularly costly smaller organisations startups may conclude costs implementing adia dependent many factors related type organisation size maturity adms scope regulation system characteristics need involve various internal functions cases external counsel performing adia major component implementation cost however significant investment time resources would clearly necessary conduct adia concrete evidence participants indicating requirement would overly burdensome significant unforeseen effects associated performance adia would lead additional costs participants policy costsadia prototype policy evaluation impact assessment policy prototyping experimentdiscussion way forward impact assessment policy prototyping experimentbased assessment three criteria policy understanding policy effectiveness policy costs conclude overall prototype law successful achieving desired policy outcome developers users conduct effective risks assessments adm application policy understanding first prototype law sufficiently clear wording users develop basic understanding much tasks required namely identify risks applications may entail rights freedoms subjects determine significant risks high low formulate mitigating measures risks assess whether measures remove risks reduce acceptable level residual risk one sources misunderstanding prototype law description types actors involved participants always identify developer user instance furthermore complex landscape actors means may also dependencies actors instance limitations models specificities platforms known developers also important know users downstream would conduct adia also complexity landscape makes less clear responsible capable executing adia instance developer learning algorithms might knowledge control training data selected user purposes model used makes hard impossible conduct adia policy effectiveness based outcomes adia exercise feedback participants also conclude overall prototype law effective general important requirements desired policy outcome met participants able identify risks posed applications requirement one formulate mitigations address risks requirement three however participants understand part assessment also required determine risks high low order help inform mitigation decisions requirement two assess mitigation measures effectiveness reducing high risks acceptable level requirement four cases addition explicit requirements prototype law concrete guidance playbook clearly necessary foster greater policy understanding observationsadia prototype policy evaluationdiscussion way forward impact assessment policy prototyping experimentpolicy cost regulatory requirements would certainly costs involved fully complying adia requirement although prototyping program necessarily limited noted previously adia process tested participants shorter less detailed would likely required compliance actual law get impression participants conducting adia would overburden one key reason overlap adia process gdpr dpia requirement many companies already comply results one reused suggests policymakers focus deliberately integrating adia dpia requirements law avoid unnecessary duplicative costs developers users ability prototype meet desired policy goal expressed anonymized survey end program participants felt adia process gave new insights risks adm applications adia process helped think new insights potential risks terms privacy data protection fairness rule realised incorporate controls current workflow evaluate potential risks new adoption adia process organisation helped understand implication developed tool real world also raised awareness possible risks helped responsible discussed survey several participants contemplating using prototype law associated guidance help improve existing risk assessment policies processes taxonomy harms particularly useful considering adopting internal revising current risk assessment processes include features learned thinking creating standardized adia instead based case case requirements depending final workshop participants also made clear would consider disclosing adia documentation demonstrate trustworthiness clients differentiate competitors range feedback may conclude prototype law contributed policy goal quotes page stem final evaluation survey program survey aimed obtaining overall reflec tion program experience identifying operational strategic implications participating companies foresaw business adia prototyping journey program survey way forward impact assessment policy prototyping experiment policy seemed effective overall based results exercise feedback participants definitely room improvement following elements could considered order improve prototype landscape complex anticipated prototype prototype law distinction developers users subjects helpful capture full complexity landscape furthermore terminology used prototype differs generally used tech community instance user tech community generally person using service organisation adm system requirements adia meet article specifically require participants justify use application adequacy measures including clear requirements conscious balancing interests documentation balancing could likely achieved instance developers users could document taking measures reduce bias datasets also measures implemented sufficient address risks type justification could help assess effectiveness mitigating measures reported participants one main difficulties experienced process given playbook guidance discovering possible tensions values posed systems helped participants identify additional risks particular step added article clear requirement adia prototype law closely connected previous recommendation justifications selection adequacy risk mitigation measures actors greater focus justification legitimacy greater emphasis value tensions part adia requirementspossible improvements adia prototype lawdiscussion way forward developer user subject impact assessment policy prototyping experimentspecific changes adia prototype law based results feedback prototype revised thus improved detail article important article prototype following changes could made amended text based feedback comments prior deployment automated system user shall assess risks envisaged automated decisionmaking system application rights freedoms natural legal definition automated decisionmaking system must revisited definitions article cases application automated system likely result high risk rights freedoms natural legal persons user shall carry automated decision impact assessment prior deployment automated impact assessment mandatory cases high risk examples high risk include limited following situations automated decision impact assessment referred paragraph shall case required case potential unfair bias discrimination towards subjects including price discrimination employment discrimination unfair differential access services potential loss control agency subject including economic psychological manipulation large scale application automated decisionmaking including profiling systematic monitoring may affect communities society avoid confusion limitative list could argued paragraph could left entirely guidance provided alongside prototype removed term unfair bias given ambiguous meaning clear whether text referring bias statistical sense model label bias fairness sense plain language continues next way forward impact assessment policy prototyping experiment amended text based feedback comments automated system impact assessment shall contain least detailed description automated system design training data purpose assessment quality integrity representativeness data used train underlying model assessment risks involved automated system poses rights freedoms natural legal persons specific focus subjects determination significant risks description measures envisaged address risks including safeguards security measures mechanisms protecting rights freedoms subjects demonstrate compliance regulation taking account rights legitimate interests concerned explanation measures deemed adequate assessment legitimacy necessity deployment automated decisionmaking explicit reference need determine significant identified risks focus requirements value tensions critical reflection adequacy risk reducing measures legitimacy via additional requirement justification cases automated decision impact assessment indicates application may result high risk natural rights freedoms natural legal persons risks mitigated user shall prior deployment consult supervisory way forward impact assessment policy prototyping impact assessment policy prototyping context risk assessment prescriptive approach classifies priori set risks organisations required identify stipulating rigid list applications defined based given criteria sector intended use etc prescriptive approach way automatic given application falls list considered high risk procedural approach enables organisations identify assess mitigate risks following number steps indicative criteria examples procedural approach automatic directed solely identification risks involves carrying methodical process risks identified also mitigated effect organisations rely corporate ethics values internal governance structures measures internal roles teams responsibilities operations management strategies communicating external stakeholders determine risks posed systems adia framework example procedural findings program confirm importance usefulness codifying risk assessment procedure viable governance mechanism putting place procedure identify assess mitigate risks accompanied detailed guidance taxonomy values examples harms list possible mitigation measures enables organisations better understand document address risks posed systems demonstrated program acknowledging limitations exercise participants startups operating different regions sectors able adopt implement adia framework based results program risk assessment approach determine high risk applications seems sound workable alternative rigid prescriptive approach based combination sectors intended risk assessment approach unconstrained prior sectoral determinations complemented set examples risks taxonomy values better job helping recommendations regulating automated making focus procedure instead prescription way determine high risk applicationsadia prototype policy evaluation based results prototyping exercise feedback prototype law playbook would advise lawmakers dealing question develop approach regulation take following recommendations account recommendations impact assessment policy prototyping experimentorganisations assess risks based specific context impact proposed procedural approach also better job taking account dynamic iterative character systems continuously evolving changing result interactions people environment risks posed systems may change keep evolving encapsulation risks based generic sectoral assumptions solution unlike procedural methodology prescriptive approach struggle identify regulate emerging risks dynamic conditions one also take account higher level uncertainty complexity ascertaining certain types risks posed systems others demonstrated program broader structural societal risks grounded moral ethical values contrast functional risks based operation systems difficult identify assess mitigate additional complexity requires robust procedural approaches risk assessment complemented operational guidance rather approach anchored rigid classifications based sector utilized notably european commission proposing procedural approach risk assessment management context recent digital services act dsa latter lays obligations large online platforms conduct risk assessments systemic risks brought relating functioning use services take reasonable effective measures aimed mitigating risks dsa act also foresees additional transparency reporting obligations include report setting results risk assessment related risk mitigation measures identified implemented context proposal dsa proposal would urge commission consider results policy prototyping experiment align consistent procedural based approach risk assessment throughout various regulatory proposals avoiding way inflexible prescriptive approach like proposed white paper procedural approach also virtue acknowledging relying factors related nature severity probability reversibility potential harms opportunity individuals exert control opt extent human oversight level automation given application enables granular assessment degree risks posed consequently enables granular determination corresponding mitigation measures necessary appropriate one equates mitigation measures set regulatory requirements companies follow building deploying applications procedural angle enables balanced adaptable regulatory approach rather applying entire set regulatory requirements default leverage procedural risk assessment approach determine right set regulatory requirements apply organisations deploying applications instead applying default level granularity associated fact procedural approach also attuned incorporate qualitative insights risk assessment see section qualitative type risk assessments impact assessment policy prototyping experimentand regardless type application context actual risks procedural approach allows flexible appropriate application regulatory requirements like human oversight explainability rights redress monitoring disclosure requirements amongst others approach statutory requirements would assigned bulk based inflexible list sectors applications proposed european commission white paper instead would tailored specific application question level extent risks assessed weighed alongside calculation benefits application procedural approach acknowledges importance looking specific context application built planned deployed helps determine tailor application specific regulatory requirements high risk applications based examples risks helping companies understand whether adia considered article playbook proved useful showcases need guidance namely terms lists examples assumptions ensure consistent reliable risk assessment process given participants received appreciated used playbook strongly encourage provision additional guidance interpret implement adia requirements regulatory requirements matter ideally guidance could provided soft law instruments order ensure appropriate flexibility adaptability changes technology society playbook process additional elements list values taxonomy harms mitigating measures considered extremely useful participants overview values taxonomy harms particular provided suitable needed guidance conduct proper risk assessment demonstrates additional operational guidance accompanied examples helps foster common understanding interpretation implementation law also demonstrates policy guidance particularly appreciated accessible made phrased manner allows understood used actually developing deploying systems practice xxii recitals provided context prototype law overwhelming majority participants stated benefited playbook would actually changed risk assessment access playbook adia playbook gave participants new insights risks applications also enabled identify new risks thus conclude guidance comply new requirements provided simultaneously new legislation defining requirements rather provide specific detailed guidance implement adia process release alongside law recommendations impact assessment policy prototyping experimentprovided post interpretation requirements supervisory authorities courts provide clarity certainty norm addressees guidance could instance framed form guidelines adia template compliance guide additional guidance also provide necessary tools tackle narrow functional technical risks broader structural societal risks overview values harms playbook enabled participants think concepts relate applications guidance complements technical perspective risk assessment according risk tends associated functioning operation system helps identify unknown risks words playbook resources reverse risk assessment strategy shifting thinking process risks application may cause technical mal function faulty operation risks could emerge manifest deployment use interaction application society shift enables developers reflect risks may affect broader societal noted throughout report assessments risk need focus solely technical functional concerns associated explainability transparency accuracy also include assessment broader structural concerns societal impacts may associated overreliance systems infringement values obviously risks emerge manifest use applications combination two approaches technical value driven helps identify new relevant risks participants also felt approach assessing application based list values made process objective systematic guidance provided adia playbook helps overcome inherent ambiguity regulation needed policy technologically neutral taxonomies examples helps identify previously unknown aspects adm system demand additional guidance participants also confirmed need tighter calibration coordination different governance instruments hard law soft law ensure regulatory regime guidance comprehensive still flexible adaptable deeply informed practical experience practitioners relevant stakeholders human rights dehumanisation impact terms fairness proportionality societal effect line technology operates also impacted however feedback received participating companies revealed risks related functioning systems built operate much easier identify risks related specific possible definition risks within regulatory scoperecommendations impact assessment policy prototyping experimentto application consequences produced systems particular feedback guidance values harms provided playbook shows difficult participants understand products services may implicate abstract values instance human autonomy difficulty prompted one participants note primary challenge imaginative enough contemplating types harm systems could result assessing risks harm meaningful applying law requires moral imagination law runs risk clear offering enough legal uncertainty avoid level uncertainty urge policy lawmakers work academia civil society industry clearly specify types risks harms expect identified systematic manner mitigated effective way playbook like one used adia framework good first step reduce uncertainty avoid burden trying identify solve every possible moral implication products deciding documenting mitigate risks posed systems needs part risk assessment process fundamental element informing overall approach based feedback received program participants would helpful users deployers adm system also described adia particular riskreducing measures taken others measures reduced services additional guidance assess risks provide taxonomy potential risks posed systems along tools better identify assess relevant ones list values taxonomy harms particular helps ensure explicit set possible risks considered risk assessment process ensures significant ones effectively flagged addressed given difficulties reported participating companies however prototype playbook could improved provide specific guidance identify assess mitigate risks related ethical issues societal impacts based feedback given participating companies new law guidance around risk assessment need clearly narrowly specify types risks targeted ensure organisations able understand practically comply yet providing clarity regard broader ethical societal risks necessarily challenging commentators pointed risk acceptable level removed altogether reasons accepting residual risk also included adia providing insights value effectiveness measures selected would help determine right set regulatory requirements applicable application question bring greater clarity tensions amongst values affected resolved improve documentation risk assessment processes justifying selection mitigation measuresrecommendations impact assessment policy prototyping regulating lawmakers must cognizant complex landscape actors involved developing deploying using impacted responsibility conduct adia may shared different actors taxonomy reflects different roles clarity responsible conducting adias parts adia recommended development taxonomy important two main reasons appropriately assign tasks identifying assessing mitigating risks better understand group stakeholders affected sound taxonomy different actors involved risk assessment implementing requirement risk assessment important clear desired particular guidance explanation values may affected throughout program participants already identified risks relate performance model data bias competence course performing risk assessments instance dpia gdpr compliance value tensions may arise helpful experience understanding impacts adm might also lead better identification risks many cases overlap adia gdpr dpia requirements order avoid double work costs adia dpia requirements integrated much possible set values may impacted provide guidance may tension one another reinvent wheel combine new risk assessment processes established ones improve overall approachrecommendationsrecommendationsrecommendations impact assessment policy prototyping experimentfinal reflections policy prototyping methodology testing prototype law participants yielded key insights value introducing risk assessment process valid governance option within evolving regulatory debate keeping idea prototyping lawmakers take experiences policy prototyping exercise improve open loop program encourage lawmakers regulators embark prototyping exercises could surpass limitations current program test greater degree accuracy effectiveness mandatory adm risk assessment policy prototyping program also helped test concept assess value policy prototyping methodological instrument aimed producing evidencebased recommendations policymakers found program promising avenue collaboration agile vehicle test iterate shape governance new emerging technologies look forward possibility similar experiments future even broader set partners come join impact assessment policy prototyping case european commission proposed white paper application would deemed high risk meets two criteria application employed sector given characteristics activities typically undertaken significant risks expected occur application sector question used manner significant risks likely good example approach risk determination comes german data ethics commission opinion algorithmic data governance proposes five tier risk classification based upon combined severity likelihood calculation different levels regulatory obligation attaching different level risk ranging level additional regulatory obligations level prohibition another example one provided center democracy technology response white paper advocating risks based severity case european commission regulatory outline presented white paper sector criterion suggests sectors covered specifically exhaustively listed new regulatory instance healthcare transport energy parts public sector list periodically reviewed amended necessary function relevant developments good example qualitative approach found singapore model governance framework companion guide present long list questions organisations consider related risk goal collecting stakeholder feedback encouraging dialogue reflection risks dutch government collaboration considerati published proposed artificial intelligence impact assessment similarly lists set questions meant elicit risk analysis ieee standard assessing impact human another highly qualitative approach measuring risk presents assessment applications calls ongoing monitoring revision iteration impact assessment institute proposed algorithmic impact assessment aia framework designed public agencies aimed supporting affected communities stakeholders seek assess claims made automated decision systems determine use acceptable add also link term algorithmic impact assessment aia referenced ainowinstitute academic side calvo proposed human impact assessment technology advancing impact assessment intelligent systems introduces social science methodologies gathering qualitative input stakeholder population risk assessment case algorithmic impact assessment tool developed canadian government help federal agencies comply directive automated decision tool developed partnership open source license currently hosted github tool uniquely quantitative consisting approximately different questions requiring simple yes answer impact risk score half questions impact questions answers incrementally increase total risk score half questions mitigation questions incrementally decrease risk score see full list questions november qualitative assessments support many regulatory agencies assessment list trustworthy altai tested proposed high level expert group artificial intelligence consists lengthy set questions organisations address new application significant impact human lives potential interfere fundamental rights applications present physical safety risk intention altai however produce risk score even final determination whether high rather altai meant collaborative reflection exercise focusing organisations important questions answer issues address deploying new ieee standard assessing impact human also highly qualitative approach measuring risk presents long term life cycle assessment applications calls ongoing monitoring revision iteration impact assessment notes impact assessment policy prototyping see agency fundamental rights report getting future right artificial intelligence fundamental rights recommending legislator consider making mandatory impact assessments cover full spectrum fundamental see also mantelero big data blueprint human rights social ethical impact assessment describing proposing broad impact assessment intentionally modeled dpias expanded include human rights ethics related issues normally encompassed dpias center democracy technology response proposing separate human rights impact assessment hria conducted top aia application presents risks individual liberties rights data society governing artificial intelligence upholding human rights dignity arguing human rights central lens thinking harms could occur ieee recommended practices assessing impact autonomous intelligent systems human incorporates many concepts human rights law somewhat broader human see facebook response white paper presents concept automated decision impact assessment adia akin dpias balanced alternative requiring blanket prior reviews regulator way align gdpr principle accountability whereby organisations acting controllers best position assess determine document level risk raised processing see also submission chair legal regulatory implications artificial intelligence universit√© grenoble alpes white paper stating ompliance application legal ethical requirements first selfassessed developers could draw comparison data protection impact assessment dpia existing gdpr privacy design daniel schiff address question academic paper principles practices responsible closing gap paper offers five interconnected reasons explain difficulty developing impact scope complexity potential impacts vast environmental democratic physical safety human agency economic becomes hard single tool process resource help organisation successfully consider identify mitigate risk across range possible many different disciplines involved creation systems organisations regulators find difficult know place accountability different discipline involved creating monitoring different nonharmonious concepts risk mitigation abundance risk assessment tools developed promoted various organisations many date lacking real evidence effectiveness distracting functional separation technical experts within organisations limits potential communicate effectively understand issues robustly respond considerations impact idea emulating impact assessments existing dpia model also proposed number see submission chair legal regulatory implications artificial intelligence universit√© grenoble alpes white paper compliance highrisk application legal ethical requirements first developers could draw comparison data protection impact assessment dpia existing gdpr privacy design principle mantelero big data blueprint human rights social ethical impact assessment describes proposes broad impact assessment intentionally modeled dpias expanded include human rights ethics related issues normally encompassed dpias katyal private accountability age artificial intelligence similarly describes assessment model human impact statement based dpia model expanded include population level societal impacts well addressed noted paper facebook believes approach would balanced alternative requiring blanket prior reviews regulator applications white paper recommends would also align gdpr principle accountability whereby organisations acting controllers best position assess identify document mitigate risk raised processing given existing processes operations companies already created conduct dpias one could add already precedent familiarity type selfassessment could adapted notes impact assessment policy prototyping noted facebook response onsistent gdpr approach complementing dpias approved codes conduct way assess impact processing operations performed controllers processors adias complemented detailed industry best practices codes conduct codes practice standards certification study policy innovation starts proposition single universal best policy design best regulatory technology instead contextual criteria success imply different regulatory designs different problems situations societies institutional must test policy ideas learn empiricism adapt regulatory technology time wiener isk governance experts scholars developed new frameworks continue value scientific data alongside qualitative measures risk particular risk governance frameworks three important features focus broadening participation risk governance process including range key stakeholders value qualitative data policy analysis use deliberative budish european commission risky business similar argued oxford university governance group response additional criteria risk assessment consider incorporating scale use number users frequency use given application risk assessment procedure instance models recommend police coverage neighborhoods based past arrests lead increase arrests neighborhoods due increased coverage data influence model creating feedback loop could cause overpolicing unrelated actual rate crime models deny loans subjects share particular characteristic never able learn whether assessment accurate adjusted final assessment list trustworthy altai hleg advised altai best completed involving multidisciplinary team people could within outside organisation specific competences expertise requirements related hleg recommended identifying following types stakeholders incorporate group conducts altai though gave detail types responsibilities roles within altai designers developers system data scientists procurement officers specialists staff use work system officers prescriptive criteria may useful presumption potential high risk actual determination made organisations carrying risk assessment along lines center information policy leadership cipl response argued roviding suggestive criteria examples presumptions high risk would practical use developing using including smes rigid lists high risk applications suited highly contextual evolving character related argument stressing importance procedural approach fact prescriptive approach seems ignoring long standing guidance make proper risk see submission centre governance future humanity institute university oxford response white paper binary approach seem follow existing risk assessment methodologies usually define risk given scenario function combination probability occurrence hazard generating harm given scenario severity harm citing general risk assessment methodology need incorporate benefits mitigating factors risk analysis raised many see brookings institute response white paper egulation raise barriers development application underscores need balanced approach regulation one takes account risks benefits regulatory process informed experts science sufficiently flexible respond learn experiences end notes impact assessment policy prototyping experiment center information policy leadership cipl response high risks related system may overridden compelling benefits individuals organisations society large thus organisations allowed rebut presumptions high risk demonstrating countervailing benefits individuals society united states proposed algorithmic accountability act authorizing ftc require companies conduct adias would include assessment relevant benefits costs omb memorandum federal agencies regulation also emphasizes executive agencies factor benefits evaluating risks entailed use application canada directive automated decision making accompanying algorithmic impact assessment tool relevant agencies use comply directive something similar tool uses scale different impact levels based reversibility duration impact determine statutory obligations apply agency branch attempting deploy procure obtaining approval approval obtained categories potential obligations include following peer review obligations public notice requirements human loop requirements explainability requirement decisions made testing requirements monitoring requirements training requirements contingency planning requirements approval operate different impact level assigned statute report tool generates different types obligations within categories importance drafting policy prototype particular playbook way readily accessible usable actionable technologists opens exciting synergies collaboration opportunities experimental governance field legal context legal design innovative approach gained traction last five years dedicated rendering laws regulations understandable easy use see minzoni believe legal design discipline set methodologies help render law whether actual law prototype law accessible usable bridging language barriers technologists policy much line increasing call look beyond individual harms pay attention societal level harms risk see high level experts group recommendations trustworthy establishing societal environmental harms one seven core requirements incorporating requirement final assessment list trustworthy german data ethics commission recommendations determination severity harm must include potential harms society social cohesion harms individual rights omb memo federal agencies regulation agencies consistent law carefully consider full societal costs benefits distributional effects considering regulations related development deployment ieee recommended practices assessing impact autonomous intelligent systems human comprehensive framework risk analysis expressly leaning toward societal level impacts individual impacts mantelero big data blueprint human rights social ethical impact assessment academic paper proposing combination human rights ethics social impact framework risk analysis attempting incorporate societal risks ways traditional impact assessments singapore wef guide organisations wherein numerous assessment questions ask organisation consider potential impacts application society collectively xxiv national institute standards technology nist argued plan federal engagement developing technical standards related tools stakeholders development plan expressed broad agreement societal ethical considerations must factor standards clear done whether yet sufficient scientific technical basis develop standards xxv final assessment list trustworthy altai hleg suggested number questions asked answered recorded beginning questions delve integration dpias risk assessment processes put place processes assess detail need data protection impact assessment including assessment necessity proportionality processing operations relation purpose respect development end notes impact assessment policy prototyping experimentdeployment use phases system put place measures envisaged address risks including safeguards security measures mechanisms ensure protection personal data respect development deployment use phases system similar idea putting systems practice order learn acting one advanced goodai response european commission proposes risk monitoring process whereby firms deploying voluntarily submit collaborative ongoing risk assessments reference testing centers giving european commission opportunity see risk assessment practice learn types risk concerned notes impact assessment policy prototyping experimentbason design policy routledge brest power theories change stanford social innovation review brookings institute submission white paper artificial intelligence importance opportunities transatlantic cooperation brown tim barry change journal product innovation management brown design harvard business review budish european commission risky calvo rafael dorian peters stephen cave advancing impact assessment intelligent nature machine intelligence center democracy technology response european commission consultation white paper artificial intelligence european approach excellence trust supporting chair legal regulatory implications artificial intelligence miai grenoble alpes consultation white paper artificial intelligence european centre information policy leadership cipl response commission white paper artificial intelligence european approach excellence considerati ecp platform information society artificial intelligence impact assessment council europe recommendation committee ministers member states human rights impacts algorithmic aspx council europe governing game changer impacts artificial intelligence development human rights democracy rule law conclusions conference data society governing artificial intelligence upholding human rights dignity datasociety european proposal legal act european parliament council laying requirements artificial intelligence com ares european commission white paper artificial intelligence european approach excellence bibliography impact assessment policy prototyping experimenteuropean commission expert group artificial intelligence hleg assessment list trustworthy artificial intelligence altai european commission regulation european parliament council single market digital services digital services act amending directive european commission ethics guidelines trustworthy high level expert group artificial intelligence european commission communication building trust human centric artificial intelligence european guidelines data protection impact assessment dpia determining whether processing likely result high risk purposes regulation european union agency fundamental getting future right artificial intelligence fundamental facebook comments european commission white paper artificial intelligence european fuller lon morality law german data ethics opinion data ethics response consultation white paper artificial intelligence european approach connecting ecosystem excellence ecosystem trust concrete proposal paper available european commission white paper artificial intelligence consultation page government algorithmic impact government directive automated ieee recommended practice assessing impact autonomous intelligent systems human ieee std may doi ethically aligned design vision prioritizing human autonomous intelligent information commissioner office ico big data artificial intelligence machine learning data impact assessment policy prototyping experimentkatyal sonia private accountability age artificial intelligence ucla rev heinonline kelsen law specific social technique chi rev kimbell lucy introducing sprints researching design policy findings academic research cabinet office policy lab kontschieder prototyping policy leurs bas kelly proof concept prototype pilot mvp name four methods testing developing mantelero alessandro big data blueprint human rights social ethical impact computer law security review minzoni marco legal design design make law easier mittelstadt brent daniel patrick allo mariarosaria taddeo sandra wachter luciano ethics algorithms mapping debate big data society national institute standards technology department commerce leadership plan federal engagement developing technical standards related tools prepared response executive order oecd recommendation council artificial intelligence office management budget omb guidance regulation artificial intelligence personal data protection commission singapore pdpc infocomm media development authority imda model artificial intelligence governance framework second position paper behalf denmark belgium czech republic finland france estonia ireland latvia luxembourg netherlands poland portugal spain sweden innovative trustworthy innovative trustworthy two sides reisman dillon jason schultz kate crawford meredith whittaker algorithmic impact assessments practical framework public agency accountability schiff daniel bogdana rakova aladdin ayesh anat fanti michael principles practices responsible closing gap arxiv preprint unesco preliminary report first draft recommendation ethics artificial intelligence uni global top principles ethical artificial intelligence impact assessment policy prototyping experimentuniversity future humanity institute consultation european commission white paper artificial intelligence european approach excellence algorithmic accountability act villa alvarez diana pamela valentina auricchio marzia design prototyping wiener jonathan regulation technology technology technology society world economic forum wef companion model governance framework implementation selfassessment guide world economic forum wef agile governance reimagining fourth industrial adia prototype law adia prototype guidance playbook xxrecitals principles annex automated decision impact assessment adia prototype adia prototype guidance playbook risk assessment overview values relevant taxonomy potential harms mitigating measures impact assessment policy prototyping experiment matter scope automated decision impact assessment adia prototype hereinafter adia policy prototype prototype makes distinction automated systems adm processes pose low risk rights freedoms natural legal persons may pose high risk defined herein prototype shall apply use automated systems natural persons course personal household activity connection professional commercial activity automated system provided actor natural person context professional commercial activity policy prototype shall apply set forth herein definitions prototype refers various actors field automated systems particular developers users subjects developer natural legal person developed automated system actor may provide learning algorithm likely person organization responsible selecting training data relevant learning algorithms subsequent creation training model user natural legal person deploying automated system achieve particular goal separately definition entails high low risk application generally speaking organization tax authorities detecting fraud social media platforms providing automated personalized recommendations banks assessing creditworthiness client automated decision system deployed system integral part delivery product service natural legal person intended use automated decisionmaking system opposed actors involved developing determining use would actor informed decision automated system follow automated decision example doctor getting advice treatment automated system border control officer conducting search person flagged system employee user independent user using automated system product service document used solely completion open loop policy prototyping program automated decision impact assessment sole purpose document elicit feedback content format participating companies policy prototyping program fictional document deprived binding legal normativity recitalsadia prototype law impact assessment policy prototyping experiment subject natural legal person directly indirectly subjected impacted automated system actors discrete role practice roles might coincide example autonomous cars could considered user subject time car manufacturer may also considered user principles purpose policy prototype distinction made automated decisionmaking systems general whose decisions likely pose high risk rights freedoms natural legal persons developing using automated system following principles minimum taken account according approach respect fundamental rights human agency need human oversight technical robustness accuracy safety privacy data protection transparency interpretability diversity fairness environmental societal wellbeing accountability use automated systems may pose high risk rights freedoms natural legal persons user shall take specific technical organizational measures ensure negative impact effects minimized requirements met whether high risk rights freedoms natural legal persons must judged context nature purpose scope application high risk significant chance automated decisions made automated system subsequent actions taken users subjects basis automated decision result negative effects significant adverse impact rights freedoms natural legal persons effects significant negative impact rights freedoms natural legal persons may include loss life injury financial property damage reputational damage interference fundamental rights right equality right privacy right freedom speech context automated decisionmaking particular attention given economic psychological societal harms may flow forth automated include inter alia legal effects lead loss economic opportunity price discrimination employment discrimination unfair commercial practices effects lead psychological harm loss loss personal autonomy collective harms loss liberty economic political instability taxonomy harms found adia prototype guidance playbook automated systems used augment human agency increase human autonomy contribute human nonetheless important note automated systems may limit human agency may used influence nudge manipulate subjects without knowledge developers users take proper measures avoid leveraging persuasive capabilities automated systems unduly influencing manipulating subjects subjects right subjected automated without meaningful human intervention decision significant negative impact rights prototype law impact assessment policy prototyping experiment right protection consequences automated absolute right right must considered relation function society balanced fundamental rights accordance principle proportionality instance automated assessment creditworthiness may warranted subject wishes enter contract receive credit risk management governance user shall assess whether decisions made automated systems may result high risk rights freedoms natural legal persons user must conduct impact assessment regards automated system prior deployment system particularly impact assessment evaluate risks poses subjects consider accuracy quality representativeness data used accuracy quality trained models broader system risk management automated decision making impact assessment propose measures address risks completing impact assessment risk reduced acceptable level acceptable level risk defined significant adverse effect rights freedoms subjects adverse effects may limited death bodily harm financial damage reputational damage discrimination stigmatisation user requires assistance input developer assess reduce risks shall responsibility user enlist help developer automated systems systems often change significantly throughout life cycle therefore user must regularly update impact assessment ensure decisions result system still meeting requirements set forth prototype impact assessment indicates process would absence safeguards security measures mechanisms mitigate risk high risk user opinion risk mitigated reasonable means terms available technologies cost implementation supervisory authority consulted prior deployment automated system use making large scale affecting communities society whole use automated leading unfair bias discrimination use automated limiting human agency use automated context surveillance may pose significant risks areas impact assessment case warranted guidance provided playbook reduce risk automated user robust system risk management governance given potential impact automated highest management involved managing risk ensuring legitimate ethical application automated order demonstrate compliance policy prototype user adopt internal policies implement measures meet requirements set prototype risk management governance cover topics allocation responsibility policies procedures escalation protocols data management impact assessments model management subject rights awareness raising monitoring oversight reporting furthermore developer user urged set mechanisms facilitate protect prototype law impact assessment policy prototyping experiment subject matter objectives policy prototype lays rules help protect fundamental rights freedoms natural legal persons may affected automated policy prototype lays rules help ensure trustworthy application automated policy prototype aims stimulate development use automated decisionmaking society article material scope policy prototype shall apply development production distribution use automated systems whose use may result high risk rights freedoms natural legal persons article definitions actor means developers users subjects party contributes design development production distribution training deployment automated systems affected system decisions algorithm means finite sequence instructions set rules designed complete task solve problem model means result training algorithm training data model mathematical representation learned domain used map inputs outputs model primary component automated system fully automated decision means decision made automated system acted upon without meaningful human intervention automated system means computational process derived machine learning statistics artificial intelligence data processing technique makes decision facilitates human developer means natural legal person responsible technical development making system user means natural legal person deploying automated system achieve particular goal means natural legal person using automated system purposes intended subject matter objectives chapter definitionsadia prototype law impact assessment policy prototyping experiment subject means natural legal person subjected directly indirectly decision automated system automated decision impact assessment adia means systematic assessment impact envisaged automated system application article risk assessment prior deployment automated system user shall assess risks envisaged automated system application rights freedoms natural legal persons cases application automated system likely result high risk rights freedoms natural legal persons user shall carry automated decision impact assessment prior deployment automated decision impact assessment referred paragraph shall case required case potential unfair bias discrimination towards subjects including price discrimination employment discrimination discriminatory differential access services potential loss control agency subject including economic psychological manipulation large scale application automated including profiling systematic monitoring may affect communities society whole automated system impact assessment shall contain least detailed description automated system design training data purpose assessment quality integrity representativeness data used train underlying model assessment risks involved natural legal persons specific focus subjects measures envisaged address risks including safeguards security measures mechanisms protecting rights freedoms subjects demonstrate compliance policy prototype taking account rights legitimate interests concerned cases automated decision impact assessment indicates application may result high risk natural rights freedoms natural legal persons risks mitigated user shall prior deployment consult supervisory risk management governanceadia prototype law impact assessment policy prototyping experiment governance developers users shall adequate effective internal governance structures measures place ensure robust oversight respective role roles design development deployment training automated systems highest management within relevant organization shall basis involved responsible explicating ethical values guide process design development deployment training automated systems developers users shall sound system risk management internal controls place specifically aimed identifying assessing documenting addressing risks involved design development deployment training automated decisionmaking systems measures include establishing adequate monitoring reporting schemes developer users able demonstrate measures taken adequate mitigate risk posed automated system used playbook would complement forthcoming legislation could basis soft law instruments codes conduct codes practice standards certifications industry guidelines etc section set ways comply proposed policy prototype implementing elements playbook organization good position comply prototype law prototype law requires automated impact assessment completed automated systems may pose high risk natural legal person rights freedoms quantifying risk impact adm system people society differ per application determine whether high low risk consider industry accepted formula developing deploying adm system developer user need assess based concrete application probability disruptive event lead negative impact well severity impact adia prototype guidance playbook risk assessment risk probability disruptive event occurs severity negative impact prototype law impact assessment policy prototyping experiment probability different factors may play role probability disruptive event occurring type application scope application number subjects involved complexity model novelty domain application deployed investment made issue spotting robustness reliability work done building testing phase factors need weighed based circumstances case impact impact disruptive event natural legal persons coming adm needs determined basis taking account scope nature context application negative impacts commonly associated adm described literature see taxonomy potential harms table example list harms may significant effect natural legal adia prototype law impact assessment policy prototyping experiment order quantify risk developers users implement risk assessment process could look something like step describe proposed adm system describe adm system goal first determine context adm system used goal system context operates determines large extent potential risk system example adm systems used medical context determine type amount medicine administer pose greater risk people recommendation engine movies streaming platform describing adm system explain system works stakeholders involved stakeholders interact context step assess adm changes existing situation second step determine given context whether adm introduces new risks benefits changes existing level risk end developer user needs determine automating existing human process introducing new automated process introduces new risks changes existing level risk stakeholders step analyse root cause change find root cause change example introducing adm became less clear decision made opacity attributed complexity model use list potential harms table find relevant root causes may lead risks rights freedoms particular subjects step determine impact stakeholders associated values determine identified changes affect stakeholders positive negative associate changes fundamental human rights hypothetical adm process increases risk discrimination thus undermining fairness equality use recitals well taxonomy harms table determine potential negative impact proposed adm system individual societal level relate values described table step determine value tensions discover tensions values relation stakeholders algorithm nudges people microtransactions platform improving bottomline may affect autonomy material another proactively removing hate speech reduces harm overall beneficial perfect accuracy task result valid speech may mistakenly taken may affect groups people others use overview values table taxonomy harms table risk practice prototype law impact assessment policy prototyping experiment determine probability negative impact occurring determine likelihood negative impact manifesting devote specific attention model step identify possible changes mitigating measures identify possible changes design alternatives risk mitigating measures reduce negative effects stakeholders see table example list technical organizational measures mitigating measures help step step assess consequences changes mitigating measures determine changes affect stakeholders positive negative step decide changes mitigating measures implement decide changes make based established principles others refer taking account laws norms step implement document implement document changes developer user could make distinction quick scan risk assessment prescreening determine whether full scale automated impact assessment necessary stopping step user follow document steps full scale automated decision impact assessment prototype law impact assessment policy prototyping experiment values relevant table overview values relevant value description possible relevance context adm privacy data protection right protection personal sphere protection personal systems able gather process infer data unprecedented scale speed personal autonomy ability person decide good bad ability think act without reliance others without control systems enable conscious delegation personal autonomy systems enable advanced personalized persuasion human dignity notion person intrinsic worth respected systems enable datafication persons people may believe engaging another person rather automated system ability think act without interference others negative liberty ability individual positive liberty systems enable surveillance unprecedented scale public private sector fairness equal distribution benefits costs substantive fairness acting fairly procedural fairness systems fairness impacted replication unfairness society potential systems procedurally unfair inaccessible contested responsibility moral obligation act particular situation duty care responsibility may outsourced applications accountability obligation account activities take responsibility actions disclose transparent manner may make harder hold actors accountable actions democracy systems governance based people chosen representatives respect rule law human systems may disrupt democratic processes changing flow information interactions people rule law governance law exercise government rule civil rights laws implicated systems material ability derive material assets systems may effects personalized pricing systems may effects automation shifting economic power transparency condition enables openness honesty visibility systems may opaque undermining transparency interpretability debate influence society still infancy concrete harms context dependent discussion generally takes place level values discuss harms connections underlying values often made instance discuss harm algorithmic manipulation refer shared value personal prototype law impact assessment policy prototyping experiment make abstract definition harmful consequential decision tangible need first describe classify number harms particular relevance context make distinction individual dimension value collective dimension value conversely harms also effect individual collective level strong focus individual dimension values harms literature collective values interests also taken please note impact automated system much dependent context used context deploy automated systems assess individual collective harms relevant consider see following pages example list harms may significant effect natural legal potential harms future privacy forum unfairness algorithm distilling harms automated prototype law impact assessment policy prototyping experiment example list harms may significant effect natural legal persons individual dimension harm economic harms root cause effect potential harm values stake examples prices tailored groups individuals based pricing price discrimination fairness material wellbeingsubjects get higher price product frequenting product page liking posts product signals strong interest based data target group insights target group influenced without knowledge economic manipulation subjectsfairness personal autonomy material wellbeing used show users ads status updates given topic pivot towards displaying desired behaviour healthier lifestyle empowers employing versus subjected power differential information asymmetriesunfair commercial practices manipulation hidden false advertisement fairness autonomy material human dignity employer evaluates employees based monitoring unbeknownst automatic decisionmaking process intentionally designed biased towards certain groups intentional loss economic opportunity employment discrimination narrowing choicefairness material wellbeing human dignity hiring algorithm intentionally trained favour young white males data may unknowingly discriminatory leading groups individuals treated unintentional loss economic opportunity employment discrimination narrowing choicefairness material wellbeing human dignityhiring algorithm unintentionally disproportionately benefits young white males based training data reflects hiring patterns data used profile subjects place different target access goods servicesnarrowing choice fairness credit scoring system used differentiate valuable customers adia prototype law impact assessment policy prototyping experiment dimension harms psychological harm root cause effect potential harm values stake examples increased surveillance personal effect autonomy human dignity privacynot sharing information fear future currently unknown consequences opaque automated loss understanding decisionloss selfefficacyhuman dignity personal autonomyperson denied job computer said profiling based inaccurate data profiling stigmatization reputational damage loss dignity personal autonomy fairnessinnocent person flagged terrorist based parameters religion false positives decisions delegated adm longer make final decisionloss control personal autonomy human dignitydoctor told adm actions perform patient undermining professional judgement doctor hyper effective personalized control dependencyloss dependency addictionpersonal autonomy human dignity quantified self apps acting personal coaches persuade people make lifestyle choices sleep eat put phone away decisions made using inadequate decisions unfair decisions fairness human dignity person denied loan based incomplete incorrect data regarding financial situation automatic decisionmaking process biased towards certain groups intentional unintentional unfair decisions discrimination stigmatizationfairness human dignity material hiring algorithm functions unintentionally disproportionately benefits white men based patterns exacerbating women current underrepresentation functions presenting current situation conception futureloss creativity reflexivitypersonal autonomy human dignitybecause model trained historic data may perpetuate strengthen status quo think outside prototype law impact assessment policy prototyping experiment harms root cause effect potential harm values stake examples increases ability surveil public surveillance loss liberty autonomy invasion privacy chilling effectsliberty personal autonomy privacyuse facial recognition emotion detection television cctv machine learning models black boxes model complex loss understanding decisionlack understanding judgment inability verify correctness accuracy dehumanisation bias discrimination procedural fairness autonomy transparencyorganisations unable explain rationale risk classification credit applications based data target group insights target group influenced without knowledge manipulation subjects fairness liberty autonomy dignity election manipulation voters targeting messages susceptible data may used profile subjects place target tailored approach loss collectivity insurance collectivity fairness equality personalized insurance based driving behaviour prices tailored groups individuals based pricing price discrimination fairness material wellbeingvulnerable groups targeted higher interest rates loans profiles perpetuate strengthen existing societal stereotypingpolarisation division fairness equality rule law human dignitysentencing algorithm incorrectly judging people color higher change recidivism white people used access bubbles polarisation division loss freedom expressionrule law democracy material content social media platforms strengthen existing opinions used doctor images audio video deepfakes disinformation fake newspolarisation division political instabilitydemocracy material wellbeinguse deepfakes make look like person said done something empowers employing versus subjected power differential information asymmetriesinequality stratification society political instabilityrule law equality employers access adm manage control workforce whereas employees access systems automatic decisionmaking process biased towards certain groups intentional discrimination political instabilityrule law equality algorithm used assess ethnicity person based name intentionally exclude service data may unknowingly biased leading groups individuals treated unintentional discrimination rule law equality material algorithm incorrectly judged people color higher chance recidivism white people data may used profile subjects place target access goods servicesdiscrimination stratification societyfairness equality material algorithm may exclude high risk categories people debts prototype law impact assessment policy prototyping experiment automated system makes decisions likely result high risk rights freedoms natural legal persons user take necessary technical organizational measures ensure automated system developed used lawful ethical robust manner technical organizational measures described shall particular aimed ensuring automated system automated decisions transparent interpretable automated system technically robust accurate reliable otherwise safe automated system functions without unfair unevenly distributed bias including content training data reflects diversity natural legal persons centered around automated system designed functions accordance applicable data protection principles including limited purpose limitation data minimization limited storage periods data quality data protection design default data security automated system used unduly influence manipulate enduser subject actors appropriate procedures place ensuring accountability accordance regulation number different interventions user take order mitigate risks identified set table described measuresadia prototype law impact assessment policy prototyping experiment activities activities may contribute trustworthy problem definition specify intended use case determine model risk assessment data selection collection select data collect data data preparation cleaning transformation reduction integration feature engineering splitting data training validation holdout determine whether data representative problem domain screen data bias review feature engineering risk ensure data protection model data determine model evaluation criteria training candidate models model tuning model validation model selection testing document modelling assess model evaluation criteria perspective values precision recall determine presence bias assess choices model tuning selection perspective subject ensure proper validation testing interpret model interpret model outcomes ensure global local interpretability model detect unwanted unfair outcomes based individual decisions perform fairness testing external assessment outcomes party audit model deployment document model training testing process communicate model operation acceptance revisit risk assessment evaluate sociotechnical interaction train interaction model disclose use adm subjects particular provide subject rights redress mechanisms monitoring monitor performance implement feedback monitor performance time degradation bias monitor exception handling provide mechanisms corrigibility interruptibility periodically update risks assessmenttable example list technical organizational measures mitigating measuresadia prototype law impact assessment policy prototyping experiment definition first step reducing potential risk associated adm assess potential risk application conceptual phase preferably using methodology described data selection collection preparation selecting collection preparing data users assess quality data users particular asses accuracy dataset terms well values dataset match true characteristics entities described dataset words closely data represent reality accuracy dataset terms trustworthiness data words data gathered reliable source trust values accurate completeness dataset terms attributes items recently dataset compiled updated relevance dataset context data collection may affect interpretation reliance data intended purpose integrity dataset joined multiple datasets refers well extraction transformation performed usability dataset including well dataset structured machineunderstandable form human interventions human filtered applied labels edited data furthermore users able account data used process training data subsequent input data user must able attest data came used wastransformed etc therefore users properly log different data sources case describe steps preparing data collecting using data personal data protection rules taken account possible synthetic data used training testing purposes model data important element evaluation adm system accuracy predictions determining accuracy adm systems make decisions impact people classification accuracy total number correct predictions divided total number predictions considered appropriate metric proper metric instance also take account effect false positives false negatives account choices made tradeoff recall false negatives precision false positives users assess risks subjects associated classified false positive false negative factor prototype law impact assessment policy prototyping experiment specific part accuracy often mentioned context bias bias could result amongst reasons using training data contains unknown bias instance attributed sample selection errors also fact training data accurately reflects real world discriminatory situation order avoid bias ongoing conversations removing sensitive attributes related bias gender ethnicity methods called blindness methods however latent variables related sensitive attributes bias may still occur therefore users consider using approaches whereby bias captured model subsequently corrected detection finally users follow state art terms training testing validating models interpret model outcomes process model selection testing validation understanding outcomes important assess whether model performing adequately also perspective subject supervisory authority explainability model outcomes important furthermore model tested fairness instance counterfactual fairness testing counterfactual fairness captures intuition decision fair towards individual actual world counterfactual world individual belonged different demographic group results different based instance ethnicity model almost certainly unfairly biased model deployment finally deploying model user train proper operation adm system particular teaching scope limitations strengths weaknesses system furthermore user observe subjects interact system determine within bounds original risks assessment therefore also worthwhile revisit initial risk assessment determine still representative final outcome phase monitoring enforcement model operation important well behaves time outside world may change making predictions based old reality less accurate time therefore user implement mechanisms deal model degradation also important responding subject feedback complaints may indicative issues underlying model example breast cancer screening want ensure miss possible tumors therefore recall set high even means false positives healthy women getting wrong diagnosis fraud detection situation may different recall high lot people flagged potential fraudsters negative consequences situation might preferable increase precision might miss fraudsters might acceptable trade means avoiding trouble lot innocent prototype law
