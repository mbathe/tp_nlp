institute ethical machine learning institute ethical machine learning home principles principles overview human augmentation bias evaluation explainability reproducible operations displacement strategy practical accuracy trust privacy security risks institute initiatives responsible principles mlsecops top procurement framework explainability framework newsletter volunteers network machine learning oss ecosystem gpu computing linux foundation contributions numfocus collaboration neurips workshop keynote neurips workshop keynote newsletter contact join responsible machine learning principles practical framework develop responsibly principles responsible development provide practical framework support technologists designing developing maintaining systems learn data principles resonate invite join ethical network beta part global network leaders driving forward positive change area next responsible machine learning principles responsible machine learning principles practical framework put together domain experts purpose provide guidance technologists develop machine learning systems responsibly human augmentation commit assess impact incorrect predictions reasonable design systems review processes bias evaluation commit continuously develop processes allow understand document monitor bias development production explainability justification commit develop tools processes continuously improve transparency explainability machine learning systems reasonable reproducible operations commit develop infrastructure required enable reasonable level reproducibility across operations systems displacement strategy commit identify document relevant information business change processes developed mitigate impact towards workers automated practical accuracy commit develop processes ensure accuracy cost metric functions aligned applications trust privacy commit build communicate processes protect handle data stakeholders may interact system directly indirectly data risk awareness commit develop improve reasonable processes infrastructure ensure data model security taken consideration development machine learning systems continue reading detail principle human augmentation commit assess impact incorrect predictions reasonable design systems review processes introducing automation machine learning systems easy forget impact wrong predictions full automation technologists understand consequences incorrect predictions especially automating critical processes significant impact human lives justice health transport etc however limited obvious critical enabling reviewers end systems significant benefits join network next human augmentation examples look towards adding review processes automatic prision sentence scrutiny fully machine learning system predicts prison sentences automatically classic example system deployed carefuly ideally review especially given example inner workings model explained addressed commitment fraud detection evaluation fraud detection prediction perfect example process design necessary instead fully removing humans process completely domain expert requested verify results model ensure performance aligned objectives often partial automation people instead performing specific process may still significant value provide extra layer safety temporary manual review process rolling automation systems ultimate objective may fully automate process however reasonable may required perform deployment system review place system precision recall evaluated production period full automation may performed deemed acceptable bias evaluation commit continuously develop processes allow understand document monitor bias development production building systems make decisions always face computational societal bias inherent data impossible avoid possible document mitigate however take step back trying embed ethics directly algorithms instead technologists focus building processes methods identify document inherent bias data features inference results subsequently implications bias given implications bias identified specific domain technology technologists able create identify explain bias data features right processes put place mitigate potential risks join network next bias evaluation examples look towards effective bias evaluation pragmatic evaluation bias technologist important obtain understanding potential biases might arise different bias identified possible evaluate results breakdown based precision recall accuracy potential inference groups google tool income classification provides interactive way visualise assess model data bias possible see race sex two strongest features right datasets whether manual labelling collecting generating simulations important appreciate getting access representative balanced datasets task expect good data boring hell underpaid people wise knowledge core spacy team basically solid call technologists able make explicit efforts getting access generating training evaluation datasets equity equality beyond deployment biased system effect reinforcing societal bias professor gina neff provides insight talk gender certainly possible system configured way works towards reduing bias however extremely sensitive complex issue example want configure system equality equity decisions taken lightly cases decision beyond technologists reasons like commitment encourages technologists focus identifying documenting biases present together potential impact ethical decisions considered together relevant industry stakeholders ethics boards regulatory bodies etc explainability justification commit develop tools processes continuously improve transparency explainability machine learning models reasonable deep learning hype technologists often throw large amounts data complex pipelines hoping something work without understanding pipelines work internally however technologists invest reasonable efforts necessary continuously improve tools process allow explain results based features models chosen possible use different tools approaches make systems explainable adding domain knowledge features instead allowing models infer even though certain situations accuracy may decrease transparency explainability gains may significant join network next explainable justification examples could get better understanding compliance design explainability feature importance often challenge explainability simplified reducing scope needs explainable occasions possible increase explainability model analysing features inference results getting better understanding importance feature result would enable technologists explain model several tools help including tensorboard screen well shap shapley additive explanations allow understanding effect features domain knowledge increase explainability great insight explainability shows possible introduce explainability even complex models introducing domain knowledge deep learning models able identify abstract complex patterns humans may able see data however many situations introducing expert domain knowledge features abstracting key patterns identified deep learning models actual features would possible break model subsequent explainable pieces reproducible operations commit develop infrastructure required enable reasonable level reproducibility across operations systems often production machine learning systems capabilities diagnose respond effectively something bad happens model let alone reproduce results production systems important perform standard procedures reverting model previous version reproducing input debug specific functionality introduces complexity infrastructure tools best practices machine learning operations aid reproducibility machine learning systems proividing ways abstract computational graphs archive data step transformation pipelines adopted provide reasonable level reproducibility operations join network next reproducible operations examples develop infrastructure enables reproducibility abstracting computational step order make machine learning model reproducible necessary abstract constituent components namely data computational graph three points abstracted possible basis model reproducibility pachyderm excellent breakdown abstract computational step together components similarly seldon core provides flexible way orchestrate operations serving models production adopting open standards often important decide level abstraction possible focus building complex layers abstract multiple machine learning libraries specific data formats multiple formats trained machine learning models popular include open neural network exchange format neural network exchange format predictive model markup language displacement strategy commit identify document relevant information business change processes developed mitigate impact towards workers automated rolling systems automate medium processes almost always impact would affect multiple individuals technologists look beyond technology initiative support necessary stakeholders develop strategy rolling technology although often technologists may leading operational transformation still important make sure processes place relevant irrespective type work automated skilled otherwise join network next displacement strategy examples look towards developing displacement strategies processes reduce impact currently lot articles covering jobs automated assembly line workers field technicians call center workers etc well technical articles providing insights deploy machine learning models across production systems however often forgotten impact individuals part processes automated fortunately business change existed long time currently startups partnering delivery partners big three management consultancy firms important technologists understand potential impact subsequently actions taken mitigate impact jevon paradox interesting concept relevant current state jevon paradox paradox talks industrial revolution innovations allowed machines perform output less coal consumption intuitively thought would mean total coal required power industry would decrease happened instead given cost perform action decreased got commoditised demand arose total coal consumption power industry actually increased analogous could rise excel areas rise business change strategies planning rollout new technology automate process number people role least responsibilities automated taken consideration people transition plan possible fully benefit time resources gained automation technologists make sure able raise relevant concerns business change operational transformation plans set would make significant positive impact rollout technology practical accuracy commit develop processes ensure accuracy cost metric functions aligned applications building systems learn data important obtain thorough understanding underlying means assess accuracy often enough using plain accuracy cost metrics may correct computer may wrong human ensuring right challenge addressed right way achieved breaking implications score metrics perspective well exploring alternative cost functions based join network next practical accuracy examples could understand practical accuracy beyond accuracy uncommon teams get stuck default accuracy targets everything possible increase percentages naively important beyond accuracy understand performance model large toolbox different approaches used aid finding suitable accuracy metrics use includes core fundamentals precision recall learning curves error bars confusion matrices beyond technologists make sure understand apply fundamentals times domain specific metrics tackling industry problem technologists make sure question implications different types errors well right way evaluating errors system critical situations may constraints types errors less critical others similarly often lot domain knowledge abstracted cost functions understand answers may intuitively correct humans represent mathematical functions trust privacy commit build communicate processes protect handle data stakeholders may interact system directly indirectly developing systems learn data often large number stakeholders may affected directly indirectly building trust within relevant stakeholders done informing data held also processes around data well understanding protecting data important technologists enforce privacy design across systems well continuous processes build trust users also relevant stakeholders procurement frameworks operational users beyond join network next trust privacy examples around building trust stakeholders interact models systems privacy right levels one key way establish trust users relevant stakeholders showing right process technologies place protect personal data uber use differential privacy prime example introduced system adds noise query results noise relative level granularity required query ensure analysis still get access relevant datasets whilst avoiding exposure personal information personal data via metadata technologists make explicit effort understand potential implications metadata involved whether metadata expose unexpected personal information relevant users stakeholders cambridge analytica scandal relevant example good generalisation similar situations direct users interact system may give access data without realising privacy breaches could extracted metadata late data risk awareness commit develop improve reasonable processes infrastructure ensure data model security taken consideration development machine learning systems autonomous systems open doors new potential security breaches importantly critical aware large percentage security breaches occur due human error opposed actual hacks someone sending dataset attached email accident losing technologists commit prepare types security risks explicit efforts educating relevant personnel establishing processes around data assess implications backdoors adversarial attacks join network next security risks examples focus become aware potential risks data models adversarial patch tricking models worth remembering given machine learning systems simple functions given right inputs possible obtain expected output adversarial patches used trick machine learning models misclassify examples adding small noise input journal great video show could trick cars security intelligence great well suggestions protect always cybersecurity impossible fully protect attackers certainly possible introduce processes mitigate basic loopholes email sent wrong person large percentage data breaches caused due simple human errors sending data wrong email address mimecast interesting article points case sensitive data healthcare important technologists take consideration whole lifecycle machine learning algorithm process infrastructure store training data accuracy documentation trained model orchestration model inference results beyond principles resonate invite join ethical network beta twitter facebook linkedin github email institute ethical rights reserved
