getting future right artificial intelligence fundamental rights european union agency fundamental rights reproduction authorised provided source acknowledged use reproduction photos material european union agency fundamental rights copyright permission must sought directly copyright holders neither european union agency fundamental rights person acting behalf agency responsible use might made following information luxembourg publications office european union print isbn pdf isbn photo credits cover stock page mimi stock page stock page stock page mykola stock page stock page stock page stock page stock page stock page stock page stock page european communities page stockpage copyright coded bias rights reserved page siberian stock page good stock page stock page stock page stock page stock page stock page stock page stock page stock page copyright coded bias rights reserved page copyright coded bias rights reserved know artificial intelligence already plays role deciding unemployment benefits someone gets burglary likely take place whether someone risk cancer sees catchy advertisement low mortgage rates speak artificial intelligence machines kind things people used able today present lives realise use keeps growing possibilities seem endless fully uphold fundamental rights standards using report presents concrete examples companies public administrations using trying use discusses potential implications fundamental rights shows whether using taking rights account fra interviewed hundred public administration officials private company staff well diverse experts including supervisory oversight authorities organisations lawyers variously work field based interviews report analyses fundamental rights taken consideration using developing applications focuses four core areas social benefits predictive policing health services targeted advertising uses differ terms complex much automation involved potential impact people widely applied findings underscore lot work lies ahead everyone one way foster rights protection ensure people seek remedies something goes awry need know used also means organisations using need able explain systems deliver decisions based yet systems issue truly complex using systems responsible regulating use acknowledge always fully understand hiring staff technical expertise key awareness potential rights implications also lacking know data protection concern refer less aware rights human dignity access justice consumer protection among others also risk surprisingly developers review potential impact systems tend focus technical aspects tackle challenges let encourage working human rights protection working cooperate share knowledge tech develop use also need right tools assess comprehensively fundamental rights implications many may immediately obvious accessible fundamental rights impact assessments encourage reflection help ensure uses comply legal standards interviews suggest use growing still infancy technology moves quicker law need seize chance ensure future regulatory framework firmly grounded respect human fundamental rights hope empirical evidence analysis presented report spurs policymakers embrace challenge michael flaherty director foreword key findings fra opinions fundamental rights relevant policymaking report mean artificial intelligence fundamental rights policy framework moving towards regulation endnotes putting fundamental rights context selected use cases examples use public administration examples use private sector endnotes fundamental rights framework applicable fundamental rights framework governing use use case examples requirements justified interferences fundamental rights endnotes impact current use selected fundamental rights perceived risks general awareness fundamental rights legal frameworks context human dignity right privacy data protection selected challenges equality access justice right social security social assistance consumer protection right good administration endnotes fundamental rights impact assessment practical tool protecting fundamental rights calling fundamental rights impact assessment available guidance tools impact assessments testing practice fundamental rights impact assessment practice endnotes moving forward challenges opportunities figures figure companies using member state figure examples different automation complexity levels use cases covered figure words interviewees often used describe use cases figure awareness gdpr right opt direct marketing united kingdom country region figure awareness right say decisions automated age gender difficulty paying bills figure awareness risks discrimination using country figure correlations words respondents often mention discussing future plans use key findings fra opinions new technologies profoundly changed organise live lives particular new technologies spurred development artificial intelligence including increased automation tasks usually carried humans health crisis boosted adoption data sharing creating new opportunities also challenges threats human fundamental rights developments received wide attention media civil society academia human rights bodies policymakers much attention focuses potential support economic growth different technologies affect fundamental rights received less attention date yet large body empirical evidence wide range rights implicates safeguards needed ensure use complies fundamental rights practice february european commission published white paper artificial intelligence european approach excellence trust outlines main principles future regulatory framework europe white paper notes vital framework grounded fundamental values including respect human rights article treaty european union teu report supports goal analysing fundamental rights implications using artificial intelligence based concrete use cases selected areas focuses situation ground terms fundamental rights challenges opportunities using overarching fundamental rights framework applies use consists charter fundamental rights charter well european convention human rights multiple council europe international human rights instruments relevant include universal declaration human rights major human rights conventions addition secondary law notably data protection acquis legislation helps safeguard fundamental rights context finally national laws member states also apply see fra bringing rights life fundamental rights landscape european union luxembourg publications office european union major conventions include international covenant civil political rights international covenant economic social cultural rights international convention elimination forms racial discrimination convention elimination forms discrimination women convention torture convention rights child convention rights persons disabilities international convention protection persons enforced disappearance universal international human rights law framework including enforcement mechanisms see schutter international human rights law cases materials commentary cambridge cambridge university press framework report based interviews officials public administration staff private companies selected member states asked use awareness fundamental rights issues involved practices terms assessing mitigating risks linked use moreover interviews conducted experts deal various ways potential fundamental rights challenges group included public bodies supervisory oversight authorities nongovernmental organisations lawyers safeguarding fundamental rights scope impact assessments accountability considering full scope fundamental rights respect charter fundamental rights charter became legally binding december legal value treaties brings together civil political economic social rights single text pursuant article charter institutions bodies offices agencies union respect rights embodied charter member states implementing union law applies equally field fieldwork research shows large variety systems used heading technologies analysed entail different levels automation complexity also vary terms scale potential impact people fra findings show using systems implicate wide spectrum fundamental rights regardless field application include also beyond privacy data protection access justice yet addressing impact respect fundamental rights interviews show scope often delimited specific rights wider range rights need considered using depending technology area use addition rights concerning privacy data protection equality access justice rights could considered include example human dignity right social security social assistance right good administration mostly relevant public sector consumer protection particularly important businesses depending context use right protected charter needs consideration using systems engages wide range fundamental rights regardless field include also beyond privacy data protection access justice fra opinion introducing new policies adopting new legislation legislator member states acting within scope law must ensure respect full spectrum fundamental rights enshrined charter treaties taken account specific fundamental rights safeguards need accompany relevant policies laws member states rely robust evidence concerning impact fundamental rights ensure restrictions certain fundamental rights respect principles necessity proportionality relevant safeguards need provided law effectively protect arbitrary interference fundamental rights give legal certainty developers users voluntary schemes observing safeguarding fundamental rights development use help mitigate rights violations line minimum requirements legal clarity basic principle rule law prerequisite securing fundamental rights legislator take due care defining scope law given variety technology subsumed term lack knowledge full scope potential fundamental rights impact legal definition terms might need assessed regular basis using effective impact assessments prevent negative effects deploying systems engages wide spectrum fundamental rights regardless field application pursuant article charter member states must respect rights embodied charter implementing union law line existing international standards notably united national guiding principles business human rights ungps businesses place human rights due diligence process identify prevent mitigate account address impacts human rights principles irrespective size sector encompasses businesses working pursuing commitments ungps adopted several legislative acts addressing sectorspecific instruments particular context due obligations human rights discussions currently underway proposing new secondary law law would require businesses carry due diligence potential human rights environmental impacts operations supply chains law would likely provide sanctions encompass use see fra recent report business human rights access remedy calls improved horizontal human rights diligence rules companies impact assessments important tool businesses public administration alike mitigate potential negative impact activities fundamental rights law specific sectors requires forms impact assessments data protection impact assessments general data protection regulation gdpr many interviewees reported data protection impact assessment required law conducted however took different forms moreover prior assessments conducted focus mainly technical aspects rarely address potential impacts fundamental rights according interviewees fundamental rights impact assessments carried system appears affect fundamental rights negatively research shows interviewees knowledge fundamental rights data protection extent limited majority acknowledge however use impact fundamental rights interviewees indicate systems affect fundamental rights extent linked tasks systems used respondents aware data protection issues respondents also realise discrimination could generally problem used fra opinion legislator consider making mandatory impact assessments cover full spectrum fundamental rights cover private public sectors applied impact assessments take account varying nature scope technologies including level automation complexity well potential include basic screening requirements also serve raise awareness potential fundamental rights implications impact assessments draw established good practice fields regularly repeated deployment appropriate assessments conducted transparent manner outcomes recommendations public domain extent possible aid impact assessment process companies public administration required collect information needed thoroughly assessing potential fundamental rights impact member states consider targeted actions support developing using planning use systems ensure effective compliance fundamental rights impact assessment obligations actions could include funding guidelines training awareness particularly exclusively target private sector member states consider using existing tools checklists tools developed european international include developed group artificial intelligence prior impact assessments mainly focus technical issues rarely address potential effects fundamental rights knowledge affects rights however exact meaning applicability rights related data protection remains unclear many respondents research findings show differences private public sector interviewees private sector often less aware wider range fundamental rights could affected data protection issues known private sector however rights access rights less well known among business representatives work fully aware potential problems others said responsibility checking fundamental rights issues lies clients ensuring effective oversight overall accountability line international human rights standards example article european convention human rights echr article charter states obliged secure people rights freedoms effectively comply states among others put place effective monitoring enforcement mechanisms applies equally respect level monitoring findings point important role specialised bodies established specific sectors also responsible oversight within mandates include example oversight area banking data protection authorities variety bodies potentially relevant oversight fundamental rights perspective however responsibilities bodies concerning oversight remains unclear many interviewed private public sector public administrations use sometimes audited part regular audits private companies specific sectors also specialised oversight bodies example area health financial services also check use related technologies example part certification schemes private sector interviewees expressed wish bodies could provide expert advice possibilities legality potential uses set independent bodies mandate protect promote fundamental rights include data protection authorities equality bodies national human rights institutions ombuds institutions research shows using planning use often contacted different bodies use consumer protection bodies fra opinion member states ensure effective accountability systems place monitor needed effectively address negative impact systems fundamental rights consider addition fundamental rights impact assessments see fra opinion introducing specific safeguards ensure accountability regime effective could include legal requirement make available enough information allow assessment fundamental rights impact systems would enable external monitoring human rights oversight competent bodies member states also make better use existing oversight expert structures protect fundamental rights using include data protection authorities equality bodies national human rights institutions ombuds institutions consumer protection bodies additional resources earmarked establish effective accountability systems upskilling diversifying staff working oversight bodies would allow deal complex issues linked developing using similarly appropriate bodies equipped sufficient resources powers importantly expertise prevent assess fundamental rights violations effectively support whose fundamental rights affected facilitating cooperation appropriate bodies national european level help share expertise experience engaging actors relevant expertise specialist civil society organisations also help implementing actions national level member states consider using available funding mechanisms public administrations developing using contact various bodies responsible overseeing systems within respective mandates sectors bodies include data protection authorities using always sure bodies responsible overseeing systems often users contacted data protection authorities seek guidance input approval personal data processing involved interviewed experts highlight relevance data protection authorities overseeing systems respect use personal data however also note data protection authorities task lack specific expertise issues experts including working oversight bodies equality bodies data protection authorities agree expertise existing oversight bodies needs strengthened allow provide effective oversight related issues according experts challenging given bodies resources already stretched also highlighted important role relevant civil society organisations specialised fields technology digital rights algorithms enhance accountability use systems data protection access justice three horizontal themes research shows use affects various fundamental rights apart specific aspects affect different rights varying extent fundamental rights topics emerged research repeatedly apply cases include need ensure use right discriminated requirement process data legally right personal data protection possibility complain decisions seek redress right effective remedy fair trial two main fundamental rights highlighted interviews data protection addition effective ways complain use came repeatedly linked right fair trial effective remedy following three fra opinions reflect findings read alongside opinions call comprehensive recognition response full range fundamental rights affected specific safeguards ensure using obligation respect principle nondiscrimination enshrined article teu article tfeu requiring union combat discrimination number grounds articles charter equality law nondiscrimination range grounds specific detailed provisions several directives also enshrine principle varying scopes application automation use greatly increase efficiency services scale tasks humans would able undertake however necessary ensure services decisions based discriminatory recognising european commission recently highlighted need additional fra opinion member states consider encouraging companies public administration assess potentially discriminatory outcomes using systems european commission member states consider providing funding targeted research potentially discriminatory impacts use algorithms research would benefit adaptation established research methodologies social sciences employed identify potential discrimination different areas ranging recruitment customer building results research guidance tools support using detect possible discriminatory outcomes rarely mentioned carrying detailed assessments potential discrimination using suggests lack assessments discrimination automated decision legislation safeguard using antiracism action plan interviewees principle aware discrimination might happen yet rarely raised issue believe systems could actually discriminate interviewees also rarely mentioned detailed assessments potential discrimination meaning lack assessment potential discrimination common perception omitting information protected attributes gender age ethnic origin guarantee system discriminate necessarily true however information potentially indicating protected characteristics proxies often found datasets could lead discrimination certain cases systems also used test detect discriminatory behaviour encoded datasets however interviewees mentioned possibility collecting information disadvantaged groups detect potential discrimination absence analysis potential discrimination actual use systems also almost discussion analysis potential positive effect using algorithms make decisions fairer moreover none interviewees working mentioned using detect possible discrimination positive outcome sense discrimination better detected data analysed potential bias since detecting potential discrimination use algorithms remains challenging interviewees briefly addressed issue different measures needed address include requirement consider issues linked discrimination assessing use investment studies potential discrimination use diverse range methodologies could involve example discrimination testing could build similar established methodologies testing bias everyday life respect job applications applicant name changed indirectly identify ethnicity relation applications tests could involve possible creation fake profiles online tools differ respect protected attributes way outcomes checked respect potential discrimination research could also benefit advanced statistical analysis detect differences datasets concerning protected groups therefore used basis exploring potential discrimination finally research interviews underscored results complex machine learning algorithms often difficult understand explain thus research better understand explain results explainable also help better detect discrimination using guidance data protection data protection critical development use article charter article tfeu provide everyone right protection personal data gdpr law enforcement directive directive elaborate right include many provisions applicable use interviewees indicated systems employ use personal data meaning data protection affected many different ways however applications according interviewees use personal data use anonymised data hence data protection law would apply personal data used data protection related principles provisions apply report highlights important issue linked data protection also relevant fundamental rights respect automated decision making according eurobarometer survey europeans know say decisions automated knowledge right considerably higher among working majority interviewees raised issue however many interviewees including experts argued clarity needed scope meaning legal provisions automated decision making area social benefits interviewees mentioned one example fully automated decisions applications mentioned reviewed humans interviewees public administration stressed importance human review decisions however rarely described human review actually involves information used reviewing output systems interviewees disagree whether existing legislation sufficient many called concrete interpretation existing data protection rules respect automated decision making enshrined article opinion european data protection board edpb european data protection supervisor edps consider providing guidance support effectively implement gdpr provisions directly apply use safeguarding fundamental rights particular regards meaning personal data use including training datasets high level uncertainty concerning meaning automated decision making right human review linked use automated decision making thus edpb edps also consider clarifying concepts automated decision making human review mentioned law addition national data protection bodies provide practical guidance data protection provisions apply use guidance could include recommendations checklists based concrete use cases support compliance data protection provisions clarity needed scope meaning legal provisions regarding automated decision making effective access justice cases involving decisions access justice process goal crucial individuals seeking benefit procedural substantive rights encompasses number core human rights include right fair trial effective remedy article echr article charter fundamental rights accordingly notion access justice obliges states guarantee individual right court circumstances alternative dispute resolution body obtain remedy found individual rights violated accordance standards victim human rights violation arising development use system public private entity provided access remedy national authority line relevant case law article charter article echr remedy must effective practice well law research findings identify following preconditions remedy effective practice cases involving systems impact fundamental rights everyone needs aware used informed complain organisations using must ensure public informed system decisions based findings show explaining systems make decisions layman terms challenging intellectual property rights hamper provision detailed information algorithm works addition certain systems complex makes difficult provide meaningful information way system works related decisions tackle problem companies interviewed avoid using complex methods certain decision making altogether would able explain decisions alternatively use simpler data analysis methods problem obtain understanding main factors influencing certain outcomes private sector interviewees pointed efforts made gradually improve understanding technology effectively contest decisions based use people need know used organisations using need able explain system decisions based opinion legislator member states ensure effective access justice individuals cases involving decisions ensure available remedies accessible practice legislator member states could consider introducing legal duty public administration private companies using systems provide seeking redress information operation systems includes information systems arrive automated decisions obligation would help achieve equality arms cases individuals seeking justice would also support effectiveness external monitoring human rights oversight systems see fra opinion view difficulty explaining complex systems jointly member states consider developing guidelines support transparency efforts draw expertise national human rights bodies civil society organisations active fundamental rights relevant policymaking artificial intelligence increasingly used private public sectors affecting daily life see end human control machines others view technology help humanity address pressing challenges neither portrayal may accurate concerns fundamental rights impact clearly mounting meriting scrutiny use human rights actors examples potential problems using technologies relation fundamental rights increasingly emerged include algorithm used recruit human resources found generally prefer men women online became racist within couple hours translations showed gender bias recognition systems detect gender well white men black women public administration use algorithms categorise unemployed people comply law court stopped algorithmic system supporting social benefit decisions breaching data protection examples raise profound questions whether modern systems fit purpose fundamental rights standards upheld using considering using systems report addresses questions providing snapshot current use technologies based selected use cases implications fundamental rights fra work big data fundamental rights report main publication stemming fra project artificial intelligence big data fundamental rights project aims assess positive negative fundamental rights implications new technologies including big current report builds findings number earlier papers facial recognition technology fundamental rights considerations context law enforcement paper outlines analyses fundamental rights challenges triggered public authorities deploy live frt law enforcement purposes also briefly presents steps take help avoid rights violations data quality artificial intelligence mitigating bias error protect fundamental rights paper highlights importance awareness avoidance poor data quality bigdata discrimination decision making focus paper discusses discrimination occur suggests possible solutions part project fra also exploring feasibility studying concrete examples fundamental rights challenges using algorithms decision making either online experiments simulation studies several fra publications address relevant issues guide preventing unlawful profiling today future illustrates profiling legal frameworks regulate conducting profiling lawfully necessary comply fundamental rights crucial effective policing border management handbook european data protection law edition designed familiarise legal practitioners specialised data protection area law data fra fundamental rights survey surveyed random sample people across including findings people opinions experiences linked data protection technology security fra report business human rights access remedy analyses obstacles promising practices relation access remedies victims human rights abuses analysing complaints mechanisms member states research maps hinders facilitates access remedies report growing attention potential drive economic growth matched body evidence different technologies affect fundamental rights positively negatively concrete examples allow thorough examination whether extent applying technology interferes various fundamental rights whether interference justified line principles necessity proportionality report provides fundamental analysis concrete use cases case studies use case term software engineering report loosely defines specific application technology certain goal used specified actor report illustrates ways companies public sector looking use support work whether taking fundamental rights considerations account way contributes empirical evidence analysed fundamental rights perspective inform national policymaking efforts regulate use tools research cover fra conducted fieldwork research five member states estonia finland france netherlands spain collected information involved designing using systems key private public sectors address relevant fundamental rights issues research based personal interviews gathered information purpose practical application technologies assessments conducted using applicable legal framework oversight mechanisms awareness fundamental rights issues potential safeguards place plans addition experts involved monitoring observing potential fundamental rights violations concerning use including civil society lawyers oversight bodies interviewed presenting main findings report presents main findings fieldwork particular report includes overview use across range sectors focus social benefits predictive policing healthcare targeted advertising analysis awareness fundamental rights implications selected rights focus four use cases discussion measures assess mitigate impact technologies people fundamental rights two annexes available fra website supplement report gives detailed description research methodology questions asked interviews provides examples potential errors using selected areas addition information five member states covered complements fieldwork research delivered contractor also available fra website maps policy developments legal framework governing use different sectors supporting policymaking report provides evidence extent fundamental rights considerations brought discussions activities develop test employ monitor systems also highlights different technologies affect rights set charter reflects protect rights becomes widespread sophisticated analysis selected fundamental rights challenges help member states well stakeholders assess fundamental rights compatibility systems different contexts findings report current views practices among using supports policymakers identifying actions needed report aim provide comprehensive mapping use different systems five member states covered research provide technical information different systems mentioned interviewees work report based interviews representatives public administration private companies involved use services businesses fra intentionally provided general definition interviewed part research based existing definitions organisations interviewed active public administration general working law enforcement private companies include working health retail pricing marketing financial services insurance employment transport energy importantly except two interviewees research include companies sell companies instead entities use support operations addition ten interviews conducted experts dealing potential challenges public administration supervisory authorities organisations lawyers working field interviews carried five member states estonia finland france netherlands spain countries selected based different levels uptake technology policy development area well incorporate experience across different parts fra outsourced fieldwork ecorys fra staff supervised work developed research questions methodology interviewers received dedicated training conducting fieldwork interviews carried anonymously consequence information identifying organisation concerned provided report addition certain details applications described notably country omitted protect respondents anonymity communicated interviewees increasing level trust allowing speak freely work also proved useful recruiting respondents conducting interviews artificial intelligence refers systems display intelligent behaviour analysing environment taking actions degree autonomy achieve specific goals systems purely acting virtual world voice assistants image analysis software search engines speech face recognition systems embedded hardware devices advanced robots autonomous cars drones internet things applications initial definition hleg subject discussion groups see hleg definition main capabilities disciplines expert group artificial mean artificial intelligence universally accepted definition rather referring concrete applications reflects recent technological developments encompass variety technologies although usually defined widely survey conducted behalf european commission among companies showed eight ten people working companies say know slightly two respondents companies know sure fra research apply strict definition use cases presents interviews defined broadly reference definition provided expert group artificial intelligence hleg interviewees also expressed variety ways think identifying use cases explore research project focused applications support decision making based data machine learning applications systems contribute automating tasks usually undertaken humans undertaken humans due large scale use cases report provide insight different technologies used discussed selected areas broad heading may contention concerning whether certain use cases constitute current level use report often refers related technologies past years seen enormous increase computing power increased availability data development new technologies analysing data increased amount variety data sometimes available almost real time internet often referred big data machine learning technologies related algorithms including deep learning benefit enormously increased computing power data availability development use flourishing use terms however limited use even prove counterproductive triggers ideas linked science fiction rather real application variety myths exist often spread via social media example claim act form entity distracts fact systems made humans computers follow instructions made given humans approach important note never anything human beings use technology achieve certain goals however human work decision making behind systems often visible centre attention entire studies many discussions explored possible definitions european commission joint research centre analysed definitions highlights often refer issues linked perception environment way system receives environment sensors information processing decision making achievement specific goals definitions frequently refer machines behaving like humans taking tasks associated human intelligence given difficulty defining intelligence many definitions remain vague makes use hard measure equally challenging define currently lawyer tell definition asked around pretty thoroughly one public administration netherlands report discusses use based concrete applications differ terms complexity level automation potential impact individuals scale application discussion around actual use involves deploying machine learning technologies seen also confusion around term learning implies machines learn like humans reality much current machine learning based statistical learning machine learning uses statistical methods find rules form correlations help predict certain outcomes different traditional statistical analysis involve detailed checks predictions produced often referred black boxes traditional statistical analysis based specific theoretical assumptions data generation processes correlations machine learning geared towards producing accurate outcomes used automating workflows decisions acceptable level accuracy obtained usual example email spam filter uses statistical methods predict email spam important know certain email blocked spam predicted high accuracy really need understand algorithm works based rules emails get blocked however depending complexity task prediction always possible high accuracy moreover report highlights understanding certain outcomes predicted acceptable certain tasks area machine learning incorporates several approaches often machine learning refers finding rules link data certain outcome based dataset includes outcomes supervised learning example dataset emails labelled spam ham used find correlations rules associated spam emails dataset rules used predict degree likelihood future email spam sometimes machine learning used find hidden groups datasets without defining certain outcome unsupervised learning example segmenting people groups based similarities demographics finally rules correlations found trial error reinforcement learning systems try optimise certain goal experimentation update rules automatically best possible output systems need enormous amounts data hardly used humans involves experimentation mainly responsible success winning board games humans often sensationalised media fundamental rights policy framework moving towards regulation policymakers time highlighted potential related technologies improve efficiency drive economic growth yet public authorities international organisations recently reflected fundamental rights challenges associated technologies coupled growing use accuracy systems turned attention whether regulate use european parliament resolution marked milestone recognition fundamental rights implications resolution stressed prospects opportunities big data fully tapped citizens public private sectors academia scientific community public trust technologies ensured strong enforcement fundamental rights called european commission member states data protection authorities develop strong common ethical framework transparent processing personal data automated may guide data usage ongoing enforcement union law later year european council called sense urgency address emerging trends including issues artificial intelligence time ensuring high level data protection digital rights ethical standards european council invited european commission put forward european approach responding calls european commission published communication set high level expert group initiatives include strong reference fundamental rights high level expert group made independent experts academia civil society industry including representative fra published ethics guidelines trustworthy policy investment recommendations trustworthy developed work triggered discussion importance framing human rights terms alongside ethical considerations led development ethics guidelines refer charter place fundamental rights consideration respect ethics guidelines include assessment list trustworthy translated checklist guide develop deploy indicating political support highest level european council calls strategic guidelines ensure europe digitally sovereign policy shaped way embodies societal values similarly commission president von der leyen committed put forward legislation coordinated european approach human ethical implications prompted significant moves towards setting legal framework govern development use related technologies including respect impact fundamental rights february european commission published white paper artificial intelligence sets policy options meeting twin objectives promoting uptake addressing risks associated certain uses new technology paper promotes common european approach deems necessary reach sufficient scale avoid fragmentation single market notes introduction national initiatives risks endanger legal certainty weaken citizens trust prevent emergence dynamic european industry legal uncertainty also concern companies planning use commission white paper highlights risks fundamental rights one main concerns associated acknowledges use affect values founded lead breaches fundamental rights result flaws overall design systems use data without correcting possible bias also lists wide range rights white paper indicates commission preference possible new regulatory framework follow approach mandatory requirements would principle apply applications would determined basis two cumulative criteria employed sector healthcare transport parts public sector significant risks expected occur used manner significant risks likely arise latter risk could assessed based impact affected parties adding element white paper also highlights instances use certain purposes considered irrespective sector include use applications recruitment processes remote biometric identification including facial recognition technologies following public consultation ran february june commission expected propose legislation first quarter ahead proposal considered various aspects potential legal framework october european parliament adopted resolutions recommendations european commission framework ethical aspects robotics related civil liability regime also adopted resolution intellectual property rights development artificial intelligence continues work resolutions criminal law use police judicial authorities criminal education culture also established special committee artificial intelligence digital following meeting october heads state government member states declared needs global leader development secure trustworthy ethical artificial intelligence invited commission provide clear objective definition artificial intelligence addition council adopted conclusions shaping europe digital seizing opportunities digitalisation access justice included dedicated section deploying systems justice german presidency council published conclusions charter fundamental rights context artificial intelligence digital change text supported objected member growing reference fundamental rights discussions indicates fundamental rights framework alongside legal necessary effective human rights compliant evaluation many opportunities challenges brought new technologies many existing initiatives guided ethical frameworks typically voluntary fundamental approach underpinned legal regulation responsibility respecting protecting fulfilling rights rests state guarantee high level legal protection possible misuse new technologies also provides clear legal basis develop reference fundamental rights application practice fully addition steps towards legal regulation taking significant policy financial actions support development related technologies alongside white paper commission published european data aims set single market data including nine common european data spaces covering areas health data financial data proposal multiannual financial framework would create digital europe programme worth billion invest strategic digital capacities including addition funding horizon europe connecting europe international actors also considering steps regulate notably council europe active player field related technologies september committee ministers council europe set hoc committee artificial intelligence cahai aims examine feasibility potential elements legal framework development design application based council europe standards human rights democracy rule law april committee ministers council europe adopted recommendations human rights impact algorithmic addition organisation economic cooperation development oecd adopted principles created policy global level unesco starting develop global standard setting instrument selected examples wide range legal policy initiatives aiming contribute standard setting area includes amongst others actual draft legislation guidelines recommendations use reports recommendations law policy fra put together list initiatives linked also include legislative initiatives member states many organisations businesses launched initiatives tackle ethical concerns however useful tackle potential problems ethical approaches often rely voluntary action sufficiently address obligation respect fundamental rights fra pointed fundamental rights report approach guarantees high level protection possible misuse new technologies wrongdoings using european commission initiative regulating helps avoid disjointed responses across member states undermine businesses across entities outside endnotes reuters amazon scraps secret recruiting tool showed bias women october chatbot chatterbot common feature embedded messaging applications simulate human conversation voice text independent robots learning racism sexism prejudices humans study finds april prates avelar lamb assessing gender bias machine translation case study google translate march gender shades project evaluating accuracy powered gender classification products see example der standard datenschutzbehörde kippt umstrittenen ams algorithmwatch poland government scrap controversial unemployment scoring privacy first dutch risk profiling system syri banned following court decision european commission european enterprise survey use technologies based artificial intelligence luxembourg july see example website myths samoili lópez cobo gómez prato delipetrev defining artificial intelligence towards operational definition taxonomy artificial intelligence luxembourg schuett legal definition arxiv hastie tibshirani friedman elements statistical learning data mining inference prediction springer see example pasquale black box society secret algorithms control money information harvard university press cambrigde london rai explainable black box glass box journal academy marketing science vol seminal paper describing difference breiman statistical modeling two cultures statistical science vol european parliament resolution march fundamental rights implications big data privacy data protection nondiscrimination security ini para para european council european council meeting october conclusions euco brussels october european commission communication commission european parliament european council council european economic social committee committee regions artificial intelligence europe com final april information available webpage high level expert group expert group artificial intelligence ethics guidelines trustworthy artificial intelligence policy investment recommendations trustworthy expert group artificial intelligence assessment list trustworthy artificial intelligence altai selfassessment european council new strategic agenda vonder leyen ursula union strives agenda europe european commission white paper artificial intelligence european approach excellence trust com final brussels february european commission white paper artificial intelligence public consultation towards european approach excellence trust july european commission adjusted commission work programme annex new initiatives may european parliament legislative observatory framework ethical aspects artificial intelligence robotics related technologies inl european parliament resolution october recommendations commission civil liability regime artificial intelligence inl european parliament resolution october intellectual property rights development artificial intelligence technologies ini european parliament artificial intelligence criminal law use police judicial authorities criminal matters ini european parliament legislative observatory artificial intelligence education culture audiovisual sector ini european parliament decision june setting special committee artificial intelligence digital age defining responsibilities numerical strength term office rso european council special meeting european council october conclusions euco october council european union shaping europe digital future council conclusions june council european union council conclusions access justice seizing opportunities digitalisation october council european union presidency conclusions charter fundamental rights context artificial intelligence digital change october see pagallo casanovas madelin approach assessing models legal governance data protection artificial intelligence web data theory practice legislation see fra fundamental rights report luxembourg publications office chapter communication commission european parliament council european economic social committee committee regions european strategy data final european council conclusions special meeting european council july euco july council europe hoc committee artificial intelligence cahai factsheet governance digital transformation council europe recommendation rec committee ministers member states human rights impacts algorithmic systems adopted committee ministers april meeting ministers deputies see dedicated oecd website see dedicated unesco website see overview fra policy initiatives council europe website fra fundamental rights report luxembourg publications office putting fundamental rights context selected use cases use technologies relatively recent survey shows companies use technologies plan chapter presents selected cases use typically referred use cases field fra collected information cases five member states estonia france finland netherlands spain involve different areas application across public administration private companies special focus put use areas social benefits predictive policing health services targeted advertising chapter provides information current use well basic information competence select areas use cases provide good sense kind related technologies currently used examples also offer context fundamental rights analysis looking broad variety use cases provides important insights actual use affect people fundamental rights chapter includes discussion fundamental rights implications makes reference cases described use cases presented chapter based information obtained interviews public private sector representatives interviewed representatives public administration work areas health services infrastructure energy judiciary law enforcement migration border management social benefits tax well transportation traffic control interviewees private companies mainly work retail marketing pricing health sector financial services energy insurance employment transport well areas focus development different sectors note interviewees noted report focuses four broad use cases benefits policing services advertising areas particularly sensitive regards fundamental rights two cover mainly public administration use social benefits allocation predictive policing two concern private companies health services targeted advertising use cases provide basis report fundamental rights analysis offering necessary context appropriate report also highlights findings interviews cover areas four areas detailed studies taxonomy providing categorisations technology noted introduction interviewees different views also stated clear definition report discusses specific use cases without classifying technology applied yet use cases examined differed machine learning different concepts umbrella private company estonia see everyone something machine learning labelling public administration netherlands according european enterprise survey beginning companies said use technologies depend percentage ranges estonia cyprus czechia see figure another companies planning use future survey indicates used mostly sector technologies used comprise variety applications aiming process equipment optimisation anomaly detection process automation forecasting price optimisation decision figure companies using member state notes survey asked use plans use ten different related technologies speech recognition visual diagnostics fraud detection analysis emotions forecasting based machine learning includes percentage companies using least one technologies source fra based data extracted european commission european enterprise survey use technologies based artificial intelligence luxembourg july use companies currently using planning use use technology described interviewees involved varying levels complexity varying levels automation figure provides overview different examples use interviewees discussed heading applications relatively straightforward understand decision making algorithms defined based example person income certain threshold eligible certain benefits algorithms used area social benefits different levels automation examples full partial human review involved applications used traditional statistical methods inform decisions include example regression analysis classical statistical method analyses correlation several pieces information variables outcome credit score example others used complex machine learning methodologies feed production forecasts statistics government reports also algorithms much higher levels complexity deep learning diagnosis support area health tools still include high level human review hence include high level automation contrast targeted advertising example potentially using highly complex algorithms without human review output decision also using highly complex algorithms including deep learning reinforcement learning see chapter descriptions terms human review would also possible area due scale algorithms operate systems also vary according potential harm could result erroneous decision based use depending area application wrong decisions based erroneous outputs system different impacts using decision making consequences different decision affirmative wrong false positive negative wrong false negative issues particularly important machine learning used based statistical calculations always come degree figure examples different automation complexity levels use cases coveredlow automation high low complexity highsocial welfare marketing law enforcement health services financial servicesareas examples medical images analysis diagnosisfacial recognition technology identiﬁcation human reviewdeep learning reinforcement learning advertising machine learning supported production forecastsregression analysis predictions credit scoringregression analysis predictions fully automated credit scoring human decisions social decision positive outcomes social automated decision making social beneﬁts source fra notes examples financial services use facial recognition technology covered detailed use case descriptions mentioned interviews examples illustrate different levels complexity automation used practice error algorithms also make mistakes especially grow complex risks lower deterministic nature rules developed example using make decisions social benefits false positive means person may erroneously receive benefits necessarily negative impact person concerned unless error found later money needs paid back however negatively impacts public administration money paid line good administration practices contrast false negative would negative impact individual would receive benefits entitled annex available fra website provides hypothetical examples effects wrong decisions based use cases discussed importantly automating tasks impact could also scale potentially exacerbating negative effect society whole severity scale potential harm one aspect needs taken consideration analysing potential limitations fundamental rights respect use example small error rates using facial recognition technology used law enforcement might still lead flagging many innocent people technology used places many people analysed might apply airports train stations thousands people could scanned daily potential bias error rates could lead disproportionally targeting certain groups society generally interviewees referred one use case asked focus one application interviews fieldwork shows companies public administrations often still beginning looking use two thirds use cases actually use deployed practice many use cases described interviewees pilot stage development still research phase applications halted tests interviewees mostly mention machine learning including use neural networks extensions see chapter description machine learning respondents either directly mentioned mentioned subfields machine learning image recognition facial recognition technology frt often interviewees mentioned use supervised machine learning mainly used optimise specifically defined outcome yet sometimes unsupervised machine learning also used categorise cluster one case referred use reinforcement learning without going much several respondents used natural language processing nlp technology analyse text speech sometimes combined machine learning algorithms mention examples involve algorithms meaning rules algorithm follow directly encoded based cases interviewees disclose could provide detailed information technology used across cases identified research figure shows frequently used words describe use cases covered report highlights importance data using systems well relevance supporting decision making fra previously highlighted thorough description data used applications essential identifying mitigating potential fundamental rights variety data used systems covered report however difficult obtain detailed information data used respondents remained rather vague data sources rather generically many respondents mentioned using open data historical data metadata concretely respondents mentioned using customer data purchases browsing behaviour administrative records data social benefits taxes interviewees also mentioned medical records police records court records well social media traffic data data included text data audio recordings video geolocation data data come internal databases companies public administration also external sources single important reason using increased efficiency vast majority respondents across public private sector mentioned using greater speed fewer errors cost reduction fewer human resources needed interviewees law enforcement also said use safety security well crime prevention humans previously performed many use cases respondents said use entails fewer mistakes humans carry mostly used save time lot public administration netherlands important deal cases efficiently making use workforce people handle cases effectively public administration netherlands figure words interviewees often used describe use cases notes fra visualisation words frequently used descriptions use cases bigger size word often interviewees mentioned terms source fra certain tasks respondents also use tasks humans previously carry quantity information could processed humans example area genome analysis traffic predictions importantly half respondents interviewed use relevant decision making however mainly used support decision making final decisions remain largely hands humans interviewees pointed enthusiastic public administration companies still cautious deploying many use cases still testing phase described stopped phase nevertheless almost interviewees aware plans reduce level technology used fact expressed intentions invest innovation new ways employ currently available systems examples use public administration use case automating social welfare systems using algorithms area social benefits background legal framework united nations special rapporteur extreme poverty human rights philip alston warned october report introducing digital welfare state including use lead digital welfare dystopia digitalisation welfare systems often accompanied reductions overall welfare budgets narrowing beneficiary pool measures reduce availability welfare digitalisation also increases power states offering opportunities control people particularly worrying countries significant rule law use algorithms public administration welfare raises major concerns respect potentially negative impact poverty inequality applied erroneously area social includes areas child welfare unemployment yet public authorities keen use new technologies make decision making social security benefits efficient potentially fairer globally new technologies used many ways administer welfare systems include identity verification eligibility assessments benefit calculations fraud prevention detection risk scoring need classification well communication authorities beneficiaries oecd defines social benefits transfers made households need certain events particular circumstances arisen including sickness unemployment retirement housing education family however commonly agreed definition social benefits social benefits particular social insurance systems different private insurance schemes involve compulsory contributions made employees employers sometimes form social policy including social security social protection area shared competence member states article tfeu pursuant article tfeu pursues objectives among things promote improved living working conditions proper social protection end supports complements activities member states number fields including social security social protection workers combating social exclusion article tfeu actions encourage cooperation member states adopt directives minimum requirements moreover decisions social security social protection adopted special legislative procedure unanimous vote backdrop member states mostly free shape social security social protection policies since virtually harmonisation social security systems differ significantly across terms benefits provided conditions eligibility benefits calculated contributions need paid etc public administrations member states working implementing related technologies area public welfare however information applications limited fra collected information use cases linked algorithms comes compensating job seekers social benefits applications data analysis use pensions use practice use cases outlined exemplify challenges using planning use area social benefits linked algorithmic decision making experimenting new technologies support jobseekers course project public organisation experimented several technologies concerning work related processing benefits job seekers assisting return work representative interviewed states tested technologies improve foster relationship job seekers improve advice given job seekers companies testing completed organisation decide apply technologies work tests include machine detection attractiveness job offers system detecting whether job seekers still actively looking job tests also looking profiling job seekers provide advice would include calculating probability someone offered available job within given time identifying parameters make job offers relevant may also reflected advice companies best practices formulating job offers profiling would allow organisation several private insurance companies interviewed research use related technologies includes handling requests customers complementary health insurance insurance compensation decision support evaluating credit risk individuals insurance pricing insurance claims management support related management functions credit decisions private insurance companies generally embrace technologies help make business profitable oecd report highlights importance technology sector also argues risk classification could lead exclusion belonging certain vulnerable groups ways undesirable societal political perspective oecd impact big data artificial intelligence insurance sector insurance companies use determine appropriate services according profile background job seeker rather analysis advice drawn employees practically would done requiring job seekers complete monthly diary job search however still consideration whether programme limited providing descriptive analyses whether provide recommendations organisation hesitant latter aspect additionally natural language processing system tested analysing content job seekers categorised relevant data extracted urgency relevance identified using chatbot using automatic replies emails considered data used systems come several sources within organisation data job seekers background including personal tax data well data salaries social security allowances used strict conditions derived highly regulated data sources salary statements accessed data job offers companies also used generate knowledge job market organisation currently use external data professional social media networks legal provisions place using data processing housing benefits failure success public body responsible processing social benefits piloted tool process applications subsequently support staff making decisions housing benefits system selected cases new benefit applications relatively straightforward calculate include new applications housing benefits submitted individual living alone children individual income government benefits overall cases deemed simple result always individual receives benefits technological solution based model following rules housing benefits calculating general housing benefits requires income estimates advance data used testing stemmed internal database contains data benefit application processes data pseudonymised need use personal information simple statistical model linear regression used input income cost limits output amount benefit however even simplified cases found difficult use practice frequent changes legislation test terminated according interviewee lack legal basis using machine learning allow using administrative decisions plans use support decision making social benefits organisation pursuing particular project due aforementioned legal challenges interviewee noted potential applications solutions area future noted related technologies support operations without legal impact particularly good organisation time organisation using image processing social benefits applications generally benefit applicants complete several forms attachments often submitted paper format efficient handling documents agency staff hard copies received scanned classified automated system first step turn images right way round algorithms documents aligned properly scanned remove spots clean edit colouring document identify columns paragraphs tables elements distinctive blocks recognise script etc application checks received application form attachment marked correctly document marked invoice system determines whether correct turning classification images done image recognition optical character recognition ocr technologies recognise text stemming images including photographs scans documents handwritten notes ocr technology converts recognised text text data pattern recognition process input scanned images first isolated compared glyphs variations letters stored system pixel pixel basis agency continue processing images develop example potentially making possible scan bar codes attachments would help speed confirmation correctness documents attachments also solutions related natural language processing automating unemployment benefits one countries selected decisions unemployment benefits fully automated national institution responsible unemployment insurance benefits updated system fully automate processing benefit applications decisions done relevant legislation adapted allow automated decisions person registers unemployed lodges application benefits system draws information applicant various databases includes example population register tax authorities databases containing information salaries work experience etc conditions receiving unemployment benefits fulfilled system calculates period payments based length person contributed insurance system amount benefits based average daily salary netherlands system risk indication syri developed government tool alert dutch public administration fraud risk citizens processing linking large amounts personal data public authorities broad coalition civil society organisations dealing privacy issues initiated lawsuit prompting district court hague scrutinise syri court ruled syri impinges disproportionately private life citizens court found everyone whose data analysed syri exposed risk addition due opacity algorithm used citizens could neither anticipate intrusion private life guard good description syri found ilja braun high risk citizens algorithm watch ruling february dutch available online privacy first dutch risk profiling system syri banned following court decision syri case procedure fully automated however employee institution must intervene necessary information extracted databases contradictory information databases decision case involves level discretion decision definitively determined based data available human leeway deciding case main reason using system improved efficiency addition system believed achieve consistency processes every application subject discretion handled way use case predictive policing trying anticipate crime advance background legal framework technologies used law enforcement particularly predictive policing existing research tools affect fundamental rights highlighted particular issues concerning discrimination among rights one recurrent concern potential predictive policing reproduce entrench existing discriminatory practices particularly reliance historical crime data may biased incomplete many crimes domestic violence hate crime remain largely unreported therefore official police focus certain crimes violence crime public places rather business fraud taxes example also make law enforcement responses less former often associated certain demographics neighbourhoods ultimately undermine police relations particular communities criminological research crime hotspots around several decades notably uses police data map certain crimes undertakes statistical tests explore crime probabilities various police forces used developed address different types crime concentrations clusters hotspots recently adaptations area applied research used tool enhance effectiveness suggesting using algorithmic tools could reduce police reliance subjective human judgments may reflect biases studies also indicated predictive policing could potentially reduce unnecessary surveillance questioning physical checks reducing humiliation harassment individuals may occur activities predictive policing aims forecast probability crime anticipate emerging trends patterns inform crime prevention intervention may also part investigation crime already taken place authoritative definition predictive typically characterised analysing data identify common patterns trends crime using algorithms create models based analysis used forecast criminal activity may occur future technologies area generally either aim predict crimes predict individuals either commit victims crimes tools aiming predict crimes generally fed historical data largely official sources time place type crimes committed complemented environmental variables population density fra activity preventing unlawful profiling today future guide developing using algorithmic profiling bias may introduced step process avoid subsequent potential violations fundamental rights experts officers interpreting data clear understanding fundamental rights fra guide explains profiling legal frameworks regulate conducting profiling lawfully necessary comply fundamental rights crucial effective policing border management information see fra preventing unlawful profiling today future guide presence certain public places services major events holidays generally use personal data contrast systems focused predicting potential perpetrators victims crime employ historical personal data could include criminal records data addresses phone numbers location data data extracted social media information known associates health income data combined criminal environmental member states shared competence area freedom security justice article tfeu includes judicial cooperation criminal matters police cooperation articles tfeu already treaty lisbon adopted annexed declaration protection personal data judicial cooperation criminal matters police cooperation observed specific rules protection personal data free movement data fields police cooperation based article tfeu prove necessary specific nature within framework predictive policing collection storage processing analysis exchange information particularly relevant processing personal data context law enforcement operations regulated level law enforcement directive directive sets comprehensive standards safeguards processing including safeguarding prevention threats public security use practice use cases collected fra signal variety ways law enforcement authorities already use plan use related technologies support work examples mentioned interviewees range data mining systems designed map crime patterns detecting online hate speech making risk assessments violence automating certain prison guard duties use cases include detecting illicit objects satellite images generally recognising objects images addition tool mentioned research used private sector fraud prevention crime detection money transfers interviewees emphasised related technology systems used automate speed tasks previously done humans thus freeing better distributing resources mapping crime support efficient allocation investigation capacity national intelligence agency public prosecutor office employ datadriven system help employees make choices use available investigation capacity aim improve allocation human resources ensuring officers present right time place interviewees suggest system could make precise assessments compared humans often rely gut feeling decisions still system always used combination human appraisal systems make operational decisions based outcomes analysts create heat map outlines prevalence certain crimes certain areas replicates manual version crime anticipation system whereby fra activity facial recognition technology rise fundamental rights considerations law enforcement law recognises sensitive data people facial images form biometric data processed facial recognition software images also quite easy capture public places although accuracy matches improving risk errors remains real particularly certain minority groups people whose images captured processed might know happening challenge possible misuses fra paper outlines analyses fundamental rights challenges triggered public authorities deploy live frt law enforcement purposes also briefly presents steps take help avoid rights violations information see fra facial recognition technology fundamental rights considerations context law enforcement police officers put pins map indicate specific risk areas using increase speed process also makes reliable users believe analyse data system based data mining machine learning processes primarily built unique police data contained crime reports witness statements suspect declarations gaps extent possible addressed using data sources criminology research social demographic information obtained national office statistics system also uses data open sources specific parameters calculation depend type crime predictive factors vary relevance across crime areas example case burglaries data burglaries collected combined data place residence known criminals distance burgled houses relevant criteria preselected allow system produce heat map predictions made next six months indicate time location burglary may occur result map small squares risk crime occurring indicated different shades interviewees indicated visualisation helps officers analyse neighbourhoods observe correlations different locations assessing risk domestic violence national police force uses internal system track cases genderbased domestic violence system helps police officers take decisions distribute resources across domestic violence cases system categorises cases basis assessed risk relapse repetition order focus riskiest cases specialist team could complete risk analysis without using however system able compute large amount data short amount time assist untrained police officers risk analysis case alleged domestic violence reported police officer starts initial investigation includes collecting evidence taking witness statements potentially making arrest using information gathered process officer fills two detailed questionnaires assess complaints evaluate probability reoffending examine evolution case assess behaviour perpetrator victim police officers also indicate level gravity nature threats faced attitudes concerning victim system produces risk score three point scale police officer raise level risk manually lower risk level indicated system level confirmed specific measures applied line established police protocols system also informs judge potentially severe cases automated activity detecting hate speech online public agency combatting hate crime uses tool detect online hate speech analysing patterns speech online basis processing system determines social groups targeted helps law enforcement adopt measures protect threats realised although tool aims identify potential victims rather perpetrators law enforcement use information generated system ask social media providers information users pursue criminal investigations one particular challenge understanding context statements made example journalists academics may use words associated hate speech report analyse occurrence fra plans initiate research online hate present social media allow fra provide input policy developments area online content moderation uses examples use private sector use case health analysing medical records save lives background legal framework healthcare particularly prominent discussions use medical data online applications potential support improved health outcomes result wider benefits pandemic increased focus interest area particularly terms potential online data applications enhance ability governments health services track spread disease health also prominent general population views uses eurobarometer survey found every second european thinks best used improve medical diagnostics develop personalised medicine improve use case covers applications related technologies public private sector stakeholders area medical records disease prediction feeding data electronic medical records emr electronic health records ehr systems related technologies support development preventative medicine recognises early risks disease designs appropriate interventions researchers predict clinical events mortality hospitalisation readmissions length stay hospital beyond disease prediction medical record data analysed predict patients adherence treatment keeping medical appointments technologies potential support improved health outcomes well increase efficiency healthcare system article tfeu supporting competence protecting improving human health member states retain full responsibility defining health policies organising managing health systems delivering health services article tfeu within competence union action complement national policies directed towards improving public health preventing physical mental illness diseases obviating sources danger physical mental health action cover health information education well monitoring early warning combating serious threats health article tfeu latter areas adopt incentive measures excluding harmonisation laws regulations member states rules policies adopted level aim ensure free movement citizens equal treatment abroad well availability safety medical products services single market considering development technologies application health care exchange medical records patients rights situations disease prediction matter public health particularly relevant gdpr health genetic data considered special category data article called sensitive data require specific protection processing could create significant risks data subjects health genetic data shared specific circumstances article gdpr gdpr provides exemption purpose limitation principle data used research purposes line article researchers required ensure technical organisational safeguards pseudonymisation anonymity place using patient data also taken action regarding exchange medical records european commission recommendation european electronic health record exchange seeks facilitate interoperability ehrs supporting members states efforts ensure citizens securely access exchange health data wherever recommendation lays technical specifications exchange data member states european data strategy february also strong focus health common european health data space one nine common european data spaces whose establishment european commission support early warning response system ewrs owned european commission operated european centre disease prevention control aims notifying level serious threats health enabling european commission countries permanent communication purposes alerting assessing public health risks determining measures may required protect public emr computerised medical record created patients healthcare ehr contains patient medical history beyond one organisation involve sharing data across healthcare system include large amount personal data encompass among others name contact details individual next kin demographic information diagnoses test results medication may also include data wearable uniform system operating across member germany national system others including belgium denmark different systems regional level systems differ considerably depending data recorded access european commission stakeholders highlighted diversity level systems lack interoperability major barrier digital single market studies highlight potential related technologies enable earlier diagnosis widen possibilities disease prevention improve patient strengthening right access preventive healthcare benefit medical treatment may also help make healthcare possibility rapid sharing data facilitate coordinated timely treatment however use presents significant data protection risks healthcare sector leads terms personal data amount personal data stored highest among industries combined large network number access points makes healthcare sector attractive target quality data also raises concern studies patients shown medical files asked accuracy found information incomplete lot important data unstructured form free text reduces data low levels accuracy completeness overall data quality increases risk medical use practice applications described interviews include simple advanced models employed public private sectors largest number use cases refer diagnosis tools however interviewees also discussed tools automate various working procedures mapping text data filing medical records analyses measurements body tissues nerve fibres smaller number examples touched advanced projects systems monitor remotely certain health indicators heart rate case systems complement expertise health professionals next sections present examples diagnostic remote monitoring tools tools help detect diagnose disease tools used support detection diagnosis diseases described interviewees work similar ways example privately owned hospital uses system interpret images stroke patients stroke imaging used detect damage brain occurred may blockages blood supply brain also generate measures compared particular values medical specialist interviewee feels application helps determine characteristics images quickly potentially depending uses tool improving quality diagnosis however highlight necessarily efficient rely application since medical professional must present could examine image rather tool offer support example specialist finds difficult interpret certain image find abnormalities system built trained validated using dataset partially based large scientific study hospital contributed supplemented purchasing foreign datasets algorithm trained adapted future based new data new versions released developers feel allowing system continue learn would make difficult validate operation private company developed algorithm supports detection breast cancer mammography exams tool gives probability degree certainty help radiologists speed analysis results decide whether additional tests warranted algorithm detects characterises anomalies mammography cancerous interviewee indicates system low rate false negatives false positives note many cases deliver clear outcome system trained radiography mammography data europe written reports past biopsies acting control data monitoring patients vital statistics remotely hospital piloting system support early detection potential illness monitoring patients health indicators example blood pressure heart rate typically takes place manually captures situation specific moment time constantly monitoring indicators potential identify trends doctors may otherwise recognise detect health issues early prevent illness system uses biosensor kind plaster gathers hemodynamic data patients continuously constantly monitoring heart pulsation respiration data used system come hospital patient data anonymised shared provider information besides gathered monitoring plaster used build train system data environmental factors incorporated pilot interviewee pointed could contain biases future system combine information gathered biosensor separate information patients emr draw conclusions trends observed public authority responsible inspecting food safety standards restaurants uses machine learning process customer review data major online platforms helps decide conduct inspections previously process based complaints authority received previous reports since introduction tool rate restaurants identified doubled around first step involves text mining algorithm identifies reviews containing key words may indicate health safety issues sick nausea rodents second step authority compared results coming customer reviews previous inspection reports improve algorithm accuracy target health inspections use case targeted advertising profiling consumers boost profit background legal framework internet transformed way live many people make use internet services often offered free daily basis companies offering services free mainly generate revenue advertising adverts automatically targeted individual consumers based information availability data online individual behaviour combined machine learning technologies considerably improved ability commercial enterprises target individuals could even far manipulating consumers predicting reactions based irrational aspects psychology reasoned cambridge analytica scandal underscored particularly negative impact uses political purposes case company illegally obtained personal data millions social media users target political adverts different social groups based certain psychological recent declaration committee ministers council europe highlights lack knowledge manipulative power algorithms effects targeted use constantly expanding volumes aggregated data exercise human rights broader sense significantly beyond current notions personal data protection privacy remain understudied require serious concerns also raised online advertising powered technologies affect data protection consumer right even way democracies word advertising associated messages designed influence consumer behaviour advertising one form another always targeted specific groups based characteristics growth social media however taken targeted advertising another level using direct access consumer data directed towards specific groups data gathered online activities targeted activities social media providers platforms like google amazon gather comprehensive user data monitoring various activities users advertisers access detailed specific area targeted advertising systems recommend content news movies one real life examples also involves socalled reinforcement learning technology based optimising certain goal experimenting updating rules automatically best possible output means systems tries different placements trial error finds best way optimise revenue including element little knowledge actual use reinforcement learning available european countries major companies working area researching issues related targeted advertising fall consumer protection falls shared competence member states article tfeu consumer protection measures seek protect health safety economic interests consumers promote right information education organise safeguard interests article tfeu adopt minimum harmonisation measures achieve high level consumer protection article tfeu yet allowing member states introduce even stringent measures nationally secondary legislation rules advertising covered directive concerning misleading comparative directive provides minimum level protection misleading advertising also harmonises rules comparative advertising across provisions directive apply relations however practically applied directive unfair commercial practices internal market took effect directive services internal covers services include advertising additionally directive certain legal aspects information society services particular electronic commerce internal market directive also applies directive forms part legal framework digital services meet significant developments area new online services practices directive currently revised part digital services act package package aims strengthen single market digital services foster innovation competitiveness european online environment fra collected information actual use cases six european companies engaged placing online ads content recommendation personalised marketing use practice examples covered include ads online based click predictions learning likelihood online users click certain links adverts automated bidding auctions online advertisement space targeted marketing communication via email tasks fully automated examples concern analyses user preferences activity calculations probabilities clicks purchases including measurement effectiveness previously made recommendations also includes methods targeted communication basis identified target groups build long term trust clients service providers targeted online ads based click predictions business models working click predictions targeted advertisements often follow click buy policy companies purchase advertising space media platforms optimise display adverts analysing interests preferences website users showing advertisements interest purpose increase relevance advertisements shown better matching interests see present example company gets paid people click advertisement buy something additionally company uses detect inappropriate content advertising advertisements alcohol firearms political content company uses range machine learning techniques field computational advertising estimate probability user clicking advertisement displayed specific context optimising customers interests relevance products measured via mapping individuals browsing histories transaction patterns information derived individuals navigation merchant websites worldwide advertising company works done via anonymised third party cookies placed merchant websites outline individuals navigation across also list products seen purchased profiles individuals linked devices used although addresses anonymised product purchased recommender system algorithm tries determine products customer could also buy case fresh data valued higher older data browsing histories stored maximum one year interests change purchases older year longer necessarily considered relevant advertisements shown respective person immediately adapted accordingly vary across websites also match content latter advertisement posted continuously analysed combination elements taken account individual interest confirmed purchase made data shared across platforms includes informing others purchase made stop advertisements particular item purchase made formula reviewed algorithm adapted individuals continuous online behaviour future company covered example expects work optimising timing terms places advertisements within given budget certain time frame also expects focus displayed ads impact consumers another example based european online market place links buyers sellers range specialised products used optimise advertising campaigns categorise products based advertisements shown website market place improve search engine experience predicting complementary substitutable products detect fraud attempts company uses machine learning predict value clicks customers buy advertisement space offered auctions examples company indicates enables make decisions otherwise would possible without would significantly scaled targeted communication customers clients case retail company focusing specialised supplies sold across physical stores online direct marketing personalised advertising used increase appeal customers time measure efficiency particular instance marketing advertising according company issue example marketing emails opened average particularly customers recognise relevant favourite products offered marketing emails sent around registered individuals system used establish may considered relevant individuals done analysing purchases made respective individuals previous six months offers displayed directly based previous purchases meanwhile new suggestions alternative products category previous purchases similar approach used bank sends emails clients messages offering specific services products sent certain clients data analysts calculate probability clients interested service product probability certain threshold client receive message system used yet include machine learning models fully automated points taken develop system third example grocery retailer uses loyalty cards increase customers interaction personalise offers loyalty card systems predict many customers likely engage product offering system covered example also suggests new products customers tracks results suggestions groups buyers similar behavioural patterns segments make personalised suggestions every week company loyalty card owners receive personalised offers email website mobile application access offers terminals system selects offerings based individual purchase history recommends new items might catch buyer interest prompt purchase endnotes see instance samoili defining artificial intelligence towards operational definition taxonomy artificial intelligence luxembourg karanasiou pinotsis study layers automated emergent normative legal aspects deep learning international review law computers technology see fra facial recognition technology fundamental rights considerations context law enforcement luxembourg publications office fra data quality artificial intelligence mitigating bias error protect fundamental rights luxembourg publications office june human rights council report special rapporteur extreme poverty human rights philip alston eubanks automating inequality hightech tools profile police punish poor martin press redden joanna dencik lina warne harry datafied child welfare services unpacking politics economics power policy studies panoptykon foundation profiling unemployed poland social political implications algorithmic decision making see also algorithm watch poland government scrap controversial unemployment scoring system oecd glossary statistical terms social benefits definition accessed august henry richardson chapter social insurance economic financial aspects social security university toronto press pieters social security overview competence domain regulation see paju european union social security law oxford hart publishing erik bakke predictive policing argument public transparency new york university annual survey american law vol andrew ferguson policing predictive policing washington university law review vol example one five women experienced violence brought serious incident attention police see fra violence women survey main results report luxembourg publications office elizabeth joh new surveillance discretion automated suspicion big data policing davis legal studies research paper braga hot spots policing small geographic areas effects crime campbell systematic reviews vol elizabeth joh new surveillance discretion automated suspicion big data policing davis legal studies research paper available ssrn erik bakke predictive policing argument public transparency new york university annual survey american law vol wim hardyns anneleen rummens predictive policing new tool law enforcement recent developments challenges eur crim policy res doi albert meijer martijn wessels predictive policing review benefits drawbacks nternational journal public administration doi law society commission use algorithm justice system algorithms criminal justice system newbold predictive policing preventative policing intelligence led policing future declaration annexed final act intergovernmental conference adopted treaty lisbon signed december directive european parliament council april protection natural persons regard processing personal data competent authorities purposes prevention investigation detection prosecution criminal offences execution criminal penalties free movement data repealing council framework decision european commission standard eurobarometer report europeans artificial intelligence european patients forum new regulation protection personal data mean patients guide patients patients organisations commission recommendation february european electronic health record exchange format digital health society exchange electronic health records across february communication commission european parliament council european economic social committee committee regions european strategy data com final brussels february decision european parliament council october serious threats health repealing decision see commission webpage communicable diseases oecd european union healthcare glance europe vera ehrenstein hadi kharrazi harold lehmann casey overby taylor obtaining data electronic health records gliklich leavy dreyer eds tools technologies registry interoperability registries evaluating patient outcomes user guide addendum use data insurance industry currently potential see example spender bullen cripps duffy falkous farrell horn wigzell yeap wearables internet things considerations life health insurance industry british actuarial journal see visualisation see short overview different ehr systems europe nurses perspective healtheurope world services storing health data cloud college europe transformation health care digital single market synopsis report public consultation european commission study big data public health telemedine healthcare roberta pastorino corrado vito giuseppe migliara katrin glocker ilona binenbaum walter ricciardi stefania boccia benefits challenges big data healthcare overview european initiatives european journal public health vol issue supplement ministry health welfare sport netherlands digitalization health care benefits patient safety literature web reports according multiple reports different cybersecurity companies time see example magazine healthcare leads cost data breaches shannon williams new report reveals wall shame health care data breaches tammy lovell statistics reveal healthcare sector affected personal data breache magazine healthcare leads cost data breaches annet sollie reuse sharing electronic health record data focus primary care disease coding doctoral dissertation vrije univesiteit amsterdam vera ehrenstein hadi kharrazi harold lehmann casey overby taylor obtaining data electronic health records gliklich leavy dreyer eds tools technologies registry interoperability registries evaluating patient outcomes user guide addendum mowafa househ bakheet aldosari abdullah alanazi show andre kushniruk elizabeth borycki big data big problems healthcare perspective studies health technology informatics sartor giovanni new aspects challenges consumer protection study committee internal market consumer protection policy department economic scientific quality life policies european parliament luxembourg neudert lisa marchal nahema polarisation use technology political campaigns communication study request panel future science technology stoa managed scientific foresight unit within parliamentary research services eprs secretariat european parliament information commissioner office ico investigation use data analytics political campaigns council europe declaration committee ministers manipulative capabilities algorithmic processes decl example costello róisín áine impacts adtech privacy rights rule law technology regulation edps opinion edps opinion online manipulation personal data sartor giovanni new aspects challenges consumer protection jabłonowska agnieszka consumer law artificial intelligence challenges consumer law policy stemming business use artificial intelligence eui working papers law wachter sandra affinity profiling discrimination association online behavioural advertising berkeley technology law journal vol forthcoming available ssrn zuboff shoshana age surveillance capitalism london edps opinion edps opinion online manipulation personal data martin gillian importance marketing segmentation american journal business education vol kaili lambe becca ricks basics microtargeting political ads facebook see example information workshop reveal bandit reinforcement learning user interactions accessed august directive european parliament council december concerning misleading comparative advertising european commission misleading comparative advertising directive objective directive directive european parliament council may concerning unfair commercial practices internal market amending council directive directives european parliament council regulation european parliament council unfair commercial practices directive directive european parliament council december concerning misleading comparative advertising see european commission webpage digital services act package fundamental rights framework applicable use presented four use cases discussed chapter affect specific fundamental rights outlined chapter full compliance fundamental rights prerequisite using technologies irrespective area concerned chapter introduces general fundamental rights framework governs use including selected secondary legislation national law section fundamental rights framework provides normative basis benchmarks design development deployment helps determine whether specific use fundamental rights compliant requirements justified interferences fundamental rights outlined section fundamental rights framework governing use cornerstone instrument fundamental rights framework applicable use charter together unwritten general principles law main source fundamental rights charter enshrines wide array fundamental rights legal value treaties institutions bodies bound charter member states act within scope law article charter many charter rights set european convention human rights echr meaning scope must corresponding echr rights article charter however prevent union law providing extensive protection fundamental rights also found provisions treaties see article teu titles tfeu secondary rights safeguarded different pieces secondary law central piece secondary law context general data protection regulation gdpr regulation governs automated processing personal data european economic area processing personal data means form part filing system within scope law result gdpr apply national data processing gdpr coupled law enforcement directive applies police judicial cooperation criminal matters instruments include numerous provisions protection personal data determining key principles data processing lawfulness fairness whether data protection legislation applies depends whether personal data processed applications use personal data example traffic data others use anonymised data cases data protection laws apply applicability entirely line personal data blurred risk anonymised data anonymisation undone however usually illegal addition persons data usually put major efforts potentially need access additional information individuals might included anonymised dataset section discusses topic detail linked results interviews carried report addition data protection acquis european law key safeguarding fundamental rights context use related technologies article teu provides one fundamental values article tfeu requires union combat discrimination number grounds moreover articles charter provide equality law beyond several directives enshrine specific detailed provisions varying scopes include employment equality directive racial equality directive gender goods services directive recast gender equality directive member states also party international human rights conventions see list conventions key findings fra opinions section contain legally binding standards safeguards comply act areas fall within scope competence main instrument echr ratified member states accompanied additional protocols great majority member states parties echr wide reach also applies areas covered law addition council europe convention protection individuals regard automatic processing personal another source data protection obligations binding member states recently national legislation also enshrines safeguards protection fundamental rights overview technical legislation beyond scope report however chapter provides examples relevant use cases discussed report complemented couple examples national laws five member states covered none five member states covered currently horizontal aispecific laws although countries looking potential need regulation countries finland issued recommendations development responsibility standards private estonia assessment concluded separate aispecific law required foreseeable future since current legal framework according relevant estonian longterm strategy however legal environment must adapted avoid unnecessary hindrances implementing situation concerning sectoral legislation relevant use different sectors varies across member states however active policymaking recently emerged national level national action plans appeared remain core policy development member states countries working growing others focused enacting policies compatible agenda sustainable educational activities promote increasing public use often identified strategy goals investment research development also frequently outlined relevant domestic discussions potential legislative reforms remain attentive european initiatives national fundamental rights safeguards also enacted instance finland began considering overhaul domestic human rights safeguards public sector proposing broader legislative update opposed individual laws specific reference processing personal data immigration law finnish constitutional law committee put forward proposal strengthen safeguards finnish constitution overriding constitutional law shortcomings relation among others protection law accountability well ambiguity algorithms automated decision making whenever public authorities automate processes processes must adhere constitutional principle rule law may endanger observance rules good administration due proposal articulated vision requirements finnish constitution sets use automated decision making within public administration research identified initiatives policies linked fundamental rights five member states examined example estonian charter includes summary citizens rights better communicating agencies electronically also targets relation right know data collected public similarly ministry interior netherlands presented policy brief parliament public values fundamental brief stresses approach strong influence human beings society whole also lists important risks fundamental rights discrimination result biased data reduced interpersonal relations takes certain forms interaction use case examples social welfare use case regulating social welfare member states enacted rules aiming protect fundamental rights specifically area addition existing horizontal regulations see section mostly define rules processing protection personal data purpose social benefits insurance estonia example insurance activities act applicable types forms insurance regulates processing transmission personal data context states public authorities health care providers insurance undertakings third parties may transmit personal data request insurance undertaking personal health court data necessary insurance undertaking perform insurance contract right obligation disclose data derives law scope act also includes data transfers purpose data processing within systems social welfare act contains specific provisions data protection persons need social assistance notified processing data provide consent processing person established target group right opt data processing social welfare act also allows local authorities process including using algorithms personal data youth years age stored state registries identify youth employment education training finland act secondary use health social data applies using social care healthcare act based norms securing protecting sensitive personal data outlined gdpr aims establish conditions effective secure processing access personal health social data certain secondary purposes research statistics innovation development knowledge management teaching authority act regulates manner registered health data processed several laws apply various types social benefits france code relations public administration applies purpose processing accessing personal data related social benefits minor amendments entry force gdpr code states algorithms used public administrations must published person subject automated decision making right informed predictive policing use case context predictive policing law enforcement directive contains key fundamental rights safeguards stipulate law enforcement authorities apply main data protection principles set include requirement data controllers competent law enforcement authorities provide data subjects information controller data processing activities identity contact details data controller purposes processing information right lodge complaint article specific cases data controllers shall provide information example legal basis processing enable data subjects exercise rights right access article requires data controller confirm upon request data subject whether processing operations related case data subject shall able access data also request additional information including purposes legal basis processing categories personal data processed right information right access restricted number cases including avoid obstructing prejudicing prevention detection investigation prosecution criminal offences protect public security national addition article law enforcement directive explicitly prohibits automated decision prohibition limited authorised national law safeguards data subject rights including least right obtain human intervention part controller see section cases scope implementing national legislation broader directive example finnish act processing personal data criminal matters connection maintaining national security strengthens right information distinguishing information provided general special healthcare use case regards fundamental rights safeguards using healthcare gdpr empowers patients rights informed part granting control personal health data data qualifies sensitive data found example medical rights include rights access one personal health data object processing personal data rectification erasure data well rights case breach gdpr administrative fines breaches processing data including health data allowed however estonia instance domestic law allows maximum penalty eur application misdemeanour procedure cases data protection inspectorate also impose similar fines misdemeanour france data protection act public health code impose stricter requirements set gdpr regarding health data processing french data protection act amended law modernisation health system allow processing personal health data various purposes provided fall within scope one exceptions general principle prohibition sensitive data processing article targeted advertising use case considering fundamental rights safeguards relation targeted advertising underlying mechanisms regarding profiling particular legal framework privacy data protection provides relevant fundamental rights provisions protection privacy personal data holds status takes precedence economic benefits hence rules processing special categories personal data relevant companies operating area applying targeted advertising place companies certain obligations main legal provisions setting rules protecting personal data gdpr directive privacy electronic communications directive lex specialis gdpr gdpr directly applicable member states whenever company based processes personal data company based outside processes data relating individuals privacy directive strong focus fundamental rights concerns processing personal data protection privacy electronic communications sector individuals use computer smartphone tablet european commission proposed regulation would replace current legislative proposal would broaden scope directive include specific provisions concerning unsolicited marketing cookies confidentiality requirements justified interferences fundamental rights chapter highlights selected fundamental rights covered charter particularly affected taking account four use cases discussed chapter rights absolute rights subject limitations line article charter accordingly analysing extent different fundamental rights impacted use section presents general steps need followed determine whether charter right limited fundamental rights affected absolute subject limitations interferences fundamental rights justified respect requirements charter echr case charter rights corresponding rights guaranteed echr article charter pursuant article charter limitation fundamental rights must provided law meet objectives general interest recognised union need protect rights freedoms others essence right necessary court justice cjeu also emphasised limitation exercise rights freedoms recognised charter must respect essence rights means fundamental rights limited certain extent completely disregarded established inalienable essential core right violated measure next step conduct necessity proportionality test outlined charter respect aspects interference charter right needs examined whether given legitimate aim could obtained means interfere less right similar requirements also imposed echr interpreted european court human rights ecthr include essence right concept derived object purpose echr respect use new technologies ecthr observed marper states strike right balance protecting fundamental rights developing new given wide range applications systems everyday life presented four selected use cases wide range fundamental rights may assessed taking account variety elements depending context particular area use notably specific purpose used functionality complexity scale deployed relevant assessing fundamental rights endnotes see also van veen artificial intelligence human rights got data society points blog data society research institute may barfield pagallo advanced introduction law artificial intelligence edward elgar see also cjeu åklagaren hans åkerberg fransson february paras european convention protection human rights fundamental freedoms amended protocols nos november ets overview application charter see fra applying charter fundamental rights european union law policy making national level luxembourg publications office regulation european parliament council april protection natural persons regard processing personal data free movement data repealing directive general data protection regulation see fra handbook european data protection law edition luxembourg publications office see example hacker legal framework training data law innovation technology forthcoming available ssrn overview european law see fra handbook european law edition luxembourg publications office council directive november establishing general framework equal treatment employment occupation council directive june implementing principle equal treatment persons irrespective racial ethnic origin council directive december implementing principle equal treatment men women access supply goods services directive european parliament council july implementation principle equal opportunities equal treatment men women matters employment occupation recast convention protection individuals regard automatic processing personal data strasbourg january ets protocol amending convention protection individuals regard automatic processing personal data strasbourg october cets finland project ethics working group ethics challenge added emphasis companies finland etiikkahaaste ethics challenge tekoäly uusi sähkö finnish republic estonia report estonia taskforce estonian government launched preparation strategy example see netherlands ministry economic affairs climate policy strategic action strategic action plan strategisch actieplan sapai example effort adapt goals development sustainable market see spain ministry science innovation universities national strategy spanish comprehensive overview see european commission national strategies artificial intelligence oecd policy observatory finnish constitutional law committee committee opinion pevl draft proposal parliament law processing personal data immigration administration related laws estonia national audit office chancellor justice everyone rights charter netherlands ministry interior kingdom relations public values fundamental rights dutch elina johanna lilja secondary use health data new finnish act donno french code des relations entre public administration new european era administrative procedure italian journal public law see fra preventing unlawful profiling today future guide luxembourg publications office tables sajfert quintel data protection directive police criminal justice authorities available ssrn note article law enforcement directive seems apply automated decisions taken solely automated processing means safeguard apply human agency involved orla lynskey criminal justice profiling data protection law precarious protection predictive policing english translation available via finlex website gdpr recital art european patients forum new regulation protection personal data mean patients guide patients patients organisations gdpr arts white case gdpr guide national implementation estonia merav griguer processing health data france look gdpr european commission proposal regulation european parliament council concerning respect private life protection personal data electronic communications repealing directive regulation privacy electronic communications com final brussels charter art far charter contains rights correspond rights guaranteed convention protection human rights fundamental freedoms meaning scope rights shall laid said also reiterated explained cjeu see example satakunnan markkinapörssi satamedia december para joined cases volker und markus schecke eifert gbr hartmut eifert november para joined cases digital rights ireland ltd minister communications marine natural resources others kärntner landesregierung others april para maximillian schrems data protection commissioner october para webmindlicenses kft nemzeti vámhivatal kiemelt vám főigazgatóság december paras see cjeu maximillian schrems data protection commissioner october paras refer article charter see also scheinin martin sorell tom surveille deliverable synthesis report merging ethics law analysis discussing outcomes april see brkan essence fundamental rights privacy data protection finding way maze cjeu constitutional reasoning german law journal lenaerts limits limitations essence fundamental rights german law journal cjeu joined cases digital rights ireland ltd minister communications marine natural resources others kärntner landesregierung others april see instance khelili switzerland october ecthr marper united kingdom nos december ecthr finland july ecthr finland february ecthr huvig france april ecthr leander sweden march scheinin martin sorell tom surveille deliverable synthesis report merging ethics law analysis discussing outcomes april ecthr marper united kingdom nos december para see also council europe recommendation committee ministers member states human rights impacts algorithmic systems appendix para impact current use selected fundamental rights deploying systems engages wide range fundamental rights seen chapter use cases presented report involve range technologies varying levels complexity automation different phases development applied different contexts different purposes different scale rights affected depend factors number horizontal fundamental issues emerge chapter begins general overview risks perceived interviewees general awareness fundamental rights implications using chapter highlights selected fundamental rights affected airelated technologies reference four use cases analysed analysis takes account presents views practices awareness issues expressed interviews conducted report interviewees first asked general risks see using asked general fundamental rights awareness using concrete fundamental rights implications mostly linked data protection availability complaints mechanisms perceived risks important recognise many issues cut across different rights example potentially biased decision made algorithm could involve right protection personal data right effective remedy similarly particular issue seen perspective different rights instance good explanation decision made algorithm required right protection personal data right good administration right effective remedy fair trial asked general risks using interviewees always mention fundamental rights main risks although highlighted related topics private sector representatives often mentioned inaccuracy risk using followed potential bias proper legal basis processing personal data one respondent international retail company stated one business risk linked european customers extremely knowledgeable rights namely people hesitate ask data storage automated decision making customers properly informed might complain company may lose client addition interviewee continued breaching law possible fines linked breach another major business risk respect public administration bias often highlighted risk associated using addition public authorities often discussed inaccuracy data risks using example interviewees working social benefits algorithms stated incorrect results general risk occur potentially due rare cases well identified algorithm due errors input data also highlighted difficulties associated moving testing deploying system including technical challenges resources required potential different results deployed respondents working targeted advertising also highlighted business risks example offering irrelevant inappropriate content one respondent mentioned potentially losing control automated systems addition interviewees indicate challenges linked difficulty interpreting results outputs systems one interviewee consultancy sector fears risk related lack absence sufficient knowledge understanding cause ongoing projects halted due company inability explain clearly algorithms perform purpose another interviewee law enforcement sector looking possible use support decisions licence applications explains inherent risks system proposes certain response example potentially using support decisions license applications firearms respondent asserts would critical understand reasoning behind negative decisions also positive decisions several interviews showed major concern assign properly trained staff sufficient expertise trace explain interact system finding also corroborated results european commission survey among companies survey indicate obstacle adopting technologies difficulty hire new staff right skills mention complexity algorithms respect ability explain decisions based algorithms interviewee working public administration mentioned alternatives completely transparent making decisions room doubt similar vein respondent working area health private sector mentions algorithms forbidden area work fixed algorithms traced risks reported without providing much additional information include data quality excessive monitoring people due use data algorithms job loss due automation profiling general awareness fundamental rights legal frameworks context everyone aware fundamental rights fra fundamental rights survey shows slightly every second person aged older heard charter slightly people two three heard echr universal declaration human rights might echr older established people common majority people interviewed project acknowledge using generally affect fundamental rights mention use potential impact fundamental rights use bring many benefits also risks like nuclear interviewee working private sector spain use impact human rights way terms decision process matter whether decision made machine interviewee working public administration estonia aware implications responses influenced different ways use also understanding fundamental rights example one respondent working production pension forecasts based machine learning says producing statistics impact fundamental rights apart data protection issues need addressed another respondent working social benefits algorithms argues impact depends widely human rights defined example right receive correct pension none interviewees working targeted advertising believe use affects fundamental rights negatively one respondent working targeted communication customers stated one reason response relates lack knowledge exactly fundamental rights practically interviewees showed awareness rights privacy data protection well rights human dignity right fair trial effective remedy also mentioned albeit briefly closer look interviewees responses indicates diverging views across respondent groups respondents working private companies discuss data protection rarely mention rights challenges company working targeted advertising mentions attentive issues linked freedom speech right information sense company promotes rights posting adverts helps news websites obtain funding continue work one interviewee notes range rights awareness much broader among public sector representatives working referred rights human dignity presumption innocence working systems different fields application also highlight use systems also covered laws example system making decisions unemployment benefits regulated national legislation unemployment insurance administrative procedures data protection however respondents aware legal standards apply use unsure absence regulation several respondents mention ethics guidelines certification schemes work existing guidelines standards necessarily specifically aimed case example security system iske area financial services payment card industry data security respondents also refer standards developed international organization standardization iso institute electrical electronics engineers ieee european committee standardization cen respondent working targeted advertising argues certification needed field posting ads issues linked health sector work banks several interviewees noted organisations developing internal guidelines respondents mention guidelines developed international level guidelines european commission rights related data protection ensured see human rights relevance private company spain touch topic assume human rights issues involved activities within legal framework activities compliant data protection good practices therefore assume human rights issues related public administration spain think regulate specific technology like sufficient general principles rules private sector estonia expert group oecd guidelines unesco standards aware ongoing developments council europe level refer need update regulations able innovate example area health yet one interviewee states existing standards sufficient need regulated separately human dignity using technologies broadly implicates duty respect human dignity foundation fundamental rights guaranteed article charter states human dignity inviolable must respected protected times cjeu confirmed case law fundamental right dignity part processing personal data must carried manner respects human dignity puts human centre discussions actions related rather technology human creating affected new technology needs focus taking human dignity starting point help ensure use benefits everyone example supporting ageing access healthcare dignified manner use also risks infringing closely connected charter rights right life article right integrity person article context important consider avoid harmful use prevent violations rights example comes use people engaging criminal activities used apart extreme cases preserving dignity includes avoiding subjecting people without knowledge informed consent strongly linked privacy data protection example people applications social benefits decided upon use people need made aware consent use automated decisions taken give another example certain proportion population feel comfortable subjected biometric identification systems hence using without allowing opt could potentially violate respondents public administration referred right dignity discussing fundamental rights one respondent considering use prisons mentions particular context first needs assessed whether risk violating fundamental rights would high right human dignity interviewees made general references right without discussing relation concrete use yes codes yes procedures codes procedures date using something created analog world digital private sector spain right privacy data protection selected challenges right respect private life protection personal data articles charter core fundamental rights discussions around use closely related rights respect private life protection personal data distinct rights described classic right protection privacy modern right right data strive protect similar values autonomy human dignity individuals granting personal sphere freely develop personalities think shape opinions thus form essential prerequisite exercise fundamental rights freedom thought conscience religion article charter freedom expression information article charter freedom assembly association article charter given two rights absolute rights subject limitations however interference needs adequately compromise essential inalienable core explained section concept private life privacy complex broad susceptible exhaustive definition covers physical psychological integrity person therefore embrace multiple aspects person physical social also zone interaction person others even public context may fall within scope privacy contexts ecthr used concept reasonable expectation privacy referring extent people expect privacy public spaces without subjected surveillance one factors albeit necessarily conclusive one decide violation right respect private life relevance scope application however appears similarly according human rights committee mere fact participants assemblies public mean privacy infringed applies monitoring social media glean information participation peaceful widespread use may technologies continue develop raise unchartered issues novel concerns right respect private life technologies may change way think privacy algorithmic tools predict reveal information people behaviour unprecedented ways without people even realizing giving away information personal data obtained internet may instance used targeted advertising raising many fundamental rights issues linked personal data sharing via apps particularly raises significant concerns including variety potential harmful effects manipulation exploitation vulnerabilities discrimination security issues fraud identity theft reduced trust digital using technologies often implies computerised processing large amounts personal data constitutes interference right protection personal data set article charter embodying data protection law well right private life article charter article echr awareness data protection issues use personal data people heard contrast virtually interviewees aware gdpr discussed data protection issues data protection rules deriving gdpr national law clearly applied rights area fundamental rights less known discussing legal framework governing use respondents mentioned data protection rules well sectoral laws clearly say legal framework apart data protection laws interviewee working spanish public administration notes rely data protection regulation norms available moment one interviewee reflecting diagnostic tool expressed view gdpr could hinder research hospital using tool support diagnosis strokes clear rules data protection interviewee indicated although know whether data protection certification requested others referred general data protection guidelines indicated aware documents respondents working target advertising aware privacy data protection issues although responsible data protection issues companies aware efforts protect data privacy one interviewee mentioned contrary earlier years personal data stored much securely handled care attention given properly handling consent data processing consequence high level awareness data protection privacy issues linked use however data protection law applies personal data processed example using anonymised data develop tools training data likely permissible many instances would trigger gdpr research shows data often however efforts often require expert knowledge potentially additional information illegal illegality necessarily preclude applicability gdpr important consider reidentification anonymised data reasonably anonymising data one aspect protecting privacy data subjects assessing risks aspects also important consider disseminating anonymised data include use data purpose outputs interviews respondents always entirely clear use personal data often superficially described data used mentioned chapter several instances interviewees indicated use data anonymised data arguing data protection relevant cases example organisation working environmental management uses aggregated data water consumption little anxious gdpr implemented end meant managing datasets access rights good reminder everything done public administration finland actually concerned gdpr might hinder afraid large databases used previously used research anymore private company netherlands gdpr give specific rules gives principles comes ethical issues private company estonia machine predictions water consumption data available individual level interviewees said use personal data although data originally stem individuals tool supporting restaurant inspection collecting data online sources use personal data interviewee indicated however indicated need careful mining data online even publicly available might include personal data usernames another example insurance company using chatbot make client contact effective data used train system chat protocols conversation logs linked personal data however example linking data personal data might possible future according respondent companies working targeted online advertising indicate using anonymised data done example excluding names social security keys encrypting data identity consumers relevant company interviewee mentioned indicate use anonymised data others possible data used make predictions decisions specific individuals example interviewee company working credit rating mentioned need know identity consumers assessments case even important right forgotten according interviewee exhaustive discussion data protection issues possible report however two aspects clearly emerged interviews automated decision making linked right human review right obtain meaningful information decisions automated automated decision making article gdpr article law enforcement directive generally forbid automated decision making meaning decision based solely automated processing including profiling produces legal effects concerning similarly significantly affects article gdpr explicit consent needed decisions solely automated legal similarly significant effect people automated decision making authorised law authorisation union national law sole precondition law enforcement directive article processing decision considered fully automated instruments require human review would great retrieve data another service client repeat line reusing data public administration finland however concept automated decision making elusive requires discussion research example cases human intervention might limited outcomes system rendering virtually importantly human review must mean human signing recommendations outputs algorithm must done someone authority competence change decision considering relevant data humans review potentially override outcomes system must also evaluated research indicates humans overrule outcomes algorithms mainly result algorithm line stereotypes behaviour threatens possible added value automated processing potentially accurate even fairer humans may also put minority groups disadvantage therefore also relevant issues discussed overall disagreement exact scope provisions data protection acquis whether impose general ban certain types automated decisions provide data subjects rights context certain types decision using algorithms area social benefits health predictive policing clearly potential legal significant consequences interviews suggest working areas well aware concept human review decisions taken support many interviewees indicate automated decisions taken one exception automation unemployment benefits based national law fully automated decisions involve discretion another example another country positive decisions based rules automated student benefits case negative decisions made humans cases refer decisions involving use statistics machine learning another respondent testing use systems including machine learning area social benefits mentions equality could negatively impacted automation makes human behaviour visible including existing biased practices makes precautions necessary consequence organisation would allow decisions made humans interviewees working health highlighted risks linked automation decisions interviewee discussing tool support stroke diagnosis feels important rely system avoid risk automation confirmation bias caution early positive experiences application could prompt users rely easily devote less attention assessment images interviewees raised similar concerns one interviewee discussing tool analyses images provide probability presence certain type lesion notes technology supports diagnosis simple cases expertise doctors particularly important trusted complex cases targeted advertising often considered significant effect people however may case example individual vulnerabilities used successful advertising considering vulnerabilities particularly important people disadvantaged groups may aware opt direct marketing see box right say decisions automated absence case law area information research needed identify impact automated decisions advertisement delivered answering questions challenging targeted advertising based highly complex technology scale eurobarometer survey asked people aware right opt direct overall citizens heard right exercised people exercise right aware becomes even important direct marketing made much efficient machine awareness levels strongly vary across percentage people know right opt direct marketing ranges bulgaria netherlands figure shows percentages also highlights based fra analysis eurobarometer data strong variation within countries broken regions regions fewer one four heard right areas higher shares people risk poverty indicates general problem people disadvantaged society tend less aware right data show people working often struggle pay bills living rural areas older less aware right figure awareness gdpr right opt direct marketing united kingdom country region note map show countries light shading aware right dark shading less aware right results regions within countries represented light grey spaces excluded fewer respondents meaning numbers observations low reliable results question general data protection regulation gdpr guarantees number rights heard following rights right object receiving direct source fra calculations presentation based european commission eurobarometer awareness right opt direct marketing among general population insuﬃcient data experiences use cases general interviewed experts highlighted data protection law difficult interpret lacks clarity comes meaning automated decision making one expert france felt automated decision making difficult explain automated decision making banned meaning exceptions gdpr allow automated decision making removed pointed used decision support tool another expert independent lawyer netherlands views current laws standards sufficient says need concretised per sector particularly expert mentions scope existing rules permissible automated decision making clear remains unclear comprehensive assessment human loop means also raised relation syri case remained unclear extent decisions reviewed another expert working supervisory authority generally sees need adapting data protection laws legislation quite comprehensive organisation supervision thereof also political behind concerns reflect findings research also raise serious issues concerning right human review example responsible officers questioned results algorithmic system built profile unemployed people poland less one percent cases essentially makes supporting tool automated decision making linked question reviewing decisions outputs systems challenge clear lack knowledge works interviewees often could explain detail system use works data uses due lack knowledge lack transparency meaningful information logic involved explaining outcomes algorithms essential several fundamental rights crucial processing personal data also ensuring algorithms fair discriminate also necessary enable people properly challenge decisions systems one interviewee working public administration explains complexity differs depending tasks licence administration systems relatively straightforward crime prevention analysis uses data sources makes harder understand another interviewee working law enforcement says current used police organisations yet complex would make explanations difficult might case future respondent working financial data transactions indicates traditional models straightforward understand however new methodologies difficult explain company invest resources making models explainable still level explainability required gdpr clear risk much trust machine public administration france huge tension surrounding gdpr want well might fact worse interpretation data turns impossible public administration netherlands explain model able model statistical explainable public administration france internally explain decisions machine learning models several means private sector estonia systems black boxes information processes already take step forward defence human rights public administration spain strongly attached idea explainable public administration france people aware right say decisions automated evidence suggests eurobarometer survey showed europeans know data protection rights fra analysis eurobarometer survey shows figure drops considerably among people lower status citizens report struggling pay bills time know right lack rights awareness among socially disadvantaged could contribute social exclusion already disadvantaged less aware challenge automated decisions see figure gender differences small yet women even less aware right women men older people considerably less aware among aged older figure awareness right say decisions automated age gender difficulty paying bills timefrom time timealmost years oldertotal difﬁculty paying bills gender age notes question general data protection regulation gdpr guarantees number rights heard following rights right say decisions automated algorithm decides granted loan source fra calculations presentation based european commission eurobarometer awareness right say decisions automated equality equality law enshrined articles charter discrimination one person treated less favourably another would treated comparable situation based perceived real personal called protected article charter prohibits discrimination based ground sex race colour ethnic social origin genetic features language religion belief political opinion membership national minority property birth disability age sexual orientation charter prohibition reflects corresponding rights echr article protocol echr article even broader establishes open list extending protection wide range new grounds unlike article echr charter right nondiscrimination freestanding right applies situations need covered charter main challenges discrimination crucial topic comes use purpose machine learning algorithms categorise classify separate one interviewed expert points making differences per bad thing according expert deciding grant loan credit history used differentiate individuals basis protected attributes gender religion however many personal attributes life experiences often strongly correlated protected attributes credit history might systematically different men women due differences earnings job histories interviewees often mention efficiency main purpose using airelated technologies yet important note justify unfair differential treatment often protected attributes might highly correlated risks example differences life situations among men women might often linked different insurance risks however acceptable ruling shows case cjeu put end gender discrimination insurance certain circumstances areas using algorithms could positively contribute reducing bias stereotyping algorithmic data analysis may produce results could dispel prejudicial attitudes example predictive policing might contexts lead equitable policing reducing reliance subjective human predictive techniques may used identify whitecollar crimes financial crimes historically nevertheless direct indirect use algorithms involve big data considered one pressing challenges use bias discrimination including discrimination algorithmic decision making occur several reasons many levels systems difficult detect often quality data biases within source potential discrimination unfair discriminatory effects generated certain groups practice difficult individuals far limited number court cases dealt discrimination relating studies highlighted potential discrimination prompted use across areas covered area predictive policing example particular risk relates potential automated decision making tools reproduce entrench existing discriminatory practices undermine equality law article charter historical crime data underpins predictive policing may reflecting inherent data gaps chronic underreporting certain types crime alongside issues data recorded human error also bias individual officers crime victimisation surveys consistently show large proportion crime never reported police public particularly crimes involving physical sexual violence hate crimes example fra survey violence women respondents showed one five women experienced violence partner anyone else brought serious incident attention fra first instance decision divisional court cardiff dismissed claim concerning lawfulness south wales police use afr locate face recognition court appeal overturned found facial recognition programme used police court appeal ruled much discretion currently left individual police officers added clear placed watch list clear criteria determining technology deployed court also held police sufficiently investigate software use exhibited race gender bias judgment first specifically matter europe considerably narrows scope permissible law enforcement agencies need fully comply human rights law court appeal bridges south wales ewca civ august ars technica police use facial recognition violates human rights court rules august court appeal police use facial recognition violates human rights survey respondents across showed three ten reported incidents racially motivated hate crime police compared violent crime hate crime property crime burglary higher rate reporting police particularly developed countries may requirement claiming insurance policy sum relying official crime statistics based reported crime looking develop models field predictive policing particularly problematic comes specific crimes specific groups variables used modelling proxies race ethnicity gender protected categories complexity algorithms makes harder identify remove biases instead providing objective analysis predictive policing software may turn echo chamber cementing existing systemic flaws injustices stamp appears scientific use predictive policing may also make law enforcement responses less equitable focusing certain crimes predictive policing currently focused property crimes theft burglaries often associated certain demographics neighbourhoods result certain demographics neighbourhoods individuals living meanwhile crime typically committed different demographics less patterns policing whereby certain neighbourhoods communities disproportionately policed predates use however promise objective turn used counteract discriminatory policing needs verified practice oxford university researcher sandra wachter highlights discrimination may occur due information linked protected attributes targeted advertising newly created profiles purpose advertising might amount indirect discrimination potentially even require new characteristics added legislation extend scope expanded experiences use cases many interviewees noted use general discriminate systems working many indicated belief excluding information protected attributes sufficient protection discrimination however discrimination occur due information contained datasets may indicate protected attributes traces protected groups often hidden information example public authority uses tax customs shows challenges linked identifying possible bias potential discrimination using algorithms scrutinising algorithms public administration body found higher degree errors tax declarations among recently issued national identification numbers almost always attributed immigrants prompted research correlation turned outputs people recent identification numbers often contained errors never filed taxes know also case also example proxy information parts number could indicate immigrant want machine discriminate basis sex put variable sex easy make examples symmetrical notice sex certain relevance public administration spain another interviewee working potential use detecting benefits fraud mentioned respect want prevent discrimination based ethnicity instance suffice remove ethnicity label neighbourhood composition often also determined ethnicity ethnicity plays role preventing discrimination often goes beyond direct characteristics even respondents aware general potential discrimination using often ruled system discriminates people based protected characteristics respondents also believe tools positive impact terms one respondent testing social benefits decisions regrets able use data protection reasons even though respondent view automation could process big datasets effectively without discrimination noting protection personal data needs observed respondent feels hinders prompt decision making automated automated respondents clear sure whether use could discriminate respondents repeatedly stated system discriminate include data protected characteristics example several interviewees working predictive policing law enforcement felt potential discrimination systems use data return outcomes related protected grounds system aim identify people others working predictive policing felt discrimination could occur particular issues training data relation predictive policing heat map case example one interviewee noted dataset never fully neutral representative complete strong risk bias possible discrimination towards particular groups identified sharing datasets increase amount data available one way mitigate risk felt impeded data protection regulations also indicated teams task travel different police authorities check quality systems used set area targeted advertising interviewees mentioned discrimination potential problem mainly asked directly overall respondents think systems discriminate three respondents mention information gender age used consequently discrimination respect occur another interviewee sure information included respondent working breast cancer detection tool highlighted age gender ethnicity relevant factors population groups likely develop certain types cancer respondents working health highlighted potential discrimination also linked uses system suggesting could become greater challenge system used staff different related example comes respondent working credit rating private company selling credit scores individuals created algorithm company uses information gender age citizenship credit risk models information impact outcome credit scores example younger people higher credit risk score influence demographics much smaller compared credit history data according interviewee system certainly impact right access sensitive personal data impossible check profiling basis public administration netherlands discrimination complicated diseases present certain ethnic groups predictions take account sexual ethnic genetic character discriminatory violation human rights private sector france make decisions sell data data analytics creditors monitor discriminate another interviewee working data strategy financial institution private sector using analyse financial transactions clearly mentions challenges understanding constitutes work interviewee mentions example clear extent illegal exclude older people receiving credit life expectancy expected lower mortgage repayment period asked findings point uncertainty ambiguity financial sector respect article charter translates real life vulnerable groups much discussion research discrimination using linked biased results respect ethnic origin gender extent age although important analyse potential discrimination groups charter covers several grounds discrimination less often part discussions research grounds include example political opinion sexual orientation disability charter provides particular rights special groups beyond articles including rights child article rights elderly article rights persons disabilities article question age respect older age groups younger adults came interviews notably comes insurance credit see however none interviewees experts directly mentioned rights child might linked extent nature use cases investigated clearly reflects fact topic high agenda many working article charter emphasises best interests child must primary consideration activities public authorities private actors concern children applies course equally field two respondents public administration mentioned possible use area child custody distribution children schools address consideration rights child respondents wish detail concerning use cases potentially reflecting sensitivity topic finally issues linked integration people disabilities raised interviews eurobarometer survey included questions asked respondents areas mostly concerned comes use including discrimination decision making unclear responsibility nobody complain around citizens indicated concerned using could lead discrimination terms age gender race nationality example taking decisions recruitment credit worthiness etc results vary across countries higher proportions people concerned discrimination netherlands luxembourg sweden lower proportions expressed concern estonia hungary lithuania see figure however question clear people know discrimination happen aware happen think figure awareness risks discrimination using country notes includes people indicated concerned could lead discrimination among three possible issues three issues source fra calculations based european commission eurobarometer among general population potential lead discrimination charter stipulates equality women men must ensured areas including employment work pay article gender discrimination major concern comes design use related technologies development side european economic social committee notes development taking place within homogenous environment principally consisting young white men results cultural gender disparities embedded technologies example training data prone manipulation may biased reflect cultural gender prejudices preferences contain errors also reflected research despite efforts achieve gender balance majority interviewees men disparities design deployment stage linked systematic disadvantages affecting women labour market potential lack awareness gender biases recent study showed increased use industrial robots could widen gender gap despite genders benefitting increased automation analysis indicated men highskill occupations would benefit disproportionally looking ahead using data algorithms could help better mainstream gender equality policies processes paying attention gendered datasets drawing discussions around gender inequalities use data data feminism could help raise awareness male point view taken default view also finds way datasets tackling gender inequality design use see also european commission white paper artificial intelligence european approach excellence trust com final brussels february european economic social committee artificial intelligence consequences artificial intelligence digital single market production consumption employment society opinion may aksoy özcan philipp robots gender pay gap europe iza discussion paper see webpage data feminism datasociety website criado perez invisible women exposing data bias world designed men london access justice right effective remedy tribunal fair trial article charter one often used charter right legal proceedings highlights importance upholding fundamental rights rule law right horizontal character empowers individuals challenge measure affecting right conferred law respect guaranteed cjeu underlined article charter constitutes reaffirmation principle effective judicial protection characteristics remedy must determined manner consistent right effective remedy also covers decisions taken support technologies data protection law reconfirms right effective judicial remedy must provided relation decisions controller well supervisory data processed technologies exception crucial note possibility lodge administrative complaint supervisory authority provided gdpr law enforcement considered effective judicial remedy article charter court involved review judicial review always remain available accessible internal alternative dispute settlement mechanisms prove insufficient person concerned opts judicial using challenge right effective remedy different ways one prominent concern lack transparency use operation new technologies algorithmic decision making notoriously opaque data collection algorithm training selection data modelling profiling situation around individual consent effectiveness error rates algorithm aspects often transparently without access information individuals may able defend assign responsibility decisions affecting appeal decision negatively affecting fair trial includes principle equality arms adversarial proceedings established requirements also form part corresponding charter right article view article charter main challenges issues reflected specific challenges right effective remedy fair trial interviewed experts outlined generally experts indicate difference accessing remedies private companies public administration public authorities often forced transparent use meanwhile companies appear secretive assessment several experts suggests however expert netherlands said people might readily complain companies reluctant complain public authorities public services often concern vulnerable people need social benefits would less inclined complain decisions opportunities successfully complain use challenge decisions based essential providing access justice interviews emphasised following important respect people aware used people aware complain sure system decisions based explained first everyone needs know dealing system taken decision affects people social benefits people concerned might complain general able complain use know involved expert explained general willingness complain biggest problem people often know used organisations transparent even though required gdpr several interviewees indicate informing people decision made based partly automated tools first step providing access complaints second everyone needs know complain may difficult people know body deals type complaints one expert pointed consumers often know complain example bank might use algorithms deciding financial matters public administration issues automated decisions decided add names employees decisions provide contact persons potentially challenging automated decision interviewees indicated ways procedures complaints place procedures complaints linked use companies organisations use anonymised aggregated data indicate complaint mechanisms place finally complaining need enough information challenge underlying decision thorough information systems provides equality arms meaningfully challenge decisions however straightforward comes use particularly intellectual property rights issues complex systems difficult explain intellectual property rights form one hurdle providing enough information decision made system works algorithms part implemented software technical invention may subject intellectual property rights right protected article charter actors often seek copyright patent trade secret protection safeguard knowledge one interviewee insurance sector claims due highly competitive market one may share much workings used technology instance particular price given customer essentially competitors could benefit knowledge underlying software subject scrutiny another respondent using handle visa applications notes using systems developed external providers whose algorithms covered intellectual property rights hinder necessary transparency later stage another challenge successfully complaining automated decisions use general challenge explain decisions based complex systems interviewees working public administration suggest usually clear guidance complain administrative decision area interviewees highlight importance detailed explanations example systems automatically provide unemployment benefits cases involve discretion clients ask reasoning behind automated administrative acts interviewee indicates clients wish see calculations behind financial decisions may system organisation website publications contain detailed descriptions calculations used interviewees recognise open transparent logic essential providing explanations regarding decisions often challenging impossible achieve one interviewee working bank mentions complex machine learning solutions used certain decision making reasoning system explained easily systems used purposes however interviewee working another bank indicates systems used use simpler methods addition complex ones get idea probable reasons decisions one expert raised problem companies internally might enough information way algorithms work lack expertise knowledge appears major hindrance practice seeking access effective experiences use cases respondents discussing predictive policing tools highlighted transparency important violence use case felt sending police file outcome system judge informing victim level risk attributed case police measures apply result enhances transparency interviewees discussing heat map example referred numerous requests police explain system purpose works highlighted transparency way reduce public anxiety number interviewees pointed possibility individuals affected system make complaints police courts topic transparency important nowadays many procedures publish information many automatic means help upload information portals lot work done terms transparency public administration spain ombudsinstitution reference domestic violence case however interviewee indicated procedure place question system police protocol terms measures protect fundamental rights health services use cases several interviewees referred ethics committees well general legal safeguards data protection rules checks controls primarily mentioned take place external actors specific complaints procedures place organisations interviewees responded question interviewees highlighted doctors ultimately take responsibility decisions patients often know use tool first place example breast cancer detection example interviewee indicated possibility legal recourse developer tool radiologist makes decision diagnosis liable errors safeguards place targeted advertising cases mainly follow data protection requirements ensuring consent obtained respected one company makes sure clients engaged illicit practices rejects clients certain sectors political advertising complaints received organisations interviewed received complaints challenging use cases interviewees claim received complaints complainants aware used noticed incorrect outputs decision making example individuals lodged complaints regarding traffic fines whereby police officer stopped car driver upon hearing car driver explanation fine wrongfully administered proceeded manually correct information system without able update system historical data cases fines remain visible throughout system particular person would continue profiled high risk occasion even though organisations rarely received formal complaints respect use interviewees often state due early stages implementation nonetheless interviewees reported repeated requests access rectification personal data people requested information removed well explanations certain recommendation made majority interviewees claim procedures decision processed undertaken human hand interviewees showed interest opening new channels analyse explain redress decisions involving solutions rights linked access justice set charter also impacted notably use law enforcement include example presumption innocence article charter identifying people suspected committed crime police may target activities specifically one person put suspicion based flawed fragmented data algorithmic uncritical reliance automated tools without proper human review takes account information might contribute discrimination decision number complaints data use miniscule rather people may asked delete information private company estonia right social security social assistance right social security assistance enshrined article charter classic social inspired various international european legal provision combining elements right great significance view free movement people within union instead tying issues social protection labour market charter right takes new communitarian approach broadly referring providing social protection cases maternity illness industrial accidents dependency old age case loss employment article however primarily programmatic statement prescribe minimum standard protection principle member states determine conditions entitlement access social benefits clarification needed yet article charter provides protection measures restricting abolishing existing social security addition access social rights guaranteed individuals legally residing within exercise right free movement regardless nationality subject national laws article thus creates justiciable rights national courts becoming increasingly apparent impact technologies social protection systems lives many individuals rely upon potentially problematic introducing technologies social welfare systems risks creating barriers access example using social security needs account potential negative discriminatory effects citizens nationals exercising right freedom movement could negatively affected example system relies data job histories available moving member states one respondent addressed right receive correct pension aspect wider definition human rights meanwhile none interviewed referred fundamental right social security social assistance could partly reflect nature use cases however lack references social rights among public sector interviewees notable consumer protection charter stipulates policies must ensure high level consumer protection based article tfeu institutions bodies needs observe principle member state authorities implementing charter principle provides guarantee particular goal high level consumer protection article tfeu concrete also determines means achieve stated aim example protecting health safety economic interest consumers well promoting right information education among use cases use targeted advertising use medical records companies particular importance comes targeted advertising consumers need aware opt targeted aware might subjected advertising want particularly problematic combination highly sophisticated systems advertising amount sort manipulation consumer consumer protection also major relevance use health data ehrs european consumer organisation beuc noted area health brings challenges consumers recommends technologies must fully respect data protection rules transparent consumer avoid discrimination beuc also called updated regulation legislative measures market surveillance law enforcement efficient redress concerning digital health products services fully protect beuc carried survey among consumers views selected member states shows one two respondents agree companies using manipulate consumer decisions addition almost half respondents believe personalised content adverts platforms added value slightly half survey respondents expressed low trust governments effectively control interviews conducted study consumer protection mentioned margins discussing risks using fundamental rights however respondents businesses refer consumer protection legislation relevant framework also applying use moreover respondents deem consumer protection authorities potentially relevant oversight bodies used general terms many interviewees business sector stress importance consumer satisfaction example company using video surveillance security customers premises mention consumer protection regulations relevant technical solutions use systems aim improve situation consumers also preserving rights several tools built understand profile consumers enable businesses improve services marketing data protection important aspect business also linked fact breaching data protection rules considered business risk mentioned one major concern companies obtaining managing consent consumers customers process data using tools marketing purposes interviewees report gdpr impact improving systems handle consent right good administration right good administration general principle law elaborated cjeu binding member also fundamental right enshrined article charter although actions institutions bodies general principle law requires member states apply requirements right good administration public action right includes limited right individual access file obligation public authority give sufficient reasons access file facilitates understanding evidentiary basis decision made reasons underlying places individual better position put forward exercising right heard right effective obligation give reasons makes perspective individuals affected process transparent person concerned know understand measure action taken transparency also enabling principle provides foundations including exercise right effective remedy according cjeu context individual decisions made important determining extent duty give france instance code relations public administration requires written explanations factual legal considerations decision right good administration also applies systems process personal data support decision making public authorities although right good administration may subjected certain limitations question arises ensure potentially huge number individuals access files personal data used systems another question make sure public authorities always give sufficient reasons operation technologies fully explained due inherent opacity complexity use system categorise unemployed people set poland highlighted problems linked public administration use algorithms based questions answered unemployed people categorisation developed statistical algorithm system received lot criticism civil society respect lack opportunities complain potential end complaint ombudsinstitution based administrative grounds led constitutional court ruling put end system intent increase efficiency drives use public sector aim directly speaks improving administration benefiting citizens respondents public administration far often indicate efficiency reason considering use presently using one respondent advises ministries digital strategies use said main reasons adopting improve service citizens reduce costs services public administration interviewees also indicate public administration particular requirements meaning used purposes needs particular attention comes decision making however efficiency system also considered important added value sense respondent working digitalisation migration management indicates building complex systems risk afterwards would require lot work understand system retrospect interviewee indicates team needs careful allow make final decisions taken human society clients ready according interviewee although systems appealing work effectively could result extra work negative results however interviewee also indicates dimension efficiency often discussing data protection requirements good administration also directly link issues raised respect data protection right effective remedy fair trial public administration process data legal basis decisions need fair transparent pathways challenge decisions need available accessible result requirements good administration directly linked discussion analysis respect legal processing data data protection fair decisions linked discussion alongside transparency ways challenge explain decisions respect access justice endnotes see european commission european enterprise survey use technologies based artificial intelligence luxembourg july fra fundamental rights mean people luxembourg publications office see webpage baseline security system iske ther website estonia information system authority see website pci security standards council barak human dignity framework right motherright barak human dignity constitutional value constitutional right cambridge cambridge university press cjeu netherlands european parliament council october paras discussion malicious use see example brundage malicious use artificial intelligence forecasting prevention mitigation fra facial recognition technology fundamental rights considerations context law enforcement luxembourg publications office november cjeu joined cases volker und markus schecke eifert gbr hartmut eifert opinion advocate general sharpston june para fra council europe edps handbook european data protection law edition luxembourg publications office june see also ecthr guide article european convention human rights right respect private family life home correspondence strasbourg council europe updated august paras ecthr lópez ribalda others spain nos october para comprehensive legal analysis meaning content privacy see also koops typology privacy university pennsylvania journal international law vol issue vermeulen surveille deliverable scope right private life public places july human rights committee general comment right peaceful assembly article september para costello róisín áine impacts adtech privacy rights rule law technology regulation norwegian consumer council consumers exploited online advertising industry fra rights matter data protection privacy fundamental rights survey luxembourg publications office rocher hendrickx montjoye estimating success incomplete datasets using generative models nature communications hacker legal framework training data law innovation technology forthcoming available ssrn article data protection working party opinion anonymisation techniques see also finck michèle pallas frank must identified distinguishing personal data gdpr october forthcoming international data privacy law max planck institute innovation competition research paper available ssrn sartor lagioia impact general data protection regulation gdpr artificial intelligence study prepared panel future science technology stoa european parliament see example data service blog access sensitive data research safes see also discussion ohm broken promises privacy responding surprising failure anonymization ucla law review gdpr art law enforcement directive art veale edwards clarity surprises questions article working party draft guidance automated profiling computer law security review vol april article data protection working party guidelines automated individual profiling purposes regulation adopted october last revised adopted february green chen disparate interactions analysis fairness risk assessments fat conference fairness accountability transparency fat january gonzález fuster artificial intelligence law enforcement impact fundamental rights european parliament policy department citizens rights constitutional affairs internal policies july brkan algorithms rule world algorithmic data protection framework gdpr beyond international journal law information technology vol article working party guidelines automated individual profiling purposes regulation adopted october last revised adopted february misuraca van noordt overview use impact public services european commission joint research centre luxembourg council directive june implementing principle equal treatment persons irrespective racial ethnic origin art council directive november establishing general framework equal treatment employment occupation art fra coe handbook european law edition luxembourg publications office june cjeu association belge des consommateurs asbl others conseil des ministres january european commission rules pricing insurance industry enter force press release december elizabeth joh new surveillance discretion automated suspicion big data policing davis legal studies research paper aleš završnik algorithmic justice algorithms big data criminal justice settings european journal criminology doi see also european commission white paper artificial intelligence european approach excellence trust com final brussels february fra bigdata discrimination supported decision making luxembourg publications office june ibid fra data quality artificial intelligence mitigating bias error protect fundamental rights luxembourg publications office korff browne use internet related services private life data protection trends technologies threats implications council europe see national equality tribunal finland decision march see also syri case discussed court appeal bridges south wales ewca civ august see also equinet regulating equal new role equality bodies brussels report prepared allen masters tolan miron gomez castillo machine learning may lead unfairness evidence risk assessment juvenile justice catalonia best paper award international conference law richardson schultz crawford dirty data bad predictions civil rights violations impact police data predictive policing systems justice rev online available ssrn fra violence women survey main results report luxembourg publications office fra second european union minorities discrimination survey main results luxembourg publications office erik bakke predictive policing argument public transparency new york university annual survey american law vol andrew ferguson policing predictive policing washington university law review vol andcouncil europe committee experts internet intermediaries algorithms human rights council europe dgi elizabeth joh new surveillance discretion automated suspicion big data policing davis legal studies research paper gstrein bunnik zwitter ethical legal social challenges predictive policing católica law review albert meijer martijn wessels predictive policing review benefits drawbacks international journal public administration doi aleš završnik algorithmic justice algorithms big data criminal justice settings european journal criminology doi wachter sandra affinity profiling discrimination association online behavioural advertising berkeley technology law journal vol forthcoming available ssrn use financial industries leading unequal access financial services see legal literature boyd levy marwick networked nature algorithmic discrimination gangadharan eubanks barocas eds data discrimination collected essays open technology institute overview child rights issues see unicef innovation human rights center berkeley artificial intelligence children rights network independent experts fundamental rights commentary charter fundamental rights european union june see also fra coe handbook european law relating access justice luxembourg publications office june cjeu unibet london ltd unibet international ltd justitiekanslern march para cjeu stoyanov izpalnitelen direktor darzhaven fond zemedelie razplashtatelna agentsia june para cjeu centre public action sociale moussa abdida december para law enforcement directive art gdpr art law enforcement directive art gdpr art law enforcement directive art gdpr art council europe recommendation committee ministers member states human rights impacts algorithmic systems adopted committee ministers april meeting ministers deputies appendix para andrew ferguson policing predictive policing washington university law review gstrein bunnik zwitter ethical legal social challenges predictive policing católica law review yeung study implications advanced digital technologies including systems concept responsibility within human rights framework prepared council europe expert committee human rights dimensions automated data processing different forms artificial intelligence council europe algorithms human rights international technology law association responsible global policy framework lack expertise also reflected survey among companies lack skills among existing staff difficulties hiring new staff prominent obstacle adoption european commission european enterprise survey use technologies based artificial intelligence luxembourg july see detailed assessment impact predictive policing presumption innocence mendola marco one step surveillance society case predictive policing see egorov wujczyk eds right social security constitutions world broadening moral legal space social justice geneva ilo global study vol europe include arts tfeu arts european social charter well points community charter fundamental social rights workers see explanations relating charter fundamental rights explanations relating charter fundamental rights explanation article scope interpretation rights principles łukasz bojarski dieter schindlauer katrin wladasch european charter fundamental rights living instrument manual becker possible role right social security economic monitoring process german law journal vol paju european union social security law oxford hart publishing peers prechal scope interpretation rights principles hervey kenner peers ward eds charter fundamental rights commentary oxford portland oregon hart publishing exception poland united kingdom see protocol application charter fundamental rights european union poland united kingdom art christiaan van veen ben zevenbergen conference social protection artificial intelligence decoding human rights digital age freedom tinker research expert commentary digital technologies public life may art charter see also explanations relating charter fundamental rights explanation article scope interpretation rights principles łukasz bojarski dieter schindlauer katrin wladasch european charter fundamental rights living instrument manual sartor giovanni new aspects challenges consumer protection study committee internal market consumer protection policy department economic scientific quality life policies european parliament luxembourg european consumer organisation beuc digital health principles recommendations beuc artificial intelligence consumers say findings policy recommendations survey recent case law see cjeu minister justice equality law reform ireland attorney general may para also confirmed cjeu joined cases minister voor immigratie integratie asiel minister voor immigratie integratie asiel july paras components initially developed cjeu case law codified article charter right leading academic literature see craig article right good administration hervey kenner peers ward eds charter fundamental rights commentary oxford portland oregon hart publishing finck automated administrative law max planck institute innovation competition research paper craig article right good administration hervey kenner peers ward eds charter fundamental rights commentary oxford portland oregon hart publishing france code des relations entre public administration article panoptykon foundation profiling unemployed poland social political implications algorithmic decision making see also algorithm watch poland scrap controversial unemployment scoring system see decision available constitutional tribunal website fundamental rights impact assessment practical tool protecting fundamental rights chapter illustrated extent using affects different fundamental rights chapter analyses fundamental rights impact assessments fria could reduce negative impacts using fundamental rights section provides brief overview current discussion need fundamental rights impact assessments field section analyses current practices addressing fundamental rights implications based interviews conducted report interviewees asked sort testing done system used controls tasks affected use technology chapter ends suggestions assess fundamental rights impact using related technologies calling fundamental rights impact assessment available guidance tools international civil called fundamental rights impact assessments conducted using related technologies example committee ministers council europe guidelines addressing human rights impacts algorithmic systems recommend states conduct impact assessments prior public procurement development regular milestones throughout contextspecific deployment order identify risks outcomes need flexible impact assessments adapt different situations given fundamental rights violations always contextual scholars exemplify based law equality always contextual depends case fundamental rights compliance automated computer software rather use case needs separate examination determine whether fundamental rights issue arises nevertheless assessments follow systematic approach provide similar information existing standards provide guidance fundamental rights impact assessment related technology include hard law soft law instruments recommendations declarations practical tools guidelines checklists beyond requirements flowing data protection legislation see box examples laws requiring mandatory assessments effects general view increasing uptake canadian government issued guidelines including mandatory requirements assessing use public administration applies system tool statistical model used recommend make administrative decision european data protection law requires data protection impact assessment dpia coe modernised convention provides general obligation examine likely impact data processing individuals rights fundamental freedoms use following assessment controllers design processing manner prevent minimise identified risks law imposes similar detailed gdpr foresees data protection impact assessment dpia data processing likely result high risk rights freedoms natural persons therefore required law dpia technology could potentially also address broader fundamental rights implications besides impact right privacy used tool investigate algorithms impacts however gdpr article dpia limited high risk cases processing personal therefore may miss high risk cases primarily obviously related protection personal time gdpr delimited specific field application accompanying expertise means potential extension scope dpia fundamental rights might gdpr also gives indications modalities undertake dpia first dpia conducted high risk second dpia provide systematic description envisaged operations purpose legitimate interests must also assess necessity proportionality processing possible risks rights individuals addition must contain planned security measures address risks pointing different methodologies apply article working party proposes check list form minimum criteria controller use assess dpia comprehensively complies gdpr finally gdpr foresees prior mandatory consultation relevant supervisory authority impact assessment indicates processing presents risks gives crucial role dpas independent bodies established law european data protection supervisor edps provides guidance carrying dpias data protection authorities also discussed provide guidance assess technologies information data protection impact assessment see fra council europe edps handbook european data protection law edition council europe modernised convention art gdpr art gdpr recitals article working party guidelines data protection impact assessment dpia october edwards veale fra bigdata discrimination decision making luxembourg publications office june gdpr art specifies carrying dpia continual process onetime gdpr art well recitals article working party guidelines data protection impact assessment dpia october annex gdpr art gdpr art edps accountability ground part data protection impact assessments prior consultation july see example declaration ethics data protection adopted international conference data protection privacy commissioners icdppc data protection impact assessments many examples guidelines global level united nations guiding principles business human rights recommend enterprises integrate findings human rights impact assessments across relevant internal functions processes take appropriate although refer specifically guidelines relevant supporting development technology rights compliant level ethics guidelines trustworthy prepared european commission group artificial also recommend performing fria system development risks fundamental rights negatively affected technology also emphasise need put place mechanisms receive external feedback systems potentially infringe fundamental rights addition private companies associations private public private well developed different types guidance support impact assessments documents usually contain clear guidelines impact assessment instead highlight different aspects criteria taken account developing carrying impact assessment broad categories include purpose system description technology assessment impact targeted evaluating fairness diversity description audits planned performed well accountability explicitly refer applicable international human rights law various codes ethics well certification schemes also several practical tools available assess impact technologies mitigate risks developed wide range actors include lists online risk management focus specifically assessing fundamental rights others focus ethical societal economic useful references performing thorough fundamental rights impact assessment technologies july example group artificial intelligence issued assessment list trustworthy altai six month pilot involving stakeholders altai helps organisations voluntary basis reliability trustworthiness reduce potential risks users supports businesses public administrations ask right questions around seven requirements responsible identified ethics guidelines trustworthy altai specifically refers need perform fundamental rights impact assessment includes examples questions assess impact right privacy rights child freedom expression well freedom information several online assessment tools target use public authorities canadian government developed algorithmic impact assessment tool aia pursuant canadian directive automated aia represents automated assessment consisting questions unfold requirements directive questions relate fundamental rights concerns system impact freedom movement likelihood incarceration individual legal status access funding benefits indigenous people score attributed reply final impact scoring provided made publically available government website another example ethics freely accessible tool designed local governments based risk management approach supports fair automated decisions minimising unintentional harm individuals field criminal justice social media areas among national human rights bodies danish institute human rights proposed human rights compliance quick involves interactive online computer programme allows companies select modify information database suit type business area operations check rights compliance quick check based human rights compliance assessment runs database questions corresponding human rights indicators uses international human rights law standards benchmarks applying fields operations provide guidance developing impact assessment technology academic work also suggested operational frameworks assessing risks using technology focus specifically identifying addressing fundamental rights implications private focus developing ethical models analysing societal impact data used creation hoc expert review others developed guidance frameworks specific case studies example field criminal justice algo care introduced assessment evaluate key legal practical concerns considered relation police using algorithmic risk assessment tools argued participatory ways involve consider views affected stakeholders communities developing impact assessment publically engage others joined expertise science law design practical impact assessments testing practice virtually systems discussed interviews subject sort testing included elements impact assessment however mainly technical data protection impact assessments rarely address potential impacts fundamental rights interviewees argue conducting fundamental rights impact assessment view system negatively affect fundamental rights unsure example respondent working traffic management using cameras monitoring traffic indicated tested accuracy system fundamental rights apart respecting data protection rules respondents simply know fundamental rights assessed part general impact assessment carried testing stages development much testing done new system used respondents highlighted moving system production challenging task mentioned public administration well private companies usually careful using many projects interviewees refer still development pilot phase started concrete testing testing done several stages include development stage pilot stages deployment tests deployment possible live experimentation carried initial stages often involves staged deployment example organisation interviewed tests different applications support job seekers conducts continuous testing selected members organisation test tool real situations using check lists interviewee mentioned challenging move deployment stage planned supervise tool real time another example involving automated granting social benefits different assessments carried implementation group lawyers data protection specialists compensation specialists accountants performed general impact assessment department responsible using system conducted tests decide whether system could used following system monitored implementation using approach first step half decisions taken system next step decisions taken automatically expanded negative decisions another area decisions added testing system really look legal aspects looked whether system private company estonia including decisions ending compensation payments time interviews conducted decisions automated interviewee indicated carrying tests feel sure system secure outstanding risks company working fraud detection system replaced system machine learning tool changing system old new system run parallel see machine learning system performs better one interviewee mentioned rigorous analysis behind direct feedback saw would impact losses versus many good customers impacting negatively interviewee added comfortable machine learning system better static rule system aspects deployed entirety use cases previous automated system existed tests reviewed humans example automated transcription service tested court hearings allowed judge included regular feedback correctness transcription services judges one interviewee law enforcement working tool detect domestic violence identifies issues precision accuracy using system police officer sufficient training knowledge system indicators required system gather required information could lead miscalculation highlight robustness system tested annually assure quality two questionnaires used completeness data training police officers using system process also considers personal data protection laws protocols applied tests discussed focus strongly technical aspects general operations fundamental rights data protection impact assessments apart data protection respondents mentioned fundamental rights typically considered respondents reflected potential impacts fundamental rights mentioned aspects considered prompted interviewer many respondents generally aware discrimination issues often discussed explicitly asked discrimination yet gave information formal tests discrimination generally respondents ruled possibility system discriminates based protected attributes example one interviewee states test system data protection laws specific applicable legal acts fundamental rights however interviewee consider potential discrimination ruled needs kept mind future technologies interviewee stated however cases generally considered testing phase systems one respondent municipal authority mentioned assess fairness model access data needed due data protection reasons according interviewee huge tension surrounding gdpr want well might fact worse interpretation data turns impossible respondents reported data protection impact assessment required law conducted although took different forms bank tested tool analysing speech customer calls find reoccurring problems carried data protection impact assessment yes assess legality personal data protection conformity specific legal public administration estonia dpia specifically testing tool outcome system tested data used testing phase deleted certain period test access data employees restricted testing phase supervised deployment tool another dpia required case sometimes lack clarity extent use related technologies notably use algorithms belongs dpia area predictive policing instance dpias done underlying architecture system rather specific tool another interviewee using algorithms financial services also mentioned assessing machine learning tool within framework dpia belief apply machine learning system underlying data one interviewee felt data protection impact assessment crime heat map example sufficiently depth safeguard quality model system equipped deal use data different rules might apply indicated standards required respondent working migration management indicated data protection officers involved analysis legal service specialised quality control tool study data protection aspects system however respondent also mentioned guidance needed companies working targeted advertising looked data protection issues although respondents sure impact assessment conducted companies assessed example whether people consented approached targeted communication targeted ads assessed whether information possible deleted including whether cookies trackers anonymised respect dpias generally respondents know area responsibility others knew positive dpia aware details appears legal assessment sometimes detached technical side technical people knowing legal assessments one interviewee private company working credit risk scoring mentioned make suggestions system could developed compliance manager tells conformity laws audits working external oversight bodies public administrations private companies involved fra research carry tests deploying often linked existing internal external oversight processes use frequently subjected internal review processes within companies public administration although necessarily formalised review processes interviewees mentioned working formalising existing internal review processes overseeing systems interviewees public sector say particularly cautious using support decisions representative working migration management public administration indicates private sector wrong results might cause losses police impacts people lives fundamental rights yet always clear public administration businesses responsible checking overseeing use public administrations appear stronger scrutiny comes oversight systems oversight often done regular audits example connected budgetary review interviewees public private organisations report systems currently checked framework existing review regular database checks absence review processes specifically look use addition interviewees report certification schemes also look use example area health financial services several interviewees mentioned contact data protection authorities companies public administrations sought permission data protection authorities using system least generally contact example one company working targeted advertising mentioned discussing use personal data national data protection authority experts interviewed report highlighted relevance data protection authorities overseeing systems respect use personal data however experts strongly highlighted data protection authorities task two reasons data protection authorities often relevant additionally budgets overstretched workload heavy experts views differ respect need additional oversight bodies potential creation specific institution however agree existing bodies work topics linked within mandates equality bodies well human rights institutions mentioned interviewed experts providing oversight concerning possible discrimination using highlighted institutions need build expertise area better contribute oversight however similar data protection authorities challenging task equality bodies given lack resources several interviewees mentioned consumer protection authorities potentially providing relevant oversight use one respondent working retail company would like advisory agency could consulted possible use innovation without investigated right away moment company prefers consult consumer authorities data protection authorities potential future marketing campaigns data protection authorities might start investigation proactive among mitigate risks also get additional audits also see sometimes regulatory audits quite sloppy good lots customer private company estonia discussing oversight developing using well experts repeatedly mention challenge really understand impact using despite need engage existing oversight bodies responsibilities oversee use fundamental rights perspective remain unclear fundamental rights impact assessment practice many key actors field fundamental rights called conducting fundamental rights impact assessments using systems section highlights elements could incorporated assessment fundamental rights impact assessments needed given contextualised assessment required uses vary considerably terms complexity level automation potential errors harm scale application well area use complex system difficult assess potential impact fundamental rights implicated vary depending area application full spectrum rights needs considered use however uses likely involve rights often affected systems discussion preceding chapter makes clear issues linked data protection well access effective remedies fair trial relevant uses thus following horizontal points could basic starting point considering impact selected rights legal processing data needs confirmed line data protection laws personal data used full data protection framework applies ensures processing legal violate person rights respect private family life data protection processing lead unfair treatment discrimination protected groups assessing needs core assessing even apparently miniscule differences scale create risks contravening principle disadvantage people depends nature kind harm severity strength harm significance many people put disadvantage compared another group people statistical assessments group differences important tool assess unfair discriminatory uses subjected related technologies able complain receive effective remedies accessible ways people complain potential decisions made effectively access remedies includes availability information allows explanation decisions addition relevant rights charter apply public administrations using need consider good administration principles businesses take consumer protection account rights relevant depending area application examples include right social protection working social benefits right freedom expression information using support online content moderation right assembly association considering use facial recognition technology public spaces right education using education sector right asylum using support migration management right collective bargaining action using gigeconomy right fair working conditions using workplace right access preventive health care using health services right presumption innocence right defence using justice sector purposes information needed assess potential impact fundamental rights implementing given variety tools purposes area application assessments contextual able meaningfully respond horizontal points raised assess specific rights linked different use cases least following information needs available description purpose context system well legal basis description possible harm using system including questions around false positives false negatives possible harm due automation scale use description technology used includes information data used building system legal basis processing description relevant information include provided fra paper data quality description accuracy system terms outcomes based training data possible tests experiments real life situations appropriate false positives false negatives considered separately include breakdowns many groups possible allow checking potential discrimination differences accuracy women men already available provision information compliance existing standards potential certifications obtained assessments safeguards lastly envisaging safeguards contributes fundamental rights compliant use could include repetition assessments deployment appropriate important learn potential feedback loops case rules updated also requires recording information use outcomes system extent data protection respected people subjected systems aware subjected technology otherwise challenge decision affecting available easily accessible channels effectively complaining decisions made based system engaging external experts stakeholders oversight bodies information could basis consultation different stakeholders experts particular system used depending nature application legal basis consultation relevant stakeholders would ensure potential harm omitted different perspectives brought assessment stakeholders could include civil society different public private organisations well experts different fields fundamental rights including data protection ten experts interviewed report highlighted existing oversight bodies also responsible oversight within mandates sectorspecific bodies certification schemes extent interviews suggest example health care financial oversight monitor comprehend effectively respond potential impacts wide spectrum fundamental rights data protection authorities equality bodies ombuds institutions national human rights institutions could play important role providing input oversight various points expertise however interviews indicated extensive upskilling resource allocation needed underpin endnotes council europe commissioner human rights unboxing artificial intelligence steps protect human rights recommendation council europe strasbourg may heleen janssen approach fundamental rights impact assessment automated international data privacy law international data privacy law vol issue february alessandro mantelero big data blueprint human rights social ethical impact assessment computer law security review vol issue august edwards lilian veale michael slave algorithm right explanation probably remedy looking may duke law technology review accessnow access submission consultation white paper artificial intelligence european approach excellence trust council europe recommendation rec committee ministers member states human rights impacts algorithmic systems april para human rights impact assessment detailed discussion respect see wachter mittelstatt russel fairness automated bridging gap law government canada directive automated united nations guiding principles business human rights endorsed human rights council resolution july principles heleen janssen approach fundamental rights impact assessment automated international data privacy law vol issue february expert group artificial intelligence ethics guidelines trustworthy april chapter iii ibid see example ibm everyday ethics artificial intelligence sony sony group ethics guidelines vodaphone vodaphone framework arborus international orange international charter inclusive april signed private companies including camfil danone edf oréal metro sodexo etc information technology industry council iti iti policy principles ecp platform information society artificial intelligence impact assessment netherlands november amnesty international access human rights watch wikimedia foundation toronto declaration protecting rights equality machine learning systems may rightscon toronto university montreal montreal declaration responsible electrical electronics engineers ieee global initiative ethics autonomous intelligent systems ethically aligned design prioritizing human wellbeing autonomous intelligent systems future life institute asilomar principles conference outcome future life institute second conference future artificial intelligence see example ecp platform information society artificial intelligence impact assessment netherlands november ieee initiative association computer machinery acm acm code ethics professional conduct june future humanity institute university oxford standards governance international standards enable global coordination research development april iso standards jtc artificial intelligence sstandard project direct responsibility jtc secretaria iso standard information technology artificial intelligence overview trustworthiness artificial intelligence may establishes among others approaches assess achieve availability resiliency reliability accuracy safety security privacy iso standards development september information technology artificial intelligence risk management awi information technology artificial intelligence bias systems aided decision making awi information technology artificial intelligence overview ethical societal concerns information available iso website electrical electronics engineers ieee ieee algorithmic bias considerations german federal association bundesverband german federal association seal quality bundesverband guetesiegel march article working party guidelines data protection impact assessment dpia october annex criteria acceptable dpia expert group artificial intelligence assessment list trustworthy artificial intelligence altai july government canada algorithmic impact assessment tool danish institute human rights human rights compliance assessment quick check june center government excellence johns hopkins university ethics algorithm toolkit government canada algorithmic impact assessment tool article working party guidelines data protection impact assessment dpia october annex data protection focus danish institute human rights human rights impact assessment guidance toolbox pulse creating tool reproducibly estimate ethical impact artificial intelligence september fairness accountability transparency machine learning principles accountable algorithms social impact statement algorithms social impact statement algorithms expert group artificial intelligence assessment list trustworthy artificial intelligence altai july see human agency oversight technical robustness safety privacy data governance transparency diversity nondiscrimination fairness societal environmental accountability expert group artificial intelligence ethics guidelines trustworthy april expert group artificial intelligence assessment list trustworthy artificial intelligence altai july government canada algorithmic impact assessment tool government canada directive automated article appendix center government excellence johns hopkins university ethics algorithm toolkit danish institute human rights human rights compliance assessment quick check june danish institute human rights human rights impact assessment guidance toolbox heleen janssen approach fundamental rights impact assessment automated international data privacy law international data privacy law vol issue february alessandro mantelero big data blueprint human rights social ethical impact assessment computer law security review vol issue august pulse program understanding law science evidence pulse ucla school law creating tool reproducibly estimate ethical impact artificial intelligence september model includes series questions assessing human rights impact projects marion oswald jamie grace sheena urwin geoffrey barnes algorithmic risk assessment policing models lessons durham hart model experimental proportionality journal vol issue ainow algorithmic impact assessments practical framework public agency accountability april institute ethical machine learning ethical network beta machine learning maturity model brave europe governments failing gdpr see wachter mittelstatt russel fairness automated bridging gap nondiscrimination law fra data quality artificial intelligence mitigating bias error protect fundamental rights luxembourg publications office june moving forward challenges opportunities report published amidst ongoing european legislative policy developments artificial intelligence global fight coronavirus pandemic potentially quickened acceptance innovative technologies yet also shown panacea problems comes various challenges report clearly shows using systems engages wide range fundamental rights also shows many businesses public administrations already using planning use related technologies however technologies involve different levels complexity examples use relatively simple algorithms level automation also varies decision making subject human review applications currently used also often development stage national legislators policymakers keep reality mind especially presented optimistic expectations potential challenges related using new technologies need regulate vast majority public administrations businesses interviewed plan keep working using two interviewees indicated use develop another two interviewees cautious plan wait see others including lack resources work using however said develop continue test tools data infrastructure respect use includes starting new continuing ongoing pilots evaluating existing efforts sharing data results others increasing data quality trying obtain data sources interviewees mentioned engaged ongoing debates expressed desire contribute development legislation still see current situation absence harmonised law area obstacle use addition respondents said working issues linked interpretability means working methods enhance understanding explanation decisions based complex indicated desire look closely ethical legal matters figure shows correlations words interviewees often use talking future use figure indicates topics often raised example interviewees often used term data discussing future try look future automate private company estonia next steps related transparency open data say publish information pdf also information reusable formatting could reused internally private sector public administration spain great thing must learn use private company spain figure correlations words respondents often mention discussing future plans use administrationai algorithmsanalysis application businesscompaniescompany continuecustomerdata decisions developdevelopment easy energy futurehumanimproveinformation learninglevel lot machinemanagement mlnationalorganisation payment peoplephaseplans police potentialprocessprocessingproject qualityrelatedservice servicessolutions supportsystemsystems taxtechnologies technology timetool translation notes based text interview summaries respondents spoke future use including words mentioned least ten times lines connecting words indicate strength word correlations within text passages size dots indicate frequency words used source fra effectively adequately protecting fundamental rights key objective current efforts better regulate use context upcoming legislation european commission white paper addresses current gaps helping mitigate uncertainty around use respect fundamental rights making use transparent accountable terms fundamental rights includes requirements use directly link information needed assess impact fundamental rights discussed requirements linked description training data data record keeping information provided subjected robustness accuracy well human oversight highly relevant assessing protecting fundamental rights respect body evidence presented report offers general insights different technologies affect fundamental rights safeguards needed ensure fully fundamental use practice time research fundamental rights implications use specific areas support policy legislative efforts level aiming shape europe digital future widely fra continue look fundamental implications carrying focussed analysis specific use cases increase knowledge potentially wrong consequently help mitigate prevent fundamental rights violations fra look potential simulation studies showcase biased algorithms negatively affect fundamental rights use often involves automating tasks previously carried humans need acknowledge human behaviour sometimes line fundamental rights using using example police might engage unlawful profiling decisions public administration companies might sometimes driven negative stereotypes current developments use need acknowledge potential discrimination respect data system built respect underlying assumptions humans turn may feed development deployment system automating certain tasks without fully understanding automated could lead unlawful processing data use technology treats people unfairly might make impossible challenge certain outcomes name challenges however increased availability data technological tools also used better understand unequal treatment occurs current technological developments increased availability data also provide unique opportunity better understand structures society used support fundamental rights compliance opportunities created also contribute better understanding consequently mitigation fundamental rights violations getting touch person european union hundreds europe direct information centres find address centre nearest phone email europe direct service answers questions european union contact service freephone certain operators may charge calls following standard number email via finding information online information european union official languages available europa website publications download order free priced publications multiple copies free publications may obtained contacting europe direct local information centre see law related documents access legal information including law since official language versions lex open data open data portal provides access datasets data downloaded reused free commercial purposes promoting protecting fundamental rights across fra european union agency fundamental rights schwarzenbergplatz vienna austria tel fax facebook twitter intelligence already plays role deciding unemployment benefits someone gets burglary likely take place whether someone risk cancer sees catchy advertisement low mortgage rates use keeps growing presenting seemingly endless possibilities need make sure fully uphold fundamental rights standards using report presents concrete examples companies public administrations using trying use focuses four core areas social benefits predictive policing health services targeted report discusses potential implications fundamental rights analyses rights taken account using developing applications aims help ensure future regulatory framework firmly grounded respect human fundamental rights fundame ntal righ tseu charter acces jus tice tion information socie
