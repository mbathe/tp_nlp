study panel future science technology eprs european parliamentary research service scientific foresight unit stoa july auditing quality datasets used algorithmic decision systems auditing quality datasets used algorithmic decision systems biases commonly considered one detrimental effects artificial intelligence use european union therefore generally committed reducing incidence much possible however mitigating biases easy several reasons types biases systems many different det ecting challenging task nevertheless achievable manage increase awareness scientific community technology industry among policy general public implement explainable components validated appropriate benchmarks iii incorporate key ethical considerations implementation ensuring systems maximise wellbeing health entire population however hardly done legal frameworks well designed purpose unfortunately irectives discrimination include loopholes hinder prevention bias specific regulations data protection could play key role solv ing issue appealing concept providing new uses data protection impact assessment option complemented measures included new regulations data currently discussion proposed data governance data acts example might become excellent tools avoid ing bias indeed proposed strategies strengthening mitigation bias first stages tool development process might become excellent anticipatory compliance appro ach furthermore creation certificates could guarantee standardisation database essential ensure tools employ adequate datasets finally strengthening subject transparency rights could extremely helpful find ing source biased results however misalignment regulations general data protection regulation corrected stoa panel future science technology author study written iñigo miguel beriain pilar nicolás jiménez marí josé rementería davide cirillo atia cortés diego saby barcelona supercomputing center guillermo lazcoz moratinos ciberer isciii request panel future science technology stoa managed scientific foresi ght unit within directorate parliamentary research services eprs secretariat european parliament acknowledgements would like thank victor dario aguilar méndez reviewing preliminary version document needless say possible mistakes responsibility administrator charge supervising project andrés garcía higuera scientific foresight unit stoa administrator responsible philip boucher scientific foresight unit stoa contact publisher please stoa linguistic version original manuscript completed july disclaimer copyright document prepared addressed members staff european parliament background material assist parliamentary work content document sole responsibility author opinions expressed herein taken represent official position parliament reproduction translation non purposes authorised provided source acknowledged european parli ament given prior notice sent copy brussels european union isbn doi stoa website intranet internet blog auditing quality datasets used algorithmic decision systems executive ummary introduction artificial intelligence transformative technology modern society offers superlative opportunities also entails substantial risks one bias produce harmful results people including social discrimination significant loss trust society however considered vel unsolvable problem existence bias predates creation tools human societies biased reproduces therefore opposing technology reason would simply hide discrimination prevent task must use means disposal many mitigate biases likely point future recommendations made mechanism contain less bias made human beings unlike humans reviewed flaws corrected consistent basis thus end day could eventually serve build fairer less biased societies good reasons consider scenario plausible types bias syst ems many different detecting challenging task nevertheless good options identify avoid mitigate biases utterly important understand biases introduced discrimination prevented ensuring fairness trustworthiness throughout steps lifecycle development includes addressing biases gathering pre data well stages model building training eva luation finally deployment phase impact assessment applied end real settings recommendations achieve goal increase awareness different types biases scientific community techn ology industry among policy general public implement explainable components validated appropriate benchmarks incorporate key ethical considerations implementation ensuring systems maximise wellbeing health entire population bias tracing boundaries important retain biases avoided must differentiate call bias statistical perspective usually understand ias point view social sciences statistics concept bias aseptic implies mechanism always segregates particular direction cases acceptable even necessary instance social support service may necessary provide assistance people low income others social science perspective however idea bias prejudice associated discrimination unfairness therefore principle avoided affirmative action often exception rule sometimes might involve active intervention aimed introducing corrective measures database consider example executive hiring decisions made atabases accurately reflect representation women area context necessary bias databases obtain fair results however general statement qualified considering legal framework discrimination considers legally discriminatory ose differences created basis certain categories gender religion political ideology moreover provisions extended biases pri nciple seem lead unfair results considered directly discriminatory thus example tool suggests higher price product person lives countryside city violate european anti laws present study argues deal kind situation resolve loopholes implicit discrimination regulations perfectly possible resort stoa panel future science technology specific regul ations data protection within concept fairness must play essential role however requires legislat ion make effort delimit understood fair unfair context bias obviously also ssible ultimately case law left determine limits concept would mean accepting level indeterminacy beneficial development european data space nevertheless necessary point could help avoid bias databases composed personal data otherwise data protection regulations would apply key considering anonymi sed data tools might serve well mitigate bias avoid occurrence unacceptable biases adequ ate system assign responsibilities key issue measures achieve objective however come cost sometimes disproportionate considering harm would caused biases hence risk approach proposed act would adequate issues stake importance measures whether internal external independent third audits example probably depend degree foreseeable risk harm individuals however general preference self models made proposed act raises doubts efficiency proposal case aspec might reconsidered act final approval future practice demonstrates risky creation bias awareness mitigation tools across lifecycle system depend turn implementation appropriate certification systems along lines suggested proposed european data strategy ata act follow strategy case datasets mechanisms simple reason discrimination unfairness always contextual know whether suitable eir purpose unknown dataset composed women data alone suitable building tool linked cervical cancer equitable distribution hospital beds example hence case datasets certificates must associated information metadata characteristics data contain namely data structures data formats vocabularies classification schemes taxonomies code lists ould described publicly available consistent manner case tools hand already possible delimit concrete uses indeed proposal classifies risk tool basis concrete goal certification corresponding tool refer purposes thus certification must consider uses include general characteristics capabilities limitations system algorithms data training testing validation processes used well documentation relevant risk management system seems certain however effectiveness system validation certification depend large extent creation standards terms information included dataset types procedures ensure absence bias system policy options based study proposes four fundamental policy options regarding mitigation bia ses provoked use datasets tools policy option new legislation focusing biases required multiple proposals made regulatory tools target data artificial intelligence suc directive yber act ata act ata governance act digital markets act igital services act artificial intelligence act auditing quality datasets used algorithmic decision systems iii creating bias standards testing ability address issue standards ould premature likely fact suitable interpretati regulation already exists approved sufficient address issue bias instead focus solving misalignments different regulatory tools especially gdpr new regulations may generate legal uncertainties bodies concerned otherwise panies may find balance regulations intersection act gdpr proposed eneral product safety regulation policy option preventive approach strengthening mitigation bias first stages tool development process control crucial avoid unnecessary harm ess ential bias prevention incorporated process creating mechanism earliest stages involves ensuring among things raining validation testing data sets sufficiently relevant representative error complete view intended purpose system policy option database certification enforcing bias beginning life cycle algorithmic systems creation certificates could serve guarantee standardisation databases essential ensure tools employ adequate datasets doubtful however whether certifications compulsory nevertheless case datasets feed high tool seems imprudent developer use datasets certification guarantees quality information provided data include policy option granting tran sparency rights opening window find source biased results policy option envisages granting system transparency rights databases systems make decisions affecting subjects developed unfort unately individual rights system currently included proposed rtificial intelligence act modified adequate compliance ensured non policies policy option facilitating companies impl ementation proposed act compliance regulations process approved entail costs risks companies especially mall edium enterprises smes draft act proposes regulatory sandboxes specific measures support small scale users providers high systems comply ing new rules however might insufficient ould complemented additional measures instance public institutions make high databases available private agents would substantially reduce expenditure associated review datasets corresponding certification initiatives could course complemented specific subsi dies aimed helping companies adapt new regulatory framework stoa panel future science technology table contents introduction methodology results used synthesis research work findings technological analys biases biased representation knowledge taxonomy biases bias occurrence development process fairness strategies bias detection mitigation elimination normative analysis biases preliminary issue extent biases relevant regulatory arena exposition current regulatory approach essential legal tools fight biases conclusions policy options assessment policy option create new regulations specificall focusing biases instead focus misalignments different regulatory tools policy option preventive approach strengthening bias mitigation data collection policy option promote database certification enforcing bias beginning lifecycle algor ithmic systems policy option strengthening transparency rights opening window find source biased results policy option facilitating implementation act references auditing quality datasets used algorithmic decision systems list figures figure inequality discrimination design use healthcare applications figure categories data types structured semi tured data formats figure notable examples real bias figure emergence bias development life cycle ist tables table illustrative examples bias types found literature table fairness non criteria table techniques algorithmic interventions hieve fairness criteria table selecti tools machi learning fairness table companies organi sations providi services machine learni fai rness auditing quality datasets used algorithmic decision systems introduction artificial intelligence transformative technology modern society inherent risks one risks biases produce harmful results people including social discrimination significant loss trust society identified mitigated identifying mitigatin biases system development process critical element trust currently underdeveloped however important retain existence bias isolated event specific technology human societies tend embrace traditionally discriminatory schemes development could even considered splendid opportunity understand biases combat areas society development implementation mechanisms help properly identify biases create social interactions nature allow correct muc efficiently biases produced humans example easier detect erase racis practices machine advises job selection thousands peopl engaged similar tasks sometimes different opinions behaviour keeping mind main objective study understand biases tha occur based solutions different fields application propose policy options serve mitigate however simple first concept bias quite blurred statistical perspective interna tional organi zation standardi zation iso defines bias degree reference value deviates truth deviation contribute harmful discriminatory results amplification prejudice stigmatisation also beneficial specific contexts affirmative action policies precision medicine practices however social perspective bias generally considered detrimental discriminatory impact indeed usually consider biases essential value however fairness vague concept many different definitions instance concrete meaning context general data protection regulation gdpr yet cla rified however seems pretty clear whatever definition adhere achieve fairness system need understand system biased bias generated always way mitigate control unfortunately current regulations provide precise definition fairness preliminary issues complexities involved legal framework undergoing period great change must added multiple proposals regulatory tools target data directive yber resiliency act ata act ata governance act igital markets act igital services act rtificial intelligence act expected become law near future need aligned gdpr analysing issue bias circumstances problematic likely current drafts contain different wordings final versions keeping mind study tries far possible stick closely drafts proposals although certainly quoted texts reflect ideas seem reasonable study divided three main parts first provide overview biases context specifically machine applications subject first part study prepared barcelona supercomputing center bsc team non exhaustive review recent literature topic also includes precise analysis different approaches proposed mitigate biases explaining advantages weaknesses second part study devoted analysis biases legal point view current legislation discrimination first outlined study shows hat shortcomings thi area call implementation regulatory tools adequately address issue bias international organization standardization see stoa panel future science technology view proper implementation relevant data protection legislation could serve purpose well however seems ecessary complement gdpr introducing measures already included new proposals creation standards certifications standards particularly necessary provide order commo language helps promote technological development europe indeed creating european standards could help promote european way things terms reconciling development efficient systems respect human rights last least essential highlight study mainly focused systems based machine learning use unambiguous well datasets hence excluding using volatile ever sources information nternet essentially focused datasets role play emergence biases therefore although analyse occurrence biases whole chain creation implementation mechanisms focus mainly use purposes several reasons according european commission communication intelligence refers systems display intelligent behaviour analysing environment taking actions degree autonomy achieve specific goals hence systems ability perceive environment collect interpret data reason information generated decide best action act using actuators finally possibly modify environment action machine learning subset aims give computers ability learn without explicitly programmed samuel algorithms trained classification prediction purposes based input data quality outputs produced algorithms therefore accuracy patterns obtained strongly dependent quality datasets used training thus fundamental guarantee data collected ght one problem needs solved new insights obtain communication commission european parliament european council council european economic social committee committee regions artificial intelligen europe brussels com final high expert group definition main capabilities disciplines auditing quality datasets used algorithmic decision systems methodology results used preparation study particularly complex several reasons first topic suc biases tools datasets hardly addressed legal point view obstac successfully faced adopting multidisciplinary approach study produc three teams different clea rly complementary expertise teams centro investigación biomédica red ciberer isciii mainly composed lawyers philosophers extensive experience field personal data act barcelona super computing center team works technical analysis bias context thanks interaction able produce study integrates complete multidisciplinary analysis issues stake allowed ensure bot diagnoses poli options designed reasonable perspective practical implementation second difficulty fact regulations concerning use data construction mechanis passed yet hence different versions released course period work others yet come forced make extraordinary effort adapt situation result analysed panoramic legal framework includes directives focused discrimination issues general data protection regulation gdpr digital services digital markets data governance data thus methodology comprised different tools first based logically exhaustive review updated available literature biases artificial intelligence applicable regulations effect sources used analysis especially related technical aspects produced last three years second comprised extensive analysis regulations jurisprudence applicable issues stake included careful analysis lot information produced institutions think tanks national data protection institutions european data protection board edpb european data protection supervisor edps etc new legal tools third analysis benefited greatly organisation series seminars debates organised context panelfit project led team included following proposal regulation european parliament council single market digital services digital services act amending directive proposal regulation european parliament council contestab fair markets digital sector digital markets act proposal regulation european parliament council harmonised rules fair access use data proposal regulation european parliament council european data governance data governance act data act proposal regulation harmonised rules fair access use data panelfit participatory approaches new ethical legal regulatory framework ict commission funded project aimed facilitating implementation new regulation data protection stoa panel future science technology event held madrid participation four experts stakeholders josé luis piñar former director spanish agency data protection director south google data governance chair elena gil doctor law attorney richard benjamins chief data strategist telefónica observatory social ethical impact artificial intelligence odiseia madrid jorge juan ramos software developer madrid event held vienna including extremely timely conference christiane wendehorst scientific director european law institute gdpr act panel discussion act panel members charles raab university edinburgh david reichel fundamental rights agency lorena jaume ethical tech society johann čas austrian academy scienc online debate biases transparency participant gemma galdón clavell ceo founder eticas algorithmic auditor ethics oversight horizon europe projects matthi spielkamp founder executive director algorithm watch dirk lanzerath executive manager german referen center ethics life sciences drze secretary general european network research ethics committees eurec fourth analysis benefited active exchange ideas academics stakeholders expertise hical legal technical issues regarding bias soriano arnaz university valencia aurelie pols data protection officer european center privacy cybersecurity ecpc jessica wulf algorithm watch richard benjamins chief data strategist telefónica observatory social ethical impact artificial intelligence odiseia madrid fruzsina mollnar gabor european group ethics ege auditing quality datasets used algorithmic decision systems synthesis research work findings technological analysis biases first part provides analysis technical aspects related biases offering nonexhaustive review different applications particular training datasets used machine learning understand associated ethical social concerns next tentati taxonomy biases introduced along study identification biases development processes finally set recommendations strategies tackle bias mitigation offered well collection initiatives tools organisations currently worki put commendations practice biased representation knowledge artificial intelligence adopted across kinds industrial sectors europe different types applications use widely proven efficient many scenar aving time cost well augmenting complementing human skills however still face plenty cases solutions particular machine learning applications cause harm form discrimination ecific populations underrepresented training datasets victims sorts biases present system life cycle defined following subsections currently live algorithmic society citizens become data donors always aware hence special attention needs paid data collected long purpose words important consider content data extent information fits purpose european union agency fundamental rights ensure higher quality datasets used train systems enhance accuracy validity reliability social inclusion essential step designing solution relies way information represented computer system understand learn knowledge solve problems figure knowledge representation complete socially inclusive stem reasoning process biased therefore provide unfair outcomes figure inequality discrimination design use healthcare applications source leslie stoa panel future science technology possibility obtaining biased outcomes strongly related characteristics data quality data management process including data gathering cleaning annotation processing technical ethical social challenges associated vary kind data figure technique used instance structured data works predefined categories data generally text usually organised relationa databases examples structured data include dates contact information lab values demographi data financial information case challenge relies high sensitivity consumi applications respect data quality related possible error knowledge representation approach enough attributes possible sparseness heterogeneity data underrepresentation social groups factors affect quality system hence performance terms accuracy reliability trustworthiness general case unstructured data images videos plain texts semi data html xml json files internal structure predefined ata models schemas unstructured semi data generated humans case images videos social media data websites media audios digital photos etc text files machine generally sensors cameras applied fields like digital surveillance traffic weather space exploration amongst others lack internal structure requires human intervention organise data pre techniques like ata annotation case knowledge representation strongly affected human judgement historically socially biased moreover comes classifying sensitive information gender race objective visual aracteristics consensus among community properly label data hereafter introduce selection examples applications using unstructured data suffered undesirable biases namely images texts figu categories data types structured semi data formats source varshney example social network data stored graph structured data format multimedia videos stored semi formats contain information structure video frames meta tags location date structured hind auditing quality datasets used algorithmic decision systems last years computer vision become major driver already used industries like manufacturing agri culture automotive medical industries amongst others applications enhancing human skills boosting economy however use raised several ethical concerns regarding bias negative impact certain social groups computer vision based supervised learning techniques generally deep neural networks used image segmentation classification recognition require large training datasets often difficult generate due cost imagenet srinivasan chander released containing millions tagged images contributing rapid growth adoption computer vision however evidence past years showed lack oversight data management processing leading serious bias problems particular control data came labelling labelled issue particularly delicate persons category taxonom proved non community example move level categories easily observe often misogynist racist creating perpetuating discriminating women bipoc disabled people practice replicated last decade big tech companies harder check datasets created ordered however several cases raised awareness towards issue turning attention towards ases upon technology built used instance user reported social media google photos tagging african friends gorillas figure main problem two one hand lack images people colour control label associated images persons attempt solve problem google censored types apes tagging system nonetheless issue misrepresentation bipoc still present years later moreover showed google vision assigning tag gun image dark hand holding thermometer simi image light hand tagged electronic device buolamwini gebru research exposed skin type gender bias commercial products particularly facial recognition systems big companies amazon ibm microsoft among others ult gender shades evaluated accuracy gender classification tools additi introduced intersectional approach showing systems performing particularly poorly dark women another research scheu erman showed facial analysis technologies consistently performing worse transgender people unable classify non genders impact systematic replication perpetuation biases amplified used third applications causing harm underrepresented communities denying access healthcare stigmatised law surveillance systems among others another area artificial intelligence quickly rowing natural language processing nlp achieving high performance multiple language tasks nlp used speec recognition virtual assistants like siri alexa automated translation google transl ate appli cations already many everyday lives email filtering chatbots predictive text however nlp models often susceptible learning implicit bias data replicate social stereotypes clear example beh aviour case googl translate used assign gender roles working gender languages hence translating sentences doctor nurse gender black indigenous people colour stoa panel future science technology language like turkish gend one like english used male version former sentence female latter google working reduce gender bias products since offers translations male female forms figure however study prates showed prevalence translating sentences containing job positions neutral gender languages gender ones higher males especially scientific engineering fields hence google translator repli cating stereotypes exist real job distribution female workers nlp techniques word embedding used build knowledge upon algorithm learns however sensitive producing mentioned situations due bad representation domain gender bias issue nlp starts training large datasets unbalanced bias also amplified learning algorithm costa microsoft released chatbot tay desi gned interact users via twitter objective improve natural conversati skills interactions company cancel less day tay tri ked social media users started replicate misogy nistic homophobic racist behaviour similarly tay openai gpt google meena facebook blender designed mimic human language trained vast amounts data coming internet includi unwanted prejudice toxi language reproducing hate speech misogynistic homophobi language racist rants could prevented algorithm designed level censorship control towards sensitive topics implementing governance mechanisms suc human oversight system policing however difficult fully automate task contemplate risky situation beginning process would need continuous review addition bias issues mentioned ove also necessary check negative impact nlp systems advise provide information people conversati onal agents produce miner miner analyses effect people common conversational agents siri google cortana voice asking questions mental health interpersonal violence physical health concluding respond inconsistentl incompletely questions example shows systems interact casually considered simple cause significant harm people ethical considerations appropriately addressed last years seen used correctly artificial intelligence amplify socially biases replicating stereotypes bad practices produce discrimination certain vulnerable underrepresented groups fundamental include multidisciplinary perspective design new technologies take account benefits deploying technologies impact society sense recent paper deepmind authors establish analyse detail large language models potential risks drawing multidisciplinary literature computer science linguistics social sciences important step process ensure high quality data management process order avoid situations ones presented section instead training datasets created processed following inclusive perspective solutions could hel reduce social inequalities models auditing quality datasets used algorithmic decision systems figure notable xamples real bias race bias google photos described section race bias compas algorithm described section gender bias google translate turkish english subsequent fix described section rxiv sources adapted twitter jackyalcine google keyword james propublica main points last years community taken turn towards ethically responsible practices design development use technology data management become one principal requirements align trustworthy european values fundamental rights particular ensure quality data enable social inclusiveness thus provid better representation world nonetheless applications direct impact human beings necessary implement governance mechanisms including human oversight knowledge representation first step process generating fair traini datasets algorithms aspects process could policed standardised others require commitment community towards ethical legal socio economic cultural aspects taxonomy biases stoa panel future science technology bias refers bias already exists construction computer system bias comes developers society subculture introduced every stage development model defining goals model collecting data building training model user interaction model example correctional offender management profiling lternative sanctions compas software measures risk person committing another cri found negatively biased towards afro people figure bias entangled sociocultural context system created subsequently introduced software technical bias introduced development computer systems introduced data collection model training testing deployment part technical aspects construction system examples technical bias include unnoticed imbalance underrepresentation protected attributes age gen der race data used model misleading visualisation data results end users technical bias common type algorithmic bias dedicated guidelines best practices help avoid type bias example bias introduced data sampling process happened beginning covid pandemic countries reported case fatality rates cfrs using different sampling strategies hence created confusing statistics countr ies introduced bias cfrs measures sampling seriously ill persons countries measured cfrs sampling wider range infected population ward emerging bias occurs system built happens users interact system data employed build system become unrepresentative intended use anymore example app streetbump reports potholes city release found users app located wealthiest parts city therefore discriminating people lower one way avoid type bias keep updated dataset represent different unexpected situations several alternative categorizations bias present literature example web page catalog dedicated listing defining possible types biases friedman nissenbaum created categories bias based oment occurred development baeza defines categories based origin bias data algorithms user interaction baeza specifically categorization refers three types bias cognitive bias systematic pattern deviation norm rationality judgement shana lebowitz business describes cognitive biases screw decisions statistical bias systematic deviation reference value cultural bias int erpretation judgement phenomena acquired throughout life even though generally want avoid remove bias systems cases would apply stemming define different attributes bias bump affect auditing quality datasets used algorithmic decision systems whether bias introduced system purpose intention whether bias desired fulfils specific objective whether bias system foreseen whether set attributes ascribed bias depends context example data collected real social media could contain biases implicit undesirable unexpected conversely prospective collection medical information historically low female representation ought biased purpose order avoid imbalance data cirillo among aforementioned attributes bias oblematic ones unexpected implicit undesired biases difficult find fix additional layer complexity represented real scenarios controlling complicated fact datas contain explicit sensitive variables purposely excluded law proscription one solution test unwanted discrimination scenario always report variables check outcome algorithm excluding moreover possible strategies obtain sensitive variables test unwanted discrimination include submitting informed consent conducting survey inferring information using publicly available sources organizations internal data use proxy variables benjamins table shows common biases developing systems mainly algorithmi biases reported table illustrative examples bias types found literature type bias definition originates cultural bias bias history society projected data developers onto system model definition model validation model deployment measurement bias results way choose utilise measure feature data design simpson paradox results aggregation subgroups differs separation subgroups data design population bias results differ ence representation dataset target population data collection sampling bias results non sampling subgroups data collection labelling bias mislabelling introduced training data often subject human judgement data collection omission result excluding data features considered data collection pre eliminat stoa panel future science technology irrelevant processing excluding bias results data scientist removes one features model model development confusion bias results model erroneously correlates variables model development model bias results using insufficient unbalanced unfair discriminatory toxic data model model development statistical bias result statistical correla tion model model development confirmation bias model result confirms developer beliefs model validation cause bias model correlation errors model validation funding bias sponsors project results according financial issues model deployment temporal bias results differences population behaviours time data maintenance main points many types bias different categorizations bias challenging problem exhaustive analysis would impossible different classifications bias depending perspective considered important understand origin bias nature order control tackle undesired biases avoid major nsequences problematic bias unexpected implicit undesirable type bias occurrence development process understanding biases appear development process system necessary prevent biases persisting intensifying biases appear data set insufficient incomplete unbalanced also inferred correlation factors example resume analysis employee recruitment even gender race explicitly reported training data set algorithm infer information variables neighb ourhood area level studies practised sports lifestyle general information may correlate strongly gender race figure shows main stages development process system common biases auditing quality datasets used algorithmic decision systems figure emergence bias development life cycle source authors problem definition hypothesis phase process stakeholders developers define desired goals solution project personal cultura biases system definition biases exist prior construction solution part cultural context system biases stage might correspond solutions designed instance classify peopl characteristics marketing applications identify population groups based particular features gender socioeconomic status political orientation religion example binary definition gender male female definition excludes mislabels data non people examples biases seeping problem definition stage found facial scanning apps dolgin data collection processing process step data collected cleaned prepared used model developers aware introduce bias definition modelling training dataset labelling data labelling bias selection training dataset sampling bias aggregation different existing datasets simpson paradox exclusion features excluding bias etc examples bias stage found solution breast cancer developed researchers mit computer science artificial intelligence laboratory csail massachusetts general hospital mgh system predicts whether patient develop breast cancer mammogram image based deep learning developers used mammograms belonged white women despite fact black women likely develop breast cancer although authors indicate system valid either black white women review carried showed worse results black women underrepresented communities stoa panel future science technology model development step model learns knowledge representation problem solved based training dataset training data unbalanced unfa discriminatory toxic model bias training process results models reflect undesirable aspects result system performs well concerning optimization goal may perform poorly concerning social damages sys tem encodes perpetuates harmful stereotypes biases present training data reasons also introduce bias include removal features model developers subsequently consider irrelevant excluding bias algorithm incorrec correlates data confounding bias amazon recruiting engine real example model ranks applicant suitability based submitted found biased women developers tried solve problem despite insufficient data available train fit model reduce gender bias eventually problem algorithm declared unsolvable proj stopped dastin model validation thi step developers test validate solution fine model stage cognitive cultural biases originating developers enter model confirmation bias occurs model results support dev eloper ideas beliefs lead developer stop tuning model considered correct confirmation bias also occur developer discards results support thei ideas beliefs hand bias happen developer detec biased results cases developers correct bias therefore persist may even become amplified system examples bias stage illustrated facial recognition systems developed ibm microsoft gender shades project evaluated accuracy three commercial based gender classifiers facial images gender shades created test data set called pilot parlia ments benchmark demonstrate systems balance facial recogni capabilities across genders skin tones following gender shades report ibm worked substantially increase accuracy new recognition system cial analysis uses different training data different recognition capabilities service gender shades evaluated april model deployment phase responses solution reviewed stakeholders inal users validate provide feedback point human cultural cognitive biases included may happen response expensive expected stakeholders suggest modifications lower cost unding bias response system contrary cultural ideas modifications suggested cultural bias examples bias stage occur response biased confirms user ideas confirmation bias user focuses surviving validate correctness solution survival bias etc one example jiang research prototype responds moral reasoning situations actions delphi ained large collection million ethical demands commonsense norm bank system responds moral judgments large number situations including socially sensitive however system allows users confirm reasoning introduces numerous cultural cognitive biases fter auditing quality datasets used algorithmic decision systems short period use model responds advice could potentially offensive problematic harmful jiang another example occurred icrosoft implemented twitter chatbot designed interact young people soon release started swear make racist learning interactions people started swear incite racist reactions although single universal solution remove bias system file consulting firms develop best practice minimise bias solutions analyse points wher risk prejudice discrimination verify size metadata training dataset adequate neither excessive insufficient training data set must representative balanced perform statistical analysis tra ining dataset including subpopulation analysis calculate model metrics specific groups dataset help determine model performance identical subpopulations pay attention self solutions monitor result time since biases may appear models learn independently establish strategies identify mitigate biases technical operational organisational points view technical strategy identify involve tools methodologies identify possible sources bias evaluate effect removing data precision solution operational strategy strategies focus improving data collection processes use internal external audit groups organis ational strategy establish work visualisation environments verify different metrics results model transparently identify significant use cases comparing system results human results improve process including human loop approach construction evaluation model diverse approach development teams diverse inclusive participation diversity facilitates identification biases throughout development validat ion system people belonging specific underrepresented communi help identify biases affect multidisciplinary approach development teams interdisciplinary knowledge ethical reflection mitigating bias equires interdisciplinary approach includes specialists various fields domain experts ethicists social scienti sts philosophers legal experts stoa panel future science technology main points bias introduced stage development sol ution necessary understand biases appear process developing solution order prevent mitigate humans introduce cultural cognitive biases solutions development deployment phases interact data model best development practices recommend including human loop development process building diverse interdisciplinary development teams ethical flection inclusive participation fairness strategies bias detection mitigation elimination biases avoid control without necessarily making cultural societal changes require technical interventions ought adopt design build apply system section focus strategies detecting mitigati undesired biases main sources unfair decisions detection mitigation bias trivial endeavour indeed challenging differentiate patterns data represent actual knowledge want system learn obesity increases colorectal cancer risk stereotypes want avoid fat people exercise habits without intervention algorithm learn owledge stereotypes previously mentioned concept fairness difficult specify indeed several notions fairness exist technically defined also entangled concepts social justice specifically concept privilege held virtue belonging certain social identity groups applications privileged group defined favourable outcome classification predicted score provides systematic advantage vertheless privilege either acceptable unacceptable depending context instance privileged access health care services according clinical severity generally acceptable however clinical severity assessed usin model biased towards instance ethnicity gumbsch borgwardt generally acceptable due systemati advantage given privileged group ethnicity well sex gender race religion protected attributes define groups considered sensitive laws regulations policies decisions deemed fair perspective group individual dwork two main notions fairness defined group fairness groups defined sensitive attributes receive similar predicted outcomes individual fairness similar individuals receive similar predicted outcomes notions fairness map three main fairness criteria systems isfy barocas based predicted outcome target variable sensitive attribute independence separation sufficiency table auditing quality datasets used algorithmic decision systems table fairness discrimination criteria fairness criterion formu definition equivalent terms independence protected attribute statistically independent prediction demographic parity statistical parity group fairness separation protected attribute statistically independent prediction given target value equalised odds conditional procedure accuracy disparate mistreatment avoidance sufficiency protected attribute statistically independent target value given prediction cleary model conditional use accuracy calibration within groups prediction outcome sensitive characteristics target variable formalism equivalency terms source barocas case binary classifier independence criterion expressed equal probability two groups receiving predicted class independence criterion also expressed difference disparate impa difference ratio disparate impact ratio relative risk ratio adverse impact ratio possibil classification constraints relaxed slack variable another form relaxation independence criter ion conditional statistical parity corbett permits set legitimate attributes affect outcome instance marital status predictions related financial well despite widely used decisions based system satisfies independence criterion lead undesired bias instance clinical severity assessed rate two groups error prediction differs instead separa tion criterion demands equality error rates two groups also accommodate forms relaxation instance depending scenario might require equality false negative rates equal opportunity hardt false positive rates predictive equality chouldechova forms relaxation separation criterion include balancing negative class kleinberg equalising correlations woodworth finally sufficiency criterion acknowledges prediction absorb sensiti characteristic purpose predicting target instance applying decision threshold margin groups nevertheless suff iciency imply equality positive predictive value predictive parity outcome test chouldechova vice versa indeed stoa panel future science technology individuals one group far margin decision threshold could incur biased decision problem known infra simoiu important stress although three fairness criteria independence separation sufficiency diagnostic value highlighting different groups experience ifferent costs classification conclusive argument drawn based fairness criterion alone corbett instance external intervention criteria could conceal unacceptable practice shown criterion based strong assumptions equipped different forms relaxation building model fairness criterion achieved three algorithmic interventi ons table choice techniques depends degree control training process possibility accessing raw data training pipeline trained model table techniques algorithmic interventions achieve fairness criteria technique description example advantages disadvantages adjusting feature space training model disparate impact remover feldman feature space transformed fairer representation techniques agnostic downstream applications adjusting constraints optimization process training time adversarial biasing lahoti classifier optimised following specific fairness criterion techniques specific model optimisation process post adjusting model fully trained multi boost kim techniques suitable black box model training needed techniques generally display limited utility compared previous ones examples notable machine learning algorithms rendered fair specifi interventions include fair regression agarwal fair decision trees aghaei fair support vector chines olfat aswani amongst many others moreover toolkits developed address machine learning fairness table several companies organisations committed area table atured auditing quality datasets used algorithmic decision systems table selection tools machine learning fairness tool company description fate microsoft tools services fairlearn microsoft interactive visualisation dashboa unfairness mitigation algorithms fairness ibm usted comprehensive set fairness metrics datasets machine learning models explanations metrics algorithms mitigate bias datasets models crowdsourcing microsoft university maryland detection bias natural language processing applications clearbox clearbox synthetic data generation datagen datagen synth etic data generation synthesis synthesis synthetic data generation mostly mostly synthetic data generation fairml dspace mit tool box diagno sing bias predictive modelling teach test accenture enture artificial testing methodology solutions validation tool google visually probe behaviour trained machine learning models lime explanations predictions machine learning stoa panel future science technology interpretable agnostic classifiers gender shades mit media lab benchmark image dataset table companies organisations providing services machine learning fairness name purpose eticas consulting applied ethics solutions algorithmic auditing focus group health wiegand inter collaboration itu create benchmarking framework assess accuracy health consulting algorithmic auditing orcaa consulting company helps companies organisations manage audit algorithmic risks sama training data platform appen data sourcing data annotation model evaluation validation ethics certification main points design strategies bias detection mitigation elimination require application fairness criteria namely independence separation sufficiency specific levels relaxation algorithmic interventions achieve fairness criterion applied pre processing post companies research institutions producing several toolkits machine learning fairness well best practice recommendations still lack standardisation whitepaper focus group artificial intelligence health auditing quality datasets used algorithmic decision systems normative analysis biases already analysed technical framework regarding biases time address issues perspective law legal tools might serve well prevent bias complicated question begin wit almost unknown term european regulatory ecosystem multiple kinds sources bias make difficult conceptualise regulate bias furthermore polysemy term lead confusion bias widely used tendency prefer one person thing another favour person thing synonym prejudice however previously stated statistics field fundamental importance algorithmic systems bias refers type systematic error deviation found use statistical analysis bias prejudice expresses problematic ethical burden bias statistical sense fact introduction statistical bias datase solution prejudice bias embedded database accurately expresses real world therefore start distinguishing two different issues problems related discrimination problems related quality data precisely nex section devoted afterwards highlight main limitations current regulatory approach address problems data collection pre stages preliminary issue extent biases relevant regulatory arena biases algorithmic systems generate results unlawful broad sense understand unlawful result harms contravenes right benefit protected law identification bias prejudice led legal analy sis focus problems discrimination generate yet analysis fundamental limitation unlawful results also stem non bias propose divide relevance bias ormative level following categories problems discriminatory nature problems related quality problems discriminatory nature algorithmic systems discrimination inseparably tied machine learning algorithms supposed scriminate data points use yet logics discrimination even predictively valid socially acceptable veale binns discriminatory problems lie models work also mited human capacity understand perform work epistemic opacity machine learni algorithms understood human inability understand complexity inner worki ngs certain models major obstacle understanding scriminatory problems moreover opacity regarding operation models deliberate choice often regulatory basis trade secret intellectual property may equally harmful allow key aspects explored even opacity algorithmic systems considered problem also makes difficult uncover discrimination borgesius understanding correlations lead particular decision may humanly unfeasible ven work done methods facilitate interpretability explainability models however understanding kind data used feed model political decision quality problems bias lead harmful outcomes without nece ssarily discriminatory bias may affect level accuracy algorithmic results therefore contribute unjustified harm different goods affected use algorithmic system however harm necessarily entail affecting way goods services distributed discriminatory way stoa panel future science technology given various kinds normative problems may arise context may useful label quality problems regulations protect value ccuracy collection processing data derived fundamental right protection natural persons relation processing personal data gdpr includes accuracy principle processing personal data ticle regulations especially regulating development products placed market protect values quality afety example achieve high level human health protection article tfeu edical device regulation mdr sets high standards quality safety medical devices ensuring among others data generated clinical investigations reliable robust requi rigorous quality management system manufact urers means mdr manufacturers must place market medical systems based faulty data endangers clinical condition safety patients stöger see anti legal remedies limitations comes protecting harms produced hoc groups formed algorithmic correlations reason seems indispensable emphasise rights values governance mechanisms linked protect quality problems bias raises exposition current regulatory approach non fundamental value level part legal framework primary law article treaty european union states union founded values respect human dignity freedom democracy equality rule law respect human rights including rights persons belonging minorities values common member tates society pluralism non tolerance justice solidarity equality women men prevail furthermore article states uni combat social exclusion discrimination shall promote social justice protection equality women men solidarity generations protection rights child similar ideas found treaty functioning european union especially part two entitle citizenship union see article charter fundamental rights article question ensure anti stance translates implementation policies able fight biases datasets tools principle two possibilities consider first concerns discrimination law tools emerged year onwards explained legal framework unfortunately shows certain loopholes therefore relevant analyse possibilities presented gdpr opinion many reasons argue effective tool ensure efficient defence values equality non ven though anonymised data still cause concerning issues last least new regulations merely approved discussed include important measures avoid biases carefully explored study anti regulations secondary legal tools discrimination level directives approved beginning constitute valuable effort towards non law applied context employment social security covered ground sex normative framework includ gender equality directive council directive racial equality directive council directive directive establishing general framework equal treatment employment occupation directive european parliament auditing quality datasets used algorithmic decision systems introduced wide protection discrimination unfortunately specific legislative technique selected regulate issues drawn quite complicated framework hinders adequate protection human rights involved aforementioned rules aimed avoiding discrimination based specific factor wide range human activities others hand sought avoid discrimination broad sense term including multiple factors many different sectors consequence loopholes hinder adequate protection discrimination instance goods services equality directives cover gender race protected grounds others furthermore appli cable directives include possibilities exceptions ban discrimination especially talk indirect discrimination cases directives state discrimination permissible objectively justified egitimate aim means achieving aim appropriate necessary problem open exceptions create uncertainty determining whether form discrimination justified principle lved case law however still far sufficient precedents regard even worse contextually limited interpretation concept discrimination endorsed court justice result ese legislative gaps law protect citizens algorithmic profiling targeting means certain disadvantaged groups lawfully excluded access certain goods services example one could imagine discrimination arise offer particularly vital goods services housing health education etc even though national law could prohibit instances discriminati harmonized prohibition exist level gerards xenidis council july implementation principle equal opportunities equal treatment men women matters employment occupation recast article directive articl directive article directive article directive article directive article directive article directive article directive instance discrimination grounds religion belief disability age sexual orientation explicitly prohibited sectors covered directive education social security access good services including healthcare housing advertising media indeed gender goods services directive expanded scope sex discrimination area goods services protection grounds sex quite match scope protection raci equality directive since gender social security directive guarantees equal treatment relation socia security broader welfare system social protection access healthcare education european union agency fundamental rights european court human rights ouncil europe handbook european non law council directive art council directive art council directive art directive europ ean parliament council art judgment december fag arbejde foa kommunernes landsforening judgment july coleman attridge law steve law judgment july sonia chacon navas eurest colectividades refers goods services market stoa panel future science technology european commission tried improve framework proposing horizontal aimed implementing principle equal treatment persons irrespective religion belief disability age sexual orientation outside labour market proposal set framework prohibition discrimination grounds establishes uniform minimum level protection within european union people suffered discrimination unfortunately never approved corresponding bodies furthermore number member states delayed implementation directives many years seem situation going change soon data protection regulations analysis essential issues main conclusion reached previous section anti regulations include concrete types discrimination good reasons consider gdpr could excellent tool address many loopholes rigidities hinder tensive application discrimination regulations first gdpr aimed protecting rights freedoms natural persons particular right protection personal data art thus one keep mind application fundamental values non possible also necessary gdpr second one must consider gdpr includes fairness principles rule personal data processing see articl gdpr also recital declares processing personal data lawful fair thus processing take place previously introduced concept fairness essential condition roceed bias mitigation schemes technical point view importance legal arena even higher face issues related biases since discrimination clearly unfair concept fairness could play key role terms biases mitigation indeed lack concrete definition fairness could allow extend use concept include cases proposal council directive implementing principle equal treatment pers irrespective religion belief disability age sexual orientation sec sec interpretation endorsed cjeu ruled data protection legislation must interpreted applied light fundamental rights enshrined charter data protection play instrumental role protection right non particular ivanova yordanka data protection impact assessment tool enforce non annual privacy forum springe cham see recitals gdpr main points context prohibition discrimination seems limited particular contexts concrete factors scenario introduces doubts permissibil use algorithms introduce bias specific cases need addressed soon possible different ways deal situation instance incongruenc contradictions could eliminated improving current regulations ong lines proposed proposal council dir ective implementing principle equal treatment persons irrespective religion belief disability age sexual orientation auditing quality datasets used algorithmic decision systems inequity discrimination beyond classical discrimination categories included dir ectives nice argument supports additional use concept even though european court justice never defined notion fairness data protection law used notion fairness two different contexts air balance consider fairness reasonable expectations data subjects help avoid discriminatory results easy uncover data subject would hardl allow type processing would cause suffer damage people suffer thus final result appeal fairness seems suitable finally additional reason support data protection regulations hould emphasized approach based regulations enormous advantage since fundamental principle gdpr data protection design obvious data controller obliged introduce measures control bias processing begins measures reviewed afterwards even deployment tool makes much easier prevent non check occurring damage already done concepts tools shall render principle applicable practice gdpr includes essential tool serve well adequately performed face risk posed biases data protection impact assessment dpia constitutes excellent opportunity ensure adequate protection human rights preliminary stage processing dpia continuous process guides supervises implementation processing activity compl ies data protection requirements impact natural persons minimized based risk approach works extraordinarily wel act approved arena introduce next secti introduction elements corresponding assessment bias dpia important contributes proper implementation idea fairness design mentioned general ability introduce biases particular difficult control posteriori recourse courts neither best mechanism prevent biases occurring hence mechanism dpia makes possible assess possibility pernicious consequences use mechanism early stages creation particularly promising achieving intended goal however necessary point dpias might get conflict type impact assessments foreseen act creating considerable legal chaos sum data protection regulation uld become efficient tool order fight bias however suffers condition limits real effectiveness focuses processing personal data therefore perfectly possible train validate systems using personal data gdpr applicable datasets may irreparable consequences anonymization protects identity individuals data imbued nonetheless personal characteristics equally biased deal consequences providers conduct impact evaluations training phases even personal data involved otherwise merely entails delaying later stage phases would better plemented beginning explicit provision act could contribute clarify issue cjeu opinion draft agreement canada european union transfer passenger name record data european union canada ecli case heinz huber bundesrepublik deutschland ecli panelfit guidelines dpia stoa panel future science technology new regulatory tools general introduction beyond discrimination regulations gdpr another set rules also great importance approaching issue bias set rules comprises regulations passed digital services digital markets act aimed creating safer digital space fundamental rights users protected establishing level playing field businesses include measures devoted fighting discrimination digital services act introduces obligation large online platforms introduce measures ensure design algorithmic systems used create discrimination among users measures include need conduct risk assessments design risk appropriate mitigation act also states large online platforms accountabl independent auditing compliance obl igations laid regulation relevant complementary commitments undertaken pursuant codes conduct crises needless say provisions shall efficient order fight bias digital mar kets act include explicit references measures need incorporated fight bias state shall apply fair non discriminatory general conditions access business users software appl ication also introduces clauses aimed prohibiting confidentiality clauses agreements written terms hinder exercise right business users raise concerns unfair behaviour gatekeepers relev ant administration public authorities however regulations interest analysing avoid biases cause discrimination datasets mechanisms primarily data governance act ata act artificial intelligence act act onwards important clauses regarding data probably included article act training validation testing data sets shall relevant representative free errors complete shall appropriate statistical properties including applicable recital article digital services act recital digital services act recital digital services act provider core platform services article digital markets act recital digital services act proposal regulation european parliament council laying harmonised rules artificial intelligence artificial intelligence act amending certain unio legislative act main points gdpr could excellent tool fight bias concept fairness use dpias essential tools protect data subjects adequately performed however shows weaknesses main problem data protection law lack coverage databases contain personal data impact assessments could help solve deficiency however would necessary consider conciliate tools dpias auditing quality datasets used algorithmic decision systems regards persons groups persons risk system intended used characteristics data sets may met level ind ividual data sets combination thereof training validation testing data sets shall take account extent required intended purpose characteristics elements particular specific geographical behavioura functional setting within high risk system intended used main issue face proposed acts missing clear connection data protection law concepts play key role gdpr data minimization data protection design apparently important acts act mention explicitly whereas data act includes references articles next sections misali gnments may generate legal uncertainties concerned bodies showed essential legal tools fight biases previous pages analysed main normative approaches bias section examine main measures tools serve mitigate purpose first necessary establish certification procedures systems procedures must sometimes dynamic given tools learn data gathered indeed case management system shall consist continuous iterative process run throughout entire lifecycle high system requiring regular systematic updating datasets hand probably need include adequate information bout important features expected used systems development processes since datasets often altered information provided also updated turn efficiency certification processes depends creation standards provide reliable knowledge datasets including essential information created types data contain etc provide homogeneous guidelines determine absenc bias predictions made mechanism reinforced certification system implementation accountability measures ensure parties involved implement adequate mitigation risks arise ideas explored deep next pages standardisation way avoid biases creation standards applicable datasets mechanisms fundamental pillar regulation given diversity characterizes sector would difficult validate datasets systems thus provide universally recognized certificates without using standards however must emphasized standardization early stages datasets arena universally agreed standards data quality assessments machine learning tools moment even though interesting proposals area gebru probably change next years since considerable efforts implemented improve scenario case currently discussed regulations efforts worth highlighting related promotion standardization inde article data act states commission may accordance article regulation act article see act article see regulation european parliament council octob european standardisation regulation standards level stoa panel future science technology request one european standardisation organisations draft harmonised standards satisfy essential requirement paragraph article data act requirements standards shall fulfil include information dataset content use restrictions licences data collection methodology data quality uncertainty furthermore artic proposed regulation details datasets shall include information data structures data formats vocabularies classification schemes taxonomies code lists shall described publicly available consistent manner information shall sufficiently described allow recipient find access use data well aligned proposals made instance agency fundamental rights defines constitutes minimum guidance understanding quality data basis following questions focus data come responsible data collection maintenance dissemination information included data information included data appropri ate purpose algorithm covered data data information missing within dataset units partial covered time frame geographical coverage data collection used building application thus data act making significant effort introduce standards datasets scenario provisions work well european strategy dat constantl appeals need create standards applicable datasets case one must always keep mind standardisation datasets would allow flexibility order able include variety possible data formats collections used applications essenti data formats often differ substantially moreover usually collected specific purpose thus makes good sense act specifies require ments generic nature concern specific sectors art last least worth mentioning data act states standards exist service type concerned provider data processing services shall request customer export data generated including relevant data formats data structures structured commonly used machine format art might particular interest present circumstances case systems act states high systems conformi harmonised standards parts thereof references published official journal european union shall presumed conformity requirements set chapter title extent standards cover requirements icle however standards exist present level organizations communicat ion commission european parliament council european economic social committee committee regions european strategy data brussels com final auditing quality datasets used algorithmic decision systems iso trying produce available still preliminary moreover standards organizations may insufficient meet requirements european regulations often demanding legal frameworks indeed legislature probably ask european standardization organizations esos produce harmonised standards therefore seems reasonable expect organizations etsi cen cenelec three european standardizat ion organizations officially recognized european union european free trade association efta responsible developing defining voluntary standards european level develop standards specifica lly adapted legal framework according available information already started preliminary works instance edition putting science standards psis workshop jointly organi sed cen cenelec joint research centre european commission jrc dedicated data quality requirements inclusive nonbiased ethical would advisable construction standards addressed process would allow inclusion suggestions stakeholders nongovernmental organisation ngo representatives final product important citizens feel interests taken account standards guarantee adequate level protection measures must also taken ensure mechanisms adopted sufficient quality strictly technical regulatory point view namely standards algorithmic bias considerations ieee also creating general standard ieee certifaied mark aimed conveying organization capability fulfil applicable transparency accountability reduction algorithmic bias privacy requirements stipulated appropriate criteria foster trust facilitate adoption use products services see indeed years ago iec iso created joint committee jtc leading standardization activities artificial intelligence created working groups foundational standards trustworthiness use cases applications data computatio nal approaches computational characteristics artificial intelligence applications governance implications currently countries participate actively work extensive involvement european countries countries participating holding total leadership positions convenorships editors cen response white paper version page key tools one documents works awi entitled treatment unwanted bias classifica tion regression machine learning tasks aimed providing provides mitigation techniques applied throughout system life cycle order treat unwanted bias cen working programme stoa panel future science technology certification certification defined attestation product process person organizati meets specific certifications usually aimed reducing information asymmetries cihon use usually considered clear cost saving somehow certification linked strictly standardization even though different concept certifications meant give evidence standards fulfilled concept certification already used multiple sectors starting introduced sector already programs place european commission level cihon well institute electrical electronics engineers iee specific countries malta digital innovation authority finkel act includes approach imposing certification system conformity assessment covers mandatory requirements applicable high sys tems based european harmoni zed standards regulation common specifications established commission system however mainly relies self even though supervised structure entiti notifying indeed internal assessment procedures permitted substantial number cases framework criticised edpb edps consider third conformity assessment must carried general basis high edpb seems appropriate suggestion works well relevant opinions academia veale borgesius certifications could also apply datasets course data act data governance act proposal specifically impose however considerations regarding standards already included clauses previously mentioned voluntary certification model probably arise would excellent idea since certification could help developers ensure datasets use train validate algorithms biased course problem washing possibility companies incorporating weak requirements providing certificates always exist thus third party performs certification would surely increase confidence since developers providers rely information provided whoever created conformity assessment voca bulary general principles ieee ethics certification program autonomous intelligent systems ecpais online available accessed main point creation standards applicable atasets mechanisms fundamental pillar regulation assets however standardisation early stages datasets arena standards related datasets shall include information dataset content restrictions licences data collection methodology data quality uncertainty standardisation datasets used tools would allow flexibility order able include variety possible data formats collections used applications auditing quality datasets used algorithmic decision systems databases perform deep analysis however intervention third parties involves inconveniences namely higher cost delays tool preparatio process case intervention states imposing certification datasets third parties might unnecessary especially providers decide exclusively use datasets contain form certification attesting quality data market inertia eventually impose modus operandi case probably reconsider issue however another issue needs adequately addressed pointed edpb edps certification mechanism created act different certification system aimed ensuring compliance data protection rules principles outlined articles gdpr however clear certificates iss ued notified bodies accordance proposal may interface data protection certifications seals marks provided gdpr unlike provided types certifications far high systems based processing personal data process personal data fulfil task misalignments may generate legal uncertainties concerned bodies since may lead situations systems certified proposal marked marking conformity placed market put service might used way compliant rules principles data protection edpb therefore relationship certificates issued said regulation data protection certifications seals marks needs clarified compliance monitoring monitoring high tools certainly needed want mitigate bias already mentioned ocess creating deploying mechanism complex able determine point bias introduced possible derive responsibility consequences however monitoring tools sometimes extremel complex several reasons first target population might variable thus evidences gathered universalised use tool nebraska madrid might happen results different terms bias hand systems based dynamic processes unlike mechanisms pharmaceutical industry example produc dataset tool instance changes time since incorpo rate new data learn new data thus true one point time may true another thi means control procedures must continuous dynamism implies controls datasets mechanisms must exercised essentially two ways first providers must establish periodic monitoring system main point act imposing certification system conformity assessment covers mandatory requirements applicable high syst ems could excellent tool fight bias however issues considered regarding certification tools certification schemes still work progress self assessment might best approach avoid issues relationship certificates issued act gdpr needs clarified stoa panel future science technology second must take account occurrence circumstances may substantially affect data example wave refugee women applying social assistance data may introduce trends differ historical ones hence need new data control requirements adequately endorsed articles act article devoted risk management stipulates provider must perform adequate testing risk systems point time throughout development process event prior placing market putting service hand article states high systems shall undergo new conformity assessment procedure whenever substantially modified regardless whether modified system intended distributed continues used current user finally article states providers establish document post monitoring system manner proportionate nature artificial intelligence technologies risks high system post monitoring system shall actively systematically collect document analyse relevant data provided users collected sources performance high systems throughout lifetime allow provider evaluate continuous compliance systems hand worth mentioning new regulatory framework data governance promoting ante control mechanisms includes controlling qual datasets make training data already mentioned provider must ensure datasets meet reasonable quality iteria article act end lawful basis allows process data sensitive categories art act need run continuous iterative processes throughout entire lifecycle high system requiring regular systematic updating art act course also excellent tool guarantee adequate compliance requirements settled regulation stages lifecycle tool however governance framework introduced act definitely complex includes supervision third parties competences shared member states commission last resort ensure compliance member states design national supervisory authority notifying authority market surveillance authority national authority competent designating monitoring notified bodies conformity assessment bodies notified bodies perform third conformity assessmen extent monitoring system role played corresponding authorities might overlap role data protection authorities dpas play according gdpr could somehow avoided dpas also designated national supervisory authorities edpb last least necessary mention apparently impressive control system include adequate mechanisms isolated individuals let alone organizations responsible protecting rights adequately supervise functioning mechanisms regulatory provisions requiring providers disaggregate informati results obtained use much less provide documentation entire process organizations stated tambiama individuals affected systems civil rights organisations right complain market surveillance authorities sue ider user failure comply requirements similarly veale zuiderveen borgesius warn provisions draft legislation aim impose obligations systems users mechanism complaint judicial redress available way deprives element could important improve control systems auditing quality datasets used algorithmic decision systems main points monitoring high tools certainly needed mitigate bias however monitoring might beco extremely complex due several reasons means must create adequate tools able deal complexity dynami monitoring carefully considered act proposing governance framework introduced act definitely complex includes supervision third parties competences shared member states commission last resort ensure compliance however provide individual citizens ngos protecting human rights equate tools complain market surveillance authorities sue provider user failure comply requirements probably reconsidered stoa panel future science technology conclusions based presented preceding sections following conclusions reached fight biases understood systematic deviations reference value norm rationality judgement individual group algorithm producing unfai consequences important com plex multiple reasons argue eradication bias impossible strategies focus reducing incidenc mitigating effects interpreted case problem specific datasets human operator introduce biases much accentuated difficult eradicate therefore criticism biases derived use systems must contemplate alternative human element may incorporate worse biases biases inherent human beings culture history multiple taxonomies bias identify ing classify ing complex soluti ons incorporate new biases tend magnify exis ting human biases identify mitigate bias solutions necessary understand aware biases introduced stages process development training dataset algorithm humans involved essential step mitigate biases create use high quality domain pecific ining datasets guarantee fair knowledge representation system mechanisms oversight accountability implemented continuously assess quality integrity data techniques exist correct biases systems via processing post processing achieve higher fairness systems currently several nies developin toolkits help process although still lack standardisati sector best practices recommend including loop development process building diverse interdisciplinary development teams hical reflection inclusive participation easy draw regulatory framework able deal bias since bias complex concept synonymous discrimination least legal point view context prohibition discrimination limited particular contexts concrete factors scenario introduces doubts allowing use algorithms introduce bias specific cases needs addressed soon possible different ways deal situation instance incongruences contradic ons could eliminated improving current regulations along lines contained proposal council irective implementing principle equal treatment persons irrespective reli gion belief disability age sexual orientation however alternative legal tools able cope discrimination issues could also considered gdpr could excellent tool fight bias concept fairness however also shows weaknesses main problem anti law limited application multiple forms unfair treatment produced algorithmi systems main problem data protection law lack coverage database contain personal data anonymi sation techniques appropriate protect privacy however protect reproduction biases using data thi aggravated fact gdpr principles applicab anonymi sed data auditing quality datasets used algorithmic decision systems creation standards certificates applicable datasets mechanisms fundamental pillar regulation assets however early stages datasets arena standards related datasets clude information dataset content use restrictions licences data collection methodology data quality uncertainty hand standardisation certifications related datasets tools must allow flexibility order able include variety possible data formats collections used applications monitoring high tools certainly needed want mitigate bias however monitoring might become extremely complex several easons means must create adequate tools able deal complexity dynamic monitoring must carefully considered proposed draft act governance framework introduced act proposal definitely complex includes supervision third parties competences shared member states european commission last resort ensure compliance however provide individual citizens ngos protecting human rights adequate tools complain market surveillance authorities sue provider user failure comply requirements probably reconsidered stoa panel future science technology policy options ssessment accordance analysis carried previous pages study policy opti ons may serve improve current situation suggested section complementary others mutually exclusive last case reasons supporting one provided policy gain better understanding present situation policy option create new regulations specifically focusing biases instead focus misalignments different regulatory tools first tempting option address issue bias develop specific regulations matter done level creation specific tool directive regulation would achieve greater unification criteria among member states responding complex issue would also gain legal certainty specificity applicable legal framework however currently good idea introduce specific regulation biases datasets biases result use mechanisms general multiple reasons support hypothesis first already overabundance data protection rules context adding new one even specific bias would probably unnecessary regulation avoided wherever possible furthermore general common regulation biases datasets tools would difficult design data sources systems diverse quantitative qualitative data wide range disparity database consisting transcripts conversations natural language one consisting numbers containing images furthermore datasets mechanisms used different purposes measures take control avoid bias likely different scenario moreover diffic ult justify existing regulations sufficient solve many problems posed biases true regulations non discrimination somewhat rigid however could possible modify existing directives approve proposed orizontal directive would add cla rity current situation furthermore data protection regulations offer interesti alternatives inclusion concept essential principle gdpr opens door possibility introducing specific recommendations processing personal data thus example would possible edpb develop opinion fairness biases establishing criteria type procedures nec essary justify data processing adoption types specific decisions fair draft regulations currently discussion introduce interesting categories concepts draw adequate approach issue ias promotion standards certification laudable initiative possibilities rules could explored considering new ones especially time biases yet seem unbearable threat short kes much advisable produce specific regulation take advantage opportunities presented already exists case slight modifications regulations approval phase would advisable particularly important promote best practices use standards auditing quality datasets used algorithmic decision systems implementation certification systems solve misalignment different regulatory tools especially gdpr new regulations generate legal uncertainties bodies concerned otherwise companies may find breach regulations intersection act gdpr eneral product safety regu tion malgieri tiani policy option preventive approach strengthening bias mitigation data collection application best practices bias mitigation policy priority start data collection onwards means data collection comply principles findable accessible interoperable usable fact fair principles respected time data collection also serve extremely efficient measure introducing standards better data governance auditing databases integrated addition proper implementation fair principles would allow much efficient integration separately constructed databases better control biases source ensur means course including adequate information characteristi data contain namely data structures data formats vocabularies classificati schemes taxonomies code lists described publicl available consistent manner policies fit well principle data protection design essential gdpr conveniently emphasised rules discussed data governance introduc tion policies aimed promoting enforcing fair principles quality controls earliest stages data processing construction datasets feed systems essential avoid damage occurring later stages evelopment implementation tools introduction standards models certification datasets great help ensur ing success early control dataset quality measures apply personal data anonymised data anonymisation use synthetic data excuse evade accountability mitigating bias non data used make decisions hat affect people therefore extend prevention introduced personal data processing anonymised personal data processing suc processing involves high risk terms rtificial intelligence act finally would worth considering need equally effective measures data collection public private sector former may considered priority many respects creation fragmented data market large differences public ivate sector may negative impact bias mitigation policy option promote database certification enforcing bias beginning lifecycle algorithmic systems policy option explores possibility intr oducing certificates datasets objecti avoiding biases comprises two main possible actions first certifying dataset developer applied best available practices avoid presence significant biases second rtifying dataset developer provides accurate relevant information dataset may prevent stakeholders developing using dataset algorithmic system biased way course dataset certificates could complemented others referring artificial tool shaped thanks data stoa panel future science technology however argued retained certification hardly ensure biases totally excluded since available techniques bias mitigation pre stage limited effectiveness application techniques imply use deployment system fed data lead biased results thus kind certifica tion stage conducted consideration limitations duly communicated stakeholders development deployment use systems trained certified databases scenarios described would necessary describe authority conduct certification three main models certification require less external intervention process certification public authorities certification authorised third parties however idea introducing certificates allows different approaches options advocate certificates obtained exclusively public entities others allow self also possible introduce different requirements depending level risk involved given treatment hand one opt either mandatory voluntary system meaning data providers could adopt certification kind quality check serves improve offer alternatively data providers could required attach obligatory certificate moreover combination different kinds regulatory certification systems considering differe risk levels perfectly possible already proposed public authorities high systems alternatively could even possible combine policy options mandatory certification high systems volun tary certification rest section issues considering two alternative approaches mandatory voluntary certification high system databases analy sed policy option mandatory certification databases ill feed high systems making data providers accountable first possible option introduction mandatory certification framework databases feeding high systems case certification databases mandatory whenever used purpose developing high system database used purpose must certified either database provider system provider former done provider policy option would require separation certification post responsibilities proposed rtificial intelligence act particularly regard responsibilities data governance currently set article therefore also requires recognition database provider separate system provider even though company may occupy roles many cases policy option voluntary certification high system databases tool allowing system providers comply regulations demonstrate compliance policy option offers voluntary certification possibility system providers demonstrate compliance data governance requirements development high risk systems auditing quality datasets used algorithmic decision systems voluntary certification datasets could appropriate tool comply ing regulation demonstrat ing compliance introduction certification market provide system providers confidence acquiring databases dataset providers achieve certification gain competitive vantage dataset providers systems include advantages disadvantages mandatory certification involves higher costs however increases reliability datasets especially certificates provided third parties last least consider although focus databases development high systems policy options would equally applicable regulation type system also sec torial basis policy option granting transparency rights subject opening window find source biased results policy option envisages granting transparency rights databases systems developed make decisions affecting purpose rights access information provided gdpr include information logic involved automated decision profiling however information extend information training datasets key logic involved automated processing result data subjects ability check whether processing data lawful fair accurate accordance gdpr limited even though safeguards serve preserve rights likewise proving discrimination without information data used training algorithmic system complicated therefore policy option able ask meaningful information training datasets information least include metadata datasheets training datasets generated certification could serve purpose information adversely affect rights freedoms others including data protec rights trade secrets intellectual property however result balance refusal provide relevant information unfortunately individual rights currently included proposed artificial intelligence act veale borgesius changed risk rul prohibited risk practices beco infective practise avoided purpose would necessary ensure information rights decisions significantly affect also extended hybrid decisions recommender decision systems decisions based solely automated processing contrary articles gdpr would advisable implement perspective individual rights without policy options reinf orce ways holding data system providers accountable information provided transparency rights alone rather inadequate govern algorithmic systems data hert lazcoz policy option facilitating implementation finally considered compliance regulations currently awaiting approval entail costs risks companies first certification processes involve charges ees example external audit per hour costs yearly audits notified body could roughly per year involving two people working stoa panel future science technology days furthermore companies wait certification launching produc market involves additional costs might challenging especially smes companies operating international markets case competitiveness would probably suffer severe damage indeed pact assessment accompanying proposal acknowledge smes supply high systems would principle affected large companies several reasons thus new regulations aimed boosting technological industrial capaci well uptake across economy consider measures could ings easier industry particular smes regulatory excellent examples measures similarly obligation consider smes interests setting fees related conformity assessment ould surely help reduce costs furthermore measures included rticle draft act providing smes priority access regulatory sandboxes excellent steps right direction however measures serve erase additional costs caused new regulations impact assessment ackno wledges additional costs margin discourage smes enteri certain markets high applications depend competitive environment specific application technical specificities theref ore necessary consider initiatives used reduce costs faced companies especially exclusively smes indeed act states framework envisage specific measures supporting innovation inclu ding regulatory sandboxes specific measures supporting small users providers high systems compl new rules opinion one appropriate measures would public institutions make high databases available private agents would substantial reduce expenditure associated review datasets correspon ding certifications initiatives european health data space facilitate non access health data training artificial intelligence algorithms datasets privacy secure timely transparent trustworthy manner appropri ate institutional governance relevant competent authorities including sectoral ones providing supporting access data may also support provision high data traini validation testing systems initiatives could course complemented specific subsidies aimed helping companies adapt new regulatory framework appropriate approach would probably type aid would alleviate heir substantial one cost market entry renda study support impact assessment regulatory requirements artificial intelligence europe final report april page commission staff working document impact assessment accompanying proposal regulation european parliament council laying harmonised rules artificial intelligence artificial intelligence act amending certain union egislative acts final page see article act act whereas auditing quality datasets used algorithmic decision systems references agarwal alekh regression quantitative definitions reduction algorithms proceedings international conference machine learning pmlr aghaei sina optimal fair decision trees non decision proceedings thirty aaai conference artificial intelligence innovative applications artificial intelligence conference ninth aaai symposium educational advances artificial intelligence aaai press acm digital library yates ricardo bias web communications acm vol may crossref barocas solon fairness machine learning beauchamp tom james childress principles biomedical ethics oxford university press belavusau henrard bird eye view anti law impact equality directives german law journal benjamins system discriminating without knowing paradox fairness privacy available knowing berk richard fairness criminal justice risk assessments state art sociological methods research sage journals bickel sex bias graduate admissions data berkeley measuring bias harder usually assumed evidence sometimes contrary expectation science vol crossref chouldechova alexandra prediction disparate impact study bias recidivism prediction instruments big data vol june atypon cirillo davide sex gender differences biases artificial intelligence biomedicine healthcare npj digital medicine vol june corbett sam algorithmic decision making cost fairness proceedings acm sigkdd international conference knowledge discovery data mining association computing machinery acm digital library costa marta analysis gender bias studies natural language processing nature machine inte lligence vol hert lazcoz gdpr blind accountability transparency heart algorithmic governan european data protection law review dolgin elie face app spots signs rare genetic disorders nature dwork cynthia fairness areness proceedings innovations theoretical computer science conference association computing machinery acm digital library stoa panel future science technology edpb joint opinion proposal regulation european parliament council laying harmonised rules artificial intelligence artificial intelligence act june accessed european union agency fundamental rights data quality artificial intelligence mitigating bias error protect fundamenta rights publications office csl json feldman michael removing disparate impact stat july flori luciano josh cowls unified framework five principles society harvard data science review vol july focus quality arti ficial intelligence bias error protect fundamental rights eur union agency fundam rights vienna austria friedman batya helen nissenbaum computer systems acm transactions information systems vol july july gebru timnit datasheets datasets communications acm gerards xenidis algorithmic discrimination europe challenges opportunities gender equality non law european commission directorate justice consumers publications office gianclaudio malgieri vincenzo tiani council rewriting act report december december last accessed gumbsch thomas karsten borgwardt bias clinical severity scores lancet digital health vol apr hardt moritz equality opportunity supervised learning adv ances neural information processing systems edited lee vol curran associates jiang liwei towards machine ethics norms kleinberg jon inherent trade fair determination risk scores innovations theoretical computer science conference itcs edited christos papadimitriou vol schloss dagstuhl fuer informatik dagstuhl research online publication server kusner matt fairness proceed ings international conference neural information processing systems curran associates leslie david stand augmenting inequality era covid healthcare bmj vol mar matias nathan lucas wright impact assessment human feedback loops tech social science research council mar crossref mehrabi ninareh survey bias fairness machine learning acm computing surveys vol july july auditing quality datasets used algorithmic decision systems miner adam smartphone conversational agents responses questions mental health interpersonal violence physical health jama internal medicine vol may olfat mahbod anil aswani spectral algorithms computing fair support vector machines proceedings twenty international conference artificial intelligence statistics pmlr prates marcelo assessing gender bias machine translation case study google translate neural computing applications vol may springer link samuel studies machine learning using game checkers ibm journal research development scheuerman rgan klaus computers see gender evaluation gender classification commercial facial analysis services proceedings acm human interaction vol cscw november schwartz reva proposal identifying managing bias artificial intelligence national institute standards technology june crossref simoiu camelia problem infra outcome tests discrimination annals applied statistics vol project euclid srinivasan ramya ajay chander biases systems survey practitioners queue vol apr pages march stöger aspects data cleansing medical computer law security review doi tambiama madiega artificial intelligence act accessed varshney kush trustworthy machine learning veale binns fairer machine learning real world mitigating discrimination without collecting sensitive data big data society doi ward dan sampling bias explaining wide variations covid case fatality rates researchgate tps wiegand thomas itu establish benchmarking process artificial intelligence health lancet vol july woodworth blake learning non predictors proceedings conference learning theory pmlr zuiderveen borge sius legal protection discrimination algorithm artificial intelligence international journal human rights routledge doi biases commonly considered one detrimental effects rtificial intelligence use therefore committed reducing incidence much possible however existence biases creation tools human societi biased reproduces therefore opposing technology reason would mpl hide discrimination prevent human supervision use available means many mitigate biases likely point future recommendations made mechanism contain less bias made human beings unlike humans reviewed flaws corrected consistent basis ultimatel could serve build fairer less biased societies study begins providing overview biases context artific ial intelligence specifically machine applications second part devoted analysis biases legal point view analysis shows shortcomings area call implementati additional regulator tools adequately address issue bias finally study puts forward several policy options response challenges identified publication scientific foresight unit stoa eprs european parliamentary research service document prepared addressed members staff european parliament background material assist parliamentary work content document sole responsibility author opinions expressed herein shoul taken represent official position parliament isbn doi
