miri machine intelligence research institutethe ethics artificial intelligence nick bostrom future humanity institute eliezer yudkowsky machine intelligence research institute abstract possibility creating thinking machines raises host ethical issues questions relate ensuring machines harm humans morally relevant beings moral status machines first section discusses issues may arise near future second section outlines challenges ensuring operates safely approaches humans intelligence third section outlines might assess whether circumstances ais moral status fourth section consider ais might diﬀer humans certain basic respects relevant ethical assessment final section addresses issues creating ais intelligent human ensuring use advanced intelligence good rather bostrom nick eliezer yudkowsky forthcoming ethics artificial incambridge handbook artificial intelligence edited keith frankish william ramsey new york cambridge university press version contains minor changes nick bostrom eliezer yudkowsky machine learning algorithms imagine near future bank using machine learning algorithm recommend mortgage applications approval rejected applicant brings lawsuit bank alleging algorithm discriminating racially mortgage applicants bank replies impossible since algorithm deliberately blinded race applicants indeed part bank rationale implementing system even statistics show bank approval rate black applicants steadily dropping submitting ten apparently equally qualified genuine applicants determined separate panel human judges shows algorithm accepts white applicants rejects black applicants could possibly happening finding answer may easy machine learning algorithm based complicated neural network genetic algorithm produced directed evolution may prove nearly impossible understand even algorithm judging applicants based race hand machine learner based decision trees bayesian networks much transparent programmer inspection hastie tibshirani friedman may enable auditor discover algorithm uses address information applicants born previously resided predominantly areas algorithms play increasingly large role modern society though usually labeled scenario described might transpiring even write become increasingly important develop algorithms powerful scalable also transparent inspection name one many socially important properties challenges machine ethics much like many challenges involved designing machines designing robot arm avoid crushing stray humans morally fraught designing sofa involves new programming challenges new ethical challenges algorithms take cognitive work social tasks previously performed algorithm inherits social requirements would surely frustrating find bank world approve seemingly excellent loan application nobody knows nobody find even principle maybe first name strongly associated deadbeats knows transparency desirable feature also important algorithms taking social functions predictable govern understand importance predictability consider analogy legal principle stare decisis binds judges follow past precedent whenever possible engineer ethics artificial intelligence preference precedent may seem bind future past technology always improving one important functions legal system predictable contracts written knowing executed job legal system necessarily optimize society provide predictable environment within citizens optimize lives also become increasingly important algorithms robust manipulation machine vision system scan airline luggage bombs must robust human adversaries deliberately searching exploitable flaws example shape placed next pistol one luggage would neutralize recognition robustness manipulation ordinary criterion information security nearly thecriterion criterion appears often machine learning journals currently interested algorithm scales larger parallel systems another important social criterion dealing organizations able find person responsible getting something done system fails assigned task takes blame programmers modern bureaucrats often take refuge established procedures distribute responsibility widely one person identified blame catastrophes result howard provably disinterested judgment expert system could turn even better refuge even system designed user override one must consider career incentive bureaucrat personally blamed override goes wrong would much prefer blame diﬃcult decision negative outcome responsibility transparency auditability incorruptibility predictability tendency make innocent victims scream helpless frustration criteria apply humans performing social functions criteria must considered algorithm intended replace human judgment social functions criteria may appear journal machine learning considering algorithm scales computers list criteria means exhaustive serves small sample increasingly computerized society thinking general intelligence nearly universal agreement among modern professionals artificial intelligence falls short human capabilities critical sense even though algorithms beaten humans many specific domains chess suggested soon researchers figure something nick bostrom eliezer yudkowsky capability ceases regarded considered epitome intelligence deep blue world championship even researchers agree something important missing modern ais hofstadter subfield artificial intelligence coalescing artificial general intelligence hereafter agi emerging term art used denote real see edited volume goertzel pennachin name implies emerging consensus missing characteristic generality current algorithms superior performance characterized deliberately programmed competence single restricted domain deep blue became world champion chess even play checkers let alone drive car make scientific discovery modern algorithms resemble biological life sole exception homo sapiens bee exhibits competence building hives beaver exhibits competence building dams bee build dams beaver learn build hive human watching learn unique ability among biological lifeforms debatable whether human intelligence truly general certainly better cognitive tasks others hirschfeld gelman human intelligence surely significantly generally applicablethan nonhominid intelligence relatively easy envisage sort safety issues may result operating within specific domain qualitatively diﬀerent class problem handle agi operating across many novel contexts predicted advance human engineers build nuclear reactor envision specific events could inside failing computers failing cores increasing engineer reactor render events noncatastrophic mundane level building toaster involves envisioning bread envisioning reaction bread toasters heating element toaster know purpose make purpose toaster represented within designer mind explicitly represented computations inside place cloth inside toaster may catch fire design executes unenvisioned context unenvisioned side eﬀect even algorithms throw outside domain locally preprogrammed specifically envisioned behavior consider deep blue chess algorithm beat garry kasparov world championship chess case machines exactly told programmers would manually preprogram database containing moves every possible chess position deep blue could encounter option deep blue programmers first space possible chess positions unmanageably large ethics artificial intelligence ond programmers manually input theyconsidered good move possible situation resulting system would able make stronger chess moves creators since programmers world champions system would able defeat garry kasparov creating superhuman chess player human programmers necessarily sacrificed ability predict deep blue local specific game behavior instead deep blue programmers justifiable confidence deep blue chess moves would satisfy criterion optimality namely moves would tend steer future game board outcomes winning region defined chess rules prediction distant consequences though proved accurate allow programmers envision localbehavior deep response specific attack deep blue computed nonlocal game map link move possible future consequences accurately programmers could yudkowsky modern humans literally millions things feed serve final consequence fed activities envisioned nature sense ancestral challenges directly adapted adapted brain grown powerful enough significantly generally applicable let foresee consequences millions diﬀerent actions across domains exert preferences final outcomes humans crossed space put footprints moon even though none ancestors encountered challenge analogous vacuum compared qualitatively diﬀerent problem design system operate safely across thousands contexts including contexts specifically envisioned either designers users including contexts human yet encountered may localspecification good simple specification behaviors exists compact local description ways humans obtain daily bread build acts safely acting many domains many consequences including problems engineers never explicitly envisioned one must specify good behavior terms consequence harmful involves extrapolating distant consequences actions thus eﬀective realized design system explicitly extrapolates consequences behavior toaster design property toaster foresee consequences toasting bread imagine engineer say well idea airplane built fly idea fly whether flap wings inflate helium something else even assure nick bostrom eliezer yudkowsky design may seem like unenviable position perspective public relations hard see guarantee ethical behavior would possible general intelligence operating unforeseen problems across domains preferences distant consequences inspecting cognitive design might verify mind indeed searching solutions would classify ethical predict specific solution mind would discover respecting verification requires way distinguish trustworthy assurances procedure say safe unless really safe pure hope magical thinking idea philosopher stone transmute lead gold assure one bear mind purely hopeful expectations previously problem research mcdermott verifiably constructing trustworthy agi require diﬀerent methods diﬀerent way thinking inspecting power plant software require agi thinks like human engineer concerned ethics simple product ethical engineering thus discipline ethics especially applied agi likely diﬀer fundamentally ethical discipline noncognitive technologies local specific behavior may predictable apart safety even programmers everything right safety system becomes greater challenge must verify system trying rather able verify system safe behavior operating contexts cognition must taken subject matter engineering moral status diﬀerent set ethical issues arises contemplate possibility future systems might candidates moral status dealings beings possessed moral status exclusively matter instrumental rationality also moral reasons treat certain ways refrain treating certain ways francis kamm proposed following definition moral status serve purposes xhas moral status xcounts morally right things paraphrased kamm chap ethics artificial intelligence rock moral status may crush pulverize subject treatment like without concern rock human person hand must treated means also end exactly means treat person end something diﬀerent ethical theories disagree certainly involves taking legitimate interests weight may also involve accepting strict moral dealings prohibition murdering stealing variety things property without consent moreover human person counts right sake impermissible things expressed concisely saying human person moral status questions moral status important areas practical ethics example disputes moral permissibility abortion often hinge disagreements moral status embryo controversies animal experimentation treatment animals food industry involve questions moral status diﬀerent species animal obligations towards human beings severe dementia alzheimer patients may also depend questions moral status widely agreed current systems moral status may change copy terminate delete use computer programs please least far programs concerned moral constraints subject dealings contemporary systems grounded responsibilities beings fellow humans duties systems fairly consensual systems lack moral status unclear exactly attributes ground moral status two criteria commonly proposed importantly linked moral status either separately combination sentience sapience personhood may characterized roughly follows sentience capacity phenomenal experience qualia capacity feel pain suﬀer sapience set capacities associated higher intelligence awareness agent one common view many animals qualia therefore moral status human beings sapience gives higher moral status view course must confront existence alternatively one might deny moral status comes degrees instead one might hold certain beings significant interests beings thus instance one could claim nick bostrom eliezer yudkowsky borderline cases one hand human infants human beings severe mental unfortunately referred marginal humans fail satisfy criteria sapience hand animals great apes might possess least elements sapience deny marginal humans full moral status others propose additional ways object could qualify bearer moral status member kind normally sentience sapience standing suitable relation independently moral status warren present purposes however focus criteria sentience sapience picture moral status suggests system moral status capacity qualia ability feel pain sentient system even lacks language higher cognitive faculties like stuﬀed toy animal doll like living animal wrong inflict pain mouse unless suﬃciently strong morally overriding reasons would hold sentient system addition sentience system also sapience kind similar normal human adult would full moral status equivalent human beings one ideas underlying moral assessment expressed stronger form principle principle substrate two beings functionality conscious experience diﬀer substrate implementation moral status one argue principle grounds rejecting would amount embracing position similar racism substrate lacks fundamental moral significance way reason skin color principle substrate nondiscrimination imply digital computer could conscious could functionality human substrate canof course morally relevant insofar makes diﬀerence sentience functionality holding things constant makes moral diﬀerence whether made silicon carbon whether brain uses neurotransmitters additional principle proposed fact systems product deliberate fundamentally relevant moral status could formulate follows better save human save bird human higher moral status human significant interest life saved bird life saved ethics artificial intelligence principle ontogeny two beings functionality consciousness experience diﬀer came existence moral status today idea widely accepted human circles particularly past idea one moral status depends one bloodline caste influential believe causal factors family planning assisted delivery vitro fertilization gamete selection deliberate enhancement maternal nutrition introduce element deliberate choice design creation human necessary implications moral status progeny even opposed human reproductive cloning moral religious reasons generally accept human clone brought term would moral status human infant principle ontogeny nondiscrimination extends reasoning case involving entirely artificial cognitive systems course possible circumstances creation aﬀect ensuing progeny way alter moral status example procedure performed conception gestation caused human fetus develop without brain fact ontogeny would relevant assessment moral status progeny anencephalic child however would moral status similar anencephalic child including one come entirely natural process diﬀerence moral status anencephalic child normal child grounded qualitative diﬀerence fact one mind since two children functionality conscious experience principle ontogeny apply although principle ontogeny asserts ontogeny essential bearing moral status deny facts ontogeny aﬀect duties particular moral agents toward question parents special duties child children would even another child qualitatively identical similarly principle ontogeny consistent claim creators owners system moral status may special duties artificial mind another artificial mind even minds question qualitatively similar moral status principles regard substrate ontogeny accepted many questions ought treat artificial minds answered applying moral principles use determine duties nick bostrom eliezer yudkowsky familiar contexts insofar moral duties stem moral status considerations ought treat artificial mind way ought treat qualitatively identical natural human mind similar situation simplifies problem developing ethics treatment artificial minds even accept stance however must confront number novel ethical questions aforementioned principles leave unanswered novel ethical questions arise artificial minds diﬀerent properties ordinary human animal minds must consider novel properties would aﬀect moral status artificial minds would mean respect moral status exotic minds exotic properties case human beings normally hesitate ascribe sentience conscious experience individual exhibits normal kinds human behavior believe people act perfectly normally lack consciousness however human beings merely behave ways similar also brains cognitive architectures constituted much like artificial intellect contrast might constituted quite diﬀerently human intellect yet still exhibit behavior possess behavioral dispositions normally indicative personhood might therefore possible conceive artificial intellect would sapient perhaps would person yet would sentient conscious experiences kind whether really possible depends answers metaphysical questions system possible would raise question whether person would moral status whatever whether would moral status sentient person since sentience least capacity sentience ordinarily assumed present individual person question received much attention question related problems philosophy mind received great deal attention particular zombie problem formulated follows metaphysically possible world identical actual world regard physical facts including exact physical microstructure brains organisms yet diﬀers actual world regard phenomenal subjective experiential facts put crudely metaphysically possible could individual physically exactly identical zombie lacking qualia phenomenal awareness chalmers familiar question diﬀers one referred text zombie allowed systematically diﬀerent physical properties normal humans moreover wish draw attention specifically ethical status sapient zombie ethics artificial intelligence another exotic property one certainly metaphysically physically possible artificial intelligence subjective rate time deviate drastically rate characteristic biological human brain concept subjective rate time best explained first introducing idea whole brain emulation uploading refers hypothetical future technology would enable human animal intellect transferred original implementation organic brain onto digital computer one scenario goes like first scan performed particular brain possibly destroying original process example brain might vitrified dissected thin slices scanned using form microscopy combined automated image recognition may imagine scan detailed enough capture neurons synaptic interconnections features functionally relevant original brain operation second map components brain interconnections combined library advanced neuroscientific theory specifies computational properties basic type element diﬀerent kinds neuron synaptic junction third computational structure associated algorithmic behavior components implemented powerful computer uploading process successful computer program replicate essential functional characteristics original brain resulting upload may inhabit simulated virtual reality alternatively could given control robotic body enabling interact directly external physical reality number questions arise context scenario plausible procedure one day become technologically feasible procedure worked produced computer program exhibiting roughly personality memories thinking patterns original brain would program sentient would upload person individual whose brain disassembled uploading process happens personal identity upload copied two similar qualitatively identical upload minds running parallel although questions relevant ethics machine intelligence let focus issue involving notion subjective rate time suppose upload could sentient run upload program faster computer cause upload connected input device video camera perceive external world slowed example upload running thousand times faster original brain external world appear upload slowed factor thousand somebody drops physical coﬀee mug upload observes mug slowly falling ground nick bostrom eliezer yudkowsky upload finishes reading morning newspaper sends emails one second objective time corresponds minutes subjective time objective subjective duration thus diverge subjective time subject estimate perception fast time flows human beings often mistaken flow time may believe one clock fact quarter past two stimulant drug might cause thoughts race making seem though subjective time lapsed actually case mundane cases involve distorted time perception rather shift rate subjective time even brain probably significant change speed basic neurological computations likely drug causing brain flicker rapidly one thought another making spend less subjective time thinking greater number distinct thoughts variability subjective rate time exotic property artificial minds raises novel ethical issues example cases duration experience ethically relevant duration measured objective subjective time upload committed crime sentenced four years prison four objective might correspond many millennia subjective four subjective years might couple days objective time fast human pain urgent alleviate pain grounds experiences greater subjective duration pain sidereal second palliation delayed since accustomed context biological humans subjective time significantly variable unsurprising kind question straightforwardly settled familiar ethical norms even norms extended artificial intellects means principles proposed previous section illustrate kind ethical claim might relevant formulate argue principle privileging subjective time normatively fundamental notion principle subjective rate time cases duration experience basic normative significance experience subjective duration counts far discussed two possibilities sapience variable subjective rate time exotic relatively profound sense metaphysically problematic well lacking clear instances parallels contemporary world properties possible artificial minds would exotic superficial sense diverging unproblematically quantitative dimension kinds mind familiar superficially exotic properties may also pose ethics artificial intelligence novel ethical level foundational moral philosophy level applied ethics ethical principles one important set exotic properties artificial intelligences relate reproduction number empirical conditions apply human reproduction need apply artificial intelligences example human children product recombination genetic material two parents parents limited ability influence character oﬀspring human embryo needs gestated womb nine months takes fifteen twenty years human child reach maturity human child inherit skills knowledge acquired parents human beings possess complex evolved set emotional adaptations related reproduction nurturing relationship none empirical conditions need pertain context reproducing machine intelligence therefore plausible many moral principles come accept norms governing human reproduction need rethought context reproduction illustrate moral norms need rethought context reproduction suﬃce consider one exotic property ais capacity rapid reproduction given access computer hardware could duplicate quickly time takes make copy software moreover since copy would identical original would born completely mature copy could begin making copies immediately absent hardware limitations population ais could therefore grow exponentially extremely rapid rate doubling time order minutes hours rather decades centuries current ethical norms reproduction include version principle reproductive freedom eﬀect individual couple decide whether children many children another norm least rich countries society must step provide basic needs children cases parents unable refusing easy see two norms could collide context entities capacity extremely rapid reproduction consider example population uploads one happens desire produce large clan possible given complete reproductive freedom upload may start copying quickly copies may run new computer hardware owned rented original may share computer also start copying since identical progenitor upload share philoprogenic desire soon members upload clan find unable pay electricity bill rent computational processing storage needed keep alive point nick bostrom eliezer yudkowsky social welfare system might kick provide least bare necessities sustaining life population grows faster economy resources run point uploads either die ability reproduce curtailed see bostrom two related dystopian scenarios scenario illustrates ethical principles suitable contemporary societies might need modified societies include persons exotic property able reproduce rapidly general point thinking applied ethics contexts diﬀerent familiar human condition must careful mistake ethical principles foundational normative truths put diﬀerently must recognize extent ordinary normative precepts implicitly conditioned obtaining various empirical conditions need adjust precepts accordingly applying hypothetical futuristic cases preconditions assumed obtain making controversial claim moral relativism merely highlighting commonsensical point context relevant application suggesting point especially pertinent one considering ethics minds exotic properties good set forth classic hypothesis concerning superintelligence suﬃciently intelligent understand design could redesign create successor system intelligent could redesign yet become even intelligent positive feedback cycle good called intelligence recursive scenarios limited humans intelligence augmented interface might turn minds designing next generation interfaces machine increased would bound occur became smart enough try design powerful version machine superintelligence may also achievable increasing processing speed fastest observed neurons fire times per second fastest axon fibers conduct signals speed light sandberg seems physically possible build brain computes million times fast human brain without shrinking size rewriting software human mind thus accelerated subjective year thinking would accomplished every physical seconds outside world millennium would fly eight half hours vinge referred minds weak superintelligence mind thinks like human much faster ethics artificial intelligence yudkowsky lists three families metaphors visualizing capability inspired diﬀerences individual intelligence humans ais patent new inventions publish groundbreaking research papers make money stock market lead political power blocks inspired knowledge diﬀerences past present human civilizations fast ais invent capabilities futurists commonly predict human civilizations century millennium future like molecular nanotechnology interstellar travel inspired diﬀerences brain architecture humans biological organisms vinge imagine running dog mind high speed would thousand years doggy living add human insight changes cognitive architecture might produce insights humanlevel mind would able find perhaps even represent amount time even restrict historical metaphors becomes clear superhuman intelligence presents ethical challenges quite literally unprecedented point stakes longer individual scale mortgage unjustly disapproved house catches fire mistreated global cosmic scale humanity extinguished replaced nothing would regard worthwhile superintelligence shaped beneficial depending technological capabilities might make short work many problems proven diﬃcult intelligence superintelligence one several existential risks defined bostrom risk adverse outcome would either annihilate intelligent life permanently drastically curtail conversely positive outcome superintelligence could preserve intelligent life fulfill potential important emphasize smarter minds pose great potential benefits well risks attempts reason global catastrophic risks may susceptible number cognitive biases yudkowsky including bias proposed bostrom suppose intuitions future scenarios plausible realistic shaped see movies read novels large part discourse future people encounter form fiction recreational contexts nick bostrom eliezer yudkowsky thinking critically suspect intuitions biased direction overestimating probability scenarios make good story since scenarios seem much familiar bias could quite powerful last time saw movie humankind suddenly going extinct without warning without replaced civilization scenario may much probable scenario human heroes successfully repel invasion monsters robot warriors much fun watch truly desirable outcomes make poor movies conflict means story asimov three laws robotics asimov sometimes cited model ethical development three laws much plot device asimov positronic asimov depicted three laws working well would stories would mistake regard ais species fixed characteristics ask good evil term artificial intelligence refers vast design space presumably much larger space human minds since humans share common brain architecture may form bias ask ais good evil trying pick premise movie plot reply exactly design talking control initial programming artificial intelligence translate influence later eﬀect world kurzweil holds ntelligence inherently impossible control despite human attempts taking precautions definition intelligent entities cleverness easily overcome let suppose clever part process improving intelligence unhindered access source code rewrite anything wants yet follow must want rewrite hostile form consider gandhi seems possessed sincere desire kill people gandhi would knowingly take pill caused want kill people gandhi knows wants kill people probably kill people current version gandhi want kill generally seems likely minds naturally stable utility functions implies initial choice mind design lasting eﬀects omohundro point development science way translate task finding design good ais modern research direction may seem premature speculate one suspect paradigms likely others eventually prove conducive creation intelligent selfmodifying agents whose goals remain predictable even multiple iterations ethics artificial intelligence improvement example bayesian branch inspired coherent mathematical systems probability theory expected utility maximization seems amenable predictable problem evolutionary programming genetic algorithms controversial statement illustrates point thinking challenge superintelligence road indeed turned directional advice present research yet even supposing specify goal system persistent begins touch core ethical problems creating superintelligence humans first general intelligences exist earth used intelligence substantially reshape mountains taming rivers building skyscrapers farming deserts producing unintended planetary climate changes powerful intelligence could correspondingly larger consequences consider historical metaphor similar diﬀerences past present civilizations present civilization separated ancient greece improved science increased technological capability diﬀerence ethical perspectives ancient greeks thought slavery acceptable think otherwise even nineteenth twentieth centuries substantial ethical women vote blacks vote seems likely people today seen ethically perfect future failure solve currently recognized ethical problems poverty inequality also failure even recognize certain ethical problems perhaps someday act subjecting children involuntarily schooling seen child maybe allowing children leave school age seen child abuse know considering ethical history human civilizations centuries time see might prove great tragedy create mind stable ethical dimensions along human civilizations seem exhibit directional change archimedes syracuse able create artificial intellect fixed version moral code ancient greece avoid sort ethical stagnation likely prove tricky would suﬃce example simply render mind randomly unstable ancient greeks even realized imperfection could done better rolling dice occasionally good new idea ethics comes along comes surprise randomly generated ethical changes would strike folly gibberish presents perhaps ultimate challenge machine ethics build executes becomes ethical like asking philosophers produce superethics deep blue nick bostrom eliezer yudkowsky constructed getting best human chess players program good moves able eﬀectively describe question dice generate good chess moves good ethics either perhaps productive way think problem strategy would want archimedes follow building superintelligence overall outcome would still acceptable tell specifically wrong much situation relative future one strong piece advice emerges considering situation analogous archimedes try invent super version civilization considers strategy would wanted archimedes follow perhaps question considering rather programmed archimedes moral expertise archimedes could recognize least civilization ethics moral progress opposed mere moral instability would require begin comprehend structure ethical questions way already comprehended structure chess serious developing advanced challenge must meet machines placed position stronger faster trusted smarter humans discipline machine ethics must commit seeking niceness although current oﬀers ethical issues already present design cars power plants approach algorithms toward humanlike thought portends predictable complications social roles may filled algorithms implying new design requirements like transparency predictability suﬃciently general algorithms may longer execute predictable contexts requiring new kinds safety assurance engineering artificial ethical considerations ais suﬃciently advanced mental states right kind states moral status may count perhaps persons much unlike sort exist perhaps governed diﬀerent rules finally prospect ais superhuman intelligence superhuman abilities presents extraordinary challenge stating algorithm outputs superethical behavior challenges may seem visionary seems predictable encounter devoid suggestions research directions ethics artificial intelligence biographies nick bostrom professor faculty philosophy oxford university director future humanity institute within oxford martin school author publications including anthropic bias routledge global catastrophic risks oup enhancing humans oup research covers range big picture questions humanity currently working book future machine intelligence strategic implications eliezer yudkowsky research fellow singularity institute artificial intelligence works foreseeable design issues goal architectures current work centers modifying classical decision theory coherently describe also known popular writing issues human rationality cognitive biases readings future human evolution bostrom paper explores evolutionary dynamics could lead population diverse uploads develop dystopian directions artificial intelligence positive negative factor global risk yudkowsky introduction risks challenges presented possibility recursively superintelligent machines moral machines wallach allen comprehensive survey recent developments nick bostrom eliezer yudkowsky acknowledgments authors grateful rebecca roache research assistance editors volume detailed comments earlier version manuscript references asimov isaac astounding march bostrom nick existential risks analyzing human extinction scenarios related journal evolution technology future human two hundred years kant fifty years turing edited charles tandy vol death palo alto ria university press bostrom nick milan ćirković eds global catastrophic risks new york oxford university press chalmers david john conscious mind search fundamental theory philosophy mind series new york oxford university press goertzel ben cassio pennachin eds artificial general intelligence cognitive technologies berlin springer doi good irving john speculations concerning first ultraintelligent advances computers edited franz alt morris rubinoﬀ vol new york academic press hastie trevor robert tibshirani jerome friedman elements statistical learning data mining inference prediction springer series statistics new york springer hirschfeld lawrence susan gelman eds mapping mind domain specificity cognition culture new york cambridge university press hofstadter douglas trying muse rationally singularity talk given singularity summit stanford may howard philip death common sense law suﬀocating america new york random house kamm frances intricate ethics rights responsibilities permissible harm oxford ethics series new york oxford university press doi kurzweil ray singularity near humans transcend biology new york viking mcdermott drew artificial intelligence meets natural sigart newsletter omohundro stephen basic artificial general intelligence proceedings first agi conference edited pei wang ben goertzel stan franklin frontiers artificial intelligence applications amsterdam ios ethics artificial intelligence sandberg anders physics information processing superobjects daily life among jupiter journal evolution technology vinge vernor coming technological singularity survive interdisciplinary science engineering era cyberspace nasa conference publication nasa lewis research center wallach wendell colin allen moral machines teaching robots right wrong new york oxford university press doi warren mary anne moral status obligations persons living things issues biomedical ethics new york oxford university press doi yudkowsky eliezer precise paper presented agi workshop bethesda may artificial intelligence positive negative factor global bostrom ćirković cognitive biases potentially aﬀecting judgment global bostrom ćirković
