joint insurance industry point view paper need rules road responsible data science jim demarco senior industry digital strategist microsoft gregory falco assistant research professor johns hopkins university jerry gupta senior vice president swiss jonathan silverman industry executive microsoft table contents opportunities risks artificial intelligence size scope available data problems discrimination three main contributors artificial intelligence data decision algorithm data scientist need rules road responsible application rules road guiding data ethical sourcing open data guiding algorithm responsible guiding designer neat framework data science practitioners calling code conduct data science opportunities risks artificial intelligence every major technological commercial disruption human history relied form insurance help people safely adopt change creation hybrid technologies use artificial intelligence guide even make decisions insurance industry blaze trail trustworthy innovation white paper explores need responsible well new risks poses investigates role data scientist creates decision insight world influenced paper argue data scientists play outsized role decision making therefore governed code conduct regarding create decision insight paper also touches insurance industry leader driving adoption new technology responsibility lead crafting code conduct starting data scientists use challenges apply insurers also apply corporate customers use insurers consume data industries implies need insurers mitigate risks inappropriate use data insurance also responsibility set standards applied within beyond insurance industry accordingly propose set core principles guidelines would make code proverbial rules road responsible applied insurers customers intend paper drive conversation around ethics data science brings insurance industry partners social policy well businesses insure common point view use job data decision scientists end much welcome feedback paper wish spark broader conversation across data science community see conclusion contact fourth industrial revolution underway marked massive social upheaval economic disruptio digital transfor mation like previous industrial revolutions seemingly unlimited opportunity perhaps eatest driver change age artificial intelligence showing great promise society embedded used speed disease diagnoses accelerate time market new vaccines communications enable people talk nativ tongue despite knowing language optimized traffic routing reduces carbon footprint shipping goods continents digital transformation fueled acceleration adoption helps businesses competitive also given rise ethical privacy risk bots driving divisive social media attacks automated identity theft host challenges previously unheard erhaps ominously poses new challenge one cor area technology yet touched human decision making fourth industrial revolution differs three previous ones first time rely technology make decisions done right enhance human judgment identif ying removing known mistakes done wrong make exacerbate mistakes guide humans make decisions int egregious even evil behavio practitioners call data scientists hav burden defining new technology manner consistent global moral norms data scientists applications build must guided set ethical principles core fairly simple uses machines mimic human behaviors make decisions interact based massive amounts data one person could remember comprehend application three main contributors decision algorithm data goes algorithm algorithm author data scientist get better decisions requires increasing amounts data role data scientist select data apply rules define algorithm data scientist success extension algorithm success relies proper application rules data eates conundrum data scientist get good data rules data scientist apply create right algorithm size scope available data drive accuracy typically requires increasing amounts data validate correct algorithmic output specific data accurate result usually quality accuracy completeness data impact effectiveness algorithm determining scope data accurately represent specific populations would affected algorithm incomplete inaccurate biased data result adverse skewed results personal data requires compliance applicable privacy laws regulations need voluminous data runs counter legal privacy requirements data minimization potentially challenges human right privacy scope data availability may limited due legal requirement individuals explicit consent processing personal data individuals control use personal data decisions made using additionally privacy laws require adequate data protection controls place processing sensitive personal data reduce risk discrimination includes data revealing racial ethnic origin religious beliefs gender personal attribute could contribute discrimination individual use data necessitates need ethics accountability compliance legal requirements considering size scope data problems discrimination insurance companies using improve ability pool mitigate risk expand coverage individuals may insurance may underinsured however concerns increased use may exclude discriminate specific groups inequitably marginalized vulnerable groups may susceptible discrimination due biases embedded data attributes income race gender discrimination also occurs proxy used strongly correlated data attributes example using employment history access credit may tied race gender discrimination devastating consequences imposing financial disadvantages families qualify affordable financial products improperly defining risks leading forcing inappropriate unsuitable products customers perpetuating systemic poverty within community precluding financial support freedom discrimination could caused bias built various stages occur due misinterpreted data bad data errors machine learning false assumptions false conclusions discrimination challenging prevent found easily identified output examples bias result discrimination data collection data accurately represent specific populations would affected algorithm output machine learning good data used training bad data incomplete inaccurate biased data result discriminatory output example car insurance company using driving records determine premiums could using biased data based tickets disproportionately issued based race discrimination occur even good accurate unbiased data proxy used correlated protected attribute race gender causing indirect discrimination algorithms discrimination built algorithm algorithm used one circumstance may cause discrimination used another similar circumstance desired output algorithm maximize profits gain efficiency may little focus fairness also weight may placed data attributes could inadvertently cause bias algorithm example putting weight zip code property insurance may adversely impact communities model training relies learning human behaviors practices mimic human decision making human behaviors free bias errors bias taught machine learning process based mimicking discriminating biased human behaviors example company hiring model based historical hiring decisions determined discriminating women based learned human hiring decisions malicious intent moral problems related data use may intentionally build bias algorithm derive desired output example companies redlining specific communities lower property values make difficult individuals community get loans purchase homes establish businesses massive amount data processed even minor error causing discrimination potentially detrimental consequences avoid discrimination prioritize fairness transparency every stage involved must develop ways predict prevent monitor bias additionally input diverse group brings different perspectives viewpoints managing bias algorithms scrutinized diverse teams different functions using multiple tests validate algorithm output line expectations business regulators discrimination bias exist stage important raise awareness provide training three main contributors artificial intelligence core emulates decision making humans naturally emulate decision making uses two key inputs algorithm establishes rules machines use decision data guides algorithm applied beneath two inputs choices made data scientist algorithm formed data used input algorithm interprets data thus three major contributors real life data algorithm data scientist crafts orchestrates consider contributors turn data works translating information data patterns guide decisions data processed algorithm often requires cleansing algorithm may able interpret data purest raw form data collected sensors needs cleansed may wide degree variation caused anything human error faulty device data cleansing generally involves selecting boundaries outliers need omitted trends easily interpretable refining sample sets target particular decision parameters data subject lifecycle processes two individuals raw dataset algorithm could arrive different results due cleansing decisions therefore transparency done data ever meets algorithm critical ethical application decision algorithm algorithms generally built set steps interpret patterns data make inferences value different decision options inferences earliest algorithms generally driven simple traceable rules engines time underlying technology computational capacity progressed power ability algorithms grown tremendously yielding far predictive insight representative data time complexity algorithms increased often reaching beyond ability draw simple references back given decision made data input time especially algorithm deployed context refinement algorithm inferences yield unexpected untraceable conclusion instead inferences second time inferences good bad application decision making yield morally indefensible actions wrong circumstances algorithms quickly moving domain decision support tools social constructs similar concept property ownership creation legal entities like social construct data algorithms require social contract supported regulations bogost warns impending computational theocracy evidenced centrelink scandal incorrect debt notices sent based opaque algorithms algorithms create false perception unbiased decision making turn risks creating vicious cycle processes flag disadvantaged reinforce algorithms new flag thereby creating permanent class economically poor permanently eroding social mobility algorithms created equal use cases different types algorithms requirements algorithms vary drastically two questions critical future ethics considerations whether right type algorithm selected problem hand algorithm curated time use data scientist data science merging blending many quantitative fields computer science actuarial science financial mathematics statistics operations research econometrics core theoretical fields individual best practices algorithms choice blending brought rush new approaches forefront emergence data science mixed advancement graphics processing unit gpu made possible run mathematical algorithms individual data scientists deal increasingly complex opaque algorithms advanced approaches quantitative science work ian bogost cathedral computation atlantic january hard explain data scientists must develop tools make sure work clearly yields result unfairly impact people affected work use manage tools influence even make decisions province human decision makers data scientists bear burden ensuring work properly informed norms would otherwise apply decision makers insurance example primary decision maker around risk actuary work data scientist support actuarial decision making therefore must subject norms governing actuaries actuaries code conduct actuaries must make decisions could particularly negative effects made incorrectly job stewards financial insurance customers also insurance agencies often balancing conflicting interests actuaries tasked properly assessing risk provide financial stability gained insurance many people possible also keeping insurance companies solvent actuary decision provide insurance provide overly expensive insurance plays significant role individual ability maintain financial safety net imperative decisions made using appropriate methodology risk accurate unfairly discriminatory weight decisions requires thoughtfulness imbued within actuarial code conduct actuaries must adhere emerging responsibility data scientist actuaries already familiar great responsibility bear data scientists see increasing influence actuarial decision making imperative share responsibility influence data scientists need extend professional responsibilities beyond merely creating algorithms accurate results ensure safe valuable ones well expanded responsibilities include multiple facets build ing ensuring valuable insights gained data lead actionable decisions performance metric always responsibility sour cing ensuring data ethically sourced bias incompleteness data isunderstood accounted modeling chitecting ensuring algorithm chosen including judicious selection metrics foroptimization provides valuable insights arerelated problem architecting includesunderstanding limitations algorithm behavior cases extrapolation business translation explaining providing knowledge transfer end users group whosedecisions automated whose decisionsare based insights generated algorithm usersneed understand limits algorithm confidence levels generates use use code professional conduct american academy actuaries need rules road adverse consequences biased algorithms legal medical malpractice consumer finance insurance decisions increasingly driven ability buy house car toyour credit limit controlled consumergets caught trap become difficult toget digital offerings heavily influenced personalization techniques play big role limiting consumer choice policing discriminatory policymaking result fundingand policy decisions made result bad dataor biased algorithms trained data favorshomogeneity public health biased algorithms could lead real possibility rationing care across public basedon inappropriate characteristics yielding healthcareallocation discriminatory ineffective excessive trust machine results air authenticity lent decision numbers lie computational models result overreliance outputs algorithms data scientists rely computational modelof design measure analyze dma perception scientific methodology toroot mistakes however variable means bywhich dma applied make art science ensuring proper outputs result dma created social construct protects perceived integrity outputs even data feeds riddled existing biases exclusions noise algorithmic outputstrays social norms risk adverse consequences legal medical profession data scientists need sustainable governing road responsible application rules road requires rules guide machines process two primary applications computational use machines process information make decisions cognitive use machines emulate human actions generate information decision making guiding data ethical sourcing open data whether computational cognitive applied built grows ingestion data applied insurance data drives analytic actuarial underwriting decisions insurer evaluates applicant comparing existing data set determine risk data used comparison purposes needs sourced manner appropriate materials unbiased mortgage underwriting classic example problems biased data uses historical mortgage data based decades redlining aimed preventing black loan applicants people color buying homes white neighborhoods using biased data perpetuates effects racism goal ethical sourcing unbiased data lead equitable decision making initiatives like open data initiative founded developed jointly sap adobe microsoft aim combine ethically sourced unbiased data together transparently single data lake used derive insights guiding algorithm esponsible two main cognitiv machine gather data inputs process according algorithm provide outputs cognitive outputs frequently used inputs computational engine makes different computing algorithms outputs algorithm computation reused inputs order provide infer ences guide algorithm make future decisions therefore initial algorithm machine learning model must built way accurat degree gat also adaptable remain useful changes accor ding learning inferences ords usable algorithm must ovide trustworthy initial application also time future computed arti icial intelligence role microsoft proposed designing remains trustworthy time requires creating solutions ased ethical principles deeply rooted important timeless values microsoft identified six core principles guide responsible algorithmic development fairness reliability safety privacy security inclusiveness transparency accountability microsoft identified six core principles guide ethical algorithmic development fairness reliability safetyprivacy security inclusiveness transparency accountability note trustworthy necessarily mean predictable algorithms provide random results given decision design order provide accurate result aggregated set decisions algorithms output results one computation next expected vary machine gains inferences detailed description downloadable copy book see algorithms building trustworthy algorithm requires addressing ethical principles step algorithmic lifecycle initial envisioning algorithmic definitions prototyping initial launch application assessment evolution six ethical principles must adhered every stage life algorithm yielding responsible lifecycle rail fairness systems treat people fairly applying biases indeed properly deployed detect eliminate bias decision algorithms safety reliability safety reliability must considered circumstances also unexpected conditions including systems attack systems must tested extensively updated based human user feedback monitored ongoing performance inclusiveness everyone benefit intelligent technology like fairness systems empower everyone engage people regardless age gender race capabilities tenet fundamental sustainable system privacy security driven data must secured external influence tampering data privacy security must mere regulatory compliance considerations need incorporated aspects insurance lifecycle privacy security must treated core customer rights insurance technology industry provide solutions people trust transparency systems used help inform decisions tremendous impact people lives critical people understand decisions made transparency understanding steps taken final reason behind machine decides part transparency means build use systems forthcoming choose build deploy systems well systems functionality transparency also means people able understand monitor technical behavior systems accountability people design deploy systems must responsible accountable systems operate accountability helps ensure systems final authority decision impacts people lives humans maintain meaningful control otherwise highly autonomous systems especially systems make consequential decisions ensure people remain ultimately accountable systems operation manage systems daily basis trained understand design limitations system authority remediate necessary organizations also consider establishing dedicated internal review body guide practices regarding development deployment systems governance six principles determine whether particular algorithm deemed ethical next present framework ensure principles properly applied creating actionable framework requires implementing smaller set practical guidelines determining whether given system meets standard laid principles framework derives test applying principles cases repeating core principles combining principles make application readily understood guiding designer framework data science practitioners powerful benefit mankind one aware flaws impact ther intrinsic lack explainability sophisticated algorithms result inaccurate biased outputs would difficult identify cure one larger risks societal systems making decisions space financial services medicine university admissions human resources example potential bias based race gender age ethnicity high mechanisms prevent bias strong case autonomous systems would difficult assess liability assessment especially problematic given movement make systems legal malignant act ors governments face temptation use systems ways infringe people privacy personal gain control ftware bugs however systems may difficult detect fix trust neutral unbiasedexplainable human understanding algorithm mechanicsaccountable clear line liability audit trailtrustable transparent principles values including data virtuosity standardized regulations address issues propose neat framework algorithm development believe algorithms neutral algorithms neutral unintentional bias certain functions credit card approval inherent accepted bias based income however biases stated upfront developing algorithms furthermore tests conducted ensure social bias present algorithms explainable propose algorithms rated based risk society algorithm impact must explainable instance image recognition algorithm may require much explainability algorithm making mortgage underwriting decisions accountable talk making algorithms legal persons purposes law strongly advocate clear line liability associated algorithm doctor making error liable data scientist making error algorithms impact liable important natural person responsible ensure accountability recourse versioning commenting standards developed along best practices logging ensure foolproof audit trail exists trustable developer approver algorithm clearly disclose purpose principles values adhered developing algorithm ensures people involved building algorithm purposeful actions take mindful impact consequences jerry gupta calling code conduct data science ethics continues emerge cornerstone trustworthy artificial intelligence need meeting minds concerning responsible creation use algorithms consensus could materialize code data science conduct code building code code ethics code data science conduct largely reported first code serve baseline set guidelines helps aid decision making artificial intelligence algorithms developed tool pointed case audit even purposes explaining boundaries algorithm functionality codes evolve time developed vacuum collective process filled heated debate ultimately beneficial exercise developing code data science conduct must arbitrator shepherds discussion arbitrator impartial necessarily benefit shape final motivation benefit tied fact code data science conduct ultimately developed insurance industry uniquely positioned sufficiently motivated equally impartial believe insurance front advocating data science ethics best candidate task insurance one heaviest users data complex algorithms insurance uses data many industries global marketplace built analyzing large amounts data disparate sources identify measure risk make decisions volume data collected analyzed gives insurance great deal experience insight data use increased incentive establishing standards ensure used responsibly insurance best assessor risk insurance built assessing risk using analytics gives authority expertise identify risks using problematic data algorithms insurance ability enforce adoption withholding business owner insurance directors officers insurance companies follow code conduct insurance providers encourage faster wider adoption creating financial incentive leaders would exposed personal liability without insurance policies place would reason push organizations change believe type enforcement would effective government mandates rules road apply every industry uses insurance uniquely suited understand drive guide change insurance mechanism interest governing responsible application accordingly following traditional role innovation insurance needs take lead welcome participants conversation important topic questions comments feedback paper would like join advocating formulating set guidelines responsible please contact insaiethics
