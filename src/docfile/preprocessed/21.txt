human rights age artificial intelligence report product access thank lead author lindsey andersen significant contributions questions report would like information contact info human rights age artificial intelligencecontents executive summary bias play makes risks different helpful harmful helpful harmful human rights human rights matter impacts human rights robotics vii recommendations address role comprehensive data protection laws recommendations government private sector need research ture uses rebuttal transparency explainability kill innovation viii conclusion human rights age artificial intelligencehuman rights age artificial intelligence executive summary artificial intelligence continues find way daily lives propensity interfere human rights gets severe mind noting technology still infant stages access conducts preliminary study scope potential range human rights issues may raised today near future many issues arise examinations area new greatly exacerbated scale proliferation impact artificial intelligence facilitates potential artificial intelligence help harm people much greater technologies came already seen consequences impacts continue grow severity scope however starting examine safeguards structures necessary address problems abuses worst disproportionately impact marginalized prevented mitigated several lenses experts examine artificial intelligence use international human rights law standards institutions examine artificial intelligence systems contribute conversations already happening provide universal vocabulary forums established address power differentials additionally human rights laws contribute framework solutions provide form recommendations recommendations fall within four general categories data protection rules protect rights data sets used develop feed artificial intelligence systems special safeguards government uses artificial intelligence safeguards private sector uses artificial intelligence systems investment research continue examine future artificial intelligence potential interferences human rights hope report provides jumping point conversations research developing space yet know artificial intelligence mean future society act build tools need protect people dangerous applications look forward continuing explore issues raised report including work partners well key corporate government institutions human rights age artificial intelligenceii introduction concept artificial intelligence elevated realm science fiction discussions highest circles academia industry government however experts begun look impact artificial intelligence human rights far even seem agree term means evident use artificial intelligence machine learning technology potential effect revolutionary changes world key topic rightscon access annual conference intersection human rights technology leading rightscon worked close partners draft publish toronto declaration protecting rights equality machine learning also participated workshop artificial intelligence human rights hosted data society research institute new york goal consider value human rights space foster engagement collaboration across sectors develop ideas outcomes benefit stakeholders working issue moving report preliminary scoping intersection artificial intelligence human rights first section proposes definitions key terms concepts including artificial intelligence machine next look different artificial intelligence systems used world today ways help harm society turning human rights look role human rights law play development artificial intelligence including interplay fundamental rights ethics looking widely adopted human rights instruments highlight ways current foreseeable uses artificial intelligence interfere broad range human rights finally offer list recommendations stakeholders protect rights recognize offering recommendations early stages development use artificial intelligence beginning grapple potential consequences one recommendations direct additional funding resources investigate issues raised report determine safeguards structures preventing mitigating future human rights abuses human rights age artificial intelligenceiii definitions artificial intelligence definition artificial intelligence marvin minsky one founding scholars defines science making machines things would require intelligence done another founding scholar john mccarthy defines science engineering making intelligent recent stanford university report defines science set computational technologies inspired typically operate quite differently ways people use nervous systems bodies sense learn reason take stuart russell peter norving authors popular textbook suggest broken following categories systems think like humans systems act like humans systems think rationally systems act reality considered field easily definable thing broken many subfields machine learning robotics neural networks vision natural language processing speech processing significant crossover among also draws fields computer science including psychology neuroscience cognitive science philosophy linguistics proba bility logic narrow currently application artificial intelligence uses image recognition language translation autonomous vehicles machines currently perform accurately humans types tasks future researchers hope achieve artificial general intelligence agi would involve systems exhibit intelligent behavior across range cognitive tasks however researchers estimate capabilities achieved least big data datasets large complex traditional data processing software analyze increasing availability big data thanks society internet use coupled rapid improvements computing power enabled significant advances past years data mining process discovering patterns extracting information large datasets era big data data mining often facilitated machine learning machine learning machine learning harry surden defines machine learning computer algorithms ability learn improve performance time essentially machine learns data time learning statistical process starts body data tries derive rule procedure explains data predict future resulting output called model different traditional approach artificial intelligence involved programmer trying translate way humans make decisions software code vast majority artificial intelligence world today powered machine learning currently many systems far accurate humans variety tasks driving diagnosing certain report comest robotics ethics mccarthy john basic questions accessed june accessed june qtd committee technology national science technology council preparing future artificial intelligence executive office president united states october preparing future artificial intelligence surden harry machine learning law accessed june preparing future artificial intelligence visual explanation machine learning works see human rights age artificial intelligencemachine learning works like programmers begin historical data set divided training set test set choose model mathematical structure characterizes range possible decisionmaking rules model includes adjustable parameters model like box parameters adjustable knobs box define objective function used evaluate desirability outcome train model process adjusting parameters maximize objective function trained use test dataset evaluate accuracy effectiveness model ideally model perform similarly test data goal able generalize model accurate response cases never seen deep learning machine learning technique uses structures called neural networks inspired human brain consist set layered units modeled neurons layer units processes set input values produces output values passed onto next layer units neural networks often consist layers large number units layer enable recognition extremely complex precise patterns data explore consider image recognition software utilizes neural networks identify picture elephant first layer units might look raw image data basic patterns perhaps thing appears four legs next layer would look patterns within patterns perhaps animal maybe next layer identifies trunk process would continue throughout many layers recognizing increasingly precise patterns image network able identify indeed picture elephant preparing future artificial intelligence elabel hidden yersoutput elephant inpu fig neural networks structure human rights age artificial intelligenceprogress deep learning cause much optimism due ability process find patterns massive amounts data whereas early typically uses decisiontree structure deep learning become dominant technique often used power specific approaches machine vision natural language machine vision specific approach allows computers recognize evaluate used google help search images facebook automatically tag people photos natural language processing specific approach helps computers understand interpret manipulate human language breaking language shorter pieces discovering pieces fit together create meaning natural language processing enables commonly used services google translate speech recognition specific approach allows computers translate spoken language allows use smartphone often paired together natural language processing used power virtual assistants like siri alexa algorithm simple algorithm set guidelines describe perform within computer science algorithm sequence instructions tell computer works algorithms neural networks type algorithm algorithms involve artificial intelligence preparing future artificial intelligence virtual assistants siri cortana alexa use neural networks speech recognition imitate human conversation deep learning case allows virtual assistants detect understand nuances speech produce response feels conversational see information ibm watson uses deep learning techniques machine vision analyze quickly accurately interpret medical information help doctors diagnose disease see information machine vision system mvs definition techopedia accessed may natural language processing accessed may speech recognition wikipedia may algorithm accessed may relationships concepts artificial intelligence human rights age artificial algorithmic using outputs produced algorithms make decisions one earliest forms algorithmic still use today united states federal sentencing guidelines judges involves nothing weighted mathematical equation drawn statistics recommends sentence length based attributes robot robots often use many forms artificial intelligence described however definition robots physical body mobility robots use able perceive changes environment function although robots typically come mind thinking artificial intelligence currently constitute small amount interactions field robotics growing area research development yet made nearly many advancements become ubiquitous forms machine bots software applications run automated tasks bots increasingly powered particularly chatbots use natural language processing conduct conversations users open data data freely available everyone view use share without restrictions broad open data movement advocates data generally treated context many advocates suggest training data systems open order surface bias errors well shed light outputs systems produce controversy best method respecting privacy interests data subjects protected information information includes reflects arises person communications readily available easily accessible general public long agreed communications content deserves significant protection law capability reveal sensitive information clear information arising metadata forms reveal even individual content thus deserves equivalent protection today types information might taken alone analyzed collectively reveal person identity behavior associations physical medical conditions race color sexual orientation national origins viewpoints enable mapping person location movements interactions time people given location including around public demonstration political event bias societal statistical definitions bias come play societal definition bias inclination prejudice person group especially way considered statistical definition bias difference true value words difference system predicts actually many cases statistical bias present given system results outcomes societally biased see information report comest robotics ethics raghav bharadwaj artificial intelligence home robots current future techemergence february see info open data movement international principles application human rights communications surveillance accessed june available deeper discussion statistical bias fairness issues see talk princeton computer scientist arving narayanan human rights age artificial intelligencehow bias play biased system data input level bias system level involves developers building personal biases parameters consider labels define although rarely occurs intentionally unintentional bias system level common often occurs two ways developers allow systems conflate correlation causation take credit scores example people low income tend lower credit scores variety reasons system used build credit scores includes credit scores facebook friends parameter result lower scores among backgrounds even otherwise strong financial indicators simply credit scores friends developers choose include parameters proxies known bias example although developers algorithm may intentionally seek avoid racial bias including race parameter algorithm still racially biased results includes common proxies race like income education postal bias data input level occurs number use historical data biased systems use existing body data identify patterns bias data naturally reproduced example system used recommend admissions top university uses data previously admitted students train model likely recommend upper class males women traditionally underrepresented groups input data representative target population called selection bias results recommendations favor certain groups another example app used input data smartphone users estimate travel times distances could accurate wealthier areas cities higher concentration smartphone users less accurate poorer areas informal settlements smartphone penetration lower sometimes official mapping input data poorly selected gps mapping app example could involve including information related cars public transportation schedules bike paths resulting system favored cars useless buses biking data incomplete incorrect outdated insufficient data make certain conclusions data date results naturally inaccurate machine learning model continually updated new data reflects current reality naturally become less accurate time unfortunately biased data biased parameters rule rather exception data produced humans information carries natural human bias within researchers begun trying figure best deal mitigate bias including whether possible teach systems learn without bias however research still nascent stages time cure bias systems weapons math destruction big data increases inequality threatens democracy cathy neil books accessed may executive office president united states big data report algorithmic systems opportunity civil rights may broadly known fatml community fairness accountability transparency machine see info human rights age artificial intelligenceiv makes risks different many problems risks explored report new different technologies come due ways evolved existing technologies including terms sophistication scale may exacerbate existing questions introduce new problems consider huge impacts accountability reliability illustrate consider two recent tech trends big data rise algorithmic today algorithmic largely digital many cases employs statistical methods similar used create sentencing algorithm discussed algorithms unchanging based statistical modeling algorithms suffer problems traditional statistics poorly sampled data biased data measurement errors recommendations make traced use algorithmic introduced new set challenges machine learning algorithms use statistics also problems biased data measurement error deterministic predecessors however systems differ key ways first whereas traditional statistical modeling creating simple model form equation machine learning much captures multitude patterns expressed single equation second unlike deterministic algorithms machine learning algorithms calibrate identify many patterns complex humans understand thus possible trace decisions recommendations addition many machine learning algorithms constantly feedback example spam filters continually learn improve spam detection capabilities users mark email spam another issue impact error rates statistical basis systems error rates even though many cases systems far accurate human beings danger assuming simply system predictions accurate human outcome necessarily better even error rate close zero tool millions users thousands could affected error rates consider example google photos google photos image recognition software found terribly prejudicial offensive error occasionally labeling photos black people gorillas system used complex model engineers unable figure happening solution could work racist merely removed words list image tags imagine similar software system used customs border patrol photographs every person enters exits database photos known suspected criminals terrorists estimated million people arrived united even facial recognition system accurate error rate would result people misidentified many people would falsely identified wanted criminals detained would impact lives conversely many known criminals would get away even relatively narrow error rates cases severe consequences difference machine learning statistical modeling accessed may comes gorillas google photos remains blind wired accessed may human rights age artificial intelligencethe bottom line scale proliferation impact demands attention proliferation data analytics come rise big data book weapons math destruction data scientist cathy neil documented algorithmic ubiquitous west assigning credit scores identifying best candidates job position ranking students college algorithmic systems increasingly employing machine learning spreading rapidly many problems traditional statistical analysis however scale reach systems trend rapid careless deployment immediate impact many people lives danger societies viewing outputs impartial pose series new problems helpful harmful every major technological innovation brings potential advance damage society data processing analysis capabilities help alleviate world pressing problems enabling advancements diagnosis treatment disease revolutionizing transportation urban living mitigating effects climate change yet capabilities also enable surveillance scale never seen identify discriminate vulnerable may revolutionize economy quickly job retraining program possibly keep despite major strides development artificial intelligence revolution decade old meaning many unknown possibilities come identify ways used help harm societies important note even helpful uses potentially negative implications example many applications healthcare pose serious threats privacy risk discriminating underserved communities concentrating data ownership within large companies time use mitigate harm may solve underlying problems treated cure societal ailments example may alleviate need medical professionals underserved areas providing resources incentives professionals would need relocate similarly use cases categorized harmful came result good intentions yet causing significant harm helpful improving access healthcare predicting disease outbreaks already significant advancements use disease diagnosis prevention also used improve access healthcare regions lack victims disease outbreaks also benefit use enable health officials intervene early contain outbreak making life easier visually impaired tools image recognition helping people visually impaired better navigate internet real optimizing agriculture helping farmers adapt change combining information global ibm watson used hospitals around world help doctors diagnose treat disease see information another example aajoh nigerian developing system remote medical diagnosis users share symptoms via text audio photographs aajoh uses provide possible diagnoses see stephen timm artificial intelligence startups africa look venture burn april examples see facebook efforst help blind see facebook using artificial intelligence help blind people see facebook facebook newsroom april see also microsoft work seeing app visually impaired people narrates world around microsoft human rights age artificial intelligencesatellite imagery weather agronomic data help farmers improve crop yields diagnose treat crop disease adapt changing environments approach farming known precision agriculture help increase farm productivity feed world growing population mitigating climate change predicting natural disasters conserving wildlife effects climate change appearing around world machine learning used make accurate climate models scientists already used rank climate models predict extreme weather well better predict extreme weather events respond natural also helpful identifying apprehending poachers locating capturing animals making government services efficient accessible despite often slow adopt new technologies governments around world using local national levels make public services efficient accessible emphasis developing smart also used allocate government resources optimize harmful perpetuating bias criminal justice many documented cases gone wrong criminal justice system use context often occurs two different areas risk whether defendant likely reoffend order recommend sentencing set predictive policing using insights various data points predict crime occur direct law enforcement action many cases efforts likely use machine learning risk scoring defendants advertised removing known human bias judges sentencing bail predictive policing efforts seek best allocate police resources prevent crime though always high risk mission however recommendations systems often exacerbate bias trying mitigate either directly incorporating factors proxies bias facilitating mass surveillance given provides capacity process analyze multiple data streams real time surprise already used enable mass surveillance around pervasive dangerous example use facial recognition although technology still imperfect governments looking facial recognition technology aili mcconnon helps cities predict natural disasters wall street journal june see hila mehr artificial intelligence citizen services government ash center democratic governance innovation harvarf kennedy school august ibm cognitive business watson helps cities help citizens artificial intelligence transforms services medium january propublica investigation revealed compas software widely used criminal justice system inaccurate forecasting future crime heavily biased black defendants investigators looked risk scores people arrested broward county florida compared subsequent criminal records found people predicted commit violent crimes went looking full range crimes defendants deemed likely reoffend actually arrested future crime jeff larson julia angwin machine bias propublica may investigation science technology committee parliament hart software used police durham england evaluate recidivism risk revealed calibrated avoid false negatives incorrectly classifying person low risk fact commit serious crimes public records suggest software developed palantir used police criminal investigations new orleans used beyond original intended scope series investigative reports significant public outcry city ended contract palantir march china particular aggressively pursuing surveillance state see paul mozur inside china dystopian dreams shame lots cameras new york times july australia unveiled plan connect network cctv cameras existing facial recognition biometric databases proposed measure pending parliament human rights age artificial intelligencetool monitor citizens facilitate profiling certain groups even identify locate enabling discriminatory profiling facial recognition software used surveil identify also target assisting spread disinformation used create disseminate targeted propaganda problem compounded social media algorithms driven engagement promote content likely clicked machine learning powers data analysis social media companies use create profiles users targeted advertising addition bots disguised real users spread content outside narrowly targeted social media circles sharing links false sources actively interacting users chatbots using natural language addition specter deep fakes systems capable creating video audio recordings real people causing many believe technology used future create forged videos world leaders malicious ends although appears deep fakes yet used part real propaganda disinformation campaigns forged audio video still good enough seem completely human behind deep fakes continues advance potential sowing chaos instigating conflict causing crisis truth perpetuating bias job market hiring processes long fraught bias discrimination response entire industry emerged uses goal removing human bias process however many products ultimately risk perpetuating bias seek mitigate areas major cause prevalent use historical data past successful employees train models thus naturally reproducing bias prior driving financial discrimination marginalized algorithms long used create credit scores inform loan screening however rise big data systems using machine learning incorporate analyze data points determine creditworthiness people live internet browsing habits purchasing decisions outputs systems produce known unlike formal credit scores largely unregulated data scientist cathy neil pointed scores often discriminatory create pernicious feedback recently amazon come fire directly marketing facial recognition product called rekognition law enforcement agencies use conjunction police body cameras would allow police identify people real time product piloted police departments orlando florida washington county oregon one example israeli company called faception bills facial personality analytics technology company claims categorize people personality types based solely faces classifiers uses include white collar offender high paedophile company released information technology correctly label people based faces see paul lewis shocked easy meet professor says facial recognition tell gay guardian july given bots estimated make least half internet traffic reach underestimated see michael horowitz paul scharre gregory allen kara frederick anthony cho edoardo saravalle artificial intelligence international security center new american security july ibid monica torres companies using screen candidates hirevue ladders august example borrower lives rough part town people default loans may given low score targeted financial products offering less credit higher interest rates systems group people together based observed habits majority case responsible person trying start business could denied credit given loan unfavorable terms perpetuating existing bias social inequality neil one company neil singled zestfinance uses machine learning offer payday loans lower rates typical payday lenders company philosophy data credit data found proxy race class national origin includes whether applicants use proper spelling capitalization application long takes read punctuation spelling mistakes analyzed suggest applicant less education native english speaker highly correlated socioeconomic status race national origin means considered poor language skills including speakers higher interest rates lead feedback loop entrenches existing discriminatory lending practices applicants trouble paying higher fees tells system indeed higher risk result lower scores similar applicants future neil human rights age artificial intelligencevi human rights human rights matter created new forms oppression many cases disproportionately affects powerless vulnerable concept human rights addresses power differentials provides individuals organizations represent language procedures contest actions powerful actors states human rights universal binding codified body international law respecting human rights required governments companies alike although governments additional obligations protect fulfill human entire system regional international domestic institutions organizations provide frameworks remedy articulate application human rights law changing circumstances including technological developments cases domestic law lacking moral legitimacy human rights carries significant normative violating human rights carries global reputational political costs naming shaming human rights violators often effective tool human rights law address egregious societal harms caused prevent harms occuring future ethics role complementary area ethics discourse largely dominated discussion good bad focus understandable ethics play important role artificial intelligence sparked discussions interplay human beings machines perhaps previous technological development considering ethical concepts justice fairness transparency accountability allows valuable debate societal impacts role also academic research community devoted addressing ethical ethics helped researching developing define boundaries major players google microsoft deepmind developed ethical principles guide pursue human rights universal ethics principles provide accountability redress way human rights ethics mutually reinforcing example company may develop ethical principles avoiding reinforcing negative social biases making sure systems accountable human oversight human rights privacy among others define ethical principles international human rights regime provide remedy principles violated additionally use deemed unethical likely also violates human rights principles procedures embedded international human rights regime leveraged combat unethical use discuss recommendations stakeholders use ethics human rights together internal policies according principles business human rights states must protect human rights abuse businesses within jurisdiction businesses responsible respecting human rights wherever operate victims must access judicial non judicial remedy information see ibid fairness accountability transparency machine learning initiative policy see microsoft google deepmind human rights age artificial intelligencehow impacts human rights role facilitating discrimination well documented one key issues ethics debate today recognize issues access partnered human rights organizations companies release toronto declaration march however right human right implicated human rights interdependent interrelated affects nearly every internationally recognized human right examine many human rights impacted rights discussed largely embodied three documents form base international human rights law international bill human includes universal declaration human rights udhr international covenant civil political rights iccpr international covenant economic social cultural rights icescr report adds right data protection defined charter fundamental implicated human right discuss current uses violate risk violating right well risks posed prospective future developments important note human rights issues discussed necessarily unique many already exist within digital rights space ability identify classify discriminate magnifies potential human rights abuses scale scope like human rights harms uses technology leverage data harms related use often disproportionately impact marginalized include women children well certain ethnic racial religious groups poor differently abled members lgbtq community marginalization groups reflected data reproduced outputs entrench historic patterns rights life liberty security equality courts fair everyone right liberty security person one shall subjected arbitrary arrest detention one shall deprived liberty except grounds accordance procedure established law article iccpr persons shall equal courts tribunals determination criminal charge rights obligations suit law everyone shall entitled fair public hearing competent independent impartial tribunal established law everyone charged criminal offense shall right presumed innocent proven guilty according law article iccpr toronto declaration protecting right equality machine learning systems human rights included freedom torture right enslaved rights detainees right imprisoned merely based inability fulfill contractual obligation rights aliens right social security mean ultimately impact rights merely found current documented violations prospective violations believed could occur near future note although many regional human rights systems comprehensive mostly limited analysis system interest universal applicability exception right data protection access recognizes right particularly relevant context analysis relating rights enumerated regional systems merited example european convention human rights charter fundamental rights far comprehensive comes workers rights use employers monitor police employee activity may violate european human rights see information examination plays see automating inequality virginia eubanks see also marginalized society face higher levels data collection access public benefits walk heavily policed neighborhoods enter health care system cross national borders data reinforces marginality used target extra scrutiny groups seen undeserving social support political inclusion singled punitive public policy intense surveillance cycle begins feedback loop article udhr articles iccpr human rights age artificial intelligence every human inherent right life right shall protected law one shall arbitrarily deprived life countries abolished death penalty sentence death may imposed serious crimes accordance law force time commission crime contrary provisions present covenant article iccpr growing use criminal justice system risks interfering rights free interferences personal liberty one example recidivism software used across criminal justice system inform detainment decisions nearly every stage assigning bail criminal software led black defendants falsely labeled high risk given higher bail conditions kept detention sentenced longer prison terms additionally systems prescribed law use inputs may arbitrary detention decisions informed systems may unlawful arbitrary criminal risk assessment software pegged tool merely assist judges sentencing decisions however rating defendant high low risk reoffending attribute level future guilt may interfere presumption innocence required fair predictive policing software also risks wrongly imputing guilt building existing police bias use past data reports suggest judges know little systems work yet many rely heavily upon results software viewed raises question whether court decisions made basis software truly considered use tools governments essentially hand decision making private vendors engineers vendors elected officials use data analytics design choices code policy choices often unseen government agency public individuals denied parole given certain sentence reasons never know articulated government authority charged making decision trials may fair right may looking forward broadly deployed facial recognition software within law enforcement raises risk unlawful arrest due error overreach history rife examples humans wrongly arresting people happen look similar wanted given error rates current facial recognition technology inaccuracies could lead increased wrongful arrests due misidentification exacerbated lower accuracy rates inability deal nuance likely cause problems future laws absolute certain cases breaking law justified example probably acceptable run red light order avoid collision tailgating car human police officer make distinction elect ticket driver red light cameras capable judgment future smart cities robocops risk loss nuance lead drastic increase people wrongfully arrested ticketed fined limited recourse time circumstances could push world people preference strictly following law rule despite extenuating circumstances losing ability make necessary judgment calls angwin machine according general comment article iccpr angwin machine previously discussed communities policed equally bias software ultimately creates negative feedback loops predict increasing criminal activity certain areas resulting continually overpoliced communities see committee experts internet intermediaries algorithms human rights study human rights dimensions automated data processing techniques possible regulatory implications council europe march robert brauneis ellen goodman algorithmic transparency smart city yale journal law technology vol face value irl online life real life podcast audio february lauren goode facial recognition software biased towards white men researcher finds verge feb human rights age artificial intelligencewith availability increasingly data lives foreseeable information social media posts activity included systems inform law enforcement judicial decisions could harnessed identify language behaviors show propensity violence risk committing certain types crimes use would implicate rights equality law fair trial rights privacy data one shall subjected arbitrary unlawful interference privacy family home correspondence unlawful attacks honour reputation everyone right protection law interference attacks article iccpr everyone right respect private family life home communications article charter fundamental rights everyone right protection personal data concerning data must processed fairly specified purposes basis consent person concerned legitimate basis laid law everyone right access data collected concerning right article charter fundamental rights privacy fundamental right essential human dignity right privacy also reinforces rights rights freedom expression many governments regions recognize fundamental right data protection data protection primarily protecting personal data related closely related right privacy even considered part right privacy within human rights system systems often trained access analysis big data sets data also collected order create feedback mechanisms provide calibration continual refinement collection data interferes rights privacy data protection analysis data using systems may reveal private information individuals information qualifies protected information treated sensitive even derived big data sets fed publicly available information example researchers developed models accurately estimate person age gender occupation marital status cell phone location data also able predict person future location past history location data order protect human rights information must treated personal data another example thin line public private data increased use government social media monitoring programs wherein law enforcement agencies collect troves social media information feed programs detect alleged threats isolated checks target public social media may seem like wise policing strategy programs instead involve massive unwarranted intake entire social media lifespan account group accounts bulk collection type found inherently violate human rights additionally systems used article udhr article iccpr article charter fundamental rights necessary proportionate principles estelle masse data protection matters protect access january steven bellovin enough enough location tracking mosaic theory machine learning nyu journal law liberty human rights age artificial intelligenceto process data insufficiently transparent accountable unclear human terms decisions reached systems violate key elements right data protection looking forward risks due ability track analyze digital lives compounded sheer amount data produce today use internet increased use internet things iot devices attempts shift toward smart cities people soon creating trail data nearly every aspect lives although individual pieces data may seem innocuous aggregated reveal minute details lives used process analyze data everything advertising optimizing public transportation government surveillance citizens world huge risks privacy situation raises question whether data protection even possible government surveillance expanded growth internet development new technologies enabling invasive surveillance tools ever example although fully centralized government facial recognition system yet known exist china work toward installing cctv cameras public places centralizing facial recognition systems shows could soon change half adults already law enforcement facial recognition use threatens end anonymity fear watched stop people exercising rights freedom association negative impact surveillance would felt acutely marginalized populations disproportionately targeted security additionally monitoring general population neither necessary proportionate goal public safety crime would almost certainly violate fundamental right privacy right freedom movement everyone lawfully within territory state shall within territory right liberty movement freedom choose residence everyone shall free leave country including rights shall subject restrictions except provided law necessary protect national security public order ordre public public health morals rights freedoms others consistent rights recognized present covenant one shall arbitrarily deprived right enter country article iccpr potential restrict freedom movement directly tied use surveillance systems combine data satellite imagery facial cameras cell phone location information among things provide detailed picture individuals movements well predict future location could therefore easily used governments facilitate precise restriction freedom movement individual group level looking forward currently lack formal mapping many poor underserved communities around world led exclusion gps mapping apps given growing trend predictive policing possible increased mapping areas combining use information data law enforcement apps rate crime levels safety neighborhoods could effectively shut tourism inhibit movement around within area even done legitimate public safety reasons may risk violating freedom movement jordan telcher facial recognition technologies mean privacy new york times july evan selinger amazon needs stop providing facial recognition tech government medium june see necessary proportionate principles privacy international guide international law surveillance august human rights age artificial intelligenceas iot extends infrastructure transportation systems smart highways biometrically tagged public transportation systems continue used locate individuals real time allowing governments restrict freedom movement additionally used automate decisions example placing people fly prohibitive travel could result people freedom movement unjustly restricted rights freedom expression thought religion assembly everyone shall right freedom thought conscience religion right shall include freedom adopt religion belief choice freedom either individually community others public private manifest religion belief worship observance practice teaching one shall subject coercion would impair freedom adopt religion belief article iccpr article udhr everyone shall right hold opinions without interference everyone shall right freedom expression right shall include freedom seek receive impart information ideas kinds regardless frontiers either orally writing print form art media choice article iccpr right peaceful assembly shall recognized everyone shall right freedom association others including right form join trade unions protection interests restrictions may placed exercise right prescribed law necessary democratic society interests national security public safety public order ordre public protection public health morals protection rights freedoms others articles iccpr direct threats internet companies host content use flag posts violate terms service governments exerting formal informal pressure companies address problem alleged terrorist content hate speech fake news without clear standards definitions led increased use automated law recently passed germany requires social media sites remove wide range content within hours flagged seven days cases less imperfect companies pressured take questionable content quickly much content removed youtube removed videos documenting atrocities syria flagged videos often serve evidence horrific crimes human rights violations youtube policy carves exceptions violent content important educational documentary value yet still taken authoritarian governments use similar technology increase censorship chinese government already replacing human censors popular chinese video platform iqiyi uses identify pornographic violent content well content deemed politically deal nuance flagged content currently reviewed humans though may change technology becomes sophisticated industry sees human resources required review unnecessary article udhr article iccpr article iccpr udhr articles iccpr article udhr freedom house survey found governments attempted control online discussions germany starts enforcing hate speech law bbc january denis nolasco peter micek access responds special rappoteur kaye content regulation digital age access january kate flaherty youtube keeps deleting evidence syrian chemical weapon attacks wired june yuan tang artificial intellifence takes jobs chinese censors financial times may human rights age artificial intelligencein countries freedom religion threat could assist government officials monitoring targeting members persecuted religious groups could force groups secrecy fear identified could produce physical consequences violence arrest death could also used identify take religious content would constitute direct violation freedom religion people able display religious symbols pray teach religion online finally censorship used restrict freedom association removing groups pages content facilitate organization gatherings collaboration given important role social media organizing protest movements globally use could widespread effect hindering assembly indirect threats violations right privacy chilling effect free expression people feel watched lack anonymity shown alter behavior surveillance compounds effect serious repercussions freedom one powerful example facial recognition used public spaces identify individuals protest may significant chilling effect assembly implementation system countries restrict free assembly would effectively prevent enjoyment right many people rely level security anonymity provides gather public express views another indirect threat impact social media search algorithms example facebook algorithm determines content user newsfeed influences widely content shared google search algorithm indexes content decides shows top search results algorithms played significant role establishing reinforcing echo chambers ultimately risk negative impacts media pluralism inhibition diversity role content ranking creation reinforcement filter bubbles poses indirect threat freedom thought shapes type information people access although people often ability access sources information seek different opinions humans limited time attention mean people countries without robust free press limited internet access social media platforms facebook often source unregulated information looking forward looming direct threat free expression online harassment harassment new increasingly perpetrated bots instead humans bot accounts masquerade real users send automated responses identified accounts anyone shares certain kind relentless online harassment chilling effect free expression particularly marginalized populations disproportionately bot designers increasingly employ natural language processing harassment bots follow suit make harder detect report get rid bot accounts predictive power already used predict help prevent armed conflict approach could also used governments predict prevent public demonstrations protests take alex comninos freedom peaceful assembly freedom association internet apc privacy international article privacy freedom expression agen artificial intelligence april council europe algorithms human michael bernstein identifying harassment bots twitter daemo august megan white solve problem like troll armies access april constance grady obline harassment threatens free speech field guide help survive vox may council europe algorithms human human rights age artificial intelligence rights equality persons equal law entitled without discrimination equal protection law respect law shall prohibit discrimination guarantee persons equal effective protection discrimination ground race colour sex language religion political opinion national social origin property birth article iccpr states ethnic religious linguistic minorities exist persons belonging minorities shall denied right community members group enjoy culture profess practise religion use article iccpr states parties present covenant undertake ensure equal right men women enjoyment rights set forth present article iccpr icescr models designed sort filter whether ranking search results categorizing people buckets discrimination interfere human rights treats different groups people differently sometimes discrimination positive social aims example used programs promote diversity criminal justice discrimination often result forms bias use systems perpetuate historical injustice everything prison sentencing loan applications although people may think online advertisements much impact lives research suggests online space result discrimination perpetuate historical biases researcher latanya sweeney found google search stereotypically african names yielded ads suggested arrest record trevon jones arrested vast majority researchers carnegie mellon found google displayed far fewer ads executive jobs women google personalized algorithms powered taught learn user behavior people click search use internet racist sexist ways algorithm translates ads compounded discriminatory advertiser preferences becomes part cycle people perceive things affects search results affect people perceive looking forward given facial recognition software higher error rates faces likely misidentification disproportionately affect people color gravity problem demonstrated aclu test amazon rekognition facial recognition software aclu scanned faces members congress public criminal mugshots using rekognition api default confidence level one congress actually mugshot database yet false matches matches people color even though members congress people color surveillance software also used express purpose discrimination allowing governments identify target deny services people different groups controversial study found system could accurately guess whether someone gay straight supposedly based solely photos faces experts strongly refuted findings pointing numerous cues could picked photos however regardless articles iccpr article icescr latanya sweeney discrimination online delivery harvard university january julia carpenter google algorithm shows prestigious job ads men women worry washington post july showed many facial recognitions systems rekognition disportionately impacted people color see russell brandom amazon facial recognition matched members congress criminal mugshots verge july human rights age artificial intelligenceof quality study model able identify sexuality men women accuracy governments could use systems like target discriminate lgbtq people places homosexuality gender nonconformity either illegal social unacceptable questionable science behind study faces high error rates kind system may matter wielding technology rights political participation self every citizen shall right opportunity take part conduct public affairs directly freely chosen representatives vote elected genuine periodic elections shall universal equal suffrage shall held secret ballot guaranteeing free expression electors access general terms equality public service country article iccpr role creating spreading disinformation challenges notion fair elections creates threat right political participation self determination presidential election showed foreign power leverage bots social media algorithms increase reach false information potentially influence voters although platforms working prevent type activity future chatbots deep fakes likely make content convincing voters harder companies detect may chill political participation particularly voters lose trust legitimacy elections looking forward surveillance could used restrict inhibit political participation including identifying discouraging certain groups people voting use facial recognition polling places voting booths could compromise secrecy ballot governments wishing discourage voters casting ballots opposition need even directly surveil act voting mere signification surveillance could sufficient convince voters ballots secret could influence voting decisions accordingly prohi bition propaganda war shall prohibited law advocacy national racial religious hatred constitutes incitement discrimination hostility violence shall prohibited law article iccpr looking forward people use technology facilitate spread disinformation influence public debate use create propagate content designed incite war discrimination hostility violence see potential scenario disputes russia ukraine crimea russia tested widely known disinformation tactics attempts undermine public faith governments around world deployed troll armies stoke flames conflict political near future could use chatbots incite racial ethnic violence regions already rife tension deploy deep fakes simulate world leaders declaring war instigating armed conflict sam levin new guess whether gay straight photograph guardian september lewis facial recognition tell article udhr article iccpr article iccpr massive protests ukraine resulted ouster president viktor yanukovych russia began massive disinformation campaign discredit new government encourage separatists initiate current civil war see gregory warner americans lean fake news ukraine rough translation audio podcast august white troll armies access human rights age artificial intelligence rights work adequate standard states parties present covenant recognize right work includes right everyone opportunity gain living work freely chooses accepts take appropriate steps safeguard right steps taken state party present covenant achieve full realization right shall include technical vocational guidance training programmes policies techniques achieve steady economic social cultural development full productive employment conditions safeguarding fundamental political economic freedoms individual article icescr states parties present covenant recognize right everyone adequate standard living family including adequate food clothing housing continuous improvement living conditions article icescr although right work constitute absolute unconditional right obtain employment require states work toward achieving full role automation jobs could poses real threat right work may prevent people accessing labor market first place automation resulted job loss certain sectors widely predicted accelerate trend although significant disagreement extent job automation achieved doubt result shifts labor market job creation job looking forward automation shift labor market significantly large numbers people find jobs struggle provide families researchers exploring ways ensure people maintain adequate standard living volatility labor market one approach universal basic income fixed income governments provide canada finland california testing basic income schemes trials planned countries job automation may bring range challenges governments address ensure adequate standard living government uses automated systems programs address poverty everything eligibility health care food visit special rapporteur extreme poverty human rights found city authorities across country using automated systems match homeless population available services systems use traditional deterministic statistical algorithms assign homeless respondent vulnerability score connect person appropriate housing existence systems raises important questions automating crucial decisions least produce traceable outcomes however shift using inherent lack transparency explainability could make automated decisions provision public service something neither government agency tasked making decision public fully understands articles udhr articles icescr see see leonid bershidsky finland basic income test ambitious enough bloomberg opinion april chis weller one biggest vcs silicon walley launching experiment gie people free money business insider september jordan pearson basic income already transforming life work postindustrial canadian city motherboard april eubanks digital statement visit usa professor philip alston united nations special rapporteur extreme poverty human rights office high commissioner human rights united nations december aspx human rights age artificial intelligence right health states parties present covenant recognize right everyone enjoyment highest attainable standard physical mental health steps taken states parties present covenant achieve full realization right shall include necessary provision reduction infant mortality healthy development child improvement aspects environmental industrial hygiene prevention treatment control epidemic endemic occupational diseases creation conditions would assure medical service medical attention event sickness article icescr promising impactful applications healthcare helping doctors accurately diagnose disease providing individualized patient treatment recommendations making specialist medical advice accessible however also ways could endanger right health one potential systems result discrimination programmed ways place outcomes cost reduction wellbeing patient example system could designed recommend different treatments depending insurance status patient much able pay potentially denying lifesaving care someone socioeconomic status harming marginalized groups already suffer insufficient access quality healthcare another potential issue negative feedback loops could result guidance system example doctors tend withdraw care patients certain diagnoses extreme premature birth severe brain injuries system may learn diagnoses nearly always fatal recommend doctor treat even cases treatment may course impact inevitable error rates system even example ibm watson accurate human doctors diagnosing disease still get diagnosis wrong occasion recommend wrong treatment case kind accountability medical decision made machine doctor issue could arise systems predict disease outbreaks recommend responses happens deploy resources area deemed high risk leaving others without assistance human health workers already make choice would preemptively may sometimes get wrong raises larger questions regarding extent certain things automated require human loop much responsibility held human doctors systems making recommendations looking forward another concern relates use determine gets access healthcare pay health insurance danger health insurance providers could use profiling based certain behaviors history system could use data points recommend individualized health insurance rates could see history illness family physically active enjoy eating fast food restaurants smoke recommend charging higher rates based factors patricia hannon researchers say use artificial intelligence medicine raises ethical questions stanford medicine news center march human rights age artificial intelligence right states parties present covenant recognize right everyone education states parties present covenant recognize view achieving full realization right primary education shall compulsory available free secondary education different forms including technical vocational secondary education shall made generally available accessible every appropriate means particular progressive introduction free education higher education shall made equally accessible basis capacity every appropriate means particular progressive introduction free education fundamental education shall encouraged intensified far possible persons received completed whole period primary education development system schools levels shall actively pursued adequate fellowship system shall established material conditions teaching staff shall continuously improved article icescr fundamentally violate principle equal access universities using deterministic algorithmic systems recommend applicants admit often meet school preferences host issues lead discrimination including use historical data previously admitted students inform model since many elite universities historically attended wealthy white males model uses data risks perpetuating past systems likely employ future would make bias harder detect could result universities discriminating guise objectivity looking forward used track predict student student performance way limits eligibility study certain subjects access certain educational opportunities right education put risk given growth research early childhood predictors success likely system could used restrict opportunities students increasingly younger ages resulting significant discrimination students coming underprivileged backgrounds ultimately denied opportunities people background tend negative outcomes system would ignore students overcome adversity achieve academic professional success would entrench existing educational inequalities righ take part cultural life enjoy benefits scientific states parties present covenant recognize right everyone take part cultural life enjoy benefits scientific progress applications benefit protection moral material interests resulting scientific literary artistic production author article icescr use technologies allow governments identify repress cultural groups could stop people taking part cultural life either directly indirectly example surveillance inspires fear identified suffering reprisals cultural identity leading people avoid cultural expressions altogether risk could used criminalize certain cultures members particular culture disproportionately arrested otherwise targeted law enforcement behaviors customs associated cultures could become linked criminal activities example system analyzing video photographic footage could learn associate certain types dress manners speaking gestures criminal activity could used justify targeting groups guise preventing crime article udhr article icescr neil weapons math destruction article udhr article icescr human rights age artificial intelligencemany developing world worry left behind global race corresponding transformational economic change developing countries stand become passive consumers systems developed china west different people cultures situations runs risk deepening existing inequality social division places internet access technology largely restricted wealthy urban risk deeper inequality compounded risk job automation lead job loss displacing manufacturing industry role economic development right marry children rights family family natural fundamental group unit society entitled protection society state right men women marriageable age marry found family shall recognized marriage shall entered without free full consent intending spouses article iccpr every child shall without discrimination race colour sex language religion national social origin property birth right measures protection required status minor part family society state article iccpr looking forward technology used health reproductive screening people found unlikely children screening could prevent marrying marrying certain person couple deemed unlikely conceive similarly dna genetics testing could used efforts produce children desired qualities robo tics use robotics represents small percentage use today however robotics growing field robots increasingly play role lives many cases robot simply provides physical body types systems explored report however physicality context robots used may raise new right life fully autonomous weapons systems currently development many countries increasing use drones similar weaponry mean autonomous weapons likely accessible actors bound traditional laws armed conflict autonomous weapons near future likely suffer inability deal nuance unexpected events conflict situation could result death injury innocent civilians human operator may able another threat right life could arise use robots healthcare robots used assist surgery existence fully autonomous surgical robots easy imagine near future robots used rehabilitative therapy general care settings robots inevitably get wrong happens accountable additionally bad actors interfere health robots made cause physical harm pathways remedy redress harm far established article udhr articles iccpr article icescr helpful starting point thinking desired boundaries robots society science fiction author isaac asimov three laws first two laws particular relevance human rights robot may injure human inaction allow human come harm robot must obey orders given human beings except orders would conflict first law explore potential threats robots human rights omest report comest robotics ibid human rights age artificial intelligence right privacy surveillance drones robots long used military increasingly used law enforcement actors well equipped technology facial recognition technology made fully example used follow certain group person drones could deepen impact widespread invasive surveillance violates necessary proportionate principles govern state surveillance right work robots enable job automation thus threaten right work ways explore right education although still nascent stages use robotics education active research area includes robots used tasks like teaching second languages primary schools general risks posed robots outcomes violate equal access example areas robots replace teachers schools students would receive different kind education human teachers may constitute violation equal access vii recommendations address harms swift action deal human rights risks help prevent foreseeable detrimental impacts providing space framework addressing problems predict large diverse field approach need extent however four broad policy approaches could address many human rights risks posed comprehensive data protection legislation anticipate mitigate many human rights risks posed however specific data additional measures also necessary government use governed high standard including open procurement standards human rights impact assessments full transparency explainability accountability processes given private sector duty respect uphold human rights companies beyond establishing internal ethics policies develop transparency explainability accountability processes significantly research conducted potential human rights harms systems investment made creating structures respond risks role comprehensive data protection laws comprehensive data protection laws apply government private sector long way addressing many human rights risks posed data engine law mandates protection personal data necessarily implicate systems given global push toward data protection legislation heartening practical consider impact european union general data protection regulation gdpr gdpr positive framework provides control person personal information empowers people make informed decisions data used gdpr limits data processing permissible ibid human rights age artificial intelligencepurposes heightened protections sensitive data also requires limits use personal data training systems rights provided gdpr similar laws offer framework prevent unaccountable uses impact individual rights ensuring level control personal data accountability use systems suggested data protection laws incompatible make broad exceptions development use misguided likely true strong data protection laws may preempt deployment certain systems companies never able innovate without regard potential harm systems used make decisions basis rationale even developers fully explain guinea pigs first suffer negative consequences data protection rights provide accountability structures mitigate harm also protect people personal data covertly commodified otherwise exploited ways harm others society large innovation industries begun pick issues developing voluntary frameworks use however history shows industry woefully inadequate protecting people particularly marginalized communities frequently targeted manipulation campaigns continues increase sophistication society afford sacrifice individual rights altar innovation instead jurisdictions without data protection laws government officials pursuing measures address human rights impact continuing revolution similarly areas laws already force overseers watchdogs ensure law followed remains relevant technology advances data protection rights right information right access work together allow people get information data entity collecting collecting use whether data used automated rights raise public awareness existence systems roles furthermore rights allow people uncover understand potential human rights harms push entities transparent use right rectification allows people ame modify information held third party incorrect incomplete inaccurate right help mitigate impact error rates systems right restrict processing gives people ability request entity stop using limit use personal information right erasure provides pathway deletion person personal data held third party entity longer necessary information misused relationship user entity terminated rights could used temporarily halt use contested system pressure entity use system responsibly see american farm bureau helped construct privacy security principles farm data addresses issues data ownership portability use sharing companies like deere monsanto early signers questions remain much principes protect many details government use algorithmic decision making system hidden behind agreements memorandums understanding vendors see human rights age artificial intelligencethe right explanation provides person get explanation automated decision made pertaining person right ensures entities understand systems use actually work pushes developers continue working make understandable right object gives people ability contest processing personal data entity data used direct marketing automated decision making human intervention take place research statistics entity legitimate right allows direct challenges decisions made using systems particularly important government use ways discriminatory also ensures human loop important automated decisionmaking systems adds layer accountability recommendations government private sector diverse field potential interference human rights depends type data system uses context system implemented example fewer different human rights risks posed city government use optimize water usage police department use criminal risk assessment tool mind recommend different approaches government private sector recommendations government use systems government often implicate value judgments necessarily linked political process free democratic government systems reason governments directly deprive people liberty report recommends higher standards public sector regarding use states bear primary duty promote protect respect fulfill human rights international law must engage support practices violate rights whether designing implementing systems required protect people human rights abuses well take positive action facilitate enjoyment recommendations articulate framework government decision making general apply type algorithmic decision making system regardless whether uses follow open procurement standards government body seeks acquire system components thereof procurement done openly transparently according open procurement standards includes publication purpose system goals parameters information facilitate public understanding procurement include period public comment states reach potentially affected groups relevant ensure opportunity input mandate human rights impact assessments states must thoroughly investigate systems identify human rights risks prior development acquisition well regular ongoing basis throughout lifecycle system human rights impact assessment may necessary part larger algorithmic impact assessment process examines broader threats including threats posed uses conduct surveillance activity interferes human rights appropriate laws must exist govern see summary state human rights obligations international law institute outlined practical framework algorithmic impact assessments public agencies article general data protection regulation gdpr sets requirement carry data protection impact assessment dpia addition article gdpr requires data protection principles applied design default conception phase product service service lifecycle human rights age artificial intelligencethe uses assessment process include testing audits independent experts identifying measures mitigate identified risks prevent rights violations occurring measuring compliance efficacy failsafe terminate acquisition deployment continued use point identified human rights violation high unable mitigated identification new legal safeguards needed protect human rights specific applications tools special determinations bias particularly criminal justice sector due risks fair trial right liberty third party used develop implement system requirement third party participate human rights assessment process ensure transparency explainability maximum possible transparency necessary system including transparency regarding purpose used works must continue throughout system life cycle agreements contracts third parties guise protecting intellectual property violation principle prevent public oversight accountability specifically adequate transparency explainability must include regular reporting governments use manage systems use open data standards training data code fullest extent possible adhering privacy standards enabling independent audits systems data clear accessible reporting operation system means providing meaningful information outputs reached actions taken minimize impacts targeted notification government system makes decision impacts individual rights avoidance black box systems meaning avoidance system person meaningfully understand works establish accountability procedures remedy use system task previously done human remove standard requirements responsibility accountability government decision making processes always human loop areas including criminal justice significant human oversight necessary governments set policies regarding automation processes eye human rights impacts additionally individuals must right challenge use system appeal decision informed wholly made system specifically accountability remedy require proper training operators system government employees use manage system must understand works bounds use potential harm proper training ensures humans remain loop meaningful way increases likelihood spotting harmful outcomes establishing responsibility outputs system although states often rely third parties design implement systems ultimate responsibility human rights interferences must lie states protect abuse government entities must acquire technical expertise necessary thoroughly vet given system establishing mechanisms appealing given use specific determination system see international principles application human rights communications surveillance last accessed june available see information open data standards government data human rights age artificial intelligenceeven systems procured implemented transparently stakeholder input may still risk significant human rights address process allows public contest use system entirety recommendations use actors also responsibility respect human rights independent state obligations meet duty actors must take ongoing steps ensure cause contribute human rights establishment ethics policies many large players laudable human rights impact assessment integrated larger ethics review processes additionally actors pursue transparency explainability measures well establish procedures ensure accountability access remedy collectively human rights due diligence informed expert stakeholders assists companies preventing mitigating abuses however firms must also meet obligations redress harms directly indirectly resulting operations via processes developed consultation affected communities recognize uses equal risk human rights harms actions required prevent respond human rights violations depend context specifically actors conduct human rights due diligence per guiding principles business human rights consisting following three core identify potentially adverse outcomes human rights actors assess risks system may cause contribute human rights violations actors must identify direct indirect harm well emotional social environmental nonfinancial harm consult relevant stakeholders inclusive manner particularly affected groups human rights organizations independent human rights experts system intended use government entity public private actors conduct assessment take effective action prevent mitigate harms well track responses identifying human rights risks actors must mitigate risks track time requires actors correct system including risks sit training data design model impact system ensure diversity inclusion relevant expertise prevent bias design inadvertent harms submit systems significant risk human rights abuses independent audits halt deployment system context risk human rights violations high impossible mitigate track steps taken mitigate human rights harms evaluate efficacy includes regular quality assurance checks auditing throughout system life cycle particularly important given role negative feedback loops exacerbate harmful outcomes state pennsylvania worked hard implement algorithmic transparency use automated decision making systems however public comments process open data standards stopped problematic systems used see see guiding principles business human rights adapted toronto declaration human rights age artificial transparent efforts identify prevent mitigate harms systems transparency individuals groups impacted well relevant stakeholders key part human rights due diligence involves practice means actors must publicly disclose information identified human rights risks including system designed context used publish technical details system including samples training data details sources data provide transparency explainability extent possible actors must highly transparent provide meaningful information systems work transparency especially important systems may significant public personal impact example medicine content recommendation moderation specifically includes adherence open source open data standards publication meaningful accessible explanations system works people meaningfully informed may impact establish appropriate mechanisms accountability remedy actors establish internal accountability mechanisms functioning systems although states primary duty provide access formal remedy case human rights violations companies must take additional action ensure access meaningful effective remedy minimum includes internal responsibility development implementation system commitment third parties developing systems third parties clearly delineating responsibility accountability vendor client including vendor obligation ensure proper training risks system well mitigate risk function creep misuse system creation clear transparent processes individual directly submit complaints seek redress human rights harms timely manner could administered internally collaboration relevant stakeholders mutually acceptable external findings feed back product policy development better prevent mitigate harms need research ture uses data protection transparency accountability mechanisms far toward mitigating human rights abuses use solve foreseeable problems instance identified future systems may substantially impact economic opportunities facilitate war conflict globally reasons recommend states entities including civil society organizations individuals academia work together investigate future uses continue explore potential human rights impacts identified emphasis placed identifying building response mechanisms potential threats ensure negative implications mitigated fullest extent possible fora pluralistic order ensure potential threats identified solutions preference specific group another diminish marginalized voices guiding principles business human rights principle procedural substantive aspects remedy information communications technology sector see access telco remedy plan see principles guiding principles business human rights information human rights age artificial intelligencerebuttal tran sparency explainability kill innovation two frequently heard arguments requirements transparency explainability one argument complex require transparency could damage innovation second argument explainability impossible mandated would require developers sacrifice complexity systems hamper innovation arguments overblown inconsistent developments today argument addressed publishing code data allows experts identify potential issues opponents transparency systems question utility publishing code training data complex systems may rely millions data points models change time although auditing systems may present new set technical challenges render transparency meaningless developers vet training data outputs identify sources bias test equitable outcomes transparency would ensure access necessary training data outputs independent experts identify sources bias test equitable outcomes including identifying problems developers missed masked process necessarily increases accountability fosters user full transparency vital cases need damage companies opponents transparency also argue transparency requirements reduce incentives invest new systems would allow replication history shown open source projects often successful facilitate innovation may option limited circumstances actors determine route untenable cases actors could facilitate access relevant code trusted identified third parties audits testing recently facebook given select researchers access data study election interference given increased public scrutiny role algorithms lives conceivable companies follow suit however information data sets used outputs still published well information could facilitate understanding measure bias however states always required provide full transparency government use systems particularly important areas law enforcement justice system although companies supplying software may reasons publishing code training data cases fundamental human rights sacrificed sake corporate interests meaningful explainability increasingly possible world largely behind opponents regulation argue requiring explainability would mean systems would substantially less complex therefore less accurate ultimately stifling innovation argument misses mark number ways first valuable levels explainability achievable although facebook may fully understand targeting advertising algorithm works knows enough tell users actions led served certain advertisement type information matters easy provide research suggests see joshua new fix tech crunch july uniqid see american farm bureau helped construct privacy security principles farm data addresses issues data ownership portability use sharing companies like deere monsanto early signers questions remain much principes protect human rights age artificial intelligenceeven possible systems measure given input affected output system used universities rank applicants could tell example ranking due gpa due standardized testing due school ranking factors level explanation would long way addressing black box challenge identifying potential sources bias additionally explainability technically valuable developers need able determine whether system solving right problem many examples systems cheated arrive desired outcome example researchers university washington created deliberately bad algorithm supposed classify images husky dogs wolves system correctly labeled images rather learning difference appearance huskies wolves system detected presence snow images wolves snow systems high stakes fields ultimately solve wrong problem outcome could life threatening explainability necessary adoption certain fields ways quest explainability spurring innovation ethical technical reasons academics major companies alike devoting significant effort toward explainability making serious progress august google deepmind published study system developed identify eye disease ocular scans system makes diagnosis points portions scan used physicians see arrived diagnosis well confident breakthroughs show explainability may driving innovation viii conclusion artificial intelligence systems changing way things done companies governments around world bringing potential significant interference human rights data protection laws safeguards accountability transparency like described paper may able mitigate worst uses known today work necessary safeguard human rights technology gets sophisticated expands areas hope report helps inspire deeper conversations crucial area care future human rights look forward engaging conversations many details government use algorithmic decision making system hidden behind agreements memorandums understanding vendors see see summary state human rights obligations international law human rights age artificial intelligencenov access defends extends digital rights users risk around world combining direct technical support comprehensive policy engagement global advocacy grassroots grantmaking convenings rightscon fight human rights digital age information visit contact info work licensed creative commons attribution international license
