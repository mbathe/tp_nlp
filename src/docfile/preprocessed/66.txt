data society governing artificial intelligence governing artificial intelligence upholding human rights dignity mark latonero governing artificial intelligence upholding human rights dignity mark latonero executive summary international human rights help guide govern artificial intelligence currently much society uncertain real human impacts systems amid hopes bring forth global good evidence sys tems already violating fundamental rights freedoms stakeholders look north star guide development rely human rights help chart course ahead international human rights powerful tool identifying prevent ing redressing important class risks harms human frame could provide developing aspirational normative legal guidance uphold human dignity inherent worth every individual regardless country jurisdiction simply put order benefit common good least design deployment avoid harms fundamental human values international human rights provide robust global formulation values report intended resource anyone working field gover nance also intended human rights field outlining concerned impacts follows translates data society governing artificial intelligencethese fields reframing societal impact systems lens human rights starting point focus five initial examples human rights areas nondiscrimination equality political participation privacy freedom expression demonstrate one implicated number recent controversies generated result systems despite examples rights harms progress already underway anticipating negative impacts persons disabilities example lead designers build systems protect promote rights primer provides snapshot stakeholder engagement intersection human rights companies private sector scrambled react face criticism others proactively assessing human rights impact products addition sectors government intergovernmental organizations civil society academia nascent developments may momentum adopting human rights approach among large tech companies civil society organizations date albeit significant number examples united nations government academia bring human rights center governance debates human rights address present unforeseen concerns pertaining work area focus human rights approach could practically implemented policy practice organizational change fur ther goal report offers initial recommendations technology companies find effective channels communication local civil society groups researchers particularly geographic areas human rights concerns high order identify respond risks related deploy ments technology companies researchers conduct human rights impact sessments hrias life cycle systems researchers reevaluate hria methodology particularly light new developments algorithmic impact assessments toolkits developed assess specific industry needs governments acknowledge human rights obligations incorporate duty protect fundamental rights national policies guidelines possible regulations governments play active role multilateral institutions like advocate development respects human rights since human rights principles written technical specifications human rights lawyers policy makers social scientists computer scientists engineers work together operationalize human rights business models workflows product design data society governing artificial academics examine value limitations interactions human rights law human dignity approaches humanitarian law ethics relation emerging technologies human rights legal scholars work stakeholders tradeoffs rights faced specific risks harms social science researchers empirically investigate impact human rights human rights investigators special rapporteurs continue researching publicizing human rights impacts resulting systems officials participating governments evaluate whether existing mechanisms inter national rights monitoring accountability redress adequate respond rapidly emerging technologies leadership also assume central role international technology debates promoting shared global values based fundamental rights human dignity data society governing artificial intelligencetable contents executive summary introduction bridging human rights human rights frame risks harms nondiscrimination equality political participation privacy freedom expression disability rights approach accessible design stakeholder overview business civil society governments united nations intergovernmental organizations academia conclusion endnotes acknowledgments author mark latonero research lead data society phd annenberg school communication university southern california data society governing artificial intelligence introduction international human rights help guide govern artificial intelligence according global ethics initiative institute electrical electronics engineers ieee largest organization technical professionals answer clear ieee report ethically aligned design lists first principle design infringe upon international human yet sys tems already infringing rights instance march human rights investigators united nations found facebook algorithmically driven news feed exacerbated circulation hate speech incitement violence congressional hearing april senator pat rick leahy questioned ceo mark zuckerberg failure facebook content detection face possible genocide myanmar rohingya ethic minority zuckerberg initially told senators advanced tools would help solve problem later conceded investors facebook systems unable detect hate local contexts reasonable accuracy anytime month zuckerberg hearing international telecommunications union itu hosted second annual global good summit many involved summit source potential risks bring better future worldwide benefits hopes fears lies increased sense uncertainty stakeholders look north star guide development rely human rights help chart course ahead simply put order benefit common good least design deployment avoid harms fundamental human values international human rights provide robust global formulation values bridging human rights stake human dignity international framework human rights law intended establish global principles norms mechanisms accountability treatment individuals definition human dignity contested normative value debated extensive literature outside scope report present purposes term human dignity gestures towards usage western moral philosophy kant notions dignity linked human autonomy agency acknowledging dignity linked traditions eastern philosophy well report usage human dignity also evokes united nation charter universal declaration human rights major rights treaties link fundamental human rights dignity worth human person equal rights men women interactions humans may challenge refine concept human dignity important topic future work data society governing artificial intelligenceapproach provides actors developing aspirational normative guidance uphold human dignity inherent worth every individual regardless country jurisdiction implementing human rights help identify anticipate worst social harms guide developing technical policy safeguards promote positive uses working accountability activate international system human rights practice including binding treaties investigations advocacy initiatives monitor social impacts establish processes redress importantly advocates use human rights focus attention power relationships inequalities impact vulnerable marginalized groups around globe implementing human rights help identify anticipate worst social harms guide developing technical policy safeguards promote positive uses working commercially might wonder care human rights increasingly stakeholders holding private sector responsible upholding released landmark document guiding princi ples business human rights calls industry respect protect provide remedies human principles provide executives developers alike template conducting due diligence human rights impacts provide guidelines businesses assume higher duty care developing deploying although milestone field business human rights guiding princi ples reflects starting point application human rights tech sector working directly need regulation hard laws along technical standards social norms market incentives effectively incorporate respect human rights business models policies practices time working human rights need actively engaged governance monitoring necessary ready invoke human rights framework challenge developed deployed business government civil society developers work together help assess risk areas anticipate needs vulnerable groups stakeholders working across silos safeguard harms systems avoid human rights abuses advance enjoyment human rights report intended resource anyone working field gover nance anywhere researched developed deployed human rights frame identify anticipate minimize important class risks harms data society governing artificial intelligencework also intended human rights field outlining concerned present impacts follows translates fields reframing societal impact systems lens human rights seeking govern governments looking craft regulation companies looking document offers perspective based established human rights accountability norms field human rights limitations certainly address ethical issues arising yet offers strong value proposition approach governance upholds human dignity based international human rights law first part report bridging human rights connects entry points human rights governance discussions next human rights frame risks harms reviews number current risks harms human rights perspective describing rights applied part three stakeholder overview catalogues current state play among stakeholders active space examples progress challenges finally conclusion discusses limitations presents several recommendations incorporating human rights approach governance bridging human rights human rights appeared periphery prominent human rights highly technical fields fully digest either would require far exegesis attempted report instead shall draw basic entry points fields inform governance discussions discussions fragmented people speak colloquially popular press tech marketing materials others speak concrete methods scientific moreover nuances terminology speed field moving make discussions difficult data society governing artificial intelligencehave considering social policy implications useful think catchphrase cluster technologies embedded social systems includes machine learning natural language processing computer vision neural networks deep learning big data analytics predictive models algorithms intrinsically situated social contexts developed deployed areas remain theoretical others machine learning already impact machine learning systems process large amounts historical training data learn examples detect patterns useful machine learning algorithms contain level statistical bias produces incorrect decisions however historical data incomplete representative specified population biases scale quickly inexplicably across sys tems systems entrench discriminatory outcomes people lives far society allow machine learning systems influence human even make decisions concerns heart questions yet answered fact today automated systems making predictions human behavior producing decisions recommendations impacting people everyday life systems increasingly becoming embedded number social contexts policing judicial sentencing medicine finance know unintentional impacts unforeseen consequences current future systems uncertainty brought urgent calls govern turn value human rights field human rights complex nonexperts purposes report anchor international human rights law drafting implementation universal declaration human rights udhr united nations udhr aspirational language established human rights grounded respect individuals derived equal status bearers inherent human dignity response disregard contempt human rights precipitated two world wars holocaust human dignity fundamental rights tied country citizenship legal regime socioeconomic position rights universal sense apply everyone everywhere provides frame discussing global impact governance last years human rights proponents developed principles udhr body international human rights law includes nine major human rights treaties regional rights instruments americas africa europe incor poration state constitutions national laws customary case yet divergence political ideologies claims sovereignty governments enforce international human rights law wildly varying thus human rights framework emerged monitor promote protect human rights involves development international human rights law interaction data society governing artificial intelligenceof diverse network actors system international organizations ngos civil society private sector academia advocates local individual level looking first principles ground governance use language human rights example one hotly debated topics discriminatory algorithms systems includes empirical research facial recognition systems see people particularly women darker skin due lack adequate training data faulty models therefore reproduce culturally engrained biases people human rights principles nondiscrimination propagated multitude treaties national laws commentary academic interpretation policies guidelines body work offers distinct value commitment also global perspective identify impact discrimination equality nondiscrimination foundational practically every major human rights instrument emerged debate input representatives world nations development human rights controversies politics last years international human rights come represent shared global values working technology policy faced difficult task deciding standards values norms apply different social contexts need balance tradeoffs developing deploying technologies need understand potential misuses abuses unintended consequences biases sociotechnical systems even costs deploying tool may help someone need human rights provide working basis understanding governing systems technical standards policy address values like nondiscrimination first place important tech companies whose products used across national borders laws values vary outside present scope report area demands foundational work concerns pathways human rights accountability remedy harms become manifest purely legal regulatory compliance framework would lag behind velocity change associated emerging technologies thus components human rights framework special rapporteurs independent investigators monitors civil society crucial calling attention risks harms scholars christiaan van veen new york univer sity nyu corinne cath oxford internet institute state human rights language legal framework source power human rights carry significant moral legitimacy reputational cost perceived human rights violator thus human rights provide link system negative social impact even one individual places like myanmar powerful companies silicon valley data society governing artificial intelligencea human rights frame risks harms section reframes number controversies generated systems taking human rights lens see classes risks harms fall within purview human rights focus rights found udhr significant human rights treaties international covenant civil political rights iccpr international covenant economic social cultural rights icesrc ratified roughly countries together three documents make international bill rights illus trates human rights indivisible interdependent section provides foundation viewing challenges future ones local problems impacted individual technologies concerns addressable framework universal rights intended starting point rather exhaustive analysis section touch upon five areas human rights nondiscrimination equality political participation privacy freedom expression addition examine rights persons disabilities help anticipate harms human dignity vulnerable groups allow develop technologies advance human rights nondiscrimination equality mentioned bias discrimination become central topics concerned governance social impact number high profile studies demonstrated case detecting skin color certain systems inherently discriminatory alarming reports detailed discriminatory algorithms already deployed justice system wherein judges use tools sentencing purport predict likelihood criminal defendant automating inequality virginia eubanks details government actors implement automated surveillance technologies harm marginalized eubanks studied automated systems discriminated poor receipt data society governing artificial intelligencegovernment assistance automating inequality includes discussion allegheny family screening tool afst predictive risk model deployed county office children youth families forecast child abuse neglect afst one step process includes human eubanks argues makes workers agency question judgment already subtly changing intake screeners moreover system override human automatically trigger investigations reports model inherent flaws contains information families use public services making effective targeting poor discriminatory effects lead harms human rights areas education housing family work governments already using algorithmic systems classify people based problematic categories example reports government china deploying systems categorize people social social credit system developed collect data chinese citizens score according social trustworthiness defined government system punitive functions shaming debtors displaying faces large screens public spaces blacklisting booking trains historically seen governments use national systems social sorting along predetermined physical categories lead discrimination marginalized groups south africa classification system built databases sorted citizens pseudoscientific racial taxonomies deployed implement racist violent policies apartheid regime case serves important cautionary tale widespread deployment social scoring sys without safeguards even systems built mundane bureaucratic functions repurposed enact discriminatory policies control importance equality nondiscrimination filtered ratification treaties provide basis constitutions state law judicial example south african constitution adopted directly accounted discriminatory policies past constitution establishes equality human dignity human rights legal foundations core values attempts frame discrimination machine learning algorithms human rights issue recent world economic forum wef report raised concerns possible solutions biased report calls human rights move center discussions even intention discrimination machine learning systems success strictly measured terms efficiency profit may end achieving expense company responsibility respect human data society governing artificial intelligencethe report challenges companies prioritize compliance human rights standards perform due diligence among recommendations call companies actively include diversity input norms systems design companies also encouraged provide mechanisms access redress make developers responsible discriminatory outputs may amnesty international access led drafting toron declaration protecting rights equality machine learning systems document grounds current attention bias binding international legal principles toronto declaration outlines responsibilities states private sector actors respect use machine learning systems including mitigating discriminatory effects transparency provision effective remedies harmed remains seen influential declaration become organizers currently process seeking endorsements particularly companies even represents significant effort translate fundamental human rights space political participation report brookings institution states advancements artificial intelligence cyber capabilities open opportunities malicious actors undermine democracies covertly effectively seen russian disinformation campaigns automated bots social media highlighted researchers attempts interfere american presidential designed mimic human behavior online conver sations detecting online bots weaponized spread disinformation political discourse could become difficult bots many useful purposes including helping search engines find content yet designed malicious purpos spreading disinformation identified platforms like undercuts possibility informed citizenry needed meaningful democratic elections viewed human rights lens use automated system bad faith actor creates human rights liability demands redress mark zuckerberg written submission congress stated badfaith actors instance operatives russian government able manipulate political process studies demonstrated bots continue used manipulate media countries across world interfere outcomes democratic data society governing artificial intelligencethe rights around political participation referenced example right right equal participation political public affairs iccpr viewed human rights lens use automated system actor creates human rights liability demands redress yet finding right remedy one contentious areas platform technology today platforms likely remove bots violate terms service rather protect users right political participation exploration would needed see human rights principles could inform contractual dis putes litigation context privacy privacy long major concern broad field includes government business academia civil society organizations example surge interest developers engineers follow principles demonstrate norms incorporated level conducting privacy impact assessment technological deployments established tool privacy compliance yet already see tensions around human right privacy development instance stanford university researchers trained deep neural network predict sexual orientation subjects without obtaining consent using set images collected online dating beyond various methodological short comings research demonstrated disregard privacy rights increases risks algorithmic surveillance data collected analyzed threatens reveal personal information users put individuals groups risk particularly living regimes would use information repress developers treat privacy ethical preference fundamental human right would strengthen privacy considerations already exist industry norms technical standards another example amazon facial recognition software made widely available july american civil liberties union aclu researchers ran experiment matching pictures members congress database public images arrested individuals researchers found software produced false matches also racially biased since amazon sold software police departments aclu expressed concern use facial recognition government surveillance pervasive opaque data society governing artificial intelligenceif developers treat privacy fundamental human right rather ethical preference privacy considerations already exist industry norms technical standards would right privacy found article universal declaration article iccpr number human rights documents national constitutions national international human rights law principles around privacy help developers analyze identify respond emerging risks capabilities demonstrated stanford study give glimpse threaten privacy rampant collection data capacity subjects concerns recently documented report human rights organizations article privacy international notes consumer products frequently equipped sensors generate collect vast amounts data without knowledge consent report states used infer sensitive facts relatively mundane data learning people emotional states health politics others data like location histories social media protecting right privacy key enjoyment number related rights freedoms expression association political participation information freedom expression right freedom expression particularly important environment wherein social media platforms use algorithms decide whose voices hear researchers cornell collaborated facebook undertake study examining emotions spread social network researchers manipulated experience almost facebook users using sentiment analysis tool identify friends posted negative comments posts negative posts removed users newsfeeds test whether algorithmically skewing feed display positive posts would keep users site study demonstrates platforms make decisions based users expressions cause world appear certain ways strengthening one reality weakening right freedom expression cornerstone fundamental human rights found article universal declaration social media platforms become central place public discussion happens strong debate role platforms content hate speech false news media manipulation circulating platforms like facebook twitter legislators public calling companies address problem calls action met concerns private companies meaningfully determine boundaries speech example david kaye special rapporteur right freedom opinion expression expressed data society governing artificial intelligenceconcern content moderation systems could even unintentionally censor minority opinions unpopular yet critical forms free nyu center business human rights argues governance technology platforms states government intervention also relentless task content moderation requires making difficult decisions standards subsequent application kaye goes indicate murky environment putting human rights center debate offers states companies key stakeholders practical standards guide content regulation would also apply deploying automated report delve far contentious important note human rights perspective informs human rights absolute decisions tradeoffs involve questions around proportionality balancing legal social impact relative multiple rights frame offers language analyze balance right freedom expression rights freedoms political participation information assembly association privacy security disability rights approach accessible design convention rights persons disabilities adopted reaffirms anyone disability treated human dignity included enjoyment fundamental human rights disability rights become emblematic technological development increases risk vulnerable groups also present clear opportunity enhance human rights convention signed countries ratified countries reaffirms rights nondiscrimination establishes principles like universal design accessibility backing international human rights regulation industry standards guidance pressure disability rights activists developers could mitigate risk disparate impacts people disabilities design stage rather deployment report new technologies australian human rights commis sion identified lack accessibility fundamental report observes almost one five australians live disability argues citizens rights protected international human rights law convention rights persons disabilities government australia ratified along related national laws commission lays plan leverages international human rights law australian law nonbinding guidelines compliance frameworks accessibility models necessary stakeholder consultations address convention disabilities partly inspired american disabilities act ada law backed enforcement mechanisms ada become influential tech industries apple example become market leader accessibly features automated programs verbalize content data society governing artificial intelligenceyet companies netflix automatically comply ada simply became law took years advocacy public pressure disability rights groups lawsuit national association deaf force netflix make platform accessible adding closed captioning online videos industry also motivated change policies accessible design structured negotiations method dispute resolution advocates companies rather underscores broader point applying human rights governance international level entails law regulation change needs come additional forces including market incentives public awareness local activism technological innovation would make compliance easier working disability rights made great progress least big tech companies model product design could integrated kinds rights precedent illustrates companies developers use inherent respect human dignity human rights act anticipated harms proactively addressing negative impacts case accessibility people disabilities developers take steps advance human rights similar way working look number human rights issues anticipate social risks like health education issues like migration protection marginalized groups conflict zones like myanmar scratches surface human rights applied systems yet fully integrating human rights approach building maintaining systems would require change tech industry culture organizations example would need see human rights integrated product design teams statements corporate social responsibility human rights values would need infused workflow organization part jobs employees working quality assurance test suites product design documentation working disability rights made great progress least big tech companies model work kinds data society governing artificial intelligencestakeholder overview recently stakeholders initiated number activities intersection human rights section provides snapshot current landscape business government intergovernmental organizations civil society academia discussion focus human rights activity business short examples activities civil society governments intergovernmental organizations academia data society governing artificial intelligencebusiness ethics topic jour tech industry human rights beginning emerge additional perspective microsoft completed first human rights impact assessment hria major tech company released late hrias tablished methodology business sector used examine impact product action viewpoint rights direct consumers external depending trans parent microsoft hria report others industry may learn operationalize human rights due diligence products addition new approaches algorithmic impact assessments may inform traditional hria increasingly advocates concerned employees able exert meaningful pressure big tech companies political firm cambridge analytica surreptitiously gained access private data tens millions facebook users influence voting behavior number nonprofits investment groups sent open letter facebook largest institutional shareholders letter claimed company failing assess address longstanding yet urgent human rights problems including critical concerns regarding civil political privacy furthermore tech workers organized public campaigns pressure employers stop building technologies may used governments social april around google employees sent letter ceo demanding company cease contract participate development project called maven department letter cited biased weaponized google later said planned renew contract project maven june google released statement principles said would still work defense industry develop importantly google states design deploy technologies whose purpose contravenes widely accepted principles international law human august google employees signed another letter expressing concern company work search engine china would censor google principles indicate engagement human rights google employee letters appealed moral ethical concerns vague terms rather human rights data society governing artificial intelligencethese letters follow trend tech employees pressuring companies live aspirational missions hot button issues migration june microsoft received letter employees demanding cancel contract immigration cus toms enforcement ice citing human rights concerns related ice forced separation migrant refugee parents children july president microsoft released statement calling gov ernment regulation facial recognition technology explicit appeal protect fundamental human rights freedom expression privacy statement reveals customer requests facial recognition turned company deployments determined pres ent greater human rights unclear determinations made formal hria underscore importance developing litmus test whether given technology deployed specific context based human rights risks one tragedies facebook myanmar issue company apparently respond adequately repeated attempts civil society human rights groups academic researchers alert company hate groups using platform harm users tech companies already teaming civil society organizations address social harms one tragedies facebook myanmar issue company apparently respond adequately repeated attempts civil society human rights groups academic researchers alert company hate groups using platform harm would take facebook similar technology organization meaningfully hear human rights activists researchers far work needed develop functioning model tech industry leadership listens acts warning signs since senate hearings facebook stated would implement positive changes hiring staff monitor problem including burmese language skills working local groups identify hate speech nonetheless report reuters human rights center university law school subsequently found platform efforts effectively curtailed hate speech data society governing artificial intelligencecivil society major international human rights organizations starting focus additional attention needed civil society potential risks harms difficult civil society organizations especially smaller ones global south find ways engage organizations developing countries may therefore see field dominated powerful countries amnesty international launched initiative human rights noting built humans shaped human values build systems mirror current societies riddled historical biases inequalities human rights watch also building program investigating impacts global symposium artificial intelligence inclusion brazil highlighted need foster diverse voices research development digital asia hub hong kong leading discussions provides model research engagement topics important region wef continuing council address future human rights developing project preparing civil society respond challenges digital emerging technologies governments dozens countries initiated national strategies yet human rights central many efforts governments seeking regulatory stance others starting focus human rights impact states enacted legislation would direct human rights impact yet european union demonstrated interest regulating technology companies appeal principles general data protection regulation gdpr establishes new protections european citizens rights around data protection privacy impacts organization collecting european residents data society governing artificial council europe study notes growing concern political public level globally regarding increased use algorithms automated processing techniques considerable impact exercise human moreover council europe commissioner human rights argued safeguarding human rights era particular rights privacy equality freedoms expression assembly june canada france called creation international study group become global point reference understanding sharing research results artificial intelligence issues best global affairs canada digital inclusion lab leading discus sions human rights canada treasury board exploring algorithmic impact assessment procurement practices includes systems impact individual liberty australia human rights commission launched project directly address human rights impact emerging technologies includes robust engagement international human rights law may serve guide new york city passed law aims help ensure algorithms used city agencies transparent fair valid setting task force make recommendations algorithmic regulation transparency bias rules apply new york appeal human rights directly move regulate may become model united nations yet sustain focus rights notable exceptions particularly independent investigators special rapporteurs secretary general strategy new technology noted investigators found evidence facebook used exacerbate hate violence myanmar despite platform use algorithms identify hate special rapporteur right freedom opinion expression david kaye expected present report late investigates impact responsibilities tech companies protect human rights official visit special rapporteur extreme poverty human rights philip alston urged actors give attention data society governing artificial intelligencethe role automation robotization job insecurity well examine possible solutions like universal basic addressed pressing issue autonomous weapons addition international humanitarian law conduct war strong human rights dimension right security person civilians caught conflict needs september secretary general released strategy new technologies seeks align use technologies like global values found charter udhr international intergovernmental organizations intergovernmental organizations may play influential role including organisation economic cooperation development oecd preparing guidance related member oecd guidelines multinational enterprises aligns guiding principles human rights calling companies protect human rights countries operate conduct human rights due diligence provide mechanism accountability notably oecd guidance requires system national contact points governments member countries appoint representatives hear grievances company national contact point system potential example mechanism redress although oecd produces soft law nonbinding could provide forum address human rights impacts arise deployed data society governing artificial intelligenceacademia work done bridge academics human rights law social science computer science philosophy disciplines order connect research social impact norms ethics technical development policy scholars harvard university published report human rights canadian government called urgent human rights agenda argued emerging model governance must situated interact existing institutional frameworks applicable laws policies particularly human university essex urged house lords united kingdom select committee human approach sit centre development use artificial intelligence enabling holistic consistent universal enforceable june stanford university global digital policy incubator held conference design human confer ence included conversation high commissioner human rights founder silicon valley organization openai discussion highlighted need translation work human rights proponents technologists data society governing artificial intelligenceconclusion today debates searching principles govern emerging future technological systems common good good involves upholding human dignity international human rights system fit purpose researchers developers designers work protect respect fundamental human rights could open path broad social benefit disregard human rights would close path researchers developers designers worked protect respect fundamental human rights could open path social benefit disregard human rights would close path course human rights limitations international human rights law principles cover broad class risks harms equipped address known unknown concerns pertaining instances systems negative social impacts identifiable anticipat terms human rights human rights systems supported globally deliberative bodies gained legitimacy treaty system national laws still many critics terms human rights human dignity long histories replete intense controversies intrinsic philosophical political reflecting current geopolitical moment outgoing high commissioner human rights warned universal rights system attack chauvinistic nationalism promotes common data society governing artificial intelligenceeven bring human rights center governance discussions gaps would remain rights principles design development deployment usage integrating desirable value sociotechnical system perennial essence human rights approach would need fully integrated organizational contexts technologists academics researchers well social contexts users may also find might influence evolution human rights dignity future work area focus human rights approach could practically implemented policy practice organizational change goal report offers initial recommendations technology companies find effective channels communication local civil society groups researchers particularly geographic areas human rights concerns high order identify respond risks related deployments technology companies researchers conduct hrias throughout life cycle systems researchers reevaluate hria methodology particularly light new developments algorithmic impact assessments toolkits developed assess specific industry needs governments acknowledge human rights obligations incorporate duty protect fundamental rights national policies guidelines possible regulations governments play active role multilateral institutions like advocate development respects human rights since human rights principles written technical specifications human rights lawyers policy makers social scientists computer scientists engineers work together operationalize human rights business models workflows product design academics examine value limitations interactions human rights law human dignity approaches humanitarian law ethics relation emerging technologies human rights legal scholars work stakeholders tradeoffs rights faced specific risks harms social science researchers empirically investigate impact human rights human rights investigators special rapporteurs continue researching publicizing human rights impacts resulting systems officials participating governments evaluate whether existing mechanisms inter national rights monitoring accountability redress adequate respond rapidly emerging technologies leadership also assume central role international technology debates promoting shared global values based fundamental rights human dignity data society governing artificial intelligencenotes ethically aligned design vision prioritizing human autonomous intelligent systems version ieee december ieee ethically aligned design provides organizing ideas series proposed technical standards governing ethical document still development represents two years stakeholder consultations milestone bridging technologists human rights principles noted however document official code conduct formal code ethics ieee members statement marzuki darusman chairperson independent international mission myanmar session human rights council united nations office high commissioner human rights march facebook social media privacy use abuse data senate committee judiciary april transcript mark zuckerberg senate hearing wash ington post april facebook first quarter results conference call facebook april good global summit itu last accessed august reputational risks clear debate whether corporations held legally accountable international human rights law overview suggests corporations accountable see international human rights law corporations sufyan droubi transnational corporations international human rights law notre dame journal international comparative law vol issue september guiding principles business human rights united nations june industry guidelines also known soft law include oecd guidelines multinational enterprises iso international organization standardization last reviewed confirmed christiaan van veen corinne cath artificial intelligence human rights got data society points may data society governing artificial see madeleine elish danah boyd situating methods magic big data artificial intelligence communication monographs september see kristian lum william isaac predict serve royal statistical society october solon barocas andrew selbst big data disparate impact california law review september arvind narayanan translation tutorial definitions fairness politics presented conference fairness accountability transparency new ork april according royal society definition machine learning systems set task given large amount data use examples task achieved detect patterns system learns best achieve desired output thought narrow machine learning supports intelligent systems able learn particular function given specific set data learn machine learning power promise computers learn example royal society april important note bias technical sense necessarily negative wrong example may want introduce bias model correct inequitable outcomes represented group difficult separate statistical bias social bias current debates brief discussion nuances bias discussions see report vibrant community academic researchers practitioners focused fairness accountability transparency see proceedings machine learning research vol february universal declaration human rights united nations adopted december overview regional human rights implementation americas europe africa see david baluarte christian vos judgment justice implementing international regional human rights decisions open society justice initiative november overview challenges implementation see international institutions global governance program global human rights regime council foreign relations may web august see joy buolamwini timnit gebru gender shades intersectional accuracy disparities commercial gender proceedings machine learning research conference fairness accountability transparency developing new face dataset phenotypically balanced basis skin type existing benchmarks researchers data society governing artificial intelligencewere able demonstrate commercially available gender classifying algorithms tested lowest accuracy darker skinned females see also simonite machines aught photos learn sexist view women wired august van veen cath artificial intelligence human rights got supra note also see jason pielemeier advantages limitations applying international human rights framework artificial data society points june world conference human rights june vienna austria office united nations high commissioner human rights last accessed august joshua kroll accountable algorithms university pennsylvania law review vol issue borocas selbst big data disparate impact supra note frank pasquale black box society cambridge harvard university press workshop primer ethics july alex campolo report jeff larson surya mattu lauren kirchner julia angwin analyzed compas recidivism algorithm propublica may virginia eubanks automating inequality martin press see also safiya umoja noble algorithms oppression search engines reinforce racism new ork university press cathy neil weapons math destruction crown random house eubanks automating inequality chapter big brother watching china compiling computer ratings citizens south china morning post international edition november notice state council printing distributing outline construction social credit system state council people republic china june meg jing zeng china social credit system puts people pressure model citizens conversation january geoffrey bowker susan leigh star sorting things classification conse quences mit press human rights council defines discrimination distinction exclusion restriction data society governing artificial intelligencepreference based ground race color sex language religion political opinion national social origin property birth status purpose effect nullifying impairing recognition enjoyment exercise persons equal footing rights freedoms ccpr general comment human rights committee hrc november prevent discriminatory outcomes machine learning world economic forum march ibid oronto declaration protecting rights equality machine learning systems may alina polyakova spencer boyer future political warefare russia west coming age global digital competition brookings march amelia acker tracking disinformation reading metadata media manipulation dis patches field july jon swaine twitter admits far russian bots posted election disclosed guardian january transcript mark zuckerberg senate hearing washington post supra note alice marwick rebecca lewis media manipulation disinformation online data society may see also jonathan ong architects networked disinformation newton february see ann cavoukian privacy design foundational principles information privacy commissioner ontario privacy data protection design policy engineering european union agency network information security december yilun wang michal kosinski deep neural networks accurate humans detecting sexual orientation facial images journal personality social psychology preprint data society governing artificial analysis critique see jake metcalf study approved irb gayface research hype pervasive data ethics gap pervade eam november see also melanie penagos systems research revealing sexual orientation case study human rights workshop data society research institute april jacob snow amazon face recognition falsely matched members congress mugshots aclu july data privacy process ieee standards association last accessed august article iccpr states one shall subjected arbitrary unlawful interference privacy family home correspondence unlawful attacks honour reputation everyone right protection law interference inter national covenant civil political rights office united nations high commissioner human rights adopted december privacy freedom expression age artificial intelligence privacy international article april ibid adam kramer experimental evidence emotional contagion social networks pnas vol aina bucher oxford university press article states everyone shall right hold opinions without interference every one shall right freedom expression right shall include freedom seek receive impart information ideas kinds regardless frontiers either orally writing print form art media international covenant civil political rights office united nations high commissioner human rights adopted december philip napoli robyn caplan media companies insist media companies wrong matters first monday vol may data society governing artificial report special rapporteur promotion protection right freedom opinion expression united nations general assembly april nyu stern center business human rights harmful content role internet plat form companies fighting errorist incitement politically motivated disinformation november report special rapporteur promotion protection right freedom opinion expression united nations general assembly april see robyn caplan lauren hanson joan donovan dead reckoning navigating con tent moderation fake news data society convention rights persons disabilities optional protocol united nations human rights echnology issues paper australian human rights commission july ibid ada may influenced convention rights persons disabilities president barack obama signed treaty senate yet ratify convention rights persons disabilities united nations treaty collection status august accessibility apple last accessed august microsoft also market leader see accessibility microsoft last accessed august lainey feingold structured negotiation winning alternative lawsuits american bar association see also lainey feingold shifting fear motivation alking digital accessibility law accessibility december keith hiatt personal interview august microsoft global human rights statement microsoft last accessed see conducting effective human rights impact assessment guidelines steps data society governing artificial intelligenceexamples business social responsibility march human rights impact assessment guidance oolbox danish institute human rights see andrew selbst disparate impact big data policing georgia rev dillon reisman jason schultz kate crawford meredith whittaker algorithmic impact assessments practical framework public agency accountability institute april open letter ceos facebook largest institutional shareholders may ron amadeo google employees revolt say company shut military drone project ars echnica april letter microsoft workers satya nadella june daisuke wakabayashi scott shane google renew pentagon contract upset employees new ork times june sundar pichai google principles keyword google june critique google principles human rights perspective see lorna mcgregor vivian google new principles need better protecting human rights conversation june kate conger daisuke wakabayashi google employees protest secret work censored search engine china new ork times august mark latonero ech companies speak refugees immigrants harvard business review may letter microsoft workers satya nadella june data society governing artificial brad smith facial recognition echnology need public regulation corporate responsibility microsoft july libby hogan myanmar groups criticise zuckerberg response hate speech facebook guardian april steve stecklow hatebook facebook losing war hate speech myanmar reuters august salil shetty artificial intelligence good amnesty international june david albot levin kim elena goldstein jenna sherman charting roadmap ensure artificial intelligence benefits berkman klein center november preparing civil society fourth industrial revolution world economic forum regulation european parliament council april protection natural persons regard processing personal data free movement data repealing directive general data protection regulation last accessed august council europe algorithms human rights study human rights dimensions automated data processing echniques possible regulatory implications march statement artificial intelligence government canada last modified july digital inclusion lab global affairs canada artificial intelligence human rights owards canadian foreign policy unpublished draft michael karlin canadian algorithmic impact assessment march note personal blog post rather government statement human rights echnology australian human rights commission may data society governing artificial julia powles new ork city bold flawed attempt make algorithms accountable new orker december local law relation automated decision systems used agencies new ork city council van veen cath artificial intelligence human rights got supra note statement marzuki darusman chairperson independent international mission myanmar session human rights council united nations human rights council march aspx report special rapporteur extreme poverty human rights united nations human rights council march pathways banning fully autonomous weapons united nations office disarmament affairs october piccone international law regulate autonomous weapons brookings institution april strategy new echnologies united nations oecd previously released guidance big data see oecd guidelines multinational enterprises oecd big data bringing competition policy digital era oecd november implementing oecd guidelines multinational enterprises national contact points oecd oecd guidelines multinational enterprises human rights oecd see raso krishnamurthy artificial intelligence human rights opportunities risks berkman klein center internet society research publication forthcoming urs gasser virgilio almeida layered model governance harvard university november see separately matthias risse human rights artificial intelligence urgently needed agenda harvard kennedy school may data society governing artificial submission house lords select committee artificial intelligence human rights big data echnology project written evidence human rights big data echnology project september building trust democracy human rights design stanford center democracy development rule law christopher mccrudden understanding human dignity oxford university press opening statement global update human rights concerns high commissioner human rights zeid hussein session human rights council united nations human rights council june gap see mark ackerman intellectual challenge cscw gap social requirements echnical feasibility human computer interaction data society governing artificial intelligenceacknowledgments author would like express appreciation individuals generously reviewed report aaina agarwal miranda bogen corinne cath tim engelhardt madeleline elish eimear farrell iason gabriel janet michael karimian hibah maroussia levesque jake metcalf carly nyst maria sapignoli brittany smith cristiaan van veen keith hiatt lent keen insight technology disability rights zachary gold made invaluable contributions melanie penagos provided key research support patrick davison provided astute editorial guidance critical feedback entire team data society supported project innumerable ways sue glueck sparked key ideas continue inspire work report animated ideas generated workshop artificial intelligence human rights held data society april workshop attendees came across sectors including global affairs canada usaid new york city government lisbon council oecd united nations office high commis sioner human rights accenture microsoft deepmind google facebook gensler research institute carnegie mellon university cornell university oxford internet institute princeton university new york university university california berkeley max planck institute data society digital asia hub global network initiative business social responsibility world economic forum human rights watch privacy international article accessnow amnesty international ieee open society foundations ford foundation rockefeller foundation following workshop body published work emerged aubra anthony corinne cath christiaan van veen elizabeth eagan sherif jason pielemeier enrique piracs ben zeverbergen highly instructive also foundational conversations dan bross steve crown eileen donahoe hannah hilligoss mark hodge dunston allison hope alexa koening vivek krishnamurthy dinah pokempner filippo raso inclusion organizations individuals convey endorsement report errors remain author alone correspondence report please contact mark latonero mark data society governing artificial intelligencedata society data society independent nonprofit research institute advances new frames understanding implications automated technology conduct research build field actors ensure knowledge guides debate technical choices datasociety
