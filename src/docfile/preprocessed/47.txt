responsibility repared expert committee human righ dimensions automated processing different forms tificial intelligence council europe study apporteur karen yeung dgi study implications advanced digital technologies including systems concept responsibility within human rights framework repared expert committee human rights dimensions tomated data processing different forms artificial intelligence apporteur karen yeung council europe study french edition esponsabilité opinions expressed work esponsibility authors necessarily eflect official policy council europe requests concerning reproduction translation part document addressed directorate communication strasbourg dex publishing correspondence oncerning document addressed rectorate general human rights rule law ver design documents publications pro duction department spdp council europe pho tos shutterstock publication spdp ditorial unit correct typographical grammatical errors council europe september pri nted council europe dgi table contents ntroduction xecutive summary hapter introduction scope study structure study understanding implications concepts responsibility implications concept responsibility human rights perspective hapter threats risks harms wrongs associated ith advanced digital technologies rise algorithmic adm systems adm systems systematically threaten particular rights societal risks associated profiling collective societal threats risks generated technologies malicious attacks unethical system design unintended system failure loss authentic real meaningful human contact chilling effect data repurposing digital power without responsibility hidden privatisation decisions public values exploitation human labour train algorithms power asymmetry threats foundations moral democratic community summary hapter bears responsibility threats risks harms wrongs posed advanced digital technologies responsibility matter dimensions responsibility advanced digital technologies including implicate existing conceptions esponsibility prospective responsibility voluntary ethics codes responsible project machine autonomy alleged control problem models allocating responsibility models models strict responsibility council europe study mandatory insurance responsibility challenges posed complex dynamic systems problem many hands interaction unpredictable dynamic interactions complex systems state responsibility ensuring effective protection human rights mechanisms enforcing responsibility advanced digital technologies technical protection mechanisms regulatory governance instruments techniques standard setting monitoring enforcement reinvigorating human rights discourse networked digital age summary hapter conclusion ppendix eferences dgi introduction terms reference steering committee media information society msi biennium committee ministers council europe aske cdmsi study development use new digital technologies services ncluding different forms artificial intelligence may impact peoples enjoyment uman rights fundamental freedoms digital age view giving guidance ture field approved committee experts human rights imensions automated data processing different forms artificial intelligence subordinate structure facilitate work cdmsi first meeting march expert committee decided focus study implications concept responsibility within human rights frame work karen yeung appointed rapporteur preparation study omposition committee experts raham bernstein professor informatics university zürich orge cancio international relations specialist federal office communications swi tzerland uciano floridi professor philosophy ethics information oxford university sed gürses assistant professor technical university delft gab rielle guillemin senior legal officer article atali helberger professor information law university amsterdam uukas ilves chair deputy director senior fellow lisbon council tanja kerševan smokvina state secretary ministry culture slovenia mcnamee independent consultant genios nastos head information unit ministry digital policy telecoms media greec ierluigi perri professor computer law university milan lfgang schulz professor law university hamburg karen eung interdisciplinary professorial fellow law ethics informatics university irmingham council europe study executive summary vanced digital technologies services including specific artificial intelligence ring extraordinary promise already generated substantial benefits articularly form enhanced efficiency accuracy timeliness convenience across range digital services emergence technologies also accompanied rising public anxiety ncerning potentially damaging effects individuals vulnerable groups ciety generally technologies force good enables rather undermines individual societal flourishing imperative acquire eeper understanding concerns require acquire deeper nderstanding impact enjoyment human rights fundamental freedoms also entails careful consideration questions concerning responsibility lie adverse consequences thi study begins premise within contemporary constitutional democratic rders society concepts institutions practices responsibility critical mportance necessary order ensure individuals organisations propriately held account adverse effects actions others order est ablish maintain foundations trustworthy peaceful social cooperation ordination acco rdingly purpose study examine implications advanced digital chnologies including concept responsibility particularly far might mpede enjoyment human rights fundamental freedoms protected echr responsibility risks consequences allocated methodological approach interdisciplinary drawing concepts academic scho larship law humanities social sciences limited extent mputer science concludes take human rights seriously globally nnected digital age allow power advanced digital technologies stems develop implement accrued exercised without respo nsibility nations bear primary duty protect human rights must therefore ensu wield derive benefits designing developing deploying technologies held responsible adverse impacts includes obligations ensu effective legitimate institutional mechanisms operate revent forestall violations human rights technologies may threaten att end health larger collective shared environment uman rights rule law anchored summary gives brief overview content report hapter introduction apter outlines technologies work refers set advanced technologies use techniques statistics computer sci ence cognitive psychology enable machines highly complex tasks efficiently technologies aim either reproduce surpass abilities would require ntelligence humans reasoning autonomy creativity etc describes chnologies work using machine learning enabling computational systems learn dgi examples data experience consequently perform specific tasks intelligently plains machine learning technologies raise issues responsibility due capacity enable task automation enable machines make decisions perform tasks extent independently human developers chapter draws attention capacity machine learning systems learn change ver time dynamically setting ability adapt local nditions via external sensor information updated input data human designers stems decide upon set initial parameters overarching goal stems intended optimise time machine learning systems designed perate making independent decisions choose alternatives ways advance without human intervention systems learn dynamically iteratively environment often olatile continuously changing implications stability predictability thei operation particular systems potential evolve unexpected ways ction apter explains context contemporary global data infrastructure chnologies display range properties direct implications concept responsibility including inscrutability opacity complex dynamic nature reliance human input interaction discretion general purpose nature global interconnectivity scalability ubiquity reliance large automated continuous operation often capacity generate hidden insight merging data sets ability accurately imitate human traits greater software complexity include vulnerability failure malicious attack capacity personalise configure individual choice environments capacity configure social choice environments thus redistributing risks benefits ptimise goal section chapter also explains interdisciplinary human rights perspective adopted stud draws human rights fundamental freedoms protected echr order understand nature risks adverse consequences generated advanced igital technologies help identify responsibility threats risks consequences att ributed allocated inform consideration kinds institutional mechanisms may needed ensu human rights effectively protected nally discussion draws attention existing work concerning adverse impact chnologies human rights fundamental freedoms upon discussion apter seeks build council europe study chapter threats risks harms wrongs associated advanced digital technologies apter two examines range adverse consequences potentially associated use vanced digital technologies begins considering context chnological innovation suggesting advances networked digital technologies likely prompt changes social economic life scale magnitude unsettling disruptive original industrial revolution resulting new industrial rev olution dawning may resemble original industrial revolution likely enerate myriad benefits might also generate unintended adverse effects recognised time revolution unfolding accordingly making reliable redictions aggregate cumulative effects current networked digital rev olution time extremely challenging discussion considers use algorithmic making adm systems rely profiling techniques may threaten several human rights section cluding rights fair trial due process art echr particularly adm systems sed automate decisions significantly affect individuals yet typically deny affecte individual opportunity participate contest otherwise challenge utcome decision inputs systems ncapable producing explanation underlying logic terms intelligible comprehensible individual rights freedom expression information art echr particularly given owerful influence global digital platforms exert informational env ironments individuals societies automated algorithms typically ecide handle prioritise distribute delete remove content nline including political electoral campaigns although platforms seeking voluntarily identify remove extremist content seri ous risks activities may meet art requirements legality egitimacy proportionality permissible interference freedom expression rights privacy data protection art echr due reliance rofiling technologies collection processing digital data gleaned tracki behaviour individuals highly granular level across population use techniques invariably affect article right private family life though contemporary data protection regimes modernised conv play mportant role safeguarding rights interests data subjects might ractice provide effective comprehensive protection rights protection discrimination exercise rights freedoms art echr may implicated due significant risks bias discrimination arising fro use machine learning algorithms due opportunities bias gorithm developers bias built del upon systems built biases nherent data sets used train models biases introduced systems implemented real world settings biases might violate right rotection discrimination exercise rights freedoms protected may also reinforce biases groups historically dgi disadvantaged thereby compounding exacerbating discrimination structural isadvantage discussion considers profiling techniques employed scale implicate collective values interests make practices pervasive sur veillance personalisation manipulation possible population level ways risk ndermining human dignity autonomy example systematically treating individuals bjects rather moral subjects section adverse social implications might accompany development use chnologies generally including rely profiling individuals nsidered section include risks harm malicious attacks unethical system design unintended system failure loss authentic real meaningful human contact chilling effect data repurposing exercise digital power without responsibility hidden privatisation decisions public values including distributive justice exploitation human labour train algorithms nally discussion highlights power asymmetry develop ploy technologies interact subject section whi digital service providers relevant third parties utilise systems acquire ery detailed data users services mine enerate predictions user traits tastes preferences considerable accuracy sers typically understand complexities digital technologies use equivalent access detailed information organisations firms whose services use opacity asymmetry expands opportunities potential exploitation may substantially threaten collective values interests readily expressed existing human rights discourse including threats chnical foundations moral democratic community collective threats risks exacerbated capacity technologies operate unprecedented speed scal generating novel threats risks challenges contemporary societies istorically confront time also likely generate problems llective action although aggregate adverse effects may large effect articular individual may relatively minor remedial action may sought bears responsibility threats risks harms wrongs posed advanced digital technologies apter considers bears responsibility adverse consequences posed advanced igital technologies begins clarifying mean responsibility respo nsibility matters emphasising vital role institutions practices respo nsibility holding account whose actions adverse impacts upon others collective interests values institutions practices serve vital role sec uring enabling peaceful trustworthy social giving expression law although concept responsibility understood many different senses highlights distinction council europe study historic retrospective responsibility looks backwards seeking allocate respo nsibility conduct events occurred past prospective responsibility establishes obligations duties associated roles tasks looks future directed towards production good outcomes prevention bad outcomes prospective responsibilities serve important guiding nction offering guidance rights obligations others way behave dealings others argues must attend prospective historic allocation responsibility adverse consequences associated technologies section ave confidence efforts made prevent harms wrongs occurring occur brought end result development mplementation technologies societies must therefore ensure nstitutional structures mechanisms relied upon ensure appropriate repa ration repair prevention harm wrongdoing arising peration technologies investigates advanced digital technologies including implicate existing nceptions responsibility section end highlights differences ncept moral responsibility one hand legal responsibility unlike orality law highly developed system institutionalising enforcing respo nsibility including application sanctions must adjudicate real world isputes also important bear mind distinction two separate distinct beit sometimes overlapping types adverse effect arise operation stems violations human rights including rights protected echr tangible harm human health property environment thi study primarily concerned analysing responsibility human rights violations rath tangible harm focusing primarily create develop deploy reside systems settings responsibilities nation states ensu human rights adequately protected systems operate time space new unprecedented ways chnologies may challenge existing conceptions responsibility chapter considers core themes raised contemporary discussions concerning adverse effects chnologies first role tech industry promulgating voluntarily committing selves abide called ethical standards argues although voluntary nitiatives many ways welcome codes standards typically lack enfo rcement sanctioning mechanisms therefore relied upon provide effec tive protection section secondly alleged control problem claimed capacity systems operate less autonomously creat ors claimed create responsibility gap developers systems fairly blamed outputs chapter demonstrates called control oblem based particular moral theory responsibility one places undue att ention conduct agent fails give due weight interests victims sec urity person property section dgi discussion chapter identifies briefly outlines range different responsibility models could adopted govern allocation distribution respo nsibility different kinds adverse impacts arising operation systems ction including models based section section strict responsibility section mandatory insurance schemes section order identify models suited allocation historic respo nsibility adverse effects systems analysis emphasises importance istinguishing human rights violations one hand tangible harm human ealth property environment although single event may result tang ible harm violation human rights responsibility rights violations kind ncluding human rights violations widely understood strict thus provided uman rights violation established need proof fault contrast allocation obligations repair tangible harm health property may legally istributed accordance variety historic responsibility models model strikes ifferent balance interest agents freedom action interest ictims rights interests security person property argued none models correct best model allocating distributing arious threats risks harms associated operation advanced digital chnologies rather identifying models appropriate entail social policy choice concerning appropriately allocated distributed apter draws attention several acute challenges arise seeking allocate respo nsibility risks adverse impacts arising operation complex interacting systems section many hands problem arises development operation stems typically entails contributions multiple individuals organisations achine components software algorithms human users often complex ynamic environments problem many hands new rests largely choice theory responsibility moral philo sophy contemporary legal systems ave developed relatively sophisticated set principles procedures etermining liability involving multiple defendants understood aving causally contributed adverse event law ability devise ractical effective responses many hands problem partly due reater emphasis law places legitimate interests victims otential victims security person respect law response differs fro choice theories responsibility moral philosophy focus almost clusively focus moral agent moreover relation human rights iolations arising operation systems discussion highlights mportance mechanisms prevent forestall human rights violations arising fro application advanced digital technologies need effective revention particularly important aggregate cumulative effect technologies could seriously threaten collective foundations necessary council europe study human rights fundamental freedom operate practice threats point nee enhance reinvigorate human rights discourse protection riven age section interaction acute challenges arise appropriately allocating istributing responsibility humans machines particularly uman loop recurring concern order ensure mplex systems incorporate always operate service umanity always designed shut human perator yet individuals entrusted responsibility supervise operation systems may understandably reluctant intervene risks turning umans placed loop moral crumple zones largely totemic humans whose central role becomes soaking fault although partial control stem vulnerable scapegoated tech developers rganisations seeking avoid responsibility unintended adverse consequences ction interacting algorithmic systems even intractable challenges arise seeking dentify anticipate prevent adverse events arise interactions etween complex systems occur speed scale simply possible age stock arket flash crash unpredictable nature interactions ultiple algorithmic systems generates novel potentially catastrophic risks barely begun grasp let alone anticipate forestall section problems warrant sustained attention consideration whi discussion chapter focuses responsibility technology esigners developers implement systems rely upon chnologies discussion section reminds states bear primary bligation ensure human rights effectively protected draws attention roblem collective action operation systems global networked age likely generate highlighting vital importance national legislation ensure human ghts protected need properly resourced national enforcement authorities equate enforcement powers valuable role accessible convenient llective complaints mechanisms addition individual legal remedies may play ensure effec tive human rights protection discussion draws attention range mechanisms potential help secure prospective historic responsibility adverse impacts stems including various kinds impact assessment auditing techniques technical rotection mechanisms section technical protection mechanisms particular nsiderable promise study emphasises need embed mechanisms within overnance framework enables relevant technical standards set transparent participatory manner ensure independent external oversight review peration befo summarising various findings chapter discussion section briefly nsiders whether existing conceptions human rights mechanisms whi protected enforced fit purpose global connected digital suggests power networked digital technologies emerged recent dgi years make possible practices actions previously impossible thereby create ovel threats risks forms wrongdoing accordingly may need reinvigorate human ights discourse networked digital age order protect nurture undations necessary human agency responsibility without human rights freedo practically meaningfully exercised development enhanced reinvigorated conception human rights could lead development new nstitutional mechanisms better placed safeguard adverse effects digital technologies age findings chapter summarised end chapter section apter conclusion apter four concludes summarising argument made preceding sections ighlights four findings arising study fir vital effective legitimate mechanisms prevent forestall uman rights violations given speed scale many advanced digital systems perate ways pose substantial threats human rights without necessarily generating sub stantial risks tangible harm preventative approach especially important given threats could seriously erode social foundations necessary moral democratic rders essential preconditions exercise individual freedom autonomy uman rights may include need develop collective complaints mechanisms faci litate effective rights protection enhance reinvigorate existing conceptions understandings human rights cond model legal responsibility applies human rights violations widely unde rstood one strict responsibility without need proof fault contrast bligations repair tangible harms may legally allocated distributed accordance range responsibility models striking different balance interests agents freedom action interest victims rights interests security ersons property identifying models appropriate preventing various threats risks associated operation advanced digital technologies rather entail social policy choice constitutional democratic cieties committed protecting respecting human rights states bear critical respo nsibility ensuring policy choices made transparent democratic anner ways ensure policy ultimately adopted effectively safegu ard human rights hird nurture support technical research concerned securing prospective historic responsibility ensuring due respect many values underpinning uman rights protection may facilitate development effective technical rotection mechanisms meaningful algorithmic auditing research needs eveloped interdisciplinary engagement technical community humanities social sciences order identify fully human rights rotections translated given expression via technical protection mechanisms bedded within systems understand human rights approach responds roblems urth effective protection human rights global connected digital age requires effective legitimate governance mechanisms instruments institutions council europe study monitor constrain oversee responsible design development implementation peration complex systems requires minimum emocratic participation setting relevant standards existence properly reso urced independent authorities equipped adequate powers systematically gather nformation investigate sanction violations including powers ski lls investigate verify systems fact comply human rights stand ards values nally study concludes serious commitment protect promote uman rights global connected digital age allow power vanced digital technologies systems develop implement accrued exercised without responsibility fundamental principle reciprocity plies deploy reap benefits advanced digital technologies ncluding provision services derive profit must responsible adverse consequences therefore vital importance states committed rotection human rights uphold commitment ensure wield digital ower including power derived accumulating masses digital data held respo nsible consequences follows obligation states ensure rotection human rights duty ensure governance arr angements enforcement mechanisms within national law ensure rospective historic responsibility adverse risks harms wrongs arising peration advanced digital technologies duly allocated dgi study implications advanced digital technologies including systems concept responsibility within hum rights framework karen great global challenge confronts promote human ights rule law states companies civil society sure artificial intelligence technologies reinforce respect ather undermine imperil human rights avid kaye special rapporteur promotion protection ights freedom opinion expression ited nations general assembly ith contributions colleagues ganna pogrebna andrew howes research assistance arlotte elves helen ryland university birmingham grateful imogen goold vice concerning content contours tort law council europe study chapter introduction scope study thi study examines implications new digital technologies services including arti ficial intelligence concept responsibility human rights perspective cuses technologies referred artificial intelligence notoriously difficult efine even technical researchers appear settled upon widely agreed efinition purposes study definition proposed within mmission communication adopted provides arti ficial intelligence refers systems display intelligent behaviour alysing environment taking actions degree autonomy achieve specific goals systems purely acting virtual world voice assistance image analysis software search engines peech face recognition systems embedded hardware devices advanced robots autonomous cars drones internet things pplications technologies require data improve performance perform well help improve automate decision making domain ccordingly study uses term describe set advanced general purpose chnologies enable machines highly complex tasks effectively draw upon set complementary techniques developed statistics computer science gnitive technologies aim reproduce surpass abilities mputational systems would require intelligence humans perform ncluding capacity learning adaptation sensory understanding interaction reaso ning planning optimisation procedures parameters autonomy creativity extracting knowledge predictions large diverse digital scope nquiry limited technologies currently available least initial research evelopment demonstrations plausible next five years particular focus chnologies leveraging machine learning proceeds assumption advances continue improve performance rather achievement eneral concerned use technology purposes undertaking useful tasks rather scientific research tool academic rese undeniable technologies generated extensive benefits particularly enh ancing efficiency accuracy timeliness convenience many services rovided many applications understood enhancing practical reach xtending enjoyment human rights freedoms example without use search eng ines massive volume information available via internet would ractically useful accessible thus enhancing right freedom information protected art european convention protection human rights uropean commission definition elaborated fully high level expert group rtificial intelligence psrc hall pesenti psrc strom use machine learning commercial research scientific research without difficulties see example leonelli metcalfe crawford dgi fundamental freedoms hereinafter echr many national governments regional rganisations around world devoting considerable resources developing strategies foster innovation development technologies based widely shared belief technologies deliver significant benefits terms enhanced effi ciency productivity service yet early triumphs associated vanced networked digital technologies fuelled called boom resul ting arms race accompanied rising public anxiety concerning otential damaging effects technologies individuals society concerns drawn attention questions responsibility lies adverse impacts threats risks purpose importance responsibility rest need ensure within constitutional democratic orders individuals rganisations held account adverse effects acco rdingly primary purpose study examine implications advanced igital technologies including concept responsibility particularly far ight impede enjoyment human rights fundamental freedoms purpose nsiders adverse effects arising development use understood bearing directly upon enjoyment human rights freedoms however indirect adverse effects including associated sks mass unemployment effects excluded sco implications use military applications including autonomous apon systems suggest risks unimportant merely rai particular concerns beyond scope inquiry structure study aim study examine responsibility lie adverse individual societal threats risks consequences associated actual anticipated evelopment application advanced digital technologies particularly continue row power sophistication adopts might understood human rights erspective far human rights fundamental freedoms protected echr help understand nature threats risks consequences elp identify responsibility threats risks consequences attributed allocated consider kinds institutional mechanisms may needed ensu human rights effectively protected responsibility protection uman rights duly end study draws concepts academic european commission committed least technologies spent white recently committed department digital culture media sport department business energy industrial strategy financial times rivalry china see european political strategy centre literature cited section discussion concept responsibility importance questions may ari concerning responsibility positive otherwise beneficial effects hould allocated concern report considering potential adverse impacts vanced digital technologies human rights study focuses responsibility adverse impacts reats risks associated technologies intentional attacks others using describ malicious use brundage ther adverse effects might intended necessarily malicious see examples discussed andvig neil australian human rights commssion observed human rights approa provides ubstantive mechanism identify prevent mitigate risk compared technology council europe study scholarship law humanities social sciences including moral legal olitical philosophy political economy computer science rather focusing case law jurisprudence european court human rights proceeds four cha pters hapter provides basic outline technologies work identifying respo attributes properties technologies ntemporary applications possess hapter examines potential adverse individual collective consequences plication advanced digital technologies may pose begins focusing use riven profiling technologies highlighting may systematically threaten particular ghts well threatening general collective values interests considers threats risks posed technologies contemporary anticipated plications chapter two concludes drawing attention growing power asymmetry etween capacity resources develop employ technologies ndividuals groups populations directly affected use hapter considers responsibility lies addressing potential adverse nsequences particularly ripen rights violations harm including harm llective values interests including might threaten undations democratic freedom human rights anchored considers several egal models responsibility might relied upon allocate distribute risks consequences also identifies several challenges associated seeking ascribe assi responsibility operation highly complex systems pically involved multiple organisations individuals interacting software hardware mponents identifies range potential mechanisms might help address challenges order secure effective legitimate human rights protection hapter concludes understanding implications concepts responsibility order examine implications concept responsibility human rights erspective necessary acquire basic understanding technologies eveloped operate machine intelligence machine learning uch excitement promise potential generate advances mprovements across wide range social domains including industrial productivity health edicine environmental management food security rely power potential achine machine learning technology allows computers perform speci fic tasks intelligently learning examples data although thics turning concepts rights freedoms effective policies practic practical realities ternational human rights principles embody fundamental values human rights approach ives mechanisms tools realise implementation accountabilities australian uman rights commission russell norvig royal society dgi machine learning techniques available time experienced major vances recent years due technological developments enhanced computing power radical increase availability digital data advances enabled evelopment machines humans specific tasks anguage processing analysis translation well image recognition years struggled achieve accurate technologies ubiquitous everyday lives living highly industrialised contemporary societies cieties people regularly interact machine learning systems enable digital serv ices example search engines product recommendation systems avigation systems provide accurate efficient responses user queries ntinually improving performance learning properties order identify advanced digital technologies including challenge existing egal moral social conceptions responsibility important identify attributes properties technologies possess roperties technologies likely affect impact upon others task automation purpose one important properties technologies lies cap acity undertake tasks many formerly required human operators automatically without need direct human achine autonomy vances machine learning techniques resulted development increasing use systems automated operate ways exhibit autonomy though term autonomy commonly used describe many applications ublic policy discussion within technical community appear dely used consensus precisely term means preconditions cha racterising human entity autonomous however policy literature autonomy often used refer functional capacity computational agents erform tasks independently require agent ake decisions behavior thout direct input human operators without human control computational ents kind operate perceiving environment adapting behaviour respo nse feedback concerning task performance decisions acti ons thought fully deterministic outset therefore fully redictable advance due almost infinite variety contexts environments whi agents might understood autonomy range property may royal society example radiologists outperformed image recognition algorithms economist lawyers outperformed functions mangan example human behaviours response driven navigation ystems see girardin blat liu european group ethics science new technologies ege ege also observes eems push even higher degrees automation autonomy robotics mechatronics combination deep learning data science sensor technology iot mechanical electrical eng ineering yet time see development toward ever closer interaction humans machines noting well aligned teams systems human professionals perform better ome domains humans machines separately council europe study less present degrees rather property depending upon extent human oversight intervention required operation machine learning systems distinguished capability learn change dynamically setting ability adapt local conditions via ternal sensor information updated input individual designers system decide set initial state parameters including overarching goal ntended optimise deployed operation outputs system evolve use different environments particular computational systems intended operate ways allow system make independent decisions choose ternatives ways advance without human ntervention current systems determine overarching goal system esigned optimise must specified systems human developers apable determining intermediate goals range levels control involvement human operators system escribed royal academy engineering four different grades control controlled systems humans full partial control ordinary car supervised systems perator instructed programmed lathe industrial machinery automatic systems carry fixed functions without intervention operator elevator tonomous systems adaptive learn make decisions royal academy engineering sae international developed standard taxonomy definitions terms elated motor vehicle automated driving systems sae international sed example department transportation part federal automated vehicles policy department transportation michalski box machine autonomy sensitivity context ntrast vacuum cleaner car fundamentally technical architecture applies overarching purpose set system human designers machine agents capable etermining order achieve purpose behaviour kinds machine agents fully determined utset capable perceiving environment adapting decisions acti ons accordingly yet machines expected operate highly contrasting contexts home env ironments relatively contained stable contrast dynamism mplexity conditions acco rdingly greater stability predictability environment context systems operate foreseeable possible outputs respo nses hence anticipated behaviour vacuum cleaner ikely easier foresee anticipate compared car dgi purposes identifying responsibility lies outputs consequences systems particular importance stability predictability see box systems learn dynamically iteratively environment ften volatile continuously changing means technologies utputs potential evolve unexpected ways means practice chnologies sometimes characterised opacity unpredictability utputs discussed may direct implications whether ways concept responsibility applied decisions actions resulting nsequences addition capacity operate without direct human oversight control chnologies number characteristics including inscrutability opacity concerns opacity nderstood three distinct related first unlike early forms including expert systems relied rule reasoning contemporary achine learning systems create utilise complex models make ifficult trace underlying logic order identify generated articular output forms learning systems enable underlying logic traced understood example utilise others including tho utilise neural networks back propagation secondly even stems utilise algorithms whose underlying operation logic understood explained human terms developed commercial providers openly available scrutiny subject intellectual roperty rights entitling owner rights maintain secrecy thirdly even information system provided chnique used train machine learning algorithm formal rules mputational system lack technical expertise able understand meaningfully comprehend information effectively reducing practical tran sparency combined effect inscrutability opacity gorithms results cha racterisation black boxes properties irect implications transparency explainability accountability plications utilise complexity dynamism technological applications utilise specific social urposes understood highly complex systems nderlying mechanisms work dynamic continual nteraction environments operate complex operational ogic generating outcomes often difficult predict particularly ploying machine learning means understanding anticipating see wagner burrell growing body technical research explainable emerged seeking identify methods hich systems might rendered intelligible humans form opacity recognises human imitations fully comprehending explaining operation complex systems reason ifferently machines zalnieruite see section see example state loomis noto diega burrell pasquale burrell datta weller yeung weller schut wooldridge council europe study function real world contexts extremely challenging even levant technical expertise typically requiring expertise multiple domains human input interaction discretion although advances strongly associated rise machines important recognise humans nvolved every stage development implementation technologies fro origination ideas proposal development design modelling athering analysis testing implementation operation addition systems also often expected operate real world environments stems designed dynamically interact humans many cases ntended scale facebook news feed system particular many plications utilise designed formally preserve human discretion stem output offered user recommendation rather executing automated decision thus example digital product reco mmendation engines offer product suggestions users human user retains rmal authority deciding whether act upon reco mmendation may significant implications concept respo general purpose technology technologies understood general purpose conceivably applied almost limitless range social domains ersatility means technologies characterised classic dual use chnologies motivations application may range benevolent sel global interconnectivity ubiquity scalability important recognise lobal interconnectivity reach internet technologies ave enabled swift technologies massive scale particularly rap widespread smart networked devices many applications used aily individuals industrialised world become ubiquitous given effi ciency convenience offer managing routine tasks involved ntemporary life means practice rapidly becoming impossible nceive modern living without yet reach penetration networked ata infrastructure smart connected devices global south rem ains poor limited compared global north living areas equivalent access services improvements efficiency nvenience available living wealthier highly industrialised automated continuous operation efficiency convenience applications offer attributed small measure ability perate automatically thus example navigation stems offer invaluable guidance individuals seek find way estination entirely foreign providing guidance concerning bryson theodorou taghi see discussion humans loop section design algorithmic systems see discussion sabre airline reservation ystem sandvig malevolent applications see brundage zuboff royal society mcsherry examples applications see narula dgi direction take time advise anticipated journey time alternative route applications possible capacity technologies collect digital data sensors embedded collected devices enabling track activities movements ndividuals highly granular lev often without individual awareness chnological capacities direct implications concepts responsibility ways affect enjoyment human rights freedoms least three ways firstly etworked nature many technologies internet internet nnected technologies made possible means operate scale real time result may considerable distance time space design implementation systems point decisions consequences arise directly immediately felt secondly capacity perate scale generates significant challenges supervision oversight discussed fully thirdly order provide highly personalised vice contextualised wider population trends traffic congestion necessitates continuous surveillance individuals population evel entailing constant personal data collection processing necessarily mplicates human rights collective value privacy data reliance large model upon computational algorithm ased determine operation machine learning systems rely critically nderlying accuracy without access relevant data set machine learning algorithms hollow shells accordingly availability size quality underlying datasets upon algorithms trained tested alidated plays critical role performance accuracy legitimacy utputs availability quality data systems rely upon uring operation capacity generate insight merging data sets much excitement surrounding technologies arises capacity generate new insight merged datasets whi used predict inform particular data set ight contain fairly mundane innocuous data individuals multiple ata sets merged mined may generate insight enable quite intimate ersonal information inferred high level accordingly issues ncerning govern collection processing digital data mplications human rights concept responsibility given ease almost negligible cost associated transferring copying digital data mplexity contemporary global data become especially cha llenging important capacity imitate human traits recent years ability technologies imitate uman traits including voice simulation visual representations human behaviour bots capable interacting humans apparent emotional sensitivity ecome high quality may extremely difficult ordinary humans detect traits artificially generated provoked concern capacity swan see discussion section kitchin prainsack kosinski council europe study deceive humans particularly production called deep fakes harnessed unethical malicious greater software complexity machine learning deep learning systems become rogressively complex due availability data also due increased rogramming complexity result systems subject three types ulnerability first increased programming complexity increases propensity stems generate stochastic components make mistakes secondly mplexity opens door wide range adversarial attacks thirdly npredictability outputs generate unintended yet highly consequential verse third party effects externalities capacity personalise configure individual choice environments one way whi systems contributed achievement greater efficiency precision acro wide range processes operations personalisation serv ice provision example use profiling techniques enables digital retailers suc amazon provide personalised product recommendations customer ased predictions gleaned continuous collection analysis customer digital traces analysed conjunction custo mers personalisation digital services offers benefits users redu cing volume irrelevant offers services receive effect segmenting individual users one user sees ersonalised informational environment may different seen ther users driven personalisation takes place routinely scale risks stering social eroding social cohesion capacity redistribute risks benefits burdens among individuals roups via use optimisation systems reconfigure social nvironments choice architectures systems operate real time scal via internet global networked architecture result systems nfigured operate manner designed optimise goal prespecified human developers scale previously impossible enab led capacity harness systems personalise informational choice env ironments individual user particularly powerful configured operate scale enables design deployment systems aimed nfluencing directing behaviour entire population users rather one solated user accordance developer chosen optimisation function stems inevitably prioritise certain values others ways nfigure shape social informational environments may beneficial individuals groups detrimental others example optimisation economist chesney citron see discussion section recent research image recognition demonstrated lack ability technology distinguish noisy nformational inputs chihuahua dogs pictures mixed muffin pictures algorithm could tell apart yao current technologies easily successfully attacked cybercriminals use system lnerabilities benefit cybercriminals falsify voice recognition captcha systems reak personal business accounts polyakov yeung pariser yeung yeung dgi function navigation systems might enable user find fastest ossible route desired destination given volume location traffic revailing user time travel routes identified system reco mmended users aggregated distributional effects residents areas traffic routed confronted greater noise levels vehicle issions congestion effects experienced residents areas traffic routed accordingly optimisation systems raise questions acco untability responsibility resulting distributional outcomes particularly iven typically consultation input deliberation affected individuals roups populations concerning distribution risks benefits arising capacity generate problems collective action capacity optimisation stems operate highly targeted manner personalised individual users scale across entire population users means systems perate ways may relatively minor effect individual level whilst aving serious significant impact collective societal level ifficult imagine circumstances operation optimisation systems may theref ore generate collective action problem collective action problems arise ndividuals would better cooperating users individual user fails take action impact individual small justify effort reso urces associated consider example problem political provision misleading inaccurate dubious political nformation individual voters intention encouraging vote articular candidate even particular individual misled voting candidate might otherwise supported practice unlikely sufficiently otivated initiate complaint legal proceedings responsible dissemination yet effect felt level pose real potentially serious threats integrity democratic elections democratic processes words one distinctive novel cha llenges systems pose arises capacity operate highly targ eted personalised manner yet scale uld pose serious societal threats motivation individual try counter threats may extremely weak implications concept responsibility human rights perspective importance understanding human rights dimensions reflected various nquiries reports commissioned produced growing number civil society rganisations increasingly focus academic scholarship concerned ethics includes work council europe including study human yeung olsen information commissioner office house commons digital culture media sports mmittee see example amnesty international access australian human rights commission cath hildebrandt executive office president montreal declaration esponsible toronto declaration protecting rights equality mac hine learning systems latonero mantelero raso risse rouvroy general assembly mantalero nuffield foundation leverhulme centre uture intelligence high level expert group council europe study rights dimensions automated data processing techniques possible regulatory mplications prepared committee experts internet intermediaries hereaft wagner study wagner study identifies examples algorithmic systems currently use may violate undermine enjoyment ost obviously implicated rights stronger lesser degree already public iscussion including rights fair trial due process art privacy data protection art freedom expression art freedom association art effective remedy art prohibition discrimination art right free elections art protocol report commissioned parliamentary assembly council europe ace undertaken rathenau instituut concluded spite impact digital technologies human rights far ittle attention paid crucial topic scarcely undamental political public debate result serious erosion uman rights taking place therefore human rights debate eriously lagging behind technological developments needs trengthened present study builds wagner study critically examining advanced digital chnologies may implicate concept responsibility chapter begins identifying amining adverse individual societal risks posed adopts human rights erspective focusing technologies may undermine practical capacity wagner study focused primarily implications human rights algorithmic ystems affect public large identifying various human rights concerns triggered increasing ole algorithms observing concerns bound expand grow gorithms automated data processing techniques related systems become increasingly complex nteract ways become progressively impenetrable human mind wagner study wagner study see section see section although internet social networking sights enhanced capacity individuals exercise eir art echr rights freedom association concerns automated sorting rofiling protested may erode rights wagner study art echr requires states ensure individuals access judicial procedures mpartially decide claims concerning violations human rights including violations ncluding effective mechanisms ensure private sector actors respect rights stablishing effective complaint mechanisms promptly remedy grievances individuals yet pacity automated processes may impede ability individuals obtain effective medy increasing use automated mechanisms complaints handling raises serious oncerns whether mechanisms regarded offering effective remedy wagner study see section art protocol echr requires states support individual right free expression holding free lections reasonable intervals elections must enable vote secret however rise ocial media use automated content recommendation systems may used purposes olitical manipulation could threaten right free elections wagner study van est gerritsen dgi exercise particular human rights freedoms systematic basis era pervaded vanced technologies rather engaging detailed analysis particular plications may adversely impact specific human rights fundamental freedoms two imensions systematic impacts considered firstly threats set rights osed algorithmic secondly wider adverse collective social mpacts technologies including limited incorporated algorithmic systems readily expressed language isting human rights discourse time wider adverse effects could systematically threat foundations notion human rights presupposes rooted number rights examined wagner study council europe study chapter threats risks harms wrongs associated vanced digital technologies commentators claim advances networked digital technologies including cur rently referred technologies powering emergence new industrial rev olution provoke far changes across every aspect social life agnitude scale disruptive unsettling wrought original dustrial examining potential threats risks associated erging technologies helpful briefly highlight broader eco nomic context affect condition development implementation option broader historic context experience modern scientific chnological innovation end may parallels larger societal effects original industrial rev olution anticipated effects new industrial revolution dawning example century industrial revolution brought myriad benefits oth individuals society credited substantial widespread mprovements living standards individual collective generated nintended adverse effects include direct adverse effects human health safety associated early forms industrial production burning fossil fuels ower industrial activity led serious climate change problem global scale yet adequately addressed resolved yet adverse effects imate change arising technologies provoked original industrial revolution become apparent century later time late address reverse effectively contemporary societies might face similar dilemma one difficulties seeking identify anticipate larger adverse societal effects chnological innovation arises difficulties predicting likely applications take especially difficulties anticipating aggregate cumulative effects ver time space rise algorithmic adm systems mputational systems utilise machine learning algorithms combined rapid despread smart devices fuelled emergence algorithmic aking systems seek harness frequently monetise digital data gleaned systematically tracking collecting digital traces left individuals behaviours utilising advanced digital technologies including order roduce new knowledge used inform decisions many stems rely upon profiling techniques entail systematic bulk llection data population individuals order identify patterns thereby redict preferences interests behaviours individuals groups often high egrees accuracy data profiles used sort individuals identify didates interest aim producing actionable insight insight used inform automate individuals undertaking rofiling clients systems widely used retailers seeking target roducts individuals identified profitable likely interested boyd crawford skilton hovsepian cukier draper turrow gandy dgi political actors organisations seeking tailor target campaign messages ndividuals identified likely persuaded increasingly cri minal justice authorities seek assess risk particular individuals gorithmically identified posing public safety order make custody decisions ndividuals whether criminal suspects convicted criminal offences context public anxieties emerged concerning societal ffects advanced digital technologies including particularly given increasing use profiling recent attention focused way social media ther content distribution platforms utilize profiling technologies ways profound mplications article right freedom expression information particularly llowing cambridge analytica scandal alleged millions profiles cebook users illegally collected microtarget individuals political messages aim swaying voter following discussion however concerned primarily way algorithmic systems generally may stematically threaten particular human rights rather focusing application speci fic domains activity adm systems systematically threaten particular rights use algorithmic systems may systematically threaten several rights cluding right fair trial rights due process art adm systems utilise data driven profiling techniques create digital profiles ndividuals groups across wide range contexts sifting sorting individuals cate gories order assist used automate inform aking substantially affect rights significant interests individuals rofiling may serious consequences affected individual opportunity articipate contest otherwise challenge outcome decision nderlying reasoning upon decision based quality integrity ata used inform decision practice almost ght fair hearing per article encompasses series specific procedural include person right know reasons decisions adversely gnificantly affect individual yet adm systems used inform may configured capable produce meaningful explanations terms ntelligible affected individual even case neural networks rely back ropagation terms intelligible algorithm concerns acerbated opacity systems arise technical complexity ifficulties assessing quality provenance underlying training data sed train algorithm enjoys intellectual roperty protection trade secret therefore need publicly stance gorton oswald ferguson house commons digital culture media sport hildebrandt hildebrandt gutwirth galligan weller matthias burrell lohr pasquale council europe study organisations utilising systems typically defend basis prevents sers gaming accordingly systems risk interfering rights process protected article including presumption innocence particularly rcumstances consequences affected individual serious particularly worrying increasing use systems criminal justice contexts inform custodial sentencing decisions primarily usa although take elsewhere including yet hildebrandt observed become resi stant notion outcomes tool might incorrect incomplete even rrelevant regard potential right freedom expression art operation algorithmic profiling may significantly affect art right freedom pression includes right receive impart information given powerful nfluence global digital platforms exert informational environment individual societal level example automated search engines act crucial atekeepers human beings wish seek receive impart information content whi indexed ranked highly less likely reach large audience seen search algorithms intentionally designed serve owner commercial interests therefore inevitably biased towards certain types content content providers pically automated algorithms rather humans decide handle prioritise istribute delete content online platforms including content handling uring political electoral campaigns practices implicate individual ght freedom expression also article inherent aim creating enabling env ironment pluralist public debate equally accessible inclusive addition online platforms increasingly pressure actively counter online hate speech automated techniques detect delete illegal content particularly llowing live video streaming via social media platforms attack civilians lone rrorist christchurch early article provides interferences free pression would therefore include algorithmic systems block access content thro ugh filtering removal must prescribed law pursue specified legitimate purpose utlined art necessary democratic accordingly widespread use algorithms content filtering content removal processes including social media latforms also raises rule law concerns raising questions legality legitimacy koker davidow applications implicate rights article also article right liberty ecurity person principle protected article hildebrandt hildebrandt argues art equality arms principle ment public prosecutor judge lawyer unable check police agent reached conclusions agents required log activity outputs purposes reached outcome enable proper review rathenau institut endorses hildebrandt ews suggested council europe consider establishing framework minimum norms taken account court interpreted purpose including decision thorities within legal system particularly involved making custody decisions concerning ndividuals within criminal justice system uses helping prevent member states devising eir individual frameworks likely result uneven varying degrees protection echr provided individual member states van est gerritsen see general assembly line jurisprudence european court human rights restriction freedom pression must correspond pressing social need proportionate legitimate aim pur sued see yildirim turkey march dgi proportionality particularly given online platforms often face unclear legislative frame work encourages remove content voluntarily without clear legal basis whi intentions welcome lack transparency accountability ncerning process criteria adopted establish content extremist clearly illegal arrangements create risk excessive interference ght freedom expression understood handing law enforcement respo nsibilities states private enterprises national legal regimes require digital ntermediaries restrict access content based vague notions extremism oblige monitor communication order detect illegal content thereby violating established principle intermediaries obliged conduct general onitoring potential chilling effects freedom dition process related concerns arise due capacity platforms decide selves constitutes extremist content therefore subject removal tools measures identification removal decisions made effectively rest private providers unless measures subject meaningful effective stat oversight risk exceeding legally constitutionally prescribed boundaries thereby ntravening rule whi imperative acting decisively spread hate messages ncitement offences indisputable practices raise considerable ncerns related legality interferences freedom expression extremist content material inciting violence often difficult identify even trained human due mplexity disentangling factors cultural context humor algorithms cur rently capable detecting irony critical analysis filtering speech eliminate armful content algorithms therefore faces high risk removing speech harmless might contribute positively public debate ther hand capacity media content platforms disseminate messages real time global scale substantially magnifies reach scope thus impact harmful speech turn automated approaches content filtering highlights acute respo nsibility challenges increasing reliance algorithmic systems contemporary ife generates offer benefits scale speed efficiency relative human digital platforms claim human oversight necessarily inadequate enerating respons ibility gap typically argue fairly expected see menn volz principle enshrined relevant council europe policy guidelines including recent uncil europe see also general assembly several states introduced aws initiated law reform initiatives address spread harmful content example ermany adopted network enforcement act netzdg law requires online platforms two million registered users germany remove manifestly unlawful content ontravenes specific elements german criminal code holocaust denial hate speech ithin hours receiving notification complaint remove unlawful content ithin even days notification compliance risks fine million law also seeks increase latform responsibility imposing greater transparency significant reporting obligations subject significant criticism basis restrictive implications freedom xpression access recently issued online harms white paper ntroduces legal duty care make companies take responsibility safety users tac kle harm caused content activity services enforced independent regulator overnment see wagner study see discussion called control problem section council europe study right privacy data protection article article right respect private family life rights data protection laced unprecedented strain due ability algorithms facilitate collection repurposing vast amounts data including personal data gleaned digital bservation individual users may generate data entirely unpredictable resul data wagner study observed use personal data urposes individual profiling subsequent repurposing threatens person right nformational particularly given noted section even fairly undane innocuous data collected digital traces individuals may merged ther data sets mined ways generate insight enable quite intimate ersonal information inferred high level contemporary ata protection regimes including conv modernised important safeguard nferring set data protection rights data subjects aimed protecting nnecessary unlawful data collection processing might provide mprehensive practically effective guarantees use intrusive profiling plications prohibition discrimination enjoyment rights freedoms art potential bias discrimination arising use machine learning chniques attracted considerable attention researchers ike concerns unfair unlawful treatment directly implicate article echr rovides enjoyment rights freedoms set convention shall sec ured without discrimination grounds sex race colour language religion olitical opinion national social origin association national minority roperty birth status many opportunities bias inadvertently affect outputs produced use machine learning techniques arising biases gorithms developers bias built model upon systems generated iases inherent data sets used train models biases introduced stems implemented might biased systems lead iscrimination generate erroneous decisions entail significant wrongdoing resul ting decisions systematically biased groups historically cially disadvantaged individuals members groups thereby rei nforcing compounding discrimination structural disadvantage even though effec intended system designers concerns particularly see example tension competition services consumer privacy oxera wagner study kosminski new rights introduced recently modernised conv include right subjected ecision significantly affecting based solely automated processing data without views taken consideration right obtain knowledge reasoning underlying data rocessing results processing applied right object grounds relating situation processing personal data concerning unless controller demonstrates legitimate grounds processing override interest rights fundamental freedoms article modernised convention protocol echr article provides enjoyment right set forth law shall secured ithout discrimination ground sex race colour language religion political opinion ational social origin association national minority property birth see also art veale binns barocas selbst wagner study dgi acute relation use machine learning techniques inform custody sentencing ecisions within criminal justice system due allegations techniques perate ways substantially biased black racial respo nse concerns growing body work concerned devising technical proaches countering bias societal risks associated profiling ntemporary applications profiling technologies may also undermine mportant collective interests values fall within scope existing uman rights protection much value technologies lies capacity sort ndividuals groups within population automate enable ersonalised predictive interventions scaled applied llowing practices may generate significant societal risks yet often overlooked ublic academic debate highly granular surveillance profiling requires collection highly granular data individuals basis scale profile individuals groups within across opulation identify inferred preferences necessitates use ass surveillance often highly intrusive yet largely invisible manner although threats whi practices pose individual privacy rights data protection readily parent discussed practices also pose serious risks collective nature rivacy thereby eroding fundamental societal conditions individual privacy ossible without individual privacy exist council europe arliamentary observes ince many technologies nowadays operate distance even aware mass surveillance people rather defenceless since ere possibilities escape surveillance activities creeping evelopment impact society human rights received far little tention political public debate yet little debate cumulative effects mass surveillance instead triggered specific plications incidents mini debates organised outcome ach debate balancing act mostly favours national security economic nterests sum debates however gradual steady dissolving privacy anonymity individual angwin see dieterich see section special rapporteur david kaye observed tackling prevalence iscrimination artificial intelligence systems existential challenge companies governments fai lure address resolve discriminatory elements impacts render technology neffective general assembly council europe parliamentary assembly committee culture science education mediah observed para primary business model internet built mass surveillance council europe council europe para wagner study also draws attention risks created data aggregation generation new ata may mined use algorithms ich creates risk urveillance private entities governments view echoed human ights council march wagner study rathenau instituut observes surveillance via iot internet performed states companies inherently involves council europe study risks magnified deepened result recent advances capabilities ave fuelled emergence powerful biometric applications used dentification purposes ways seriously threaten several human rights including rotected article china example facial recognition technology eing introduced beijing subway enable facial features subway users dentified tracked travel technologies already deployed train stat ions used pop concert locate suspected fugitive even implemented scho ols monitor student distraction automatically alert teacher distraction difficult imagine powerful technologies rece ntly developed deepmind reported outperform professional uld deployed repressive regimes ways magnify anxieties strike eart right left alone potentially severe chilling effects may freedom expression individual democratic freedom particularly deployed states identify detain individuals identified political combined use profiling technologies enable fairly innocuous mundane data merged mined ways may reveal highly personal cha racteristics sexual orientation powerful tools hands overnmental regimes whether liberal repressive therefore generate acute threats xercise human rights fundamental freedoms personalisation attractions profiling technologies readily identifiable wishing engage rofiling enable automated sorting targeting candidates interest order ersonalise way individuals treated techniques applied scal yet ways allow readjustment reconfiguration personalised fferings response user capacity engage ersonalisation digital services potentially profound implications social solidarity mmunity consider example practice personalised pricing data rofiling rise digital retailing makes possible industrial capitalism goods mass produced supplied retailers typically made available consumers eographic locations terms applied universally customers entering store particular time price contrast profiling enables oods services fered potential customers personalised prices custo mer sees individualised digital shop front access prices offers made others level set use riven profiling order identify maximum willingness pay individual thereby optimising revenue kind intentional discrimination ight unlawful far might directly indirectly discriminate individuals rocessing personal data researchers still trying grasp full extent harmful effects ives individuals caused surveillance known effects comforting urveillance chilling effect also leads behavioural effects instance sult surveillance individuals conform perceived group norms conforming effect occurs even hen people unaware conforming kaminski witnov states companies inforce surveillance activities part complex cohen van est gerritsen cowley hutson donahoe kosinski yeung townley miller dgi basis protected grounds contemporary equality law nevertheless effect seri ous departure pricing practices prevailed driven age ways become widespread ubiquitous may seriously undermine social lidarity manipulation personalisation informational environments profiling makes possible rings new capacities manipulate individuals subtle highly effective individual level manipulation may threaten personal autonomy emerging right gnitive recent cambridge analytica scandal run election brexit referendum vividly illustrates deployed scale urposes political microtargeting manipulate voting behaviour may entail use automated bots operating social media websites may threaten right freedom expression information article could seriously undermine foundations emocratic orders perverting right free elections protected article protocol manipulative practices called persuasive digital technologies enable understood interfering rights protected articles configured automatically continually reconfigured tailor informational cho ice environment architecture individuals use profiling redict often great accuracy behaviours interests preferences vulnerabilities individuals scale applications used manipulate deceive individuals thu interfering informational decisional capacity engage manipulative practices exacerbated recent ergence powerful applications simulate human traits including voice mulation visual representations human behaviour robots capable interacting umans apparent emotional sensitivity accuracy precision tremely difficult humans detect traits artificially generated chnologies likely attractive tools malign actors deceive manipulate thers example researchers already predict advanced synthesised oices used gather information phone deceptive fraudulent urposes attacks become commonplace widespread readily etected targeted individuals may seriously threaten article right liberty sec urity collective security respect rule law upon individual collective liberty security depends opportunities utilise technologies yeung european commission studied prevalence personalisation practices uropean commission competition markets authority cma commissioned onomic research use pricing algorithms potential competition concerns including collusion personalised pricing competition markets authority yeung example recent study norweigan consumer council analysed sample settings facebook google windows show default settings dark patterns techniques feat ures interface design meant manipulate users used nudge users towards privacy intrusive ptions forbrukerradet academic support recognition right cognitive sovereignty aimed providing ndividuals protection forms manipulation deception advancing igital technologies increasingly make possible order guarantee individuals threshold level overeignty minds see bublitz might right also ossible right might recognised falling within article echr establishes right freedom thought conscience religion gorton wagner study house commons digital culture media sport yeung lanzing council europe council europe study undermine integrity legal process might also become possible brudage bserve report malicious present recording authentication technology still edge forgery techn ology video crime committed serve highly compelling vidence even provided untrustworthy source future however forgeries may challenge seeing believing aspect ideo audio evidence might also make easier people deny legations given ease purported evidence might ave produced addition augmenting dissemination misleading nformation writing publication fake news stories could automated routine financial sports reporting often today production issemination forgeries becomes increasingly synthetic may constitute large portion media information systematic treatment individuals objects rather moral agents though personalisation individuals informational environments portrayed social edia companies enabling provision ore meaningful content two cha racteristics underlying system upon practices rely tend treat individuals objects rather moral subjects firstly individuals ngled basis causal theory simply basis correlations ata sets result systems typically provide reasoned account ndividuals explaining singled treatment particular kind seco ndly underlying logic processing operations highly complex paque ways practically sometimes technically incomprehensible discussed ove words many contemporary systems designed capture mmodify optimise value extraction interests system owner tracking alysing digital traces daily behaviour individuals primarily ncerned identifying reasons individuals behave particular ways rieder theref ore refers commercial applications big data techni ques offering nterested readings contrast disinterested pursuit knowledge cha racterises pursuit scientific inquiry academic net effect plications humans increasingly treated objects rather moral subjects sorted sifted scored evaluated technological systems ways appear starkly dds basic right individuals treated dignity respect lies foundation human rights fundamental european gro ethics explains brundage rieder merton law enforcement applications individual profiling within criminal justice system especially roubling observed axon offering free body camera technologies police epartment following acquisition two machine vision companies reports axon new focus predictive methods policing inspired google embrace deep learning ncrease sales raises new civil liberties concerns instead purchasing patterns systems ooking much vague dependent targets like suspicious activity behind appearances technical neutrality systems rely deeply subjective assumptions constitutes uspicious behaviour counts suspicious person per thus individuals become objects suspicion basis data analysis demonstrable causal basis dgi driven optimisation social processes based social scoring systems hich countries experiment violate basic idea equality freedom way caste systems construct different kinds people ere reality different properties people attack democratic systems utilisation scoring systems basis ominance access powerful technologies evented human dignity foundation human rights implies eaningful human intervention participation must possible matters con cern human beings environment therefore contrast tomation production appropriate manage decide umans way manage decide objects data even techn ically conceivable autonomous management human beings ould unwelcome would undermine deeply entrenched european core time commercial applications profiling purposes accompanied use experimentation individuals use testing without subject supervisory research ethics oversight provided academic nstitutions pursuant declaration helsinki latter sets core requirements ethical conduct human subject widespread routine use ractices reflects belief human users merely objects ripe experimentation fundamental norms institutional oversight mechanisms designed safegu ard protect dignity rights individuals applicable julie cohen put citi zens reduced raw material sourced bartered ined curiously fabricated privatised commons data summary threats posed profiling technologies take together cumulative effects practices resonate concerns profiling expressed korff report council europe concerning trend threats implications private life data protection use nternet related services expresses strongest possible terms rofiling systems provide appearance infallibility objectivity reliability accuracy assessments produce yet outputs inevitably unavoidably generate erro either false positives false negatives generate discriminatory effects certain practically impossible individuals challenge korff concludes profiling thus really poses serious threat kafkaesque world owerful corporations state agencies take decisions significantly affect eir customers citizens without able willing xplain underlying reasoning decisions subjects denied effective individual collective remedies serious ssue profiling poses fundamental threat basic principles rule law relationship powerful people emocratic observations alert collective cumulative impacts contemporary plications technologies undertaken systematically scale european group ethics science new technologies kramer tufecki powles korff browne korff browne council europe study may time seriously erode destabilise social moral foundations ecessary flourishing democratic societies individual rights freedoms eaningfully exercised collective societal threats risks generated technologies though concerns listed attributed use profiling additional concerns threats collective interests values ari use individual profiling include malicious attacks unethical system design unintended system failure derstandable fears emerged concerning safety security mplications technologies including concerns potentially catastrophic nsequences malicious attacks systems including data poisoning attacks use adversarial safety critical systems successfully targeted even unintended fear failure technologies within systems autonomous ehicles could seriously harm public safety worse systems could perate ways designed prioritise safety particular classes persons thers many would regard unethical even unlawful societies become ncreasingly dependent upon devices systems enerally many safety critical ensuring safety security systems acq uires even greater especially due rise various avenues pportunities malicious attack confined direct attack systems selves may also include strategies aimed exploiting network effects enable apacity target communicate individuals scale yet relative loss authentic real meaningful human contact addition concerns use technologies imitate human ehaviour diffuse often anxieties collective life may become ncreasingly dehumanised tasks previously performed humans automated many fear values qualities cherish including value real human interaction enuine empathy compassion concern may replaced relentless efficiency nsistency driven services concerns particularly prevalent chnologies utilised care environments robot nurses care nannies botic care assistants ways otherwise threaten denude societies cha racteristic values features inhere real authentic human contact connection rel ationships use sex robots example although inescapably fraught imperfect nevertheless contribute fundamentally meaning value human applications generated concerns need ensure designed operate ways respect dignity care might fall within technologies liable failure autonomous systems exception pertinent issue whether autonomous systems ever eated without manual override royal cademy engineering thomas brundage forbrukerradet yearsley dgi scope article protection private family life prompted arg favour right meaningful human contact chilling effect data repurposing dditional concerns arise worries people might refrain participating systems could improve life conditions seeking treatment cancer due fears ersonal data taken highly sensitive contexts might used systems contexts ways may contrary concerns chilling effects ari sing ease data obtained one purpose may repurposed ther unrelated social ends helps explain importance honouring upholding urpose specification principle enshrined many contemporary data protection regimes ndividual autonomy freedom understood include capacity individuals move etween multiple roles identities partition keep separate systematic use personal data profiling ndividuals may threaten capacity digital power without responsibility rries systems essentially treat people objects rather moral subjects understood part wider set concerns exploitation individuals serv ice big tech several strands concern firstly serious ncerns instantaneous scale technologies operate facebook news feed limited practical capacity meaningful human oversight systems kind wedge capacity machines relative capacity humans monitor evident repeated claims social media firms realistically expected respect fully rights individuals providing mprehensive timely content moderation given scale speed platforms perate quite simply outpace human yet allowing riven automation operate without comprehensive human oversight threatens enerate serious responsibility gap big tech reaps benefits riven platforms without concomitant concerns kind prompted parliamentary assembly council europe pace suggest contexts human contact interaction play central role raising children caring lderly people disabilities right meaningful human contact could play role see council urope parliamentary assembly para evidence chilling effect occurred indiv iduals unwilling ndertake genetic testing circumstances would likely assist healthcare owing fears resulting information may used others ways contrary interest articularly employment life insurance contexts farr understood terms raz conception autonomy requires individuals adequate ran options widespread data repurposing inform organisational ndividuals may effectively diminish autonomy reducing range options available ccording raz person maker author life must mental abilities form intentions sufficiently complex kind plan execution include minimum rat ionality abiity comprehend means required realize goals mental faculties necessary plan actions etc person enjoy autonomous ife must actually use faculties choose hat life must words adequate options available choose finally choice must free coercion manipulation others must independent raz see discussion section keen council europe study constitute violation basic norms social reciprocity amounting unjustified taking citizens communities entails naked exercise ower without responsibility words responsibility gap claims arisen emergence computational systems capacity recent contemporary spin least context social media platforms tomated systems may designed remove distribute content users scale speed human content moderators keep pace social media latforms claim responsible secondly big tech hitherto successful managed immunise external regulation claiming abide ethical principles includes claimed use technological solutions discussed sec tion seek normative values design operation chnological systems unless subject external oversight sanction likely provide meaningful hidden privatisation decisions public values technologies aim reproduce improve human performance respect task would require intelligence humans perform yet claim chnologies outperform humans based narrow def inition overarching goal couched terms performance narrowly defined task identifying malign ssue images seeking incorporate complex chnical systems developed provide services individuals real world contexts thi invariably implicates wider range values beside precision efficiency task erformance hese systems invariably reflect values value priorities system evelopers might aligned collective values public democratic constitutional values human rights designed serve yet even relation stems directly affect interface public citizens affected groups organisations typically given meaningful opportunity participate dentifying values value systems configured systems used evaluate recidivism risk convicted criminals see king release custody offers vivid example although criminal justice system ntemporary democracies founded expected give effect several important cri minal justice values scoring systems hitherto designed optimise one value public technologies become embedded tools ptimising efficiency social coordination smart navigation systems smart nfrastructure management example inevitably make decisions prioritise values others impact directly individuals groups may enefit others may yet sheila sts scholars repeatedl highlighted technological systems reflect normative values given despread effects determination values subject democratic matthias discussed section see discussion see section technological strategies interpreted human rights oncerns tech firms empowering define often narrow scope scope content ser right exclusive powers enforcement korff browne zweig jasanoff dgi participation deliberation rather resolved privately private providers otivated commercial exploitation human labour train algorithms systems often claimed outdo human performance algorithms trained large numbers human workers example algorithm answering search queries evaluated army mechanical turk workers act like gorithm algorithm outperforms answers even algorithm trai ned may unwanted side effects use automated algorithms requ iring humans identify weed exemplified case social edia content moderators asked remove inappropriate content social etworks training models well consequent human acti vities weed models externalities often concealed maintain ythology seamless humans train models often located oor communities often global south typically work extremely precarious typically provided support dealing psychological urdens may come clean activities claim many gorithms continue learn general user population allows system owners free ride user labour thereby nurturing mode production contributes creati conditions unpaid labour normalised legitimised human rkers denuded rights power asymmetry threats foundations moral emocratic community adverse impacts arising increasing power sophistication emerging digital technologies exacerbated radical asymmetry power etween develop deploy algorithmic systems individual users sub ject asymmetry power arises largely due former unique ability eng age synoptic pervasive surveillance users collecting accessing massive ata sets gleaned users digital interactions continuous basis turn enables subject individuals populations algorithmic evaluation order sort score empowering platform owners communicate irectly users basis automatically scale contrast practical cap acity individuals understand navigate complexity data ecosystems whi embedded extremely limited individual users abi lity identify whet digital information services made available sam terms thi power asymmetry suggests least current institutional arrangements eed capacity existing rights existing mechanisms oversight enforcement respond comprehensively risks associated increasingly owerful digital technologies wagner study observed irani see example chen ekbia nardi ferraris see findings reported mireille hildebrandt refers digital unconscious ooded data contrast information individuals connect hildebrandt council europe study increasing use automation algorithmic spheres ublic private life threatening disrupt concept human rights rotective shields state interference traditional asymmetry power information state structures human beings shifting towards asymm etry power information operators algorithms may public private acted upon particular existing human rights institutions may struggle provide effective eaningful protection least three reasons rstly given highly complex opaque nature technologies difficult ractice individuals identify rights infringed ways ften individuals unaware technologies used purposes aluating even individuals willing assert human rights nfringements arise use automated example rem edies available might provide desired outcome perhaps ample much individuals want explanation treated less fav ourably others want insist entitled equally fav ourable seco ndly even individuals aware rights may interfered resul use systems one might question likelihood individuals ractice seek initiate remedial action circumstances regard nterference sufficiently serious motivate invest time energy resources asso ciated launching maintaining compliant resulting collective action roblem means aggregate adverse impacts systems likely continue nremedied least absence collective complaints mechanisms official body competence resources remit take enforcement necessary ensure effective uman rights protection thi rdly many larger adverse societal concerns readily expressed anguage discourse human rights concern collective values interests ncluding threats broader amorphous moral social political culture ntext advanced digital technologies operate time speed scale technologies operate poses novel threats risks challenges ntemporary societies hitherto contend yet many anticipated cum ulative collective effect systems time could fatally undermine social technical conditions essential exercise human rights fundamental freedo current approaches interpretation enforcement human rights highly individualised likely struggle address collective ggregate cumulative risks harms technologies might generate rds existing approaches rights discourse tend overlook deeper stematic societal concerns including threats underlying democratic moral fabric individual rights anchored without wagner study edwards veale yeung see section dgi summary thi section examined adverse individual collective threats risks society application advanced digital technologies may pose emphasized way whi widespread growing use advanced digital technologies including articularly rely upon profiling technologies may systematically threaten exercise human rights well general collective values interests fall outside scope existing understandings human rights protection also nsidered threats risks posed technologies contemporary ticipated applications include concerns associated hostile malicious plications unethical unsafe design operation systems iminishing opportunities authentic real meaningful human contact chilling effect data repurposing exercise digital platforms others capabilities power thout responsibility creeping yet hidden privatisation decisions public values exploitation human workers train algorithms finally highlighted rowing power asymmetry capacity resources develop ploy technologies individual users groups populations directly affected thei use may substantially diminish capacity identify seek protection redr ess existing institutions potentially serious ndividual collective threats risks associated development application vanced digital technologies inevitably raise important questions responsibility oiding preventing mitigating allocated furthermore risks pen harm violate human rights responsibility nsequences attributed allocated institutional mechanisms relied pon ensure adequate enforcement redress particularly given collective action roblem faced individual questions chapter seeks dress beginning examination concept responsibility responsibility atters analysis ways technologies challenge existing conceptions respo nsibility council europe study chapter bears responsibility threats risks harms wro ngs posed advanced digital technologies preceding section demonstrated advanced digital technologies generate serious threats risks individual collective interests values may perpetuate mmission substantial systematic wrongdoing including human rights violations take together threaten health collective moral social foundations emocratic societies accordingly section considers bears responsibility revention management mitigation making reparation ripen harms rights violations individuals groups society following discussion highlights concept responsibility implicated emergence advanced digital chnologies including particularly light implications human rights protected nder echr referred chapter following discussion proceeds several stages rstly begins clarifying mean responsibility responsibility matters phasising vital role securing giving expression rule law esse ntial peaceful social seco ndly considers two core themes raised contemporary discussions adverse sks associated technologies notably role tech industry promulgating oluntarily committing abide ethical standards secondly leged control problem claimed flow capacity systems perate less autonomously human creators thi rdly identifies range different responsibility models could adopted overn allocation responsibility different kinds adverse impacts arising peration systems including models based risk creati strict responsibility mandatory insurance schemes cus report implications human rights responsibility human rights iolations widely understood strict strict provided human rights iolation established need proof fault contrast allocation obligations repair tangible harm health property may legally distributed acco rdance variety historic responsibility models allocation historic respo nsibility tangible harm arising operation systems also prospective imension guiding function identifying nature scope obligations involved development production implementation systems respo nsibility models briefly outlined urthly draws attention acute challenges allocation responsibility enerated operation complex interacting systems entails ntributions multiple individuals organisations machine components software gorithms human users often complex highly dynamic environments fthly draws attention range mechanisms securing prospective historic responsibility adverse impacts systems including various kinds mpact assessments auditing techniques technical protection mechanisms xthly emphasises role obligations states relation risks associated vanced digital technologies focusing specifically obligations ensure effective rotection human rights dgi finally highlights need reinvigorate human rights discourse digital age drawing att ention need protect nurture foundations necessary uman agency responsibility without human rights freedoms ractically meaningfully exercised responsibility matter setting aims study already noted society conceptions ractices responsibility vital importance serve ensure within nstitutional democratic orders individuals organisations held account verse effects actions despite extensive legal philosophical iterature concerned responsibility relatively academics focus attention ndamental role responsibility individuals society woven beneath surface scholarship lies recognition concept responsibility serves two critical nctions broadly reflecting moral philosopher gary watson refers two faces first face essential sense world moral ents authors lives act basis reasons watson puts sponsibility important issues lead life indeed hat life biographical sense quality aracter life issues reflect one face responsibility call aretaic face watson identifies second face responsibility concerned practices olding people hen speak conduct deserving censure remonstration outrageous unconscionable views even wrong uggest response agent principle appropriate nvoke practice holding people morally accountable typically dge judge members moral community entitled rinciple react various ways difference two faces responsibility might call self isclosure view responsibility one hand moral accountability view ther illuminated following scenario someone betrays ideals choosing dull secure occupation favor skier potentially enriching one endangers something deep mportance life trivial ends sleeping little drinking much efore important performances example acted badly least unwisely assessments thereby olding responsible distinct holding responsible would think accountable others whereas many ases suppose behavior nobody unless think moral que think accountable timid foolish behavior watson watson watson council europe study also harms others thereby violates requirements interpersonal relations different similar sentiment reflected concept basic responsibility articulated eveloped legal scholar john gardner claims basic responsibility central sense world fundamental identity rational agents creatures act basis reasons individuals want lives make rati onal sense add story whats also watson control arguably central accountability practices characterize sec ond face responsibility cause practices notably practice moral acco imposition demands people shall argue ise issues fairness arise aretaic appraisal concerns bout fairness underlie requirement control avoidability con dition moral accountability holding responsible taken equivalent holding accountable notion holding confused attitude believing hold responsible holding people sponsible involves readiness respond certain ways ook cases liable certain reactions result ailing one required require demand certain behavior agent lay unless agent behaves liable certain verse unwelcome treatment convenience shall call diverse forms verse treatment hol ding accountable thus involves idea iability sanctions entitled make demands entitled pose conditions study concerned identifying responsibility lie ndividual collective threats risks harms human rights violations stemming vanced digital technologies focuses primarily second face responsibility nderstood terms holding accountable nevertheless crucial link two faces responsibility rests status individual moral agent capacity make active choices decisions including decisions affect otential cause harm perpetuate wrongs others gardner puts moral ents insofar basically responsible basic responsibility therefore central reflection faces responsibility gardner observes whenever erpetrate wrongs mistakes always hunt around justifications excuses ecause rational beings want avoid unpleasant consequential responsibility hobbesian explanation also deeper reason refers aristotelian planation rational beings want assert basic responsibility requ ires give good account res ponsibility rule law words basic responsibility essential ndividuals authors lives also individuals members community watson gardner watson gardner gardner claims account provide need anyone particular ffered world hence rejects view responsibility necessarily relational dgi moral agents moral agents capacity freedom make choices ecisions actions ways might wrongful cause harm whether ther individuals conditions essential maintain stability social peration needed sustain community life basic responsibility responsibility ractices members community hold account cha racterise political community largely moral community community moral ents critical importance mutual respect exercised members moral community makes possible sustains community life ultimately ies foundations contemporary rule law society lacks system institutionalising responsibility practices order hold people responsible verse impacts conduct including conduct harms others iolates human rights would benefit vital protective functions nstitutional system provides essential peaceful trustworthy social peration coordination words system ensuring responsibility duly located plays critical role sustaining underlying social framework cooperation thout law rule time important recognise stabi lity continuity social foundations rest ultimately mutual respect sel individual members moral community system chnological coercion control mutual respect absent fro ostensibly happy stable orderly efficient society depicted huxley brave new wor inhabitants brave new world meaningful rights freedoms moral community society comprised members merely passive objects thoughts actions controlled exercise technological power authoritarian dictator notions freedom tonomy human rights fail flourish simply lack meaning countability answerability transparency critical importance institutionalised systems responsibility secure social undations upon rule law founded highlights need within moral olitical community committed respect human rights establish implement nstitutional mechanisms holding members community account rding conduct although concept accountability contested present purposes usefully described requiring person explain justify criteria kind decisions acts make amends fault error nderstood accountability mechanisms possess following four features setting standards ainst judge account obtaining account judging account deciding consequences follow concept accountability particular mportance relationships principal agent agent expected act behalf principal therefore required give account ans werable principal whose behalf agent acts transparency directly linked accountability far accountability requires called upon account explain reasons actions justify actions accordance articular set rules standards evaluation transparency therefore important east two reasons enable affected decision action know reasons galligan huxley yeung yeung oliver see also bovens literature cited therein council europe study action decision enable affected party evaluate quality reaso echanisms accountability particular importance relation exercise overnmental power within liberal democratic societies governmental officials rega rded servants citizens upon whose behalf act ower ultimately derived yet importance accountability arises whenever ercise power capacity affect others adverse ways accordingly concerns power scale effects complex systems rely upon chnologies given rise cluster concerns understood united ncern secure algorithmic accountability particularly given opacity systems potential utilised ways highly consequential implications ndividuals groups society securing accountability responsibility uman rights violations adverse consequences resulting operation chnologies therefore essential although existing laws including data protection law nsumer protection law competition law constitutional laws enshrine legal rotection human rights within national legal systems potential play gnificant important role securing various dimensions algorithmic accountability thei contribution securing algorithmic accountability beyond scope study rather following discussion seeks examine implications advanced digital chnologies including systems concept responsibility focusing primarily mplications human rights violations drawing moral philosophy legal scho larship dimensions responsibility thi general concept responsibility holding accountable extensively examined legal philosophical literature various insights literature selectively rawn upon analysis follows although many different senses term responsibility use purposes study temporal element respo nsibility worth emphasising facing two directions historic retrospective responsibility looks backwards seeking allocate respo nsibility conduct events occurred past shall see considerable ifficulties claimed arise allocating historic responsibility harms wrongs cau sed systems prospective responsibilities establish obligations duties associated roles tasks look future directed towards production good outcomes revention bad outcomes prospective responsibilities serve important guiding function cane puts one important reasons interested responsibility related concepts role play practical reasoning rights obligations people way behave dealings context responsibility actions resulting consequences yeung weller zalnieriute yeung hart cane dgi autonomous systems idea role responsibility sometimes legitimate effective response threats risks harms rights violations posed advanced digital technologies likely require focus consequences individuals society attends ensure prospective responsibility aimed reventing mitigating risks historic responsibility adverse effects arising peration complex systems technologies embedded duly justly assigned historic prospective dimensions respo nsibility attended individuals society confidence efforts ade first prevent harms wrongs occurring secondly occur nstitutional mechanisms relied upon ensure appropriate reparation repair revent harm wrongdoing necessitate focus involved evelopment deployment implementation technologies individual users roups affected action state states acting collectively operatively ensure establishment maintenance conditions needed safegu ard citizens unacceptable threats risks thereby ensuring human rights adequately protected words proper consideration responsibility chnologies systems attend positions moral agent moral atient well larger moral community generally order answer uestions responsibility advanced digital technologies including implicate existing conceptions sponsibility aving clarified mean responsibility highlighted need attend rospective retrospective dimensions position consider respo nsibility lies adverse consequences threats risks associated evelopment implementation technologies including human rights violations ther wrongs harms arising operation although question simple stat considerable conceptual challenges seeking answer eur opean group observed technologies raise questions human moral responsibility morally relevant agency located dynamic complex systems advanced robotic components moral responsibility attributed portioned responsible sense words complexity technologies larger ntexts implemented applied obscure lines moral responsibility articularly operate unexpected ways generate harm violate rights must bear mind moral responsibility legal responsibility distinct albeit rel ated concepts unlike morality law highly developed system institutionalizing enforcing responsibility including application sanctions certain circumstances ecause must adjudicate real world disputes requires finality judgement legal society rely exclusively individuals inclinations act hart see section liu zawieska cane european group ethics cane council europe study ethically lack institutional mechanisms enforce standards ncluding lawful authority sanction means entirely voluntary stem would fail provide stable reliable social foundations necessary trustw orthy peaceful social cooperation within contemporary societies law role sec uring institutionalising responsibility ensure protection legal rights enfo rce performance legal duties therefore essential following discussion emonstrates way legal systems allocated historic responsibility pically sensitive interests victims society security person property comparison moral philosophical accounts responsibility nded focus conduct moral agent whether appropriately attracts lame yet applying moral legal concepts responsibility development mplementation advanced digital technologies including contemporary contexts may straightforward capacity technologies systems operate ways previously possible may challenge existing legal moral social nceptions responsibility particularly given properties identified section resp including inscrutability opacity complex dynamic nature reliance human input interaction discretion general purpose nature global interconnectivity scalability ubiquity automated continuous operation often reliance large capacity generate hidden insight merging data sets ability accurately imitate human traits greater software complexity include vulnerability failure malicious attack capacity personalise configure individual choice environments capacity redistribute risks benefits burdens among individuals roups via use optimisation systems reconfigure social env ironments choice architectures capacity generate collective action problems befo proceeding important clarify conceptual distinction two different pes adverse effects may arisen operation systems violations human rights including limited rights protected echr tangible harm human health property environment separate distinct concepts consequences possible human rights iolation occur without tangible harm vice versa example removal cebook iconic photograph naked old girl fleeing napalm bombs uring vietnam war grounds nudity violated community standards nderstood violation article right freedom expression information though generate substantial tangible conversely car llides injures wild animal entails infliction harm without human ghts violation yet given event series events may entail tangible harm iolation human rights thus vehicle collides fatally injures see scott isaac dgi pedestrian would entail violation article right life infliction tang ible focus report examining responsibility implications systems uman rights perspective therefore primarily concerned analysing responsibility uman rights violations rather responsibility tangible harm arising operation systems following discussion focuses primarily upon create develop mplement preside systems asks whether held responsible verse consequences systems might generate beginning examination two themes arisen contemporary responses concerned identifying respo nsibility lies risks technologies may pose first voluntary action industry promulgating publicly proclaiming commitment called ethical uidelines secondly claims systems act autonomously relieves creat ors responsibility decisions consequential adverse effects bligations state relation adverse effects considered various models responsibility might apply ascribing responsibility develop mplement systems described prospective responsibility voluntary ethics codes responsible project sing public anxiety recent techlash response growing power practices policies big tech firms particularly following use political cambridge analytica scandal precipitated numerous voluntary ethics initiatives tech industry initiatives typically entail promulgation set norms stand ards either individual tech firms group tech firms including technical standard setting publicly voluntarily espo using commitment comply publicised standards conduct often cal led codes ethical conduct initiatives understood part ovement towards liu zawieska refer responsible features initiatives worth highlighting firstly concerned rospective responsibility seeking identify allocate role responsibility spheres bligation involved stage design development deployment technologies aim demonstrating public seriousness mmitment addressing ethical one notable feature initiatives tend steadfastly avoid explicitly referring historic responsibilities nvolved design development deployment technologies things awry neither tend specify upon blame fall nsequences acknowledge obligation compensate adversely affected scope adverse effects regarded constituting legally recognisable harm varies national egal systems common law systems example forms arm emotional distress mental anguish may legally recognised harm purposes ompensation awards personl injury cases gilliker economist example beneficial movement supported future life institute see conn see example various recommendations guidelines developed ieee global initiative thical considerations autonomous systems example google objectives applications see pichai liu zawieska liu zaweiska loui miller eschelman council europe study rather liu explains role responsibility describes sense responsibility attaches individual virtue position occupies function expected fulfil therefore performance obligations connected individual role specified advance thus individual ischarged duties attached role office regarded due fulfilment seco ndly responsible initiatives characterised emerging rofessional movement located within longer standing social henomena often discussed rubric corporate social responsibility character ethical codes social rather legal entirely voluntary means hey obligations commitments specified codes legally enforceable violated initiatives typically make provision establishment aintenance enforcement institutions mechanisms independent ternal body empowered evaluate extent commitments mplied impose sanctions thus although initiatives rovide welcome recognition tech industry ethical development eployment advanced digital technologies matter public concern warrants acti attention initiatives lack formal institutional mechanisms enforce san ction violations systematic representation public setting tho standards accordingly initiatives roundly criticised form ethics washi failing take ethical concerns codes practice supported institutional mechanisms backed law ncluding provision external participation setting evaluation standards selves independent external oversight evaluate whether individual firms rganisations fact complied specified norms standards would stro nger basis upon affected society generally could confidence meaningful democratically legitimate safeguards place prevent itigate ethical risks associated technologies see section need meaningful effective safeguards human rights perspective insists upo time prospective approaches ensure historic responsibility event harm wrongdoing occurs duly allocated liu zaweiska argue though responsible project may welcomed leaves responsibility concerned role responsibility rather causal responsibility like role responsibility causal responsibility form historic responsibility concern identify establish relation cause effect thus retrospective nature nherently relational orientation foregrounds moral patient cane critical narrowly defined way role responsibility attached specific roles tasks bserving responsible person involves taking seriously prosp ective responsibilities hatever attaching whatever activity one engaged particular time cane liu wagner metzinger green hagendorff nemitz see ahrc supra david kaye special rapporteur promotion protection right reedom opinion expression general assembly stated development codes ethics accompanying institutiona structures may important compement substitute ommitments human rights codes guidelines issued public private sector bodies shoud mphasize human rights law provides fundamental rules protection individuals ontext artificial intelligence general assembly dgi person persons harmed relevant activity contrast allocation responsibility focuses prospective role responsibilities identified respo nsible agents accordingly responsibility gap arises discharging one rospective role responsibilities necessarily guarantee causal responsibility duly words designation role responsibility ensure retro spective accountability allocate blame concerned lfilment obligations rather atonement accountability machine autonomy alleged control problem alleged control problem frequent claim made response concerns need identify respo nsibility lies adverse implications advanced digital technologies systems operate less autonomously without direct human intervention ntrol outside develop implement fairly regarded respo nsible decisions actions corresponding consequences view utlined argues agent considered responsible knows particular facts urrounding action able freely form decision act elect one suitable set available alternative actions based increasing class machines matthias refers autonomous artificial agents capable fulfilling often quite narrow purposes moving autonomously space acting without human supervision agent software rogramme moves information space internet search spider physical presence robotic pet move time space ents deliberately designed act inevitably interact things people cial entities laws institutions expectations least physical resence learn direct interaction real environments return irectly manipulate environment share environment humans atthias argues responsibility gap arises machine agents kind uman agent programmed longer exerts direct control machine agent ehaviour gradually transferred machine would therefore unjust old humans responsible actions machines could sufficient offers several examples kinds machine agents including rel upon legal literature term victim potential victim tends used rather moral patient atter common applied philosophical literature liu zaweiska liu matthias matthias matthias argument prominent shaping debate underlying choice theory oral responsibility upon argument rests challenged instead academic responses ave either sought counter argument via commitment methodological moral individualism uch every action ultimately attributable human individuals whatever role objects layed bringing particular outcome ancillary hanson view council europe study operation artificial neural networks instead clear distinct symbolic repr esentation information flow control sometimes large matrix naptic weights directly interpreted rather knowledge behaviour sto red neural network inferred indirectly experimentation plication test patterns training network finished reinforcement learning usually based neural network concepts ditionally lifts distinction training production phase reinforcement earning systems explore action space working operational environment whi central feature enabling adapt environments well big drawback concerning predictability information stored network fully checked even indirectly always changes even prove athematically overall performance system eventually converge optimum unavoidable errors way optimised state creat system matthias comments really programmer traditional sense eliminate errors must explicitly permitted order stem remain operational improve performance genetic programming methods additional layer code perates programmer product programming unlike neural etworks designer still defines operating parameters system etwork architecture input output layers interpretation least efines alphabet used semantics symbols genetic programmer loses minimal amount control creates machine programs time matthias observes autonomous agents deprive programmer spa tial link programmer resulting machine agent accordingly achine agent acts outside programmer observation horizon might able ntervene manually case fault error might occur much later point thus processes involve designer machines increasingly losing control gradually transferring control machine according matthias programmer role changes coder creator software organisms nfluence creator machine decreases influence operating environment ncreases programmer transfers control product environment specially machines continue learn adapt final operating environment articularly given agents interact potentially great variety umber people users situations typically possible creator redict control influence operating environment according matthias net resul machines operate beyond creators control may thus cause harm justly hold responsible yet matthias argues chnologies conceived tool employed humans responsibility fault always side humans programmers coders manufacturers developers users etc johnson brys sullins others responded considering signal instantiation ral legal person independent ontological status gunkel including ascription moral ency computational systems dennett sullins however weight academic opinion enies entities moral responsibility right lack ntal qualities hence meet epistemic condition generally accepted necessary moral sponsibility least philosophical literature often expressed terms intentionality capacity act voluntarily awareness actions anticipated consequences tions johnson kuflick sparrow asaro hanson dgi without systems must find way address responsibility gap oral practice legislation theories moral responsibility atthias claim create autonomous machines justly held respo nsible actions rests choice account moral responsibility tended dominate contemporary academic reflection concerning ethical moral mplications according accounts moral responsibility conduct rightly att racts blame fault fault understood terms freely thi account agent morally responsible unwanted outcome caused establish caused must engaged conduct held cau sally responsible establishing causal link requires voluntarily chose engage relevant conduct even conduct turns consequences effects intend want according matthias developers computational ents capacity make decisions ways rogrammed advance human developers developers lack requisite degree ntrol therefore morally responsible decisions computational ents validity claim capacity computational agents act autonomously reaks chain causation acts developers decisions taken tho agents highly preliminary matter important recognise cho ice theories moral responsibility particularly unsuitable model identifying respo nsibility human rights violations inherent nature concept rights enerally human rights particular protect values fundamental mportance interference attracts responsibility per without proof consider example facebook removal iconic image etnamese girl circumstances national legislation imposes legal obligations state actors respect human rights facebook would regarded egally responsible violating right freedom expression without need emonstrate capacity control whether image removed rds violation right freedom expression occurred even decision taken automated algorithmic system acting independently without irect human intervention even human designers automated system ntended foreseen specific image question might automatically removed models allocating responsibility though model responsibility applies human rights violations widely nderstood one strict responsibility without need proof fault allocation obligations repair tangible harm health property may legally distributed acco rdance variety responsibility models systems might operate ways result human rights violations harm individuals property matthias wallace cited cane matthias recent affirmation see gunkel ascribing causal responsibility action event interpretive act matter scientific ruth per see special representative secretary general ruggie principles council europe study allocation historic responsibility harm serves guiding function nvolved design development production implementation systems speci fying nature scope obligations models briefly outlined llowing discussion variety legal models might applied allocate istribute adverse effects arising conduct clearly demonstrates mistake expect one single model responsibility apply fairly ifferent kinds adverse consequences might flow use advanced digital chnologies previously noted unlike philosophical analysis responsibility tend focus agents expe nse victims society legal models relational sense concerned position individuals conduct attracts responsibility moral agents also impact nduct individuals society legal scholar philosopher eter cane observed esponsibility function quality manifested conduct quality conduct also concerned interest share ecurity person property way resources risks istributed society responsibility relational words legal responsibility emphasises relationship moral agents moral atients society generally rather focusing exclusively conduct moral ents whether conduct justly attracts responsibility accordingly academic analysis variety ways national legal systems allocate responsibility conduct cau ses harm adverse events including rights violations may may result arm demonstrate models entails different balancing interest oral agents moral patients victims typically referred legal scho larship discussion however seek evaluate whether current legal proaches adopted within national legal systems adequately allocate responsibility harm thro ugh application national civil liability rules particularly given capacity national allocate historic responsibility harms wrongs systems yet fully sted via instead following discussion briefly outlines four broad models respo nsibility reflected legal systems notably ased models models strict responsibility mandatory nsurance exemplars different ways legal responsibility risks concept responsibility used much commonly outside law refer human conduct consequences thereof trigger responses tend speak moral responsibility one hand legal liability latter referring primarily formal institutionalised mposts sanctions penalties characteristic law legal systems morality cane cane cane european commission currently undertaking reviewing issues see example european mmission various bodies working seeking evaluate capacity national civil liability rules respond equately harm arising operation systems example european commission ntends produce guidance address way product liability directive plies artificial intelligence robotics internet things european commission study identifies various models responsibility utilised legal systems simple ason author report trained familiar legal ystem taken indication models representative responsibility dels reflected legal systems way superior models adopted elsewhere dgi human rights violations collective harms might intended erely heuristics aimed highlighting range potential models responsibility ight used allocate distribute threats risks harms associated use vanced digital sketches therefore selectively describe refer condition epistemic condition applicable odel rather providing complete detailed account model content ntours taken together reveal model strikes different balance interest agents freedom action interest victims rights interests security person suggests identifying models appropriate allocating distributing various risks associated peration advanced digital technologies means entail soci policy choice concerning burdens appropriately allocated istributed models models constitute core model responsibility nderpins criminal law focus primarily voluntariness agent conduct interpreted requiring satisfaction two conditions firstly control ndition demonstrating agent causally responsible legally proscribed nduct far agent free voluntary choice concerning whether act secondly epistemic condition requiring proof fault broadly understood requ iring agent actual knowledge awareness particular facts sur rounding harmful consequences agent conduct agent action nderstood based model respo nsibility underpins accounts moral responsibility redominated discussions concerning whether human evelopers autonomous computational agents morally responsible actions tho agents time least computational agents lack capacity sub jective knowledge awareness intent responsibility models readily plied computational agents per satisfy requisite epistemic models however applied human evelopers users computational agents conduct individuals according european parliament draft motion civil liability rules robotics civil iability damage caused robots crucial issue also needs analysed addressed ion level order ensure degree efficiency transparency consistency mplementation legal certainty throughout european union benefit citizens consumers bus inesses alike european parliament committee legal affairs legal systems distinction civil criminal law critical importance primary purpose criminal law impose penalties punishments engage riminal conduct hence paradigm riminal liability focuses primarily alleged offender onduct mental state contrast primary purpose civil law identify allocate legal bligations repair identified legally responsible relevant harm accordingly sponsibility civil law concerned also impact conduct others operation civil criminal law paradigms fault based neg strict responsibility models distinction civil criminal law aradigms discussed extensive discussion see cane cane danaher law mental elements legal fault criteria intention recklessness malice see cane hildebrandt himma solum gless andrade council europe study intentionally develop deploy technologies dangerous malicious purposes ample order commit fraud misappropriate property would clearly satisfy requ irements establishing responsibility model prima facie violation human rights would arise proof subjective ntent could shown would need legal responsibility ghts violations typically strict would also likely generate responsibility nder criminal law offences person property well triggering civil obligations repair restoration models law models legal responsibility tangible harm basis general duty take reasonable care prevent foreseeable risks harm models responsibility conventionally applied determine whether agents sub ject legal obligations repair towards suffered harm result ent failure discharge general duty care control condition similar whi applies models responsibility also applies models insofar must shown ent caused relevant damage injury however epistemic condition applicable models considerably less demanding applicable models example legal liability negligence rican law require proof agent accompanying mental state thereby see king strike fair balance interest agents freedom action nterests victims safety security legal philosophers emphasised order old agent morally responsible agent need fact actual subjective kno wledge consequences behaviour order justly held responsible john oberdiek explains facts matter morally endowed normative force ears upon permissibility prospective action reasonably deciding upon course action oberdiek points ordinary erson morally expected take reasonable epistemic care expected know facts stick head sand fall back subjective nderstanding failed take reasonable care find discover relevant facts acco rdingly whether responsibility based model ascribed human developers computational agents systems circumstances stems generate decisions behaviours cause harm depend upon whether arm reasonably foreseeable consequence computational systems actions ecisions negligence law legal responsibility causing harm ascri bed subject legal duty care duty arises broadly speaki reasonably foreseeable risk action could harm proximate person use technologies commission crime might appropriately regarded aggravating fac tor commission criminal offence see see also hallevy causation negligence may negated application principles remoteness damage horsey rackley chapter hart oberdiek dgi foreseeability therefore operates define kinds risks person may egally responsible bounds harms may reas onable foreseeability also plays role determining person expected act uty care discharged person acts ordinary person exercising reasonable care oid foreseeable hence reasonable foreseeability operates touchstone etermining relevant reference class evaluating whether activities riving may result tangible harm others gives rise legal duty care oberd iek observes common law standard appropriate moral standard ecause case activities important able hold ther accountable respective characterisations risk words must justify characterisation way withstands moral order identify whether reasonably foreseeable given risky action ight ripen harm encounter called reference class problem berdiek plains reference class problem problem redescribabi lity articular risk infinitely uniquely correct nerative reference class credible beliefs take example consider fatal injury caused uber vehicle collided woman pushing bicycle shopping bags hanging handlebars vehicle operating mode minutes mistook woman car hich therefore expected would take evasive action recognising mistake anding back control vehicle human driver seconds collision human river able seems unlikely car developers could reaso nably foreseen vehicle sensing system would mistakenly believe woman pushing bicycle shopping bags dangling handlebars another ehicle hand seems well within bounds reasonable foresight car sensing technologies would fail correctly classify unusually shaped objects enco untered normal driving conditions errors kind might lead fatal llisions time identifying whether particular events associated operation articular technological object reasonably foreseeable invariably product perience exposure emerging phases new technology eing rolled expectations behaviours consequences relatively nsettled however time passes become accustomed omission failure act causes harm criteria manifest range particular ays one duty protect others risks arise result one creating source nger one assumed responsibility person interests liphant chapter oberdiek oberdiek oberdiek smith example microsoft experimental tay chatbot designed learn converse human onversational terms observing interacting twitter users improving performance via onversational interaction learning programmes engage web users casual onversation instead quickly learned parrot slew hateful invective uman twitter users fed bot resulting microsoft decision shut chatbot kind sponse fact anticipated tay developers yet could persuasively argued responses council europe study patterns behaviours action behaviours actions may become fam iliar developers therefore likely regarded reasonably foreseeable herefore developers technologies held responsible negligently failing take steps would averted resulting harm yet even thi begs question reasonable expectations tech industry making ecision release emerging technology real world contexts rightly implement emanding governance regimes new pharmaceuticals also true risky vanced digital technologies ditional questions arise concerning minimum standard care system evelopers responsible attaining design implementation tonomous computational systems consider fatal collision uber vehicle whi misclassified pedestrian wheeling bicycle approaching vehicle ntemporary discussions common refrain autonomous cars safer uman drivers thereby suggesting relevant comparator reasonable human river appropriate apply model responsibility standard care apply ordinary human vehicle driver operating traditional car unintended harm resulting actions car propriate apply model responsibility conventionally applies product anufacturers govern development operation vehicles ntemporary european law systems model strict responsibility product defects scussed words important policy choices made means standard ordinary human driver provides sui table strict responsibility study already noted model legal responsibility applicable rights violations ncluding violations human rights fundamental freedoms strict responsibility strict legal liability called anglo legal parlance model respo nsibility attaches agent without proof fault legal responsibility rights iolations attaches cause regardless whether responsible agent eng aged conduct breached legally specified standard conduct regardless whet conduct intended accompanied particular mental varieties strict liability identified cane three direct relevance study strict liability strict liability arises legal rights violated violation sphere protection bounded right triggers liability classic example tres pass land interfering owners right exclusive dominion intrusions without consent constitute unlawful interference intruder sense blameworthy already noted violations uman rights fall category cases kind reasonably foreseeable given volume frequency offensive posts mad online via twitter see guadian liu zaweiska nemitz thomas thomas thomas cane dgi outcome based strict liability form liability rests causation adverse utcomes extrinsic consequences regardless fault contemporary european roduct liability laws based model imposes strict liability anufacturers defective products cause harm natural persons rel ation advanced digital technologies questions arise concerning constitutes rel evant defect consider fatal collision uber vehicle initially isclassified pedestrian wheeling bicycle another vehicle handing back control human driver soon recognised error however late human river prevent collision could argued circumstances vehicle defective far functioned precisely way developers ntended hand defective interpreted mean fit purpose vehicle failure correctly classify pedestrian take evasive action avoid fatal collision could readily characterised similar approach often plied risk damage linked unpredictability behaviour specific groups animals cases liability attributed persons nsidered responsible supervising animal typically regarded best laced adopt measures prevent reduce risk harm strict liability arises connection specified activity various possession offences laws prohibit possession guns knives illicit sub stances forth law vicarious liability important form acti strict liability relevant activity defined primarily terms rel ationship another person whose breach law first person held stri ctly liable virtue relationship vicarious liability applies employment rel ationship employer strictly liable unlawful conduct ployee carried course duty jurisdictions may adopt stri liability approach towards carry dangerous activities operator nuclear power plant aircraft ultimately responsible dangerous acti vity owner vehicle cases underlying rationale erson created risk time also derives economic benefit acti various forms strict liability distribute risks associated potentially harmful acti vity agents victims ways accord considerable weight interests ictims security person property recognise responsibility merely function quality agent manifested conduct quality conduct also concerned interest share security person roperty way resources risks distributed society thereby delineating undaries responsibilities mandatory insurance rather focus allocating responsibility potential candidates understood contributing harms wrongs might arise operation advanced igital technologies society might decide instead prioritise need ensure see european union strict liability damage caused autonomous robots favoured european parliament draft tion civil law rules robotics european parliament committee legal affairs european commission cane council europe study harmed operation technologies financially mpensated may achieved instituting kind mandatory insurance scheme hich could established basis establishing insurance fund tho harmed operation technologies could scheme ight funded various ways including via contributions tech industry aims administered independent public authority one could also simply require rms involved value chain advanced digital systems designed implemented take mandatory liability beyond scope thi study evaluate desirability schemes benefit enabling armed operation technologies seek financial compensation rcumstances difficult identify precisely firms ought regarded respo nsible harm relevant firms become insolvent may become ncreasingly important become reliant autonomous intelligent systems ntinue operate long human corporate developers owners died cease exist societies may need develop institutions collective nsurance order ensure victims systematically left roposals confer legal status intelligent machines order facilitate administration compensation payments injured victims proposed responsibility challenges posed complex dynamic systems preceding analysis proceeded largely assumption seeking assign respo nsibility adverse consequences advanced digital technologies rel ations readily identified practice however technologies form essential mponent highly complex sophisticated systems generating acute cha llenges seeking identify lines causal moral legal responsibility three cha llenges briefly outlined following discussion problem many hands umans loop unpredictable effects complex dynamics arise etween multiple interacting algorithmic systems problem many hands exc ept relation forms strict responsibility assignment responsibility threats risks harms rights violations including human rights violations typically european parliament committee legal affairs recommended scheme kind harm caused specific categories robots recommending obligatory insurance scheme could based obligation producer take insurance autonomous robots produces stablished supplemented fund order ensure damages compensated cases insurance cover exist european parliament committee legal affairs european commission example european parliament committee legal affairs called european commission onsider creating specific legal status robots long run least sophisticated utonomous robots could established status electronic persons responsible making ood damage may cause possibly applying electronic personality cases robots make tonomous decisions otherwise interact third parties independently european parliament mmittee legal affairs european parliament policy department citizen rights constitutional affairs juri committee emphatically opposed particular proposal nevjans proposals separate distinct academic discussion concerning whether robots regarded moral agents entitled moral rights protection examination appropriate legal moral status agents independent agents right beyond cope study see solum koops teubner teubner dgi require assessment whether understood caused agent yet see king assign causal responsibility adverse effect could plausibly regarded direct consequence operation complex system hether utilises technologies one immediately encounters many hands problem arises one adopts based model respo nsibility first identified context information technology philosopher chnology helen problem many hands unique computers igital technology algorithms machine learning rather refers fact complex arr individuals organisations components processes involved evelopment deployment implementation complex systems stems malfunction otherwise cause harm becomes difficult identify lame concepts conventionally understood terms individualistic nceptions words causal responsibility necessarily distributed complex technological systems concerned diluting causation mere many hands problem may especially acute seeking identify locus resp onsibility harms wrongs resulting development operation stems given rely number critical components namely models developed order represent feature space ptimisation goal system intended achieve algorithms based models analyse data produce outputs whi may trigger som kind action decisio input data might might include personal data gorithms trained human developers involved design systems must make decisions models algorithms data used train algorithms upon performance tested include human beings ndertake task labelling data used train larger system context algorithmic system bedded operates assuming could satisfactorily identify allocation moral responsibility verse impacts relation components unlikely ensure ines moral responsibility unintended adverse consequences readily identified dynamically combined within complex integrated system challenges compounded fact digital products services open software tensions updates patches implemented change ftware system may affect behaviour entire system individual mponents extending functionality may change system operational risk relevant adverse event might systemic individual harm individual human ghts violation necessarily entailing material loss damage harm collective interests thompson nissenbaum thompson liu zaweiska zalnieriute council europe study profile including capacity operate ways might cause harm violate human responding challenges may helpful bear three considerations mind rstly issues relating allocation legal responsibility harm arising activities nvolving multiple parties new many legal systems therefore developed rel atively sophisticated set principles procedures determining liability ultiple potential defendants european commission recently bserved identifying distribution liability redress amongst multiple actors involved value chain emerging digital technologies operate may relevant purposes ensuring victims obtain compensation damage suffered although reso lving questions likely important overall policy standpoint order rovide legal certainty involved production implementation secondly relatedly law ability devise practical responses despite apparent intractability many hands problem least partly attributed reater emphasis places legitimate interests moral patient security person rather almost exclusive focus moral agent reflected cho ice theories moral responsibility upon many hands probl rests thi rdly focus report responsibility human rights violations arising fro development implementation advanced digital technologies rather respo nsibility harm particularly important ensure effective egitimate mechanisms operate prevent forestall human rights violations articularly given many human rights violations associated operation vanced digital technologies may result tangible harm individual health property need preventative approach especially important given speed scale whi technologies operate resulting cumulative aggregate effects uman rights violations caused operation systems could seriously erode social undations necessary moral democratic orders essential preconditions uman rights exist suggesting existing approaches human rights protection need reinvigorated networked interaction many individuals firms organisations involved development mplementation advanced digital technologies technologies often intended perate ways involve retaining active human points serious cha llenges associated identifying appropriate distribution authority thomas see example models shared responsibility liability hosting platforms streel bui ten peitz helberger european commission see section human oversight may achieved governance mechanisms hitl hotl hic approach hitl refers capability uman intervention every decision cycle system many cases neither possible esirable hotl refers capability human intervention design cycle system nitoring system operation hic refers capability oversee overall activity ystem including broader economic societal legal ethical impact ability decide use system particular situation include decision use system particular situation establish levels human discretion use system ensure ability override decision made system see high level expert group dgi responsibility humans machines given complex interaction particular many tasks previously performed humans undertaken machines humans invariably involved various points throughout chain development sting implementation operation royal academy engineering observed always humans chain unclear case injury hich human chain bears responsibility designer manufacturer rogrammer interaction humans machines within complex dynamic stems generate especially challenging questions concerning appropriate role humans supervising operation one recurring theme concern order ensu increasingly complex systems always operate service umanity systems always designed shut human perator yet royal academy engineering observed might thought always need human intervention ometimes autonomous systems needed humans might make bad oices result panic especially stressful situations therefore uman override would problematic human operators always right always best intentions could autonomous systems trusted ore human operators situations hand even humans retained loop aim supervising mputational systems individuals placed positions may understandably reluctant intervene decade ago johnson commented case future automated air traffic difficult question whether human air traffic controllers intervene comp humans formerly held role sponsibility duties either replaced caretakers technology become caretakers concern environment umans assigned interact automatic systems may perceive ntervention morally risky better may reason let computer ystem act humans stay way intervene behaviour tomated computer systems call doubt wisdom system esigners expertise system ime person ooses intervene system brings heavy weight moral responsibility pon hence human controllers incentive let automaticity computer system unchallenged flight esponsibility part humans shows responsibility igned sense computer increasingly rely expanding range services systems automation akes possible particularly digital technologies grow ever powerful phisticated continued insistence placing human loop act supervisory cap acity risks turning humans placed loop moral crumple zones largely totemic umans whose central role becomes soaking fault even partial control royal academy engineering royal academy engineering johnson powers question far humans responsibly transfer functionality computer ithout time reserving humans see kuflik council europe study system vulnerable scapegoated tech firms organisations see king avoid responsibility unintended adverse elish twang stud aviation autopilot litigation highlights modern aircraft largely controlled ftware yet pilots cockpits remain legally responsible aircraft operation yet cul tural perceptions tend display automation bias elevating reliability infallibility automated technology whilst blaming humans error see box automation bias responsibility humans loop collision tesla car mode exemplifies tendency blame roximate humans loop unintended adverse consequences rather sur rounding system human embedded tesla collided truck may due vehicle autopilot fai lure detect truck official investigation following collision revealed though autopilot functioned designed detect truck human failed respo investigation concluding driver automation monitoring steering wheel torque effective methods ensuring driver eng agement authority undertaking investigation concluded crash result speci fic defect autopilot system tesla responsible accident tesla provided adequate warning customers indicating autopilot stem must operated supervision human driver driver ands remain wheel eyes road responsibility lay uman driver addition tesla terms services included provisions referred sem nature autopilot stating driver take control car seconds driver noticed problematic vehicle behaviour ource european commission staff working docum ent liability emerging digital technologies apr unpredictable dynamic interactions complex systems ven intractable challenges arise seeking identify anticipate prevent adverse ents arise interactions complex systems occur speed scale simply possible elish elish points tragedy air france flight crashed atlantic ocean killing people board classic example positioning individual pilots moral crumple zones flight flown storm route brazil france resulting ice crystals forming lane pitot tubes part avionics system measures air speed frozen pitot tubes sent faulty ata autopilot turn reacted precisely way designed react sence data automatically disengaged transferring control aircraft back human pilots pilots caught surprise overwhelmed avalanche information flashing lights loud arning signals confusing instrument readings official french report concluding lost ognitive control situation series errors incorrect manoeuvres pilots resulting fatal crash elish observes news coverage accident report emphasised pilots errors fai led draw attention fact many errors least partly due automation hanging kind control exercised human operator creating opportunities new kinds error elish ibid dgi age flash crash occurr stock market went freefal five minutes correcting apparent reason provides vivid individual agents capacity learn env ironment iteratively improve performance might subject mathematical erification testing identifying multiple different algorithms might interact gorithmic agents complex dynamic ecosystem generates risks unpredictable otentially dangerous outcomes words interactions generate risks ave barely begun challenge devising solutions enable reliably predict model take action prevent unwanted potentially catastrophic outcomes ari sing interaction dynamic complex systems generates new increasingly urgent frontier computational research leading computer sci entists shadbolt hampson warn dangers hyper stems generating considerable new risks response needs vigilant intelligent inventive long remain control machines benefit greatly need evelop policy frameworks beyond dangers world opportunitya state responsibility ensuring effective protection human rights one significant concerns emergence algorithmic systems increasing power big tech firms including concerns radical power asymmetry etween firms individuals subject accordingly ands firms power deploy algorithmic systems overwhelmingly resides obligation protect human rights international domain law lies primarily ation states given human rights protection primarily intended operate vertically rotect individuals unjustified interference state however well established echr jurisprudence rights protected convention ground positive substantive bligations requiring member states take action order secure within risdiction rights protected accordingly states obliged echr introduce national legislation policies necessary ensure echr ghts duly respected including protection interference others including tech rms may therefore subject binding legal duties respect human enforceable legal obligations grounded convention protection human rights ncluding right effective remedy offers solid foundations imposing legally enfo rceable effective mechanisms ensure accountability human rights violations beyond contemporary rhetoric ethics form voluntary self egulation tech industry realistically expected akansu smith shadbolt hampson ibid schwab economist rainey wicks ovey scope extent required protection depend upon particular right question ibid pilot judgement procedure european court human rights provides institutional mechanism rough states directed adopt individual remedial measures domestic legal orders rder bring end violations found court supervised committee ministers see glas council europe study discussion various models allocating historic responsibility outlined section raws largely legal approaches introduced via legislation adjudicated courts developed courts interpretation application common determining legal liability harm wrongdoing one significant drawback asso ciated reliance upon judicial remedies redress concerns etter suited remediating substantial harms suffered opposed less gnificant harms suffered many difficulties seeking redress via courts agnified space challenge detecting harm determining proving cau sation say nothing serious practical obstacles disincentives faced ndividuals invoking judicial time capacity systems lobally networked environment generate collective action problems already ighlighted underlining need importance properly resourced national enfo rcement equipped adequate enforcement powers authorities may also sug gest accessible convenient collective complaint mechanisms may necessary ensu enforcement action taken relation human rights violations resulting operation systems time important recognise addition nventional legal mechanisms redress via courts many institutional overnance mechanisms could help secure responsible human evelopment implementation advanced digital technologies following section theref ore provides brief outline possible institutional governance mechanisms beyond voluntary self initiatives currently emerging may serve enhance oth prospective retrospective responsibility threats risks harms wrongs ari sing operation advanced digital technologies briefly outlines several possible echanisms governance institutions might invaluable role play securing acco untability human rights violations could complement existing legal mechanisms mechanisms enforcing responsibility advanced digital technologies though regulatory governance mechanisms classified many different ways three features worth highlighting purposes study firstly distinguish etween mechanisms operate ante basis provide oversight aluation object process system implemented real world set tings therefore primarily concerned securing prospective responsibility ther hand post mechanisms operate implementation ccurred therefore primarily concerned securing historic responsibility stud already emphasised dimensions responsibility must attended order secure responsible development implementation systems yet stud primarily concerned human rights implications technologies eed effective legitimate mechanisms prevent forestall human rights iolations considerable importance particularly given speed scale stems operate combined culture move fast break things cha racterises operational strategy leading tech firms strategy consists forging ead rapid technological innovation without attending carefully potential risks vance preferring deal adverse blow event time may practically possible unwind technological innovations ready brought secondly important attend legal enf orceability regulatory governance institutions mechanisms order identify whet extent regarded optional mechanisms tech mantelero taplin vaidhyanathan dgi industry freedom selectively adopt ignore altogether whether legally andated substantial legal sanctions attach thirdly though regulatory governance mechanisms conventionally taken form social nstitutions present context role technical protection mechanisms rely pon modality control sometimes referred regulation design may equally important study turns technical protection mechanisms one promising fields research flourished response growing awarenes ethical legal concerns raised use technologies found technical responses emerged aim seeking hard particular alues design operation algorithmic techniques incorporated one features often associated design regulatory overnance mechanisms capacity operate real time rather ante post although early work field utilising technical measures secure rotection particular interests values use ict focused primarily chnological solutions protection parallel work also began take place field data privacy became known privacy design data protection esign work recognised technology could applied service interests alues concurrently threatened seeking improve bite legal norms rights data privacy seeking build norms information systems dition work privacy engineering recent research machine learning ftware engineering understood building approach seeking secure called human rights protection design include following explainable xai advances machine learning techniques including relying eural networks often used aid human decision yet logic easi explainable opt particular choice know readily interpretable explain present outcomes ways humans understand growing recognition need ensure outputs enerated systems rendered intelligible opened gnificant field computational research explainable xai fairness accountability transparency machine learning fatml similarly rowing community researchers directed attention towards developing chniques identify overcome problems digital discrimination referring bias discrimination arising use data mining machine learning nemitz yeung ibid ibid originally referred electronnic copyright management systems ecms later referred digital rights management systems drms bygrave see example kohane carton weller yeung weller see example samek wierzynski barocas selbst criado zliobaite council europe study techniques known discrimination techniques machine earning regulatory governance instruments techniques ore conventional social organisational forms regulatory governance instruments emerged response recognition technologies might utilised ways uld undermine important values including explicitly concerned ensuring technological systems operate ways respect human rights two briefly iscussed human rights impact assessment algorithmic auditing rights impact assessment various scholars organisations roposed various forms algorithmic impact assessment effect proposed models applied seeking procure deploy gorithmic systems order identify human rights ethical social implications thei proposed systems take steps ameliorate concerns design peration algorithmic systems prior implementation various general impact assess ment models proposed number models also een risk assessment models vary widely terms criteria assessment data protection law mandates use data rotection impact assessments dpias certain circumstances building pre isting approaches privacy impact assessment largely focused aluation impacts data quality security models human ghts impact concerned evaluating impact proposed stem human rights party undertaking assessment proposed models intended applied data controller dpias others propose assessment undertaken external third party accreditation body approach reflected see particular annual event organised fatml ttp resources listed ttp see general assembly endorses techniques example relation use algorithmic systems pubic sector see stitute report outlines framework public sector entities use carrying algorithmic impact assessments prior purchasing deploying automated decision relation riminal justice risk assessment see selbst oswald relation human rights risks internet registries see article article general data protection regulation gdpr requires preparation data protection mpact assessments data processing likely result high risk rights freedoms atural persons various models human rights impact assessment understood specific forms human ights due diligence growing guiding principles business human rights uses term due diligence essential first step towarad identifying mitigating redressing verse human rights impacts per rasso see also toronto declaration machine earning mantelero dgi guiding principles business human rights relation human rights due iligence mandatory voluntary adoption rights impact assessment roposals intended adopted voluntary basis data ntroller choose whether undertake assessment steps take light others dpia mandated law cert threshold conditions scale evaluation human rights impact assessment concerned scrutinising wide range business operations assess conformity human rights stand ards forms impact assessment dpia pia much narrower scale evaluation focusing single data processing activity pact assessment techniques valuable focusing attention various ways whi proposed activity may risk interfering human rights ways might therwise overlooked ignored yet order impact assessment approaches rovide real substantive protection necessary develop clear gorous methodological approach firms organisations willing adopt nsistently ways reflect genuine commitment identifying human rights sks rather merely regarding bureaucratic burden resulting ritual isplays formal compliance without genuine concern respect human algorithmic auditing unlike impact assessment approaches intended take lace system implementation algorithmic auditing techniques aimed testing evaluating algorithmic systems operation algorithmic auditing erging field applied technical research draws upon suite emerging rese arch tools techniques detecting investigating diagnosing unwanted verse effects algorithmic proposed techniques might formalised institutionalised within legally mandated regulatory overnance framework algorithmic systems least algorithmic stems regarded high risk systems terms seriousness scale consequences event failure unintended adverse effects subject eriodic review oversight external authority staffed suitably qualified chnical specialists example cukier suggest new roup professionals needed algorithmists take role may nstitute profession akin law medicine accounting engineering relied upon undertake task algorithmic auditing either independent ternal algorithmists monitor algorithms outside internal gorithmists employed organisations monitor developed deployed rganisation subjected external raso mantelero see mantelero edwards veale power desai kroll sandvig see example resources available auditing algorithms approach would resemble governance conventional financial auditing counting systems within organisations subject internal auditors employed house also fro external auditors legally obliged review accounts certify veracity val idity cukier see also crawford schultz citron council europe study standard setting monitoring enforcement techniques approaches described significant potential instruments thro ugh prospective historic responsibility systems rely upon advanced igital technologies might secured yet order potential realised must attend legal institutional governance frameworks embedded example various strands technical research referred section nsiderable potential facilitate prospective responsibility digital technologies providing lcome recognition technical community digital systems neutral mbued values might act ways consistent human rights important work nurtured supported also important emerges fro interdisciplinary engagement technical community law umanities social sciences order elaborate fully human rights values translated technical mechanisms protection human rights approach respo nds problem value conflict equally important attend legal atus techniques although tech industry keen adopt technical respo nses ethical problems merely placing blind faith industry solutions risks becoming erely another form ethics washing words unless technical approaches backed law subject transparent evaluation oversight mpetent independent authority ensure validity operation may provide effec tive human rights protection regulatory governance scholarship emphasised ital three elements regulatory governance process attended setting standards information gathering monitoring activity required comply tho standards enforcement action sanctions effective egitimate regulatory governance requires stakeholder participation setting rel evant standards properly resourced independent authority equipped adequate owers systematically gather information investigate sanction confidence technological protection mechanisms intended ensure human rights values respected operation digital processes must robust mechanisms oversight investigate verify fact operate hence technical standards developed ndependently ideally participatory process affected stakeholders involved subject external scrutiny examination compliance tho standards scrutinised external body power impose seek ensure imposition sanctions violation words without eaningful independent oversight mechanisms unlikely provide foundations securing meaningful human rights accountability various national local governments increasingly recognising need formal institutionalised systematic nsideration evaluation algorithmic systems reflected various ublic authorities commissioned provide review oversight chnical reinvigorating human rights discourse networked digital age enter new globally networked digital age need protect human rights nderlying value commitments upon rest paramount importance greene morgan yeung lodge wegrich nemitz summary national initiatives across europe see access dgi prompts consideration whether existing conceptions human rights echanisms enforced fit purpose new andscape powerful networked digital technologies emerged recent years ake possible practices actions previously impossible thereby create novel threats risks forms provoking reflection whether additional new uman rights regimes institutional governance required ensure risks meaningfully addressed although basic structure institutional frame work human rights protection universally recognised reasonably expected develop effective responses many threats cha llenges wrought rising power digital automation machine intelligence several reasons existing rights discourse enforcement mechanisms may requ ire reinvigoration provide effective protection firstly many rights nferred upon data subjects difficult assert practice largely due opacity systems technologies embedded secondly nderstanding scope content existing rights developed conceived rights might fail provide comprehensive protection full ran threats risks individuals technologies may give rise particularly relation illegitimate attempts deceive manipulate individuals persuasive technologies may enable see problems discrimi nation see example although rights data protection confer upon data subject right nsist upon human intervention express view contest fully automated decision profound effects rights apply partially automated decisions necessarily ensure practice affected individual readily detect whet treated unequally others whether differential treat ment amounted discrimination thus prima facie unlawful thirdly erhaps importantly considering adequacy existing human rights ndamental freedoms address new risks associated new digital technologies data subject freedom waive rights consenting specific practices would otherwise constitute thereby forgoing protections ghts example individuals rely article protect rights interests implicated provision services significant risk rights would readily waived individual networked age built pon free services business model thus return free access digital services efficiency convenience offer individuals willingly exchange personal contrast core data protection principles upon contemporary european data rotection regimes including modernised convention rest reflected risprudence european court human rights article include mandatory bligations imposed data controllers waived individual brownsword scotford yeung extent european court human rights willing recognise possibility individuals aiving echr rights conditions required effective waiver likely depend upon ight question specific context claimed waiver alleged arise example coppola italy september para court stated neither letter spirit article prevents person waiving free either expressly tac itly however waiver must effective convention purposes established nequivocal manner attended minimum safeguards commensurate importance dition must run counter important public interest relation private law ontractual relationships actors court likely consider issue waiver rms positive duty states take reasonable measures protect individuals infringement onvention rights private persons including obligation ensure legal regulation ther measures relevant rights practical effective exercise solove council europe study including principles lawfulness processing purpose specification data inimisation thereby offering systematic protection core underlying values llective interests regimes ultimately seek protect quite apart potential weaknesses individualised orientation ntemporary conceptions human rights existing mechanisms enforcement fail give due attention threats technologies may pose collective oods particularly need preserve nourish underlying undations make possible moral agency human rights space operate eading philosopher law technology mireille hildebrandt expresses concerns rms technical conditions assumed exist order law ntemporary understandings rule law fulfil yet within smart env ironments operate continuously collecting digital data material world rder infer predict therefore anticipate future behaviour things people systems technical conditions supplanted augmented thereby altering ossibility exercise currently understand thought choice reason ecause smart technologies operate continuously immanently esigned learn producing outcomes designers orth american jurist julie cohen develops hildebrandt insights drawing legal scho larship growing body work sociology science referred science chnology studies sts cohen argues ensure human rights perationalised era smart environments must take affordances seriously therwise rights ineffective according affordance theory design chnological objects environments condition constrain possibilities action ncluding range actions responses design object affords ser thus recognise smart digital technologies continually immanently mediate beliefs choices legal discourse human rights ncluding privacy understood incomplete cohen therefore persuasively argues requires merely extending rights discourse rather require econceive rights new ways well developing different vernacular rights iscourse one recognises central role sociotechnical configurations affording constraining freedoms capabilities people fact particular ghts discourse operated set often unexamined assumptions built env ironment properties constraint physical impossibility universal sur veillance lack constraint possibilities spaces people use gather assemble various purposes including democratic protest advances etworked digital technologies challenging assumptions earning relevant constraints affordances include affecting hysical space also affordances govern flow data information direct impacts rights freedoms therefore need expand frame rights discourse encompass architecture rights nceived terms affordances practical matter ways speak effective force new kinds material opera tional hildebrandt cohen citing hildebrandt cohen cohen cohen dgi words inability rights provide comprehensive response threats osed technologies deeply rooted inherent limitations proaches effectively address systematic harms experienced primarily llective societal level rather level individual example introduction new right meaningful human contact attractions ight effective addressing concerns systematic societal dehumanisation whi lies foundation many anxieties expressed increasing reliance computational technologies words aggregate cumulative effects technologies time scale may systematically threaten chnical foundations notion human rights presupposes ecause smart digital technologies radically different kind kinds chnologies societal challenge contend difference cusing architectural implications technologies attention drawn erspective cohen describes inherently communal highlights responsibility stat collective responsibility moral community attend undations moral democratic freedom way aggregate cum ulative impact adverse social concerns referred could fundamentally ndermine moral democratic commons without human rights ndamental freedoms practice realised asserted social foundations ust minimum ensure conditions necessary moral agency responsibility resent secure absence freedom human rights yet lack institutional mechanisms monitoring health chnical foundations human rights democratic freedom anchored thi may require develop new vocabulary rights institutional mechanisms ensuring health sustainability foundations secure meaningful human ghts protection new digital summary thi section highlighted importance ensuring responsibility actual otential adverse consequences associated development operation advanced igital technologies allocated prospectively retrospectively fair effective location responsibility threats risks adverse impacts vital rotect human rights safeguard welfare individuals groups society large even fundamentally ensure society remains moral community attributing responsibility adverse risks effects increasingly powerful phisticated digital technologies generates considerable challenges owing fact great many individuals organisations involved development mplementation may operate unexpected ways lcome recognition need take seriously responsibility risks verse effects advanced digital technologies found proliferation voluntary discussed section yeung hildebrandt cohen yeung yeung brownsword yeung council europe study initiatives tech firms tech industry promulgated codes good hical practice publicly proclaim aspire meet yet oluntary initiatives lack institutional mechanisms meaningful public articipation setting relevant standards external enforcement san ctioning mechanisms constitute legitimate effective safeguards though capacity advanced digital systems operate less autonomously een claimed distance developers responsibility operation claim rest particular narrow conception moral responsibility seen ran responsibility models might available allocating responsibility adverse mpacts systems noting relation human rights infringements responsibility propriately assigned strict basis without proof fault states bear primary duty ensuring effective protection human rights grounds legal obligation introduce ational legislative frameworks give rise legal duties obligations acto addition fundamental value human rights strength importance increasingly recognised grounding horizontal effects actors ncluding tech judicial remedies constitute important avenue whi adversely affected operation technologies might seek redress ave also identified range governance instruments including technical protection echanisms could utilised secure meaningful effective accountability whi warrant consideration although various governance mechanisms described backed help secure meaningful human rights protection nlikely provide adequate comprehensive protection particular advanced etworked digital technologies power sophistication nderstood radically different kind kinds technologies particularly given thei profound implications collective shared technical social democratic oral architecture societies must therefore reinvigorate existing human rights iscourse instruments ways foreground collective responsibility attend foundations moral democratic freedom way gregate cumulative impact adverse social concerns referred could ndamentally undermine moral democratic commons without human ghts fundamental freedoms practice realised asserted private sector comprehensively developed special rapporteur ruggie codified corporate social responsibility respect human rights act accordingly even ountries national legislation demand dgi chapter conclusion vances techniques referred artificial intelligence likely continue evelop grow power sophistication foreseeable future relatively recent success combined global interconnected data infrastructure erged time enabled proliferation digital services systems ready delivered considerable benefits particularly terms enhanced efficiency convenience offer across wide range social domains activities though access remains largely province inhabitants wealthy industrialised ations bring extraordinary promise potential deliver sub stantial improvements individual collective including potential enh ance capacity exercise enjoy human rights freedoms yet legitimate rising public anxieties adverse societal consequences including thei potential undermine human rights protection study highlighted uld threaten destabilise foundations upon moral agency ultimately rest study therefore sought examine implications advanced digital chnologies including concept responsibility human rights perspective identified series responsibility relevant properties technologies outlining ran adverse impacts technologies may generate sought identify responsibility preventing managing mitigating impacts including risk uman rights violations may allocated distributed thi study shown legitimate effective response threats risks harms rights violations potentially posed advanced digital technologies likely require cus consequences individuals society attends ensure prospective responsibility aimed preventing mitigating threats risks asso ciated technologies historic responsibility ensure ripen arm rights violations responsibility consequences duly justly assigned onl confidence sustained systematic effort made revent harms wrongs occurring occur underlying acti vities brought end effective legitimate institutional mechanisms ensuring appropriate reparation repair prevention harm place ecessitate focus involved development deployment mplementation technologies individual users collective interests affected role states ensuring conditions safeguarding individuals subject jurisdiction risks ensuring human rights adequately protected findings study worth highlighting particularly important ensure effective legitimate mechanisms operate prevent forestall human rights violations particularly given many human rights violations associated operation advanced digital chnologies may result tangible harm need preventative approach especi ally important given speed scale technologies perate real risk violations may erode collective undations essential freedom democracy human rights exist thi several implications firstly suggests states important respo nsibility ensure attend larger environment whi human rights anchored secondly stronger collective complaints echanisms may needed ameliorate collective action problem ndividuals may encounter responding rights violations generated peration systems thirdly existing conceptions human rights may need council europe study reinvigorated networked age order account way whi technologies may reconfigure environments threats may pose collective goods values model legal responsibility applies human rights violations widely nderstood one strict responsibility without need proof fault ntrast allocation obligations repair tangible harm may legally istributed accordance variety responsibility models briefly outlined ection variety potential legal models could applied locate distribute adverse effects arising conduct early demonstrates mistake expect one single model legal respo nsibility fairly apply different kinds adverse consequences ight flow use advanced digital technologies legal models respo nsibility emphasise relationship moral agents moral patients ciety generally unlike much applied philosophical analysis responsibility systems tended focus conduct moral agents whether conduct justly attracts responsibility agents expense moral patients victims society various legal models responsibility strike different alance interest agents freedom action interest ictims rights interests security person property identifying models appropriate allocating distributing various sks associated operation advanced digital technologies means sel entail deliberate social policy choice concerning risks shoul appropriately allocated distributed democratic societies espo use commitment human rights state bears critical responsibility ensu ring policy choices made transparent democratic manner whi ensures policy ultimately adopted effectively safeguard human ghts various strands technical research considerable potential help secure rospective historic responsibility advanced digital technologies evelopment techniques may enable effective technical protection echanisms meaningful algorithmic auditing research nurtured supported needs developed interdisciplinary engagement etween technical community law humanities social sci ences order elaborate fully human rights norms translated nto technical mechanisms protection human rights approach responds problem value conflict taking human rights seriously hyperconnected digital age require effec tive legitimate governance mechanisms instruments institutions lace monitor oversee development implementation operation mplex systems suggestions might take forward need ensure governance mechanisms institutions capacity set appendix voluntary initiatives tech ndustry via promulgation called ethical standards conduct ublicly claim seek honour constitute welcome recognition tech ndustry technologies develop may produce adverse effects whi bear responsibility however provide adequate bust human rights protection minimum responsible development mplementation requires democratic participation setting rel evant standards existence properly resourced independent authorities dgi equipped adequate powers systematically gather information investigate sanction violations particular confidence technological protection mechanisms intended ensure human rights alues respected operation digital processes must bust independent mechanisms external oversight investigate verify fact operate otherwise unlikely provide foundations securing meaningful accountability respect obligation states ensure governance mechanisms established implemented way ensure protection human rights serious commitment protect promote human rights yperconnected digital age allow power advanced digital chnologies systems develop implement accrued ercised without responsibility fundamental principle reciprocity applies eploy reap benefits advanced digital technologies including rovision services derive profit must responsible adverse nsequences therefore vital importance nations committed protect human ghts uphold commitment ensure wield digital power including ower derived accumulating masses digital data held responsible nsequences follows obligation states protect human rights duty introduce national law governance arrangements ensure rospective historic responsibility adverse risks harms rights violations arising fro operation advanced digital technologies duly allocated council europe study appendix thi appendix identifies range measures institutional mechanisms might warrant rther consideration research order help ensure human rights protected age advanced networked digital technologies intended reco mmendations merely invite reflection discussion rospective responsibility nsider offering additional funding support encourage interdisciplinary research med developing techniques mechanisms standards help ensure rospective responsibilities preventing mitigating risks harm wrongs arising peration advanced digital technologies duly assigned nsider measures encourage states interstate cooperation work towards eveloping legally supported institutional governance mechanisms facilitate protection human rights threats risks posed advanced digital technologies might clude legal requirements undertake human rights impact analysis incorpo rating gorithmic impact analysis prior deployment advanced digital technologies ncluding publicly available statement identifying potential interferences uman rights value conflicts resolved system architecture operation develop conjunction wide range stakeholders code best practice reparing human rights impact analysis advanced digital technologies clarify scope content legal obligations involved evelopment digital services including software developers particularly bligations bear directly upon human rights protection consider need subject developers providers legal obligations engage demonstrate adequate verification testing complex computational stems may direct substantial impact human rights prior rel ease periodic intervals following implementation environments encourage use technical protection mechanisms human rights esign data mining techniques explainable identifying serve valuable role ensuring human rights adherence consider need provide legal support techniques including subjecting external versight review order provide greater level assurance echanisms operate fact ways human rights compliant encourage research development techniques standards sup port responsible compliant innovation digital tech industry ncluding modelling data provenance quality algorithmic auditing validation erification testing consider establishing professional accreditation scheme appropriately qualified chnical experts trained algorithmic auditing techniques class professionals subject fiduciary duties loyalty good faith verifying certifying desi operation algorithms dgi develop methodological framework set metrics systematically identifying evaluating magnitude seriousness potential threats risks ndividual rights including threats pose foundations whi human rights fundamental freedoms anchored posed proposed otential applications consider whether applications pose threats judged serious disproportionate human rights impact prohibited nless subjected prior public consultation approval propriately constituted independent supervisory authority framework might include class applications prohibited outright pose unacceptable grave potentially catastrophic threats human rights ndamental istoric responsibility nsider supporting development guidance techniques help ensure istoric responsibility duly assigned individual collective harms rights violations resul ting operation advanced digital technologies may include encouraging stat intergovernmental cooperation towards developing legally supported institutional overnance mechanisms might include member state action review assess whether national legal systems operate ensure responsibility harm caused advanced digital technologies uly allocated identifying potential gaps may need addressed via egislative reform consider need develop instruments clarify locate efault historic responsibility harms wrongs involved esign developers deployment ownership provision digital systems uld include legal liability make reparation harmed wronged peration services including obligation compensate introduce easures avoid future occurrence developing suitable instrument nsideration might given desirability kind due diligence defence certain clearly narrowly defined circumstances leading reduction tent developer legal responsibility harm wrongdoing support research appropriate distribution allocation authority etween humans loop complex computational systems light ackno wledged problem automation bias tendency allocate responsibility ndividual humans loop rather develop implement system human embedded see also high level group artificial intelligence council europe study consider desirability mandating compulsory insurance regime digital industry including whether establish national insurance scheme funded igital tech industry ensure victims left uncompensated support development capacity establish new extend capacity existing governance institutions meaningfully rigorously investigate enforce prospective historic responsibilities digital service developers roviders consider desirability introducing collective complaints mechanisms whether liberalise standing rules order overcome problem collective action arise large number individuals may vulnerable rights infringement unlikely sufficiently motivated take action even though cum ulative effect may substantial end consider whether llective complaints procedure adopted enhance effectiveness speed mpact implementation european social charter provides suitable odel review adequate resourcing powers investigation sanction remedies ublic enforcers may include need develop build technical expertise competence machine learning software development evaluation chniques within public sector rec onfiguring human rights discourse networked digital age nsider ways existing human rights protection discourse may need develop rder ensure effective protection human rights globally connected digital age reco gnising need attend foundations form basis law moral community might include consider desirability new convention human rights networked digital would minimum recognise prospective historic respo nsibility risks harms rights violations must fully allocated istributed consider need formal recognition within convention similar ultilateral instrument role independent institutional mechanisms safegu ard collective risks technologies pose social undations democratic orders human rights anchored consider whether new collective monitoring mechanisms may ecessary desirable order track evaluate aggregate cumulative effec technologies human rights across member states end nsider need desirability establishing global observatory undertake thi monitoring reporting function systematic basis apply precautionary approach cases interacting algorithmic systems capacity cause catastrophic harm could reasonably reseen individual digital service provider consider prohibition articular kinds algorithmic applications potential causing catastrophic arms consider need systematic monitoring structures expert institutions order prevent applications developed deployed dgi references ethics regulation new artificial intelligence part accountability power nformation communication society ethics regulation new artificial intelligence part autonomy liability nformation communication society wants privacy protection want journal consumer behaviour ternational research review acc ess mapping regulatory proposals artificial intelligence europe available ttps accessed report available ttps cessed aka nsu flash crash journal capital markets studies nesty international artificial intelligence good available ttps ccessed drade novais machado neves contracting agents legal personality epresentation artificial intelligence law gwin larson mattu kirchner machine bias propublica may available ttps accessed art icle danish institute human rights dutch internet ample cctld human rights impact assessment tool available ttps accessed aro body kick still soul damn legal perspectives robotics robot thics ethical social implications robotics edited lin abney bekey mit press diting algorithms adding accountability automated authority available ttp accessed stralian human rights commission human rights technology issues paper july available man accessed baro cas selbst big data disparate cal rev barr instagram account astounds internet independent march ailable ttps accessed nnett moses koker open secrets balancing operational secrecy ransparency collection use data national security law enforcement agencies lbourne university law review bos trom superintelligence paths dangers strategies oxford oxford university press bov ens new forms accountability comparative european politics council europe study boyd crawford critical questions big data information communication ociety browns word code control choice east east west legal studies browns word scotford eds oxford handbook law regulation echnology oxford oxford university press bru ndage avin clark toner eckersley garfinkel dafoe scharre zeitzoff lar anderson malicious use artificial intelligence forecasting prevention available arxiv preprint accessed blitz mind mine cognitive liberty legal concept cognitive enhancement interdisciplinary perspective edited hildt franke dordrecht springer rrell machine thinks understanding opacity machine learning big society bry son theodorou society maintain artificial intelligence saari eds digitalization services bry son robots slaves close engagements artificial companions key social ychological ethical design issues edited wilks amsterdam john benjamins publishing bygra privacy brownsword scotford eds xford handbook law regulation technology oxford oxford university press responsibility law morality oxford hart publishing carto helsby joseph mahmud park walsh cody patterson haynes ghani identifying police officers risk adverse proceedings sigkdd international conference knowledge discovery data mining available ttps accessed cath governing artificial intelligence ethical legal technical opportunities allenges phil trans mathematical physical engineering sciences ttps labourers keep dick pics beheadings facebook news feed ired october available ttps accessed ches ney citron deep fakes looming challenge privacy democracy ational california law review forthcoming tron technological due washington university law review coh affording fundamental critical analysis law con research beneficial artificial intelligence future life institute available ttps accessed cow ley beijing subway install facial recognition fears grow china surveillance une telegraph available ttps accessed dgi council europe recommendation committee ministers member states roles responsibilities internet intermediaries adopted march available ttps accessed cou ncil europe parliamentary assembly committee culture science education dia technological convergence artificial intelligence human rights april doc ailable ttp accessed rawford schultz big data due process toward framework redress predictive rivacy boston college law review dan aher robots law retribution ethics information technology dat sen zick algorithmic transparency via quantitative input influence theory experiments learning systems security privacy ieee symposium eee dav idow welcome algorithmic prison use big data profile citizens subtly ilently constraining freedom atlantic february nnett hal kills blame hal legacy computer dream ality edited stork mit press sai kroll trust verify guide algorithms law harvard journal technology streel buiten peitz liability online hosting platforms exceptionalism centre regulation europe report available ttp accessed etrich mendoza brennnan compass risk scales demonstrating accuracy equity predictive parity northpointe ahoe software eaten world mean human rights security governance march security available ttps accessed doshi kohane comorbidity clusters autism spectrum disorders lectronic health record series pediatrics raper turow audience constructions reputations emerging media echnologies new issues legal social policy oxford handbook law regulation echnology edited brownsword scotford yeung oxford oxford university press economist imitating people speech patterns could bring trouble available ttps accessed economist images everything radiology future work available ttps accessed economist techlash amazon facebook google ailable ttps accessed council europe study edwards veale slave algorithm right explanation probably remedy looking duke tech rev kbia nardi heteromation dis contents invisible division labor uman machine first monday available ttps author accessed lish letting autopilots hook blame humans automation fails une available ttp accessed ngineering physical sciences research council epsrc ttps accessed schelman moral responsibility stanford encyclopedia philosophy winter dition edited edward zalta available ttps accessed uropean commission communication artificial intelligence communication com mission european parliament european council council european economic social committee committee regions artificial intelligence europe uropean commission consumer market study online market segmentation ersonalised european union july available ttps accessed may uropean commission liability emerging digital technologies european commission staff rking document com final available ttps cessed uropean commission evaluation council directive july proximation laws regulations administrative provisions member states concerning iability com final available ttps accessed uropean commission high level expert group ethics guidelines trustworthy uropean commission high level expert group definition main capabilities isciplines uropean economic social committee committee regions artificial intelligence europe com final available ttps accessed uropean group ethics science new technologies ege statement artificial ntelligence robotics autonomous systems available ttps accessed uropean convention protection human rights fundamental freedoms echr uropean parliament committee legal affairs report recommendations ommission civil law rules robotics rapporteur delaveux inl available ttp accessed uropean political strategy centre age artificial intelligence towards european strategy mach ines available ttps accessed dgi european union council directive july approximation laws gulations administrative provisions member states concerning liability defective roducts xecutive office president big data report algorithmic systems opportunity vil rights available ttps accessed want life insurance think twice getting genetic test july available accessed rguson policing predictive rev rraris bosco impact profiling fundamental rights available ssrn ttps accessed nancial times series arms race available ttps rukerradet norweigan consumer council deceived design june available ttps cessed alligan due process fair procedures clarendon press oxford alligan law modern society oup oxford andy panoptic sort political economy personal information westview ardner mark oxford journal legal studies ardner introduction hart punishment responsibility essays philosophy second edition oup oxford guardian microsoft deeply sorry racist sexist tweets chatbot available ttps accessed illiker new head damages damages mental distress english law torts gal studies irardin blat taxi drivers navigation stems pervasive mobile computing las functioning pilot procedure european court human rights ractice netherlands quarterly human rights orton manipulating citizens political campaigns use behavioral social science arms democracy new political science eene hoffman stark better nicer clearer fair critical assessment vement ethical artificial intelligence machine learning hawaii international con ference system sciences doi available ttp accessed may unkel mind gap responsible robotics problem responsibility ethics nformation technology council europe study hagendorf ethics ethics evaluation guidelines available ttps accessed may pesenti growing artificial intelligence industry available ttps cessed allevy liability crimes involving artificial intelligence systems springer international ublishing anson beyond skin bag moral responsibility extended agencies ethics nformation technology art punishment responsibility essays philosophy law oxford niversity press oxford elberger pierson poell governing online platforms contested coo perative responsibility information society ildebrandt gutwirth profiling european citizen springer netherlands ildebrandt criminal law technology driven society dubber ornle eds oxford handbook criminal law oxford oxford university press ildebrandt smart technologies end law novel entanglements law echnology edward elgar publishing ildebrandt data intelligentie het strafrecht moerel prins ildebrandt tjong tjin tai zwenne schmidt eds homo digitalis nederlandse lters kluwer imma artificial agency consciousness criteria moral agency properties artificial agent moral ethics information technology orsey rackley tort law oxford university press oxford utson artificial intelligence could help deaf july science available ttp accessed uxley brave new world chatto windus global initiative ethical considerations autonomous systems available ttps accessed ira difference dependence among digital workers case amazon mechanical urk south atlantic quarterly asanoff ethics invention technology human future norton company ohnson computer systems moral entities moral ethics information echnology ohnson powers omputer systems responsibility normative look techn ological complexity ethics information technology kami nski witnov conforming effect first amendment implications rveillance beyond chilling speech rich fix future atlantic books london dgi kitchin data revolution sage los angeles rff browne use internet related services private life data protection rends technologies threats implications council europe available ssrn ttps accessed koo hildebrandt bridging accountability gap rights entities information society minnesota journal law science technology kos inski stillwell graepel private traits attributes predictable digital ecords human proceedings national academy science ramer guillory hancock experimental evidence massive emotional con tagion social proceedings national academy sciences uflik computers control rational transfer authority irresponsible abdication utonomy ethics information technology anzing strongly recommended revisiting decisional privacy judge hypernudging philosophy technology tonero governing artificial intelligence upholding human rights human dignity data society available ttps cessed may leon elli rethinking reproducibility criterion research quality fiorito scheall suprinyak eds including symposium mary morgan curiosity imagination surprise resea rch history economic thought methodology volume emerald publishing mited refining responsibility differentiating two types responsibility issues raised utonomous weapons systems edited bhuta beck geiss liu kress tonomous weapons systems ethics policy cup new york zawieska responsible robotics towards human rights regime oriented challenges robotics artificial ethics information technology dge wegrich managing regulation london palgrave macmillan maxwell watts legal practitioners approach regulating gorithmic regulation edited yeung lodge oup oxford press miller ethics professional responsibility computing wiley ncyclopedia computer science engineering edited wah nney oliphant tort law edition oxford university press oxford ngan lawyers could next profession replaced february ailable ttps accessed ntelero big data lueprint human rights social ethical impact ass computer law security review ntalero artificial intelligence data protection challenges possible remedies port prepared council europe consultative committee convention protection dividuals regard automatic processing personal data guidelines council europe study artifical intelligence data protection available ttps accessed may tthias responsibility gap ascribing responsibility actions learning thics information technology cukier big revolution transform live hink work london john murray volz exclusive google facebook quietly move toward automatic blocking xtremist available ttps accessed mcs herry widen weaken global digital divide medium may accessed rton normative structure science sociology science theoretical mpirical investigations edited merton chicago university chicago press tcalf crawford hum subjects big data research emerging ethics ivide big data society tzinger ethics washing made europe der taggespiegel april available ttps cessed may chalski carbonell mitchell eds machine learning artificial intelligence appr oach springer science business media ller worry worry price discrimination law thics using personal information pricing tech pol rgan yeung introduction law regulation text materials cambridge cam bridge university press ses koker open secrets balancing operational secrecy transparency col lection use data national security law enforcement melb rev arula everyday examples artificial intelligence machine october ailable ttps accessed emitz constitutional democracy technology age artificial intelligence phil rans evjans european parliament legal parliamentary affairs committee european ivil law rules robotics study juri committee available ttp cessed ilsson principles artificial intelligence morgan kaufmann issenbaum accountability computerized science engineering ethics issenbaum accountability computerized science engineering ethics issenbaum privacy context technology policy integrity social life stanford stanford law books dgi nissenbaum contextual approach privacy daedalus journal american ademy arts sciences oto diega dehumanisation algorithmic decisions cros sroads intellectual property data protection freedom ournal intellectual roperty information technology law uffield foundation leverhulme centre future intelligence ethical social plications algorithms data artificial intelligence roadmap research available ttps cessed may erdiek imposing risk normative framework oxford oxford university press sen logic collective action public goods theory groups cambridge harvard university press iver law politics public accountability search new public law neil weapons math destruction big data increases inequality threatens demo cracy broadway books wald grace urwin barnes algorithmic assessment policing models essons durham hart model experimental proportionality information ommunications technology law oxera consumer data online markets paper prepared june squale black box society secret algorithms control money information arvard university press riser filter bubble london penguin books squale black box society boston harvard university press chai google principles june available ttps accessed olyakov seven ways cybercriminals use machine learning available ttps accessed wer audit society oxford oxford university press wles citizens mere physical masses data harvesting guardian rch available ttps accessed pra insack logged ownership exclusion public value digital data formation big data society rai ney wicks ovey jacobs white ovey european convention human ghts edition oxford oxford university press ras hilligoss krishnamurthy bavitz kim artificial intelligence human rights pportunities risks berkman klein center internet society harvard university available ttps accessed raz morality freedom oxford oxford university press council europe study rieder big data paradox diversity digital culture society sse human rights artificial intelligence urgently needed agenda harvard ken nedy school faculty research working paper series available ttps accessed roy vroy data fundamental rights freedoms world big data eport bureau consultative committee convention protection individuals regard automatic processing personal data council europe available ttps accessed royal academy engineering autonomous systems social legal ethical issues august ailable ttps accessed royal society machine learning power promise computers learn ample april available ttps accessed ssell norvig artificial intelligence modern approach malaysia pearson ducation limited sae international taxonomy definitions terms related motor vehicle tomated driving systems available ttps cessed explainable artificial intelligence understanding visualizing interpreting deep learn ing itu journal ict discoveries special issue san dvig hamilton karahalios langbort auditing algorithms research methods detecting discrimination internet platforms data discrimination converting critical concerns nto productive inquiry available accessed schu wooldridge june intention reconsideration complex environments proceedings fourth international conference autonomous agents acm schwab davies nadella shaping fourth industrial revolution world economic foru scott isaac facebook restores iconic vietnam war photo censored nudity ailable ttps accessed adbolt hampson digital ape scribe melbourne ski lton hovsepian industrial revolution responding impact artificial telligence business springer ith franken deadly consequences unpredictable code guardian gust available ttps accessed sol ove introduction privacy self consent dilemma harvard law view sol legal personhood artificial intelligences ncl arrow killer robots journal applied philosophy dgi xiaoyuan taghi khoshgoftaar survey collaborative filtering vances artificial intelligence connected car quantified self becomes quantified car journal sensor actuator etworks ullins ethics artificial life modelling moral agents ethics information echnology aplin move fast break things politikens forlag eubner ghts electronic agents animals new actors politics journal law society ebuner digital personhood status autonomous software agents private law ailable via ssrn network accessed homas trust computers gresham lectures london october available ttps accessed may homas safety critical systems gresham lectures london january available ttps accessed may homas society ready driverless cars gresham lectures london october ailable ttps acce ssed may hompson moral responsibility public officials problem many hands erican political science review toronto declaration protecting rights equality machine learning ystems available ttps accessed ownley morrison yeung big data personalized price discrimination com petition law yearbook european law ufekci algorithmic harms beyond facebook google emergent challenges omputational agency telecomm high tech competition markets authority pricing algorithms october cma available ttps accessed may information commissioner office democracy disrupted personal information political fluence july available ttps cessed may government online harms white paper available ttps accessed may department business energy industrial strategy artificial intelligence sector deal ailable ttps accessed department digital culture media sport million develop world leading talent available ttps accessed council europe study house commons digital culture media sports committee disinformation fake news nal report eighth report session february available ttps accessed may niversite montreal montreal declaration responsible development available ttps accessed may general assembly report special rapporteur promotion protection ght freedom opinion expression session august available ttps accessed special representative secretary general guiding principles business human ghts implementing united nations protect respect remedy framework endorsed human rights council resolution june available ttps accessed citizenship immigration service meet emma virtual assistant available ttps accessed department transportation automated driving systems vision safety available cessed vai dhyanathan googlization everything worry university cal ifornia press van der sloot data protection rules protect individu assessment proposed general data protection regulation international data privacy law van est gerritsen assistance kool human rights robot age hallenges arising use robotics artificial intelligence virtual augmented reality xpert report written committee culture science education media parliamentary sembly council europe pace hague rathenau instituut available ttps henau accessed ale binns fairer machine learning real world mitigating discrimination ithout collecting sensitive data big data society doi gner study human rights dimensions automated data processing techniques particular algorithms possible regulatory implications october council europe com mittee experts internet intermediaries available ttps accessed gner eth ics escape regulation shopping bei profiling cogitas ergo sum edited hildebrandt amsterdam university press amsterdam fort hcoming llace responsibility moral sentiments harvard university press boston tson agency answerability selected essays clarendon press oxford wel ler challenges transparency paper presented icml workshop human terpretability machine learning whi sydney nsw australia available arxiv preprint accessed ich control alt delete consumer research attitudes data collection use policy search report june dgi white calls billion keep china available ttps accessed erzynski challenges opportunities explainable january available ttps accessed chihuahua muffin search best computer vision api available ttps accessed earsley need talk power manipulate humans june mit echnology review june available ttps accessed ung employ design regulation avoiding brave new world law nnovation technology eung design handbook ethics values technological design edited van den hoven varmaas van poel dordecht springer eung hypernudge big data mode regulation design information ommunication society eung algorithmic regulation critical interrogation regulation governance doi eung blockchain transactional security promise automated law enforcement withering freedom law reinvention ethics digital age edited otto graf eung five fears mass predictive personalization age urveillance cap italism international data privacy law eung weller transparency understood legal scholars machine earning community profiling cogitas ergo sum bayamlioglu baraliuc janssens hildebrandt eds amsterdam university press lnieriute rule law automation government dern law review iobaite survey measuring indirect discrimination machine learning available arxiv reprint accessed council europe study zook grote microgeographies global finance high trading construction information inequality environment planning economy space boff big surveillance capitalism prospects information civilization ournal information technology zwe wenzelburger krafft chances risks security related gorithmic systems european journal security research council europe continent leading human ights organisation comprises member states including members uropean union council urope member states signed european onvention human rights treaty designed otect human rights democracy rule law european court human rights oversees implementation onvention member digital technologies services including ools come extraordinary promise particularly orm enhanced efficiency accuracy timeliness across wide range services yet emergence technologies also accompanied rising public regarding potentially damaging effects vulnerable groups society generally giv pervasiveness daily life must acquire deeper understanding impact exercise human rights fundamental freedoms car efully consider allocate responsibility case adv erse consequences take human rights globally connected digital age allow power advanced digital technologies systems wield derive benefits crued exercised without responsibility eff ective democratically legitimised governance enforcement mechanisms must put place ensure responsibility risks harms wrongs ising operation advanced digital technologies duly allocated
