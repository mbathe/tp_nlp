discrimination artificial intelligence algorithmic study frederik zuiderveen borgesius professor law institute computing information sciences icis radboud university nijmegen researcher institute information law university amsterdam netherlands opinions expressed work responsibility author necessarily reflect official policy council europe published directorate general democracy council europe printed strasbourg table contents executive summary introduction artificial intellige nce algorithmic decision iii discrimination risks lead iscrimination fields rings discrimination risks legal regulatory safeguard non law data protection law regulation recommendations organisations using equality bodies human rights monitor ing bodies improving regulation regulation fast technolog enforcement regulating new types differentiation vii conclusion bibliography executive summary report written anti department council europe concerns discrimination caused algorithmic decision types artificial intelligence advances important goals efficiency health economic growth also discriminatory effects instance systems learn biased human decisions public private sector organisations take driven dec isions far effects people public sector bodies use predictive policing example making decisions eligibility pension payments housing assistance unemployment benefits private sector use select job applicants banks use decide whether rant individual consumers credit set interest rates moreover many small decisions taken together large effects way illustrat ion aidriven price discrim ination could lead certain groups society consistently paying relevant legal tools mitigate risks discrimination non law data protection law effectively enforced legal tools could help fight illegal discrimination council europe member states human rights monitoring bodies european commission racism intolerance equality bodies aim better enforcement current non discrimination orms also opens way new types unfair differentiation might say discrimination escape current laws statutes apply discrimination basis protected characteristics skin colour statutes apply system invents new classes correlate protected characteristics differentiate people differentiation could still unfair however instance reinforces social inequality probably need additional regulation protect fairness human rights area regulating general right approach use systems varied one set rules different sectors different values stake different problems arise therefore sector rules considered research debate needed introduction report written department council europe concerns risks discrimination caused algorithmic decision types artificial intelligence advance important goals efficiency health economic growth society relies many thing including spam filtering traffic planning logistics management speech recognition diagnosing diseases algorithmic decision may appear rational neutral unbiased unfortunately algorithmic decision making also lead unfair illegal discrimination requested report focuses following questions fields algorithmic decision types create discriminatory effects could create foreseeable future regulatory safeguards including redress mechanisms regarding currently exist safeguards currently considered recommendations made mitigating risks discriminatory organisations using equality bodies council europe member states human rights monitoring bodies european commission racism intolerance types action legal regulatory self reduce risks report uses word discrimination refer objectionable illegal discrimination instance basis gender skin colour racial origin report speaks line legal tradition use words racial origin race report however accept theories claim separate human races differentiation referring discrimination neutral unobjectionable report focuses one risk relation algorithmic decision risk discrimination many related topics thus utside scope report automated weapon systems cars filter bubbles singularity monopolies risk robots cause mass unemployment also scope privacy related questions regarding mas sive amounts personal data collected power report relies literature review length constraints report seen quick scan rather apping relevant aspects algorit hmic decision discrimination would like thank bodó balázs janneke gerards dick houtzager margot kaminski dariusz kloza gianclaudio malgieri stefan kulk linnet taylor michael veale sandra wachter bendert zevenbergen valuable suggestions remainder report structured follows chapter introduces artificial intelligence algorithmic decision key phrases next report discusses questions chapter iii maps fields leads might lead discriminat ion chapter discusses regulatory safeguards chapter highlights organisations prevent discrimination using chapter also offers recommendations equality bodies hum rights monitoring bodies mitigating risks discriminatory algorithmic decision chapter gives suggestions improving regulation chapter vii provides concluding thoughts purpose algorithmic decision often discriminate sense differentiate distinguish individuals entities see detail different meanings discrimination lippert artificial intellige nce algorithm decision phrases algorithmic decision used various ways consens definitions artificial intelligence algorithmic decision related concepts briefly introduced algorit algorithm described abstract formali sed description computational procedure report decision simply refers output finding outcome procedure rough rule thumb one could think algorithm computer program times algorithm decides fully automatic fashion instance pam filter ervice filter fully automatically spam messages user inbox sometimes humans make decisions assisted algorithms decisions partly automatic example based assessment customer credit system bank employee may decide whether customer borrow money bank however discussing discrimination many risks similar fully partly automated decisions recommendations computers may air rationality infallibili people might blindly follow wagner note human may often led rubber stamp algorithmically prepared decision time context skills make adequate decision individual case human decisio may also try minimis responsibility following computer tendency believe computers follow advice dourish see also domingos wagner see also broeders zarsky sometimes called automation bias see section legal rules dist inguish fully partly automated artificial intelligence artificial intelligence loosely speaking cience making machines smart formally concerns study design intelligent agents context agent something acts broad research field exists since types instance much research expert systems programs reconstructing expertise reasoning capabilities qualified specialists within limited domains researchers program med computers answer questions using preformulated answers expert systems commercial success expert systems two disadvantages observes alpaydin first logical rules systems always fit messy reality wor real life things true false grades truth person either old old oldness increases gradually age second experts provide parasuraman manzey see also citron rieke bogen robinson see discussion article gdpr section royal society russel norvig citing poole mackworth goebel computational intelligence study design intelligent agents russel norvig two early publications turing mccarthy puppe alpay din alpaydin knowledge answers put systems process costs lot time money machine learning past decade one type particularly successful machine machine learning knowledge system provided experts contrast machine learning systems set task given large amount data use examples achieved detect patterns system learns best achieve desired output rough rule thumb machine learning could summarised predictions lerh ohm give detail descripti machine learning refers automated process discovering correlations sometimes alternatively referred relationships patterns variables dataset often make predictions estimates outcome machine learning become widely used past decade part data become available train machines machine learning successful nowadays many people say refer machine learning type related phrases data mining big data profiling data mining type machine learning process discovering interesting patterns massive amounts alpaydin alpaydin xiii royal society paul jolley anthony lehr ohm see also royal society lipton jordan data data mining also referred knowledge discovery data hrase big data roughly refers analysing large data profiling involves automated data processing develop profiles used make decisions terminology report regarding technology report sacrifices precision readability uses system decision etc without specifying whether refers machine learning another technology thus report system refer instance computer running algorithm fed data human operators ease reading report uses phrases effects almost entity acts however systems spontaneously come existence wagner note mathematic computational constructs adverse human rights impacts implementation application human interaction indeed system makes decisions organisation decided use task practice organisation starts using rarely makes relevant decisions system organisation might deploy system many important choices made cases effects certain decisions pre design stage system han pei kamber see also frawley describe data mining nontrivial extraction implicit previously unknown potentially useful information data han pei kamber xxiii see data mining one step knowledge discovery process boyd crawford see hildebrandt ferraris wagner see also dommering rie bogen robinson see way modern digital systems developed gürses van hoboken focus privacy analysis also relevant systems discrimination may become apparent system deployed real world apart organisations consist many people managers lawyers specialists nevertheless brevity report sometimes says organisations things next chapter discusses lead discrimination highlights areas leads might lead discriminatory effects iii discrimina tion risks fields algorithmic decision types create discriminatory effects could create foreseeable future lead discriminati section discusses lead discrimination next section gives examples led might lead discrimination systems often black boxes often unclear somebody system makes certain decision opaqueness decisions difficult people assess whether discriminated basis instance racial origin decision lead discrimination several ways seminal paper barocas selbst distinguish five ways decision lead unintentionally problems relate target variable class labels defined label ling training data iii collecting training data feature selection proxies addition systems used purpose discriminatory discuss problem turn defining target variable class labels pasquale barocas selbst see also neil gives accessible well introduction discrimination risks area systems barocas selbst group ways slightly differently involves computers find correlations data sets instance company develops spam filter company feeds computer messages labelled humans spam labelled messages training data computer finds characteristics messages correlate labelled spam set discovered correlations often called model predictive model instance messages abelled spam might often contain certain phrases magic weight loss pill millions dollars etc might sent certain addresses barocas selbst put exposing machine learning algorithms examples cases interest previously identified instances fraud spam default poor health algorithm learns related attributes activities serve potential proxies qualities outcomes int erest outcome interes called target variable target variable defines data miners looking explain barocas selbst labels divide possible values target variable mutually exclusive categories spam filtering people roughly agree class labels messages spam situations less obvious target variable sometimes note barocas selbst defining target variable involves creation new classes suppose company wants system sort job applications find good employees good employee define words class labels good employee one sells products one never late work barocas selbst barocas selbs barocas selbst internal citations omitted barocas selbst target variables class labels explain barocas selbst may greater lesser adverse impact protected classes suppose instance poorer people rarely live city centre must travel work employees therefore poorer people late work often others traffic jams problems public transport company could choose rarely late often class label asses whether employee good people immigrant background average poorer live work choice class label would put people immigrant background disadva ntage even outperform employees sum discrimination creep system organisation defines target variables class labels training data labelling examples decision also discriminatory results system learns discriminatory training data barocas selbst describe two ways biased training data discriminatory effects first system might trained biased data second problems may arise system learns biased case system reproduce bias barocas selbst see peck barocas selbst training data biased represent discriminatory human decisions situation occurred medical school school received many applications could place therefore school developed computer program help sort applications training data computer program admission files earli years people selected applicants could enter medical school training data showed computer program characteristics input correlated desired output admitted med ical school computer reproduc selection system turned computer program discriminated women people immigrant background apparently years provided training data people selected students biased women people immigrant background british medical journal noted program introducing new bias merely reflecting already system sum training data biased system risks reproduc ing bias training data ata collection sampling procedure also biased instance collecting data crime could case police stopped people immigrant background past lum isaac ote police focus attention certain ethnic groups certain neighbourhoods likely police records systematically groups neighbourhoods system train biased sample learn people immigrant background likely lowry macpherson barocas selbst lowry macpherson lum isaac commit crime lum isaac note biased data used train predictive models models reproduce biases effects biased sample could even ampl ified predictions suppose police pay extra attention neighbourhood many immigrants neighbourhood average crime levels police register crime neighbourhood elsewhere numbers show crime registered thus seems occur neighbourhood even policemen sent way policing basis crime statistics cause feedback give another example poor people may represented data set illustrated street bump smartphone application use features gps feeds report road conditions city council street bump site explains volunteers use street bump mobile app collect road con dition data drive data provides governments real information fix problems plan long investments fewer smartphone users among poor people among wealthier people poor people likely undercounted effect could faulty roads poor neighbourhoods represented dataset therefore receive fewer reparations street bump app used city boston city aims correct bias data example illustrates data collection could inadvertently lead biased data set sum biased training data lead biased systems lum isaac lum isaac see also ferguson harcourt robinson koepke accessed september crawford see also barocas selbst federal trade commission feature selection fourth problem relates features categories data organisation selects system organisation wants use predict something automatically needs simplify world able capture barocas selbst note organisation must make choices attributes observe subsequently fold analyses suppose organisation wants predict automatically job applicants good employee possible least costly system assess job applicant completely organisation could focus instance certain features characteristics job applicant selecting certain features organisation might introduce bias certain groups example many employers look people studied famous expensive universities might relatively rare certain racial groups study expensive universities therefore may discriminatory effects employer select job applicants basis whether studied famous sum organisations cause discriminatory effects selecti features system uses prediction barocas selbst barocas selbst barocas selbst proxies another problem concerns proxies data included training set may correlate protected characteristics barocas selbst point sometimes criteria genuinely relevant making rational well decisions also happen serve reliable roxies class membership suppose bank uses system trained data covering last twenty years predict loan applicants problems repaying loan training data contain information protected charac teristics skin colour system learns people postal code likely default loans uses correlation predict defaulting hence system uses first glance neutral criterion postcode predict defaulting loans suppose postcode correlate racial origin case bank act basis prediction denied loans people postcode practice would harm people certain racial origin barocas selbst explain problem stems researchers call redundant encodings cases membership protected class happens encoded data occurs particular piece data certain values piece data highly correlated membership specific protected classes illustrate dataset contain explicit data people sexual orientation still give information people sexual orientation facebook friendships expose sexual orientation found study study demonstrates method accurately predicting sexual orientation facebook users analy sing friendship barocas selbst barocas selbst see also dwork associations percentage given user friends self gay male strongly correlated sexual orientation user proxy problem difficult solve barocas selbst note computer scientists unsure deal redundant codings datasets simply withholding variables data mining exercise often removes criteria hold demonstrable justifiable relevance decision hand hence way ensure decisions systematically isadvantage members protected classes reduce overall accuracy determinations intentional discrimination another situation also occur discrimination purpose example organisation could intentionally use proxies discriminate basis racial origin kroll observe prejudiced decisionmaker could skew training data pick proxies protected classes intent generating discriminatory results organisation uses proxies discrimination would harder detect organisation openly discriminates give hypothetical example organisation could discriminate pregnant women discrimination would difficult discove retail store target reportedly construct pregnancy prediction score based around products analysing shopping behaviour customers woman buys products target predict reasonable accuracy pregnant target wanted reach people advertising moments life jernigan mistree barocas selbst barocas selbst barocas selbst see also bryson friedman nissenbaum hacker kim vetzo gerards nehmelman kroll likely ange shopping habits therefore target wanted know female customers going give birth knew could identify second trimester good chance could capture years target used prediction targeted marketing organisation could also use prediction discrimination sum decision lead discrimination least six ways relate definition target variables class label labelling iii collecting training data selection features proxies organisa tions could use systems discriminate purpose also lead types unfair differentiation errors return topics chapter fields bring discrimination risks section provides examples fields decision making led could lead discrimination police crime prevention start public sector notorious example system discriminatory effects system known correctional offender manageme profiling alternative sanctions compas compas system used parts predict whether defendants commit crime idea compas help judges determine whether somebody allowed probation supervision outside prison compas system use racial igin skin colour input research angwin investigative journalists duhigg quoting statistician target see target case also siegel chapter see kim see equivant propublica showed compas biased blacks propublica summarise compas correctly predicts recidivism percent time blacks almost twice likely whites label led higher risk actually reoffend makes opposite mistake among whites much likely blacks label led lower risk commit crimes moreover black defendants also twice likely white defendants misclassified higher risk violent recidivism white violent recidivists percent likely misclassified low risk violent recidivism compared black violent recidivists northpointe company behind compas dispute system propublica northpointe disagree mainly standard fairness used assess academic statisticians argued cases different standards fairness incompatible mathematically consequences discrimination prevention could look like propublica concerned called disparate mistreatment differen groups receive different error types disproportionately instance individuals groups higher possibility deemed high would commit crime yet another angwin angwin larson paragraph largely written michael veale discussion compas propu blica northpointe academics part rather technical good summary discussion feller see also shared statement civil rights concerns see view northpointe dieterich mendoza brennan important characteristic risk scores correctly calibrated means group individuals deemed chance going commit crime group indeed commit crime also within groups within bla white defendants case judges would need interpret high risk black defendant differently high risk white defendant brings biases play statisticians indicated whe underlying propensity recidivism differ mathematically impossible also equalised error sometimes police use systems predictive policing automated predictions commit crime rime noted predictive policing systems reproduce even amplify existing discrimination selection employees students private sector discriminatory effects well saw instance used select prospective employees students example medical school showed system could lead discrimination biased training data reportedly amazon stopped using system screening job plicants system biased women words reuters company reali sed new system rating candidates software developer jobs technical posts gender way based historical training data amazonʼs system taught male candidates preferable see chouldechova hildebrandt ferguson perry van brakel hert dastin dastin advertising used targeted online advertising profitable sector companies facebook google among world valuable companies derive profit online online advertising discriminatory effects sweeney showed people searched african names google displayed advertisements suggested somebody arrest record white names google displayed fewer ads suggestive arrest records presumably google system analysed people surfing behaviour inherited racial datta tschantz datta simulated identical internet users male female settings researcher analysed ads google google showed simulated males ads certain career coaching agency promised large salaries frequently simulated females finding suggestive discrimination researchers note unclear women shown fewer ads high jobs opaqueness system determine caused findings due limited visibility ecosystem includes google advertisers websites users example opaqueness systems makes harder discover discrimination cause people could discriminated without aware ystem fortune mother company google officially called alphabet sweeney datta tschantz datta datta tschantz datta datta tschantz datta datta target job ads men women might realise excluded dutch data protection authority found facebook enabled advertisers target people based sensitive characteristics instance data lating sexual preferences used show targeted advertisements data protection authority says facebook amended practices make targeting angwin perris propublica showed facebook ets advertisers exclude users race facebook system allows advertisers exclude black hispanic ethnic affinities seeing ads propublica also showed firms use facebook targeting possibilities advertise job ads people certain spanish researchers showed facebook labels users sensitive interests islam reproductive health homosexuality advertisers target advertising basis interests munoz smith patil zuiderveen borgesius chapter section dutch data protection authority dutch data prote ction authority dutch data protection authority angwin perris see also angwin tobin varner dalenberg examines application non law targeting ngos filed lawsuit usa facebook discrimination fair housing laws allowing exclusion women disabled veterans single mothers housing advertisement potential audience bagli angwin scheiber tobin cabañas cuevas cuevas interests defined special categories data also called sensitive data european data protection law see article european union general data protection regulation see data protection law section price discrimination online shops differentiate price identical products based information shop consumer practice called online price differentiation shop recognise website visitors instance cookies cate gorise price price price differentiation shops aim charge consumer maximum price willing princeton review company offers online tutoring services charged different prices different areas ranging dollars presumably costs delivering service area company offers tutoring service internet angwin found company price differentiation practice led higher prices people asian background customers areas high density asian residents times likely offered higher prices regardless income company probably set discriminate basis racial origin perhaps company tested different prices different neighbourhoods found certain areas people bought amount services even higher prices nevertheless effect tha certain ethnic groups paid image search analysis systems search images also discriminatory effects search google images three black teenagers led mugshots search three white kids mostly lead pictures happy white kids response shocked reactions google said image search results reflection content across web including frequency types images appear way zuiderveen borgesius poort angwin mattu larson larson mattu angwin described online means sometimes unpleasant portrayals sensitive subject matter online affect image search results appear given query indeed one could say google system merely reflected society even fault lies society rather system image search results could influence people beliefs kay matuszek munson found image search results occupations slightly exaggerate gender stereotypes portray minority gender occupation less professionally also slight women different type problem concerns image recognition systems image recognition software difficulties recognising analysing non faces facial software hewlett packard recognise dark faces google photos app labelled picture african couple gorillas nikon camera kept asking people sian background someone blink asian man passport picture rejected automatically subject eyes closed eyes buolamwini gebru found darker skinned females misclassified group ith error rates maximum error rate lighter skinned males perhaps errors mentioned result training system pictures white men google reaction quoted york allen kay matuszek munson frucci bbc news see also noble sharp regan buolamwini gebru translation tools behind automated translation tools also reflect inequality discrimination people type doctor nurse google translate translate phrases turkish google translate provides bir hemşire bir doktor turkish sentences gender tur kish differentiate words translating turkish text english google translate provides nurse doctor example taken research caliskan bryson narayanan shows machines learn word associations written texts associations mirror learned humans words natural language necessarily contains human biases radigm training machine learning language corpora means inevitably imbibe biases well prates avelar lamb tested twelve gender languages hungarian chinese google translate authors ote sentences engineer gender languages translate sentences english google translate authors conclude google translate exhibits strong tendency towards male defaults moreover male defaults prominent exaggerated fields suggested troubled gender stereotypes stem science technology engineering mathematics jobs sum translation tools provide results reflect existin gender inequality perhaps results could also worsen inequality could influence people ideas nuancing risk caliskan bryson narayanan narayanan prates avelar lamb prates avelar lamb saw decision could discriminatory effects systems necessarily perform worse humans unfortunately many humans also make discriminatory decisions indeed cases systems discriminate trained data reflect discrimination humans hence makes difference whether one compares decision human decision real world unfortunately sometimes discriminatory hypothetical decisions ideal world without course goal world without unfair illegal discrimination apart could also used discover discrimination suppose system shows collection stock photos contains gender stereotypes one way interpreting finding system illustrates stereotyped behaviour already exists hence system could help discover existing inequality might remained hidden otherwise legal regulatory safeguard regulatory safeguards including redress mechanisms regarding currently exist safeguards currently considered law data protection law main legal regimes could protect people discrimination chapter discusses regime turn highlights potential relevant fields law self regulation chapter paints broad brush focuses core principles legal regimes issues lying utside scope report include differences regulation council europe member states territorial scope laws enforcement laws organisations states see also tene polonetsky see munoz smith pati non law discrimination prohibited man treaties constitutions including european convention human rights article european convention human rights tates enjoyment rights freedoms set forth convention shall secured without discrimination ground sex race colour language religion political opinion national social origin association national minority property birth direct indirect discrimination prohibited european convention human direct discrimination means roughly summarised people discriminated basis protected charact eristic racial origin european court human rights describes direct discrimination follows must difference treatment persons analogous relevantly similar see article united nations declaration human rights article international covenant civil political rights article charter fundamental rights european union protocol con vention lays similar prohibition regarding certain aspects broader enjoyment right set forth law shall secured without discrimination ground sex race colour language religion political opinion national social origin association national minority property birth status article protocol convention protection human rights fundamental freedoms european treaty series rome september total number ratifications protocol stood see list european convention human rights horizontal effect convention directly regulate discrimination private sector situations based identifiable characteristic law ination law uses similar definition indirect discrimination occurs roughly speaking practice neutral first glance ends discriminating people certain racial origin another protected characteristic indirect disc rimination called disparate impact united states indirect discrimination described follows european court human rights difference treatment may take form disproportionately prejudicial effects general polic measure though couched neutral terms discriminates group situation may amount indirect discrimination necessarily require discriminatory intent indirect discrimination defined similar law indirect discrimination shall taken occur apparently neutral provision criterion practice would put persons racial ethnic origin particular disadvantage compared persons unless provision criter ion practice ecthr biao denmark grand chamber may para direct discrimination defined follows article racial equality directive direct discrimination shall taken occur ere one person treated less favourably another would treated comparable situation grounds racial ethnic origin employment equality directive gender goods services directive recast gender equality directive use similar definitions even within european union non law partly harmonised see generally concept indirect discrimination tobler ellis watson ecthr biao denmark grand chamber may para objectively justified legitimate aim means achieving aim appropriate necessary decision unintentionally lead indirect discrimination regarding indirect discrimination law focuses effects practice rather intention alleged hence relevant whether discriminator intention discriminate law used fight discriminatory decisions inst ance decisions make people certain racial background pay goods services could breach prohibition indirect discrimination decision accidental indirect discrimination probably occurs often intent ional discrimination however non law several weaknesses context decision prohibition indirect discrimination provide clear easily applicable concept indirect discrimination results rather open standards often difficult apply practice needs proven seemingly neutral rule practice decision disproportionately affects protected group ereby prima facie discriminatory many cases statistical evidence used show disproportionate european court human rights accepts suspicion indirect discrimination rebutted alleged discriminator invoke objective justification article racial equality directive capitalisation punctuation adapted ecthr biao denmark grand chamber may para see also hacker could say prohibition indirect discrimination closer standard rule see sunstein baldwin cave lodge chapter ecthr others czech republic grand chamber november paras general policy measure disproportionately prejudicial effects particular group may considered discriminatory even specifically aimed group discriminator intent case however policy measure objective reasonable justification justification must objective reasonable measure practice rule meet requirements jective reasonable justification pursue legitimate aim reasonable relationship proportionality means employed aim sought achieved along similar lines law says practice constitute indirect discrimination objectively justified legitimate aim means achieving aim appropriate necessary whether alleged discriminator invok objective justification depends circumstances case requires nuanced proportionality therefore always clear whether certain practice breaches prohibition indirect discrimination ecthr biao denmark grand chamber may paras deleted internal citations numbering quotation ecthr biao denmark grand chamber may para see also ecthr case relating certain aspects laws use languages education belgium others july para article racial equality directive collins khaitan hacker requirement prima facie case indirect discrimination must shown may also cause difficulties since type discrimination remain hidden suppose somebody applies loan website bank bank uses system decide requests bank automatically denies loan customer website customer see loan denied moreover customer see whether bank system denies loans disproportionate percentage instanc even customers knew system rather bank employee decided would difficult discover whether system discriminatory another weakness relates non law concept protected chara cteristics non statutes typically focus direct indirect discrimination based protected characteristics race gender sexual many new types differentiation seem unfair problematic might say discriminatory remain outside scope non statutes hence non law leaves gaps section return unfair types differentiation might escape non law conclusion non law particular concept indirect discrimination prohibits many discriminatory effects however enforcement difficult non discrimination law weaknesses next section takes look data protection law data protection law data protection law legal tool aims defend fairness fundamental rights right privacy right see larson similar example real life job ads see facebook older gerards khaitan non data protection law grants rights people whose data processed data subjects imposes obligations parties process personal data data controllers eight principles form core data protection law summarised follows personal data may processed lawfully fairly transparently lawfulness fairness transparency data may collected purpose specified advance used unrelated purposes purpose limitation data limited necessary processing purpose data minimisation data sufficiently accurate accuracy data retained unreasonably long period storage limitation data secured data breaches illegal use etc integrity confidentiality see article recital gdpr article coe data protection convention council europe big data guidelines article article gdpr article coe data protection conven tion article gdpr article coe data protection convention article gdpr articles coe data protection convention data controller responsible compliance accountability principles included council europe data protection convention revised european union general data protection regulation gdpr similar principles included hundred national data privacy laws data protection law could help mitigate risks unfair illegal instance data protection law requires transparency personal data processing therefore organisations must provide nformation instance privacy notice stages decision process involve personal rue people read privacy nevertheless notices could helpful researchers journalists supervisory authorities privacy notice suggests processing practice could discriminatory effects authorities investigate certain circumstances gdpr data protection convention require organisations data controllers conduct data protection impact assessment dpia impact assessment described follows impact assessment tool used analysis possible consequences initiative relevant societal concern concerns initiative present dangers concerns view article gdpr article coe data protection convention article coe data protection convention greenleaf see interplay data protection law discrimination law schreurs gellert hacker lammerant hert blok article article article gdpr articles coe data protection convention zuiderveen borgesius support ing informed decision whether deploy initiative conditions ultimately constituting means protect gdpr requires dpia practice likely result high risk rights freedoms natural persons especially using new circumstances gdpr always requires dpia gdpr assumes high risk instance ganisations take fully automated decisions legal similar effects hence many systems make decisions people gdpr requires risk unfair illegal discrimination must also considered conducting council europe data protection convention charter fundamental rights european union member state must independent data protection authority data protection authorities must powers gdpr gives details investigati powers data protection authorities data protection authority instance obtain access premises controllers carry investigations form data protection audits order data controllers provide kloza see also article working party binns mantelero wright hert article gdpr article gdpr see also recital gdpr article gdpr could also apply systems article working party see also kaminski edwards veale article charter fundamental rights european union see also article gdpr chapter coe data protection convention chapter gdpr chapter coe data protection convention information give access data processing systems rules automated decisions gdpr contains specific rules certain types automated individual decision rules aim among things mitigat risk illegal council europe data protection convention also contains rules automated decision less detailed gdpr focus gdpr article gdpr sometimes called kafka provision contains prohibition fully automated decisions legal similar significant effects applies instance fully automated practices without human predecessor gdpr already similar provision applied much main rule gdpr provision automated individual decision reads follows data subject shall right subject decision based solely automated processing including article gdpr data protection authorit also exercise rights processors organisations process personal data data controllers article gdpr discussion gdpr rules automated decisions based includes sentences zuiderveen borgesius poort see recital gdpr article coe data protection convention recital gdpr korff predecessor article data pro tection directive article based provision data protecti act france see bygrave gdpr defines profiling follows means form automated processing personal data consisting use personal data evaluate certain personal aspects relating natural person particular analyse predict aspects concerning natural person performance work economic situation health personal preferences interests reliability behaviour location movements art gdpr produces legal effects concerning similarly significantly affects roughly summarised people may subjected certain automated decisions far effects gdpr says people right subject certain decisions generally assumed right implies prohibition slightly rephrasing mendoza bygrave four conditions must met provision apply decision based solely automated data processing decision legal similarly significant effects example decision legal effects would court decision decision regarding social benefit granted law pension example decision similarly significantly effects would bank denies credit ata protection authorities say nline price differentiation could similarly significantly affect somebody leads prohibitively high prices effectively bar someone certain goods services exceptions prohibition certain automated decisions short prohibition apply automated decision based individual explicit art gdpr hert gutwirth korff wachter mittelstadt floridi zuiderveen borgesius mendoza bygrave see article working party recital gdpr see examples could constitute aut omated decisions similarly significantly affect people article working party article working party consent necessary contract individual data controller iii authorised controller rely consent contract exception bypass prohibition different rule triggered data controller shall implement suitable measures safeguard data subject rights freedoms legitimate interests least right obtain human intervention part controller express point view contest decision hence circumstances data subjec ask human reconsider automated decision instance bank could ensure customers call bank human reconsider decision bank automatically denies loan bank website addition general transparency requirements gdpr also contains transparency requirements specific automated decisions controller shall provide data subject following information existence automated decision including profiling least cases meaningful information logic involved well significance envisaged consequences processing data hence cases organisation would exp lain uses decision would provide meaningful information logic process great deal scholarly attention whether gdpr rules automated decisions create right article working party article gdpr kaminski notes gdpr text creates version algorithmic due process right opportunity heard kaminski article gdpr explanation individual recital suggests existence individual right explanation decisions right could useful protect many cholars sceptical whether right would effective noting instance many types automated decisions remain outside scope gdpr rules illustrate gdpr automated decision provision applies decisions bas solely automated processing hence bank employee denies loan basis recommendation system long employee rubber provision see instance edwards veale goodman flaxman kaminski kaminski lgieri comandé mendoza bygrave selbst powles wachter recital processing subject suitable safeguards include right obtain explanation decision reac hed assessment see instance edwards veale wachter zuiderveen borgesius chapter section see article working party working party says superficial check human rubber stamping sufficient however noted veale edwards clear organisations supposed ensure decisions non superficial human input remains seen practical effec gdpr provisions noted predecessor gdpr provision automated decisions remained dead letter regardless attention gdpr provisions helped foster interdisciplinary discussion explaining cisions modernised convention appears generous individuals phrasing around explanation rights unlike gdpr provision applies decisions significant effect solely based automated processing conv ention gives individuals right obtain request knowledge reasoning underlying data processing results processing applied breadth means apply result yet seen practice national implementations caveats several caveats order egarding protection law possibilities tool fight discrimination first compliance enforcement deficit data prote ction authorities limited resources many data protection authorities power impose serious sanctions authorities received new powers gdpr previously organisations take compliance protection law appears compliance improved arrival gdpr early tell second parts algorithmic processes outside scope data protection law data protection law nly applies personal data processed apply predictive models relate identifiable persons example predictive model says people living article coe data protection convention every individual sha right obtain request knowledge reasoning underlying data processing results processing applied see veale edwards see zuiderveen borgesius chapter section postal code pay bills late personal datum model refer individual predictive model applied individual data protection law applies third data protection law uses many open abstract norms rather black data protection law must use open norms provisions apply many different situations private public sector regulatory approach omnibus approach many advantages instance open norms adapt time new technology developed one disadvantage open norms difficult fourth data protection law strict rules special categories data sometimes called sensitive data data regarding racial origin revealing health rules create challenges assessing mitigating discrimination many methods tackle discrimination systems implicitly assume organisations hold ese sensitive data yet meet data protection law many organisations may holding tension remains respecting data protection law collecting sensitive data fight fifth even explanations decisions might legally required gdpr convention often difficult explain logic behind decision system see zui derveen borgesius chapter chapter see weaknesses data protection law area decision wachter mittelstadt zuiderveen borgesius chapter section see different types legal rules chapter section article gdpr article coe data protection convention strict rules special categories data aim part fight discrimination see special categories data context malgieri comandé goodman ringelheim schutter ringelheim schutter veale binns žliobaitė custers methods audit systems maintaining privacy using cryptograph emerging see kilbertus analysing large amounts data arrives cases clear much explanation would help people especially insofar places burden understand decision said transparency explanation decisions could useful decade scholars calling development transparency technologies tets enable meaningful transparency regarding automated decision technologies aim making information flows transparent feedback awareness thus enabl ing individuals well collectives better understand information collected aggregated analy sed used decision making computer scientists exploring various forms explainable case much early assess effect modernised convention gdpr legal research needed data protection law could help mitigate discrimination data protection law largely untested non tool offer possib ilities fight illegal discrimination ananny crawford burrell binns edwards veale hildebrand kroll wachter mittelstadt russell edwards veale hildebrandt utwirth chapter diaz gürses see guidotti miller selbst barocas tickle see also google project could inspect machine learning model coding required accessed october project took inspiration wachter mittelstadt russell researchers starti explore data protection law help fight discrimination see instance goodman mantelero hacker hoboken kostic forthcoming wachter wachter mittelstadt regulation area decisions fields law could also help ensure fairness perhaps help mitigate discrimination related problems example consumer law could invoked protect consumers types manipulative driven discriminatory behaviour company causes problems company monopoly position competition law could also help protect public sector administrative law criminal law could relevant protect fair procedures freedom information laws could used obtain information public sector applicati fields law protect people area largely unexplored discussion fields law falls outside scope report regulation consideration several regulatory measures could relevant discrimination currently considered council europe consultative committee convention protection individuals regard automatic processing personal data published draft report september artificial intelligence data protection challenges possible remedies council europe steering committee media information society set expert committee committee experts human rights dimensions automated data processing different forms artificial see consumer law european data protection supervisor helberger zuiderveen borgesius reyna jabłonowska see competition law ezrachi stucke graef graef valcke graef clifford van nooren see administrative law van eck oswald cobbe see rieke bogen robinson fink oswald grace mantelero intelligence expert committee conduct studies give guidance possible future standard european union active area european commission published ommunication set high expert group artificial tasked propos ing draft ethics agency fundamental rights also examining furthermore commission proposed eprivacy regulation protect privacy internet could relevant machine learning would limit collection certain types privacy sensitive data internet regulation concerns type decision algorithmic trading stock exchanges etc regulation states investment firm shall ensure compliance staff least general understanding algorithmic trading systems trading algorithms vestment firm operate moreover investment firm shall establish monitor trading systems trading algorithms clear formalised governance arrangement perhaps similar requirements could adopted sectors council europe msi accessed september european commission artificial intelligence europe see also european group ethics science new technologies accessed october see zuiderveen borgesius article commission delegated regulation july supplementing directi european parliament council regard regulatory technical standards specifying organisational requirements investment firms engaged algorithmic trading article idem several organisations proposed principles aim fair accountable ethical example organisation fatml fairness accountability transparency machine learning published principles accountable algorithms social impact statement algorithms principles call organisations ensure algorithmic decisions create discriminatory unjust impacts comparing across different demographics race sex etc self principles ethics often less focused discrimination examples include asilomar principles future life montr eal declaration responsible principles ethical uni global ieee technical professional organisation launched global initiative ethics autonomous intelligent partnership benefit people society set apple amazon deepmind google facebook ibm microsoft study formulate best practices principle self principles laudable ethical obviously better unethical principles could help mitigate discrimination problems could provide inspiration accessed september accessed september accessed september accessed september accessed september accessed september see also koene accessed september see list critique ethics principles greene hoffman stark however protecting human rights left selfregulation soft main problem self regulation principles often somewhat abstract give detailed wagner warns ethics washing context much debate ethics seems increasingly focussed private companies avoiding regulation unable unwilling properly provide regulatory solutions ethics seen easy soft option help structure give meaning xisting self initiatives indeed soft law distract possible need hard legal regulation chapter discusses law could improved first turn recommendations organisations usin human rights monitoring bodies equality bodies recommendations recommendations made mitigating risks discriminatory organisations using equality bodies council europe member states human rights monitoring bodies european commission racism intolerance organisations using several measures important public private organisations wishing prevent discrimination use asures include education obtaining technical legal expertise careful planning projects see generally self fundamental rights angelopoulos see campolo wagner see also nemitz education education important make organisations realise risks accidental discrimination relevant employees organisation including managers lawyers computer scientists aware risks seen many exa mples discriminatory organisations set discriminate organisations aware risks might able prevent discrimination perhaps ducation could also help mitigate effects automa tion bias among employees risk assessment mitigation organisation starts project perform risk assessment risk mitigation entails involving individuals multiple disciplines computer science law define risks project recording assessment mitigation processes iii monitoring implementation project often reporting outward way either public oversight organisations ensure receive help computer scientists understand discrimination risks phrase computer scientist used shorthand data scientists people sufficient knowledge could also provide expertise emerging field computer science focuses discrimination risks field decisions since organisation called fatml organises workshops conferences aim ringing together growing community researchers practitioners concerned fairness accountability transparency machine learning computer scientists published citron see automation bias parasur aman manzey rieke bogen robinson see institute mantelero mantelero accessed august promising results instance discrimination data defining risks project challenging left alone computer scientists make value decisions building system often find risks choices hard communicate senior decision assessing mitigating discrimination risks requires active support developing systems time money needed active consideration relevant projects risks applicable legal normative principles different sector different risks involved system selects job applicants example one predicts crime therefore xperts knowledge particular sector may useful set ethics committee assess discuss systems entail risks human also useful bring academics civil society group potentially impacted individuals discuss concerns one way assess risks project carry appropriate type impa assessment inspiration drawn gdpr dpia requirement certain risky data processing organisations especially public sector consider publishing impact assessment report see custers kamiran alders kamiran calders kusner pedreschi ruggieri turini veale van kleek binns kaminski engineers defining discrimination fairness without extensive conversation lawyers community members campolo council europe big data guidelines para see article gdpr see council europe big data guidelines article see also reisman selbst risks syst also monitored use particularly phenomena system modelling likely change time risks impacts may change organisations consider publishing yearly reports monitoring system often possible prevent least minimise discriminatory effects instance organisation choose use certain features input data stem illustrate one company helps select employees says use distance work factor predict applicants successful employees factor correlates much race reported atlantic distance employee lives work instance never factored score given applicant although reported clients different neighbourhoods towns different racial profiles means scoring distance work could violate equal standards companies university research labs workforce often diverse largely male white instance organisations might pay attention discrimination diverse workforce hence organisations aim hire diverse obviously aiming diverse workforce always important see also article gdpr gama peck see also rieke robinson campolo public sector bodies compared private sector public sector extra responsibilities indeed many legal rules instance field human rights criminal procedure law administrative law aim protect people powerful state extra responsibilities also apply publi sector bodies use systems therefore possible systems public sector designed situations information systems could released public scrutiny spirit open data movement yet cases information might leak personal data create privacy risk might allow people game system therefore public bodies might want enable controlled access systems researchers civil society secure environments much statistical agencies sensitive microdata furthermore public sector could adopt sunset clause introducing systems take decisions abou people sunset clause could require system evaluated say three years assess whether brought hoped results disappointing disadvantages risks great consider ation given abolish ing ystem public sector bodies extra responsibilities private sector organisations companies take similar measures proposed public sector see kroll munoz smith patil veale binns edwards laskov lippman bamb auer zarsky see various degrees openness open data context zuiderveen borgesius gray van eechoud mccray oye petersen broeders schrijvers hirsch ballin equality bodies human rights monitoring bodies recommendations made equality bodies council europe member states human rights monitoring bodies european commission racism intolerance mitigating risks discrimination education technical expertise equality bodies human rights monitoring bodies aware promise threats therefore education equality bodies monitoring bodies basics risks needed equality bodies human rights monitoring bodies also ensure obtain technical expertise involving computer computer scientists recognise understand certain risks better instance computer scientists even specia lists could carry certain types investigations discrimination rieke bogen robinson note scrutiny sophisticated successful problems system often discovered simple obser vation system inputs outputs computer scientists specialists often know specialists hire certain investigations depending budget equality bodies human rights monitoring bodies could hire computer scientists project permanent basis mentioned phrase computer scientist used report shorthand data scientists people sufficient knowledge could also provide expertise see importance technical expertise data protection authorities raab szekely rieke ogen robinson rieke bogen robinson also give examples scrutiny systems equality bodies human rights monitoring bodies consider organising public awareness campaigns organisations public private noted many ases organisations use discriminatory systems accident awareness could help generally schools universities teach computer science data science related topics teach students human rights ethics many unive rsities already offer courses computer science equality bodies human rights monitoring bodies could consider assisting schools universities permit public debate would good general public knew risks discriminatory many advantages possibilities however awareness building lead responsibilisation term describes process whereby subjects rendered individually responsible task previously would duty another usually state agency would recognized responsibility policy makers make people responsible defending discrimination said awareness important inclusive debate risks decisions see ecri statute resolution article ecri general policy recommendation para para explanatory memorandum para fiesler compiled list courses tech ethics see ecri general policy recommendation combating racism racial discrimination school education december str asbourg cri accessed octobe wakefield fleming see also ellis watson prior consultation equality bodies equality bodies could require public sector bodies discuss planned projects involve decision individuals groups nstance equality body could help assess whether training data equality bodies could also require public sector body using decision people ensure sufficient legal technical expertise assess monitor risks public sector bodies could required regularly assess whether systems discriminatory effects depending national situation uality bodies could also suggest rather require equality bodies human rights monitoring bodies could help develop specific method human rights impact assessment mentioned mpact assessments useful date specific impact assessment method developing method different stakeholders people different disciplines involved inspiration drawn privacy data protection impact engage public procurement processes equality bodies seek national provisions processes well lobbying increased access involved procurement public systems early stage equality bodies elp ensure concerns around discrimination built systems see ecri general policy recommendation article see also article gdpr prior consultation reisman discuss algorithmic impact ssessments since council europe member states different legal systems method provide inspiration directly applied see binns kloza mantelero wright hert see also brussels laboratory data protection privacy impact assessments procured systems open enough audit subject appropriate safeguards cooperate data protection authorities said discrimination two relevant legal frameworks law data protection law would shame fields law operate equality bodies cooperate data protection authorities instance could hel pful exchange knowledge learn one many data protection authorities technical expertise house experience hiring outside computer scientists research projects data protection authorities may learn organisations use systems entail discrimination risks ould warn equality bodies equality bodies could provide information data protection authorities instance discrimination ris depending national situation could also useful equality bodies cooperate consumer protection authorities competition law authorities cooperation knowledge sharing different types regulators europea data protection supervisor proposed set voluntary network regulatory bodies share information possible abuses digital ecosystem effective way tackling see schreurs gellert hacker lammerant hert blok see ecri general policy recommendation article raab szekely instance researchers university leuven examined facebook tracking data protection authority belgium see belgian data protecti authority perhaps initiative could provide nspiration equality bodies human rights monitoring bodies cooperate academics equality bodies human rights monitoring bodies keep touch perhaps cooperate academics report illustrates many examples discriminatory decisions discovered academic researchers investigative journalists many academics love assist regulators regular contact short term equality bodies monitoring bodies could visi conferences events academic researchers meet many international privacy conferences discriminatory much topic several conferences attract mix regulators practitioners civil society group scholars different disciplines law computer science philosophy equality bodies monitoring bodies could also consider organising conference round tables events discrimination risks foster contacts research community equality bodies perhaps equality bodies monitoring bodies could commission research discrimination risks european data protection supervisor aside within universities cooperation needed different types legal scholars non law specialists often working human rights institute data protection law specialists often working law technology institutes see rieke bogen robinson see instance cpdp computers privacy data protection conference brussels apc amsterdam privacy conference tilting perspectives perspectives plsc privacy law scholars conference acm conference fairness accountability transparency acm fat amsterdam accessed october see section set working party discrimination equality bodies human rights monitoring bodies engage civil society group work also consumer civil society group focus technology policy digital rights civil society groups work discrimination often different expertise groups work tech nology digital rights contact groups would useful many interested litig ation regulation depending national situation equality bodies could also engage strategic litigation area decision equality bodies human rights monitoring bodies could push regulation mitigate discrimination risks suggestions improve regulation discussed next chapter see ecri sta tute resolution article ecri general policy recommendation article see ecri statute resolution article consumer organisations beuc european consumer organisation could point contact beuc members consumer organisations european countries accessed october see also european consumer organisation beuc groups focusing rights freedoms digital environment european digital rights edri could point contact edri association civil human rights organisations across europe accessed october see gangadharan niklas interviewed ngos conclude better cooperation needed privacy chnology ngos discrimination ngos see ecri general policy recommendation article see ecri statute resolution article ecri general policy recommendation article improving regulation types action legal regulatory self reduce risks current law weaknesses applied discrimination saw chapter additional regulation probably needed protect people illegal discrimination unfair differentiation section provides preliminary remarks regulating area fast ing technology ection focuses improving enforcement existing non norms section discusses whether legal norms amended decision suggestions chapter meant starting points discussion rather definitive policy advice regulation fast technology regulating brings extra challenges rules apply fast technology adopting statute treaties may take years even decades meanwhile technology market society develop quickly challenges unique experience regulating new technologies regulating area new technologies policy combin differen types rules statutes broad principles guidelines regulators instance specific statutes could phrased reasonably technology way technology legal provisions broad principles advantage changed every time new technology developed disadvantage broad principles difficult apply practice therefore see koops guidance regulators guidelines amended faster thus specific concrete guidelines evaluated regularly amended ever required data protection law partly takes combined approach data protection law gdpr modernised convention ontains many broadly phrased provisions applied different situations instance data protection law contain specific rules cctv monitoring workplace far personal data including video images used ata protection law apply cctv workplace monitoring addition data protection law statutory provisions data protection authorities often adopt interpretative guidelines specific concrete requirements different situations automated decision european data protection board predece ssor adopted guidelines since similarly council europe dopted see zuiderveen borgesius chapter baldwin cave lodge chapter see koops suggesting data protection law seen best practice regulating fields technology develops quickly plenty criticise data protection law data protection law developed since early could seen legal answer new development large bureaucracies automated personal data processing since inception data protection law adapted continuously new developments illustrated recent gdpr modernised convention article working party article working party article working party see website european data protection board predecessor called article working party opinions guidelines also compiled site guidelines addition data protection convention instance big police hence new legal rules adopted mitigate discrimination risks area perhaps statutory rules combined possibility regulatory bodies adopt guidelines easier amend possibilities statutory law regulator guidance self varying degrees influence public regul ators basic idea remains different types rules koops puts multi legislation open formulations mixed approach abstract concrete rules periodically evaluated adequate leg certainty respect current technologies may ensured time sufficient scope given future technological developments course must democratic legitimacy sufficient checks balances regarding entiti set rules guidelines sum regulating area new technologies hard possible often necessary links accessed october council europe big data guidelines council europe police personal data guide council europe profiling recommendation see angelopoulos brown marsden specifically regulation hirsch kaminsky koops enforcement improving enforcement current non norms regarding discrimination area decisions overarching norms reasonably clear society accept discrimination basis protected characteristics racial origin suggestions enforcement ion norms area transparency noted one problems systems lack transparency black box opaqueness seen problem opaqueness also makes harder discover discrimination regulation aim improve transparency law including guidelines etc could instance require systems used public sector developed way enable auditing explainability private sector requirements could precedents requirements private sector requirement interpretability exists certain systems algorithmic types systems could useful public sector bodies release underlying code software sometimes examining code provide information system works rieke bogen robinson note code audits likely useful clearly defined question software program operates regulated pasquale also zarsky see rieke bogen robinson pasquale see auditing systems sandvig see rieke bogen robinson see section part algorithmic trading space particular standards measure system behaviour performance freedom information laws could adapted code systems subject laws amendment would enable journalists academics others obtain examine code systems often protected trade secrets intellectual property rights company terms protection mak harder regulators journalists academics investigate systems perhaps law adapted improve research exceptions enable types research perhaps law require organisations disclose certain information researchers upon request regulation must strike delicate balance public interest transparency commercial privacy interests many cases code alone give much information system system assessed used practice even moderately complex programs observe rieke bogen robinson may necessary see program run wild real users data truly understand effects law could require public sector use systems properly assessed risks enable oversight auditing similar requirement could considered private sector systems used certain decisions instance eligibility insurance credit research debate needed rieke bogen robins see bodo malgieri wachter mittelstadt similar questions arise open data versus privacy discussions see zuiderveen borgesius gray van eechoud rieke bogen robinson see campolo see campolo conduct audits oversight auditing systems organisation needs considerable investigation enforcement powers council europe member states ensure equality bodies data protection authorities receive adequate funding sufficient investigation enforcement without enforcement transparency necessarily lead sum equality bodies human rights monitoring bodies push regulation enables better enforce ment current non norms area decision making however decision also opens way new types discrimination differentiation largely escape current laws turn topic regulating new types differentiation law data protection law leave gaps context many non statutes apply certain protected characteristics race gender sexual statutes apply discrimination basis financial stat instance data protection law help fill definitely gaps non discrimination law systems escape law differentiate basis newly invented give simplified example suppose system finds correlation suggested specific oversight body automated profiling decision might useful see koops see ecri general policy recommendation article see kaminski see section gerards khaitan custers see also mittelstadt using certain web browser great willingness pay online shop could charge higher prices people using practices would remain outside scope tion law browser type protected characteristic hypothe sis assume browser type proxy protected characteristic einforc social inequality decisions remain outside scope nondiscrimination law still lead differentiation unfair drawbacks instance insurance companies could use systems set premiums individual consumers deny consumers insurance extent risk differentiation necessary accepted practice insurance considered fair high customers pay higher premiums drawbacks much risk differentiation could make insurance unaffordable consumers ould threaten risk function insurance furthermore risk differentiation might result poor paying consumer lives poor neighbourhood many burglaries might pay house insurance risk burgla higher neighbourhoods many poor people live higher risks poor people pay average evidence practices altho ugh technical perspective price discrimination easy however travel booking site showed expensive hotels apple users cheaper ones users mattioli see insurance dutch association insurers financial conduct authority peppet swedloff germany specific rule automated decisions insurance context see bundesdatenschutzgesetz vom juni bgbl section accessed october see also malgieri discrimination insurance avraham generally could reinforce social inequality instance valentino vries singer soltani showed onl ine price differentiation practices effect people poor areas paid higher prices several shops charged consumers live countryside consumers large cit countryside consumers drive visit competitor therefore online shop use cheap prices customers drive hours buy product cheaper price large city consumer easily competitor buy product therefore online shops offered cheaper prices large cities pricing scheme effect probably unintentionally poorer people paid average higher prices people tend poorer countryside thus reinforce soci inequality noted someone financial status protected characteristic law regulate practice assuming practice lead indirect discrimination based protected characteristic lead errors law little say incorrect predictions false positives false negatives problem decisions often incorrect particular individual decision often enta ils applying predictive model individuals simplified example predictive model people living postal code pay bills based group profile company denies loans people postal code valentino vries singer soltani valentino vries singer soltani see reinforcing inequality social sorting also atrey danna gandy lyon naudts taylor turow gandy warned ears ago discriminatory effects large data processing gandy data protection law data somebody financial status among special categories data article gdpr also denies loans pay bills practices could disproportionately harm certain groups society sometimes system makes errors minority groups new rules additional regulation considered decision escapes non law still unfair probably useful adopt rules decision general used many different sectors man purposes often threaten human system chess computer bring risks system predictive policing even systems make decisions humans risks different different ectors different rules apply fairness decision assessed abstract sector application area different arguments different different sectors different normative legal princ iples apply instance right fair trial presumption innocence important field criminal law consumer transactions freedom contract important principle hence new rules considered rules need focus specific sectors whether need new rules could assessed follows particular sector several questions answered rules apply sector rationales rules rule example aim zarsky see example system errors minorities rieke robinson situation decisions could form prohibited indirect discrimination see also hardt see royal society schauer see also wachter mittelstadt protect human right express legal principle equality contractual freedom right fair trial economic rationales also differ sector sector instance risk oling important insurance relevant sectors hence sector rationales behind rules differ could decision used sector risks instance false positives serious problem context criminal law false positive could lead people questioned arrested perhaps even punished accept decision breaches underlying values criminal law contrast incorrect decision system price discrimination makes consumer pay extra effect often less harmful incorrect decision leads someone arrested police iii considering rationales rules sector law improved light decision making threaten law underlying principles undermine law goals current law leaves important risks unaddressed amendments considered conclusion new rules may needed decision protect fairness human rights right non discrimination however research debate required questions whether rules needed empirical technical research information neces sary good policy clear need information discrimination hence council europe member states support research research human rights monitoring bodies equality bodies academics empirical research needed instance unclear scale decision making used often algorithmic decision lead discrimination basis racial origin instance types unfair differentiation computer science research solutions needed instance could systems designed respect promote human rights fairness accountability training data checked discrimination risks noted emerging vibrant field computer science focuses generally countries fund research part funding used research risks fairness human rights mitigating ose risks normative legal research also need public debate ormative legal research could prohibition indirect discrimination enforced effectively law deal unfair differentiation mains outside scope law define fairness diverse sectors law technology protect see wagner see campolo accessed october people structural discrimination law protect types group privacy safeguard rule law systems make decisions people types decisions never taken computers could data protection law used practice fight discrimination new rules needed tweaks law data protection law sufficient tweaks would needed new rules would needed vii conclusion conclusion offers many exciting possibilities improve societies decision also brings risks often opaque discriminatory effects instance system learns data reflecting biased human decisions public private sector rganisations take driven decisions far effects people public sector bodies use predictive policing sentencing recommendations decisions instance pensions housing assistance unemployment benefits private sector also take dec isions major consequences people decisions regarding employment housing credit moreover many small decisions taken together large effects one targeted vertisement rarely major problem aggregate targete advertising may exclude groups price differentiation could lead certain groups society consistently paying see intersectional discrimination crenshaw fredman see also ecri general policy recommendation combating racism racial discrimination employment adopted june cri recommendation accessed october see structural discrimination para explanatory memorandum ecri gene ral policy recommendation see bygrave chapters taylor van der sloot floridi vedder hildebrandt bayamlıoğlu leenes relevant legal instruments mitigate risks aidriven discrimination non law data protection law effectively enforced legal instruments could help fight illegal discrimination council europe member states human rights monitoring bodies european commission racism intolerance equality bodies aim better enforcement current norms also paves way new types unfair differentiation discrimination escape current laws non discrimination statutes apply discrimination basis protected characteristics racial origin statutes apply organisations differentiate basis newly invented classes correlate prot ected characteristic differentiation could still unfair however instance reinforces social inequality probably need additional regulation protect fairness human rights area regulating general right approach use systems varied one set rules need sector rules different values stake different problems arise different sectors debate interdisciplinary research need make right choices enjoy many benefits minimising risks unfair discrimination bibliography shared statement civil rights concerns use pretrial risk assessment instruments shared statement civil rights concerns signed civil rights organisations accessed october allen three black teenagers search shows society google racist june guardian teenagers accessed october alpaydin machine learning new mit press ananny crawford seeing without knowing limitations transparency ideal application algorithmic accountability new media society angelopoulos study fundamental rights limitations online enforcement self report ivir institute information law university amsterdam accessed october angwin scheiber tobin dozens companies using facebook exclude older workers job ads propublica december targeting accessed september angwin tobin varner facebook still letting housing advertisers exclude users race propublica november housing accessed september angwin machine bias software used across country predict future criminals biased blacks propublica may accessed september angwin mattu larson tiger mom tax asians nearly twice likely get higher price princeton review propublica article working party opinion processing personal data means video surveillance february article working party guidelines data protection impact assessment dpia determining whether processing likely result high risk purposes regulation brussels october article working party opinion data processing work june article working party guidelines automated individual decision making profiling purposes regulation february atrey intersectional case poverty discrimination law human rights law review avraham discrimination insurance lippert kasper routledge handbook ethics discrimination routledge bagli facebook vowed end discriminatory housing ads suit say new york times marc accessed october baldwin cave lodge understanding regulation theory strategy practice edition oxford university press bambauer zarsky algorithm game march notre dame law review forthcoming accessed october barocas selbst big data disparate impact calif law rev bayamlıoğlu leenes rule law implications data decision techno perspective doi law innovation technology bbc news google apologises photos app racist blunder july accessed october belgian data protection authority victory authority facebook proceeding february facebook accessed october binns data protection impact assessments meta approach international data privacy law binns reducing human percentage perceptions justice algorithmic decisions chi april canada accessed october bodo tackling algorithmic control crisis technical legal ethical challenges research algorithmic agents yale tech broeders schrijvers hirsch ballin big data secu rity policies serving security protecting freedom wrr brief netherlands scientific council government policy wrr accessed october bryson three different sources bias fix adventures july accessed october boyd crawford critical questions big data provocations cultural technological scholarly phenomenon information communication society brown marsden regulating code good governance better regulation information age mit press buolamwini gebru gender shades intersectional accuracy disparities commercial gender classific ation conference fairness accountability transparency burrell machine thinks understanding opacity machine learning algorithms big data society bygrave minding machine article data protection directive automated profiling computer law security report bygrave data protection law approaching rationale logic limits information law series kluwer law international cabañas cuevas cuevas facebook use sensitive data advertising europe arxiv preprint caliskan bryson narayanan semantics derived automatically language corpora contain human biases sci ence campolo report accessed october chouldechova fair prediction disparate impact udy bias recidivism prediction instruments big data accessed october citron technological due process rev cobbe administrative law machines government judicial review automated public decision presented microsoft cloud computing research centre symposium university cambridge available ssrn accessed october collins khaitan indirect discrimination law controversies critical questions ollins khaitan eds foundations indirect discrimination law hart publishing council europe big data guidelines consultative committee convention protection individuals regard automatic processing personal data guidelines protection individuals regard processing personal data world big data strasbourg january accessed october council europe msi council europe committee experts human rights dimensions automated data processing different forms artificial intelligence accessed september council europe police personal data guide consultative committee convention protection individuals regard automatic processing personal data practical guide use personal data police sector february council europe profiling recommendation recommendation committee minist ers member states protection individuals regard automatic processing personal data context profiling adopted committee ministers november meeting ministers deputies crawford think big data foreign policy may accessed october crenshaw demarginalizing intersection race sex black feminist critique antidiscrimination doctrine feminist theory antiracist politics custers power knowledge ethical legal technological aspects data mining group profiling epidemiology wolf legal publishers custers calders schermer zarsky discrimination privacy information society springer dalenberg preventing discrimination automated targeting job advertisements computer law security review danna gandy glitters gold digging beneath surface data mining bus ethics dastin amazon scraps secret recruiting tool show bias women october reuters amazon accessed october datta tschantz datta automated experiments privacy settings proceedings privacy enhancing technologies datta discrimination online advertising multidisciplinary inquiry conference fairness accountability transparency hert gutwirth regulating profiling democratic constitutional state hildebrandt gutwirt eds profiling european citizen springer schutter ringelheim ethnic profiling rising challenge european human rights law modern law review dieterich mendoza brennan compas risk scale demonstrating accuracy equity predictive parity northpoint diaz gürses understanding landscape privacy technologies accessed october domingos master algorithm quest ultimate learning machine remake world basic books dommering regulating technology code law dommer ing ascher coding regulation essays normative role information technology asser press dourish algorithms others algorithmic culture context big data society dutch association insurers grip data green paper big data understanding data green paper big data accessed october dutch data protection authority dutch data protection authority facebook violates privacy law may authority accessed october dutch data protection authority informal english translation conclusions dutch data protection autho rity final report findings investigation processing personal data facebook group february accessed october duhigg companies learn secrets new york times february accessed october dwork fairness awareness proceedings innovations theoretical computer science conference acm ecri general policy recommendation equality bodies combat racism intolerance national lev december strasbourg cri accessed october ecri statute resolution council europe committee minis ters resolution res statute european commission racism intolerance objectid accessed october edwards veale slave algorithm right explanation probably remedy looking duke edwards veale enslaving algorithm right explanation right better decisions ieee security privacy ellis watson anti law oup oxford european agency fundamental rights handbook european data protection law edition publications office european union european commission communication commission european parliament european council council european economic social committee committee egions brussels com final swd final accessed september european cons umer organisation beuc automated decision making artificial intelligence consumer perspective beuc position paper schmon june accessed october european data protection supervisor privacy competitiveness age big data interp lay data protection competition law consumer protection digital economy march accessed september european data protection supervisor edps opinion coherent enforcement fundamental rights age big data opinion september accessed septemb equivant compas classification accessed september european group ethics science new technologies statement artificial intelligence robotics autonomous systems march accessed september ezrachi stucke virtual competition harvard federal trade commission big data tool inclusion exclusion understanding issues january accessed october feller computer program used bail sentencing decisions labeled biased blacks actually clear washington post ferguson rise big data policing surveillance race future law enforcement nyu press ferraris defining profiling profiling project working paper accessed october frawley piatetsky matheus knowledge discovery databases overview magazine fiesler tech ethics curricula collection syllabi accessed september financial conduct authority feedback statement call inputs big data retail general insuranc september accessed december fink opening government black boxes freedom information algorithmic accountability information communication society fortune fortune valuable companies accesses september fredman intersectional discrimination gender equality non discrimination law european network legal perts gender equality report european commission directorate justice consumers may accessed october friedman nissenbaum bias computer systems acm transactions informat ion systems tois frucci face webcams recognize black people gizmodo december accessed october gama survey concept drift adaptation acm comput surv gandy panoptic sort political economy personal information westview gellert vries hert gutwirth comparative analysis anti data protection legislations discrimination privacy information society springer berlin heidelberg gerards scrimination grounds bell schiek eds ius commune case books common law europe hart goodman discrimination data sanitisation auditing european union general data protectio regulation goodman flaxman european union regulations algorithmic decision right explanation arxiv preprint graef competition law data protection onli platforms data essential facility kluwer law international graef algorithms fairness role competition law targeting price discrimination towards end consumers accessed september greene hoffman stark better nicer clearer fairer critical assessment movement ethical artificial intelligence machine learning stark pdf accessed september greenleaf global tables data privacy laws bills privacy laws business international report accessed september guidotti others survey methods explaining black box models acm computing surveys csur gürses van hoboken privacy agile turn cambridge handbook consumer bridge university press cambridge accessed october hacker teaching fairness artificial intelligence existing novel strategies algorithmic discrimination law common market law review issue han pei kamber data mining concepts techniques elsevier harcourt prediction profiling policing punishing actuarial age university chicago ess hardt big data unfair understanding sources unfairness data driven decision making accessed october helberger zuiderveen borgesius reyna perfect match closer look relationship consumer law data protection law common market law review hildebrandt fining profiling new type knowledge hildebrandt gutwirth eds profiling european citizen springer hildebrandt criminal law technology data society dubber hörnle oxford handbook crimin law oxford university press hildebrandt smart technologies end law novel entanglements law technology edward elgar publishing hildebrandt gutwirth eds profiling european citizen springer hirsch law policy online privacy regulation self seattle rev jabłonowska consumer law artificial intelligence challenges consumer law policy temming business use artificial intelligence final report artsy project seque accessed september jernigan mistree gaydar facebook friendships expose sexual orientation first monday jordan artificial intelligence revolution happened yet april hasnt accessed august kay mat uszek munson unequal representation gender stereotypes image search results occupations proceedings annual acm conference human factors computing systems acm kaminski right explanation explained accessed october kaminski binary governance two approach accountable algorithms rev forthcoming kamiran calders classifying without discriminating international conference computer control communication february kamiran calders data preproces sing techniques classification without discrimination knowledge information systems khaitan theory discrimination law oup oxford kilbertus blind justice fairness encrypted sensitive attributes proceedings international conference machine learning icml kim data discrimination work mary kloza van dijk gellert maurice borocz tanas mantovani quinn data pro tection impact assessments european union complementing new legal framework towards robust protection individuals policy brief article accessed september koene ieee establishing standards ethical technology wang east china normal university koops ict regulation chnology koops bert jaap eds starting points ict regulation deconstructing prevalent policy one information technology law series asser accessed october koops reflections profiling power shifts protection paradigms hildebrandt gutwirth eds profiling european citizen cross perspectives springer korff comments selected topics draft data protection regulation september accessed september kroll accountable algorithms university pennsylvania law review lammerant hert blok big data gelijke behandeling big data equal treatment blok big data het recht sdu uitgeverij accessed october lippert born free equal philosophical inquiry nature discrimination oxford university press kusner counterfactual fairness advances neural information processing systems larson job ads see facebook older new york times december larson analyzed compas recidivism algorithm propublica may accessed august larson mattu angwin unintended consequences geographic targeting technology science laskov lippmann machine learning adversarial environments machine learning lehr ohm playing data legal scholars learn machine learning ucdl rev lipton swirling nomenclature slurried thought june nomenclature accessed august lowry macpherson blot profession med clin res lum isaac predict serve significance lyon surveillance social sorting computer codes mobile bodies lyon surveillance social orting privacy risk automated discrimination routledge malgieri trade secrets personal data possible solution balancing rights international data privacy law malgieri right explanation algorithm legib ility member states legislations august accessed october malgieri right legibility automated decision exists general data protection regulation international data privacy law malgieri sensitive quasi data algorithmic era information communications technology law mantelero artificial intelligence data protec tion challenges possible remedies draft report council europe consultative committee convention protection individuals regard automatic processing personal data september intelligence accessed september mantelero big data blueprint human rights social ethical impact assessment computer law security review mattioli orbitz mac users steered pricier hotels wall street journal august mccar thy proposal dartmouth summer research project artificial intelligence august accessed october mccray oye petersen planned adaptation risk regulation initial survey environmental health safety regulation technological forecasting social change mendoza bygra right subject automated decisions based profiling miller explanation artificial intelligence insights social sciences arxiv preprint mittelstadt ethics algor ithms mapping debate big data society munoz smith patil big data report algorithmic systems opportunity civil rights white house executive office president accessed october narayanan language necessarily contains human biases machines trained language corpora freedom tinker august human accessed september naudts fair unfair algorithmic differentiation uck egalitarianism lens evaluating algorithmic decision august accessed october nemitz democracy technology age artificial intelligence phil trans soc accessed october noble algorithms oppression search engines reinforce racism nyu press neil weapons math destruction big data increases inequality threatens democracy crown publishing group oswald algorithm cision public sector framing issues using administrative law rules governing discretionary power philosophical transactions royal society mathematical physical engineering sciences oswald grace intelligence policing use algorithmic analysis freedom information study journal information rights policy practice parasuraman manzey complacency bias human use automation attentional integration hum factors pasquale black box society secret algorithms control money information harvard university press pasquale toward fourth law robotics preserving attribution responsibility explainability algorithmic society july ohio state law journal vol accessed october paul jolley anthony reflecting past shaping future making work international development report united states agency international development accessed october peck watching work atlantic december accessed october pedreschi ruggieri turini discrimina data mining acm int conf knowledge discovery data mining kdd peña gangadharan niklas antidiscrimination data understanding human rights discourse automated discrimination europe peppet regulating internet things first steps toward managing discrimination privacy security consent texas law review perry predictive policing role crime forecasting law enforcement operation accessed september poole mackworth goebel computational intelligence logical approach oxford university press new york prates avelar lamb assessing gender bias machine translation case study google translate accessed september puppe systematic introduction expert systems knowledge representations problem methods springer science business media raab szekely data protection authorities information technology computer law security review regan new zealand passport robot tells applicant asian descent open eyes reuters december china accessed october reisman schultz crawf ord whittaker algorithmic impact assessments practical framework public agency accountability institute rieke bogen robinson public scrutiny automated decisions early lessons emerging methods upturn omidyar network accessed october rieke robinson civil rights big data algorithmic future september report social justice technology version washington upturn pdf version accessed october ringelheim schutter processing racial ethnic data antidiscrimination policies reconciling promotion equality privacy rights brussels bruylant robinson koepke stuck pattern accessed october royal society machine learning power promise computers learn example april accessed may russell norvig artificial intelli gence modern app roach third edition prentice hall sandvig auditing algorithms research methods detecting discrimination internet platforms data discrimination converting critical concerns productive inquiry selbst disparate impact big data policing selbst powles meaningful information right explanation international data privacy law selbst barocas intuitive appeal explainable mac hines fordham law review forthcoming accessed october sharp nikon camera says asians people always blinking may accessed october schauer profiles probabilities stere otypes harvard university press schreurs hildebrandt kindt vanfleteren cogitas ergo sum role data protection law non law group profiling private sector profiling european citizen spri nger siegel predictive analytics power predict click buy lie die john wiley sons sunstein problems rules california law review swedloff risk classification big data evolution connecticut insurance law journal sweeney discrimination online delivery acm queue taylor data justice case connecting digital rights freedoms globally big data society taylor van der sloot floridi eds group privacy new challenges data technologies springer tene polonetsky taming golem challenges ethical algorithmic decision ncjl tech tickle truth come light directions challenges extracting knowledge embedded within trained artificial neural networks ieee trans neural networks tobler indirect discrimination case study development legal concept indirect discrimination law vol intersentia turing digital computers think reprinted copeland essential turing clarendon press turow daily new advertising industry defining identity worth yale university press valcke graef clifford ifairness constructing fairness areas law intra interdisciplinarity computer law security review valentino singer soltani websites vary prices deals based users information wall street journal december van brakel hert policing surveillance law pre society unders tanding consequences technology based technology policing van eck geautomatiseerde ketenbesluiten rechtsbescherming een onderzoek naar praktijk van geautomatiseerde ketenbesluiten een financieel belang relatie tot rechtsbescherming automated administrative chain decisions legal protection research legal safeguards regarding practice automated chain decisions financial interests phd thesis university tilburg accessed september van nooren van gorp van eijk fathaigh regulate digital platforms new framework evaluating policy options policy internet accessed october veale binns fairer machine learning real world mitigating discrimination without collecting sensitive data big data society veale binns edwards algorithms remember model inversion attacks data protection law philosophical transactions royal society mathematical physical engineering sciences veale van kleek binns fairness accountability design need algorithmic support high public sector decision proceedings annual acm conference human factors computing systems chi veale edwards clarity surprises questions article working party draft guidance automated decision profiling computer law security review vedder information technology privacy reconsidering social responsibilities private organizations moore business ethics principles practice sunderland business education publishers vetzo gerards nehmelman algoritmes grondrechten algorithms fundamental rights utrecht juridisch accessed october wachter normative challenges identification internet things privacy profiling discrimination gdpr computer law security review volume issue june wachter mittelstadt right reasonable inferences data protection law age big data september columbia business law review forthcoming accessed october wachter mittelstadt russell counterfactual explanations without opening black box automated decisions gdpr spring harvar journal law technology wachter mittelstadt floridi right explanation automated decision exist general data protection regulation international data privacy law wagner ethics escape regulation ethics washing ethics hildebrandt profiling cogitas ergo sum amsterdam university press draft available accessed september wagner algorithms human rights study huma rights dimensions automated data processing techniques possible regulatory implications dgi prepared committee experts internet intermediaries msi council europe accessed june wakefield fleming responsibilization sage dictionary policing sage publications ltd wright hert eds privacy impact assessment springer york three black teenagers google rac ist june google accessed october zarsky mine business making case implications data mining personal information forum public opinion yale journal law technology zarsky analytic challenge discrimination theory age predictive analytics isjlp zarsky trouble algorithmic decisions analytic road map examine efficiency fairness automated opaque decision making science technology human values žliob aitė custers using sensitive personal data may necessary avoiding discrimination data decision models artificial intelligence law zuiderveen borgesius behavioural sciences regulation priva internet sibony alemanno eds nudge law law learn behavioural sciences hart publishing accessed september zuiderveen borgesius improving privacy protection area behavioural targeting kluwer law international accessed september zuiderveen borgesius poort online price discrimination data privacy law journal consumer policy accessed september zuide rveen borgesius gray van eechoud open data privacy fair information principles towards balancing framework berkeley accessed september zuiderveen borgesius van hoboken fahy irion rozendaal assessment commission proposal privacy electronic communications directorate internal policies policy department citizen right constitutional affairs may accessed september
