fra focus quality artificial intelligence mitigating bias error protect fundamental rightshelping make fundamental rights reality everyone european union fra focus contentsalgorithms used machine learning systems artificial intelligence good data used development high quality data essential high quality algorithms yet call high quality data discussions around often remains without specifications guidance actually means since several sources error data collections users technology need know data come potential shortcomings data systems based incomplete biased data lead inaccurate outcomes infringe people fundamental rights including discrimination transparent data used systems helps prevent possible rights violations especially important times big data volume data sometimes valued quality data quality artificial intelligence fundamental rights artificial intelligence machine learning algorithms use data beware bias case study use data internet low data quality impact fundamental rights assessing data quality conclusion asking right questions data quality artificial intelligence mitigating bias error protect fundamental rights data quality artificial intelligence fundamental rights artificial intelligence big data continues topic high priority policy science business media throughout world developments area high relevance new technologies impact spheres life hence also impact funda mental rights ethical implications topic many discussions time discus sions need acknowledge human rights framework setting binding legal obligations around seen starting point evaluation opportunities challenges brought new technologies european union strong fundamental rights framework enshrined charter fundamental rights related case law provides guidance development guidelines recommendations use paper sets contribute many ongo ing policy discussions around big data high lighting one aspect needs attention fun damental rights perspective namely awareness avoidance poor data quality aim explaining use high quality data become aware avoid using low quality data data quality building algorithms technologies one concerns funda mental rights compliant use data algorithm application good data uses following often quoted garbage garbage principle low quality data lead low quality outcomes produced algorithms turn lead violation fundamental rights obviously privacy data protection important area use low quality data affect rights also affected example automated system used justice system based poor quality data negatively impact right fair trial effective remedy well principle good administration referred fra previous focus paper algorithms biased result lead discrimination women ethnic minorities elderly groups based protected grounds example voice recognition system mainly trained male voices system may perform accurately used women due data qual ity problem quality data used leads une qual performance services different groups population identified one potential problems result discrimina tion data supported decision making fra explored earlier focus addition data reflect existing bias discriminatory behaviour taken potentially reinforced fra barocas selbst artificial intelligence many definitions one definition included european commission commu nication artificial intelligence europe artifi cial intelligence refers systems display intelligent behaviour analysing environment taking actions degree auton omy achieve specific goals systems purely acting virtual world voice assistants image analysis software search engines speech face recognition sys tems embedded hardware devices advanced robots autonomous cars drones internet things applications using daily basis translate languages generate subtitles videos block email spam many technologies require data improve per formance perform well help improve automate decision making domain example system trained used spot basis data concerned network important accept term refer one thing current technological devel opments processes general discussed heading refers increased automation tasks use machine learning automated decision making core current discussions machine learning applications lies use algorithms algo rithms rules followed computer pro grammed humans translate input data outputs european comission see definition algorithms fra useful discussion definition artificial intelligence found united nations human rights councl fra focus data quality broad concept two generic concepts related data quality used social sciences survey research highlighted representation means data cover well population cover errors means data measure intend measure data quality key concern policy discussions discussions research assessment algorithms often focus need explain complex algorithms work however assess ing algorithms focus type quality data used algorithms equal importance included assessment algorithms recently academic research data quality machine learning received increased however many text books articles dealing data science machine learning still overlook crucial aspect data quality scratch sur face paper contributes dis cussion fundamental rights implications highlighting concepts data quality devel opment algorithms technologies used social sciences survey research focuses one potential source impact fun damental rights serves provide guidance ongoing policy discussions use relation fundamental rights topic data quality mentioned repeatedly policy documents relation use european council conclusions june acknowledged data essen tial development artificial european group ethics science new technologies ege refers discriminatory biases datasets used train run systems prevented detected reported neutralised earliest stage possible see example gebru holland richardson schultz crawford text books use big data machine learning discuss data quality issues detail see example salganik cabitza foster european council european group ethics science new technologies committee civil liberties jus tice home affairs european parliament libe committee opinion motion european parliament resolution comprehen sive european industrial policy artificial intelli gence highlighted importance quality accuracy well representa tive nature data used development deployment algorithms specifically libe committee noted use outdated incomplete incorrect data different stages data processing may lead poor predic tions assessments turn bias eventually result infringements fun damental rights individuals purely incorrect conclusions false outcomes moreover european commission high level expert group published ethics guidelines include data governance one requirements trustworthy highlight importance biases datasets used machine learning could include human misjudgement errors mistakes need keep record data fed toronto declaration initiated signed several rights groups technologists researchers issues statements avoiding bias discrimina tion machine learning systems one state ment calls private sector take account risks commonly associated machine learning systems including incomplete unrepresenta tive data datasets representing historic sys temic bias european commission efficiency jus tice cepej council europe adopted european ethical charter use artificial intelligence judicial systems environ ment charter puts forward principles including principle quality security includes use certified sources intangible european parliament committee civil liberties justice home affairs european commission expert group artificial intelligence rightsconn canada council europe data quality artificial intelligence mitigating bias error protect fundamental rights artificial intelligence machine learning algorithms use data one main drivers behind technological devel opments area unprecedented availability vast amounts data collected analysed used ever increas ing pace phenomenon referred big data often exclusively data gathered internet smartphones data con sidered important asset provides basis many applications progress field sense questions concerns related data quality core discussions developments data constitute basis many technological developments area machine learning one broad field discussions focus learning algorithms make use data establishing patterns applied new unseen data algorithm learns rules based examples included training data discussions one paper focus supervised machine learn ing uses labelled major advances made image rec ognition algorithm built learning classify pictures instance many pictures includ ing houses analysed create algorithm identifying houses rules based analysis tested new set pictures also include houses accuracy examples include data previous crime incidents help understand likely crime occurs data social media posts example use specific words combinations words used predict someone likely click advertisement data previous data loosely defined less structured standardised information processed computers usually form text numbers example images analysed content translated numbers representing position colour pixels paper raises issues mainly arise data people one subset data discussion would similarly apply unsupervised learning labelled data available categorisations data developed ways algorithms trained splitting training data training test validation sets relatively complicated part discussion paper addition use reinforcement learning component trial error included training phase considered paper accessible description machine learning found future privacy forum alpaydin examinations outcomes help understand predict patients certain illness highest risk suffer fatal diseases data browsing history could used predict income people examples make use labelled data already include information desired outcome information used learn situations yet available data labels description image often created humans prone human bias error important note learning algorithms easily beyond data use learn patterns training data computer scientists make possible efforts learn data hand machine learning model deployed used real life always easily possible verify success potential damage using machine learning algorithms least three different data sets training data used build algo rithm could data internet users browsing history whether click cer tain advertisements example demo graphic characteristics employment history unemployed people information whether found job time could used predict unemployed find job supervised machine learning desired outcome needs included training data data used learn desired outcome features desired come often referred labels basis algorithm learns patterns algorithm deployed fed new unseen features input data eval uated model parameters taking actions making decisions example browsing history people without yet know ing would click certain simplified description one type machine learning algorithms help get better understanding type data involved cases machine learning algorithms fra focus algorithm produces inferred labels predictions inferences deduced actions put data produced unseen data fed machine learning algorithm figure visualises process much sim plified description process serves illustrate data used supervised machine learning example shown training data contain information internet behaviour example browsing history data pos sible possessions user example smart phone person bought training data also includes labels could information known income people example obtained survey among internet users algo rithm finds correlations features labels derives rules rules used new unseen features example knowing person reads certain information online busi ness news bought newest smart phone feeding information algorithm pro duces label inferred features example high income figure simplified illustration types data used algorithms training data labels featuresincome algorithmunseen features inferred labels labels high income features reading business news online behaviour smartphone brand newest smartphone source fra algorithm following process described learn rules patterns based train ing data training data low quality notably structurally different new unseen features outputs algorithms pro duce poor could include repro duction bias dataset amplification existing bias lead discrimination low quality data refer many different aspects leading problem algorithm using new data training data cover sessions valtorta different group people compared new data correlations features labels different results inferred labels often erroneous herein many aspects data quality paper high lights two important errors derived survey research errors representation differ ent population groups covered training data new data measurement errors training data include right information data quality artificial intelligence mitigating bias error protect fundamental rights beware bias case study use data internet internet one important though source data generation collection draws data come variety sources cover different types data various topics data different sources impact bias section focuses data internet generic case study illustrate potential errors representation many businesses try harness information internet data often freely availa ble much information available data exactly used applications however internet social media one frequently used sources following describes comparative data use internet data companies highlights bias internet data general level give general sense coverage issues data internet potential bias increasing coverage data internet may reflect subset entire population related limited access internet different levels par ticipation online services social media often data collected items referred internet things iot although many systems use data internet sev eral applications use data internet could include insurance companies using data social media create risk scores potential cus development facial recognition algorithms based images beginning one ten busi nesses employees indi cates use big data analytics percentage businesses using big data analytics highest malta netherlands followed belgium ireland finland big data analytics might important eas ily applied larger companies due potentially resources data hand overall one three larger enterprises uses big data analytics particularly large enter prises belgium netherlands see discussion internet governance forum wang instance google provides list datasets used development including many internet generated data ireland denmark finland among enterprises using big data important source geolocation data portable devices mostly information people move measured informa tion smartphones every second enterprise using big data make use data similarly big data using enterprises use social media data data sources include enterprises smart devices sensors used businesses use big data data exemplify smartphone social media data important sources big data ana lytics potentially used devel opment machine learning algorithms busi ness decisions example area insurance unconventional sources types data increasingly use data internet raises many ques tions relation included data extent information included fit purpose first everyone access internet social media coverage different applica tions varies well secondly everyone wants access internet particular social media applications result certain groups covered data gathered internet way location data representative make information available use example portable devices smartphones depending individuals manage location settings enormous growth use internet almost lets one forget many people access internet data often biased represents particu lar group population lead invalid larger enterprises include persons employed statistics enterprises include businesses least persons employed considering financial sector data based eurostat eurostat example life bureau new york state department financial services issued circular insurers authorised write life insurance new york advising use external data sources reference social media internet data circular highlights potential discrimination challenges potential issues reliability accuracy data see life bureau new york state fra focus applied groups included training data applica tion biased coverage internet data com parison total population exemplified official statistics eurostat figure strong increase proportion households internet access beginning households internet access household means one ten households connection internet households beginning however general access internet varies considerably across countries regions within countries different groups population figure exemplifies often referred digital divide showing different pro portion households internet connec tion higher income households compared lower income households among richest quar ter households fourth quartile almost internet access contrary poorest quarter households first quartile internet access observed however gap closing time proportion richer house holds internet access twice proportion poorer households larger proportion richer households larger figure households internet access source fra based eurostat additionally strong geographical disparity terms levels access internet per centage households access internet ranges low bulgaria level access internet regionally clustered declining access north south west east eurostat data quality artificial intelligence mitigating bias error protect fundamental rights looking individuals households many said begin ning never use internet percentage never using internet dif fers across occupational age groups education levels gender internet use widespread among students workers ict profes sionals women men high education among younger people high proportions indi viduals never using internet found among older people aged finally proportion individuals never using internet high among people low formal educa tion among men even higher among women points strong disadvan tage among women low education terms using internet gender gap pronounced among levels education consequently data generated internet necessarily unrepresentative respect cer tain groups population includes south ern eastern countries poorer fami lies older people people low education particularly addition use social media among groups even lower general internet use also source biased data apparently easy access smartphones social media distract ing fact many individuals want use social media slightly half individuals use internet participate social networks creating user profiles posting messages content facebook twitter etc stark differences across member states popu lation groups using social media social media use higher among students younger peo ple aged years ict professionals women men high formal edu cation statistics underpin data internet social media limited terms coverage population shortcomings potentially limit use data internet develop ing machine learning models applied general population specific groups ever potential harm using biased data systems algorithmic decision making depends purpose application low data quality impact fundamental rights section provides brief overview fun damental rights may affected using low quality data technologies algo rithms fra currently carrying project examines concrete use cases technol ogies fundamental rights perspective information found box develop point obvious impact right article charter fundamental rights several reports studies highlighted use either biased data lead unequal treatment people based charac teristics sex age disability sexual orien tation ethnic origin religion among grounds protected structural differences training data protected attrib utes gender ethnic origin political opin ion output data machine learning algorithms fra barocas selbst discriminate individuals based attributes examples discrimination result using inadequate data growing hiring algorithm found generally prefer men online chatbot became racist within couple machine translations showed gender face recognition systems worked well white men black sentiment analysis method piece text assigned score positive negative provides sexist racist results reproduc ing reasons comes mainly based data used train machine learning systems discrimination also affect enjoyment economic social rights relates access services example algorithms automation dastin johnston prates avelar lamb buolamwini gebru caliskan bryson narayanan fra focus increasingly used areas related access employment social services welfare primary purpose make allocation resources efficient field use algorithms negative impact especially poor peo ple research united states moreover health related data exclude certain groups application newly developed treat ments might work groups equality men women article charter another related area impacted low data quality one gender sented sexist behaviour represented training increase inequality men access fair trial effective remedies article charter also impacted particularly algorithms used area crime preven tion criminal justice system use algorithms area justice needs testing highlighted cepej european ethical char one potential problem might use biased data automated addition enjoy access fair trial effective reme dies cases someone claims mistreated wants challenge decision based algorithm information system algorithm works essential example person denied access service result algorithm auto mated person right challenge decision able information algorithm works needed assess ment quality training data one important part assessment quality algorithms even though accessible information quality data required access effec tive algorithms used public administration potential problems arise low quality data hence impact principle good administration established law article eubanks buolamwini gebru prates avelar lamb crawford algorithms reproducing gender biases see zhao wang yatskar ordonez chang bolukbasi chang zou saligrama kalai council europe richardson schultz crawford wagner details negative fundamental rights implications consult raso hilligoss krishnaumurthy bavitz kim council europe accessnow charter mirrors principle applying institutions accordingly every person right affairs han dled impartially fairly within reasonable time institutions bodies use automated means contribute however article also mentions right includes among others obligation administration give reasons decisions also interpreted need make transparent data sources used train algorithms automated systems finally developments area strongly impact issues related respect private family life article protection per sonal data article however application data protection law question data quality building technologies algorithms clear data protection legislation offers min imal guidance topic principle data accuracy general data protection regulation gdpr related data quality nar row sense focuses obligation keep personal data accurate date accu racy usually interpreted correctness per sonal data one individual age one person database correct although term accuracy could interpreted widely addi tionally gdpr covers important rights access rectification erasure data minimisation security data however data quality means much used technologies limited personal data training data might used anonymised way data subjects might consent data features used systems new predictions ongoing discussion new inferred labels see figure actually covered data protection legislation researchers started analysing topic highlighting importance consider inferred data personal data rights gdpr could apply including right know data access rectify delete object research topic needed charter article applies institutions bodies established law much broader also includes administrations member states gdpr article see also fra additional law relevant aspect police directive law enforcement authorities use rely data protection reg comes use data institutions wachter sandra mittelstadt brent data quality artificial intelligence mitigating bias error protect fundamental rights use anonymised data needs assessed well used services pro vide decisions individuals example deci sions access services based sta tistical predictions based group characteristics post code occupation traits duly anonymised apart data accuracy aspect need assessment quality data used real world applications derives directly data protection principles accountability trans parency however transparency might difficult comes questions copyright intellec tual property business automated gdpr requires data controllers provide meaningful information logic involved well significance envisaged consequences process ing data quality data used developing algorithms seen one aspect able understand logic signif icance consequences automated decision making systems based algorithms makes description assessment data used train algorithm essential component provi sion meaningful information algorithms fra project artificial intelligence big data fundamental rights fra launched research project artifi cial intelligence big data fundamental rights project aims assessing positive negative fundamental rights implications new technologies including big data anal yses concrete case studies carrying interviews public administration busi nesses selected member states explores fundamental rigths impact selected areas health insurance additionally project collects information awareness fundamental rights issues among public adminis tration businesses applying tech nologies finally project aims explore feasibility studying concrete examples fun damental rights challenges using algorithms either online exper iments simulation studies information project see fra artificial intelligence big data fun damental rights assessing data quality many criteria looked assessing quality data applications general data quality includes many different issues exam ple questions completeness accuracy consist ency timeliness duplication validity availability fra research use biometric data largescale migration databases highlighted quality data notably accuracy alphanu merical data biometric identifiers negatively impact protection personal data large scale databases visa information system vis schengen information system sis incorrect data individuals rather com monly trust new technologies large databases often lets people forget data might inaccurate discussion mainly concerned accuracy data relation individuals data quality takes much broader scope levendovski gdpr article also article article burt fra era big data artificial intelligence big data applications aggregated data used learn patterns society automate pro cesses decision one problems big data sheer size data tendency convince findings based data must accurate however data quality taken account assumption might hold data quantity one criteria accuracy meas uring predicting something tackle statistical accuracy based data determine well represent real world needs assessed alongside data quality within systems european travel information authorisation system etias foresees use algorithms namely screening rules create risk indicators see meng formally third component refers difficulty problem hand component mentioned text complicate discussion unnecessarily context data quantity data quality problem difficulty refer three statistical concepts sample size bias variance fra focus definition data quality whether data used fit purpose consequently quality data depends strongly pur pose use following gives guid ance errors occur production use data based classical social science litera ture help understand errors training data used machine learning systems understanding errors helps identify potential problems data driven systems bias discrimination measurement representation two general sources error related data quality using data producing sta tistics measurement error representation error developed discussed area classical survey research together two issues present total survey error however also impact data qual ity data sources issues related representation measurement also importance assessing quality algo rithms based data machine learn ing algorithms make use aggregated information training data use learn measurement error measurement error refers accurately data used indicate reflect intended measured concept appropriate sur vey data question asked respondent must evaluated terms well question measures example asking someone view impact immi grants economy help measure xenopho bia additionally important know well answers questions measure really true respondents answer question hon estly much editing reorganising data distort measurement concept cal zhu groves robert groves robert lyberg lars link total error framework big data see bierer refers instance automated classification documents case pyrrho investments mwb property british court endorsed first time use predictive coding process document disclosure civil procedure paragraphs judgment contain detailed description steps taken deploying algorithm document classification include among others definition data set sample size batches control set reviewers confidence level margin error see united kingdom england wales high mind due reducing answer categories building index obviously important survey data sometimes used appli cations machine learning however questions measurement need addressed data sources well data adminis trative sources social media one intends measure credit worthiness based information income questions asked accurate information income information provided persons information declared income tax authorities income good indicator credit worthiness often several pieces information used combination measure one concept data often approximate intend meas ure example define measure good employee would someone rarely coming late statistics machine learn ing concepts creditworthiness good employee need defined ways measured give another example would like measure country origin people dataset information available nationality might used instead called proxy however means perfect measurement leave obtained nationality another country country origin countries substantial numbers obtaining citizenship hence nationality good proxy country origin data always approximate real world phenomena always error measurement important understand much error acceptable machine learning systems measurement error links question features included training data include information measure well meas ure used predict outcomes process labelling outcome data crucial importance particularly assessing bias often data labelled humans means people tasked look spe cific input data record outcome exam ple people looking pictures input data social science last question called operationalisation well measure concept want measure credit worthiness hand information income barocas selbst borgesius data quality artificial intelligence mitigating bias error protect fundamental rights descriptions pictures output data used algorithm learn patterns data labelling process measure ment errors arise especially qual ity control labelling process included representation error statisticians much concerned ques tion representative sample pop ulation good reason data cover well population cover resulting statistics incorrect biased entire population intended covered application included input data used building application error rep resentation hence needs assessed impact error gold standard statistics random selection sample means controlled way selection data units used analysis simplest efficient way selecting data simple random sampling means every person total popu lation covered application equal likelihood selected case small sample used accurate representations always certain amount error remains researchers decide acceptable level however often possible achieve situation likelihood selection would equal units additionally even persons selected rep resentative way might agree data used provide information real problem typical big data sources used making predictions general population data often internet using internet certain applications online constitute specific group population rep resent total population online applications target use question less important yet still question needs asked data used building application accurately represent future users example model built using data time ago outdated application work well due representation error automated systems timeliness data seems particular importance respect data analysed near real time algo rithms trained based historical data pre dict behaviour occurrences timeliness referes level confidence confidence interval deemed acceptable researchers based number observations sampling data crucial aspect assess one needs ask coverage data used building application changed time would impact future example users online portal two years ago still comparable behaving similar way using portal today question major importance algorithms used online since data behaviour constantly updated changing another point sometimes overlooked data often incomplete although data col lection might representative target popu lation parts data often missing people data set example informa tion forms income available eve ryone relying income data tax authorities give another example could considerable percentage online users cer tain application opted data used use purposes assess data quality information missing data partial data dealt necessary well example using algorithm developed one state another state case wisconsin loomis defend ant claimed court reference risk assessment report sentencing violated constitutional right due process report included scores estimating risk recidivism calculated proprietary algorithm defendant alleged among others software used sentencing wisconsin authorities tested wisconsin population although violation found case wisconsin supreme court ruled inves tigation report must contain information software limitations including notification algorithm compares defendants national sample population wisconsin moreover court noted software must constantly monitored accu racy due changing populations subpopula tions para source united states supreme court wisconsin state wisconsin eric loomis july academic research referred concept drift patterns data evolve time render data obsolete time see zliobaite pechenizkiy gama fra focus reliability validity two sources errors measurement representation error related two impor tant conditions data quality analysis often used social sciences survey research relia bility validity two concepts tradi tionally used describe measurement errors latent constructs social sciences measure ment certain concepts several indica tors example build index direct measurement possible using measurement related issues reliability refers stable consistent measurements validity refers question data prediction actually measure intend measure thus related errors representation measurement data reliable high variance results vary lot data valid biased measure wrong thing invalid data see example carmines zeller jackman often miss target systematically bias unre liable data might right target show much variation uncertainty means often miss target despite right average important aspect big data analytics large amounts data used mitigate errors comprehensive meas urement based many observations number observations used often large big data applications decreases statistical uncer tainty however without high quality data terms low errors representation meas urement large volumes data increase validity measurements contrary could miss target consistently happen partial data used example data certain demographic group systemati cally different groups population data quality european statistical system lessons quality data seen competitive advan tage particularly times increased demand quick data means thorough checks data quality undertaken european statistical system ess partnership eurostat national statistical institutes highlights need data quality quality declaration based european statistics code practice con tent code used reference frame applications well principle number code practice makes explicit reference accuracy reliability requiring source data intermediate results outputs regularly assessed validated sampling errors measured systematically documented well analysis potential impacts revi sion data production improve process principle number code practice commit ment quality also guide applications data quality management refers four indicators quality including quality policy made public procedures place plan monitor quality data production process product quality regularly monitored assessed outputs regularly thoroughly reviewed including external experts appropriate criteria come long standing experi ences production statistics also related use data systems based machine learning methods however questions machine learning still slightly different need adapted depending specificities goals use case one important differ ence official statistics aim describing population persons companies coun tries case statistics national econ omy according selected characteristics poten tially identifying correlations sometimes aiming causal explanations comparison machine learning mainly concerned predicting characteristics one unit one person one company one country slightly different implications accuracy prediction becomes even important com pared general statistics population groups developments area machine learning draw experiences disciplines statistics economics social sciences psychology sociology devel oped quality criteria purpose studies european statistical system european statistical system eurostat data quality artificial intelligence mitigating bias error protect fundamental rights dataset descriptions assessing data quality assessment errors data begins basic understanding data come cover proper assessment training data achieved providing descriptions datasets used experts field machine learning proposed use dataset descriptions referred datasheets nutrition labels providing information content quality way data quality issues important understanding certain algo rithm works addressed suggested describe datasets similar way hardware com ponents described check components comply industry standards datasets including information people could similarly described including detailed information dataset creation composition data collection process preprocessing distribution dataset currently standardised way describing data sets agreed upon field stand ardisation would allow flexibility able include variety possible data mats collections used applications important data generated one purpose needs assessed also fit another good way describing data pioneered european data archives portals data service example describes data documented based existing data archives also make use international standards schemes describing datasets example data documentation initiative ddi pri vate international standard description data surveys data sources social behavioural economic health pro vides guidance standardised way describ ing datasets meta data standards devel oped initiative document data way necessary sharing data reuse order able assess data quality information con text data collection well methodology data level descriptions needed includes information methodology used obtaining data information population observational units covered data method data collection interviews online tracking etc sampling procedures temporal geographical coverage information users applications better asses quality potential errors tool uses particu lar data set existing practices developed time disciplines encom passing statistics offer potential avenues data quality assurance relation conclusion asking right questions assessing technologies algorithms fundamental rights perspective complex task assessments data processing need beyond tra ditional data protection impact assessments machine learning systems algorithms make use data require broader flexible ways assessing addressing data quality relation several interconnected fundamental gebru holland january european parliament council european commission reached agreement revised directive open data public sector information proposal highlights wide range information many areas public authorities activity constitute vast diverse valuable pool resources recital addition allowing documents held public authorities allow improve quality information collected recital see european parliament european council data institutions agencies bodies available open data portal see website data service see website data documentation initiative human rights impact assessments see mantelero flexible ways testing machine learning systems potential discrimination see veale binns important increase awareness knowledge among businesses public private algorithms work part improved standing algorithms important query basis development algorithms data use algorithms negatively impact fundamental rights data used build measures wrong thing additionally harm done data used build tems represent population used outlined concepts measurement representation errors help understand ing whether certain data sources problem atic errors assessed data available documented appropriately agreed standards data quality assessments machine learning applications ever promising research drawing experiences social sciences following questions could serve minimum guidance understanding quality data answering gebru fra focus help identify potential fundamental rights problems use algorithm due data quality data come respon sible data collection maintenance dissemination information included data information included data appropriate purpose algorithm covered data resented data information missing within dataset units partially covered time frame geographical cov erage data collection used building application quality data give rise discrimina tory otherwise erroneous machine learning sys tems therefore understanding data qual ity help understand mitigate potential problems systems assessment algo rithms however stop apart data parts development algo rithms example way algorithm works black box predictive power algorithm equally important also considered new technologies need holistic assess ment potential fundamental rights evaluation training data outlined paper part assessment relation focus data quality impor tant many developers businesses pub lic authorities might make use easily available potentially free data developing essence purpose using machine learning algo rithms efficient save resources investing costly data acquisition might con tribute saving costs therefore data sources easily available often preferred moreover guidelines reporting machine learning models see luo zook matthew example among datasets commonly used machine learning enron contains approximately exchanged employees energy company went bankruptcy due accounting frauds although dataset may adequate automatic categorisation spam detection content enron demonstrates gender bias see mohammad yang data could used development algorithms often accessible due copyright restrictions hence attraction data sourced result data inter net used purposes origi nally envisaged analysing using data involved production consequences using data respect fundamental rights emerging increased understanding impact fun damental rights interdisciplinary research required topic combines elements many differ ent areas including law computer science statistics social science focus paper contributes discussion highlighting understood data quality survey research apply ing machine learning algorithms means assessment systems based algorithms include evaluation data quality draw established experience scientific rigour social sciences survey research levendovski see groves robert data quality artificial intelligence mitigating bias error protect fundamental rights access human rights age artificial intelligence alpaydin machine learning mit press barocas selbst big data disparate impact california law review vol bierer errors inference foster eds big data social science practical guide methods tools chapman crc bolukbasi chang zou saligrama kalai man computer programmer woman homemaker debiasing word embeddings paper given conference neural information processing systems nips december borgesius discrimination artificial intelligence algorithmic council europe buolamwini gebru gender shades intersectional accuracy disparities commercial gender classification proceedings machine learning research pmlr burt beyond explainability practical guide managing risk machine learning models future privacy forum white paper cabitza giant feet clay validity data feed machine learning medicine cabitza magni batini eds organizing digital world lecture notes information systems organisation springer cal zhu challenges data quality data quality assessment big data era data science journal vol caliskan bryson narayanan semantics derived automatically language corpora contain biases science carmines zeller reliability validity assessment thousand oaks vol civil liberties justice home affairs opinion committee civil liberties justice home affairs committee industry research energy comprehensive european industrial policy artificial intelligence robotics ini december council europe algorithms human rights study human rights dimensions automated data processing techniques possible regulatory implications council europe european ethical charter use artificial intelligence judicial systems environment crawford artificial intelligence white guy problem new york times june dastin amazon scraps secret recruiting tool showed bias women thomson reuters october ddi alliance main page accessed april eubanks automating inequality hightech tools profile police punish poor martin press european commission communication commission european parliament european council council european economic social committee committee regions artificial intelligence europe swd final arpil european commission expert group artificial intelligence ethics guidelines trustworthy version published april european council council conclusions june euco european group ethics science new technologies statement artificial intelligence robotics autonomous systems european parliament resolution february comprehensive european industrial policy artificial intelligence robotics ini strasbourg february fra focus parliament european council regulation european parliament council april protection natural persons regard processing personal data free movement data repealing directive general data protection regulation european parliament european council proposal directive european parliament council public sector information recast final cod april european parliament european council regulation european parliament council october protection natural persons regard processing personal data union institutions bodies offices agencies free movement data repealing regulation decision european statistical system quality declaration european statistical system european statistical system eurostat european statistics code practice national community statistical authorities eurostat table accessed january eurostat table households level internet access accessed april foster big data social science practical guide methods tools chapman fra bigdata discrimination datasupported decision making fra handbook european data protection law edition luxembourg publications office fra watchful eyes biometrics systems fundamental rights luxembourg publications office gebru datasheets datasets groves derivative inquiry dangers facing fields use data without producing data provosts blog georgetown lyberg total survey error past present future public opinion quarterly vol groves survey methodology second edition wiley holland dataset nutrition label framework drive higher data quality standards data nutrition project internet governance forum best practice forum internet things big data artificial intelligence output report december jackman measurement boxsteffensmeier eds oxford handbook political methodology oxford university press johnston robots learning racism sexism prejudices humans study finds independent april levendovski copyright law fix artificial intelligence implicit bias problem washington law review life bureau new york state insurance circular letter january luo guidelines developing reporting machine learning predictive models biomedical research multidisciplinary view journal medical internet research mantelero big data blueprint human rights social ethical impact assessment computer law security review vol meng statistical paradises paradoxes big data law large populations big data paradox presidential election annals applied statistics vol mohammad yang tracking sentiment mail genders differ emotional axes proceedings workshop computational approaches subjectivity sentiment analysis association computational prates avelar lamb assessing gender bias machine translation case study google translate corr data quality artificial intelligence mitigating bias error protect fundamental rights hilligoss krishnaumurthy bavitz kim berkman klein center internet society harvard university artificial intelligence human rights opportunities risks september richardson schultz crawford forthcoming dirty data bad predictions civil rights violations impact police data predictive policing systems justice new york university law review online rightscon toronto toronto declaration salganik bit bit social research digital age princeton princeton university press sessions valtorta effects data quality machine learning algorithms iciq future privacy forum privacy expert guide artificial intelligence machine learning data service document data accessed april united kingdom england wales high court pyrrho investments limited mwb property limited ewhc february united nations general assembly report special rapporteur promotion protection right freedom opinion expression august united states supreme court wisconsin state wisconsin eric loomis july veale binns fairer machine learning real world mitigating discrimination without collecting sensitive data big data society wachter mittelstadt right reasonable inferences data protection law age big data columbia business law review wagner liable control ensuring meaningful human agency automated decisionmaking systems policy internet vol wang poodle dog evaluating automatic image annotation using human descriptions different levels granularity proceedings international conference computational linguistics zhao wang yatskar ordonez chang men also like shopping reducing gender bias amplification using constraints paper given conference empirical methods natural language processing september zliobaite pechenizkiy gama overview concept drift applications japkowicz stefanowski eds big data analysis new algorithms new society springer zook matthew ten simple rules responsible big data research plos comput biol fra european union agency fundamental rights schwarzenbergplatz vienna austria tel fax european union agency fundamental rights print isbn pdf isbn print pdf information following fra publications offer information relevant topic paper bigdata discrimination decision making watchful eyes biometrics systems fundamental rights fundamental rights interoperability information systems borders security surveillance intelligence services fundamental rights safeguards remedies volume field perspectives legal update surveillance intelligence services fundamental rights safeguards remedies european union mapping member states legal frameworks impact fundamental rights proposed regulation european travel information authorisation system etias handbook european data protection law edition handbook european law relating access justice handbook european law edition
