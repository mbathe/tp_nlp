regulating europe four problems four solutions march opinion lilian edwards professor law innovation society newcastle university introduction regulating europe four problems four solutions introduction subject paper european commission proposal artificial intelligence act act published april draft council position also since published aim paper help create trustworthy balances proportionately social interest innovation better delivery public services adverse impacts fundamental rights societal values aim aligns proposed act welcome principle first comprehensive attempt world regulate fundamental rights perspective closely followed inception european union plans regulate act sets harmonised rules development placing market use systems european union however area impact wider since governs provider places systems market service act like gdpr explicitly positioned become global model given advantage quite likely become case ada lovelace institute particular interest independent research institute working data policy regulation consider build develop perhaps reject model becomes entrenched major structural change politically unlikely within act legislative process stage great deal effort already sunk commission council shortly parliament make fundamental changes structure goal implausible fundamental changes act addition true ante fundamental rights impact assessment discussed detail may regarded point unrealistic start council european union proposal regulation european parliament council laying harmonised rules artificial intelligence artificial intelligence act amending certain union legislative acts progress report available introduction regulating europe four problems four solutions regulating globally feel important eye horizon well ground another limitation acknowledge act trammelled requirements constitutional internal market law understandably tends make use already existing infrastructure paradigms especially provided new legislative framework nlf market surveillance authorities msas short act excellent starting point holistic approach regulation however reason rest globe unquestioningly follow ambitious yet flawed regime held place twin constraints new legislative framework see legislative basis law therefore paper seems important flag debates policymakers world beyond crucial regulatory turning point paper therefore primarily critique existing act hope relevance legislative process informed especially ada practical theoretical track record impact assessments data stewardship public participatory methods regulatory policy also survey flaws potential global model getting right several things paper first serious debate whether holistic instrument regulating systems opposed governance sectors labour health military applications might also include codes conduct ethical principles technical standards well law right way full scope second similar fundamental debates whether actually exists merely term advanced software data engineering exist useful scope thirdly several jurisdictions international organisations beginning also regulate contribute discourse global model regulation nonexhaustively include council europe new proposals human rights currently finalised cahai aiming introduction regulating europe four problems four solutions open ratification canadian directive automated imposes requirement questionnairebased algorithmic impact assessment certain cases exciting new chinese law regulates recommender algorithms contains many ways distinctly socialist furthermore large number bodies also developed governance tools including principles codes ethics notably models algorithmic impact issues models addressed next phase research convenes international experts discuss alternative global models governance labour emotion biometrics technical mandates standards conjunction alan turing institute paper however primarily seek point key flaws act whole possible suggest solutions drawn experience independent organisation mission make data work people society many reading paper already familiar act proposal reprised detail shortly issuing short act proposal far maia grenoble alpes council europe recommendation legal framework available government canada algorithmic impact assessment tool available creemers webster toner translation internet information service algorithmic recommendation management provisions effective march digichina available course debate whether needs regulation entirely governed market discard debate already concluded favour regulation kind leading model developed data society ngo sectoral example ifow working promote statutory algorithmic impact assessment public sector automated see hansard public authority algorithm bill hansard vol publicauthorityalgorithmbill critiquing act regulating europe four problems four solutions critiquing act starting point proposal takes unhelpfully oversimplified view way systems function problem derives origins act structure new legislative framework nlf adopted sought ensure safety products entering circulating internal market scheme worked relatively well tangible products division duties seems much questionable world service learns changes service upstream general purpose part services platform lifecycle issues unpacked series issues product service system delivered dynamically multiple hands lifecycle different contexts different impacts various individuals groups derives various features current market discussed detail impacted systems sometimes thought endusers data subjects consumers rights almost role act incompatible instrument whose function safeguard fundamental rights alleged nature act illusory arbitrary genuine assessment risk based reviewable criteria necessary act lacks general fundamental rights risk assessment systems scope act discuss broadly upstream services involve artificial intelligence service accordance dominant industry use term refers models provided customers commercial basis see cobbe singh artificial intelligence service legal responsibilities liabilities policy challenges computer law security review critiquing act regulating europe four problems four solutions product service system delivered dynamically multiple hands lifecycle different contexts different impacts various individuals groups act draws inspiration existing product safety legislation largely conceives providers equivalent manufacturers products like dishwashers toys kinds products indubitably initial manufacturer person knows best make product safe thus duties placed manufacturers beginning lifecycle dishwasher way downstream deployers use adapt may significant originally built act takes notice nearly enough therefore fails appropriately regulate many actors get involved various ways downstream supply chain manifests number different ways many products dynamic static products behaviour successful implementation change new data new uses new integrations turn changes risk profiles requires continuous evaluation many products produced single organisation involve complex web procurement outsourcing data variety sources etc changes question scope accountable different parts lifecycle notably smaller downstream providers likely save time resources maintenance obligations relying heavily services delivered large tech firms google microsoft amazon follows path cloud computing already trodden shall see creates substantial issues regulation lifecycle systems general purpose meaning system applied different contexts raise different impacts different individuals groups example developer facial recognition system could sell product authenticate entry prisons surveil customers targeted advertising holistically evaluating risk system abstract impossibility generalpurpose predominantly delivered tech giants dominant market share critiquing act regulating europe four problems four solutions system necessarily creature right function larger system platform facebook social media platform runs wide variety systems services given time including content moderation algorithms recommendation engines advertising algorithms search functions others may belong facebook may affiliated run third party translating complex web actors data models services legal regime places duties rights certain identifiable actors extremely hard act primary responsibility analogy manufacturers physical goods placed initial provider place systems provided others operation confusingly termed users suggest alongside others renaming deployers highly limited regulated role act comes play principally substantial modification made upstream yet many obligations act scheme ensuring human oversight correctly implemented systems effectively put place users deployers often buy system shelf regard making substantial modification necessary become regarded legally providers article act fails take work admittedly difficult determining distribution sole joint responsibility contextually throughout lifecycle protect fundamental rights end users practically completely compared unfavourably recent developments gdpr case courts attempting distribute responsibility data protection among various controllers relevant times art act substantial modification means change system following placing market putting service affects compliance system requirements set title iii chapter essential requirements results modification intended purpose system assessed see wirtschaftsakademie judgment court grand chamber june available subsequent cjeu case law critiquing act regulating europe four problems four solutions example chains providers give detailed example algorithm enables training model novel efficient way might made freely available online academic researcher might adopted delivering machine free trained model might incorporated fee commercial cloud provider offering saas saas might purchased government department deliver publicfacing service datasets training testing various stages might retrieved various global providers varying degrees access datasets constructed system might characterised high risk annex iii paragraph point put service public body yet system would product many hands ongoing contractual relationships would clear fulfil duties certify system compatible essential requirements chapter furthermore characterisation high risk example might cut last step yet might well access either model training data technical resources legal rights license assess alter system meanwhile initial provider could currently claim time provision intended use successful regime regulate increasingly made components supplied chains providers must grapple problem general purpose act failure appropriately regulate many actors get involved various ways lifecycle particularly struggle regulate systems appropriately general purpose means loosely system applied different contexts raise different impacts different individuals groups clearer definition much needed however critiquing act regulating europe four problems four solutions example general purpose example developer facial recognition system could sell product authenticate entry prisons surveil customers targeted advertising holistically evaluating risk system abstract impossibility seen recent uber disputes facial recognition systems used verify identity context deployment discriminate workers colour majority uber workforce want make systems operate fairly fashion must careful deployed embedded existing processes downstream built upstream example large language models one key case study general purpose large language models open systems services often incorporated downstream multiple systems multiple purposes contexts supervised imagined upstream providers include mundane analytics language translation well services large language models may allow automated generation text translation speech text automated bot assistants etc large language models extremely useful among things speech synthesis generation translation known dangerous sources errors discrimination adverse however systems may largely fall controls act uses thus impacts determined initial provider downstream deployers pleased note draft council position article clarified person deployer effect puts service uses system intended purpose comes duties certify confirmation essential requirements chapter iii seem need substantial see butler uber facing new driver claims racial discrimination guardian available see bender dangers stochastic parrots language models big facct proceedings acm conference fairness accountability transparency march available critiquing act regulating europe four problems four solutions modification clearly aimed catching downstream adapter deployer text seems done nothing meet problem almost certainly lacks mandatory access testing data ability compel changes upstream service unless built rights contract highly unlikely especially chains providers example time council proposal removes liability upstream provider article exculpates large tech suppliers like amazon google microsoft whose involvement certification safe discussed vital since effective control technical infrastructure training data models well resources power modify test users conventional sense rights almost role act scheme contrast european data protection regime also intended protect fundamental rights palpable deriving design act primarily product safety instruments role end users systems subjects rights objects impacted obscured human dignity neglected incompatible instrument whose function ostensibly safeguard fundamental rights current proposal fails many key points regulation enforcement cycle consult users start providers high risk certify meet various fundamental rights requirements even though users suffer potential impacts give users chance make points unelected technical bodies turn democratically made rules standards actually tell companies making build importantly allow users challenge complain systems line wrong infringe rights gdpr already shown areas like targeted advertising lack protection data transfers users activists complainants crucial enforcement regulators act far weaker enforcement structures gdpr voice cut act critiquing act regulating europe four problems four solutions users must given chance views considered product certified valid enter market well rights challenge legality system placed market civil society representatives users must empowered resourced enter process behalf want start debate whether regulators like existing data protection authorities already struggling cope policing gdpr really manage also represent voice user whether look building extra capacity central european body become champion users central source expertise users throughout really need order trust would draw experience consumer law use many countries figure could receive user complaints basis group spot patterns complaint possibly instruct aid regulators civil society taking representative actions also currently part framework act could also assist reducing impact state market surveillance authority msa acts single point permission circulate systems single market whatever reason unable fulfil regulatory role properly also discuss point users could become directly involved initial impact assessment system alleged nature act illusory arbitrary impacts groups society whole need considered well risks individuals rights risks considered throughout lifecycle market entry act lay criteria poses unacceptable risks society individuals merely designates set lists categories systems deemed unacceptable risk thus banned small number systems notably including biometric systems ombudsman model developed users public sector services make complaints spread successfully private sector consumer law especially digital spheres see chapter hertogh kirkham eds research handbook ombudsman research handbooks law politics edward elgar critiquing act regulating europe four problems four solutions allowed market certain safeguards put place essential requirements known systems even arbitrarily designated limited risk although obligations associated basically transparency labelling minimal extent duplicate existing requirements gdpr lists justified externally reviewable criteria thus regarded political compromises one point time leaving challenge legal validity systems principle rather point detail draft text added council november illustrates point well insurance systems digital critical infrastructure added little precision latter means little justification selected say emotion recognition systems many regard pernicious practical terms uncertain certain systems red lists argue new systems added future according criteria article regard unacceptably arbitrary denying justiciability lacking futureproofing suggest therefore initial criteria assessing high risk developed possibly mirroring criteria adding new systems annex iii existing categories article examining systems meet escape scope criteria essential precursor part impact assessment process discussed without legitimacy certain systems red list public trust rule law inherently compromised see heaven faces always tell truth feelings available systems typically take images faces data drawn bodily functions sweat body temperature interpret using algorithmic models indicating certain behavioural states attentiveness truth telling character features reckless identity gay critiquing act regulating europe four problems four solutions clearly problems may arise suggestion given internal market basis act seems possible argue red list lists may defined ante fulfil ostensible purpose act harmonise placing systems single market commission furthermore argued strength proposal weakness providers asked system high risk check fall one categories list argue creates certainty obviously risk assessment process would run risk gamed based charitably providers adding audit kind process would help exclude risk would add cost take time address extent repel point act also lacks comprehensive process assessment impacts risks system act ambitious enough assessing seeing risks caused act speaks continually risks fundamental rights prime reason mentions initial proposal yet contains comprehensive ante fundamental impact assessment systems unpacking statement pose two basic questions criteria use certify safety systems society certifying conformity fundamental rights type protected charter european convention human rights sufficient agree criteria certified system released market society ante assessment put impact postfactum assessment audit combination certifying safety systems fundamental rights beyond nearest act ante assessment compliance fundamental rights need certification essential requirements chapter iii however applies see present include many critiquing act regulating europe four problems four solutions systems consumers encounter daily basis search engines content moderation profiling targeted interventions sense act fact step backwards gdpr machinelearning systems processing personal data already required carry data protection impact assessment dpia even system subject chapter iii requirements constitute true fundamental human rights impact assessment hria three chapter iii articles refer fundamental rights cases briefly far kind hria already required recommended specific classes private public sector activities number states denmark scotland developed specifically algorithms council europe sponsor european convention human rights echr many key interests may impacted freedom thought due included another problem chapter iii lack systematic concern impacts groups particularly algorithmically constituted groups chapter iii occasionally refers risks groups article whole concentration individuals society much scholarship human rights domain argued concentrating individual rights conventional echr human rights structure leaves crucial gaps relation common minority interests allows structural discrimination persist grow individual rights tend empower already empowered exercise rights fail support marginalised impacted communities instrument often cited give rights individuals society least data protection law critique built points gaping gap around rights groups society may presumed systems also required undergo dpia means certain especially given likely assertions probably wrong proof may tiresome systems process anonymised data possibly controversial synthetic data see useful summary ifow policy briefing building systematic framework accountability algorithmic decision making available freedom thought conscience religion see art european convention human rights available could argued prohibition systems art subliminally manipulate users based freedom thought however explicit extended general principle throughout act even throughout iii essential criteria due process rule law concepts see art european convention human rights available critiquing act regulating europe four problems four solutions whole even importantly class actions may help groups get remedies based individual rights algorithmic systems construct new groups whose commonalities easily fitted existing rules discrimination protected would thus unfortunate see regulation mostly proceed traditionalist individualised path arguably ante impact assessment audit comprehensively take account fundamental rights also move beyond fundamental rights scrutinise important risks ethical impact assessment work already extensively explored possibilities generally context legal mandates include risks groups communities individual structural discrimination caused contexts deployment environmental impacts effectiveness transparency contestability views wishes end users affected communities many issues contained chapter iii conformity exercise issues already raised part dpia noted systems may require dpia participation affected users desirable mandated publication required subsequent certain period clearly feel dpia adequate justification gaps essential requirements scheme act participation key point ada lovelace institute already conducted considerable prior research concerns user participation impact assessment lack already highlighted fatal weakness act point research shows development teams tend particularly rarely include representation marginalised groups impacted biased unfair systems giving access individuals affected systems see mantelero personal data decisional purposes age analytics individual collective dimension data protection computer law security review volume issue available even outside data protection sphere scholars recognised severe weakness privacy law failure support privacy social good well individual remedy see regan legislating privacy unc press ada lovelace institute technical methods regulatory inspection algorithmic systems available see gdpr art critiquing act regulating europe four problems four solutions point flaws design stage development crucial conventionally done civil society intervention perhaps time regulation consider adding direct ways users intervene addition properly financing giving access civil society public scrutiny would assisted mandatory publication completed impact assessments publication would also assist representative group challenges available resource actors supply chain minimise burden subsequent impact assessments social media also offers potential route users get directly involved opposed via mediation civil society crippled resource constraints approaches could course vulnerable trolling abuse would carefully piloted policed representation would haphazard see social media voices often coming privilege drown others approaches might expand types participation could ever additional traditional routes communities well represented various social media platforms number obvious reasons alternately perhaps board maintain standing panel representative users type citizens jury could mandated comment impact assessment stage ada lovelace already set framework participatory modes data methods could applied governance design algorithms addition data underpins ada developed participatory process use aias particular context process european commission could explore similar process could adapted needs call imaginative thinking get affected deployment systems traditionally regarded inert consumers become truly involved ada lovelace institute participatory data stewardship available critiquing act regulating europe four problems four solutions third party certification ante scrutiny scrutiny chapter iii approach big problem around enforcement well ventilated civil society requirements chapter iii systems met real risk exploited adversely avoid true scrutiny reflection good argument made given history inadequate online relating ante certification external third party required hand may regarded disproportionately costly restrictive innovation might encourage regulatory arbitrage less stringent question much burden prior certification impose production distribution various products services medicines vaccines environmentally toxic products chemicals cars globally conflicted multiple different models operation extensive prior vetting drugs food drugs agency fda largely private data protection impact assessment dpia set gdpr certain types personal data processing number jurisdictions experimenting algorithmic impact assessments various types notably sectoral assessments also private sector many companies including tech giants implementing trialling various types differently scoped impact assessment ada lovelace institute current work within nhs explored practical use case whether risk impact assessment best delivered ante external certification internal ante backed external audit see notably failure safe harbor largely scheme guaranteeing privacy safeguards data sent companies see cjeu schrems dpc act avoids threat demanding certification condition entry internal market thus effectively applying rules extraterritorially might however lead abandoned market providers seeking entry single market via passporting less demanding member states see footnote also explored concept state federal level algorithmic accountability act proposed congress would require companies large userbases conduct impact assessments automated systems affect certain sensitive domains people lives notably respect digital labour performance management see footnote see watkins moss metcalf singh elish governing algorithmic systems impact assessments six observations aies proceedings conference ethics society available ada lovelace institute algorithmic impact assessment case study healthcare available critiquing act regulating europe four problems four solutions might audit regular schedule possibly triggered external event types assurance also extensively investigated inter alia information commissioner office centre data ethics debate ante assessment systems versus difficult complex one ante algorithmic impact assessment every system especially defined widely act source uncertainty investors developers customers costly especially deployers rather providers might regarded reasonable cost business see figure certification rather internal add costs seems impact assessment adding impact assessment might need done proposal may already seen particularly given already suggested prior assessment providers possibly external certification must made whether system falls category triggers application chapter iii see point nonetheless argue indeed drafters act economics promotion need balanced social value public trust hence uptake well protection harms grafting true ante impact assessment audit act structure may simply politically feasible would explain partial human rights scrutiny compromise chapter iii true entirely new structure needs considered regulation see ahamat chang thomas need effective assurance centre data ethics innovation available critiquing act regulating europe four problems four solutions one way reduce burdens ante especially external certification would reduce overall scope act currently wide embraces traditional software systems based rules logic well systems mostly think say aim act suggest regulate every piece software digital world would better approached proportionate sectoral legislation scope reduction included small extent draft council position organisations edri access already argued arbitrary reduction scope act machine learning might highly damaging fundamental rights hand veale highlighted current wide scope act may pose threat effective regulation sectors largely untouched mandatory safeguards within act scheme given potential effect maximum harmonisation measure finally suggest real consideration needs given best incentivise full engagement algorithmic impact assessment aia solution would tie eventual liability reformed product liability indeed national tort laws whether obligations act including carry aia judged fully due diligence met another would insist audit publication aia different levers compliance investigated work ada act art edri open letter civil society calls red lines european union artificial intelligence proposal available see example dutch syri benefits system scandal involve advanced system vervloesem dutch activists got invasive fraud detection system banned algorithmwatch available veale borgesius demystifying draft artificial intelligence act computer law review international see evaluation council directive july approximation laws regulations administrative provisions member states concerning liability defective products available report safety liability implications artificial intelligence internet things robotics available following consultation questionnaire launched closed january full proposal product liability adapted awaited critiquing act regulating europe four problems four solutions proposed solutions act restructured provide adequate oversight systems providers deployers current term act user renamed deployer providers deployers share responsibility assessing conformity fundamental rights safety standards chapter iii essential requirements applicable without need prove deployer made substantial modification draft council position inserted article partly adopted clarified person deployer effect puts service uses system intended purpose comes duties certify confirmation essential requirements chapter iii without need prove substantial modification time however council proposal removes liability upstream provider general purpose article propose responsibility allocated deployer alone since power control modify infrastructure alongside technical resources largely lies upstream provider responsibility joint provider recent gdpr jurisprudence joint data controllers much nuanced appraisal must made duties lie point time empowered either legally practical control power access data models make changes start mandatory access testing data must provided downstream deployer takes system category see example critiquing act regulating europe four problems four solutions participation impacted systems design safeguarding must enabled due regard given appropriate views stages oversight systems propose affected impacts systems individuals groups must input time systems certified compliant requirements chapter iii ante impact assessment additionally introduced canvassed particularly refers fundamental rights affected must consulted process views given due regard suggested innovative methods standing representative panels citizens juries might explored well conventional representation civil society similar rights participate must made available standardsetting activity envisaged chapter either directly via civil society representatives public deliberation mechanisms standing panels citizens juries could used provide input efficiently democratically call nonethless better resourcing technical resources civil society properly fulfil advocacy role note suggestion central technical task force established assist state market surveillance authorities msas also argue task force would even better established aid civil society resources technical expertise thinly spread impacted rights make complaints systems put operation market national regulator central ombudsman see right apply systems individual redress always available algorithmic harms whether national law product liability rules otherwise representational actions akin gdpr article also available currently act envisages reports flaws systems market fed back system deployers users insufficient unenforceable incentives european consumer organisation beuc regulating protect consumer position paper act available critiquing act regulating europe four problems four solutions deployers comply vitally complaints impacted systems well deployers must also fed back design system question particularly important systems seen bias unfairness may embedded upstream deployment particular contexts alerting particularly crucial existing state regulators dpas msas act may overwhelmed inaccessible impacted systems gdpr experience shown state level regulators may become bottlenecks action subject industry capture reasons enforcement mechanisms currently leads consider models complaint redress particular administrative consumer law form independent ombudsman role could include element collating complaints national regulators producing transparency reports assessing grouping repeated complaints passing priority action relevant regulator court well assisting civil society preparing representative actions justifiable reviewable criteria set categorising systems high risk rather arbitrary list suggest criteria commission adding new systems existing categories laid article adopted appropriate modifications become criteria categorisation systems high risk ideally certified third party criteria available courts regulators assess certification issues arise also think consideration given applying similar classification regime systems included particularly arbitrary though view category currently designed little value anyway terms fundamental rights protection see international association privacy professionals edps discusses gdpr enforcement review proposal available see section enterprise act discussion competition markets authority supercomplaints available complaints critiquing act regulating europe four problems four solutions providers deployers systems must participate assessing risks impacts potential harms systems individuals society including impacts human rights emerging mechanism ante fundamental rights impact assessment value act scheme potential overly burdensome duplicative regulation needs assessed context already existing requirement certify conformity chapter iii well likely possibility dpia required duplication existing obligations chapter iii alongside new obligations undertake fundamental rights impact assessment assess avoided see figure feel alone essential requirements chapter iii produce safe systems society needs external scrutiny accredited third parties necessary unless equally effective safeguarding mechanism provided addition audit obligations ante impact assessments introduced addition chapter iii high risk consider group societal values well fundamental rights environmental impacts demonstrate efficacy determined whether system fact needed consonant human dignity consider views individuals groups communities actually potentially affected particular designers required participatory processes examine systems might misused deployment contexts harmfully impact vulnerable made public encourage accuracy enable scrutiny provide templates providers especially smes research consider external scrutiny supplied regular audit system deployed instead supplement ante assessment critiquing act regulating europe four problems four solutions aspirational model constrained new legislative framework nlf possible following might combined layered set compliance processes regime categorisation risk ante impact assessment process essential requirements certification within current act structure process would look like figure flow chart potential new system incorporating impact assessment modules systemsassesment whether high risk unacceaptable risk minimal risk systems yesno iterations iterations marketalgorithmic impact assesment new user voice efficacy sustainability structural individual harms essential requirements certificates compliance requirements risk management systems data data governance echnical documentation transparency human oversight accuracy robustness cybersecurity audit audit critiquing act regulating europe four problems four solutions ideal may seen potentially repetitive process commonalities overlaps established across essential requirements processes compliance becomes systematic layered process classification design testing monitoring building safeguards opposed simple checklist arbitrary relatively small list systems layered process could save developers time money early red flags module could signal redevelop system putting market saving time liability later probably late act process embed model would mean tearing chapter iii late states considering regulation hand ante algorithmic impact assessments aias however formulated never alone silver bullet recommend hesitancy knowing number key problems need navigated first aia contested emerging term poorly defined discussed clearly pinned interaction audit objectives requirements limits impact assessment process need discussion ada lovelace institute nhs lab aia objectives included encouraging reflexivity product teams documenting key decisions making transparent enabling affected communities systems say construction impacts possible aims kind conceived something widely scoped overall especially defined act answer may development sectoral aias work already advancing fields like labour secondly must acknowledge limitations aias form accountability enable accountable relationship regulators members public empowering former two ask questions critiquing act regulating europe four problems four solutions pass judgement enforce sanctions latter crystal ball must deployed part wider set accountability practices particular enforcement processes act currently stands particularly weak market surveillance authorities msas far less hands enforcement state data protection authorities dpas gdpr dpas coming barrage criticism noted role user complaints provoking enforcement worked well gdpr entirely absent act considerable inequality power state bodies tech giants recognised danger regulatory capture possible capitulation state msas especially smaller states system furthermore overarching body envisaged bring harmonisation enforcement board far unlike equivalent clear purpose powers regulating europe four problems four solutions author lilian edwards leading academic field internet law taught information technology law law privacy law internet law undergraduate postgraduate level since involved law artificial intelligence since worked university strathclyde university edinburgh became chair internet law university southampton professor internet law university sheffield late returned scotland become professor university strathclyde retaining close links renamed script ahrc centre university edinburgh resigned role take new chair law innovation society newcastle university editor major author law policy internet one leading textbooks field internet law future privacy forum award best paper slave algorithm michael veale award best paper facct automated hiring barbara wellberry memorial prize work online privacy invented notion data trusts concept ten years later proposed legislation partner horizon digital economy hub nottingham lead alan turing institute law turing fellow fellow institute future work newcastle theme lead data nucore regulation data edwards consulted inter alia commission oecd wipo ada lovelace institute lead work future global regulation regulating europe four problems four solutions ada lovelace institute ada lovelace institute established nuffield foundation early collaboration alan turing institute royal society british academy royal statistical society wellcome trust luminate techuk nuffield council bioethics mission ada lovelace institute ensure data work people society believe world data work people society world opportunities benefits privileges generated data justly equitably distributed experienced recognise power asymmetries exist ethical legal debates around development technologies represent people conversations focus types technologies want build types societies want build research policy practice aim ensure transformative power data used harnessed ways maximise social wellbeing put technology service humanity funded nuffield foundation independent charitable trust mission advance social foundation funds research informs social policy primarily education welfare justice also provides opportunities young people develop skills confidence stem research addition ada lovelace institute foundation also founder nuffield council bioethics nuffield family justice observatory find website twitter adalovelaceinst email hello permission share document published creative commons licence preferred citation edwards regulating europe four problems four solutions ada lovelace institute available isbn
