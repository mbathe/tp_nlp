strasbourg january consultative committee convention protection individuals regard automatic processing personal data convention report artificial intelligence artificial intelligence data protection challenges possible remedies directorate general human rights rule law report alessandro mantelero associate professor private law polytechnic university turin department management production engineering document expression author personal viewpoint contents part state art introduction devel opment perspective adopted existing framework principles individuals self data processing minimisation bias part challenges possible remedies limitations use transparency risk assessment ethics committees participatory assessment liability vigilance sector issues references part state art troduction defining field research report easy matter since boundaries data protection rtificial intelligence hereinafter rather uncertain one hand dataintensive technologies including represent challenge application traditional principles data protection making blurrier less clear difficult appl coe hildebrandt barocas nissenbaum citron pasquale mantelero rubinstein boyd crawford tene polonetsky broad field encompassing variety approaches attempt emulat human cognitive skills villani data protection necess ity correlated leaving aside science fiction scenarios rapid evolution applications recent years roots progressive process datafication cukier lycett result personal data increasingly become source target applications personal assistants smart home devices background different approaches emerging development use regulation reality largely unregulated often grounded fundamental rights relying instead mainly data processing regarding data pro cessing global framework offers range ways safeguard fundamental rights particular right protection personal data europe active role field data protection may lead prominent part play region address ing regulatory challenge development adoption perspective focused fundamental rights may also mitigate envisioned clash market technology development inclusive approach perspective convention general council europe attitude fundamental rights solution existing tension may provided regulatory framework jurisprudence european court human rights terms policy foundational nature fundamental rights led parties convention favour development technology grounded rights merely driven market forces high companies moreover historical roots european protection lie urging policy makers consider potential adverse consequences data processing technolog ies approach necessarily mpact development consistent values expressed convention regulations council europe parties convention therefore actively encourage developers towards value design products services away vague overly optimistic views time governments first use manner centred safeguard ing promoti data protect ion fundamental rights thereby avoiding development systems technologies con strain individual collective rights freedoms reason important extend european regulatory leadership field data protection value regulation villani based following three precepts term artificial intelligence originally coined john mccarthy american computer scientist known father see mccarthy minsky rochester shannon proposal dartmouth summer research project arti ficial intelligence august accessed june definitio available value approach encompassing social ethical values risk assessment management participation council europe standpoint broader borders encompasses wide variety legal culture regulatory approaches despite council europe legal framework convention provide uniform background terms common values uncil rope may one best fora combine attention fundamental rights flexibility techn ology regulation adopting principle approach principles broader scope interpreted specifically meet challenges changing world whe reas detailed legislative provisions appear able react quickly enough socio technological change moreover principle regulation leave room peculiarities local context even relevant regard application impact contextual legal ethical social values ieee course data protection per cover aspects require broader approach encompassing human societal edps mantelero raso council europe however data protection strengthen complement response questions data protection focus individuals awareness social consequence data use link personality rights may expand data controller approach beyond data protection fundamental rights collective interests regarding complementary role data protection helps reveal way data use purposes processing represent key element better understand ing potential consequences variety rights freedoms finally raises many different sector issues concerning various fields application labour justice administration crime control contract relationships etc consequences use sustainability environment impact political impact etc must addressed separately given focus convention issues discussed report concerns common core applications data processing terms potential impact analysis may therefore provide contribution debate around issues concerning general specific application development years report scientific works published evolution unnecessary trace uneven trajectory scientific social interest technology society shown since earl iest studies mcculloch pitts turing recent contributions necessary describe increasing variety applications results achieved however historical perspective importan properly understand present near future two questions arise regard policy debate last years focuse forms reasonably expect next years answers questions crucial address ing regulation indeed need put development technology context avoid confusin commercial media narrative surrounding begin mere hype occurred past cloud computing big data iot clear tendency vendors magnify possibilities term become see modernised convention prote ction individuals regard processing personal data preamble art see consultative committee convention protection individuals regard automatic processing personal data guidelines protection dividuals regard processing personal data world big data hereinafter guidelines adopted january buzzword context strictly involve technology however basis truth attention concerning peculiar technological environment make possible today achieve results could dreamt past past decade increas ing availab ility bandwidth data transfer data storage computational resources new paradigm cloud computing progressive datafication large part life environment created completely new context led breakthrough enabling new forms data management extract information create new knowledge big data analytics machine represent recent products development process norwegian data protection authority concrete application technologies make possible envisage kind reasonably expected next years show still far general bostrom executive office president national science technology council committee technology norwegian data protection authority cummings although algorithms artificial intelligence come represent new mythologies time cnil report focuses existing near future applications leaving aside challenging questions concerning human terms machine liability risks humanity bostrom kurzweil convention original text modernised version refers automated processing automatic processing autonomous data processing implicitly highlighting autonomy key element human beings european commissio brief summary state art clearly shows unavoidably based data processing algorithms necessarily impact personal data use pose questions adequacy existing data protection regulations address ing issues new paradigms raise perspective adopted ajor threats concern disputed sets value adopted developers users latter including consumers decision use support choices emerging tendency towards technocratic market society push personal data moneti sation forms social control cheap fast decision solutions spiekermann large smart cities small precision medicine scale trend strengthens challenges progressively erodes individual self privacy focused models mindful cautio decision processes data bulimia complexity data processing extreme logic may undermine democratic use data supp lanting individuals collective bodies well freedom self kind data dictatorship imposed data scientist insensitive societal issues prevent adverse consequences prevailing benefits itu information commissioner office world economic forum necessary stress central ity human technology development means reaffirm ing predominance fundamental rights field sense right protection personal data become stepping stone wards design ing different data society development driven pure economic interest dehumanising algorithmic efficiency difference two technologies summarised follows patterns connections make difference traditional analytical methods need programmed find connections links learns data sees computer systems therefore respond continuously new data adjust analyses without human tervention thus helps remove technical barriers traditional methods run analysing big data norwegian data protection authority broad debate needed reinforce fundamental rights paradigm need critically assess drive towards extreme datafication aspects lives affirm importance individual collective rights governments citizens need recognise risks datafication potentially damaging implications solutions rouvroy industrial product development past awareness risk barrier innovation rather enabler innovation must developed responsib taking safeguard fundamental rights goal necessarily requires development assessment procedures adoption participatory models supervisory authorities human rights development technology might increase costs force developers business slow current impact products services individual rights society assessed advance time medium long approach reduce costs increase efficiency accurate systems increased trust world economic forum fewer complaints moreove business society mature enough view responsibility towards individuals society primary goal development alternatively ollow different path earlier technologies done early stages risk develop unregulated environment driven purely technological feasibility market political interests criteria guarantee respect human right development therefore based principles convention foundations flourishing digital society key element approach proportionality development inspired proportionality efficiency therefore prevail individuals rights freedom individuals right subordinate automated systems legislators aim curb applications safeguard individual societal interests responsibility mere accountability also requires developers decision makers act socially responsible manner also entails creation specific bodies support monitor actions risk management accountable means assessing potential adverse consequences application taking appropriate measure prevent mitigate consequences participation participatory forms risk assessment essential give voice citizens time citizens participation understood diminish decision accountability transparency despite current limitations affecting transparency certain degree transparency help ensure effective rticipation citizens accurately assess consequences applications existing framework principles exi sting regulatory framework applicable data processing mainly grounded convention although legal instruments concerning data protection may also relevant regard specific fields context guidelines big data adopted council europe council europe represent first attempt address use data solutions decision part broader wave documents resolutions adopted several european institu tions regulate impact algorithms society council europe experts internet intermediaries see also modernised convention protection individuals regard processing personal data art see recommendation committee ministers member states roles responsibilities internet intermediaries see practical guide use personal data poli sector guidelines protection individuals regard processing personal data world big data msi european data protection supervisor ethics advisory group european parliament european union agency fundamental rights fra scope guidelines adopted big data contribute protection data subjects regarding processing personal data big data context spelling applicable data protection prin ciples corresponding practices view limiting risks data subjects rights risks mainly concern potential bias data analysis underestimation legal social ethical implications use big data cision processes marginalisation effective informed involvement individuals processes although focused big data analytics guidelines cover variety questions involving dataintensive complicated plication decision making reason considerations potential positive role risk assessment encompassing ethical societal concerns testing data minimi sation expert committees precautionary reedom human decision equally applied remedies discussed report see part concrete applications call analysis new issues role transparency various values underpin applications suggest new remedies broader data protection impact assessment potential limitations use finally approach adopted existing supervisory bodies data protection supervisory autho rities may need reconsidered light new challenges posed potential consequences society sense manner big represents challenge application traditional data processing may warrant search new applicative solutions safeguard personal information fundamental rights individuals self data processing last years privacy scholars repeatedly pointed weakness data subjects consent terms self long technical data processing notices social technical lock obscure interface design lack awareness part data subject reasons weakness moreover profiling hidden nudging practices challenge idea freedom choice based contract ual agreement notion data subjects control information finally frequent complexity obscurity algorithms hamper chance obtain ing real informed consent legal scholars addressed issues highlighting role transparency multis edwards vale selbst powles wachter mittelstadt floridi burrell rossi risk assessment guidelines mantelero flexible forms see also commission european group ethics science new technologies potential suse autonomous technologies poses major challenge risk awareness precautionary approach crucial see also sense norwegian data protection authority report elaborates legal opinions technologies described report big data data protection principles pressure report provide eater technical detail describing artificial intelligence also taking closer look four relevant challenges associated data protection principles embodied gdpr fairness discrimination purpose limitation data min imisation transparency right information see guidelines section given nature big data uses application traditional principles data processing principle data minimisation purpose lim itation fairness transparency free specific informed consent may challenging technological scenario example analytics make hard identify specific purpose data processing moment data collection machine learning algorithms hand whose purposes necessarily specified may predict explain purpo ses achieved cases therefore transparency purpose manner data processing may remain limited consent broad consent sheehan dynamic consent kaye although none solutions provide definitive answer problem individual consent certain contexts solutions alone combined may reinforce moreover notion self circumscribed given case data processing used broad sense refer freedom choice use right nsmart version devices services office privacy commissioner canada smart devices appliances become normalized increasing erosion choice individuals would preferred non versions zero option goes eyond individual dimension also relates way community decide role play shaping social dynamics collective behaviour decisions affecting entire groups individuals asilomar principles human ntrol humans choose whether delegate decisions systems accomplish human chosen objectives minimi sation big data guidelines data minimi poses challenges technologies differ big data machine learning algorithms need large amount data produce useful results means certain degree minimi sation possible moreover mentioned previous section zero option adoption solution help reduc quantity data collected limiting amount informatio required survey ing sample population rather large proportion addition council europe guidelines big data extended guidelines contain principle equally applied data collected processed way minimise presence redundant marginal data case primarily concerns training data norwegian data protection authority pointed would natural start restricted amount training data monitor model accuracy fed new data norwe gian data protection authority moreover studies could also examine develop ment algorithms gradually delete data using automatic forgetting mechanisms gama although may affect post explanation based decisions doshi although machine learning necessarily require large datasets training phase important adopt design paradigm critically assesses nature amount data used reducing redundant marginal data gradually increasing size training dataset minimisation may also achieved training algorithms using synthetic department digital culture originat ing sub personal data subsequently anonymised barse see also protocol amending convention protection individuals regard automatic processing personal data ets explanatory report para see also modernised convention protection individuals regard processing personal data art see guidelines section para see also guidelines section para technically feasible controllers applicable processors test adequacy solutions adopted limited amount data means simulations use larger scale synthetic data generated data model built real data representative original real data see definition synthetic data oecd glossary statistical terms approach confidentiality instead disseminating real data synthetic data generated one population models released bias although accurate systems reduce eliminate human bias decision also possible applications affected potential bias deterministic machine learning uses data input extract information analytics create train models bias may concern data scientists methods measurement bias bias affecting survey methodolog ies bias cleaning pre tages veale binns object investigation social bias due historical underrepresentation categories world economic forum data sources selection bias person responsible analysis confirmation bias department digital culture information commissioner office institute biased datasets may adversely affect algorithms higher impact case bias may affect design development training algorithm issue already partially addressed council europe guidelines big data hich suggest approach avoid potential hidden data biases risk discrimination negative impact rights fundamental freedoms data subjects collection analysis stages bias may due biased datasets institute may also result intentional unintentional decisions developers sense achine predictions performance constrained human decisions values design develop maintain systems shape systems within understanding world institute development left hand designers alone technical background may mean less aware societal consequences decisions committees experts range fields social scien law ethics etc may represent best setting discuss address questions impact individuals society see section compensating limited viewpoint developers multidisciplinary committees might also able detect potential bias depends identity developers gender bias ideological bias minorities institute another way reduce chances application bias participatory forms risk assessment mantelero focused merely data security data quality see section also active engagement groups potentially affected applications contribute detection removal existing bias institute approach focused responsible design guidelines aims prevent biased condition affect datasets algorithms context necessarily characterised certain degree obscurity complexity prior assessment responsible design effective analys carried discriminatory result discovered selbst even result traced data quality problem problems ten quite complicated rectify might easy determine something data difficult figure something even sources bias identified magnitude source effec still likely unknown brauneis see amazon ditched recruiting tool favored men technical jobs guardian october company realized new system rating candidates software developer jobs technical posts gender way amazon computer models trained vet applicants observing patterns résumés submitted company period came men reflection male dominance across tech industry see guidelines section para see guidelines section controllers applicable processors carefully consider design data processing order minimise presence redundant marginal data avoid potential hidden biases risk discrimination negative impact rights fundamental freedoms data subjects collection analysis stages attention potential bias ear liest design stage department digital culture also entails deeper reflection training datasets training phase general curb negative consequences historical bias data point suggested tracking provenance development use training datasets throughout life cycle institute accurate test ing training phase deployment algorithms large scale could reveal hidden bias guidelines big data highlight role simulations guidelines big data institute moreover hidden bias may also involve machine bias different human bias cummings machines humans different capabilities equally importantly make different mistakes based fundamentally divergent decision architectures caruana szegedy context assessment potential bias also become controversial given multiple variables involved classification people groups necessarily correspond traditional discriminatory categories donovan questions regarding machine bias deflected argument human decisions fallible way reduce human error four reasons comparison work first solutions designed applied serial product liability poor design bias inevitably affects numerous people similar circumstances whereas human error affects individual case second although fields error rates close lower tha human brain image labelling instance artificial intelligence index complicated decision making tasks higher error rat cummings third socio dimension human error sets apart machine error terms social acceptability exoneration necessarily influences propensity adopt potentially fallible solutions finally comparing adverse tcomes human decisions federal ministry transport digital infrastructure licensing automated systems justifiable unless promises produce least diminution harm compared human driving words positive balance isks essentially based mere numerical comparison resulting harms number victims human cars number full autonomous cars reductive assessing consequences human decisions need consider distribution effects individuals adversely affected belonging different categories varying conditions harm occurred severity consequences moreover sort quantitative approach appear odds precautionary approach guidelines require adoption risk prevention policies rather mere reduction harm see guidelines section technically feasible controllers plicable processors test adequacy solutions adopted limited amount data means simulations use larger scale would make possible assess potential bias use different param eters analysing data provide evidence minimise use information mitigate potential negative outcomes identified risk process described section see aletras tsarapatsanis preoţiuc mpos predicting judicial decisions european court human rights natural language processing perspective peerj computer science part challenges possible remedies limitations use data protection regulations well convention provide safeguards equally applied algorithms including algorithms used automated decision systems however red line human automated decision drawn basis mere existence non decision process indeed supposedly reliable nature mathematics solutions induce taking decisions basis algorithms place trust picture individuals society analytics suggest moreover attitude may reinforced threat potential sanctions taking decision ignores results produced analytics presence human decision per sufficient algorithms benefit allure mathematical objectivity combined complexity data management subordinate position taking decision organis ation make harder human decision take decision one suggested background distinction made cases human decision maker effective freedom guidelines big data already highlighted importance protecting effective freedom human decision assessing case potential imbalance important role may played expert committee see section may also facilitate stakeholders participation assessment see section decisions delegated systems human decision effective oversight decis ions broader question arise whether adopt systems rather human methods lead communities groups potentially affected towards participatory discussion adoption solution analysing potent ial risks see risk asse ssment adopted nitoring application see vigilance transparency context several different meanings may consist disclosure applications used description logic access structure algorithms applicable datasets used train algorithms moreover transparency ante post binns requirement data decision although transparency important public scrutiny automated decision models reisman generic statement use little tackle ris unfair illegitimate data use hand access ing algorithms structure may make possible detect potential bias however rights competition issues sometimes restrict access see also brauneis robert ellen goodman algorithmic ansparency smart city yale tech time deference algorithms may weaken decision capacity government officials along sense engagement agency see guidelines section basis reasonable arguments human decision allowed freedom rely result recommendations provided using big data see itu margaret chan former director observed medical decisions complex based many factors including care compassion patients doubt machine imitate act compassion machines rationalize streamline replace doctors nurses interactions patients see also article modernised convention explanatory report point principle respected stages processing including initial stage ciding whether carry processing see article modernised convention case even barriers exist complexity adopted models may represent major challenge human cognition lipton addition cases transparency may prevent public bodies carrying duties predictive policing systems conflict data controller security obligations concerning personal data data subjects requesting access veale forthcoming reasons solution focused disclosing logic algorithms may better option even disclosure interpreted less narrow giving information type input data expected explaining variables weight shining light analytics architecture various forms transparen regarding logic algorithms complex analysis processes deep challenge notion transparency terms expla ining logic algorithms goodman flaxman doshi decisions taken using non systems make hard provide detailed information logic behind data processing furthermore dynamic nature many algorithms contrast static nature transparency algorithms continuously update changed whereas transparency disclosure concerns algorithm used given moment finally access algorithms enough tect potential bias resources terms time skills also required perform kind analys ananny crawford ideal transparency places tremendous burden individuals seek information system interpre information determine significance result deterrent effect solutions auditing veale binns intervention human decision impaired research studies currently trying develop bias detection methods based algorithms though hard see introduc ing algorithmic supervisor algorithms reduce complexity data governance none points weakens argument increased transparency generally burrell especially public role safeguarding data subject self edwards vale selbst powles wachter mittelstadt floridi rossi transparency difficult achieve regard architecture logic algorithms may still helpful clarif ying reasons behind decision use complex tool burt transparency part solution challenges several limitations fully addressed ananny crawford forget algorithms case algorithms sometimes harder human beings read understand mathematical logical notation natural language hence isclosure computer code may less helpful alternative easier means interpretation see brauneis robert ellen goodman algorithmic transparency smart city yale tech see also modernised conve ntion protection individuals regard processing personal data article information may provided learning use models giving data subjects chance test analytics different input values even case however danger misleading identification relevant inputs diakopoulos see article loi janvier amended loi juin cases may impossible explain reason decision suggested algorithm burrell moreover solutions right explanation focused decisions concerning specific persons collective issues use group level remain una ddressed remedies possible many cases auditing process requires significant effort human intervention compromised complexity data processing see lomas natasha ibm launches cloud tool detect bias explain automated decisions techcrunch blog september accessed september launches see article loi janvier amended loi juin public sector known use algorithms great attention principle equal treatment commitment transparency access rights administrative processes limitations may affect algorithmic transparency public sector see brauneis robert ellen goodman algorithmic transparency smart city yale tech arned three principal impediments making government use big data prediction transparent absence appropriate record generation practices around algorithmic processes insufficient government insistence appropriate disclosure practices assertion trade secrecy confidential privileges government contractors article investigate one component application datasets used training analys biased datasets automatically produce biased results finally applications focus sed data ignoring contextual information often vital understand apply solution pro posed application decontextuali sation also danger choice algorithmic model models originally used one purpose different context different purpose donovan cite case predpol algorithm originally designed predict earthquakes later used identify crime hotspots assign police using models trained historical data different population institute risk assessment given limits transparency individual self see section data protection regulations increasingly stressing role risk assessment risk assessment data controller safe environment greatly enhance individuals trust willingness use applications users preferences based effective risk analysis measures mitigate risks norwegian data protection authority rather merely relying marketing campaign bran reputation use algorithms modern data processing techniques council europe experts internet intermediaries msi well trend towards technologi edps encouraged take wider view possible adverse outcomes data processing asilomar principles risks risks posed systems especially catastrophic existential risks must subject planning mitigation efforts commensurate expected impact groups experts scholars gone beyond traditional sphere data protection taylor floridi van der sloot consider impact data use fundamental rights collective social ethical values mantelero access assessment compliance ethical social values complicated traditional data protection assessment whereas example values data integrity underlying data security data management technologically generalised across various social contexts social ethical values situation different necessarily context differ one community another world economic forum making harder identify benchmark kind risk assessment point clearly addressed first section guidelines big data council europe urges data controllers data processors adequately take account likely impact intended big data processing broader ethical social implications order safeguard hum rights fundamental freedoms light convention new element concerns range interests safeguarded rights protected assessment addresses rights beyond traditional data protection like right barocas selbsr well respect social ethical values european economic social committee institute order achieve see also modernised convention protection individuals regard processing personal data art see guidelines section para see also modernised convention protection individuals regard proce ssing personal data article see also regarding self cars federal ministry transport digital infrastructure federal government action plan report ethics commission automated connected driv ing ethical rules self computers case dilemmatic situations injury persons ruled commission states must distinction based personal features age gender ethical systems wider implications addressed must institutional changes hold power accountable access guidelines recognise relative nature social ethical values insist data uses must conflict ethical values commonly accepted relevant community communities prejudice societal interests values norms guidelines acknowledge difficulties identifying values considered broader assessment propos practical steps wards end following view privacy scholars examined issue wright suggest common guiding ethical values found international charters human rights fundamental freedom european convention human rights given context nature social ethical assessment fact international charters may provide high guidance guidelines combine general suggestion tailored option represented hoc ethics committees assessment detects high impact use big data ethical values committees cases already exist practice identify specific ethical valu safeguarded regard given use data providing detailed context guidance risk architecture values defined guidelines based three layers first general level represented common guiding ethical values international charters human rights fundamental freedoms second layer takes account context nature social ethical assessment focuses values social interests given communities finally third layer consists specific set ethical values identified ethics committees relation given use data complexity assessment entails continuous evolution potential risks measures tackle respect data protection supervisory authorities play significant role supporting data controllers informing data security measures providing detailed guidelines risk guidelines therefore leave assessment exclusively hands data controllers line approach adopted regulation use big data may sig nificantly impact rights fundamental freedoms data subjects controllers consult supervisory authorities seek advice mitigate risks outlined impact assessment guidelines big data reach number conclusions extended focussing automation decision core challenging applications finally increased burden consequent broader assessment justified nature rights freedoms potentially affected application also represents opportunity achieve competitive advantage fostering public products services give companies chance better respond increasing consumers concern data use similarly increasing government agencies accountability systems increase citizens trust public administrati prevent unfair decisions perspective significant role also guidelin section para see guidelines section para assessment likely impact intended data processing described section highlights high impact use big data ethical values controllers could establish hoc ethics committee rely existing ones identify specific ethical values safeguarded use data two model based general guidelines tailored guidance provided hoc committee already adop ted clinical trials big data context specific application technology poses context questions must necessarily addressed depending conflicting interes case result context asses sment conflicting interests see guidelines section para see guidelines section para see also modernised convention protection individuals regard processing personal data explanatory report development use innovative technologies also respect rights help build trust innovation new technologies enable development played certifications ieee additionally need develop certification scheme ensures technologies independently assessed safe ethically sound see brundage codes conduct standards different tool contribute increas accountability provide guidance data system encompass ing procedures race decision process prevent form manipulation generated results ethics committees respect applications ethics committee attracting increasing attention circles though unanimous consensus nature function theoretical studies policy document corporate initiatives offer differ ing solutions regard first difference approach emerges concerns level committees work polonetsky tene jerome calo white house ieee proposals describe national committees villani provide general guidelines issues completely new idea resembles existing national bioethical committees however case data applications use personal information interplay national committees ational data protection authorities needs examined carefully mantelero interplay national bodies antitrust national security authorities many countries already independent watchdogs supervising specific sector applications operate may operate regulatory perspective therefore important collaborate authorities reconsider role strengthen mutual cooperation european data rotection supervisor conseil national numérique different approach would introduce ethics committees company level supporting data controllers specific data applications focusing data controllers operati ons might assume broader role act expert committees ethical issues lso broad range societal issues relating including contextual application fundamental rights mantelero several already set internal external committees advise critical projects second solution based corporate ethics committees creates fewer difficulties terms overlap exi sting regulator supervising bodies may require learly defined relationship committees supervisory authorities national legislators might empower supervisory authorities scrutini committees shortcomings abilities decisions affect data processing conseil national numérique types advisory boards creating ethics committees aises questions independency internal external status best practice avoid conflict interest see also article modernised convention see also consultation new centre data ethics innovation see sense increasing propensity big data high companies set ethic committees advisory boards see natasha lomas deepmind ethics research unit questions techcrunch october accessed axon ethics board accessed may dna web team google drafting ethical guidelines guide use tech employees protest defence project dna india april accessed may see also united nations guiding principles business human rights impleme nting united nations protect respect remedy framework united nations human rights council doc make committees also depend complexity tools applications societal issues significant legal ethical sociological expertise well domain specific knowledge essential committees may play even important role areas transparency stakeholders engagement difficult achieve predictive justice crime detection predictive policing ethics committees provide valuable support developers design ing right socially algorithms moreover dialogue developers favour creation transparent data processing procedures facilitate clearer definition rationale see also section participatory assessment experts ethics committees play important role detecti potential adverse consequences applications help data controllers address critical issue however cases analysis impossible without engaging target communities groups social impact assessment societal consequences may arouse interest public participation individual group empowerment assessment process non discrimination equal participation assessment participatory also helpful gaining better understanding various competing interests ethical social lower level technical complexity terms consequences applications committee could repl aced expert ethics society similar dpo role data protection also mandatory requirement regarding appointment quality members ethics committee appointments guided type data use potential impact fundamental rights taking ethical societal issues key criteria see sense ieee recommends create roles senior level marketers ethicists lawyers pragmatically plement ethically aligned design precedent new type leader found idea chief values officer created kay firth cser cambridge kay firth lucid ethics advisory see also department digital culture media sport data ethics framework section use data proportionate user need accessed july role participatory approaches stakeholders engagement specifically recognised context fundamental rights danish institute human rights paul hert human rights perspecti privacy data protection impact assessments david wright paul hert eds privacy impact assessment springer dordrecht case law required clarify scope duty study impact certain technologies nitiatives also outside context environmental health regardless terms used one safely adduce current human rights framework requires states organise solid decision procedures involve persons affected tech nologies participation various stakeholders engagement civil society business community defining sectoral guidelines values effective mere transparency despite emphasis latter recent data processing debate danish institute human rights engagement rights stakeholders essential hria stakeholder engagement therefore situated core cross component see also lker participation end right also means empowering communities influence policies projects affect well building capacity decision take account righ individuals communities formulating implementing projects policies limited form engagement based awareness suggested council europe committee experts internet intermediaries council europe tee experts internet intermediaries msi public awareness discourse crucially important available means used inform engage general public users empowered critically understand deal logic operation algorithms include limited information media literacy campaigns institutions using algorithmic processes encouraged provide easily accessible explanations respect proced ures followed algorithms decisions made industries develop analytical systems used algorithmic decision data collection processes particular responsibility create awareness stakeholder engagement also represents development goal assessment united nations office high commissioner human rights since reduces risk representing certain groups may also flag critical issu underestimated ignored data controller wright mordini however stakeholder engagement seen way decision makers data controllers case evade responsibilities leaders entire process palm hansson decision must remain committed achieving best results terms minimising negative impact data processing individuals society finally articipatory assessment effects algorithmic decision cnil may also drive data controllers adopt solutions developing applications actively engaging groups potentially affected liability vigilance liability around applications remains open issue various reasons product liability whose principles focused risk management uncertainty broadly extended number applicable regulatory models strict liability liability based fault etc strategies state intervention mandatory insurance one valuable solution appears extension product liability logic algorithms channelling liability producer would seems workable alternative data protection officer algorithms cnil identifying within company authority team responsible algorithm operation moment processes data humans pervasive ness applications different parts involved role user make difficult disentangle different aspects liability moreover iability serves sort closing rule system valuable various ante remedies transparency work asilomar principles failure transparency system causes harm possible ascertain however since tort liability normally regulated national legislators report needs discuss different available nevertheless worth pointing risk management transparency liability combined applications development phase also following stage algorithms use access acm ould lead supervisory authorities data controllers adopt forms algorithm vigilance analogous pharmacovigilance react quickly event unexpected dangerous outcomes microsoft chatbot commission nationale informatique des libertés linc sector issues significant impact many sectors society economy predictive policing justice precision medicine marketing political propaganda sector applications characterised different challenges properly discussed report provides understanding includin respect possible biases may induced design use algorithms liability also assumes different forms different fields application liability decision cars etc since liability quite conte specific see vincent james twitter taught microsoft friendly chatbot racist asshole less day verge march see also public voice universal guidelines artificial intelligence universal termination obligation institution established system affirmative obligation terminate system human control system longer possible general overview main issues concerning interplay data protection last section theref ore briefly shed light two main areas public sector workplace applications aise number specific questions used public sector reisman largely due imbalance power citizen administration essential services provided moreover adoption complex obscure solutions governments agencies make difficult comply accountability obligations concerning data proce ssing reisman state affairs would seem warrant adoption tighter safeguards beyond remit hoc committees auditing afeguards also contemplate evaluation process critically assess need proposed solutions suitability delivery services public agencies private companies acting behalf process requires minimum applications available public auditing testing review subject accountability standards institute achieve goal public procurement procedures may impose specific duties transparency prior assessment providers moreover procurement procedures may also address issues concerning trade secrets protection introducing specific contractual exceptions increase transparency make auditing possible regarding effects future work leaving aside impact labour market solutions may ffect relationships within first place increase employer control employees situation often characterised imbalance power moreover use hidden unregulated forms data processing might transform workplace vivo social experiment raising additional important questions role transparency ethics committees voluntary participation dat processing finally devices given employees employers may dual use instance wearable well devices worn workplace gather biological data intended safeguard employe health employees may also use outside work track sport fitness unless repercussions data protection individual freedom properly examined twin uses may blur boundaries work private life institute raising issues pervasive control right disconnect see also eur court bărbulescu romania judgment sept ember application eur court libert france judgment february application references access toronto declaration protecting rights equality non discrimination machine learning systems declaration acm acm code ethics professional conduct institute report social economic implications artificial intelligence technologies near institute report accessed october institute litigating algorithms challenging government use algorithmic decision systems ananny crawford seeing without knowing limitations transparency ideal application algorithmic accountability new media society artificial intel ligence index annual report accessed december asilomar principles axon ethics board barocas nissenbaum big data end run around anonymity consent lane stodden bender nissenbaum eds privacy big data public good frameworks engagement cambridge university press barocas selbst big data disparate impact california law review barse kvarnstrom jonsson synthesizing test data fraud detection systems annual computer security applications conference proceedings binns reducing human percentage perceptions justice algorithmic decisions bostrom superintelligence paths dangers strategies oxford oxford university press boyd crawford critical questions big data provocations cultural technological scholarly phenomenon information communication society brauneis goodman algorithmic transparency smart city yale tech bray international differences ethical standards interpretation legal frameworks satori deliverable egalaspects brundage malicious use artificial intelligence forecasting prevention mitigation february burrell machine thinks understanding opacity machine learning algorithms big data society burt leong shirrell beyond explainability practical guide managing risk machine learning models future privacy forum calo ryan consumer subject review boards thought experiment stan rev online review accessed february caruana lou gehrke koch sturm elhadad intelligible models healthcare predicting pneumonia risk hospital readmission proceedings annual sigkdd international conference knowledge discovery data mining citron pasquale scored society due process automated predictions rev cnil linc plateforme une ville les données personnelles coeur fabrique smart city cnil humans keep upper hand ethical matters raised algorithms artificial intelligence port public debate led french data protection authority cnil part ethical discussion assignment set digital republic bill december cnil humans keep upper hand ethical matters raised algorithms artificial intelligence report public debate led french data protection authority cnil part ethical discussion assignment set dig ital republic bill commission european group ethics science new echnologies statement artificial intelligence robotics autonomous systems retrieved conseil national numérique ambition numérique pour une politique francaise europeéenne transition numérique rapport ambition council europe guidelines protection individuals regard processing personal data world big data council europe experts internet intermediaries msi study human rights dimensions tomated data processing techniques particular algorithms possible regulatory implications rights cummings roff heather cukier kenneth parakilas jacob bryce hannah chatham house report artificial intelligence international affairs disruption anticipated london chatham house royal institute international affairs intelligence diakopoulos algorithmic accountability reporting investigation black boxes tow center digital journalism dna web team google drafting ethical guidelines guide use tech employees protest defence project dna india april google project donovan matthews caplan hanson algorithmic accountability primer doshi accountability law role explanation edwards vale slave algorithm explanation probably remedy oking duke law technology review european commission european group ethics science new technologies statement artificial intelligence robotics autonomous systems european commission european artificial intelligence landscape european data protection supervisor ethics advisory group towards digital ethics eag report european data protection supervisor opinion edps opinion coherent enforcement fundamental rights age big data european economic social committee ethics big data balancing economic benefits ethical questions big data policy context european parliament european parliament resolution march fundamental rights implications big data privacy data protection non ation security law ini european union agency fundamental rights fra bigdata discrimination data decision making executive office president national science technology council committee technology preparing future artificial intelligence washington federal ministry transport digital infrastructure ethics commission automated connected driving accessed july gama survey concept drift adaptation acm computing surveys goodman flaxman regulations algorithmic decision right explanation stat hildebrandt smart technologies end law novel entanglements law technology edward elgar publishing ieee global initiative ethical considera tions artificial intelligence autonomous systems ethically aligned design vision prioritizing wellbeing artificial intelligence autonomous systems version ieee information commissioner office big data artificial intelligence machine learning data protection itu good global summit rep ort kaye dynamic consent patient interface twenty century research networks european journal human genetics kurzweil singularity near humans transcend biology london duckworth linnet floridi van der sloot eds group privacy new challenges data technologies springer international publishing lipton mythos model interpretability machine learning concept interpretability important slippery acmqueue lomas deepmind ethics research unit questions techcrunch october accessed may lycett dataf ication making sense big data complex world european journal information systems mantelero big data blueprint human rights social ethical impact assessment assessment computer law security review mantelero future consumer data protection rethinking notice consent paradigm new era predictive analytics computer law security review mantelero regulating big data guidelines council europe context european data protection framework computer law sec rev cukier big data revolution transform live work think london john murray mcculloch pitts logical calculus ideas immanent nervous activity bulletin mathematical biophysics office privacy commissioner canada internet things introduction privacy issues focus retail home environments heading weapons math destruction london penguin books palm hansson case ethical technology assessment eta technological forecasting social change polonetsky tene jerome beyond common rule ethical structures data research non settings colorado technology law journal raso artificial intelligence human rights opportunities risks reisman schultz crawford whittaker algorithmic impact assessments practical framework public agency accountability rossi artificial intelligence potential benefits ethical considerations european parliament policy department citizens rights constitutional affairs briefing rouvroy data men fundamental rights liberties world big data rubinstein big data end privacy new beginning international data privacy law selbst disparate impact big data policing georgia law review selbst andrew powles julia meaningful information right explanation international data privacy law sheehan broad consent informed consent public health ethics spiekermann ethical innovation value system design approach boca raton crc press szegedy zaremba sutske ver bruna erhan goodfellow fergus intriguing properties neural networks tene polonetsky privacy age big data ime big decisions stan rev online danish institute human rights human rights impact assessment guidance toolbox danish institute human rights ieee global initiative ethical considerations artificial intelligence autonomous systems ethically aligned design vision prioritizing wellbeing artificial intelligence autonomous systems version ieee norwegian data protection authority artificial intelligence privacy report turing computing machinery intelligence mind department digital culture media sport data ethics framework united nations office high commissioner human rights frequently asked questions human rights approach development cooperation new york geneva united nations united nations guiding principles business human rights implementi united nations protect respect remedy framework united nations human rights council doc veale binns fairer machine learning real world mitigating discrimination without collecting sensitive data big data society veale binns edwards algorithms remember model inversion attacks data protection law philosophical transactions royal society forthcoming villani meaningful artificial intelligence towards french european strategy wachter mittelstadt floridi right explanation automated decision making exist general data protection regulation international data privacy law walker future human rights impact assessments trade agreements utrecht wiarda institute legal research white house consumer privacy bill rights administration discussion draft discussion wight mordini privacy ethical impact assessment wright hert eds privacy impact assessment springer dordrecht world economic forum prevent discriminatory outcomes machine learning wright hert eds privacy impact assessment springer dordrecht wright framework ethical impact assessment information technology ethics inf technol
