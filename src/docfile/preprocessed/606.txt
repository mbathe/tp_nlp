isp digital future whitepaper yjolt special publication algorithms economic justice taxonomy harms path forward federal trade commission rebecca kelly slaughter janice kopec mohamad batal august contents algorithms economic justice introduction algorithmic harms iii using ftc current authorities better protect consumers new legislative regulatory solutions conclusion acknowledgements algorithms economic justice rebecca kelly slaughter algorithms economic justice taxonomy harms path forward federal trade commission proliferation artificial intelligence algorithmic helped shape myriad aspects society facial recognition deepfake technology criminal justice health care applications seemingly endless across contexts story applied algorithmic one promise peril given novelty scale opacity involved many applications technologies stakes often incredibly high ftc commissioner aim promote economic social justice consumer protection competition law policy recent years algorithmic produced biased discriminatory otherwise problematic outcomes important areas american economy article describes harms caused algorithmic spheres employment credit health care housing profoundly shape lives individuals harms often felt acutely historically disadvantaged populations especially black americans communities color many harms describe entirely novel algorithms especially dangerous simultaneously obscure problems amplify giving false impression problems could possibly exist article offers three primary contributions existing literature first provides baseline taxonomy algorithmic harms portend injustice describing harms technical mechanisms drive harms second describes view ftc existing section ftc act equal credit opportunity act fair credit reporting act children online privacy protection act market studies section ftc aggressively applied thwart injustice finally explores new legislation ftc rulemaking section ftc act could help structurally address harms generated algorithmic yale information society project yale journal law technology vol introduction proliferation artificial intelligence algorithmic recent years shaped myriad aspects society applications technologies innumerable facial recognition deepfake technology criminal justice health care across contexts story algorithmic one promise peril given novelty scale opacity involved stakes high consumers innovators regulators algorithmic fuels could realize promise promoting economic justice distributing opportunities broadly resources efficiently benefits effectively pairing dramatically deeper pools data rapidly advancing technology might yield substantial benefits consumers including potentially mitigating pervasive biases infect human used appropriately judiciously algorithms also throughout article use several related distinct terms including algorithms artificial intelligence machine learning deep learning neural networks terms component term comes commentators often used image russian nesting matryoshka dolls illustrate relationships algorithm defined finite series outermost doll uses algorithms algorithms use next includes machine learning machine learning turn includes deep learning finally neural networks make backbone deep learning see definitive glossary higher mathematical jargon math vault last accessed mar algo eda kavlakoglu machine learning deep learning neural networks difference ibm blog may see jon kleinberg jens ludwig sendhil mullainathan cass sunstein algorithms discrimination detectors proc nat acad sci algorithms economic justice rebecca kelly slaughter transformed access educational improved health outcomes improved diagnostic rates care potentially transformative power algorithmic also risks serious harm misused criminal justice system example commentators note algorithms contribute wrongful detainment biased risk assessments used determine status even mounting evidence reveals algorithmic decisions produce biased discriminatory unfair outcomes variety economic spheres including employment credit health care see matt kasman jon valant opportunities risks student placement algorithms brookings inst see cade metz london lab claims breakthrough could accelerate drug discovery times irene transforming diabetes care artificial intelligence future popular health mgmt see alvaro bedoya color surveillance slate amy cyphert machine learning legality consequences online surveillance students may clare garvie alvaro bedoya jonathan frankle perpetual unregulated police face recognition america geo ctr privacy tech see kashmir hill another arrest jail time due bad facial recognition match times see algorithms criminal justice system risk assessment tools elec privacy info last visited jason tashea courts using sentence criminals must stop wired apr see infra section yale information society project yale journal law technology vol pandemic attendant social economic fallout underscore incredible stakes decisions delegate technology even unemployment soared firms increasingly use algorithms help make employment notwithstanding questions swirl compliance nondiscrimination likewise opaque algorithms used select receives vaccinations resulted wide distributional perverse commissioner federal trade agency whose mission protect consumers unfair deceptive practices promote competition seat use abuse algorithms role see firsthand problems posed algorithms nuanced many flaws algorithmic analogs related human technical processes ftc body enforcement experience draw article utilizes institutional expertise outline harms applied algorithms well tools ftc disposal address offering three primary contributions existing literature first provides baseline taxonomy adam forman nathaniel glasser christopher lech insight may push companies use hiring tool bloomberg may miriam vogel could bring bias pandemic level crisis thrive global june natasha singer vaccine doses gets algorithms decide times eileen guo karen hao stanford vaccine algorithm left frontline doctors mit tech rev algorithms economic justice rebecca kelly slaughter algorithmic harms threaten undermine economic civil identify three ways flaws algorithm design produce harmful results faulty inputs faulty conclusions failure adequately test harmful consequences algorithms stem design flaws accordingly also identify three ways sophisticated algorithms generate systemic harm facilitating proxy discrimination enabling surveillance inhibiting competition markets show several stages design development implementation algorithms failure closely scrutinize impacts drive discriminatory outcomes harms consumers second article describes view ftc existing section ftc act equal credit opportunity act ecoa fair credit reporting act fcra aggressively applied defend threats example argue encourage creditors collect demographic data compliance ecoa safe harbor assess existing algorithms indicia bias also discuss algorithmic disgorgement innovative course consumer protection competition challenges posed algorithmic well beyond listed purpose taxonomy comprehensive provide working framework common obvious concerns facilitate mapping enforcement tools onto problems term surveillance capitalism coined shoshanna zuboff recent book acknowledging rich body work topics borrow zuboff shorthand purposes describing algorithmic flaw see generally shoshana zuboff age surveillance capitalism fight human future new frontier power see also julie cohen truth power legal constructions informational capitalism amy kapczynski law informational capitalism yale mar surveillance capitalism refers way throughout today digital economy pervasive web algorithms collects processes immense pools consumer data often real time constant adjustments algorithms evolve improve relentless effort capture monetize much attention many people possible practically speaking companies accomplish goals microtargeting forms subtle behavioral manipulation system surveillance capitalism systematically erodes consumer privacy promotes misinformation disinformation drives radicalization undermines consumers mental health reduces eliminates consumers choices see infra section part surveillance capitalism yale information society project yale journal law technology vol promising remedy ftc secured recent enforcement actions finally section identify limitations reach existing enforcement tools limitations tie directly article third contribution explore ftc rulemaking section ftc act new legislation could help effectively address harms generated algorithmic hope draw attention ingenuity interested public challenges posed algorithms work together creating enforcement regime advances economic justice equity ultimately argue new technology neither panacea world ills plague causes words technologist david edelman magic math consider threats algorithms pose justice must remember technology magic neither cure shortcomings take focused collaboration policymakers regulators technologists attorneys proactively address technology harms harnessing promise article proceeds three sections section outlines taxonomy harms caused algorithmic section iii outlines ftc existing toolkit addressing harms ways act comprehensively improve efficacy tools limitations authority finally section discusses new legislation regulation aimed addressing algorithmic holistically algorithmic harms taxonomy algorithmic harms describing harms technical mechanisms drive useful starting point section divided david edelman twitter algorithms economic justice rebecca kelly slaughter two subparts first addresses three flaws algorithm design frequently contribute discriminatory otherwise problematic outcomes algorithmic faulty inputs faulty conclusions failure adequately test second subpart describes three ways even sophisticated algorithms still systemically undermine civil economic justice first algorithms facilitate discrimination enabling use facially neutral proxies target people based protected characteristics second widespread application algorithms fuels fueled surveillance capitalism third sophisticated opaque use algorithms inhibit competition harm consumers facilitating anticompetitive conduct enhancing market power six different types algorithmic harms often work first set often directly enabling considering interplay helpful describe individually course harms enumerated herein intended exhaustive list challenges posed algorithmic taxonomy however help identify common pervasive problems invite enforcement regulatory intervention therefore helpful framework consideration potential enforcement approaches algorithmic design flaws resulting harms first three categories algorithmic harms generally stem common flaws design application specific algorithms faulty inputs value algorithm inherently related quality data used develop faulty inputs produce thoroughly problematic outcomes broad concept captured familiar phrase garbage garbage data used develop algorithm might skewed individual data points reflect problematic human biases overall dataset adequately representative often skewed training data reflect historical enduring yale information society project yale journal law technology vol patterns prejudice inequality faulty inputs create biased algorithms exacerbate one recent example amazon failed attempt develop hiring algorithm driven machine learning effort ultimately abandoned deployment algorithm systematically discriminated women discrimination stemmed fact resumes used train amazon algorithm reflected skew company applicant pool despite engineers best efforts algorithm kept identifying pattern attempting reproduce faulty inputs also appear heart problems standardized testing international baccalaureate prestigious global degree program high school students cancelled exams instead relied algorithm predict student test scores based inputs grades past performance students given school result baffling test scores consequences example relying schools past average test scores likely disadvantaged students taken courses receive college credit save see solon barocas andrew selbst big data disparate impact rev nicol turner lee paul resnick genie barton algorithmic bias detection mitigation best practices policies reduce consumer harms brookings inst may david lehr paul ohm playing data legal scholars learn machine learning davis rev jeffrey dastin amazon scraps secret recruiting tool showed bias women reuters roby chatterji center equity advanced coursework testing ctr progress algorithms economic justice rebecca kelly slaughter thousands dollars according percent public schools offer classes title numerous students reportedly saw college scholarships admissions offers rescinded algorithm assigned unexpectedly low test similar case united kingdom used algorithm replace play pivotal role university admissions ultimately retracting scores response widespread protests critics pointed inputs similar used algorithm unfairly stacked deck students education help enable upward social mobility inputs instances reflected structural disadvantages see meredith broussard algorithms give real students imaginary grades times avi global exam grading algorithm fire suspected bias reuters july one student describes come entire last two years high school driven goal getting many college credits could save money school saw scores heart melissa gordon emily vanderkamp olivia halic international baccalaureate programmes title schools united states accessibility participation university enrollment ibo underrepresented minority students less access social economic capital hinder educational attainment exacerbate cycle poverty schools high proportion students eligible become title schools allows allotment federal resources attempt close achievement gap department education see hye jung han opinion algorithm decide student future politico tom simonite meet secret algorithm keeping students college wired july see daan kolkman algorithm world learn grading fiasco london sch econ impact blog yale information society project yale journal law technology vol socioeconomic bbc noted coverage locks advantages means talented outlier bright child school school rapidly improving could delivered short developers use faulty data train algorithm results may replicate even exacerbate existing inequalities injustices faulty conclusions different type problem involves feeding data algorithms generate conclusions inaccurate better phrased data garbage type flaw faulty conclusions undergirds fears rapidly proliferating field affect recognition technology often fueled failures experimental design many companies claim affect recognition see richard adams niamh mcintyre england downgrades hit pupils disadvantaged areas hardest guardian sean coughlan algorithm say bbc news additional implications around concept faulty conclusions consider going forward particular need think carefully deployed implemented well impacted choices one important example development deployment facial recognition technology clearly exacerbate existing racial disparities clear disturbing evidence technologies accurate identifying individuals least three separate occasions black men wrongfully arrested based faulty facial recognition matches see joy buolamwini timnit gebru gender shades intersectional accuracy disparities commercial gender classification proc machine learning res brian fung facial recognition systems show rampant racial bias government study finds cnn bus kashmir hill another arrest jail time due bad facial recognition match times algorithms economic justice rebecca kelly slaughter products accurately detect individual emotional state analyzing facial expressions eye movements tone voice even underlying algorithms attempt find patterns reach conclusions based certain types physical presentations mannerisms one might expect human character reduced set objective observable factors example consider algorithmic analysis facial popular flavor affect recognition technology review analyzed thousand studies emotional expression concluded fforts simply read people internal states analysis facial movements alone without considering various aspects context best incomplete worst entirely lack validity matter sophisticated computational nevertheless large host see kate crawford report inst manish raghavan mitigating bias algorithmic hiring evaluating claims practices proc conf fairness accountability transparency lisa feldman barrett emotional expressions reconsidered challenges inferring emotion human facial movements psychol sci pub int see also abstract explaining people communicate anger disgust fear happiness sadness surprise varies substantially across cultures situations even people within single situation furthermore given configuration facial movements scowl often communicates something emotional zhimin chen david whitney tracking affective state unseen persons proc nat acad sci finding detecting emotions accuracy requires information available face body angela chen karen hao emotion researchers say overblown claims give work bad name mit tech rev late one researcher ran microsoft face api application programming interface public dataset nba player pictures found interpreted black players negative emotions white players see lauren rhue racial influence automated perceptions emotions cjrn race ethnicity see also isobel asher hamilton experts doubt amazon new halo wearable accurately judge emotion voice worry privacy risks bus insider saheli roy choudhury amazon says yale information society project yale journal law technology vol sell questionable affect recognition technology sometimes deployed grant deny formative life opportunities striking example use affect recognition technology hiring despite growing concerns including number companies claim products capable reliably extrapolating personality traits predicting social outcomes job methods analysis range questionable assessments observable physical factors described one researcher characterized snake example one recent study algorithmic employment screening products highlighted company purports profile sixty personality traits relevant job resourceful adventurous cultured based algorithm analysis applicant recorded video cover course algorithmic hiring tools potentially problematic growing evidence facial recognition identify fear cnbc see rebecca heilweil illinois says know grading online job interviews vox recode discussing recently passed illinois law requiring companies notify job seekers used evaluate applicant fitness part video interview bradford newman using make hiring decisions prepare eeoc scrutiny bloomberg law describing letter ten senators eeoc see rebecca heilweil artificial intelligence help determine get next job vox recode providing examples companies use recruiting arya leoforce initial contact potential recruit reconnecting prior candidate mya personality assessments pymetrics video interviews hirevue see arvind narayanan assoc professor comput princeton university presentation recognize snake oil see raghavan supra note algorithms economic justice rebecca kelly slaughter suggests products space suffer major structural indeed princeton arvind narayanan computer scientist criticized tools claim predict job performance based body language speech patterns fundamentally algorithmic hiring products merit skepticism application recent studies suggest might systematically disadvantage applicants disabilities present differently majority company applicants reports trouble employer using algorithmic hiring product screen applicants pseudoscience claims power make objective assessments human character handwriting analysis purports reveal one personality even polygraph testing long inadmissible court claims pernicious analog counterparts might encounter less skepticism even though opacity algorithms prevent objective analysis inputs despite veneer objectivity comes see narayanan supra note see jim fruchterman joan mellea expanding employment success people disabilities benetech anhong guo toward fairness people disabilities research roadmap acm sigaccess accessibility computing see also alex engler employment algorithms disability discrimination default brookings inst additionally many companies capitalize positive associations despite fact even use material way business one recent report found full percent european startups classified companies accurately fit description startups label attract percent percent funding rounds technology startups see parmy olson nearly half startups cashing hype forbes mar yale information society project yale journal law technology vol throwing around terms machine learning many contexts technology still deeply indeed algorithm assessment candidate sometimes less accurate useful subjective though still imperfect impression employer gets conducting risks compounded certain products emphatically marketed producing reliable objective predictions potential hires conclusions fact flawed algorithmic hiring problematic number reasons example already seeing development market strategies products designed beat different kinds hiring algorithms people unable afford services judged creating yet another barrier employment perpetuates historical wealth inequality hinders social mobility see sangmi cha smile eyes beat south korea hiring bots land job reuters hilke schellmann job interviews transform next decade wall see also miranda bogen aaron rieke help wanted examination hiring algorithms equity bias upturn see generally alex engler auditing employment algorithms discrimination brookings inst mar algorithms also used deceive manipulate consumers example dark patterns deepfake technology dark patterns digital user interfaces designed deceive manipulate consumers taking unintended actions may microtargeting personalization see lauren willis deception design harv tech fall rebecca kelly slaughter acting chair fed trade comm opening remarks bringing dark patterns light ftc workshop apr arunesh mathur dark patterns scale findings crawl shopping websites proc acm interaction deepfakes use deep learning neural networks identify reconstruct patterns audio video image new content looks feels sounds real example companies use clip person algorithms economic justice rebecca kelly slaughter phenomenon quite familiar ftc new technology old lack substantiation failure test even algorithm designed care good intentions still produce biased harmful outcomes unanticipated often algorithms deployed without adequate testing could uncover unwelcome outcomes harm actual voice generate deepfake audio clip voice saying anything type content used manipulate deceive consumers including imposter scams fraud disinformation deepfake technology widely accessible avoid detection constantly improving see bobby chesney danielle citron deep fakes looming challenge privacy democracy national security cal dan boneh preparing age deepfakes disinformation stan ftc recently held workshops important topics bringing together enforcers academics advocates help inform agency law enforcement regulatory approach see fed trade comm bringing dark patterns light ftc workshop ftc apr fed trade comm say ftc workshop voice cloning technologies ftc advertisers must reasonable basis advertising claims ftc policy statement regarding advertising substantiation appended thompson med advertiser claims product proven efficacy established reasonable basis claim must consist precise type amount proof would satisfy relevant scientific removatron int citations omitted aff cir advertisements contain express representations regarding particular level support advertiser product claim commission expects firm level thompson med determine constitutes reasonable basis efficacy claim commission applies pfizer factors type claim type product benefits truthful claim ease developing substantiation claim consequences false claim amount substantiation experts field would agree reasonable pfizer see also thompson med daniel chapter one ftc lexis ftc direct marketing concepts supp mass yale information society project yale journal law technology vol people real world ftc frequently cautions area data security testing important step insufficient prevent constant monitoring evaluating retraining essential practices identify correct embedded bias disparate health care field provides good examples bias result failure adequately assess variables used algorithm failure monitor outcomes test bias recent study found racial bias widely used algorithm intended improve access care patients chronic health algorithm used health care costs proxy health needs variety reasons unrelated health needs white patients spend health care equally sick black counterparts using health care costs predict health needs therefore caused algorithm disproportionately flag white patients additional researchers estimated result embedded bias number additional caution subject data security vast quantities information involved developed machine lead serious data security concerns access control implementations proper storage proper disposal data companies get security side equation wrong may violating data security rules well causing harms discussed article see generally turner lee supra note ziad obermeyer dissecting racial bias algorithm used manage health populations science medical community increasingly scrutinizing role algorithms perpetuating potentially exacerbating racial disparities health care treatment outcomes see nwamaka eneanya reconsidering consequences using race estimate kidney function jama arguing equation kidney function leads care black patients without substantial increase diagnostic precision darshali vyas hidden plain use race correction clinical algorithms new eng med critically cataloguing algorithms across health care fields sujata gupta bias common health care algorithm disproportionately hurts black patients sci news algorithms economic justice rebecca kelly slaughter black patients identified extra care reduced half potential scale harm staggering researchers called particular healthcare algorithm one largest typical examples class commercial tools applied roughly million people united states researchers uncovered flaw algorithm able looked beyond algorithm outcomes produced access enough data conduct meaningful notably researchers identified flaw algorithm manufacturer worked mitigate impact ultimately reducing bias type bias reduction harm mitigation testing modification seeks still inquiry risks using health care spending proxy health care needs including relevant social context raised concerns although simple bias healthier white patients get cut line ahead black patients even though black patients researchers continue emphasized algorithm unique rather emblematic generalized approach risk prediction health care sector industry algorithms already used scale today unbeknownst obermeyer supra note researchers analyzed data patients one hospital used care algorithm focused patients white identified black period algorithm given patients risk score based past health care costs theory patients risk scores similarly sick instead average black patients risk scores white patients chronic diseases gupta supra note obermeyer supra note recent ftc privacycon professor obermeyer explained correcting issue algorithm required effort message work extra effort hugely valuable make difference biased algorithm one actually works structural biases see fed trade comm transcript privacycon yale information society project yale journal law technology vol test reliably detect prevent bias early ongoing testing outcomes instance may caught flaw years another example front years ago reporter found typing number common female names linkedin would result prompt similarly spelled man name example stephan williams searching stephanie according reporter common male names entered linkedin never prompted female alternative example potentially biased outcome uncovered user testing might prevented altogether platform engaged regular outcome testing company initially denied algorithmic almost month later linkedin engineering conceded search algorithm fact produce biased indeed executive highlighted systematic shortcoming linkedin approach testing may prevented company effectively detecting see generally nicole wetsman quick fix find racial bias health care algorithms verge algorithms use proxy measures health costs measure examined carefully says bias proxy would evaluated see matt day linkedin search engine may reflect gender bias seattle times linkedin discontinued practice reports see matt day linkedin changes search algorithm remove name prompts seattle times see chris baraniuk linkedin denies gender bias claim site search bbc news see igor perisic making hard choices quest ethics machine learning linkedin engineering blog see however algorithm serve suggestions based solely word search frequency without aware gender actually resulted biased results retrospect obvious removing gender consideration algorithms actually blind since algorithms economic justice rebecca kelly slaughter kind bias meaningful consequences case profiles names turned less frequently potentially resulting fewer employment opportunities women perhaps one troubling examples chronic failure test reflected safiya noble chronology repeated instances search bias stereotyping google beginning searches phrase black girls google would return multiple pornographic sexual content results including top result type damaging proliferation racist stereotypes massive algorithms went years extended many groups recently google search three black teenagers generated results perpetuating stereotypes instance public attention identified flaw fixed troubling results persisted years failure test scale risks elevating embedding society persistent pernicious stereotypes entirely possible examples algorithmic bias product multiple algorithmic flaws often case stands examples additional testing algorithm impact across two obvious protected classes race gender might detected disparate effect much earlier facilitated correction examples deployer algorithm tracking information first place use verify output algorithms fact recent years linkedin appears taken deliberate approach testing algorithms underlying stated effort make company algorithms fair equitable company also created tools designed address biased inequitable results uncovered testing initiatives encouraging goals laudable success require constant vigilance see ryan roslansky helping every company build inclusive products linkedin blog may sriram vasudevan addressing bias applications linkedin fairness toolkit linkedin engineering blog see safiya noble google striking history bias black girls time mar see also safiya noble algorithms oppression search engines reinforce racism nyu press yale information society project yale journal law technology vol reluctant acknowledge denied possibility problem limited algorithms instances unintended bias admitting might occur despite best intentions imperative sophisticated algorithms exacerbate systemic harms previous subsection explored problems specific design application individual algorithms contrast harms enumerated subsection describe broadly societal consequences flawed algorithmic course categories harms neither exhaustive mutually exclusive issues described subsection tie closely flaws enumerated proxy discrimination addition flaws algorithmic design implementation enumerated promise algorithmic also tempered systemic contributions broader social harms one pernicious harm work recent examples algorithmic bias problem scholars termed proxy algorithmic systems engage proxy discrimination use one facially neutral variables stand legally protected trait often resulting disparate treatment disparate impact protected classes certain economic social civic words algorithms identify seemingly neutral characteristics create groups closely mirror protected class proxies used inclusion exclusion see baraniuk supra note see generally anya prince daniel schwarcz proxy discrimination age artificial intelligence big data iowa rev see roxy discrimination requires usefulness discriminator derives least part fact produces disparate impact humans unwittingly proxy discriminate law prohibits rational discrimination person firm may find discrimination based characteristic predictive legitimate objectives even though characteristic predictive power derives correlation infra part iii section note algorithms economic justice rebecca kelly slaughter facebook use lookalike audiences facilitated housing discrimination presents one clearest illustrations proxy discrimination according allegations department housing urban development hud facebook offered customers advertising housing services tool called lookalike advertiser using tool would pick custom audience represented best existing customers facebook identified users shared common qualities customers became audience generate lookalike audience facebook considered proxies included user likes geolocation data online offline purchase history app usage page based factors facebook algorithm created groupings aligned users protected classes facebook identified groups less likely engage housing ads included excluded targeting accordingly according hud grouping users like similar pages unrelated housing presuming shared interest disinterest advertisements facebook mechanisms function like advertiser intentionally targets excludes users based protected charge discrimination facebook fheo mar see also tracy jan elizabeth dwoskin hud reviewing twitter google practices part housing discrimination probe post mar charge discrimination facebook fheo mar see also cmt comm rohit chopra matter proposed rule amend hud interpretation fair housing act discriminatory effects standard inputs intuitive result discrimination seemingly neutral inputs especially analyzed combination data points also substitute members protected class likely wide range characteristics common detected increased collection different types information data points volume input combination inputs turn substitute proxy protected yale information society project yale journal law technology vol problem may persist across advertising algorithms designed maximize clicks conversions even advertiser requests broad audience inclusivity algorithm may skew ads demographic segments expected based historical performance generate clicks one recent study researchers specified identical audience three different job postings lumber industry position supermarket cashier position taxi despite request audience lumber job went audience percent white percent male supermarket cashier went percent female audience taxi position went percent black dangers proxy discrimination amplified machine learning optimization likely affect credit sphere combination expanding innovative fintech market paired alternative credit scoring potential extend credit people need fintech innovations also enable continuation historical bias deny access credit system efficiently target products least afford indeed biases exacerbated use algorithms algorithms automate appearance simultaneously obscuring visibility muhammad ali discrimination optimization facebook delivery lead skewed outcomes proc acm interaction prior study google delivery job ads demonstrated similar problematic results identical sample randomly assigned male female identity google showed executive position male group times times female group amit datta michael carl tschantz anupam datta automated experiments privacy settings tale opacity choice discrimination proc privacy enhancing tech see john detrixhe jeremy merril fight financial advertisers using facebook digital redlining quartz concerns also caught attention congress see examining use alternative data underwriting credit scoring expand access credit hearing task force fin tech comm financial cong algorithms economic justice rebecca kelly slaughter inputs formulae used make decisions opacity make bias even harder identify recent study illustrates promise residual peril algorithmic lending decisions credit study found loans made lenders latinx black borrowers pay considerably interest refinance study also found fintech algorithms discriminate percent less significant discrimination harming latinx black borrowers still scholars could conclude definitively caused discriminatory outcomes fintech platforms surmised likely due type optimization based neutral characteristic aligned minority status saw examples proxy discrimination new use facially neutral factors generate discriminatory results something society civil rights laws grappling context algorithms sometimes flaw might example proxy discrimination one reasons health care algorithm discussed earlier ultimately produced biased outcomes reason robert bartlett discrimination fintech era nat bureau econ research working paper basis points respectively tune basis points interest purchase mortgages basis points refinance mortgages case learning higher prices could quoted profiles borrowers geographies associated see prince schwarcz supra note see big data game changers comes risk unintentional proxy discrimination particular proxy discrimination ais virtually inevitable whenever law seeks prohibit use characteristics whose predictive power measured directly facially neutral yale information society project yale journal law technology vol believe hospital manufacturer algorithm question trying disadvantage black patients important note however proxy discrimination also intentional obscurity provided allow actors effectively launder bias discrimination algorithms pursuit illegitimate profits maintain oppressive proxy discrimination results disparate impact always pernicious whether identify underlying intent give rise legal liability even surveillance capitalism additional way algorithmic fuel broader social challenges role plays system surveillance business model systematically erodes privacy promotes misinformation drives see solon barocas andrew selbst big data disparate impact rev alan rubel clinton castro adam pham agency laundering information technologies ethical theory moral prac fed trade comm big data tool inclusion exclusion understanding issues ftc see elisa jillson aiming truth fairness equity company use ftc bus blog apr infra part iii section see zuboff supra note see dipayan ghosh nick couldry digital realignment rebalancing platform economies corporation consumer associate working paper series working paper filippo menczer thomas hills information overload helps fake news spread social media knows sci soroush vosoughi deb roy sinan aral spread true false news online science mar proliferation technologies deepfakes rapidly improving algorithmic text generation exacerbate algorithms economic justice rebecca kelly slaughter undermines consumers mental reduces eliminates consumers disinformation problem see supra note ben buchanan truth lies automation language models could change disinformation ctr security emerging tech may see marc faddoul guillaume chaslot hany farid longitudinal analysis youtube promotion conspiracy videos arxiv mar manoel horta ribeiro auditing radicalization pathways youtube proc conf fairness accountability transparency jeff horwitz deepa seetharaman facebook executives shut efforts make site less divisive wall may algorithms exploit human brain attraction divisiveness read slide internal facebook presentation left unchecked warned facebook would feed users divisive content effort gain user attention increase time platform presentation stated extremist group joins due recommendation tools activity came platform groups join discover algorithms recommendation systems grow jeff horwitz facebook knew calls violence plagued groups plans overhaul wall see vikram bhargava manuel velasquez ethics attention economy problem social media addiction bus ethics ddicting users social media unjustifiably harms way demeaning objectionably exploitative business model social media companies generates strong incentive perpetrate wrongdoing cheng internet addiction relationship suicidal behaviors multinational observational studies clinical psychiatry melissa hunt fomo limiting social media decreases loneliness depression soc clinical psych christian montag bernd lachmann marc herrlich katharina zweig addictive features social platforms freemium games background psychological economic theories int env res pub health see infra section part threats competition yale information society project yale journal law technology vol much today digital economy fundamentally geared toward maximizing consumer attention monetizing eyeballs time spent better industries broadcasting focus remarkably short time proliferation algorithms behavioral advertising created staggering fundamentally different system surveillance unlike attention ecosystems old opaque algorithms ubiquitous lives functionally impossible escape reach machine learning enables pervasive web algorithms process immense pools consumer data often real constant adjustments algorithms evolve improve relentless effort capture monetize much attention many people possible many enterprises remarkably successful using algorithms optimize consumers attention little regard downstream consequences one troubling aspects surveillance capitalism affects children contexts many companies use algorithms attract maintain monetize children employing algorithmic recommendation systems functions especially children involved engines digital economy dangerous consequences difficult avoid example recent study content youtube concluded due platform recommendation system young children able likely encounter disturbing videos randomly browse course amount information encountered consumer enormous attention limited resource participants attention economy great lengths capture resulting information overload often plays key role loss information see filippo menczer thomas hills information overload helps fake news spread social media knows sci algorithms economic justice rebecca kelly slaughter platform starting benign content youtube innocuous authors highlight influx disturbing inappropriate content targets young children infamous elsagate controversy episode nefarious users uploaded disturbing videos featuring children spiderman elsa mickey violent lewd conduct pernicious content often masked innocent thumbnails video titles making difficult children parents exposure type content traumatize young children carries serious risks early childhood even troubling youtube algorithms promote disturbing inappropriate videos young children additional view brings platform content creator additional revenue course youtube asserts taken steps address issue removing disturbing content company transparent effectiveness kostantinos papadamou disturbed youtube kids characterizing detecting inappropriate videos targeting young children proc fourteenth int aaai conf web social media important study received funding european union national science foundation see michael rich director founder harvard medical school center media child health explains videos made upsetting fact characters children thought knew trusted behaving see sapna maheshwari youtube kids startling videos slip past filters times see also elyse samuels william neff sex drugs peppa pig big problem disturbing kids content youtube post mar craig timberg youtube says bans preteens site still delivering troubling content young post mar yale information society project yale journal law technology vol researchers suggest dangers uncurated content combined engagement oriented gameable recommendation systems considering advent algorithmic content creation deepfakes monetization opportunities sites like youtube reason believe organic end beyond recommendation algorithms companies may seek monetize children attention illegally harvesting data using serve behavioral advertisements conduct violates children online privacy protection act coppa core commission recent complaints latter case commission settlement required defendants materially remake youtube platform ways would reduce amount illegal behavioral advertising content specifically whenever new video uploaded youtube content creators designate content videos designated youtube would serve behavioral advertisements track persistent identifiers allow comments papadamou supra note assessment youtube current mitigations shows platform struggles keep problem manually reviewed disturbing restricted videos respectively removed papadamou supra note children online privacy protection rule implements coppa requires websites apps online services provide notice information practices obtain verifiable parental consent collecting personal information children thirteen including use persistent identifiers track user internet browsing habits targeted advertising addition third parties advertising networks also subject coppa actual knowledge collecting personal information directly users websites online services see see complaint united states hyperbeard cal june commission brought case new york attorney general see complaint fed trade comm google llc youtube llc algorithms economic justice rebecca kelly slaughter despite requirement voted settlement primary objection required enforceable commitment youtube would police accuracy channels designations identify undesignated content turn behavioral advertising suggested dissent one way would technological backstop securing commitment settlement important strong financial incentives content behavioral advertising lucrative contextual youtube myriad content creators might bet could escape coppa enforcement since settlement finalized youtube announced use machine learning actively search content automatically apply sounds like technological backstop mind two major differences first entirely voluntary second application effectiveness opaque youtube dial back see dissenting statement commissioner rebecca kelly slaughter matter google llc youtube llc fed trade comm file comes relief current order looks like fence one three sides missing fourth side mechanism ensure content creators telling truth designate content cynical observer might wonder whether wake order youtube even inclined turn blind eye inaccurate designations content order maximize profit light fence looks like moat giving youtube handy argument face coppa liability content see also dissenting statement commissioner rohit chopra matter google llc youtube llc fed trade comm file see todd spangler youtube new supervised mode let parents restrict older kids video viewing variety using technology consistently apply age restrictions youtube official blog better protecting kids privacy youtube youtube official blog yale information society project yale journal law technology vol away discretion public would none wiser brings broader set concerns surveillance extends beyond coppa single platform certain technology companies almost unlimited discretion algorithms present information consumers pervasive algorithms process unfathomable amount data makes remarkably effective exploiting exacerbating cognitive companies deploy often maximize monetize user engagement microtargeting forms subtle behavioral manipulation order fuel advertising revenue also data engaged user data generates worth emphasizing however companies use information merely capture attention simply tweaking code companies powerfully shape behavior even outlooks rob privacy also understand surveillance capitalism harms manipulates consumers crucial understand way given set algorithms exacerbates exploits social tendencies cognitive vulnerabilities see ryan calo digital market manipulation geo rev successfully curtail harms interdisciplinary partnerships technologists behavioral scientists others key thankfully creative initiatives already begun emerge example partnership university warwick indiana university bloomington observatory social media osome pronounced awesome recently published informative primer topic see menczer hills supra note see cohen supra note zuboff supra note matz kosinski nave stillwell psychological targeting digital mass persuasion proc nat acad sci building recent advancements assessment psychological traits digital footprints paper demonstrates effectiveness psychological mass adaptation persuasive appeals psychological characteristics large groups individuals goal influencing petra persson attention manipulation information overload behav pub pol algorithms economic justice rebecca kelly slaughter ftc recently announced timely important section nine social media industry potential subtle manipulation clear obvious study intended help agency better understand companies advertising practices collect use track derive personal demographic information practices affect children teens vulnerable populations joint statement commissioners chopra wilson noted alarming still know little companies know much project seeks understand business models influence americans hear see talk information share among topics study seeks uncover children families targeted categorized well whether consumers subjected threats competition pitfalls associated algorithmic sound obviously laws ftc enforces consumer protection mission ftc also responsible promoting competition threats posed algorithms profoundly affect mission well moreover two missions actually distinct related algorithms economic considered competition consumer protection lenses full discussion see infra section iii see joint statement ftc comm chopra slaughter wilson social media video streaming service providers privacy practices fed trade comm file see fed trade comm resolution directing use compulsory process collect information regarding social media video streaming service providers privacy practices fed trade comm matter apr see also vindu goel facebook tinkers users emotions news feed experiment stirring outcry times june yale information society project yale journal law technology vol implications algorithms antitrust law well beyond scope article briefly highlight ways competition imperiled use misuse topics include traditional antitrust fare pricing collusion well novel questions implications use algorithms dominant digital firms entrench market power engage exclusionary practices algorithmic pricing practice setting prices dynamically automatically algorithms sometimes enhanced artificial intelligence machine learning become body literature algorithmic pricing affect competition grown past several years includes concerns use algorithms facilitate anticompetitive personalized use exec order fed reg july recognizing unfair data collection surveillance practices may damage competition see salil mehra antitrust competition time algorithms rev andreas mundt algorithms competition digitalized world competition pol int july see emilio calvano protecting consumers collusive prices due sci john asker chaim fershtman ariel pakes artificial intelligence pricing impact algorithm design nber working paper march zach brown alexander mackay competition pricing algorithms harv bus working paper april ezrachi stucke algorithmic collusion problems see dube sanjog misra personalized pricing customer welfare patrick kehoe bradley larsen elena pastorino dynamic competition era big data stanford univ fed reserve bank minneapolis working paper pricing algorithms economic working paper use algorithms facilitate collusion personalised pricing competition mkts working paper october algorithms economic justice rebecca kelly slaughter algorithms execute agreement even given rise criminal antitrust algorithms may enhance ability firms collude either tacitly limited cases enforcement collusion facilitated algorithms unclear whether conduct fact occurring whether simply difficult enforcers detect moving forward competition enforcers may deploy department justice brought criminal charges two companies united states topkins executing agreement using algorithms matter executives seller posters art agreed fix prices products sold amazon marketplace adopted specific pricing algorithms execute conspiracy press release announcing matter doj noted commitment pursue illegal agreements whether occur room internet using complex pricing press release dep justice former executive charged price fixing antitrust division first online marketplace prosecution apr tacit collusion contrast explicit collusion firms able coordinate behavior achieve anticompetitive outcomes independent conduct without agreement conduct enable joint profit maximization reducing competition harming consumers see calvano supra note one recent study duopoly german gasoline station markets researchers found empirical evidence prices increased stations adopted algorithmic pricing practices modeling shown pricing algorithms temper competition increase profits largest benefits going dominant technologically savvy firms see stephanie assad algorithmic pricing competition empirical evidence german retail gasoline market cesifo working paper brown mackay supra note however fact algorithms may make easier firms predict respond changes demand may also increase firm temptation deviate lower price times high predicted demand see jeanine catherine tucker collusion algorithm better demand prediction facilitate coordination sellers mgmt sci apr jason connor nathan wilson reduced demand uncertainty sustainability collusion could affect competition info econ pol via yale information society project yale journal law technology vol technology effort detect indeed united kingdom competition markets authority already deploying online price monitoring effort detect illegal resale price even absent collusion algorithms fuel personalized pricing practices may alter competitive dynamics market ways harm consumers example data collected consumers pricing algorithms may able help sellers better gauge consumer maximum willingness example firm ziprecruiter changed flat subscription fee range fees decided customer customer based data provided survey potential customer basing price indicia customer willingness pay company profits increased percent compared price see giovanna massarotto ashwin ittoo gleaning insight antitrust cases using machine learning stan computational antitrust thibault schrepel computational antitrust introduction research agenda laying broad vision use machine learning enhance antitrust investigation enforcement simon nichols restricting resale prices using data protect customers competition mkts auth june personalized pricing form antitrust doctrine refers price discrimination charging different consumers different prices price discrimination involves presenting personalized price exactly equal consumer willingness pay type pricing rare extremely difficult achieve price discrimination refers pricing based volume goods services purchased price discrimination pricing based characteristics consumers groups consumers provide indicia customers willingness pay goal underpinning forms price discrimination charge consumers maximum price consumer willing pay product see herbert hovenkamp federal antitrust policy law competition practice comparing profitability various forms price discrimination rafi mohammed retailers use personalized prices test willing pay harvard business review algorithms economic justice rebecca kelly slaughter practice always result price increase case majority customers enjoyed price reduction future algorithmic advances could allow firms precisely target willingness pay pocket consumer surplus profit furthermore increased prices potential harm price discrimination addition changing competitive landscape personalized pricing also implicate broader discrimination concerns surrounding use personalized pricing may also lead fracturing relevant product markets purposes merger analysis increase possibility harm particular groups consumers antitrust enforcers may need examine numerous markets order fully capture potential competitive harm specific groups consumers especially targeted consumers may uniquely vulnerable harm targeted groups consumers may also disproportionately fall protected dube misra supra note pricing personalized degree discriminating consumers based race religion gender national origin could violate antidiscrimination laws pricing decisions based consumer data may also disparate impacts protected classes see infra part iii section see also personalized pricing digital era note united states claire kelloway personalization price discrimination open mkts inst possible example propublica found princeton review priced sat prep services based zip code asians twice likely get higher price see julia angwin algorithms decide pay propublica propublica analysis found asians nearly twice likely get higher price princeton review asians make percent population overall accounted percent population areas princeton review charging higher prices sat prep mcsweeny dea implications algorithmic pricing coordinated effects analysis price discrimination markets antitrust enforcement antitrust fall merger might previously required analysis competitive effects one relevant product market may yale information society project yale journal law technology vol course concerns antitrust law extend well beyond pricing especially kinds digital markets broadly deploy algorithms accumulation concentration vast amounts data entrench incumbents create barriers entry firms accumulate data use better train algorithms may give enduring point new entrants may never able reach scale needed meaningfully short lack access data may become lasting barrier entry product algorithms also play significant role types antitrust complaints raised dominant digital platforms exclusionary conduct manipulation search complaints reflect fact digital platforms able deploy algorithms opaque business decisions appear neutral may fact benefit platform expense especially vertical instead require antitrust enforcers examine dozens hundreds potential relevant product markets even majority consumers would negatively affected proposed transaction however may nonetheless appropriate define price discrimination market product consumers live households without terrell mcsweeny brian dea data innovation potential competition digital markets looking beyond price effects merger analysis cpi antitrust chronicle noting data analytics capabilities create barriers entry digital markets competition enforcers thus pay particularly close attention whether merger would enhance barriers entry even price effects unlikely katharina pistor code capital law creates wealth inequality see antitrust report competition digital markets competition markets authority algorithms reduce competition harm consumers algorithms economic justice rebecca kelly slaughter rivals may harm competition well consumers might inhibited accessing broader range algorithms systems become sophisticated pervasive competition enforcers must closely monitor affect competition wide variety markets particularly digital markets already dominated powerful incumbents identifying preventing harms may require different investigative strategies collaboration among enforcers academics technological tools evolve enforcement strategies must keep iii using ftc current authorities better protect consumers question critical algorithmic problems inputs faulty conclusions failure adequately test proxy discrimination surveillance capitalism threats rather advance economic justice algorithmic problems addressed mitigated effective solutions consumers competition might benefit net algorithmic innovations throughout article suggested pitfalls algorithmic wholly different problems regulators confronted many years section see complaint colorado google dec google incentive power control utilize systematic multipronged discriminatory attack specialized vertical providers operating vertical market google choosing google misconduct undermines competition harms advertisers wish buy general search advertising hurts consumers face unjustified obstacles reaching content may valuable ultimately assume costs higher advertising passed along see competition markets authority supra note schrepel supra note james niels rosenquist fiona scott morton samuel weinstein addictive technology implications antitrust enforcement sch mgmt addition threats algorithms emerging technologies also merit close examination competition enforcers see thibault schrepel collusion blockchain smart contracts harv tech yale information society project yale journal law technology vol consider ftc use current authority address new fact patterns civil rights laws logical starting point addressing discriminatory consequences algorithmic state federal civil rights laws already prohibit discrimination areas care employment housing none laws specifically contemplates discrimination arising context automated decisions relying vast fields data allow discrimination simply involved algorithm neither explanation excuse incumbent law enforcers think creatively apply existing civil rights law new fact patterns relevant law enforcement agencies explicit authorities many cases existing jurisprudence may difficult apply algorithmic bias precisely opacity makes demonstrating discrimination already high bar even difficult must consider legal protections currently exist outside direct civil rights statutes ftc four types enforcement authority provide agency ability protect consumers promote economic justice face algorithmic harms general authority ftc act rules statutes fcra ecoa coppa study authority section rulemaking authority section section ftc act enforcement activity conducted ftc brought general authority provided commission section ftc act prohibits unfair deceptive acts practices act century old since passage see prohibiting discrimination health care prohibiting discrimination employment prohibiting discrimination housing prohibiting credit discrimination algorithms economic justice rebecca kelly slaughter agency able apply statute general language meet new enforcement challenges approach urgently needs applied algorithms one innovative remedy ftc recently deployed algorithmic disgorgement premise simple companies collect data illegally able profit either data algorithm developed using novel approach recently deployed ftc case everalbum january commission alleged company violated promises consumers circumstances would deploy part settlement commission required company delete data also facial recognition models algorithms developed users photos videos authority seek type remedy comes commission power order relief reasonably tailored violation innovative enforcement approach send clear message companies engaging illicit data collection order train models worth decision order everalbum see also final order cambridge analytica llc file complaint everalbum commission may seek injunctions containing provisions broader conduct declared telebrands ftc cir ftc orders limited prohibiting narrow lane wrongdoer past violations may effectively close roads prohibited ftc ruberoid thorough explanation views importance specific general deterrence effective enforcement see dissenting statement commissioner rebecca kelly slaughter regarding matter ftc facebook july yale information society project yale journal law technology vol agency also use deception authority connection algorithmic harms marketers products services represent use technology unsubstantiated ways identify predict job candidates successful outperform candidates deception enforcement ground ftc company makes claims quality products services whether products related law requires statements supported verifiable finally ftc use unfairness authority target algorithmic injustice unfairness prong ftc act prohibits conduct causes likely cause substantial injury consumers injury reasonably avoidable consumers outweighed countervailing benefits consumers number factual predicates could give rise unfairness claim connection algorithmic harms example secretly collecting audio visual sensitive individual feed algorithm could give rise unfairness addition algorithm used exclude consumer benefit opportunity based actual perceived status protected class conduct could also give rise unfairness ftc aggressive use unfairness target conduct harms consumers based protected status unfairness imperfect tool introducing hurdles reasonable avoidability countervailing benefits already complicated question specific injury caused disparate outcomes limitations mean however ftc unfairness see supra note see complaint ftc vizio see jillson supra note algorithms economic justice rebecca kelly slaughter authority used combat fundamentally unfair phenomenon unlawful discrimination well algorithmic harms discussed vigorous enforcement ecoa fcra ftc also enforces two laws afford protections related extension credit credit information relevant consumers navigating algorithms related credit first ftc enforces equal credit opportunity act prohibits credit discrimination basis race color religion national origin sex marital status age applicant receives income public assistance good faith exercised right consumer credit protection everyone regularly participates credit decision including setting terms credit arrange financing real estate brokers must comply ecoa antidiscrimination framework creditor uses proxies determine consumers target credit proxies correlate see generally fed trade comm big data tool inclusion exclusion ftc prove violation ecoa antidiscrimination protections plaintiffs typically must show disparate treatment disparate disparate treatment occurs creditor intentionally treats applicant differently based protected characteristic disparate impact hand occurs company employs facially neutral policies practices disproportionate adverse effect protected company practices legitimate business need reasonably achieved means less disparate impact even evidence shows company decisions justified business necessity less discriminatory alternative decisions may still violate ecoa see fed trade comm big data tool inclusion exclusion supra section part proxy discrimination yale information society project yale journal law technology vol protected class membership creditor may violating ftc investigate conduct appropriate vigorously pursue enforcement addition enforcement one useful approach would encourage creditors make use ecoa exception permits collection demographic information test algorithmic outcomes regulation implements ecoa presumptively prohibits collection demographic information unlike regulation implements home mortgage disclosure act hmda generally requires collection demographic data mortgages result rules mortgage credit monitored closely way demographic information credit supposed unmonitored benevolent idea behind ecoa course lending would eliminate gender race disparities case experience shows gender race disparities substantially persist often proxy believe mortgage data kinds credit monitored creditors consciously disparities basis protected status regulation already contains exception permits collecting demographic data purpose conducting defined inquiry designed used specifically determine extent effectiveness creditor compliance act short ecoa permits ftc example company made credit decisions based consumers zip codes resulting disparate impact members protected class ftc could challenge practice ecoa see andrew smith using artificial intelligence algorithms ftc apr see supra section part proxy discrimination regulation sets various requirements see generally algorithms economic justice rebecca kelly slaughter encourage creditors collect demographic data borrowers use test algorithmic systems reduce vanishingly creditors take advantage exception know case speculate perhaps fear collection data validate exacerbate claims decisions biased words creditor visibility demographics might seen crediting existence bias perspective line idea creditors often find much easier never ask race gender use enforcers private plaintiffs generally must credit bayesian improved surname geocode algorithm proxy race national origin gender datasets borrowers disparities collection demographic data purpose sign bias long clear data actually used purpose enforcers see responsive changes results tests strong sign efforts legal compliance lack indifference alarming credit disparities course creditors collect data conduct must able show also using impermissible purposes marketing ftc also enforces fair credit reporting act applies consumer reporting agencies cras compile sell consumer reports containing consumer information used expected used credit employment insurance housing similar decisions consumers eligibility certain benefits transactions see grace abuhamad fallacy equating blindness fairness ensuring trust machine learning applications consumer credit mit may miranda bogen aaron rieke shazeda ahmed awareness practice tensions access sensitive attribute data antidiscrimination proc conf fairness accountability transparency see marc elliott using census bureau surname list improve estimates associated disparities health servs outcomes res methodology yale information society project yale journal law technology vol currently fcra provides several important protections consumers ecoa companies rely consumer report information making credit housing decisions must provide adverse action notices following negative example housing application denied notices tell consumers right see information reported dispute inaccurate fcra also requires cras apply reasonable procedures ensure maximum possible accuracy preparing consumer reports several companies provide tenant screening services including using automated faced serious consequences allegedly failing adhere standard recent ensuring accuracy program inputs particularly important companies adopt even complex platforms including driven still research needed understand limitations adverse action notices ecoa fcra providing sufficient information consumers application denials particularly context complexity algorithmic see also smith supra note fcra adverse action requirements would apply vendor cra see ftc realpage tex see united states appfolio realpage see smith supra note consumer financial protection bureau also exploring issues recently held tech sprint aimed improving consumer adverse action notices see albert chang tim lambert jennifer lassiter cfpb first tech sprint october help improve consumer adverse action notices consumer fin protection bureau blog patrice alexander ficklin tom pahl paul watkins innovation spotlight providing adverse action notices using models consumer fin protection bureau blog july algorithms economic justice rebecca kelly slaughter poses unique challenges expanding requirements example broader reporting existence correction errors rates adverse action notices volume nature error also help mitigate problems arise algorithmic providing visibility effects decisions significant limitation adverse action notice consumer access information negative outcome making difficult know systematic denials taking place across protected coppa ftc also enforces used protect children certain data abuses law empowers ftc write rules mandate disclosures websites directed children prohibit website operators coercing children disclose excessive data require website operators use certain safeguards protect children ftc currently reviewing coppa rule addition hosting workshop agency requested public comments help inform effort producing much thoughtful substantive interested readers see andrew selbst solon barocas intuitive appeal explainable machines fordham rev sandra wachter brent mittelstadt chris russell counterfactual explanations without opening black box automated decisions gdpr harv tech louise matsakis fair algorithm actually look like wired see selbst barocas supra note see also supra note see federal trade commission future coppa rule ftc workshop ftc fed trade comm request public comment federal trade commission implementation children online privacy protection rule july yale information society project yale journal law technology vol see federal register notice get sense questions section ftc act another tool ftc disposal ability write reports informed studies conducted section ftc provision gives ftc opportunity study depth algorithms related technologies deployed effectively adapt combat harms provision also empowers commission require entity file annual special reports answers writing specific questions provide information entity organization business conduct practices management relation corporations partnerships addition collecting information request public comment federal trade commission implementation children online privacy protection rule fed reg proposed july see fed trade comm order file special report ftc matter report study advertising practices products see fed trade comm order file special report ftc matter apr report study advertising practices alcoholic beverages reporting requirements potential focus corporate attention resources issues previously neglected also provide information allows consumers firms investors encourage advocacy consumer spending investment improve practices see california transparency supply chains act cal civ code requiring businesses disclose efforts eradicate slavery human trafficking direct supply chains directive european parliament council october amending directive regards disclosure diversity information certain large undertakings groups requiring companies meeting certain criteria publish information social environmental practices algorithms economic justice rebecca kelly slaughter specific businesses ftc also collect information study social media services discussed one exciting use important ftc continue use authority deepen expertise use impact algorithms modern economy focusing potential harms consumers whether enforcement industry studies agency always strives keep pace emerging technologies changing particularly given scale opacity rapid proliferation algorithmic economy room improvement specifically agency needs resources broader range expertise improved accountability space requires sophisticated understanding underlying technologies business models employ ftc could effectively study hold companies accountable could hire additional staff including would expand agency analytical framework technologists market specialists increased capacity would support effective systematic investigations data abuses including perpetrated algorithms including sustainability treatment employees respect human rights diversity company boards see fed trade comm patent assertion entity activity ftc study broadly studying patent assertion entities industry around see supra section part end surveillance capitalism subsection states localities also studying harms associated algorithms foreign counterparts see competition markets authority supra note state artificial intelligence policy elec privacy info last visited mar identifying three states one city conducting studies see supra section see also jillson supra note yale information society project yale journal law technology vol new legislative regulatory solutions addition comprehensively aggressively using enforcement tools currently ftc disposal also worth considering gaps authority addressed legislative regulatory solutions fortunately many academics advocates policymakers across around grappling questions section identifies elements promising legislative regulatory solutions powerfully complement tools described guiding principles many harms seem novel analogs algorithmic presents special risks simultaneously obscure problems amplify giving impression could possibly exist reasons others believe viable system addressing algorithmic harms require minimum three critical principles transparency fairness accountability nearly every problematic example unclear precisely inputs decisions produced biased otherwise harmful outcome proprietary algorithmic models often cloaked secrecy limited human frustration opacity black box lead consumers feel powerless time patina neutral technology making decisions leads sense deployers developers bad algorithms responsible results combination obscurity widespread application see supra section see danielle keates citron frank pasquale scored society due process automated predictions rev see jennifer cannon report shows consumers trust artificial intelligence fintech news algorithms economic justice rebecca kelly slaughter complicated facially neutral technology provides false sense security objectivity algorithmic increasing transparency lifts curtain opaque processes longtime staple regulatory transparency requires developers deployers algorithmic systems make sure automated decisions explainable defensible possible benefit sunlight advocates academics third parties widely test discriminatory harmful transparency companies data practices also enable consumers vote cases transparency may empower consumers advocates challenge incorrect unfair outcomes type transparency effectively incorporated regulatory framework european union general data protection regulation gdpr example anchors protections increased transparency requirements gdpr use automated individuals including profiling produces legal similarly significant effects triggers certain obligations data controllers must give individuals specific information process must take steps prevent errors bias discrimination gdpr also gives individuals right challenge request review referred right louis brandeis people money bankers use work already ongoing dependent accessibility data see rebecca kelly slaughter acting chair fed trade comm protecting consumer privacy time crisis remarks future privacy forum commission regulation art state illinois recently passed law seeks introduce similar transparency certain hiring decisions artificial intelligence video interview act ass enacted requiring employers notify applicant may used analyze applicant video interview consider applicant fitness position provide applicant information yale information society project yale journal law technology vol effective transparency however must provide meaningful intelligible information simply overwhelm user information trigger decision fatigue effects extensive notice provisions privacy laws like gdpr must studied carefully ensure fall former latter category result frequent notices nudge user simply accepting practice informed opportunity exercise choice nominal transparency may benefit whatsoever addition requiring transparency must also endeavor even better discriminatory applications algorithms context fairness sometimes difficult action multiple jurisdictions reflects understanding addressing discrimination critical framework regulating example issued guidelines list seven key requirements systems meet trustworthy including transparency diversity nondiscrimination fairness united states biden administration already taken steps encourage federal government prioritize explaining works general types characteristics uses evaluate applicants obtain consent applicant evaluated see also online privacy act cong establishing right human review automated decisions see ninareh mehrabi survey bias fairness machine learning acm computing surveys july osonde osoba algorithmic equity framework social applications rand example nondiscrimination core element european commission recently proposed regulations algorithms see commission proposal regulation european parliament council laying harmonised rules artificial intelligence artificial intelligence act amending certain union legislative acts com final apr see expert group artificial intelligence ethics guidelines trustworthy eur commission see also expert group artificial intelligence assessment list trustworthy artificial intelligence altai eur commission july algorithms economic justice rebecca kelly slaughter increase transparency equity accountability executive prioritizing transparency fairness necessary sufficient regulation algorithmic must also involve real accountability appropriate remedies increased accountability means ones benefit advantages efficiencies bear responsibility conducting regular audits impact assessments facilitating appropriate redress erroneous unfair algorithmic decisions principles transparency fairness accountability inform much ftc enforcement work implicates algorithmic given breadth depth algorithmic harms described principles also animate ftc rulemaking section congressional action section rulemaking initiative ftc already possesses means address algorithmic harms basis rulemaking authority section ftc act added trade commission improvement tool see exec order fed reg july exec order fed reg values also espoused relation omb memorandum executive departments previous administration document set forth ten principles agencies weigh considering regulatory approaches design development deployment operation applications one key principles fairness specifically omb advised agencies consider whether application issue may reduce levels unlawful unfair otherwise unintended discrimination compared existing see memorandum russell vought director office mgmt budget heads executive departments agencies pub stat yale information society project yale journal law technology vol conjunction help advice experts empowers ftc address harms prospectively passage ftc rulemaking procedures diverged sister agencies beginning ftc promulgated trade regulation rules using procedures established administrative procedure act apa efforts shrouded questions whether ftc act delegated authority agency promulgate binding provided definitive legislative affirmation ftc rulemaking procedures required issue rule section cumbersome apa statute requires additional steps advance period special notifications congress informal hearings consider disputed issues material fact among logistical challenges insurmountable initially commission successful note federal trade commission modes administration harv rev see unfair deceptive advertising labeling cigarettes relation health hazards smoking fed reg july requiring cigarette labels advertising clearly disclose health hazards smoking note congress eventually intervened statute supplant ftc regulation federal cigarette labeling advertising act modes administration supra note legal questions ultimately decided agency favor see nat petroleum refiners ass ftc cir oversight hearings fed trade comm consumer protection subcomm comm government operations cong statement paul rand dixon acting chairman fed trade comm note much ftc ability make rules falls section congress granted ftc ability promulgate rules standard apa procedures discrete arenas see granting rulemaking authority regulate use made made america labels authorizing rulemaking authority regulate motor vehicle dealer algorithms economic justice rebecca kelly slaughter promulgating rules section resulting variety rules protect recent years however commission shied away extensive section new democratic majority commission already taken action make section rulemaking viable bringing commission procedures line statutory requirements congressional intent first open meeting several decades commission adopted changes rules practice remove procedural hurdles section changes help unlock section rulemaking term procedural prison allow commission see advertising ophthalmic goods services fed reg july successful section rulemaking regulating provision ophthalmological goods services commission initiated dozen new rulemakings five years following passage miles kirkpatrick bar ass report american bar association section antitrust law special committee study role federal trade commission see kurt walters ftc rulemaking existing authorities recommendations july revisions rules practice fed reg july statement commission regarding adoption revised section rulemaking procedures fed trade comm july press release fed trade comm ftc votes update rulemaking procedures sets stage stronger deterrence corporate misconduct july changes show ftc turning page decades returning participatory dynamic process issuing section rules congress envisioned clear rules help honest businesses comply law better protect consumers workers bad actors also lead substantial deterrence due significant civil penalties rulebreakers streamlined procedures section rulemaking means commission ability issue timely rules issues ranging data abuses dark patterns unfair deceptive practices widespread yale information society project yale journal law technology vol fulfill statutorily directed mission one important area commission attention data clear rulemaking target conduct otherwise violate law words ftc proscribe rule conduct could pursue enforcement ftc act value rulemaking clarifies boundaries law markets prohibited conduct exclusively identified enforcement actions take place harm already occurred threats consumers arising data including posed algorithmic harms mounting urgent imperative ftc take action within existing authority protect consumers authority includes section rulemaking although slow imperfect available help better protect consumers least initiating rulemaking would significantly advance public debate targeted study thoughtful commentary nuanced proposals see exec order fed reg july recommending commission exercise statutory rulemaking authority areas unfair data collection surveillance practices may damage competition consumer autonomy consumer privacy see supra section rebecca kelly slaughter commissioner fed trade comm near future privacy law remarks silicon colorado law school rather simply thinking narrowly data privacy want thinking terms data abuses broadly privacy generally refers limits collection sharing data individual would prefer keep private separate problems involving collecting data individuals problems involving targeting information individuals decisions made individuals often based collected data rebecca kelly slaughter commissioner fed trade comm ftc data privacy enforcement time change keynote address nyu law school program corporate compliance enforcement algorithms economic justice rebecca kelly slaughter area algorithmic justice section rule might affirmatively impose requirements transparency fairness accountability noted easy endeavor require input activism interested strongly urge attorneys technologists state attorneys general academics advocates policymakers stakeholders help ftc craft rules address urgent rule could way accounts context relative risk charting new path better protect legislative proposals finally legislatures could craft solutions problem implementing necessary transparency accountability framework hold developers deployers algorithmic accountable congress state legislatures presently considering bills passed could make meaningful difference regulatory landscape several legislative proposals specifically address types transparency accountability requirements discussed algorithmic accountability act one comprehensive proposed bill would impose number new requirements companies using automated mandating assess use automated decision systems including training data impacts accuracy fairness predicate section rulemaking commission must reason believe unfair deceptive acts practices subject proposed rulemaking prevalent ftc accepts rulemaking petitions public see petition rulemaking concerning use artificial intelligence commerce electronic privacy info ctr strongly encourage individuals groups proposals submit office secretary rebecca kelly slaughter acting chair fed trade comm keynote remarks consumer federation america virtual consumer assembly may algorithmic accountability act cong yale information society project yale journal law technology vol bias discrimination privacy security evaluate information systems protect privacy security consumers personal information correct issues discover impact assessments proposed bill also authorizes ftc create rules requiring companies jurisdiction conduct impact assessments highly sensitive core insight proposed bill required impact assessments vigilant testing iterative improvements fair necessary cost outsourcing decisions algorithms addition congress currently contemplating federal privacy law privacy legislation may seem directly applicable problems discussing today fact play important role addressing algorithmic worth noting requirements imposed europe done part privacy law gdpr vocal advocate federal privacy believe bill incorporate specific protections including civil rights provisions limit dangers algorithmic bias require companies proactive avoiding discriminatory outcomes privacy bill proposed senator cantwell several colleagues consumer online privacy rights act includes civil rights provision seeks accomplish type broader bill prohibits processing transfer see hearing oversight fed trade comm comm commerce science transportation cong statement commissioner rebecca kelly slaughter fed trade comm rebecca kelly slaughter commissioner fed trade comm near future privacy law remarks silicon colorado law school see consumer online privacy rights act cong algorithmic justice online platform transparency act also provides strong civil rights provisions building upon transparency requirements algorithmic accountability act adding civil rights protections algorithms economic justice rebecca kelly slaughter data basis individual actual perceived protected status purpose marketing manner unlawfully discriminates otherwise makes opportunity unavailable individual class proposed bill also prohibits processing transfer data manner unlawfully segregates discriminates otherwise makes unavailable goods services facilities place public accommodations history teaches substitute strong civil rights laws outlaw discrimination outright finally alongside federal efforts great laboratories likely continue propose adopt innovative similar consumer online privacy rights act see algorithmic justice online platform transparency act cong consumer online privacy rights act protects wider range classes civil rights laws protected classes include actual perceived race color ethnicity religion national origin sex gender gender identity sexual orientation familial status biometric information lawful source income disability see consumer online privacy rights act cong example california consumer privacy act ccpa passed came effect various rights protections residents country populous state cal civ code california privacy rights act cpra via ballot proposition going effect expands ccpa also establishes dedicated state privacy enforcer california privacy protection agency proposition california privacy rights act cal sec state official voter information guide also noteworthy illinois biometric information privacy act bipa imposes range requirements companies collection retention biometric information comp stat despite decade old bipa continues highly relevant targets practice increasing prevalence sophistication example facial recognition buttressed private right action allows private litigation complement enforcement efforts enforcers yale information society project yale journal law technology vol conclusion growth algorithmic presents immense opportunity risk society algorithms could promote economic justice helping distribute opportunities broadly resources efficiently benefits effectively article documents perilous potential algorithms amplify injustice simultaneously making injustice less detectable developers create algorithms faulty inputs flawed conclusions fail test models rely proxies foster often exacerbate discrimination create powerful engines monetize attention surveil consumers manipulate behavior without regard societal consequences deployment algorithms also imperils competition left unaddressed algorithmic flaws repeatedly systematically harm consumers harms often felt acutely already vulnerable historically disadvantaged populations especially black americans communities color ftc tools still capable addressing problems posed algorithms algorithmic shares many features problematic innovations generations past agency must deploy section ftc act fcra ecoa coppa section studies creatively mitigate algorithmic harms confronting challenges algorithmic also require new tools strategies also may certain applications algorithms pose profound risk injustice vital life functions opportunities moratorium might appropriate necessary society goal urgent achievable collaboration study creativity limit downside risks algorithms without unduly constraining upside rewards need consider applications tailor enforcement policy responses appropriately algorithms economic justice rebecca kelly slaughter acknowledgements would like thank many colleagues experts generously helped article take shape insights contributions especially grateful austin king david berman many substantive contributions expert research assistance keen questioning deft wordsmithing would like thank caroline holland synda mark gaurav laroia tori finkle elena goldstein rita xia elise phillips maggie yellen chris suhler josh banker particularly lucky access rich expertise patient support many colleagues throughout federal trade commission office policy planning bureau consumer protection bureau competition bureau economics office general counsel office international affairs office chief information officer presidential innovation fellows shared time wisdom particular effort greatly benefited generous insightful engagement aaron alva josephine liu richard gold special thanks andrew burt yale information society project well ben rashkovich spurthi jonnalagadda colleagues yale journal law technology careful edits thoughtful guidance finally must acknowledge efforts office greatly enhanced administrative moral support kristin greer joint publication information society project yale law school yale journal law technology information society project yale law school yale journal law technology publication available open access attribution sharealike igo igo license digital future whitepaper series made possible thanks support immuta ideas opinions expressed whitepaper authors reflect views yale law school federal trade commission organizations including sponsors author rebecca kelly slaughter commissioner united states federal trade commission views expressed article necessarily reflect views federal trade commission commissioner janice kopec attorney advisor office commissioner slaughter mohamad batal honors paralegal office commissioner slaughter contributed article digital future whitepaper series digital future whitepaper series launched venue leading global thinkers question impact digital technologies law society digital future whitepaper series led isp visiting fellow andrew burt isp executive director nikolas guggenberger visiting fellows artur pericles lima monteiro nabiha syed spurthi jonnalagadda yale law school served research assistant whitepaper information society project information society project isp intellectual center yale law school founded professor jack balkin past twenty years isp grown handful people gathering discuss internet governance international community working illuminate complex relationships law technology society yale journal law technology yale journal law technology yjolt law review yale focused interaction law technology law review yale law school offer fully interactive publication environment yjolt publishes articles related law technology semiannually ben rashkovich yale law school served yjolt editor special publication wall street new
