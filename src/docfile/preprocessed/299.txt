responsible use public policy data science toolkit felipe gonzález teresa ortiz roberto sánchez ávalos responsible use public policy data science toolkit copyright banco interamericano desarrollo esta obra encuentra sujeta una licencia creative commons igo puede ser reproducida para cualquier uso otorgando reconocimiento respectivo bid permiten obras derivadas cualquier disputa relacionada con uso las obras del bid que pueda resolverse amistosamente someterá arbitraje conformidad con las reglas cnudmi uncitral uso del nombre del bid para cualquier fin distinto reconocimiento respectivo uso del logotipo del bid están autorizados por esta licencia requieren acuerdo licencia adicional note que enlace url incluye términos condiciones adicionales esta licencia las opiniones expresadas esta publicación son los autores necesariamente reflejan punto vista del banco interamericano desarrollo directorio ejecutivo los países que gonzález teresa ortiz roberto sánchez ávalosresponsible use public policy data science toolkit responsible use public policy data science development bank social sector social sector multidisciplinary team whose actions based conviction investing people improve lives overcome development challenges latin america caribbean together countries region social sector formulates public policy solutions reduce poverty improve provision education work social protection health services objective build productive region equal opportunities men women greater inclusion vulnerable groups information see development bank idb lab idb lab innovation laboratory idb group financing knowledge connections mobilized catalyze innovation oriented towards inclusion latin america caribbean idb lab innovation powerful tool transform region creating unprecedented opportunities populations vulnerable situations due economic social environmental conditions information see organisation economic development oecd oecd international organisation works build better policies better lives goal shape policies foster prosperity equality opportunity together governments policy makers citizens work establishing international standards finding solutions range social economic environmental challenges one example oecd principles artificial intelligence first principles adopted governments principles promote innovative trustworthy respects human rights democratic values responsible use public policy data science policy observatory policy observatory inclusive hub public policy helps countries encourage nurture monitor development use trustworthy used policy makers stakeholders countries become recognised centre policyoriented evidence debate guidance supported strong partnerships actors stakeholder groups international organisations provides analysis unique source data visualisations developments also contains database policies countries allows governments compare policy responses develop good practices measures collective progress towards trustworthy network experts wonk blog facilitate collaborative policy discussions oecd work relevant specific application public sector accessed oecd observatory public sector innovation opsi provides overview measures implemented public sector including governance policy making public service design delivery fair lac initiative collaboration partners strategic allies interamerican development bank idb leads fair lac initiative promote responsible adoption artificial intelligence decision support systems improve social services delivery create development opportunities reduce social inequality toolkit part set documents tools guide technical teams policymakers towards end pombo lac responsible use public policy data science toolkitacknowledgements authors would like express special thanks cristina pombo coordinator idb fair lac initiative professor ricardo director data science northeastern university silicon valley campus member group experts experts fair lac time valuable contributions authors also grateful contributions karine perset administrator luis aranda policy analyst authors also appreciate support comments luis tejerina elena arias ortiz natalia gonzález alarcón tetsuro narita constanza daniel korn ulises cortés josé antonio guridi bustos cesar rosales sofia trejo responsible use public policy data science toolkittabla contenido acerca este material iniciativa fair lac qué este manual quién este manual introducción sistemas decisiones componentes sistema para políticas públicas retos del ciclo vida del conceptualización diseño definición correcta del problema respuesta política pública necesidad proporcionalidad fuente manejo datos calidad relevancia los datos disponibles información incompleta acerca población objetivo desarrollo los modelos ausencia errores validación fugas información clasificación probabilidades clases sub sobreajuste errores cuantificados evaluación humana equidad desempeño diferencial predictores uso monitoreo degradación desempeño experimentos recopilación datos rendición cuentas interpretabilidad explicación predicciones explicabilidad predicciones individuales trazabilidad cuadernillos trabajo fuente manejo datos desarrollo los modelos rendición cuentas herramientas referencias contents fair lac initiative executive summary toolkit toolkit key terms introduction machine learning systems components system public policies challenges machine learning life cycle planning design correct definition problem public policy response oecd principles data collection processing data quality relevance available data data qualification completeness target population model building validation absence inappropriate use validation samples data leakage classification models probabilities classes overfitting unquantified errors human evaluation fairness differential performance predictors deployment monitoring performance degradation experiments evaluate model effectiveness accountability interpretability explainability predictions traceability tools tool robust responsible checklist tool data profile tool model card workbooks data collection processing model building validation accountability references responsible use public policy data science toolkitexecutive summary finance insurance agriculture transportation artificial intelligence technologies diffusing apace sectors creating opportunities also raising distinctive policy issues public sector promises generate productivity gains improve quality public services analyzing social network activity real time policy makers example leverage systems obtain accurate assessment pressing societal problems needs outcomes predictions made systems inform policy formulation implementation evaluation backdrop governments around world equipping relevant technical skills leverage power support public policy development however given public policy significantly impact people lives wellbeing systematic approach needed ensure appropriate safeguards place seize opportunities address challenges posed use systems public policy teams using system lifecycle guiding framework analysis toolkit provides technical guidance public policy teams wish use technologies improve processes outcomes phase system lifecycle design data collection processing model building validation deployment monitoring toolkit identifies common challenges using public policy contexts outlines practical mechanisms detect mitigate challenges policy makers technical teams accountable proper functioning system phase lifecycle regard one chapter toolkit dedicated exploring issues use public policy outlining practical mechanisms addressing true objective promoting responsible use public policy making section toolkit includes checklists help guide practical implementation data profile tool model card also provided help assess data issues document system characteristics assumptions made risk mitigation measures implemented throughout lifecycle moreover toolkit provides section workbook containing practical examples challenges mitigation strategies covered report well relevant code implement using programming languages fair lac initiative policy observatory idb oecd partnered help move policy discussion principles practice implementation toolkit concrete step direction toolkit although significant number principles support ethical provide guidance developed little responsible use public policy data science toolkitclarity best practices putting principles operation vayena objective toolkit identify areas risk recommend mitigation measures avoid outcomes contrary aims outcomes include undesirable consequences wasting resources due inadequate targeting outcome undercuts seeking achieve toolkit toolkit intended technical teams working application machine learning algorithms public policy however covers challenges common applications technology assumed reader basic knowledge statistics programming although concepts introduced brief descriptions additional references included toolkit includes workbooks various examples challenges solutions discussed different types models linear others different implementations keras xgboost used show problems arise regardless choice particular tool algorithm although codes examples developed topics methodologies applied described toolkit implemented programming language key terms artificial intelligence system capable influencing environment producing output predictions recommendations decisions given set objectives uses machine data inputs perceive real virtual environments abstract perceptions models analysis automated manner machine learning manually iii use model inference formulate options outcomes systems designed operate varying levels autonomy adapted oecd algorithmic fairness mathematical representation specific definition fairness incorporated model selection fitting process important take account different definitions exclusive satisfying one could imply satisfying others verma rubin algorithmic inequality technical flaws models produce disparity results protected groups must evaluated context given definition algorithmic fairness systems related concept automated autonomous intelligence final decisions consequent actions made without direct human intervention system performs tasks previously done human many contexts systems referred automated systems decision support systems related concept assisted augmented intelli gence decision support systems generate information used input human toolkit intended regulate explain aims objectives bodies actors material toolkit reproducible according instructions repository contains dockerfile describing infrastructure dependencies replication programming language used along following packages tidyverse recipes themis rsample parsnip yardstick workflows tune knitr patchwork responsible use public policy data science machine learning set techniques allow system learn behaviors automated manner patterns inferences instead explicit symbolic instructions entered human oecd predictive structure types models used make predictions linear random forests neural networks algorithm parameters hyperparameters interactions probabilistic guarantees using samples designed randomization possible certain assumptions characterize behavior estimators procedures high probability example confidence interval performance metrics contains actual value observed subpopulations interest protected subpopulations subpopulations target population want concrete performance evaluations estimates models target population entire group people households geographical areas etc targeted specific policy responsible use public policy data science toolkitintroduction machine learning subset artificial intelligence machine learning methods increasingly used inform actions interventions various contexts business public policy service delivery practice methods used varying degrees success growing concern understand positive negative performance influence methods society barocas selbst suresh guttag machine learning systems organisation economic development oecd describes system system capable influencing environment producing output predictions recommendations decisions given set objectives uses machine data inputs perceive real virtual environments abstract perceptions models analysis automated manner machine learning manually iii use model inference formulate options outcomes systems designed operate varying levels autonomy adapted oecd figure stylised conceptual view system although machine learning methods type algorithms systems use ones seen growth recent years methods constitute set techniques allows system learn behaviors automated way patterns inferences instead explicit symbolic instructions entered human oecd toolkit discusses common challenges use machine learning technologies decision making decision support include detecting mitigating implementation errors biases evaluating possibility undesirable results company public sector institution society context environmentdata inputperceiving acting humans machineshumans machines outcome outputai modelai system responsible use public policy data science toolkittwo archetypes use machine learning process systems related concept assisted augmented intelli gence decision support systems generate information used input human systems related concept automated autonomous intelligence final decisions consequent actions made without direct human intervention system starts perform tasks previously done human many contexts systems referred automated systems wide variety techniques expert knowledge subject modelling general development successful support system based machine learning toolkit intended discuss particular machine learning methods specific tuning processes hastie tibshirani friedman kuhn johnson gelman hill rather focus evaluation methods important challenges shared across systems regardless type algorithm technology used evaluation machine learning system carried basis questions maximum error rate tolerated unacceptable biases considered answered within specific context application includes purposes motivations well risk end users stakeholders words many technical criteria pertain specific problem hand biases limitations support systems known even system low precision useful used responsibly hand system limitations understood even systems lead unintended consequences misuse objectives toolkit focuses subset challenges related technical processes throughout lifecycle systems used decision support toolkit describes different biases deficiencies caused training data problems decisions development model validation monitoring process produce undesirable biased results process two types systems generic necessarily use machine learning also systems interactive learn dynamically using reinforcement learning techniques toolkit consider systems responsible use public policy data science toolkitcomponents system public policies systems public policy life cycle replace public policy making function assist public policy development cycle providing information public policy cycle made following stages identification problem every project begin correctly identifying issue public policy seeks address along possible causes consequences issue policy formulation intervention policy considered applied certain people units processes formulated generally assume evidence benefit policy applied target population support system intervention defined cycle begins design development support system result used focus guide intervention chosen previous stage oecd forthcoming policy implementation public policy implemented either pilot project larger scale policy evaluation effectiveness reliability cost expected unintended consequences relevant characteristics policy measure evaluated results positive intervention continued scaled parallel public policy making cycle development system lifecycle includes following stages oecd planning design data collection processing iii model building validation deployment monitoring phases usually take place iteratively necessarily sequential figure figure public policy lifecycle supported support system source prepared authors used different ways including recognition event detection forecasting personalization interaction support optimization reasoning knowledge structures combination embedded composite system driverless vehicle problem accountabilityii data collection processing iii model building validationiv verification validationi planning design evaluación public policy life cycle implementación políticapolicy formulation support systemai life cycle responsible use public policy data science toolkitin interrelation two cycles important challenges generated evaluated considered development use robust responsible systems challenges machine learning life cycle construction robust responsible decision support systems requires careful consideration possible sources bias investigation deficiencies documentation assumptions clear definition algorithmic fairness objectives criteria system must meet understanding limitations tolerable errors specific context system implementation monitoring measures avoid undesirable biased results achieve toolkit presents common challenges mistakes building applying machine learning methods system lifecycle common problems mechanisms detect suggestions mitigate described according stage system life lifecycle planning design refers information criteria public policy necessary conceptualize project data collection processing focuses data generation process selection control data sources identification mitigation deficiencies biases data model building validation includes key principles methods building robust correctly validated models deployment monitoring evaluation model production monitoring key principles avoid unexpected degradation addition accountability dimension system lifecycle refers explanatory measures promote understanding mechanisms system produces output output reproducibility user capacity identify challenge errors unexpected results actors stage lifecycle accountable proper functioning system based roles context consistent state art three tools proposed accompany development system tool robust responsible checklist tool consolidates main concerns stage life cycle checklist must reviewed continuously technical teams tool data profile tool initial exploratory analysis data collection processing stage lifecycle provides information reassess quality completeness temporality consistency well possible biases potential damage implications use system tool model card tool final description system reporting main assumptions important characteristics well risk mitigation measures implemented see instance oecd good practice principles data ethics public sector specific principle systems data available responsible use public policy data science toolkit box sources bias system bias poses one pressing challenges throughout lifecycle many mitigation measures considered model development depend correct understanding treatment biases problem bias addressed early development process implementation review points different stage lifecycle review point experts end users corresponding system invited verify defend hypotheses made stage validate results model following concepts important explain system error difference predicted value resulting model real value variable error systemati cally one direction specific subset data specific subpopulation called bias example variable value consistently lower one subgroup data salary women respect equally qualified men equivalent job salary variable biased conversely error random called noise bias system ethical implications results used formulate public policies considered unfair prejudicial certain subgroups population assessment bias subject specific algorithmic fairness definition determined public policy algorithmic fairness definition mathematical representation public policy objective incorporated model selection fitting process defini tion task public policy technical teams modelling team carry validations ensure compliance section toolkit different definitions algorithmic fairness implications discussed depth example cases objective system may bound criteria demographic parity equality possibilities representation quotas among many criteria occasions compliance one definition algorithmic fairness makes impossible comply another partially totally exclusive different sources bias biases intrinsic data including historical biases undesirable states patterns replicated model representation bias occurs incomplete infor mation due either missing attributes sample design total partial absence data subpopulations measurement biases arise omission inclusion variables included model suresh guttag biases appear due methodological errors example biases arise training due errors validation processes definition metrics evaluation results evaluation bias biases arise due erroneous assumptions target pop ulation may affect definition model biases arise due misuse monitoring models whether inappropriate interpretations results temporary changes patterns real world ture methods throughout different sections toolkit main reasons biases presented different measures mitigate proposed prediction models variance bias captured model learning generalization goal models high bias create systems learn little observed data models high variance opposite effect perfectly learning training data model building vali dation section toolkit describes phenomena greater detail measures mitigate corresponding risks responsible use public policy data science toolkit source based figures suresh guttag generationhistorical biasrepresentation biasmeasurement bias implications real worldevaluation bias population selectioncollection training evaluation validationmodel data population responsible use public policy data science toolkit planning design responsible use public policy data science toolkit responsible use public policy data science planning design implementation solution considered separately public policy results system good design public policy intervention system embedded tool substitute public policy implies projects employ robust responsible must start definition problem technology correct definition problem public policy response toolkit assumes least two types actors involved development system policy maker decision maker technical team develops implements system definition public policy always responsibility knowledge social dynamics issues technical team must able understand problem able orient results model towards satisfying goal desired intervention likewise technical team responsible advising guiding design system explaining feasible clearly delineating system limitations risks constant communication technical team required instance definition population system applied protected groups protected attributes algorithmic fairness measures applied need discussed understood sets definitions direct impact quality coverage data well quality model results assessed oecd principles although significant potential streamline processes expand state capacity also noted silver bullet problem type intervention defined necessary contextualize rethink use machine learning line oecd principles box important consider broader governance frames application system including standards laws jurisdiction system implemented also important establish appropriate requirements planning design system define narrow development options technical team example explainability requirements predictions could limit use algorithms difficult interpret see section entitled components system public policies introduction toolkit section toolkit discusses different definitions algorithmic justice implications depth concept explainability described section toolkit responsible use public policy data science toolkit box oecd principles organisation economic development oecd principles promote use artificial intelligence innovative trustworthy respects human rights democratic values principles set standards practical flexible enough stand test time include five principles responsible stewardship trustworthy inclusive growth sustainable development wellbeing stakeholders engage creating credible contribute inducing outcomes beneficial people well planet values fairness values human rights democracy rule law incorporated throughout system lifecycle allowing human intervention safeguard mechanisms transparency explainability actors develop operate systems provide information foster overall understanding systems among stakeholders allows people affected systems comprehend outcome challenge decision needed robustness security safety systems need function appropriately throughout lifecycle actors ensure traceability apply systematic risk management approaches mitigate risks accountability actors developing deploying operating systems respect principles accountable proper functioning systems oecd principles also contain five recommendations national policies international cooperation investing research development fostering digital ecosystem shaping enabling policy environment build ing human capacity preparing labor market transformation promoting international cooperation trustworthy oecd principles adopted may oecd member countries first international standard signed governments beyond oecd members countries including argentina brazil costa rica malta peru romania ukraine singapore egypt already adhered principles adherents welcomed june adopted principles draw oecd principles responsible use public policy data science toolkit box planning design checklist correct definition problem public policy response qualitative public policy problem clearly defined qualitative describe problem currently addressed considering responses related institutions use would improve government response problem qualitative protected groups protected attributes identified within project age gender education level race level marginalization qualitative actions interventions carried based result system defined principles quantitative need system justified considering possible solutions require use personal data automated decisions quantitative evidence public policy action recommendation system result benefit people planet driving inclusive growth sustainable development qualitative implementation technologies similar previous projects reviewed quantitative considered minimizing exposure personally identifiable information anonymizing collecting information relevant analysis responsible use public policy data science toolkit data collection processing responsible use public policy data science toolkit responsible use public policy data science data collection processing plethora data sources used inform public policy censuses surveys administrative records web page usage logs even satellite images data become useful information describe target population phenomenon analyzed however data collected always frequency disaggregation coverage make relevant afford quality required used example surveys designed using probability sampling specify type analysis done design tend conducted infrequently thus may insuf ficient capture patterns data hand information administrative records data internet interaction social networks visits measurements web pages etc telephony calls gps location etc tend much higher frequency cases represent whole population always possible use data make decisions entire population statistical systems based data regardless whether supervised unsuper vised model implemented training data key machine learning system data quality qualification analyzed using criteria volume completeness validity relevance representativeness precision timeliness accessibility comparability interoperability different sources defining criteria precisely difficult context problem entails subtle idiosyncrasies relevance precision refer quality measurement usefulness inform decision timeliness refers fact data occur timeframe necessary inform problem analyzed accessibility comparability interoperability refer fact data extracted timely manner different data sources necessary consistency applied jointly section addresses challenges data collection processing related two common concerns machine learning data quality relevance available data data qualification completeness target population sections touch upon issues highlighted oecd good practice principles data ethics public sector regards data quality data qualifi cation good practice principles aim support public officials implementation data ethics digital government projects products services trust placed core design delivery public integrity upheld specific actions taken governments public organisations granular level public officials oecd data quality relevance available data machine learning algorithms capture observed patterns relationships data trained objective identify patterns new cases observed model training reason training data determines way stage recommended data profile see tool toolkit filled covered detail section concerns data domain structure included data profile responsible use public policy data science toolkit algorithm behave however available data always ideal every use case two main problems undesirable suboptimal states collected data bad correspondence ideal available variables undesirable suboptimal states collected data first challenge identify training data may captured undesirable states real world undesirable states include biases inequities lead harmful outputs certain subgroups population well pattern could considered suboptimal undesirable social policy point view example amazon experimented human resources recommendation system based supervised learning techniques model trained using database company candidate selection processes stored previous years database identified whether candidate accepted rejected job department system based assumption algorithm could capture good candidates reduce work human resources department making first selection candidates team taken account technology industry characterized predominantly male system tended recommend higher proportion men since men accepted positions historically creating bias seemed show men successful fact capturing bias box undesirable suboptimal states collected data checklist qualitative discuss possible historical social inequalities use case specialists field quantitative perform exploratory analysis available data model trained identify possible historical biases undesirable states poor correspondence ideal available variables public policy decisions made based definition one ideal target variables mind however ideal variables may may available accessible data many cases necessary use substitute proxy variables get closer ideal variable introduce types variables machine learning models may learning implicit biases may desirable example scholarship seeks benefit smartest students ideal variable run problem defining meant smart finding variable describe concept test assigns value using standardized test described proxy responsible use public policy data science toolkit variable intelligence however test measures dimensions intelligence underestimate intelligence people wilson ideal target variables clearly stated available variables must analyzed understand suitable used proxy ideal variable systematic biases must identified within context use examples health care system implemented algorithm predict medical care needs different patients case public policy wanted tool would preventively indicate patients high risk requiring medical care using historical information hospitals given ideal complication risk variable available algorithm used expenditure incurred patients illness proxy variable hypothesis sicker people would end spending medical treatment overcome disease obermeyer showed system racially biased underestimated number black patients need health care racial bias caused subpopulation spending average less money white patients using expenditure proxy risk complications showed healthier white patients appeared require healthcare sicker black patients case using health spending proxy need medical care inappropriate biased omitted variable economic inequality box poor correspondence ideal available variables qualitative ideal target variables clearly stated variables must analyzed understand suitable substitute target variable systematic biases validity proxy metric identified qualitative use selected response variable clearly justified purposes intervention data qualification completeness target population machine learning models used public sector intended generate information inform actions policies target population time data sources include entire population would case census subset sample available survey administrative database etc one seek develop extrapolations predictions estimates help probabilistic natural samples statistics sample subset cases individuals population two sampling possibilities probability sampling name given sample cases selected probabilistic design infer several possible models explain data deciding model use uncertain simple stratified cluster random responsible use public policy data science toolkitsample case predictions estimates applied target population evaluated precision probabilistic guarantees error ranges provided estimates quantities associated entire target population example national household survey probabilistic design generally consists definition stratification units random selection different levels primary secondary units household selected known probability even sample designed way households rural areas possible make inference entire population certain guarantees size estimation error natural samples natural sample occurs cases selected randomly flawed process partially derstood natural process case possible know happen apply policy resulting model general population possible construct error ranges predictions estimates using statistical methods probabilistic guarantees estimated quantities predictions unknown error models characteristics useful sample may apply target population situation may aggravated underrepresented protected groups see williams shows predictive values anemia may different different racial groups predictions developed one group may perform poorly another usual case type sample occurs particular subgroups population excluded flawed data capture mechanism selection bias case social networks phone call record data population without access internet smartphone excluded natural samples data result estimation prediction errors biases predictive structures different would observe target popula tion invalid models extrapolations supported data subsets population probability sampling would preferred method machine learning projects case possible understand exactly sampled rates rates related population rates however probability sample always possible mean natural samples useful since many cases source data available however important understand data come order take account limitations identify risks involved making decisions entire population typical case data samples come social networks user demographic composition differs substantially general population study united kingdom found average twitter facebook users considerably younger responsible use public policy data science toolkit general population likely higher levels education prosser mellon study data explain particularities affect results important element take account balanced samples terms popu lation characteristics neither necessary sufficient condition qualify database appropriate construction machine learning models example case information collected social networks sample contains percent men percent women tell anything type conclusions drawn data selection observations occurring probabilistic process could present bias dimension necessarily generalize total population box probabilistic natural samples checklist qualitative possible differences database population system developed analyzed use literature related topic information experts study particular unmeasured selection biases quantitative although models built various data sources designed natural validation ideally carried sample allows statistical inference target population validation sample must appropriately cover target population interest missing incomplete attributes many machine learning projects compromised poor data qualification collecting data real world samples common observations missing data observations attributes available missing incomplete attributes phenomenon significant effect conclusions drawn data one hand crucial information units unknown result models poor performance little utility absent information might also associated relevant characteristics units want predict missing observations different imputation methods implemented important explore reasons censorship mechanism behind missing values literature three main assumptions rubin missing completely random mcar occurs probability missing observations censorship fault occurs totally randomly missing random mar occurs missing values depend values variable takes relationship missing values observed data individual missing random mnar occurs missing values depend values variable takes unobserved data example people higher income tend disclose income income surveys responsible use public policy data science toolkit box missing incomplete attributes checklist qualitative analysis missing values missing variables performed qualitative important omitted variables associated measurements identified qualitative reasons missing observations identified quantitative imputation processes evaluated terms sensitivity assumptions data preferably multiple imputation methods used assess imputation uncertainty little rubin buuren causal comparison humans rationalize world try understand terms cause effect understand something happened alter behavior change future outcomes machine learning model give results seem describe causal relationships necessarily exist lead inadequate policies wrong econometric techniques randomized controlled trials natural experiments methods instrumental variables used assess causality control phenomena selection bias endogeneity due omitted variables among others recent years works athey machine learning algorithms begun introduce experimental techniques processes like testing started used broadly digital contexts facilitate creation large experiments internet however cases machine learning algorithms seek describe causal relationships necessary careful type use algorithms stuart box causal comparison checklist qualitative understand describe reasons response variable correlated known unknown variables describe possible biases based expert knowledge analysis qualitative case work done ensure causality results limitations results explicitly communicated public policy quantitative case attempting causal inference models hypoth eses considerations methods used support causal interpretation must described robustness checks conducted documented activity filling data profile see tool recommended data collection processing stage lifecycle end stage recommended source data management section model card see tool filled discussion held public policy responsible use public policy data science toolkit model building validation responsible use public policy data science toolkit responsible use public policy data science model building validation process developing model involves making many decisions implications model results several types methodological decisions flawed may lead errors generate biases prevent system generalizing results adequately another group decisions conceptual nature substantially change way system behaves choose two models type errors report definition algorithmic justice choose discussed beginning toolkit none questions make sense outside context system specific application however possible create framework understanding errors discussed technical teams public policy absence inappropriate use validation samples machine learning models primarily trained create predictions unobserved cases useless evaluate system terms prediction performance regarding observations trained since system could memorize system usefulness lies extent make correct predictions using data outside training set validation generally involves least two data samples training validation preferably three figure training data subset data used train model validation data subset data training evaluated iteratively test data subset data kept hidden model selected used confirm results avoid random partition training validation data favors hinders evaluation generally carried consists dividing data pieces calculating average evaluations validation data pieces remaining training data called evaluation usually chosen figure evaluation stages source prepared authors phenomenon related overfitting discussed model validation datasettuning validation dataset confirmation results test datasettrain model training datasetevaluation validation dataset responsible use public policy data science toolkit first challenge appropriate validation process case model results would represent training dataset performance metrics set used indicator potential behavior model new cases could overestimating performance successful validation also related quality criteria completeness representativeness information see section target population different represented data used training population might completely different behavior even evaluation process carried correctly box absence inappropriate use validation sample checklist quantitative validation test samples constructed properly consider appropriate size covering subgroups interest protected avoiding information leaks construction construction validation sample must produced sampling design allows inference target population lohr validation sample cover subgroups interest protected possible make inferences subpopulations includes appropriate sample sizes according sampling methodology lohr sample available essential analysis risks limitations natural sample conducted experts professionals know process generated sample data data leakage data leakage occurs information outside designed training dataset used creation model contaminating training dataset kaufman rosset perlich additional information modifies learning process casts doubt model validation way estimating production performance system occurs two ways contamination training sample receives data leaks test validation set target leakage inclusion feature going available model used production contamination contamination occurs part validation test samples used construction models training error often results unrealistic performance levels validation set model making predictions based observations seen error often occurs applying methodologies aggregate share information database composition individual observations example scaling variable creating averages counts etc processes performed splitting training validation dataset responsible use public policy data science toolkit box data leak checklist quantitative processing preparation training data avoid using validation test data way solid barrier must maintained training versus validation testing includes data recoding normalizations selection variables identification outliers type preparation variable included models also includes sample weights balances based target leakage error occurs model trained information available way quality model put production generally temporality data groupings subtle cases error difficult detect since variable present information updated retroactively example seen crime mortality statistics reports theft may take time reported authorities databases due bureaucratic administrative processes observed incidence period could systematically increase time passes example target variable available production may complete given certain lags inherent reporting phenomenon considered training data used already complete evaluation model may appear accurate production accuracy data significantly degraded box target leakage validation scheme replicate closely possible scheme predictions applied includes replicating temporary windows observation registration variables prediction windows groups data considering whether information available group prediction made whether would necessary predict new groups classification models probabilities classes machine learning supervised classification algorithms systems whose objective assign category class label new observations called binary classification target variable two classes classifying email spam spam multiclass classification two classes plant species identification algorithm imbalanced data classification problem imbalanced dataset occurs distribution observations across known classes equally distributed types datasets one classes many examples referred majority class one classes fewer observations referred minority classes groups less percent total observations later groups present considerable difficulties predictive models may little information responsible use public policy data science toolkit highly imbalanced data class predictors perform poorly never predict minority class even performance measures good notably always predict majority class accuracy equal percentage elements class examples consider million data points majority class minority class may good idea subsample negatives given fraction say percent negative data point consider million data points majority class minority class may impossible properly discriminate observations building validation sets makes situation worse validate predictive performance build model cases may best build model information gathered box class imbalance checklist quantitative make probability predictions instead class predictions probabilities incorporated subsequent decision process quantitative absolute number minority cases small difficult find appropriate information discriminate class data need collected minority class quantitative dominant class weighting cases avoid losing calibration successful strategy reduce data size training time without affecting predictive performance quantitative replicate minority class better balance classes quantitative machine learning techniques allow weight class different weight total weight class balanced arbitrary point classification problems recommended used instead classifying observation probable class output probabilistic classification algorithm probability distribution set classes methods provide information policymaker uncertainty regarding classification make decision whether observation classified positive negative technical team must choose threshold observation classified belonging class point often mistakenly accepted binary classifications default value many machine learning models decision responsible use public policy data science toolkit important implications made outside context problem hand important discussed selected taking consideration types errors implications box arbitrary point checklist quantitative using probabilistic classification algorithms suitable incorporate uncertainty regarding classification quantitative avoid standard probability points choose optimal interpretation predicted probabilities using receiving operating characteristic curve measures analyze errors adequateness assessment metrics classification problems points taken criteria related context decision constructed analyzing classification confusion matrix shown table table confusion matrix real positive negative predictedpositive true positive false positive negative false negative true negative errors classification model divided false positives false negatives false positive observation model incorrectly predicts positive class false negative observation model incorrectly predicts negative class performance measures combined different ways depending use case social policy objective commonly used metrics accuracy one used metrics evaluate classification models fraction predictions correctly made model precision fraction observations classified positive model actually positive sensitivity recall fraction positives observations model classified correctly accuracy precision sensivity responsible use public policy data science toolkit specificity fraction negatives observations model classified correctly context considered defining criteria assess classification models example model ranking prevalence fatal disease cost diagnos ing sick person disease false negative much greater cost sending healthy person tests false positive words depending application cost false negatives different cost false positives reason use analysis recommended since compares result model context criteria also misleading depending composition training evaluation database instance imbalanced data used accuracy percent actually mean significant model underperformance partial solutions issue include using measures combine precision sensitivity score curve help analyze true positives false positives context application box adequacy assessment metrics checklist qualitative implications different types errors specific use case correct way evaluate questioned qualitative limitations model clearly explained implies identi fying false positives false negatives implications system decision would life target population quantitative analysis system conducted compared status quo use decision support strategies possible overfitting generalization refers ability model perform accurately unobserved data training process generalization important data collected sample may incomplete noisy model fails generalize performs poorly usually due one following related phenomena figure overfitting occurs model memorizes particularities training data unable generalize unseen examples model complex available data tends capture characteristics part predictive structure often reflected model performs well training data poor performance validation dataset underfitting occurs model unable perform well training data generalize new data happens individual characteristics observations given little weight underfitted model tends ignore patterns predictive structure reflected systematic identifiable errors example systematic overprediction certain groups values input responsible use public policy data science toolkit figure overfitting source prepared author box underfit overfit checklist quantitative overfitting necessary methods refined moderate overfitting including methods regularization restricting functional space possible models using training data disturbing training data hastie tibshirani friedman quantitative underfit data protected groups sensitive variables reviewed verify undesirable systematic errors unquantified errors human evaluation many cases biases model captured chosen performance metrics example document search system performs well performance metrics may systematically return short documents producing biased results promotional documents reasons type bias range errors including miscalculated data attributes selecting attributes consider part problem failures measured model algorithms produce results escape lens validation metrics models may poor performance put production reasons include errors calculating predictions treatment data excludes important metrics make quality fair predictions absence metrics measure certain types errors difficult problem solve errors may directly measurable necessary discover biases errors outside technical evaluation context possible include additional evaluation metrics would capture problems fitted good fit overfitted responsible use public policy data science toolkit box unmeasured errors human review checklist qualitative human assessment conducted use case experts look known biases errors establishing monitoring schemes allow identi fication unmeasured errors biases recommended example panels reviewers used examine predictions consider whether reasonable panels must balanced terms user type expertise include necessary fairness differential performance predictors methods produce unfair discriminatory results subgroups population buolamwini gebru barocas selbst bolukbasi may caused aforementioned challenges including poorly designed sourcing handling data errors design model examples differential performance bias include different acceptance rates receiving benefits different groups detection errors human faces different depend ing race evaluation results decision support system carried taking account objectives may different even contradictory objectives point view machine learning problem example might sacrifice overall performance model improve performance model subgroup even though subgroup small compared population whole affirmative action correct existing social gaps although analysis ethical implications machine learning models relationship definition justice still open field study important strand literature seeks implement mathematical definitions fairness models describe impartiality towards subgroups ability make decisions mitigate unwanted outcomes algorithmic fairness inequality meant justice change according culture tradition also specific public policy project problem example certain cases policies seek social inclusion affirmative action diversity quotas reparation policies cases policies simply based regional territorial arguments criteria integrated design process analysis training data error evaluation process output system process separated two important stages terms protected attribute protected characteristic variable one model predictions meet certain fairness criterion one protected variable exist dataset age gender race responsible use public policy data science algorithmic fairness definition mathematical representation specific definition fairness incorporated model selection fitting process important take account different definitions exclusive satisfying one may imply satisfying others verma rubin algorithmic inequality technical flaws models produce disparity results protected groups must evaluated definition algorithmic fairness previously determined objective model developer establish clear guidelines avoid deficiencies model producing undesirable disparities subgroups protected variable gender race level marginalization necessary select definition algorithmic fairness advance following three definitions algorithmic justice among widely used although others defined depending particular problem objectives omission protected variables demographic parity two widely contested strategies groups protected variable ignore variable aim achieve demographic parity predictions first strategy intended eliminate possibility disparity including variable model approach usually fails solve problem typically attributes associated produce similar results even considered geographic area postal code socioeconomic level may important reasons include predictive models example case blood pressure variations racial groups terms predisposition high blood pressure lackland model evaluates risk heart attack would accurate appropriate includes variable second strategy demographic parity establishes segment protected class gender certain age ranges must obtain positive result proportion allocation school scholarships undesirable example wanted construct classifier certain disease would need consider possible women men affected differently however demographic parity objective must taken account building model equality opportunity concept equality opportunity hardt price srebro one less dependent objectives refers predictive performance across different groups defined protected variable verma rubin variable want predict prediction say prediction satisfies equality opportunity independent given true value means influence prediction know true value words belonging belonging protected group influence result classification predictors significantly deviate criterion likely produce disparities associated protected variable equality opportunity assumption responsible use public policy data science toolkit tive error rates subgroup similar instance binary classification models false positive false negative rates approximately equal example suppose want create system select recipients prestigious scholarship institution defines membership indigenous community protected variable simplicity assume takes two values indigenous indigenous predictor satisfies equality opportunity false positive false negative rates indigenous people people counterfactual justice measure considers predictor fair result remains value protected attribute modified introducing change race gender condition practice single algorithmic justice measure works problems cases seeking compliance one definition implies fully complying others choice made considering context reasons behind justified documented box algorithmic fairness inequality checklist qualitative identify protected groups attributes age gender race poverty level etc qualitative algorithmic fairness criterion used model defined experts quantitative protected attributes exist assessment must made far predictions deviate chosen algorithmic fairness definition quantitative must proper predictions necessary achieve chosen algorithmic fairness criterion quantitative case classification models points different subgroups adjusted achieve chosen algorithmic fairness criterion quantitative collect relevant information protected subgroups cases characteristics improve predictive performance minority groups end phase recommended model development sections model card filled discussion held public policy activity responsible use public policy data science toolkit deployment monitoring responsible use public policy data science toolkit responsible use public policy data science toolkit deployment monitoring machine learning methods used make decisions necessary monitor model performance variables used time monitor particular undesirable results may result user interaction systems evaluate data collection processing process improve performance evaluate results performance degradation performance model degrade time multiple reasons including machine learning models assume static relationship input output variables degrade quality predictions due changes underly ing relationships variables changes data collection methods methodological adjustments harm model performance example case administrative data ministry could change data collection processes digitize systems systematize data cleaning processing way makes given model obsolete model degradation also occurs interactive systems system users form closed feedback loop users interact elements decided system vice versa mitigate possible errors necessary monitor input variables relation model behavior update assumptions accordingly jointly domain experts behavior error metrics time also monitored including total positive negative rates disaggregated protected group variable interest distribu tion predictions time box performance degradation checklist performance degradation qualitative plan monitor performance model collection information time quantitative monitor various metrics associated predictions predefined subgroups including protected variables quantitative monitor drift variable distributions respect training set quantitative monitor changes data collection processing methodology may reduce quality predictions qualitative feasible fraction predictions examined humans scored according rubric scale variable interest responsible use public policy data science toolkit experiments evaluate model effectiveness data collection mechanisms maintain model designed way keeps model date reaching optimal performance improvements data collection process overall performance model could difficult assess without strong counterfactuals sense experimental tests type example used possible understand desirable undesirable consequences using model vaver koehler box experiments data collection checklist quantitative possible plan assign randomized status quo treatments units experimental designs make performance behavior comparisons sample results algorithmic regime quantitative identify unobserved variables seek ways measure possible model evaluate model performance using information end phase recommended use monitoring section model card filled discussion held public policy responsible use public policy data science toolkit accountability responsible use public policy data science toolkit responsible use public policy data science accountability regulations european union general data protection regulation gdpr define accountability requirement organizations put place appropriate technical organizational measures able demonstrate effectiveness requested although development technical standards norms systems still pending task community toolkit described main technical aspects measures avoid mitigate bias lifecycle however several challenges remain related social legal requirements use systems entails applications section reviews concepts interpretability explainability traceability systems interpretability explainability predictions interpretability concrete mathematical definition interpretability molnar generally refers degree human consistently predict model results kim interpretable model easier individual understand process led certain decision miller model high interpretability desirable social policy application criterion accountability becomes fundamental several reasons degree interpretability models used make decisions important technical perspective molnar learn problem including causal relationships achieve social acceptability use model detect potential biases algorithm debug improve models complex algorithms deep neural networks millions relationships parameters obtaining model interpretability algorithms still open field machine learning high interpretability necessary use intrinsically interpretable methods linear regression logistic regression decision trees recommended explainability individual predictions many cases may legally ethically necessary provide explanations model reached certain conclusions person granted loan someone qualify social program research areas computer vision natural language processing successful implementations usually developed highly complex models deep neural networks transparent underlying assumptions used reach given prediction carrillo cantú noriega european union example article gdpr describes right person challenge decision system especially automatic responsible use public policy data science toolkit area ongoing research several methods already exist increase explainability predictions molnar methods counterfactual explanations wachter mittelstadt russell shapley values lundberg lee integrated gradients deep networks sundararajan taly yan used box explainability individual predictions checklist qualitative legal ethical explainability requirements project context analyzed qualitative process place provide explanations particular individu als decision made qualitative pros cons algorithms discussed according level interpretability explainability order choose appropriate one quantitative simpler models linear decision trees explanations constructed quantitative deep neural networks use available methods counterfactual explanations shapley values integrated gradients parsimonious models widely held model always better covariates used partially correct model find patterns among interrelationship variables however interpretability taken account parsimonious methods use fewer relevant features preferable models use many perhaps less relevant features potential biases occur using data characteristics variables although valid given time dataset easily susceptible change process evolves algorithms predictive methods use many irrelevant attributes higher risk failing explicitly silently data sources processes change examples may use variables actively influenced policy continue future learning characteristics training set image recognition recognizing animal species context information collected zoo camera trap landscape type bias harms system explainability may difficult detect parsimonious methods expert knowledge mitigate risk responsible use public policy data science toolkit box parsimonious models checklist qualitative including available features build train model may increase risk disproportionately affecting users variables included learning process must theoretical support explanation help prediction task quantitative parsimonious methods use fewer relevant features preferable models use many less relevant features quantitative methods partial dependence plots friedman importance breiman molnar point problematic variables heavily weighted prediction past observations expert knowledge traceability process traceable one whose execution steps poorly documented include poorly specified processes operator decisions extract data undocumented inaccessible sources omit necessary code materials give necessary information ensure reproducibility results traceability allows users understand processes followed system arrive outcome including system shortcomings limitations little traceability model risks outlined throughout document difficult identify may even exacerbated contrast steps data collection clearly documented unambiguously specified traceable project box traceability checklist quantitative lifecycle well documented including data provenance collection mechanisms infrastructure used model dependencies code metrics interpretation results documentation include data sources including dataset metadata data collection processes data processing information see tool complete appropriately documented code defining necessary libraries appropriate versions allow third party understand purpose part code information code executed including detailed documentation parameters computing requirements information must guarantee reproducibility original results third party information results computational process used included process information monitoring strategy including details performance metrics thresholds well expected model behavior mitigation actions ideally aforementioned steps replicable third party minimal intervention original system creators operators responsible use public policy data science toolkit qualitative deficiencies limitations biases model communicated stakeholders considered decision support qualitative technical team completed data profile see tool model card see tool process continuous updating tools defined responsible use public policy data science toolkit tools responsible use public policy data science toolkit responsible use public policy data science toolkit tool robust responsible checklist tool consolidates main concerns risk dimension lifecycle checklist must reviewed continuously technical team accompanied fritzler drivendata planning design correct definition problem public policy response qualitative public policy problem clearly defined qualitative describe problem currently addressed considering responses related institutions use would improve government response problem qualitative protected groups protected attributes identified within project age gender education level race level marginalization qualitative actions interventions carried based result system defined principles quantitative need system justified considering possible solutions require use personal data automated decisions quantitative evidence public policy action recommendation system result benefit people planet driving inclusive growth sustainable development qualitative implementation technologies similar previous projects reviewed quantitative considered minimizing exposure personally identi fiable information anonymizing collecting information relevant analysis lifecycle data collection processing data quality relevance available data qualitative discuss possible historical social inequalities use case specialists field quantitative perform exploratory analysis available data model trained identify possible historical biases undesirable states responsible use public policy data science toolkit poor correspondence ideal available variables qualitative ideal target variables clearly stated available variables must analyzed understand suitable substitute target variable systematic biases validity proxy metric identified qualitative use selected response variable clearly justified purposes intervention data qualification completeness target population probabilistic natural samples qualitative possible differences database popula tion system developed analyzed use literature related topic information experts study particular unmeasured selection biases quantitative although models built various data sources designed natural validation ideally carried sample allows statistical inference target population validation sample must appropriately cover target population interest missing incomplete attributes qualitative analysis missing values variables performed qualitative determined whether important omitted variables associated measurements qualitative reasons missing observations identified causal comparison qualitative understand describe reasons response variable correlated known unknown variables describe possible biases based expert knowledge analysis qualitative event work done ensure causality results limitations results explicitly communicated public policy model building validation absence inappropriate use validation samples quantitative validation test samples constructed properly considering appropriate size covering subgroups interest protected subgroups avoiding information leaks implementation responsible use public policy data science toolkit data leakage data leak quantitative processing preparation training data avoid using validation test data way solid barrier must maintained training versus validation testing includes data recoding normalizations selection variables identification outliers type preparation variable included models also includes sample weights balances based target leakage validation scheme replicate closely possible scheme predictions applied probabilities classes imbalanced data quantitative make probability predictions instead class predictions probabilities incorporated subsequent decision process quantitative absolute number minority cases small difficult find appropriate information discriminate class data need collected minority class quantitative dominant class weighting cases avoid losing calibration successful strategy reduce data size training time without affecting predictive performance quantitative replicate minority class better balance classes arbitrary point quantitative using probabilistic classification algorithms suitable incorporate uncertainty regarding classification quantitative avoid standard probability points choose optimal interpretation predicted probabilities using receiving operating characteristic curve measures analyze errors adequateness assessment metrics qualitative implications different types errors specific use case well correct way evaluate questioned qualitative limitations model clearly explained implies identifying false positives false negatives implications system decision would life target population quantitative analysis system conducted compared status quo use decision support strategies possible responsible use public policy data science toolkit underfit overfit checklist quantitative overfitting necessary methods refined moderate overfitting including methods regularization restricting function space possible models using training data disturbing training data hastie tibshirani friedman quantitative underfit data protected groups sensitive variables reviewed verify undesirable systematic errors unquantified errors human evaluation failures measured model qualitative human assessment conducted experts look known biases errors establishing monitoring schemes allow identification unmeasured errors biases recommended example panels reviewers used examine particular predictions consider whether reasonable panels must balanced terms user type expertise including necessary fairness differential performance algorithmic fairness inequality qualitative algorithmic fairness criterion used model defined experts quantitative protected attributes exist assessment must made far predictions deviate chosen algorithmic fairness definition tested disparate error rates quantitative case classification models points different subgroups adjusted achieve chosen algorithmic fairness criterion deployment monitoring performance degradation qualitative plan monitor performance model collection information time quantitative monitor various metrics associated predictions predefined subgroups including protected variables quantitative monitor drift variable distributions respect training set quantitative monitor changes data collection processing methodology may reduce quality predictions quantitative possible plan assign randomized status quo treatments units experimental designs make performance behavior comparisons sample results algorithmic regime quantitative identify unobserved variables seek ways measure possible model evaluate model performance using information responsible use public policy data science toolkit accountability interpretability explanation predictions explainability individual predictions qualitative legal ethical explainability requirements project context analyzed qualitative process place provide explanations particular indi viduals decision made qualitative pros cons algorithms discussed according level interpretability explainability choose appropriate one parsimonious models qualitative including available features build train model may increase risk disproportionately affecting users variables included learning process must theoretical support explanation help prediction task quantitative parsimonious methods use fewer relevant features preferable models use many less relevant features quantitative methods partial dependence plots friedman importance breiman molnar point problematic variables heavily weighted prediction past observations expert knowledge traceability quantitative lifecycle well documented including data collection infrastructure used dependencies code metrics interpretation results qualitative deficiencies limitations biases model communicated stakeholders considered sion support qualitative technical team completed data profile see tool model card see tool process continuous updating tools defined responsible use public policy data science toolkit tool data profile data profile exploratory analysis provides information evaluate quality integrity temporality consistency possible biases dataset used train machine learning model gebru data input collection origin name dataset used institution created dataset purpose institution create dataset used mechanisms procedures used collect data household survey sensor software api comply existing data protection regulations scale dataset obtain documentation variable within dataset provide short description including name type represents measured etc data input domains data domain proprietary public personal personal data identified pseudonymized unlinked pseudonymized anonymized aggregated proprietary intellectual property rights considerations data input structure data static dynamic dynamic often updated data quality qualification data obtained observed derived synthetic provided individ uals organizations data representative population interest analyze spatial temporal coverage data analyze coverage protected groups sex race age describe type sampling used obtain data describe important dimensions data sample may differ population particular unmeasured selection biases use literature related subject information experts identify possible undesirable states data could lead prejudicial biases inequities given subgroup pattern considered suboptimal undesirable social policy point view missing values explain reasons information available includes information intentionally removed identify reasons responsible use public policy data science toolkitfor missing data think whether missing data associated variable predict document imputation processes used substitute missing data capture frequency weekly monthly daily average number observations per individual version dataset used appropriate dataset available given problem hand responsible use public policy data science toolkit tool model card rubric presented card summarizes main characteristics decision support system highlights main assumptions important characteristics system mitigation measures implemented mitchell planning design basic information people developed model date version type use cases background target population forecast horizon actors components interact results use cases considered development uses considered related warnings definition protected groups data collection processing training data dataset used labeling preprocessing data preparation steps potential biases shortcomings depending use case model building validation modeling algorithms used training assumed parameters constraints input assumptions made using expert knowledge data interaction interaction active interaction passive interaction performance metrics technical metrics used select evaluate models analysis model use case according definition protected groups selected fairness measures validation data datasets used labeling steps evaluation adaptation validation data according use case responsible use public policy data science toolkit potential biases shortcomings depending use case quantitative analysis summary validation error reported summary analysis report fairness measures protected groups deployment monitoring monitoring recommendations monitoring improvement strategy production human monitoring strategies applicable accountability explainable predictions strategy explain particular predictions strategy understand importance different attributes ethical considerations recommendations warnings responsible use public policy data science toolkit workbooks responsible use public policy data science toolkit responsible use public policy data science toolkitworkbooks section shows several examples challenges solutions explained main document different types models linear others different imple mentations keras xgboost used show problems arise regardless choice particular tools booklets use decimal point notation maintain consistency packages use programming language used along following packages tidyverse recipes mis rsample parsnip yardstick workflows tune knitr patchwork material reproducible according instructions contains dockerfile describes infrastructure dependencies replication data collection processing data quality relevance available data using models predict wrong metric lead wrong decisions sometimes problem clear proxy metric obvious shortcomings times subtle example shown seeks predict demand certain product let think vaccines medicine order make supply decisions historical data inventory weeks sales predictor variable associated sales case vaccines could temperature another inventory depletion separate data training testing fitting model subset training data case linear model used dependent variable sales week covariates predictor covariate train sales filter week test sales filter week week train select head kable week inventory sales forecast depletion responsible use public policy data science toolkit sales week predictor data sales call formula sales week predictor data sales coefficients intercept week predictor evaluate prediction error preds predict newdata test round mean abs preds test sales mean test sales percentage error low fitted data predictions look follows preds predict newdata sales sales mutate pred preds cols sales pred type units ggplot mutate units ifelse type sales week units aes week units group type color type xintercept xintercept annotate text label train annotate text label test responsible use public policy data science toolkit making demand inventory decisions type model wrong reason difference ideal variable real demand medicines observed variable sale medicines difference inventory depletions periods although demand enough inventory buyers marked red following graph preds predict newdata sales sales mutate pred preds cols sales pred type units ggplot mutate units ifelse type sales week units aes week aes group type color type units data filter sales depletion week aes sales color red xintercept xintercept annotate text label train annotate text label test responsible use public policy data science toolkit use policy suggested predictions percent would see sales first graph however used inventory policy units would observe following preds predict newdata sales sales mutate pred preds mutate inventory pred mutate sales ifelse week pmin inventory demand sales cols sales pred type units ggplot aes week aes group type color type units data filter sales inventory week aes sales color red xintercept labs subtitle inventory predictions preds predict newdata sales sales mutate pred preds mutate inventory mutate sales ifelse week pmin inventory demand sales cols sales pred type units responsible use public policy data science toolkit ggplot aes week aes group type color type units data filter sales inventory week aes sales color red xintercept labs subtitle inventory cte units therefore prediction policy exacerbates burnout problem unintended use data without considering generating process lead large errors decisions case confusion comes separating concepts demand sales suitable demand indicators models would help solve problem simplistic solutions taking data stockouts occur make situation even worse increase bias select weeks sales tend low reduce accuracy natural samples bias training samples different populations models applied difficulties correctly validating predictions natural samples poor representativeness example data national household income expenditure survey mex ico used inegi simulate scenario want exemplify data mutate focos mutate ingcor mutate ifelse yes mutate ifelse pisos pisos yes mutate washer ifelse wash lavad yes mutate car mutate marginalization marginalization responsible use public policy data science toolkit median rename occupied perocu rename levelaprob select marginalization occupied washing machine car prop train training test testing suppose interested estimating household income use cell phone sur vey conduct furthermore suppose access areas high marginalization filter train yes marginalization low training testing linear model built logarithm income available data library splines formula log occupied washing machine car formula data take representative sample compare size biased formula data train nrow error evaluated test sample constructed data biased characteristics training data households cell phone low degree marginalization responsible use public policy data science toolkit predict newdata mean abs log round error sample similar population algorithm intended apply greater predict newdata test predict newdata test test test mean abs log test round however main problem reflected graphs logarithmic scales used make multiplicative comparisons interesting due nature income point represents household sample similar population methodology applied prediction households using model plotted horizontal axis vertical axis corresponds income household reference line smoother added focus performance relatively households lessthan pesos per month ggplot test filter log aes exp alpha method loess span limits breaks xlab forecast thousands per quarter ylab current income thousands per quarter labs subtitle test performance nwith training bias responsible use public policy data science toolkit ggplot test filter log aes exp alpha method loess span limits breaks xlab forecast thousands per quarter ylab current income thousands per quarter labs subtitle performance test nwith representative sample training although commonly expected relatively low observed values opposite relatively high values households incomes less pesos per month biased model overpredicts true income around percent test filter bias mean exp mean round bias responsible use public policy data science toolkit compared trained model representative sample effect considerably less test filter bias mean exp mean round bias two problems bias produces considerably larger error implementation validation even worse bias greater households predictions high produce poor targeting seek identify households natural samples causal comparisons example taken hastie tibshirani friedman rossouw following data considered goal predict heart disease chd data rename sbp tobacco tobacco ldl adiposity adiposity famhist typea obesity obesity age age chd tibble tobacco adiposity dbl dbl dbl dbl chr dbl present absent present present present data accessed responsible use public policy data science toolkit present absent present present present rows variables obesity dbl alcohol dbl age dbl dbl library recipes rsample prop training recipe factor prep juice trees mode classification xgboost fit data evaluate model parameters well interested interpreting effect variables model partial dependence graph prevalence heart disease obesity variable considered responsible use public policy data science toolkit library pdp pdp partial fit plot true prob true train dplyr select xlab systolic blood pressure ylab average prediction correct interpretation partial dependence graph hastie tibshirani friedman depends fact retrospective study patients risk heart disease underwent interventions reduce risk including taking medicines reduce blood pressure causal interpretation blood pressure reductions promoter heart disease incorrect potentially dangerous responsible use public policy data science toolkit model building validation leak training validation several examples leakages training validation produce biased estimates predictor performance presented selecting variables dividing data step must done without using validation data includes methods used example originally hastie tibshirani friedman use synthetic data generated following process simulating response variables binomial distribution simulating independent covariates standard normal distribution simulate function prob data map rnorm data rbinom prob data simulate simulate dim tally kable selection variables given function function selects variables correlated target variable responsible use public policy data science toolkit select function data correlations data cols matches variable variable summarize corr abs cor arrange desc corr select selected correlations corr pull variable data select selected wrong method variables selected method wrong run data used validation performance estimate optimistic select head round kable whatever validation made whether separating dataset percentage hits appears greater responsible use public policy data science toolkit validate glm family binomial mean predict valid valid round however actual performance model mean predict round correct method selection variables must done round select validate glm family binomial mean predict valid valid round oversample partitioning one ways solve class imbalance problems use oversampling techniques however careful avoid information leakage errors applying techniques example see oversampling small class separating validation data produce overly optimistic estimates prediction error suppose severe imbalance two classes simulate prob mutate factor levels tally kable responsible use public policy data science toolkit wrong method suppose synthetic minority technique smote chawla applied first try balance data recipe prep juice obtaining tally kable training validation separated training testing classification method generated using random forest decision trees metrics accuracy recall precision forest trees mtry mode classification ranger responsible use public policy data science toolkit fit data forest predict metrics truth estimate round kable accuracy binary recall binary precision binary first glance seems performance excellent however since relationship rest covariates know error correct method rebalancing classes training validation separated like part done using stratified sampling example built simple random sampling prop train training test testing recipe data train prep juice trees mtry mode classification ranger fit data predict test responsible use public policy data science toolkit test metrics truth estimate round kable kable accuracy binary recall binary precision binary although accuracy seems high precision sensitivity zero trivial classifier always predicts ruling class may better accuracy one constructed leaks implementation variables available time prediction case show example variable used erroneously available time making predictions data greene credit data rename expense expenditure dependents dependents income income age age owner owner mutate owner owner yes credit head round kable card reports age income share expense ownerselfemployeddependents monthsmajo cardsactive yes yes yes yes yes yes yes yes yes want build model predict applications accepted automate selection process logistic regression keras penalty used responsible use public policy data science toolkit credit train training test testing data preparation recipe card credit model penalty keras epochs verbose false classification adjust preprocessing parameters prep train preprocess data bake train bake test adjust model fit fit card expense dependents income age data evaluate metrics accuracy recall precision fit predict test metrics truth factor card estimate round kable kable responsible use public policy data science toolkit accuracy binary recall binary precision binary seems performing reasonably well remove variable expenditure performance model totally degraded fit card expense dependents income age data fit predict test metrics truth factor card estimate round kable kable accuracy binary recall binary precision binary sensitivity poor precision calculated model make positive predictions test set reason performance degradation spending refers use credit cards includes card want make acceptance prediction train mutate expense card tally kable responsible use public policy data science card false false yes true yes indicates expense probably includes expense current card expense variable measured delivery card performance model new applications poor since expense variable time application obviously count much client spend future point evaluation best decisions made analysis using lift curves like previous example based gains losses decision although information often available ideal evaluate model helps much actions intend take worth possible analysis uncertain values suppose thinking treatment retain students training improvement program retention treatment costs pesos per student estimated experiments external analysis treatment reduces probability dropping percent kind assessment social value student persisting program evaluate model context problem follows assuming percentage students likely rotate treated expected cost calculated percentage students treated simulate reducing probability dropping due treatment add costs treating model compared scenario applying treatment necessary use highly technical measures give summary treatment model help maintain value portfolio responsible use public policy data science toolkit ggplot filter type model treatment aes factor cut loss ylab incremental profit millions xlab lower treatment cutoff probability labs subtitle profit action choose point example simulations refine choice want separate effect treatment effect treatment applied according model compared action consists treating students random ggplot aes factor cut loss group interaction type cut color type ylab incremental profit millions xlab lower treatment cutoff probability labs subtitle profit action responsible use public policy data science toolkit bottom line model helps considerably targeting program area two curves shown class imbalance severe class imbalance face two problems absolute terms elements class able discriminate effectively even correct attributes feature usual predictive evaluation methods deficient evaluate performance predictions consider following scenario put forth james data contains real customer records record consists variables contain sociodemographic data variables product ownership variables sociodemographic data derived postal codes customers living areas zip code sociodemographic attributes variable purchase indicates whether client purchased caravan insurance want predict variable purchase caravan data mutate mostype factor mostype moshoofd factor moshoofd mutate purchase purchase yes yes mutate purchase purchase select nrow caravan data information available responsible use public policy data science toolkit caravan count purchase mutate pct sum mutate pct round pct tibble buy pct fct int dbl yes natural distribution response seen data relatively little data yes category stratified sampling used obtain similar proportions training test sets caravan strata buy prop train training test testing logistic regression used applies methods produce class probabilities boosting random trees neural networks library tune data preparation recipe buy train prep model responsible use public policy data science toolkit glm classification fit buy data juice incorrect analysis confusion matrix training data predict juice juice select buy purchase truth prediction yes test ones bake test predict select buy purchase truth prediction yes get poor performance according confusion matrix test training sensitivity low although specificity rate correct negatives high typical conclusion model predictive value necessary oversample low occurrence class responsible use public policy data science toolkit correct analysis instead starting modifies natural proportions categories data work probabilities instead class predictions example visualized receiving operating characteristic curve lift curve curve takes probabilities account predict type prob select buy select buy buy autoplot xlab specificity ylab sensitivity seen possible achieve good levels sensitivity degradation specificity accepted originally high example cutting obtain specificity sensitivity possibly adequate problem filter abs round tibble specificity sensitivity responsible use public policy data science toolkit dbl dbl dbl happens oversample oversample recipe buy train mostype moshoofd purchase prep model juice count purchase tibble buy pct fct int yes glm classification fit buy data training confusion matrix apparently better predict select buy purchase responsible use public policy data science toolkit truth prediction yes testing results similar model built ruling class also added purchase prep juice glm classification fit buy data predict type prob select buy select buy predict type prob select buy select buy buy buy mutate type natural mutate type oversampling mutate type subsample responsible use public policy data science toolkit ggplot aes specificity sensitivity color type lty original problem fit working wrong point evaluated point smote equivalent much smaller one without smote worse still probabilities oversampled model reflect occurrence rates response interest produce misleading summaries response rates expected observed production equality protected attributes following example derived hardt price srerbro suppose protected attribute two values blue orange orange disadvantaged minority group simulated data used follows score attribute associated protected attribute responsible use public policy data science toolkit function exp function pmax rnorm pmax rnorm blue tibble type blue score orange tibble type orange score data blue orange mutate ifelse type blue mutate rpois nrow data select mutate pay rbinom select using histogram score minority group obtained values lowest score variable ggplot aes score fill type simple logistic regression model fitted responsible use public policy data science toolkit glm pay score type family binomial mutate predict type response actual compliance rates two groups first strategy considered point applied groups function cuts result mutate recibe ifelse type blue cortes cortes decision ifelse receive accepted rejected result type decision pay count ungroup tibble decision type pays chr chr dbl int blue accepted blue accepted blue rejected blue rejected orange accepted orange accepted orange rejected orange rejected type decision responsible use public policy data science toolkit summarize sum mutate total sum mutate prop total filter decision accepted tibble groups type decision type total prop chr chr int int dbl blue accepted orange accepted note orange group received considerably less acceptance blue group total proportion furthermore precision rate true positives evaluate proportion would comply accepted accepted according point filter pay type mutate tvp sum filter decision accepted tibble groups type type decision pays tvp chr chr dbl int dbl blue accepted orange accepted seen orange group also disadvantage since among comply fewer acceptance decisions next step consider demographic parity case decided give number loans group depending size responsible use public policy data science toolkit function prop type summarize cut quantile prop tibble cut type chr dbl blue orange point blue demanding orange problem observed pull cut filter pay type mutate tvp sum filter decision accepted tibble groups type type decision pays tvp chr chr dbl int dbl blue accepted orange accepted addition demanding blue group comply blue group also given fewer acceptance decisions additionally considerably fewer people accepted population responsible use public policy data science toolkit equal opportunity solution acceptance rate within group pay similar populations occurs approximately function prop filter pay type mutate rank length filter prop select type cut pull cut filter pay type mutate tvp sum filter decision accepted tibble groups type type decision pays tvp chr chr dbl int dbl blue accepted orange accepted note positive outcome variable unfairly assigned method solve problem case relevant understand criteria successful result considered depending group protected attribute particular segment allowed greater arrears payments another group allowed less arrears group considered repeat offender much lesser offense groups responsible use public policy data science toolkit accountability interpretability measures importance permutations used examine models example return credit application acceptance prediction exercise consider importance based permutations molnar credit train training test testing data preparation recipe card credit model penalty keras epochs verbose false classification adjust preprocessing parameters prep train preprocess data bake train bake test adjust model fit fit card expense dependents income age data library iml model fit fit dplyr select expense dependents income age predictor predictor new model data ifelse card yes type prob imp featureimp new predictor loss compare difference plot imp responsible use public policy data science toolkit seen network without hidden layers importance concentrated single predictor expenditure seen represents information leak diagnosis useful general although dramatic example point variables important consider carefully important also consider effect variables associated protected groups necessary carefully examine affect predictions parsimonious models use fewer attributes facilitate analysis maintain data flow reduce exposure leakage problems undesirable effects explanation predictions explain individual predictions shapley values used molnar lundberg lee graphs indicate assigned contribution attribute indi vidual prediction idea considering marginal effects prediction depending presence absence attributes contributions obtained add difference particular prediction average prediction averages across interest groups also examined consider example factors detecting heart disease rossouw fit dplyr select function object newdata newdata missing results return results responsible use public policy data science toolkit predictor predictor new data chd type prob case interest case shapley new predictor plot case several measures contribute positively likelihood heart disease tobacco use age cholesterol measurements contributions explain high probability particular individual contrast following person close average age cholesterol levels increasing positively use family history diabetes case interest case shapley new predictor plot responsible use public policy data science toolkit remark model partial dependence graphs discussed coefficients interpreted causally cholesterol needs lowered two indi viduals information model uses build prediction average prediction population shapley values calculated two age groups example responsible use public policy data science toolkitreferences athey estimation inference heterogeneous treatment effects using random forests journal american statistical association barocas selbst big data disparate impact ssrn elibrary bolukbasi chang zou saligrama kalai man computer programmer woman homemaker debiasing word embeddings arxiv breiman random forests machine learning págs buolamwini gebru feb gender shades intersectional accuracy disparities commercial gender classification friedler wilson conferen ceproceedings conference fairness accountability transparency págs new york usa pmlr buuren mice multivariate imputation chained equations journal statistical software págs carrillo cantú noriega individual explanations machine iadb chawla smote synthetic minority technique journal artificial intelligence research drivendata ethics checklist data scientists obtenido friedman greedy function approximation gradient boosting machine annals statistics págs fritzler ethical checklist data science obtenido gebru morgenstern vecchione wortman wallach daumé crawford datasheets datasets retrieved gelman hill data analysis using regression models cambridge university press greene econometric analysis pearson education obtenido hardt equality opportunity supervised learning corr harini suresh framework understanding unintended consequences machine learning mit obtenido responsible use public policy data science toolkithastie tibshirani friedman elements statistical learning springer new york inegi encuesta nacional ingresos gastos los hogares diseño muestral obtenido james data introduction statistical learning applications obtenido kaufman rosset perlich leakage data mining formulation detection págs kim examples enough learn criticize criticism interpretability advances neural information processing systems kuhn rsample general resampling infrastructure obtenido kuhn johnson applied predictive modeling springer new york lackland racial differences hypertension implications high blood pressure management american journal medical sciences little rubin statistical analysis missing data wiley lohr sampling design analysis cengage learning lundberg lee unified approach interpreting model predictions arxiv miller explanation artificial intelligence insights social sciences artif págs mitchell zaldivar barnes vasserman hutchinson gebru model cards model reporting retrieved molnar interpretable machine learning obermeyer powers vogeli mullainathan dissecting racial bias algorithm used manage health populations science págs oecd forthcoming framework classification systems paris oecd publishing oecd artificial intelligence society paris oecd publishing oecd good practice principles data ethics public sector responsible use public policy data science toolkitpombo cabrol alarcón ávalos fair lac adopción ética responsable inteligencia artificial américa latina caribe doi prosser mellon twitter facebook representative general population political attitudes demographics social media users available ssrn rossouw coronary risk factor screening three rural communities coris baseline study south african medical journal tydskrif vir geneeskunde rubin statistical analysis missing data second edition john wiley sons stuart misunderstandings among experimentalists observationalists causal inference journal royal statistical society series part págs sundararajan taly yan axiomatic attribution deep networks arxiv suresh guttag framework understanding unintended consequences machine learning arxiv vaver koehler measuring effectiveness using geo experiments google vayena global landscape ethics guidelines springer science business media llc verma rubin fairness definitions explained conferenceproceedings international workshop software fairness págs new york usa association computing machinery wachter mittelstadt russell counterfactual explanations without open ing black box automated decisions gdpr arxiv washingtonpost studies showing racial disparities criminal justice system obtenido williams racial differences hemoglobin concentration measurements iron copper zinc american journal clinical nutrition págs wilson score tell cnn responsible use public policy data science toolkit responsible use public policy data science toolkit
