guidance auditing framework draft guidance consultation ico information commissioner office auditing framework draft guidance consultation contents guidance produced guidance mean guidance relate ico work guidance ico focusing risk approach guidance set principles legislation applies guidance structured accountability governance implications ofai approach governance risk management set meaningful risk appetite need consider undertaking data protection impact assessments understand relationships trade manage need ensure lawfulness fairness transparency systems principle lawfulness fairness transparency apply identify purposes lawful basis using need statistical accuracy address risks bias discrimination assess security data minimisation security risks introduce case study security risks introduced externally maintained software steps take manage risks privacy attacks data minimisation privacy techniques available case study losing track training data used build systems types privacy attacks apply models models systems enable individual rights systems individu rights apply different stages lifecycle version auditing framework draft guidance consultation individual rights relate data contained model enable individual rights relating solely automated decisions legal similar effect role human oversight version auditing framework draft guidance consultation guidance glance applications artificial intelligence incr easingly permeate many aspects lives understand distinct benefits bring also risks pose rights freedoms individuals developed framework auditing focusing best practi ces data protection compliance whether design system implement one third party provides solid methodology audit applications ensure process personal data fairly comprises auditing tools procedures use audits investigations detailed guidance data protection includes indicative risk control measures deploy use process personal data guidance aimed two audiences compliance focus data protection officers dpos general counsel risk managers ico auditors technology specialists including machine learning experts data scientists software developers engineers cybersecurity risk managers guidance clarifies assess risks rights freedoms pose appropriate measures implement mitigate data protection ethics overlap guid ance provide generic ethical design principles use corresponds different data protection principles structured follows part one addresses accountability governance including data protection impact sessments dpias part two covers fair lawful transparent processing including lawful bases assessing improving system performance mitigating potential discrimination part three addresses data minimisation security part four facilitate exercise individual rights systems including rights related automated decision version audi ting framework guidance consultation detail produced guidance mean guidance relate ico work guidance ico focusing risk approach guidance set principles legislation applies guidance structured produced guidance see new uses artificial intelligence everyday healthcare recruitment commerce beyond understand nefits bring organisations individuals risks one top three strategic priorities decided develop framework auditing compliance data protection obligations framework gives solid methodology audit applications ensure process personal data fairly lawfully transparently ensures necessary measures place assess manage risks rights freedoms arise supports work investigation assurance teams assessing compliance organisations using well using framework guide activity also wanted share thinking behind framework therefore two distinct outputs auditing tools procedures used investigation assurance teams assessing compliance organisations using detailed guidance data protection organisations outlines thinking also incl udes indicative risk control tables end section help organisations audit compliance systems guidance aims inform think constitutes best practice data compliant version auditing framework guidance consultation guidance statutory code contains advice interpret relevant law applies recommendations good practice organisational technical measures mitigate risks individuals may cause exacerb ate penalty fail adopt good practice recommendations long find another way comply law reading ico guidance technology strategy mean term variety meanings within research community refers various methods using non system learn experience imitate human intelligent behaviour whilst context data protection referred theory development computer systems able perform tasks normally requiring human intelligence visual perception speech recognition decision translation languages however use large amounts data make predictions classifications individuals existed sectors like insurance since century long term coined traditional forms statistical analysis statistical models calculated using pen paper later calculator modern machine learning techniques much easier create statistical models using computationally intensive techniques much larger datasets increase complexity models combined decreasing costs creating heightened concerns risks rights freedoms individuals one prominent area machine learning use computational techniques create often complex statistical models using typically large quantities data models used make classifications predictions new data points involves recent interest driven way whether context image recognition speech classifying credit risk guidance therefore focuses data protection challenges may present acknowledging kinds may differ processing large amounts personal data purpose data protection law applies processing data context statistical models using models make predictions people guidance relevant regardless whether classify activities version auditing framework guidance consultation use umbrella term becom mainstream way organisations refer range technologies mimic human thought similar technologies similar sources risk likely benefit set risk measures whether call machine learning complex information processing something else risks controls identified helpful important differences different types example simple regression models deep neural networks refer explicitly resources see international working group data protection telecommunications working paper privacy artificial intelligence pdf external link idance relate ico work guidance designed complement existing ico resources including big data achine learning report published updated guidance explaining decisions made produced collaboration alan turing institute explain guidance data report provide stron foundatio understanding data protectio implications technologies note commissioner foreword edition thi complicated fast area new considerations ave arise las three years terms risks pose individuals organisational technical measures taken address risks engageme stakeholders gaine additional insights nto org anisations using ground beyo presented report another significant challenge raise explainability par government sector deal collaboration turing institute produced guidance organisations best explain use individuals resulted explain guidance published draft form consultation last year process finalising explain guidance light feedback stakeholders update links guidance ompleted exp lain guidance already covers challenge explainability individuals substantia detail guidance includes additional considerations explainability within organisation internal oversight compliance two pieces guidance complementary recommend reading tandem version auditing framework guidance consultation reading ico guidance big data artificial intelligence machine learning data protection ico turing consultation explaining decisions guidance guidance guidance covers best practices data compliant two broad intended audiences first compliance focus including data protection officers general counsel risk managers ico auditors words utilise guidance exercise audit functions data protection legislation second technology specialists including machine learning developers data scientists software developers engineers cybersecurity risk managers guidance written accessible audiences parts aimed primarily either compliance technology roles signposted accordingly ico focusing risk approach taking risk approach means assessing risks rights freedoms individuals may arise use implementing appropriate proportionate technical organisational measures mitigate risks general requirements data protection law mean ignore law risks low may mean stop planned project sufficiently mitigate risks help integrate guidan existing risk management process organised several major risk areas risk area describe version auditing framework guidance consultation risks involved may increase likelihood impact possible measures could use identify evaluate minimise monitor control risks technical organisational measures included consider good practice wide variety contexts however since many risk controls may need adopt specific include exhaustive definitive list guidance covers risks implications risks governance accountability regardless whether using accountability measures place however adopting applications may require existing governance risk management practices applications exacerbate existing risks introduce new ones generally make risks difficult assess manage decision organisation therefore reconsider organisation risk appetite light existing proposed applications sections guidance deep one challenge areas explores associated risks processes controls guidance set principles guidance provide generic ethical design principles use may overlaps ethics data protection proposed ethics principles already reflected data protection law guidance focused data protection compliance although data protection dictate designers jobs use process personal data need comply principles data protection design default may direct application developers play role processing however also note responsibility put place appropriate technical organisational measures designed plement data protection principles effective manner developer use personal data train models controller processing data protection law applies certain design choices lik ely result systems infringe data protection one way guidance help designers engineers understand choices better design high performing systems whilst still protecting rights freedoms individuals version auditing framework guidance consultatio worth noting work focuses exclusively data protection challenges introduced heightened general data protection considerations addressed except far relate challenged resources read global privacy assembly declaration ethics data protection artificial intelligence pdf external link information ethics data protection intersect context legislation applies guidance deals challenges raises data protection relevant piece legislation data protection act dpa sets data protection framework alongside general data protection regu lation gdpr comprises following data protection regimes part supplements tailors gdpr part sets separate regime law enforcement authorities part sets separate regime three intelligence services guidance apply regardless part dpa applies processing however relevant differences requirements different regimes explicitly addressed text shou also review guidance brexit impacts data protection law impacts areas ico competence data protection notably freedom information considered reading ico guidance information different regimes read guide data protection nee detail data protection brexit see faqs version auditing framework guidance consultation guidance structured guidance divided several parts corresponding different data protection principles rights part one addresses issues primarily relate accountability principle requires responsible complying data protection principles demonstrating compliance sections part deal implications accountability including protection impact assessments dpias controller processor responsibilities assessing justifying trade part two covers lawfulness fairness transparency processing personal data systems sections covering lawful bases processing personal data systems assessing improving system performance mitigating potential discrimination ensure fair processing part three covers principle security data minimisation systems part four vers facilitate exercise individuals rights personal data systems rights relating solely automated decisions particular part four covers ensure meaningful human input non decisions meaningful human review solely automated decisions version auditing framework guidance consultation accountability governance implications glance accountability principle makes responsible complying data protection demonstrating compliance system context accountability requires responsible complian system assess mitigate risks document demonstrate system compliant justify choices made consider issues part dpia system intend use note legally required complete dpia use systems process personal data dpias offer opportunity consider using systems process personal data potential risks could due complex ity mutual dependency various kinds processing typically involved supply chains also need take care understand identify controller processor relationships additionally depending designed deployed systems inevitably involve making trade privacy competing rights interests need know trade may manage otherwise risk fail adequately assess strike right balance however also note always comply fundamental data protection principles trade requirement away detail approach governa nce risk management set meaningful risk appetite need consider undertaking data protection impac assessments understand relationships trade manage version auditi framework guidance consultation approach governance risk management used well potential make organisations efficient effective innovative however also raises significant risks rights freedoms individuals well compliance challenges organisations different technological approaches either exacerbate mitigate issues many others much broader specific technology rest guidance suggests data protection implications heavily dependent specific use cases population deployed overla pping regulatory requirements well social cultural political considerations increases importance embedding data protection design default organisation culture processes technical complexities sys tems make difficult demonstrating addressed complexities important element accountability delegate issues data scientists engineering teams senior management including data protectio officers dpos accountable understanding addressing appropriately promptly addition upskilling need diverse well resourced teams support discharging responsibilities also need align internal structures roles responsibilities maps training requirements policies incentives overall governance risk management strategy important underestimate initial ongoing level investment resources effort required governance risk management capabilities need proportionate use particularly true adoption still initial stages technology associated laws regulations governance risk management best practices still developing quickly also currently developing general accountability toolkit specific provides baseline demonstratin accountability gdpr could build approach accountability update final version guidance refer final version accountability toolkit published set meaningful risk appetite risk approach data protection law requires comply obligations implement appropriate measures context particular circumstances nature scope context purposes version auditing framework guidan consultation processin inten risks poses individuals rights freedoms compliance consideration therefore involve assessing risks rights freedoms individuals takin judgements wha appropriate circumstances cases need ensure comply data protection requirements applie use technologie proce personal data conte specific ature risks pose circumstances processing require strike appropriate balance betwee competin interests ensuri data protec tion compliance may turn impact outcome processing unrealistic adop zero tolerance approac risks rights freedoms indee law require ensuring risks identified managed mitigated see ffs manage manage risks individuals tha arise processi personal data systems importan develop mature understanding articulatio fundamental rights risks balance othe interests ultimately necessary assess risks individuals rights use poses determine need address establish impact use ensure approach fits organisation circumstances processing appropriate also use risk assessment frameworks complex task take time get right ultimately however give well ico fuller meaningful view risk positions adequacy compliance risk management approaches following sections deal implications accountability including undertake data protection impact assessments systems identify whether controller processor specific processing operations involved development deployment systems resulting implications responsibilities assess risks rights freedoms individuals address design decide use system version auditing framework guidance consultati justify document demonstrate approach take including decision use processing question need consider undertaking data protection impact assessments dpias key part data protection law focus accountability data protection design see dpias mere box ticking compliance exercise effectively act roadmaps identify control risks rights freedoms use pose also perfect opportunity consider demonstrate accountability decisions make design procurement systems need carry dpias data protection law using process personal data likely result high risk individuals rights freedoms therefore triggers legal requirement undertake dpia result assessment indicates residual high risk individuals sufficiently reduce must consult ico prior starting processing addition conducting dpia may also required undertake kinds impact assessments voluntarily instance public sector organisations required undertake equality impact assessments organisations voluntarily undertake algorithm impact assessments reason combine exercises long assessment encompasses requirements dpia ico produced detailed guidance dpias explains required complete section sets things think carrying dpia processing person data systems relevant provisions legislation see articles recitals gdp external link see sections dpa external link decide whether dpia list types processing likely result high risk use process personal data must carry dpia case major project involves use personal data good practice dpia version auditing framework guidance consultation read list processing operations likely result high risk examples operations require dpia detail criteria high risk combination others reading ico guidance see decide whether dpia guid ance dpias assess dpia dpia needs describe nature scope context purposes processing personal data needs make clear going use process data need detail collect store use data volume variety sensitivity data nature relationship individuals intended outcomes individuals wider society well context lifecyc dpia best serve purpose undertake earliest stages project development feature minimum following key components describe processing dpia include systematic description processing activity including data flows stages processes automated decisions produce effects individuals explanation relevant variation margins error performance system may affect fairness personal data processing see statistical accuracy description scope context processing including data process number data subjects involved source data far individuals likely expect processing dpia identify record degree human involvement decision process stage takes place automated decisions subject human intervention view implement processes ensure meaningful also detail fact decisions overturned version auditing framework guidance consultation difficult describe processing activity complex system may appropriate maintain two versions assessment first presenting thorough technical description specialist audiences second containing high description processing explaining logic personal data inputs relate outputs affecting individuals dpia set roles obligations controller include processors involved systems partly wholly outsourced external providers organisations involved also assess whether joint controllership exists article gdpr collaborate dpia pro cess appropriate use processor illustrate technical elements processing activity dpia reproducing information processor example flow diagram processor manual however generally avoid copying large sections processor literature assessment relevant provisions legislation see article recitals gdpr external link need consult anyone seek document views individuals representatives unless good reason consult relevant internal stakeholders consult processor use one consider seeking legal advice expertise appropriate unless good reason seek document views individuals representatives intended processing operation dpia therefore important describe processing way consu lted understand relevant provisions legislation see article article gdpr external link assess necessity proportionality deployment system process personal data needs driven proven ability system fulfil specific legitimate purpose version auditing framework guidance consultation availability technology assessing necessity dpia evidence accomplish purposes less intrusive way dpia also allows demonstrate processing personal data system proportionate activity assessing proportionality need weigh interests using risks may pose rights freedoms individuals ystems need think detriment individuals could follow bias inaccuracy algorithms data sets used within proportionality element dpia need assess whether individuals would reasonably expect system conduct processing systems complement replace human decision document dpia project might compare human algorithmic accuracy better justify use also describe trade made example statistical accuracy data minimisation document methodology rationale identify assess risks dpia process help objectively identify relevant risks assign score level risk measured likelihood severity impact individuals use personal data development deployment systems may pose risks individuals information rights considering sources risk dpia consider potential impact material damage harm individuals instance machine learning systems may reproduce discrimination historic patterns data could fall foul equalities legislation similarly systems stop content published based analysis creator personal data could impact freedom expression contexts consider relevant legal frameworks beyond data protection relevant provisions legislation see articles recitals gdpr xternal link identify mitigating measures identified risk consider options reduce level assessed risk examples could data minimisation providing opportunities individuals opt processing version auditing framework guidance consultation ask dpo advice considering ways reduce avoid risk record dpia whether chosen measure reduces eliminates risk question important dpos information governance professionals involved projects earliest stages must clear open channels communicat ion project teams ensure identify address risks early lifecycle data protection afterthought dpo professional opinion come surprise eleventh hour use dpia document safeguards put place ensure individuals responsible development testing validation deployment monitoring systems adequately trained appreciation data protection implications processing dpia also evidence organisational measures put place appropriate training mitigate risks associated human error also document technical measures designed reduce risks security accuracy personal data processed system measures introduced mitigate risks identified dpia document residual levels risk posed processing required eliminate every risk identified however assessment indicates high risk unable sufficiently reduce required consult ico ahead processing conclude dpia record additional measures plan take whether risk eliminated reduced accepted overall level residual risk taking additional measures opinion dpo one whether need consult ico happens next although must carry dpia processing personal data begins also consider live document means reviewing dpia regularly undertaking reassessment appropriate nature scope context purpose processing risks posed individuals alter reason version auditing framework guidance consultation instance depending deployment could demographics target population may shift people adjust behaviour time response processing relevant provisions legislation see articles recital gdpr external link reading ico guidance read guidance dpias guide gdpr including list processing operations likely result high risk dpias legally required also read detailed guidance dpia including step described may also want read relevant sections guide lawfulness fairness transparency lawful basis processing data minimisation accuracy reading european data protection board european data protection boar edpb replaced article working party includes representatives data protection authorities member state adopts guidelines complying requirements gdpr produced guidelines data protection impact assessments endorsed edpb relevant guidelines include guidelines data protection officers dpos guidelines automated individual decision profiling version auditing framework guidance consultation understand relationships controllership important systems many cases various processing operations involved may undertaken number different organisations therefore crucial determine controller joint controller processor use involves multiple orga nisations first step understanding relationships identify distinct sets processing operations purposes see assess dpia organisations work need assess whether controller processor joint controller consult guidance assista nce assessment essence decide purposes means processing controller process personal data instruction another organisation processor jointly determine purposes means processing another organisation joint controllers usually involves processing personal data several different phases possible may controller joint controller phases processor others means processing decided controllers processors may discretion decide details means possible generalise every context following examples show kinds decisions means processing may indicate controller decisions details could taken processor type decisions may make controller type decisions likely make controller include deciding collect personal data first place purpose processing individuals collect data tell processing long retain data respond requests made line individuals rights version auditing framework guidance consultation specifics circumstances may make controller read guidance controllers processors context type decisions made controllers include source nature data used train model target output model predicted classified broad kinds algorithms used create models data regression models decision trees random forests neural networks feature selection features may used model key model parameters complex decision tree many models included ensemble key evaluation metrics loss functions trade false positives false negatives models continuously tested updated often using kinds data ongoing performance assessed whilst non list constitutes decisions purpose means make decisions likely controller another organisation jointly determine joint controllers decisions processors take conversely make decisions process data basis agreed terms likely processor processors different obligations depending terms contract controller able take certain decisions systems methods use process personal data store data security measures protect retrieve transfer delete dispose data context processors may able decide depending terms contract spe cific implementation generic algorithms programming language code libraries written data models stored formats serialised stored local caching version auditing framework guidance consultation measures optimise learning algorithms models minimise consumption computing resources implementing parallel processes architectural details models deployed choice virtual machines microservices apis make kinds decisions may processor rather controller practice means provide variety services without necessarily considered controller however key remember overarching decisions data processed purposes taken controller providing development tools stance might provide based service consisting dedicated cloud computing environment processing storage suite common tools services enable clients build run models data chosen process using tools infrastructure provide cloud example clients likely controllers whilst processor could therefore decide processor programming languages code libraries tools written configuration storage solutions graphical user interface cloud architecture clients controllers long take overarching decisions data models want use key model parameters processes evaluating testing updating models use clients data purposes decided become controller processing providing prediction service companies provide live prediction classification services customers instance might develop models allow customers send queries via api objects image get responses classification objects image case prediction service provider likely controller least processing first processing necessary create improve models wer services means purposes processing principally decided service provider likely controller processing second processing necessary make predictions classi fications particular examples behalf version auditing framework guidan consultation clients kind processing client likely controller processor however may even considered controller joint controller latter kind processing design services way customers sufficient influence essential elements purposes processing involved prediction instance enable customers set balance false positives negatives according requirements add remove certain features model may practice joint controller exerting sufficiently strong influence essential means processing furthermore initially process data behalf client part providing service process data clients improve models controller processing decided undertake purposes instance recruitment consultant might process job applicants data behalf clients using system provides scores applicant also retaining data improve system cases explicitly state purposes outset seek lawful basis see section purposes lawful bases information additionally data protection legislation states tha anyone acting authority controller processor shall process personal data except instructions controller unless required law need consider applies particular circumstances example processor permitted process instructions controller processes personal data due role processor processing may still infringe gdpr even purposes fair compatible original controller needs agree disclose data third controller data sharing operation needs comply data protection law relevant provisions legislation see article gdpr external link see sections dpa external link responsibilities procuring models local deployment companies sell provide free pre models standalone pieces software customers install run order develop market robust system organisations would purchase third parties likely processed personal data form train system however version auditing framework guidance consulta tion integrate system processing environment developer may play part processing providers make decisions processing personal data purposes training models sell controller processing however third party developers systems may intend process personal right controllers behalf processors procured models deploy model provider process personal data controller processing undertake using model provider services identify processing operations controller processor ensure clear clients procuring services different responsibilities part considerations selecting system process personal data remember compliance data protection law remains responsibility whether procure system build check developer des igned system including whether line data protection principles result assess whether using service going help meet processing objectives well data protection obligations controller writing contracts service level agreements also need remember contract might stipulate status controller processor matters data protection perspective practice decides purposes essential means processing similarly provider services identify processing operations controller processor ensure clear clients relevant provisions legislation see articles recital gdpr external link reading ico guidance read guidance guide gdpr version auditing framework guidance consultation resources see court justice european union cjeu judgment case unabhängiges landeszentrum für datens chutz uld schleswig wirtschaftsakademie holstein gmbh see also cjeu judgment case fashion gmbh verbraucherzentrale nrw trade manage use must comply requirements data protection law however number different values interests may times pull different directions risk approach data protection law help navigate potential trade privacy one hand competing values interest using therefore need iden tify assess interests strike appropriate balance given context whilst continuing meet obligations law right balance particular trade depends specific sectoral social context operate impact individuals however methods use assess mitigate trade relevant many use cases following sections provide short overview notable trade likely face designing procuring systems privacy statistical accuracy fairness data protection context generally means handle personal data ways people would reasonably expect use ways unjustified adverse effects improving statistical accuracy system outputs one considerations ensure compliance fairness principle important note word accuracy different meaning contexts data protection accuracy data protection one fundamental principles requiring ensure personal data accurate necessary kept date accuracy generally statistical modelling refers often system guesses correct answer many cases answers personal data accuracy principle applies personal data process system need statistically accurate order comply principle however statistically accurate version auditing framework guidance consultation system likely processing line fairness principle clarity guidance use term accuracy refer accuracy principle data protection law use term statistical accuracy refer accuracy system information differences data protection accuracy statistical accuracy see section need statistical accuracy general system learns data case models data trained statistically accurate likely capture underlying statistically useful relationships features datasets example model predicting future purchases based customers purchase history would tend statistically accurate customers includ training data new features added existing dataset may relevant model trying predict instance purchase histories augmented additional demographic data might improve statistical accuracy model however generally speaking data points collected person people whose data included data set greater risks individuals reading ico guidance read guidance data minimisation guide gdpr statistical accuracy discrimination discussed address risks bias discrimination section use systems lead biased discriminatory outcomes may turn pose compliance risks terms fairness princip need implement appropriate technical measures mitigate risk considerations also include impact techniques statistical accuracy system performance example reduce potential discrimination might modify credit risk model proportion positive predictions people different protected characteristics men women equalised may help prevent discriminatory outcomes could also resul higher number statistical errors overall also need manage version auditing framework guidance consultation practice may always tension statistical accuracy avoiding discrimination example discriminatory outcomes model driven relative lack data minority population statistical accuracy model could increased collecting data whilst also equalising proportions correct predictions however case would face different choice collecting data minority population interests reducing disproportionate number statistical errors face collecting data due risks posed rights freedoms individuals explainability statistical accuracy part fairness considerations also include trade explainability statistical accuracy systems complex systems based deep learning may hard follow logic system therefore difficult adequately explain work sometimes characterised black box problem depending circumstances may view complex systems statistically accurate effective especially comes problems like image recognition may therefore think face trade explainability statistical accuracy however many applications simpler models perform well trade explainability statistical accuracy may actually relatively small issues considered greater depth explain project guidance general point use black box models thoroughly considered potential impacts risks advance members team determined use case organisational support responsible design implementation systems system includes supplemental interpretability tools provide domain level explainability explainability exposure personal data commercial security providing individuals meaningful information logic driven decision potentially increase risk inadvertently disclosing information nee keep private including personal data also information proprietary logic system process recent research demonstrated proposed methods make models explainable unintentionally make easier infer personal data individuals whose data used train model see version auditing framework guidance consultation sections model inversion attacks membership inference attacks research also highlights risk course providing explanation individuals may accidentally reveal proprietary information model works however must take care conflate commercial interests data protection requirements commercial security data protection security instead consider extent trade genuinely exists research stakeholder engagement far indicate risk quite low however theory least may cases need consider right individuals receive explanation example interests businesses maintain trade secrets noting data protection compliance traded away risks active areas research likelihood severity subject debate investigation continue monitor review risks may update guidance accordingly manage offs cases striking right balance multiple trade matter judgement specific use case context system meant deployed whatever choices make need accountable efforts proportional risks system considering deploy poses individuals identify assess existing potential trade designing procuring system assess impact may individuals consider available technical approaches minimise need trade consider techniques implement reasonable level investment effort clear criteria lines accountability final trade decisions include robust risk independent approval process appropriate take steps explain trade individuals human tasked reviewing outputs review trade regular basis taking account among things views individuals representatives emerging techniques best practices reduce version auditing framework guidance consultation document processes outcomes auditable standard capture dpia appropriate level detail also document considered risks individuals personal data processed methodology identifying assessing trade scope reasons adopting rejecting particular technical approaches relevant prio ritisation criteria rationale final decision final decision fits within overall risk appetite also ready halt deployment systems possible achieve appropriate trade betw een two multiple data protection requirements outsourcing third systems either buy solution third party outsource altogether need conduct independent evaluation trade part due diligence process also required specify requirements procurement stage rather addressing trade post recital gdpr says producers solutions encouraged take account right data protection developing designing systems make sure controllers processors able fulfil data protection obligations ensure authority modify systems deployment either directly via third party provider align consider appropriate trade outset new risks considerations arise instance vendor may offer screening tool effectively scor promising job candidates may ostensibly require lot information candidate order make assessment procuring system need consider whether justify collecting much personal data candida tes request provider modify system seek another provider see section data minimisation version auditing framework guidance consultation culture diversity engagement stakeholders need make significant judgement calls determining appropriate trade effective risk management processes essential culture organisation also plays fundamental role undertaking kind exercise require collaboration different teams within organisation diversity incentives work collaboratively well environment staff feel encouraged voice concerns propose alternative approaches important social acceptability different contexts best practices relation trade subject ongoing societal debates consultation stakeholders outside organisation including affected trade help understand value place different criteria assessing offs worked example many cases trade precisely quantifiable lead arbitrary decisions perform contextual assessments documenting justifying assumptions relative value different requirements specific use cases one possible approach help identi best possible trade visually represent choices different designs graph plot possible choices system could designed graph two criteria balanced example statistical accuracy privacy axis statistical accuracy given precise measurement ways described section need statistical accuracy privacy measures likely less exact indicative nature could include amount personal data required sensitivity data extent might uniquely identify individual nature scope context purpose processing risks rights freedoms data processing may present individuals number individuals systems applied graph reveal known production frontier one way help decision makers understand system design decisions may impact balance different values version auditing framework guidance consultation used method figure visualise trade privacy statistical accuracy might look like presented senior decision maker responsible approving choice particular system help understand trade figure data points graph represent different possible technical configurations system resulting different design choices models amount types data used point represents possible end result particular trade statistical accuracy privacy scenario figure none proposed systems achieve high statistical accuracy high privacy trade privacy statistical accuracy significant different use case trade may look different visualised figure version auditing framework guidance consultation figure scenario may easier achieve reasonable trade statistical accuracy privacy graph also shows cost sacrificing either privacy statistical accuracy lower systems middle curve edge example diminishing returns statistical accuracy possible systems bottom right intend choose system would justify placing higher value statistical accuracy warranted circumstances need take account impact rights freedoms individuals able demonstrate processing still fair proportionate overall visual representati trade also include lower limits either variable willing figure version auditing framework guidance consultation figure scenario figure possible system meets lower limits statistical accuracy privacy suggesting pursue deployment systems may mean looking methods dat sources reformulating problem abandoning attempt use solve problem mathematical approaches minimise trade cases precisely quantify elements trade number mathematical mputer science techniques known constrained optimisation aim find optimal solutions minimising trade technical specialist engineer assess viability techniques particular context instance theory differential privacy provides framework quantifying minimising trade knowledge gained dataset statistical model privacy people similarly various methods exist create models optimise statistical accuracy also minimising mathematically defined measures discrimination version auditing framework guidance consultation approaches provide theoretical guarantees hard meaningfully put practice many cases values like privacy fairness difficult meaningfully quantify example differential privacy may able measure likelihood individual uniquely identified particular dataset sensitivity identification therefore always supplement methods qualitative holistic approach inability preci sely quantify values stake mean avoid assessing justifying trade altogether still need justify choices example controls risk statement inadequate inappropriate trade analysis decisions lea systems incorrectly prioritise one criterion another important criteria preventative clearly document purpose model important criteria model specification ensure specification signed ppropriate management senior management review various models trade analysis approve particular model use systematically review trade options provide justification specific model selected ensure reviews completed action taken result complete training ensure system designers date latest techniques detective periodic review trade given new data available since date deployment periodically analyse corrective select appropriate model include thorough justification change retrain system developers version auditing framework guidance consultation need ensure lawfulness fairness transparency systems glance use process personal data must ensure lawful fair transparent compliance principle may challenging context systems process personal data various stages variety purposes risk fail appropriately distinguish distinct processing operation identify appropriate lawful basi could lead failure comply data protection principle lawfulness section presents considerations help find appropriate lawful basis various kinds personal data processing involved creatin using ensure processing fair detail principles lawfulness fairness transparency apply identify purposes lawful basis using need statistical accuracy address risks bias discrimination principle lawfulness fairness transparency apply first development deployment systems involve processing personal data different ways different purposes must identify purposes appropriate lawful basis order comply ith principle lawfulness second use system infer data people order processing fair need ensure system sufficiently statistically accurate avoids discrimination consider impact individuals reasonable expectations version auditing framework guidance consu ltation finally need transparent process personal data system comply principle transparency core issues regarding transparency principle addressed explain guidance discussed detail identify purposes lawful basis using consider deciding lawful bases whenever processing personal data whether train new system make predictions using existing one must appropriate lawful basis different lawful bases may apply depending particular circumstances however lawful bases may likely appropriate training deployment others time must remember responsibility decide lawful basis applies processing must always choose lawful basis closely reflects true nature relationship individual purpose processing make determination start processing document decision swap lawful bases later date without good reason must include lawful basis privacy notice along purposes processing special categories data need lawful basis additional condition processing reading ico guidance read guidance lawful basis processing guide gdpr distinguish urposes development deployment many cases determining purpose lawful basis make sense separate development training systems deployment distinct separate purposes different circumstances risks therefore consider whether different lawful bases apply development deployment example need version auditing framework guidance consu ltation system trained general task deploy different contexts different purposes instance facial recognition system could trained recognise faces functionality could used multiple purposes preventing crime authentication tagging friends social network applications might require different lawful basis cases implement system third party processing personal data undertaken developer different purpose intend use system therefore may need identify different lawful basis processing personal data purposes training model may directly affect individuals model deployed may aut omatically make decisions legal significant effects means provisions automated decision making apply result different range available lawful bases may apply training deployment stages following sections outline considerations gdpr lawful bases consider part dpa stage rely consent consent may appropriate lawful basis cases direct relationship individuals whose data want process training deploying model however must ensure consent freely given specific informed unambiguous involves clear affirmative act part individuals advan tage consent lead trust buy individuals using service providing individuals control also factor dpias however consent apply individuals must genuine choice abo whether use data may implications depending intend data difficult ensure collect valid consent complicated processing operations example things want data difficult ensure consent genuinely specific informed key individuals understand using personal data consented use instance want collect wide range features explore different models predict variety outcomes consent may appropriate lawful basis provided inform individuals activities obtain valid consent version auditing framework guidance consultation consent may also appropriate lawful basis use individual data deployment system purposes personalising service making prediction recommendation however aware consent valid individuals must also able withdraw consent easily gave relying consent basis processing data system deployment drive personalised content ready accommodate withdrawal consent processing relevant provisions gdpr see articles recitals external link reading ico guidance read guid ance consent guide gdpr information reading data protection oard european data protection board edpb replaced article working party includes representatives data protection authorities member state adopts guidelines complying requirements gdpr adopted guidelines consent edpb endorsed may rely performance contract lawful basis applies processi using objectively necessary deliver contractual service relevant individual take steps prior entering contract individual request provide quote service less intrusive way processing data provide service processing practice objectively necessary performance contract rely lawful basis processing data furthermore even appropriate ground use system may appropriate ground processing personal data train system system perform well enough without trained individual personal data performance contract depend processing version auditing framework guidance consultation similarly even use performance contract lawful basis processing personal data provide quote prior contract mean also use justify using data train system also note unlikely able rely basis processing personal data purposes service improvement system cases collection personal data use service details users engage service development new functions within hat service objectively necessary provision contract service delivered without processing conversely use process personal data purposes personalising content may regarded necessa performance contract cases whether processing regarded intrinsic service depends nature service expectations individuals whether provide service without processing personalisation content means system integral service consider alternative lawful basis relevant provisions legislation see article recital gdpr external link reading ico guidance read guidance contracts guide gdpr information rea ding european data protection board european data protection board edpb replaced article working party includes representatives data protection authorities member state adopts guidelines complyi requirements gdpr edpb published guidelines processing personal data article context online services november version auditing framework guidance consultation rely legal obligation public task vital interests examples use system process personal data may legal obligation purposes detecting anti laundering part proceeds crime act similarly organis ation uses part exercise official authority perform task public interest set law necessary processing personal data involved may based grounds limited number cases processing ersonal data system might based protecting vital interests individuals example emergency medical diagnosis patients otherwise incapable providing consent processing fmri scan unconscious patien diagnostic system however unlikely vital interests could also provide basis training system would rarely directly immediately result protecting vital interests individuals even dels eventually built might later used save lives training potentially life systems would better rely lawful bases relevant provisions legislation see article recitals gdpr provisions using legal obligation external link see article recitals gdpr provisions using public interests see article article recital gdpr provisions using vital interests external link see sections schedule paras data protection act external link reading ico guidance read guidance legal obligation vital interests public task guide gdpr information rely legitimate interests depending circumstances could base processing personal data training ongoing use legitimate interests lawful basis version auditing framework guidance consultation important note legitimate interests flexible lawful basis processing always appropriate example way intend use people data would unexpected cause unnecessary harm also means taking additional responsibility considering protecting people rights interests additionally public authority rely legitimate interests processing legitimate reason performing tasks public authority three elements legitimate interests lawful basis help think three test need identify legitimate interest pur pose test show processing necessary achieve necessity test balance individual interests rights freedoms balancing test wide range interests constitute legitimate inter ests data protection law third parties well commercial societal interests however key understanding legitimate interests may flexible comes additional responsibilities requires assess impact processing individuals able demonstrate compelling benefit processing address document considerations part legitimate interests assessment example organisation seeks rely legitimate interests processing personal data purposes training machine learning model legitimate interests may allow organisation room experiment different variables model however part legitimate interests assessment organisation demonstrate range variables models intends use reasonable approach achieving outcome best achieve properly defining purposes justifying use type data collected allow organisation work necessity balancing aspects lia example mere ossibility data might useful prediction sufficient organisation demonstrate processing data necessary building model version auditing framework guidance consultation relevant provisions legislation see gdpr article recitals external link reading ico guidance read guidance legitimate interests guide gdpr also published lawful basis assessment tool use help decide basis appropriate well legitimate interests template word special category data data criminal offences intend use proces special category data data criminal offences need ensure comply requirements articles gdpr well dpa special category data personal data needs protection sensitive order process need lawful basis article well separate condition article although linked number conditions also require meet additional requirements safeguards set schedule dpa must determine document condition processing start ensure appropriate policy document place required complete dpia processing likely high risk data criminal offences need lawful basis article gdpr either lawful official authority article dpa sets specific conditions provide lawful authority also process type data official authority processing data official capacity special category data must determine condition processing identify official authority start also document version auditing framework guidance consultation relevant provisions legislation see articles gdpr external link reading ico guida nce read guidance special category data criminal offence data guide gdpr impact article gdpr data protection law applies automated individual decision making profiling article gdpr additional rules protect individuals carrying solely automated making legal similarly significant effects may application context using system make kinds decisions however carry type making decision necessary entry performance contract authorised law applies based individual explicit consent therefore identify processing falls article make sure give individuals informatio processing introduce simple ways request human intervention challenge decision carry regular checks make sure systems working intended reading ico guidance read guidance rights related automated decision maki including profiling guide gdpr version auditing framework guidan consultation example controls risk statement reliance inappropriate lawful basis processing results potential failure fulfil necessary requirements non legislation preventative ensure system developers completed training associated competency assessments document training key stakeholders relevant personnel identified senior management risk managers audit thoroughly assess justify lawful basis processing dpia consult specialists within model design workforce ensure requirement dpia documented developers provided clear guidance assessment criteria complete legitimate interests assessment reliance legitimate interests lawful basis detective monitor individual rights requests complaints indiv iduals including action taken result individual level boarder analysis conduct periodic dpia review ensure remains accurate date periodically assess model usage ensure purpose remains necessit legitimate interests still valid conduct periodic review records processing ensure validity lawful basis corrective implement corrective measures system order satisfy original lawful basis select new lawful basis associated actions example carrying legitimate interests assessment obtaining consent retrain system developers individuals involved assessment lawful bases version auditing framework guidance consultation need statistical accuracy statistical accuracy refers proportion answers system gets correct incorrect section explains controls implement ensure systems sufficiently statistically accurate ensure personal data process complies fairness principle difference accuracy data protection law statistical accuracy said section trade manage accuracy slightly different meanings data protection contexts data protection accuracy one fundamental principles requires take reasonable steps make sure personal data process incorrect misleading matter fact necessary corrected deleted without undue delay accuracy refers often sys tem guesses correct answer many contexts answers system provides personal data instance system might infer someone demographic information interests behaviour social network data protectio accuracy principle applies personal data whether information individual used input system output system however mean system needs statistically accurate order comply accuracy principle many cases outputs system intended treated factual information individual instead intended represent statistically informed guess something may true individual future order avoid personal data misinterpreted factual ensure records indicate statistically informed guesses rather facts records also clude information provenance data system used generate inference also record becomes clear inference based inaccurate data system used generate statistically flawed way may affected quality inference similarly processing incorrect inference may impact individual may request inclusion additional information record countering incorrect infe rence helps ensure decisions taken basis potentially incorrect inference informed evidence may wrong version auditing framework guidance consultation gdpr mentions statistical accuracy context profiling automated decision making recital states organisations put place appropriate mathematical statistical procedures profiling individuals part technical measures ensure factors may result inaccuracies personal data corrected risk errors minimised use system make inferences people need ensur system sufficiently statistically accurate purposes mean every inference correct need factor possibility incorrect impact may decisions may take basis failure could mean processing compliant fairness principle may also impact compliance data minimisation principle personal data including inferences must adequate relevant purpose system therefore needs sufficiently statistically accurate ensure personal data generated processed lawfully fairly however overall statistical accuracy particularly useful measure usually needs broken different measures important measure prioritise right ones see next section relevant provisions legislation see gdpr articles recital external link reading ico guidance read guidance accuracy guide gdpr well guidance rights rectification erasure reading european data protection board european data protection board edpb replaced article working party includes representatives data protection authorities member state adopts guidelines complying requirements gdpr published guidelines automated decision making profiling edpb endorse guidelines may version auditing framework guidance consultation define prioritise different statistical accuracy measures statistical accuracy general measure closely system predictions match correct labels defined test data example system used classify emails spam spam simple measure statistical accuracy number emails correctly classified spam spam proportion emails analysed however measure could misleading instance emails received inbox spam could create ccurate classifier simply labelling everything spam would defeat purpose classifier genuine email would get reason use alternative measures assess good system measures shoul reflect balance two different kinds errors false positive type error cases system incorrectly labels positive emails classified spam genuine false negative type error cases system incorrectly labels negative actually positive emails classified genuine actually spam important strike balance two types errors mor useful measures reflect two types errors including precision percentage cases identified positive fact positive also called positive predictive value instance nine emails classified spam actually spam precision system recall sensitivity percentage cases fact positive identified instance emails actually spam system identifies seven recall trade precision recall assessed using measures statistic link place importance finding many positive cases possible maximising recall may come cost false positives lowering precision addition may important differences consequences false positives false negatives individuals version auditing framework guidance consultation example filtering system selecting qualified candidates interview produces false positive unqualified candidate invited interview wasting employer applicant time unnecessarily produces false negative qualified candidate miss employment opportunity organisation miss good candidate prioritise avoiding certain kinds error based severity nature risks general statistical accuracy measure depends possible compare performance system outputs ground truth checking results system real world instance medical diagnostic tool designed detect malignant tumours could evaluated high quality test data containing known patient outcomes areas ground truth may unattainable could high test data exists trying predict classify subjective whether social media post offensive risk statistica accuracy misconstrued situations systems seen highly statistically accurate even though reflecting average set human labellers thought rather objective truth avoid record indicate outputs intended reflect objective facts decisions taken basis personal data reflect limitations also example must take account accuracy principle information see guidance accuracy principle refers accuracy opinions finally statistical accuracy static measure usually measured static test data real life situations systems applie new changing populations system statistically accurate existing population data customers last year may continue perform well change characteristics population population system applied future behaviours may change either accord adapting response system system may become less statistically accurate time phenomenon ref erred machine learning concept model drift various methods exist detecting instance measure distance classification errors time increasingly frequent errors may suggest drift regularly assess drift retrain model new data necessary part accountability decide document version auditing framework guidance consultation appropriate thresholds determining whether model needs retrained based nature scope context purposes processing risks poses example model scoring cvs part recruitment exercise kinds skills candidates need particular job likely change every two years anticipate assessing need train fresh data least often application domains main features change often recognising handwritten digits anticipate less drift need assess based circumstances reading ico guidance see guidance accuracy principle guide gdpr resources see define prioritise different statistical accuracy measures see learning concept drift overview explanation concept drift always think carefully start whether appropriate automate prediction making process include assessing effectiveness system making statistically accurate predictions individuals whose personal data processes assess merits using particular system light consideration effectiveness making accurate therefore valuable predictions systems demonstrate sufficient level statistical accuracy justify use decide adopt system comply data protection principles ensure functions individuals responsible development testing validation deployment monitoring adequately trained understand associated statistical accuracy requirements measures make sure data clearly labelled inferences predictions claimed factual ensure managed trade reasonable expectations version auditing framework guidance consultation adopt common terminology staff use discuss statistical accuracy performance measures including limitations adverse impact individuals else part obligation implement data protection design default consider statistical accuracy appropriate measures evaluate design phase test measures throughout lifecycle deployment implement monitoring frequency proportional impact incorrect output may individuals higher impact frequently monitor report also review statistical accuracy measures regularly mitigate risk concept drift change policy procedures take account outset statistical accuracy also important consideration outsource development system third party either fully partially purchase solution external vendor cases examine test claims made third parties part procurement process similarly agree regular updates reviews statistical accuracy guard changing population data concept model drift provider services ensure designed way allow organisations fulfil data protection obligations finally vast quantity personal data may hold process part systems likely put pressure pre processes use identify necessary inaccurate personal data whether used input data therefore need rev iew data governance practices systems ensure remain fit purpose example controls risk statement inaccurate output decisions made systems could lead unfair negative outcomes individuals failure meet fairness principle preventative put place data governance framework describes personal data used ongoing training testing evaluation system service correct accurate relevant representative complete possible version auditing framework guidance consultation provide training key stakeholders document relevant personnel identified senior management risk managers audit document access management controls segregation duties development deployment systems ensure changes affecting statistical accuracy made signed authorised persons maintain evidence controls monitored document levels approval authority systems maintain evi dence appropriate approval dpia include thorough assessment different errors maintain documented policies processes dealing third parties evidence due diligence completed particular procuring systems services ensure meet statistical accuracy requirements allow regular maintain document policy process performing pre implementation testing systems changes prior maintain idence testing completed prior deployment system results test detective post testing document results testing action taken result monitor output nce expectations conduct human review sample decisions statistical accuracy including sample selected criteria used document individual rights requests complaints regarding statistically inaccurate outputs systems individuals particular relating article including action taken result individual level broader analysis ensure continuous oversight third including regularl reviewing performance expectations adherence contractual requirements test system new data set confirm outcome reached corrective retrain system improving input data different balance false ositives negatives using different learning algorithm retrain system developers relation discriminatory model performance change decision made assess whether individuals could impacted inaccu racy version auditing amework draft guidance consultation ddress risk bias discrimination system learn data may unbalanced reflect discrimination may produce output discriminatory effects people based gender race age health religion disability sexual orientation characteristics fact systems learn data guarant outputs lead discriminatory effects data use trai test systems ell designed used ight lead system treat certain groups less favourably data protectio law ntended balance righ protection personal data function society processing personal data leads discrimination bias impact fairne processing poses compliance issues fairness principle wel risks individuals rights freedoms including right iscrimination furthermore gdpr specificall notes organisations hould take measure prevent discriminatory effect natural persons additionally ant legal framework notably equality act sits longside data protection law app lies range organisations thi include government departments service providers employers education providers transport providers association membership bodies well providers publi functions gives individuals protection discrimination whether generated human automate making system combination two section explor means practice context focusing machine learning system used assify make prediction abo individuals lead discrimination also explore technical organisational measures hat ado manage isk ight system lead discrimination let take hypothetical scenario example bank develops system calculate credit risk potential customers bank use system approve reject loan applications system trained large dataset containing range information previous borrowers occupation income age whether repaid loan testing bank wants check possible gender bias finds system tends give women lower credit scores version auditing framework guidance consultation two main reasons might one imbalanced training data proportion different genders training data may balanced example training data may include greater proportion male borrowers past fewer women applied loans therefore bank enough data women algorithm generate statistical model designed best fit data trained tested men training data model pay attention statistical relationships predict repayment rates men less statistical patterns predict repayment rates women might different put another way statistically less important model may systematically predict lower loan repayment rates women even women training dataset average likely repay loans men issues apply population represented training data example facial recognition model trained disproportionate number faces belonging particular ethnicity gender white men perform better recognising individuals group worse others another reason training data may reflect past discrimination instance past loan applications wome rejected frequently men due prejudice model based training data likely reproduce pattern discrimination certain domains discrimination historically significant problem likely experience problem acutely police stop young black men recruitment traditionally male roles issues occur even training data contain protected characteristics like gender race variety features training data often closely correlated protected characteristics occupation proxy variables enable model reproduce patterns discrimination associated characteristics designers intend problems occur statistical model however likely occur systems include greater number features may identify complex combinations features proxies protected characteristics many modern methods powerful traditional statistical approaches better version auditing framework guidance consultation uncovering non patterns high dimensional data however also include patterns reflect discrimination technical approaches mitigate discrimination risk models discrimination roader problem realistically fixed technology various approaches mitigate discrimination computer scientists others developing different mathematical techniques measure models treat individuals different groups potentially discriminatory ways field often referred algorithmic fairness many techniques early stages development may ready basic approac hes developers take measure mitigate potential discrimination resulting systems cases imbalanced training data may possible balance adding removing data subsets population adding data points loan applications women alternatively could train separate models example one men another women design perform well possible however cases creating different models different protected classes could violation non law different car insurance premiums men women cases training data reflects past discrimination could either modify data change learning process modify model training order techniques effective need choose one mathematical fairness measures measure results measur grouped three broad categories outcome error parity equal calibration model fair excludes protected characteristics making classification prediction anti classification approaches also try identify exclude proxies protected characteristics attendance single school impractical removing possible proxies may leave predictively useful features also ften hard know whether particular variable combination variables proxy protected characteristic without data collection analysis version auditing framework guidance consultation outcome error parity compares members different protected groups treated model outcome parity model fair gives equal numbers positive negative outcomes different groups error parity model fair gives equal numbers errors different groups error parity broken parity false positives false negatives see section statistical accuracy details equal calibration calibration measures closely model estimation likelihood something happening matches actual frequency event happening according equal calibration model fair equally calibrated members different pro tected groups instance classification model sorts loan applicants low medium high chance repayment equal proportions male female applicants actually repay within risk category mean equal proportions men women across different risk categories instance women actually higher repayment rates men may women men low risk category unfortunately different measures may often incompatible therefore need consider conflicts carefully selecting particular approach example equal calibration incompatible outcome error parity except rare cases actual distribution outcomes equal different protected groups attempting achieve outcome parity removing protected characteristics required anti measures may result learning algorithm finding using irrelevant proxies order create model equalises outcomes may unfair process special category data assess address discrimination systems techniques discussed require access dataset containing personal data representative sample population person represented data need labels protected characteristics interest outlined equality act cou use dataset containing protected characteristics test system performs protected group also potentially model performs fairly kind analysis need ensure appropriate lawful basis process data purposes different data protection considerations depending kinds discrimination testing testing system discriminatory impact age sex gender special data protection conditions processing protected characteristics version auditing framework guidance consultation classifi special category data data protection law still need consider broader questions lawfulness fairness risks processing poses whole possibility data either special category data anyway becoming processing processing involves analysing inferring data health genetic status also note dealing personal data results specific technical processing physical physiological behavioural characteristics individual allows confirms individual unique identificat ion data biometric data use biometric data purpose uniquely identifying individual also special category data system uses biometric data testing mitigating discrimination pur pose confirming identity individuals within dataset making kind decision relation biometric data come article data still regarded biometric data gdpr special category data similarly personal data allow confirm individual unique identification biometric data special category data however protected characteristics outlined equality act classified special category data include race religion belief sexual orientation may also include disability pregnancy gender reassignment far may reveal information person health similarly civil partnerships recently available couples data indicates someone civil partnership may indirectly reveal sexual orientation testing system discriminatory impact basis characteri stics likely need process special category data order lawfully addition lawful basis article need meet one conditions article gdpr also require additional basis authorisation law found schedule dpa conditions processing special category data appropriate depends individual circumstances example using special category data ssess discrimination identify promote maintain equality opportunity organisation using scoring system assist recruitment decisions needs test whether system discriminating religious philosophical belie version auditing framewor guidance consultation collects religious beliefs sample job applicants order assess whether system indeed producing disproportionately negative outcomes erroneous predictions organisation relies substantial public interest condition article equality opportunity treatment condition schedule dpa provision used identify keep review existence absence equality opportunity treatment certain protected groups view enabling equality promoted maintained example using special category data assess discrimination research purposes university researcher investigating whether facial recognition systems available market perform differently faces people different racial ethnic origin part research project order researcher assigns racial labels existing dataset faces system tested thereby processing special category dat rely archiving research statistics condition article read schedule paragraph dpa finally protected characteristics using assess improve potentially discriminatory origin ally processed different purpose consider whether new purpose compatible original purpose obtain fresh consent required example data initially collected basis consent even new purpose compatible still need collect fresh consent new purpose new purpose incompatible ask consent relevant provisions legislation see article recitals gdpr external link see schedule dpa exte rnal link reading ico guidance read guidance purpose limitation special category data guide gdpr version auditing framework guidance con sultation special category data discrimination automated decision using special category data assess potential discriminatory impacts systems usually constitute automated making data protection law involve directly making decisions individuals similarly discriminatory model data diverse population order reduce discriminatory effects involve directly making decisions individuals therefore classed decision legal similarly significant effect however cases simply model diverse training set may enough sufficiently mitigate discriminatory impact rather trying make model fair ignoring protected characteristics making prediction approaches directly include characteristics making classification order ensure members potentially disadvantaged groups protected instance using system sort job applicants rather attempting create model ignores pers disability may effective include disability status order ensure system discriminate including disability status input automated decision could mean system likely discriminate people disability factor effect condition features used make prediction approach amounts making decisions individuals solely automated way significant effects using special category data prohibited gdpr unless explicit consent individual meet one substantial public interest conditions laid schedule dpa need carefully assess whi conditions schedule may apply example equality opportunity monitoring provision mentioned relied contexts processing carried purposes decisions particular individual therefore approaches lawful based different substantial public interest condition schedule accidentally infer special category data use many contexts non characteris tics postcode live proxies protected characteristic like race recent advances machine learning deep learning made even easier systems detect patterns world reflected seemi ngly unrelated data unfortunately also includes detecting patterns discrimination using complex combinations features might correlated protected characteristics non ways version auditing framework guidance consultation instance system used score job applications assist human decision maker recruitment decisions might trained examples previously successful candidates information contained application may include protected characteristics like race disability mental health however examples employees used train model discriminated grounds systematically rated performance reviews algorithm may learn reproduce discrimination inferring characteristics proxy data contained job application despite designer never intending eve use protected characteristics model possible may inadvertently use model detected patterns discrimination based protected characteristics reproducing outputs described protected characteristics also special category data special category data defined personal data reveals concerns special categories model learns use particular combinations features ufficiently revealing special category model may processing special category data stated guidance special category data use profiling intention inferring special category data special catego data irrespective whether inferences incorrect furthermore reasons stated may also situations model infers special category intermediate step another data inference may able tell model looking data went model outputs produces may high accuracy even though intend using machine learning personal data proactively assess chances model might inferring protected characteristics special category data order make predictions actively monitor possibility throughout lifecycle system potentially inferred characteristics special category data ensure appropriate article condition processing noted model used make legal similarly significant decisions solely automated way lawful person consent meet substantial public interest condition appropriate provision schedule reading ico guidance read guidance special category data information version auditing framework guidance consultation mitigate risks appropriate approach managing risk discriminatory outcomes systems depend particular domain context operating determine document approach bias discrimination mitigation beginning application lifecycle take account put place appropriate safeguards technical measures design build phase establishing clear policies good practices procurement lawful processing high training test data important especially enough data internally whether procured internally externally satisfy data representative population apply system although reasons stated sufficient ensure fairness example high street bank operating training data could compared recent census senior management responsible signing chosen approach manage discrimination risk accountable compliance data protection law able leverage expertise technology leads internal external subject matter experts accountable senior leaders still need sufficient understanding limitations advantages different approaches also true dpos senior staff oversight functions expected provide ongoing advice guidance appropriateness measures safeguards put place mitigate discrimination risk many cases choosing betwe different risk management approaches requires offs see section manage includes choosing safeguards different protected characteristics groups need document justify approach choose offs driven technical approaches always obvious non technical staff data scientists highlight explain proacti vely business owners well staff responsibility risk management data protection compliance technical leads also proactive seeking domain knowledge including known proxies protected characteristics inform algorithmic fairness approaches undertake robust testing anti measures monitor system performance ongoing basis risk management policies clearly set process person responsible final validation system deployment appropriate update version auditing framework guidance consultation discrimination monitoring purposes organisational policies set variance tolerances selected key performance metrics well escalation variance investigation procedures also clearly set variance limits system stop used replacing traditional decision systems consider running concurrently period time investigate significant difference type cisions loan acceptance rejection different protected groups two systems differences system predicted perform practice beyond requirements data protection law diverse workforce powerful tool identifying managing bias discrimination systems organisation generally finally area best practice technical approaches continue develop invest time res ources ensure continue follow best practice staff remain appropriately trained ongoing basis cases may actually provide opportunity uncover address existing discrimination traditional decision proce sses allow address underlying discriminatory practices resources equality act external link european charter fundamental rights external link example controls risk statement discriminatory output decisions made systems could lead statistically inaccurate decisions individuals certain groups preventative put place data governance framework describes personal data used ongoing training testing evaluation system correct accura relevant representative complete possible ensure developers completed training associated competency assessments identify address bias discrimination systems provide training key stakeholders document relevant personnel identified senior management risk managers audit version auditing framework guidance consultation document access management controls segregation duties development deployment systems ensure changes affecting statistical accuracy made signed authorised persons maintain evidence controls monitored document levels approval authority systems maintain evidence appropriate approval dpia include thorough assessment risk discrimination mitigants controls place prevent maintain documented policies processes dealing third parties evidence due diligence completed maintain documented process section peer review system design maintain evidence review completed maintain documented policy process performing pre implementation testing systems changes prior maintain evidence testing completed results test document levels approval attestation diversity representation training test data prior use within system maintain evidence appropriate approval detective regularly monitor algorithmic fairness using appropriate measures document levels approval attestation diversity representation training test data prior use within system maintain evidence appropriate approval regularly review model performance recent data corrective add remove data overrepresented groups including thorough analysis justification retrain model fairness constraints retrain model designers relation discriminatory model performance version auditing framework guidance consultation assess security data minimisation glance systems exacerbate known security risks make difficult manage also present challenges compliance data minimisation principle exacerbate known security risks make difficult manage two secu rity risks increase potential loss misuse large amounts personal data often required train systems potential software vulnerabilities introduced result introduction new code infrastructure default standard practices developing deploying involve processing large amounts data risk fails comply data minimisation principle number techniques exist enable data minimisation effective development deployment detail security risks introduce types privacy attacks apply models steps take manage risks privacy attacks models data minimisation privacy techniques available systems security risks introduce must process personal data manner ensures appropriate levels security unauthorised unlawful processing accidental loss destruction damage section focus way adversely affect security making known risks worse challenging control security requirements one approach security appropriate security measures adopt depend level type risks arise specific processing activities version auditing framework guidance consultation using process personal data important implications security risk profile need assess manage carefully implications may triggered introduction new types risks adversarial attacks machine learning models see section reading ico guidance read guidance security guide gdpr security outcomes general information security data protection law information security key component auditing framework also central work information rights regulator ico planning expand general security guidance take account additional requirements set new gdpr guidance specific cover range topics relevant organisations using including software supply chain security increasing use software different security compared traditional technologies unique characteristics mean compliance data protection law security requirements challenging established technologies technological human perspective technological perspective systems introduce new kinds complexity found traditional systems may used using depending circumstances use systems also likely rely heavily third party code relationships suppliers also existing systems need integrated several new existing components also intricately connected complexity may make difficult identify manage security risks may increase others risk outages human perspective people involved building deploying systems likely wider range backgrounds usual including traditional software engineering systems administration data scientists statisticians well domain experts security practices expectations may vary significantly may less understanding broader security compliance requirements well data protection law specifically security personal data may always key priority especially someone previously building applications non data research capacity version auditing framework guidance consultation complications arise common practices process personal data securely data science engineering still development part compliance security principle ensure actively monitor take account state security practices using personal data context possible list known security risks might exacerbated use process personal data impact security depends way technology built deployed complexity organisation deployin strength maturity existing risk management capabilities nature scope context purposes processing personal data system risks posed individuals result following hypothetical scenar ios intended raise awareness known security risks challenges exacerbate key message review risk management practices ensuring personal data secure context case study losing track training data systems require large sets training testing data copied imported original context processing shared stored variety formats places including third parties make difficult keep track manage example organisation decides use system offered third recruiter part hiring process effective organisation needs share data imilar previous hiring decisions sales manager recruiter previously organisation used entirely manual scanning process led sharing personal data candidates cvs involve transfer large uantities personal data organisation recruiter organisation must ensure appropriate lawful basis processing beyond sharing additional data could involve creating multiple copies different formats stored different locations see require important security information governance considerations version auditing framework guidance consultation organisation may need copy recruitment data separate database system examine select data relevant vacancies recruitment firm working selected data subsets need saved exported files transferred recruiter compressed form upon receipt recruiter could upload files remote location cloud cloud files may loaded programming environment cleaned used building system ready data likely saved new file used later time organisation recruiter time data copied stored different places increased risk personal data breach including unauthorised processing loss destruction damage example copies training data need shared managed necessary deleted line security policies many recruitment firms already information governance security policies place may longer fit adopted reviewed necessary updated circumstance technical teams record document movements storing personal data one location another help apply appropriate security risk controls monitor effectiveness clear audit trails also necessary satisfy accountability documentation requirements addition delete intermediate files containing personal data soon longer required compressed versions files created transfer data systems depending likelihood severity risk individuals may also need apply techniq ues training data extracted source shared internally externally example may need remove certain features data apply privacy enhancing technologies pets sharing another organisation case study security risks introduced externally maintained software used build systems organisations build systems entirely house cases design building running systems provided least part third parties organisation may always contractual relationship version auditing framework guidance consultation even hire engineers may still rely significantly frameworks code libraries many popular development frameworks open source using party open source code valid option developing software components system scratch requires large investment time resources many organisations afford especially compared open source tools would benefit rich ecosystem contributors services built around existing frameworks however one important drawback standard frameworks often depend pieces software already installed system give sense risks involved recent study found popular development frameworks include lines code rely external dependencies therefore implementing require changes organisation software stack possibly hardware may introduce additional security risks example recruiter hires engineer build automated filtering system using based framework framework depends number specialist source programming libraries needed downloaded recruiter system one libraries contains software function convert raw training data format required train model later discovered function security vulnerability due unsafe default configuration attacker introduced executed malicious code remotely system disguising training data far example january vulnerability discovered numpy popular library python programming language used many machine learning develo pers circumstance whether systems built house externally combination need assess security risks well ensuring security code developed house need assess security externally maintained code frameworks many respects standard requirements maintaining code managing security risks apply applications example external code security measures inclu subscribing security advisories notified vulnerabilities internal code security measures include adhering coding standards instituting source code review processes version auditing framework guidance consultation whatever approach need ensure staff appropriate skills knowledge address security risks additionally develop systems mitigate security risks associated third party code separating development environment rest infrastructure possible two ways achieve using virtual machines containers computer system run inside isolated rest system configured specifically tasks recruitment example engineer used virtual machine vulnerability could contained many systems developed using programming languages well scientific machine learning uses like python necessarily secure however possible train model using one programming language python deployment convert model another language java makes making insecure coding less likely return recruitment example another way engineer could mitigated risk malicious attack filtering model would convert model different programming language prior deployment reading ico guidance read report protecting personal data online services learning mistakes others pdf information although written report content area may still assist ico developing security guidance include additional recommendations oversight review externally maintained source code data protection perspective well implications security data protection design resources guidance national cyber security centre ncsc maintaining code repositories may also assist types privacy attacks apply models personal data people system trained might inadvertently revealed outputs system version auditing framework guidance consultation normally assumed personal data individuals whose data used train system inferred simply observing predictions system returns response new inputs however new types privacy attacks models suggest sometimes possible update focus two kinds privacy attacks model inversion membership inference model inversion attacks model inversion attack attackers already access personal data belonging specific individuals included training data infer personal information individuals observing inputs outputs model information attackers learn goes beyond generic inferences individuals similar characteristics figure illustration model inversion membership inference attacks reproduced veale remember model inversion attacks data protection law example one model inversion attack early demonstration kind attack concerned medical model designed predict correct dosage anticoagulant using patient data including genetic biomarkers proved attacker access demographic information individuals included training data could infer genetic biomarkers model despite access underlying training data version auditing framework guidance consultation example two model inversion attack another recent example demonstrates attackers could reconstruct images faces facial recognition technology frt system trained recognise frt systems often designed allow third parties query model model given image person whose face recognises model returns best guess name person associated onfidence rate attackers could probe model submitting many different randomly generated face images observing names confidence scores returned model could reconstruct face images associated individuals inc luded training data reconstructed face images imperfect researchers found could matched human reviewers individuals training data accuracy see figure figure face image recovered using model inversion attack left corresponding training set image right fredriksen inversion attacks exploit conﬁdence information resources algorithms remember model inversion attacks data protection law simple demographics often identify people uniquely model inversion attacks exploit confidence informatio basic countermeasures membership inference attacks membership inference attacks allow malicious actors deduce whether given individual present training data model however version auditing framework guidance consultation unlike model inversion necessarily learn additional personal data individual instance hospital records used train model predicts patient discharged attackers could use model combination data particular individual already work part training data would reveal individual data training data set practice would reveal visited one hospitals generated training data period data collected similar earlier frt example membership inference attacks exploit confidence scores provided alongside model prediction individual training data model disproportionately confident prediction tha person seen allows attacker infer person training data gravity consequences models vulnerability membership inference depend sensitive revealing membership migh model trained large number people drawn general population membership inference attacks pose less risk model trained vulnerable sensitive population patients dementia hiv merel revealing someone part population may serious privacy risk black box white box attacks important distinction black box white box attacks models two approaches correspond differe operational models white box attacks attacker complete access model inspect underlying code properties although training data example providers give third parties entire pre trained model allow run locally white box attacks enable additional information gathered type model parameters used could help attacker inferring personal data model black box attacks atta cker ability query model observe relationships inputs outputs example many providers enable third parties access functionality model online send queries containing input data receive model response examples highlighted black box attacks white black box attacks performed providers customers anyone else either authorised unauthorised access either model que response functionality respectively version auditing framework guidance consultation models include training data design model inversion membership inferences show models inadvertently contain personal data also note certain kinds models actually contain parts training data raw form within design instance support vector machines svms neighbours knn models contain training data model cases training data personal data access model means organisation purchasing model already access subset personal data contained training data without exert efforts providers models third parties procuring aware may ntain personal data way unlike model inversion membership inference personal data contained models like attack vector personal data contained models would design easily retrievable third party storing using models therefore constitutes processing personal data standard data protection provisions apply steps take manage risks privacy attacks models train models provide others assess whether models may contain personal data risk revealing attacked take appropriate steps mitigate risks assess whether training data contains identified identifiabl personal data individuals either directly may access model assess means may reasonably likely used light vulnerabilities described rapidly developing area hould stay state art methods attack mitigation security researchers still working understand factors make models less vulnerable kinds attacks design effective protections mitigation strategies one possible cause models vulnerable privacy attacks known overfitting model pays much attention details training data effectively almost remembering parti cular examples training data rather general patterns model inversion membership inference attacks exploit avoiding overfitting help mitigating risk privacy attacks also ensuring model able make good inferences new examples seen however avoiding overfitting version auditing framework guidance consultation completely eliminate risks even models overfitted training data still vulnerable privacy attacks cases confidence information provided system exploited frt example risk could mitigated providing end user would need balanced need genuine end users know whether rely output depend particular use case context going provide whole model others via application programming interface api would subject white attacks way api users would direct access model however might still subjected black box attacks mit igate risk could monitor queries api users order detect whether used suspiciously may indicate privacy attack would require prompt investigation potential suspension blocking particular user account measures may become part common time monitoring techniques used protect security threats rate reducing number queries performed particular user given time limit model going provided whole third party rather merely accessible via api need consider risk white box attacks model provider less easily able monitor model deployment thereby assess mitigate risk privacy attacks however remain responsible ensuring personal data used train models exposed result way clients deployed model may able fully assess risk without collaborating clients understand particular deployment contexts associated threat models part procurement policy sufficient information sharing party perform respective assessments necessary cases model providers clients joint controllers therefore need perform joint risk assessment cases model actually contains examples training data default svms knns mentioned transfer personal data treat adversarial examples main data protection concerns involve accidentally revealing personal data potential novel security risks adversarial examples examples fed model deliberately modified reliably misclassified images version auditing framework guidance consultation manipulated even real modifications stickers placed surface item examples include pictures turtles classi fied guns road signs stickers human would instantly recognise stop image recognition model adversarial examples concerning security perspective might themselve raise data protection concerns involve personal data security principle refers security personal data protecting unauthorised processing however adversarial attacks necessarily involve unauthorised processing personal data compromise system however may cases adversarial examples risk rights freedoms individuals instance attacks demonstrated facial recognition systems slightly distorting face image one individual adversary trick facial recognition system misclassifying another even though human would still recognise distorted image correct individual would raise concern system statistical accuracy especially system used make legal similarly significant decisions individuals may also need consider risk adversarial examples part obligations nis directive ico competent authority relevant digital service providers nis include online search engines online marketplaces cloud computing services nis incident includes incidents compromise data stored network information systems related services provide likely include cloud computing services even adversarial attack involve personal data may still nis incident therefore within ico remit reading ico guidance information nis regulations including whether qualify relevant digital service provider read guide nis example controls risk statement infrastructure architecture systems increases likelihood unauthorised access alteration destruction personal data preventative subscribe security advisories receive alerts vulnerabilities comply assess system external security certifications schemes version auditing framework guidance consultation subject software quality review one individuals view read parts source code least one reviewers must author code document policy process separation development environment rest network infrastructure evidence separation adhered happened approach asset management ensure coordinate approach optimisation costs risks sustainability document contracts third parties clear role responsibilities third parties document policies processes dealing third parties evidence due diligence information security completed document policy processes breach reporting escalation adhere policy process model governance policy assess secure implementations trained model mplement appropriate post development processes place review latest privacy enhancing techniques assess technique applicability context implement appropriate document dpia including thorough assessment security risks mitigants controls reduce likelihood impact attack api access policy place monitors volume patterns requests identify report sus picious activity ensure staff trained understand breach reporting policy procedures follow detective monitor api requests detect suspicious requests take action result regularly test assess evaluate effectiveness security measures put place techniques penetration testing monitor complaints monitoring take action result including broader analysis identify individuals may impacted corrective evidence changes made system design including analysis justification reduce risk future attacks version auditing framework guidance consultation data minimisation privacy techniques available systems considerations data minimisation principle need make data minimisation principle requires identify minimum amount personal data need fulfil purpose process information example article gdpr says quote personal data shall adequate relevant limited necessary relation purposes hey processed data minimisation however systems generally require large amounts data first glance may therefore difficult see systems comply data minimisation principle yet using part processing still required whilst may appear challenging practice may case data minimisation principle mean either process personal data process going break law key process personal data need purpose determining adequate relevant limited therefore going specific circumstances existing guidance data minimisation deta ils steps take context systems adequate relevant limited therefore also case specific however number techniques adopt order develop systems process data need still remaining functional section explore relevant techniques supervised machine learning systems currently common type use within organisations individuals acc ountable risk management compliance systems need aware techniques exist able discuss assess different approaches technical staff example default approach data scientists designing building systems might involve collecting using much data possible without thinking ways could achieve purposes less data must therefore implement risk management practices designed ensure data minimis ation relevant minimisation techniques version auditing framework guidance consultation fully considered design phase similarly buy systems implement systems operated third parties considerations form part procurement process due diligence also aware may help comply principle data minimisation techniques described eliminate kinds risk also techniques require compromise comply data minim isation requirements others may need balance data minimisation compliance utility objectives making statistically accurate non models see trade section detail first step take towards compliance data minimisation understand map processes personal data might used relevant provisions legislation see article recital article right rectification article right erasure gdpr external link reading ico guidance read guidance data minimisation principle guide gdpr process personal data supervised models supervised algorithms trained identify patterns create models datasets training data include past examples type instances model asked classify predict specifically training data contains target variable thing model aiming predict classify several predictor variables input used make prediction instance training data bank credit risk model predictor variables might include age income occupation location previous customers target variable whether customers repaid loan trained systems classify make predictions based new data containing examples system never seen query sent model containing predictor variables new instance new customer age income occupation model responds best guess target variable new instance whether new customer default loan version auditing framework guidance consultation supervised approaches therefore use data two main phases training phase training data used develop models based past examples inference phase model used make prediction classification new instances model used make predictions classifications individual people likely personal data used training inference phases techniques use minimise personal data designing applications designing building applications data scientists generally assume data used training testing operating system aggregated centralised way held full original form single entity multiple places throughout system lifecycle however personal data need consider whether necessary process purpose achieve outcome processing less personal data definition data minimisation principle requires number techniques exist help minimise amount personal data need process minimise personal data training stage explained training phase involves applying learning algorithm dataset containing set features individual used generate prediction classificati however features included dataset necessarily relevant purpose example financial demographic features useful predict credit risk therefore need assess features therefore data relevant purpose process data variety standard feature selection methods used data scientists select features usefu inclusion model methods good practice data science also way towards meeting data minimisation principle also discussed ico previous report big data fact data might later process found useful making predictions enough establish need keep purpose retroactively justify collection use retention must collect personal data might useful version auditing framework guidance consultation future although may able hold information foreseeable event may occur able justify reading ico guidance read report big data artificial intelligence machine learning data protection privacy methods consider also range techniques enhancing privacy use minimise personal data processed training phase including perturbation adding noise federated learning techniques involve modifying training data reduce extent traced back specific individuals retaining use purposes training well models apply types enhancing techniques training data already collected possible however apply collecting personal data part mitigating risks individuals large datasets pose measure effectiveness privacy techniques balancing privacy individuals utility system mathematically using methods differential privacy differential privacy way measure whe ther model created algorithm significantly depends data particular individual used train mathematically rigorous theory meaningfully implementing differential privacy practice still challenging monitor developments methods assess whether provide meaningful data minimisation particular context attempting implement perturbation modification could involve changing values data points belonging individuals random known perturbing adding noise data way preserves statistical properties features generally speaking choose much noise inject obvious consequences much still learn noisy data instance smartphone predictive text systems based words users previously typed rather always collecting user actual keystrokes system could designed create noisy false version auditing framework guidance consultation words random means makes substantially less certain words noise words actually typed specific user although data would less accurate individual level provided system enough users could still observe patterns use train model aggregate level noise inject less learn data cases may able inject sufficient noise render data pseudonymous way provides meaningful level protection federated learning related preserving technique federated learning allows multiple different parties train models data local models combine patterns models identified known gradients single accurate global model without share training data federated learning relatively new several large applications include auto correction predictive text models across smartphones also medical research involving analysis across multiple patient databases sharing gradient derived locally trained model presents lower privacy risk sharing training data gradient still reveal personal informatio individuals derived especially model complex lot fine variables therefore still need assess risk case federated learning participating organisations may nsidered joint controllers even though access data reading information controllership read section rela tionships see rappor randomised aggregatable privacy preserving ordinal responses example perturbation minimise personal data inference sta make prediction classification individual models usually require full set predictor variables person included query training phase number techniques use minimise personal data mitigate risks posed data inference stage including converting personal data less human readable formats making inferences locally preserving query approaches version auditing framework guidance consultation consider approaches converting personal data less human readable formats many cases process converting data format allows classified model way towards minimising raw personal data usually first converted abstract format purposes prediction instance human words normally translated series numbers called feature vector means deploy model may need process human version personal data contained query example conversion happens user device however fact longer easily interpretable imply converted data longer personal consider facial recognition technology frt example order facial recognition model work digital images faces classified converted faceprints mathematical representations geometric properties underlying faces distance person nose upper lip rather sending facial images servers photos could converted faceprints directly individuals device captures sending model querying faceprints would less easily identifiable humans face photos however faceprints still personal indeed biometric data therefore much identifiable within context facial recognition models use used purposes uniquely identifying individual would special category data data protection law making inferences locally another way mitigate risks involved sharing predictor variables host model device query generated already collects stores individual personal data example model could installed user device make inferences locally rather hosted cloud server instance models predicting news ntent user might interested could run locally smartphone user opens news app day news sent phone local model would select relevant stories show user based user personal bits profile information tracked stored device shared content provider app store constraint models need sufficiently small computationally efficient run user hardware however recent advances purpose hardware smartphones embedded devices mean increasingly viable option version auditing framework guidance consultation important note local processing necessarily scope data protection law even personal data involved training processed user device organisation creates distributes model still controller far determines means purposes processing similarly personal data user device subsequently accessed third party activity would constitute processing data query approaches feasible deploy model locally enhancing techniques exist minimise data revealed query sent model allow one party retrieve prediction classificat ion without revealing information party running model simple terms allow get answer without fully reveal question reading see privad practical privacy online advertising external link targeted advertising handset privacy security challenges external link proof concept examples making inferences locally see tapas trustworthy privacy participatory sensing example privacy query approaches anonymisation role conceptual technical similarities data minimisation anonymisation cases applying preserving techniques means certain data used systems rendered eudonymous anonymous however note pseudonymisation essentially security risk reduction technique data protection law still applies personal data undergone pseudonymisation contrast anonymous information means information question longer personal data data protection law apply reading ico currently developing new guidance anonymisation take account new recent developments technique field storing limiting training data sometimes may necessary retain training data order model instance new modelling approaches become available debugging however whe model established unlikely modified training data may longer needed version auditing framework guidance consu ltation model designed use last months worth data data retention policy specify data older months deleted reading european union agency network information security enisa number publications pets including research reports external link example controls risk statement developers properly assess adequacy necessity relevance personal data used systems systems resulting noncompliance data minimisation principle preventative document levels approval authority systems including personal data sets included within model evidence appropriate approval review personal data relevance stage model development includ ing detailed justification retention data confirmation irrelevant data removed deleted separate data different stages lifecycle based conditions data minimisation principle document retention policy schedule evidence schedule adhered personal data deleted line schedule retention outside schedule justified approved carry independent review model input output specifically regarding relevance personal data inputs document dpia including thorough assessment pets considered considered appropriate detective periodic review features within model check still relevant testing systems fewer features see results achieved view reducing amount personal data processed monitor individual rights requests complaints individuals including action taken result individual level boarder analysis periodically assess whether model remains compliant data minimization processes used third parties corrective version auditing framework guidance consultation remove delete non features select less invasive model including thorough justification change remove erase training data longer required data longer predictively useful implement appropriate pets version auditing framework guidance consultation enable individual rights systems glance way systems developed deployed means personal data often managed processed unusual ways may make harder understand individual rights apply data challenging implement effective mechanisms individuals exercise rights detail individual rights apply different stages lifecycle individual rights relate personal data contained model enable individual rights relating solely automated decisions legal similar effect role human oversight individual rights apply different stages lifecycle data protection law individuals number rights relating personal data within rights apply wherever personal data used various points development deployment lifecycle system therefore covers personal data contained training data used make prediction deployment result prediction might contained model section describes considerations may encounter developing deploying attempti comply individual rights information access rectification erasure restriction processing data portability object rights referred articles gdpr cover right detail discusses general challenges facilitating rights context appropriate mentions challenges specific rights rights individuals solely automated decisions affect legal similarly significant ways discussed detail version auditing framework guidance consultation role human oversight rights raise particular challenges using enable individual rights requests training data creating using models invariably need obtain data train models instance retailer creating model predict consumer purchases based past transactions needs large dataset customer transactions train model identifying individuals training data potential challenge enabling rights typically training data includes information relevant predictions past transactions demographics location contact details unique customer identifiers training data also typically subjected various measures make amena ble algorithms however detailed timeline customer purchases might transformed summary peaks troughs transaction history process transforming data prior using training statistical model nstance transforming numbers values often referred pre create confusion regarding terminology data protection processing refers operation set operations performed personal data pre machine learning terminology still processing data protection terminology therefore data protection still applies processes involve converting personal data one form another pot entially less detailed form may make training data potentially much harder link particular named individual however data protection law necessarily considered sufficient take data scope therefore still nee consider data responding individuals requests exercise rights even data lacks associated identifiers contact details transformed pre training data may still considered personal data used single individual relates combination data may process even associated customer name instance training data purchase pre diction model might include pattern purchases unique one customer example customer provide list recent purchases part request organisation may able identify portion training data hat relates individual version auditing framework draft guidance consultation kinds circumstances obliged respond individual request assuming taken reasonable measures verify identity exceptions apply consult guidance determining personal data information identifiability right access regard requests access rectification erasure training data manifestly unfounded excessive may harder fulfil motivation requesting may unclear comparison access requests might typically receive collect maintain additional personal data enable identify individuals within training data sole purposes complying gdpr per article may times therefore able identify individual training data individual provide additional information would enable identification therefore fulfil request right rectification right rectification may also apply use personal data train system steps take respect rectification depend data process well nature scope context purpose processing case training data system one purpose processing may find general patterns large datasets context individual inaccuracies training data likely affect performance model since one data point among many compared personal data might use take action individual example may think important rectify incorrectly recorded customer delivery address rectify incorrect address training data rationale likely tha former could result failed delivery latter would barely affect overall accuracy model however practice right rectification allow disregard requests think less important purposes right erasure may also receive requests erasure personal data contained within training data note whilst right erasure absolute still need consider erasure request receive nless processing data basis legal obligation public task unlikely lawful bases training systems see section lawful bases information version auditing framework guidance consultation erasure individual personal data training data unlikely affect ability fulfil purposes training system therefore unlikely justification fulfilling request erase personal data training dataset complying request erase training data entail erasing models based data unless models contain data used infer situations cover section right data portability individuals right data portability data provided controller lawful basis processing consent contract provided data includes data individual consciously input form also behavioural observational data gathered process using service cases data used traini model demographic information spending habits counts data provided individual right data portability would therefore apply cases processing based consent contract however discussed pre methods usually applied significantly change data original form something effectively analysed machine learning algorithms transformation significant resulting data may longer count provided case data would subject data portability although still constitute personal data data protection rights still apply right access however original form data pre data derived still subject right data portability provided individual consent contract processed automated means right informed inform individuals personal data going used train system cases may obtained training data individual therefore opportunity inform time cases provide individual information specified article within reasonable period one month latest since using individual data purposes training system normally constitute making solely automated decision legal similar significant effects need provide information decisions taking however still need comply main transparency requirements version auditing framework guidance consulta tion reasons stated may difficult identify communicate individuals whose personal data contained training data instance training data may stripped personal identifiers contact addresses still remaining personal data cases may impossible involve disproportionate effort provide information directly individual therefore instead take appropriate measures protect individual rights freedoms legitimate interests instance could provide public information explaining obtained data use train system enable individ ual rights requests outputs typically deployed outputs system stored profile individual used take action instance product offers customer sees website might driven output predictive model stored profile data constitutes personal data subject rights access rectification erasure whereas individual inaccuracies training data may negligible effect inaccur ate output model could directly affect individual requests rectification model outputs personal data inputs based therefore likely made requests rectification training data however said predictions inaccurate intended prediction scores opposed statements fact personal data inaccurate right rectification apply personal data resulting analysis provided data subject right portability means outputs models predictions classifications individuals scope right portability cases features used tra model may result previous analysis personal data instance credit score result statistical analysis based individual financial data might used feature model cases credit score included within scope right data portability even features reading ico guidance read guidance individual rights guide gdpr including right informed right access right erasure right rectification version auditing framework guidance consultation right data portability individual rights relate data contained model addition used inputs outputs model cases personal data might also contained model explained section could happen two reasons design accident fulfil requests regarding models contain data design personal data included models design certain types models support vector machines svms contain key examples training data order help distinguish new examples deployment cases small set individual examples contained somewhere internal logic model training set typ ically contains hundreds thousands examples small percentage ends used directly model therefore chances one relevant individuals makes request small remains possible dependin particular programming library model implemented may built function easily retrieve examples cases might practically possible respond individual request enable using models contain personal data design implement way allows easy retrieval examples request access data could fulfil without altering model request rectification erasure data may possible without model either rectified data without erased data deleting model altogether well model management system deployment pipeline accommodating requests redeploying models accordingly prohibitively costly fulfil requests regarding data contained models accident aside svms models hat contain examples training data design models might leak personal data accident cases unauthorised parties may able recover elements training data infer analysing way model behaves rights access rectification erasure may difficult impossible exercise fulfil scenarios unless individual presents evidence personal data could inferred model may version auditing framework guidance consultation able determine whether personal data inferred therefore whether request basis regularly proactively evaluate possibility personal data inferred models light state technology minimise risk accidental disclosure enable individual rights relating olely automated decisions legal similar effect data protection requires implement suitable safeguards processing personal data make solely automated decisions legal similarly significant impact individuals afeguards include right individuals obtain human intervention express point view contest decision made obtain explanation logic decision processing involving solely automated decision making falls part dpa safeguards differ gdpr lawful basis processing requirement authorisation law processing involving solel automated decision making falls part dpa applicable safeguards depend regulations provided particular law authorising automated making although individual right request consider decision take new decision based solely automated processing safeguards token gestures guidance published european data protection board edpb states human intervention involve review decision quote must carried someone appropriate authority capability change decision review also include quote thorough assessment relevant data including additional information provided data version auditing framework guidance consultation conditions human intervention qualifies meaningful similar apply render decision solely automated see previous section however key difference solely automated contexts human intervention required case basis safeguard individual rights whereas system qualify solely automated meaningful human intervention required every decision could rights relating automated decisions particular issue systems type complexity systems involved making solely automated decisions affect nature severity risk people data protection rights raise different considerations well compliance risk management challenges basic systems automate relatively small number explicitly written rules unlikely considered set clearly expressed rules determine customer eligibility product however resulting decisions could still constitute automated decision within meaning data protection law also relatively easy human reviewer identify rectify mistake decision challenged individual system high interpretability however systems based may complex present challenges meaningful human review systems make predictions classifications people based data patterns even highly statistically accurate occasionally reach wrong decision individual case errors may easy human reviewer identify understand fix every challenge fro individual result decision overturned expect many could two particular reasons may case systems individual outlier circumstances substantially different considered training data used build system model trained enough data similar individuals make incorrect predictions classifications assumptions design challe nged continuous variable age might broken binned discrete age ranges like part modelling process bins may result different model substantially different predictions peopl different ages validity data pre design choices may come question result individual challenge version auditing framework guidance consultation steps take fulfil rights related automated decision making consider system requirements necessary support meaningful human review design phase particularly interpretabilit requirements effective interface design support human reviews interventions design deliver appropriate training support human reviewers give staff appropriate authority incentives support address escalate individuals concerns necessary override system decision however additional requirements considerations aware ico explain guidance looks extent complex systems might affect ability provide meaningful explanations individuals however complex systems also impact effectiveness mandatory safeguards system comp lex explain may also complex meaningfully contest intervene review put alternative point view instance system uses hundreds features complex nonlinear model make prediction may difficult individual determine variables correlations object therefore safeguards around solely automated systems mutually supportive designed holistically individual mind information logic system explanations decisions give individuals necessary context decide whether grounds would like request human intervention cases insufficient explanations may prompt ndividuals resort rights unnecessarily requests intervention expression views contests likely happen individuals feel sufficient understanding decision reached process indivi duals exercise rights simple user friendly example communicate result solely automated decision communicated website page contain link clear information allowing individual contact member staff intervene without undue delays complications also required keep record decisions made system part accountability documentation obligations also include whe ther individual requested human intervention expressed version auditing framework guidance consultation views contested decision whether changed decision result monitor analyse data decisions regularly changed response individuals exercising rights consider amend systems accordingly system based might involve including corrected decisions fresh training data similar mistakes less likely happen future substantially may identify need collect better training data fill gaps led erroneous decision modify model process changing feature selection addition compliance requirement also opportunity improve performance systems turn build individuals trust however grave frequent mistakes identified need take immediate steps understand rectify underlying issues necessary suspend use automated system also offs human may entail either terms erosion privacy human reviewers need consider additional personal data order validate reject generated output possible reintroduction human biases end automated process reading ico guidance read guidance documentation guide gdpr reading european data protection board european data protection board edpb replaced article working party includes representatives rom data protection authorities member state adopts guidelines complying requirements gdpr published guidelines automated decision making profiling february edpb endorsed guidelines may explain logic involved driven automated decision individuals also right meaningful information logic involved automated decision detail comply right please see recent explain guidance produced collaboration alan turing institute turing version auditing framework guidance consultation example controls risk statement infrastructure architecture systems inhibits ability recognise respond act upon individual rights requests preventative ensure systems developers receive training includes requirement consider individual rights offset set document levels approval authority systems including consideration model maintain evidence appropriate approval implement document policy process dealing requests data processing pipeline particular defining circumstances would respond data used train versus output impact individual provide individual rights training facing individuals including escalate complex requests dpia include thorough data flow mapping consider data indexing making systems searchable using common identifiers part system design requests anticipated fully automated decision making ensure humans may required investigate decision skil tools autonomy investigate override decision ensure data subjects informed processing data purposes training system profiling cases data used training another organisation direct relationship dat subject informing directly would involve disproportionate effort ensure make information publicly available organisations source data processes place inform data subjects processing ensure individuals given means provide additional data order identified within systems maintain documented policies processes dealing third parties particular roles responsibilities controller processor clear detective conduct peer reviews ensure actions completed required version auditing framework guidance consultation conduct periodic review sample requests ensure accurate complete declined justification manifestly unfounded appropriate systematically monitor time taken respond requests order identify systems potentially complex submit dummy requests test process measure outcomes corrective system data storage indexing training data consider additional ata could help identify data subjects case request correct inaccurate personal data contextualise inferred data misleading matter fact delete personal data required employees responsible identification execution requests retrain humans reassessment resource requirements humans pressured make decisions time redesign simplification inclusion warnings select appropriate model including thorough justification change overturn decisions one rogue reviewer action taken result including broader assessment impacts individuals role human oversight used inform legal similarly significant decisions individuals risk decisions made without appropriate human oversight infringes article gdpr mitigate risk ensure people assigned provide human oversight remain engaged critical able challenge system outputs wherever appropriate difference solely automated partly automated decision making use systems two ways automated decision making adm system makes decision automatically version auditing framework guidance consultation decision system supports human decision maker deliberation example could use system automatically approves rejects financial loan merely provide additional information support loan officer deci ding whether grant loan application whether fully automated decision making generally less risky human decision making depends specific circumstances therefore need evaluate based context regardless relative merits automated decisions treated differently human decisions data protection law specifically article gdpr restricts fully automated decisions legal similarly significant effects individuals limited set lawful bases requires certain safeguards place contrast use decision support tools support human decision subject conditions result restrict ions safeguards automated decision arguably carries higher risk human making even though may cases mitigate risks human decision decide use support human decision aware decision fall outside scope article human stamped human input needs meaningful degree quality human review intervention final decision made individual key factors determining whether system used automated merely decision ensuring human input meaningful situations responsibility human using system senior leaders data scientists business owners oversight functions among others expected play active role ensuring applications designed built used intended deploying systems desi gned decision support tools therefore intended outside scope article aware existing guidance issues ico edpb key considerations human reviewers must involved checking system recommendation apply automated recommendation individual routine fashion reviewers involvement must active token gesture actual meaningful influence decisio version auditing framework guidance consultation including authority competence recommendation reviewers must weigh interpret recommendation consider available input data also take account additional factors relevant provisions legislation see gdpr article recital external link see dpa sections external link reading ico guidance read guidance tomated decision making profiling guide gdpr reading european data protection board european data protection board edpb replaced article working party includes representatives data protection authorities member state adopts guidelines complying requirements gdpr published guidelines automated decision making profiling february edpb endorsed guidelines may additional risk factors systems need consider meaningfulness human input automated decision system use however basi may however complex systems two additional factors could potentially cause system intended decision inadvertently fail ensure meaningful human input therefore fall scope article automation bias lack interpretability automation bias mean models based mathematics data people tend think objective trust output regardless accurate version auditing framework guidance consultation terms automation bias automation complacency describe human users routinely rely output generated decisio system stop using judgement stop questioning whether output might wrong lack interpretability mean types systems may outputs difficult human reviewer interpret examp rely complex high dimensional deep learning models outputs systems easily interpretable explanation tools available reliable risk human able meaningfully assess output system factor decision meaningful reviews possible reviewer may start agree system recommendations without judgement challenge means resulting decisions effectively solely automated distinguish solely non automated systems yes take clear view intended use system beginning specify document clearly whether using support enhance human decision make solely automated decisions senior management review sign intended use system making sure line organisation risk appetite means senior management needs solid understanding key risk implications associated option ready equipped provide appropriate degree challenge must also ensure clear lines accountability effective risk manageme policies place outset systems intended support human decisions policies specifically address additional risk factors automation bias lack interpretability possible may know advance whether partly fully automated application meet needs best believe fully automated system fully achieve intended outcome processing may carry risks individuals partly automated system cases risk management policies dpias clearly reflec include risk controls option throughout system lifecycle version auditing framework guidance consultation address risks automation bias may think address automation bias chiefly improving effectiveness training monitoring human reviewers training key component effective risk management controls mitigate automation bias place start project including scoping design phases well development deployment design build phase relevant parts organisation business owners data scientists oversight functions work together develop design requirements support meaningful human review outset must think features expect system consider additional factors human revi ewers take account finalising decision instance system could consider quantitatively measurable properties like many years experience job applicant human reviewer qualitatively assesses aspect application written communication human reviewers access use data used system arguably taking account additional factors means review may sufficiently meaningful decision may end considered solely automated necessary consider capture additional factors consideration human reviewers example might interact directly person decisi gather information charge designing front interface system must understand needs thought process behaviours human reviewers enable effectively intervene may therefore helpfu consult test options human reviewers early however features systems use also depend data available type model selected system building choices need test confirm assumptions made design phase system trained built address risks interpretability also consider interpretability design phase however interpretability challenging define absolute terms measured different ways example human reviewer predict system outputs change given different inputs identify important inputs contributing particular output identify output might wrong version auditing framework guidance consultation important define document interpretability means measure specific context system wish use personal data system process systems interpretable others instance models use small number human features age weight likely easier interpret models use large number features relationship input features model output also either simple complicated simple rules set conditions certain inferences made case decision trees easier interpret similarly linear relationships value output increases proportional input may easier interpret relationships non output value proportional input output value may increase decrease input increases one approach address low interpretability use explanations using methods like local interpretable model explanation lime provides explanation specific output rather model general limes use simpler surrogate model summarise relationships input output pairs similar system try ing interpret addition summaries individual predictions limes sometimes help detect errors see specific part image led model classify incorrectly however represent logic underlying system outputs misleading misused therefore assess whether context lime similar approaches help human decision maker meaningfully interpret system output many statistical models also designed provide confidence score alongside output could help human reviewer decision lower confidence score indicates human reviewer needs input final decision see need statistical accuracy assessing interpretability requirements part design phase allowing develop explanation tools part system required risk management policies establish robust risk based independent approval process processing operation uses also set clearly responsible testing final validatio system deployed individuals accountable negative impact interpretability version auditing framework guidance consultation effectiveness human reviews provide sign systems line adopted risk management policy train staff address risks training staff pivotal ensuring system considered non solely automated starting point train retrain human reviewers understand system works limitations anticipate system may misleading wrong healthy level scepticism system output given sense often system could wrong understand expertise meant complement system provide list factors take account provide meaningful explanations either rejecting accepting system output decision responsible also clear escalation policy place order training effective important human reviewers authorit override output generated system confident penalised authority confidence created policies training alone supportive organisational culture also crucial training programme kept date line technological developments changes processes human reviewers offered refresher training intervals appropriate focussed training human reviewers however worth noting also consider whether function requires additional training provide effective oversight risk internal audit monitoring undertake analysis many times human reviewer accepted rejected system output key part effective risk monitoring system risk monitoring reports flag human reviewers routinely agreeing system outputs demonstrate genuinely assessed decisions may effectively classed solely automated gdpr version auditing framework guidance consultation need controls place keep risk within target levels outcomes beyond target levels processes swiftly assess compliance take action necessary might include temporarily increasing human scrutiny ensuring appropriate lawful basis safeguards case decision effectively become fully automated reading ico guidance read explain draft guidance methods explaining interpreting systems example controls risk statement systems incorrectly classified fully automated result lack meaningful human oversight potential non legislation preventative implement document policy process classification systems relation article including level approval authority maintain evidence decision process appropriate approval provide training humans employed provide meaningful oversight including ability challenge system decision provide independent review ensure system developers understood skills experience ability human overseers designing system include pre testing assessment human oversight ensure meaningful set document levels approval authority systems particular relation model complexity ensure human reviewers interpret challenge maintain evidence appropriate approval conduct document analysis time expected human meaningfully review detective conduct post testing document results testing action taken result test sample decisions ensure human making right decision document tests including sample selected criteria used version auditing framework guidance consultation monitor decisions made compare human decisions document action taken result performance goes outside defined tolerances conduct document mystery shopping exercises periodically provide deliberately misleading data human disagree ensure input meaningful monitor individual rights requests complaints individuals particular relating article including action taken result individual level boarder analysis conduct periodic assessment human confidence overturning outcome monitor individuals performance identify outliers action taken result corrective human decision makers reassess resource requirements humans pressured make many decisions short space time simplification inclusion warnings select appropriate model include thorough justification change overturn decisions one rogue reviewer action taken result including broader assessment impacts individuals version
