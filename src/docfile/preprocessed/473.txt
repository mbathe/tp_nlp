critiquing reasons making artificial moral agents pmc back top skip main content official website united states government know means official federal government websites often end sharing sensitive information make sure federal government site site secure ensures connecting official website information provide encrypted transmitted securely log show account info close account logged username dashboard publications account settings log access keys ncbi homepage myncbi homepage main content main navigation pmc website updating october learn try search pmc archive search pmc advanced search user guide journal list springer formats pdf actions cite collections add collections create new collection add existing collection name collection name must less characters choose collection unable load collection due error please try add cancel share permalink copy resources similar articles cited articles links ncbi databases journal list springer library nlm provides access scientific literature inclusion nlm database imply endorsement agreement contents nlm national institutes health learn pmc disclaimer pmc copyright notice sci eng ethics published online feb doi reasons making artificial moral agentsaimee van wynsberghe scott robbinsaimee van wynsberghetechnical university delft jaffalaan delft netherlands find articles aimee van wynsberghescott robbinstechnical university delft jaffalaan delft netherlands find articles scott robbinsauthor information article notes copyright license information pmc disclaimertechnical university delft jaffalaan delft netherlands aimee van wynsberghe email nov accepted feb author accessthis article distributed terms creative commons attribution international license permits unrestricted use distribution reproduction medium provided give appropriate credit original author source provide link creative commons license indicate changes industry leaders academics field machine ethics would believe inevitability robots coming larger role lives demands robots endowed moral reasoning capabilities robots endowed way may referred artificial moral agents ama reasons often given developing amas prevention harm necessity public trust prevention immoral use machines better moral reasoners humans building machines would lead better understanding human morality although scholars challenged initiative develop amas currently missing debate closer examination reasons offered machine ethicists justify development amas closer examination especially needed amount funding currently allocated development amas funders like elon musk coupled amount attention researchers industry leaders receive media efforts direction stakes debate high moral robots would make demands society answers host pending questions counts ama whether morally responsible behavior paper shifts burden proof back machine ethicists demanding give good reasons build amas paper argues done development commercially available amas proceed artificial moral agents robot ethics machine ethicsintroductionrobots perform exceptionally well clearly defined tasks like playing chess assembling car classifying images vacuuming floor increasingly however robots assigned general tasks require one skill driverless car example supposed get point point following rules road reacting unforeseen child running middle road ball order robots execute function require algorithms algorithms controlling robots becoming increasingly autonomous often require artificial intelligence autonomy robots increases likelihood encounter situations morally salient robots continue designed developed deployed morally salient contexts robots hospital lifting bathing patients robots military assisting bomb disposal intelligence executive summary international federation shows marked increase robot sales across every sector year next including increase total number service robots sold alone robots used save lives assist dangerous activities enhance proficiency human workers many industry leaders academics field machine study endowing machines ethical believe robots morally charged contexts inevitably demand machines endowed moral reasoning capabilities robots often referred artificial moral agents amas paper variety reasons offered machine ethicists favor amas challenged paper asks given reasons adequate justification design development amas academic domain variety scholars fields ethics technology robot ethics argued development amas bryson johnson miller sharkey tonkens currently missing debate amas closer look reasons offered society academics media machine ethicists justify development amas closer inspection particularly compulsory given amount funding allocated development amas funders like elon musk coupled amount attention researchers industry leaders receive media efforts moreover stakes high resulting technology could create novel demands society questions counts ama whether deserving whether morally responsible behavior words machine moral reasoning capabilities might thought deserve moral consideration form rights protections coeckelbergh darling gunkel order examine justifications amas paper begins description field machine ethics terminology used response machine ethics found literature robot ethicists scholars field ethics technology subsequent sections reasons offered favor developing robots moral reasoning capabilities evaluated argued reasons lack empirical intuitive support burden proof thereby shifted machine ethicists justify ethicssummarized machine ethicist susan anderson ultimate goal machine ethics create autonomous ethical machines term machine ethics first used mitchell waldrop magazine article question responsibility waldrop aaai held symposium machine ethics resulted edited volume machine ethics susan leigh michael anderson anderson anderson field may referred names machine morality purposes paper machine ethics field study dedicated computational entity moral several phrases terms discussing robots moral reasoning capabilities moral machines implicit explicit ethical agents purposes article however term artificial moral agent ama used consistency clearly restricts discussion robots capable engaging autonomous moral reasoning moral reasoning situation without direct real time input human user moral reasoning aimed going beyond safety security decisions context might done whether achieved practice questions beyond scope paper questions underpinning field machine ethics rather interest paper targeting reasons offered support developing robot machine would act like think ethical way central feature works science fiction writer isaac asimov asimov coined term robotics study robots best known work articulating exploring three laws robotics asimov short three laws kind principled deontological approach embedding ethics machine series short stories asimov reveals difficulty nuances robots acting ethical manner ethical principle conflicts another degree experience wisdom intuition required come solution resolution conflict stories highlight struggle define ethics computational academic domain variety scholars fields ethics technology robot ethics argued development amas one hand scholars insist technology ought designed way responsibility distribution remains tethered humans johnson miller similarly computer scientist joanna bryson argues robots ought remain instrumental service humans slaves meeting needs human users intentionally designed moral agent bryson claim predicated assumption humans robots responsible existence capacities hand philosopher ryan tonkens argues given impossibility finding universal agreement concerning ethical theory used program machine initiative moot tonkens arguments robot ethicist amanda sharkey outlines misappropriation use ethical quest make moral machines insists creation safe machines instead line thinking miller argue responsible development requires careful use terminology representation media miller arguments still waiting adequately answered machine ethics community however purpose paper question positive reasons offered machine ethicists building amas reasons yet fully evaluated yet closer inspection reveals lack sufficient justification given high stakes research development question coupled current speed funding machine ethics initiatives must addressed developing moral machinesmachine ethicists offered six reasons found literature favor promoting development moral machines stand alone reasons rather often intertwined part reason sounds convincing first glance interdependency rather strength reason disentangling reasons shows dubious foundation allows one challenge endeavor machine moral decision making abilities become technological necessity wallach artificial moral agents necessary weak sense inevitable colin allen wallach ethicists claim robots morally salient contexts avoided development inevitable anderson anderson moor scheutz wallach exactly meant morally salient contexts unclear researchers would include contexts healthcare elder care childcare sex life death decisions made daily hourly basis arkin lokhorst van den hoven sharkey sharkey sharkey sharkey sharkey van wynsberghe question robots entering service sectors international federation robotics executive summary tells total number professional service robots sold rose considerably units service robots defense applications accounted total number service robots professional use sold moreover sales medical robots increased others morally salient context much broader space institution ordinary situation daily life turned morally charged situation artificial agent finds presented moral dilemma choice action inaction potentially cause harm agents scheutz quote scheutz saying morally charged situation arise moment event someone could harmed action robot thin description morally charged decision making situation adds ambiguity discussion namely level autonomy robot definition harm scheutz talking seems assumption made quote concerning robot robot must make choice action inaction thus robot must autonomous according scheutz autonomous robot interacting human user potential harm user endowed moral reasoning capabilities would scheutz industrial robots possess divergent levels autonomy work humans presence already shown robots bring serious harm sometimes death humans scheutz position would imply industrial robots well ought developed also definition harm ought adopted physical harm corporeal body mind object discussion robot algorithm ability collect store share information users home setting considering real possibility home robots connected internet things iot holds potential hackers companies related robotics company access personal data users harm come one data proven noteworthy late people refused mortgage loans stalked blackmailed harassed online worse harm extended include risk one digital information interaction machine might cause harm demands endowed ethical reasoning capacities one must concede every device one interacts day phone fridge alarm clock kettle etc ought capabilities thus scheutz position leads conclusion technology one interacts potential harm physical otherwise must developed ama simply distinction must made morally charged situation one hand delegated moral role consider animals used therapeutic purposes elderly care facility one would never demand dog placed context would need reason ethically role therapy potential harm context indeed dog would trained ensure degree safety reliability interacting would dog moral dog end thought mind let day discussion limited examination morally salient context contexts military healthcare often thought morally salient agree inevitable robots placed within contexts case different nuanced problem put form dilemma placed morally salient context either machines delegated moral role one chooses first machine delegated moral one must accept inevitable machines delegated moral role addition inevitability machine morally salient context however simply case plenty machines operating morally salient contexts delegated moral role providing valuable service consider example corti listens emergency phone calls makes correlations breathing speech patterns caller risk heart attack peters information presented phone operator assist decision making short support system decision making operator may akin cancer detection traditional technologies operating suite electrocardiogram respiratory monitor corti clearly morally salient context life death yet machine delegated moral role human still charge holds responsibility decision making one agrees machine ethicists one accept inevitable moral role reserved human case assigned machine probably unnecessary likely harmful point simply reason believe however one takes horn dilemma claim follows robots inevitably morally salient contexts without delegated morally salient role problem little new microwaves coffee machines exist hospital need moral reasoning capabilities horn little interest machine ethicists short evidence suggest inevitable need machines moral reasoning capabilities regardless whether function morally salient moral machines prevent harm humansfor many scholars development moral machines aimed preventing robot hurting human beings ensure humans overcome potential physical harm technological solution presented namely develop amas way minimize human harm build morally competent robots detect resolve morally charged situations ways scheutz line reasoning pretty straight forward clear capable causing harm human beings anderson anderson mitigated reduced endowing robot ethical reasoning capabilities also speaks interconnection reasons favor amas robots inevitable robots could harm therefore robots made unclear amas solution problem however plenty technologies capable harming human beings lawn mowers automatic doors curling irons blenders solution always either design safety features limit contexts technology used elevator door sensor close people lawn mowers guard protect blades ovens lights warn stovetop hot one normally use barbeques indoors chainsaws daycare centers machine ethicists first suggest endowing technology moral reasoning capabilities solution problems machine ethicists may also agree pursuit safe robots real concern ethicists ethics reduced safety notions values rights freedoms good bad right wrong central study ethics form basis discussion competing conceptions good life one may believe values safety security fundamental achieving good life however ethics reduced issues amas simply solution possibly harmful machines moral object case world moral linguistic trojan horse wordthat smuggles rich interconnected web human concepts part computer system operates sharkey concept moral machines artificial moral agents invites strongly requests user believe robot may care robot experience feelings robot developers could increase desirability robot therefore profits however problematic public invites kind fictive asymmetric deceptive relationship human machine ethicists must either distinguish makes machines moral beyond safe must stop using world moral word reductionist account morality would equate preventing systems get sophisticated ability function autonomously different contexts environments expands become important ethical subroutines allen idea behind using complexity argument favor amas robots increasingly become complex terms programming longer possible know novel situations uncertainty results impossibility engineer predict every scenario possible engineer predict robot actions consequently one simply foresee morally problematic situation robot instead authors use complexity argument promote development amas claim robot needs moral competence order govern unpredictable actions inevitably unpredictable unstructured human environments robot using complexity reason developing amas expects complex robots robots ought placed contexts complexity unpredictability could cause problems human importance issue context within robot placed words problem mitigated simply restricting context within machines used example designers google complex machine alphago may idea machine next move make notoriously difficult game however ethical moral problem context game restricted complexity pose problem may argue human beings unpredictable cause harm human beings solution prevent delegation moral roles human beings one might ask treat machines differently outside scope paper engage debate predictable humans noted regard serious moral sex harming innocent people places restrictions unpredictable human beings imprisonment humans may unpredictable terms next assume random person intentionally cause trustother machine ethicists argue making amas increase public trust constructing artificial moral agents serves least two purposes one better understanding moral reasoning two increasing trust confidence creating autonomous agents acting behalf wiegel talk media expressing concerns surrounding likes elon musk steven hawking markoff rather preventing development robots source fears machine ethics may offer viable realistic solution anderson anderson line thinking assumes robots given moral competence put public ease lead public acceptance noted acceptance differs acceptability example public may accept geo tagging tracking algorithms smartphone devices meant privacy breaching technologies lack transparency existence acceptable practices upholding societal important clarifications needed discussing trust concept traditionally speaking trust described interaction persons person institution scholar john hardwig trust placed people processes knowledge hardwig recent years scholars discussing new form trust trust algorithms simon new form trust commonly referred algorithmic authority described practice placing confidence decisions made algorithm shirky wikipedia example form trust requires trust persons algorithms regulating content trust broken result feelings disappointment part truster resulting negative feelings relate trust concept reliability either one misplaced result oftentimes feelings disappointment simon trust distinguished reliability intensity emotions experienced afterwards trust differs reliance let feel betrayed disappointed baier simon relatedly simon claims one speak trust systems rather reliance usually ascribe intentionality unanimated objects feel betrayed hence trust unanimated objects rely formulation hardwig placed people processes knowledge concerns placing trust robots one must ask machine ethicists asking public trust algorithm directing robot designer development process public asked trust algorithm one must consider unfortunately often algorithms blindly algorithms hidden within system cases aware work assess impact information receive words algorithms simon public asked trust algorithm considered simon rightly asserts must way works decisions made development made transparent subject however public asked trust designer designers developers ought develop code conduct perhaps form soft law adhere transparency required public knowledge required public asked trust process robot developed kind procedural trust standards certifications must developed provide user knowledge required place trust process robot developed examples procedural trust fairtrade iso gmos case important point inconsistency promotion amas reasons complexity reasons trust inconsistent expect unpredictability machine expect trust machine time may case might trust persons time clarity needed understanding society asked trust level predictability one immoral usein american science fiction movie robot frank compelling story retired cat burglar convinces robot help enter business story raises question interaction sense safe reliable interactions rather robot capable evaluating human request action thus another reason put forward development amas stated preventing humans misusing inappropriately using robot requires robot developed moral machine thus prevent misuse main problem reason potential constrain autonomy humans always clear good thing oftentimes context required miller consider example couple home drinks together domestic violence ensues heated argument women tries get away car breathalyzer car picks alcohol system car start would right thing instance device programmed deontologist would believe one never get behind wheel consuming alcohol utilitarian might suggest woman life saved overall good maximized unless course women get car accident harm two others easy problems solve require particular details context another example misuse unclear elderly person home wants fourth glass wine asks robot fetch robot fetches wine robot misused far contributing poor health choices user robot good far fulfilled request user presenting scenarios like meant show difficulty determining right good thing yet one claiming robots involved decision making procedure must clear good robot distinguished bad better moral machinesendowing robot capability override edit human decisions draws discussion robot superior moral reasoner human computer science professor james gips suggested back many human beings live lives flawlessly moral saints robot could gips also along lines professor philosophy eric dietrich suggested humans genetically hardwired humans exit stage leaving behind planet populated machines although perfect angels nevertheless vast improvement dietrich assumption robot could better moral decision making human given would impartial unemotional consistent rational every time made decision thus decisions would based bias emotions decision would result affinity towards one person group people another importantly robot would never tire would energy consistent decision making make choice time line reasoning promote amas also often invoked speaking robots military contexts particular computer ronald arkin discusses power autonomous military robots overcoming shortcomings humans battlefield arkin robots would rape pillage villages taken wartime would programmed ethical agents according laws war rules general concerns reason first underlying programming enable machines reason morally implies one understanding moral epistemology one program machines learn correct moral least know enough amas learn something works gets complicated moral epistemology serious philosophical objections therefore presents barrier reduced programming could better standard moral truth judge implies objective moral truths moral realist sense possible know opposed error theory idea moral truths nothing know moral skepticism moral truths possible humans know based quotes seems moral truths machines would better knowing truths independent human attitudes russ calls moral truths big stance independent moral truths whereby truths dependence upon human desires beliefs needs etc objections one could come know truths finlay machine built somehow discover moral truths heretofore yet discovered morality would lot easier simply knew moral truths one would accept faith machines better moral consistency promised machine ethicists public good moral truths known opposite situation human beings find shown previous sections amas argued needed one predict kind situations moral dilemmas faced chess game outcome win loss autonomous car drives one order save five passengers another car would clear cut situation everyone could agree correct decision indeed books written decision human disagreement done trolley problem see greene presumes human emotions human desires evolutionary history getting way moral worse could include moral emotions necessary part moral judgment reasoning kristjánsson pizarro roeser amas would require even horizon say moral principles humans know standard judge amas furthermore let also assume live promise better moral reasoners humans might make sense outsource moral decisions machines would assume good moral reasoning necessary part human good life aristotle believed leading moral life gaining moral understanding practice necessary leading good life aristotle many contemporary philosophers agree outsourcing moral reasoning machines could cause undesirable moral deskilling human beings vallor point clear machines better moral reasoners would good reason use added make assumption assume understanding morality good life may understanding moralityfinally machine ethicists sometimes argue developing robots moral reasoning capabilities ultimately lead better understanding human morality hope try implement ethical systems computer learn much knowledge assumptions built ethical theories build artificial ethical reasoning systems learn behave ethically gips short regardless resulting machine process attempting create machine would benefit humans far would learn moral attributes gips moor wiegel important consideration response claim ethical theories little people reason morally work help understand human morality experiments moral psychology show human morality deeply influenced irrelevant situational factors doris merritt driven emotion haidt haidt joseph influenced evolutionary past street sure intense debate literature regard studies point human morality descriptive sense dependent upon many complex factors building machine tries perfectly emulate human morality must use factors combined rather rely ethical theory paper reasons offered machine ethicists promoting development moral machines shown fall short one takes closer look assumptions underpinning claims claims autonomous robots used morally salient contexts need require robot endowed ethical reasoning capabilities merely placing something ethical situation like heart monitor icu hospital ward also demand thing ethically reflect course action power robots said contexts still harnessed even without making moral article shown amas promoted reasons inevitability complexity establishing public trust preventing immoral use would better moral reasoners would better understanding human morality amas none articulated development moral machines work practice inherent bias learn ethical impossibility difficulty understanding complexity robot decision evaluate trust superior ethical reasoning robot dangers language used endeavors one refer moral machines artificial moral agents ethical agents goal really create safe reliable machines rather called safe robots best way avoid confusion considering critical unique operational function appears gained endowment ethical reasoning capabilities robots simply end authors suggest implication policy makers academics place moratorium commercialization robots claiming ethical reasoning skills would allow academics study issues time protecting consumer indirect user society exposure technology poses existential closing goal paper pick apart reasons favor moral machines way shifting burden proof back machine ethicists ethicists anymore tell think pursuit ama flawed rather shown motivations developing moral machines withstand closer inspection machine ethicists need provide better reasons machine ethicists ball research supported netherlands organization scientific research nwo project number scott robbins wishes acknowledge european research council erc advanced grant titled global terrorism collective moral responsibility redesigning military police intelligence institutions liberal democracies gtcmr part made research paper possible would also like thank deborah johnson graciously providing incredibly useful feedback see popular news articles see deng morals machine rutkin sophie hanson robotics first robot granted citizenship saudi arabia see gershgorn hatmaker readings machine ethics see wallach allen anderson anderson anderson moor scheutz allan see wallach allen moor concept notion artificial moral agents built momentum thought experiment possible reality rich detailed discussion amas authors recommend following allen floridi sanders himma johnson miller nagenborg wiegel please refer also work van wynsberghe illustrating robots healthcare need delegated roles ethical reasoning moral responsibility required van wynsberghe furthermore existing frameworks applications realizing ethical values technological design see friedman nissenbaum nissenbaum van poel van den hoven van wynsberghe robbins form trust may also referred procedural trust simon concerns trust process knowledge created rather actions word trust used comes quotation however noted authors inclined use work rely informationaimee van wynsberghe email robbins email smit wallach artificial morality hybrid approaches ethics information technology google scholar allen varner zinser prolegomena future artificial moral agent journal experimental theoretical artificial intelligence google scholar allen wallach moral machines contradition terms abdication human responsibility lin abney bekey editors robot ethics ethical social implications robotics cambridge mit press google scholar allen wallach smit machine ethics ieee intelligent systems google scholar anderson machine metaethics anderson anderson eds machine ethics new york cambridge university anderson machine ethics creating ethical intelligent agent magazine google scholar anderson anderson robot good call ethical autonomous machines scientific american pubmed google scholar anderson anderson machine ethics cambridge cambridge university press google scholar aristotle ross ackrill urmson nicomachean ethics oxford university press retrieved accessed oct governing lethal behavior autonomous robots boca raton crc press google scholar asimov robot new york spectra google scholar baier trust antitrust ethics google scholar bryson robots slaves wilks close engagements artificial companions key social psychological ethical design issue amsterdam john benjamins publishing retrieved accessed mar stephen hawking warns artificial intelligence could end mankind bbc news retrieved accessed aug robot rights towards justification moral consideration ethics information technology google scholar darling extending legal protection social robots effects anthropomorphism empathy violent behavior towards robotic objects rochester retrieved machine ethics robot dilemma nature news pubmed google scholar dietrich homo sapiens build better robots nature journal experimental theoretical artificial intelligence google scholar doris persons situations virtue ethics nous retrieved four faces moral realism philosophy compass google scholar floridi sanders morality artificial agents minds machines google scholar friedman nissenbaum bias computer systems acm transactions information systems retrieved feb inside mechanical brain world first robot citizen retrieved dec toward ethical robot ford glymour hayes eds android epistemology cambridge mit moral tribes emotion reason gap new york penguin press google scholar gunkel vindication rights machines philosophy technology google scholar haidt emotional dog rational tail social intuitionist approach moral judgment psychological review pubmed google scholar haidt joseph innate mind volume foundations future evolution cognition carruthers laurence stich editors innate mind new york oxford university press google scholar hardwig role trust knowledge journal philosophy google scholar hatmaker saudi arabia bestows citizenship robot named sophia retrieved feb artificial agency consciousness criteria moral agency properties must artificial agent moral agent ethics information technology google scholar johnson miller artificial moral agents ethics information technology google scholar kristjánsson emulation use role models moral education journal moral education retrieved accessed oct van den hoven responsibility military robots lin abney bekey editors robot ethics ethical social implications robotics cambridge mit press google scholar markoff relax terminator far away new york times retrieved accessed aug virtue ethics situationist personality psychology ethical theory moral practice google scholar miller wolf grodzinsky ethical trap roboticists robots issue artificial agent ethical science engineering ethics pubmed google scholar moor nature importance difficulty machine ethics ieee intelligent systems google scholar moor four kinds ethical robots philosophy retrieved accessed feb machine economist retrieved accessed mar artificial moral agents intercultural perspective international review information retrieved feb computer systems embody values computer google scholar peters heart attack helps emergency dispatchers find retrieved january nothing feelings role emotions moral judgment journal theory social behaviour google scholar roeser moral emotions intuitions berlin springer google scholar rutkin ethical trap robot paralysed choice save retrieved feb need moral competency autonomous agent architectures müller springer international publishing retrieved accessed aug ethical disagreement ethical objectivism moral indeterminacy philosophy phenomenological research google scholar sharkey welcome robot teachers ethics information technology google scholar sharkey robots responsible moral agents care connection science google scholar sharkey ethical frontiers robotics science pubmed google scholar sharkey evitability autonomous robot warfare international review red cross google scholar sharkey sharkey rights wrongs robot care lin abney bekey editors robot ethics ethical social implications robotics cambridge mit press google scholar sharkey van wynsberghe robbins hancock sexual future robots hague netherlands retrieved accessed feb speculative post idea algorithmic authority retrieved feb entanglement trust knowledge web ethics information technology google scholar street darwinian dilemma realist theories value philosophical studies google scholar tonkens challenge machine ethics minds machines google scholar vallor moral deskilling upskilling new machine age reflections ambiguous future character philosophy technology google scholar van poel translating values design requirements mitchfelder mccarty goldberg editors philosophy engineering reflections practice principles process dordrecht springer google scholar van den hoven ict value sensitive design goujon lavelle duquenoy kimppa editors information society innovation legitimacy ethics democracy honor professor jacques berleur boston springer google scholar van wynsberghe designing robots care care centered design science engineering ethics pmc free article pubmed google scholar van wynsberghe method integrating ethics design robots industrial robot international journal google scholar van wynsberghe healthcare robots ethics design implementation healthcare robots ethics design implementation retrieved accessed aug wynsberghe service robots care ethics design ethics information technology google scholar van wynsberghe robbins ethicist designer pragmatic approach ethics lab science engineering ethics pubmed crossref waldrop question responsibility magazine google scholar wallach implementing moral decision making faculties computers robots society google scholar wallach robot minds human ethics need comprehensive model moral decision making ethics information technology google scholar wallach allen moral machines teaching robots right wrong new york oxford university press retrieved accessed feb building blocks artificial moral agents proceedings workshop retrieved feb wendell wallach colin allen moral machines teaching robots right wrong ethics information technology google scholar articles science engineering ethics provided courtesy springer formats pdf actions cite collections add collections create new collection add existing collection name collection name must less characters choose collection unable load collection due error please try add cancel share permalink copy resources similar articles cited articles links ncbi databases cite copy download format ama apa mla nlm follow ncbi twitter facebook linkedin github connect nlm national library medicine rockville pike bethesda web policies foia hhs vulnerability disclosure help accessibility careers nlm nih hhs
