artificial intelligence children toolkit march contents world economic forum rights reserved part publication may reproduced transmitted form means including photocopying recording information storage retrieval document published world economic forum contribution project insight area interaction findings interpretations conclusions expressed herein result collaborative process facilitated endorsed world economic forum whose results necessarily represent views world economic forum entirety members partners corporate checklist companies fall short actions rewards leading product team guidelines foundational principles challenge definition children youth social networks overarching limitations putting children youth first fair inclusive responsible safe transparent labelling system guide parents guardians benefits risks contributors images getty images artificial intelligence children toolkit designed help companies develop trustworthy artificial intelligence children first time history generation children growing world shaped artificial intelligence set powerful algorithms designed collect interpret data make predictions based patterns found data children youth surrounded many products use daily lives social media education technology video games smart toys speakers determines videos children watch online curriculum learn way play interact others toolkit produced diverse team youth technologists academics business leaders designed help companies develop trustworthy artificial intelligence children youth help parents guardians children youth responsibly buy safely use products used educate empower children youth positive impact society children youth especially vulnerable potential risks posed including bias cybersecurity lack accessibility must designed inclusively respect rights child user design protect children youth potential risks posed technology technology must created innovative responsible responsible safe ethical transparent fair accessible inclusive designing responsible trusted good consumers businesses society parents guardians adults responsibility carefully select ethically designed products help children use safely stake determine future play childhood education societies children youth represent future everything must done support use responsibly address challenges future toolkit aims help responsibly design consume use designed help companies designers parents guardians children youth make sure respects rights children positive impact lives artificial intelligence children march artificial intelligence children corporate member product team parent guardian corporate users checklist executives guidelines product teams contain actionable frameworks guidance help company design innovative responsible children youth using guidelines lead trusted company delights child users companies keep mind children often use products designed specifically sometimes difficult predict products might later used children youth result carefully consider whether children youth might users technology developing carefully consider help increase benefits mitigate potential risks posed technology children youth responsible setting culture around responsible strategy investment products checklist designed help executives learn benefits risks children youth better lead innovate grow read checklist product teams design develop deploy technology children youth use responsible design starts product teams continues ongoing responsibility guidelines designed engineers developers product managers members product team use throughout product life cycle companies keep mind children often use products designed specifically children youth first checklist fair inclusive responsible safe transparent artificial intelligence children consumers parents guardians parents guardians decide technologies buy children educating better understanding benefits risks posed technology make deliberate informed decisions protect children sure positive impact lives learn guide parents guardians tool parents guardians designed based labelling system figure understand six important categories labelling system labelling system designed included products physical packaging online accessible code like nutritional information food packaging labelling system designed concisely tell consumers including parents guardians well children youth works options available users companies encouraged adopt tool help create greater trust transparency purchasers child users products learn labelling system age data use use networkssensors accessibility labelling system figure source world economic forum artificial intelligence children corporate decisionmakers actionable frameworks guidance help companies design innovative responsible children youth checklist executives companies provide products services incorporating artificial intelligence intended use children youth many companies use differentiate brands products incorporating toys interactive games extended reality applications social media streaming platforms educational products little patchwork regulations guide organizations must navigate sea privacy ethics concerns related data capture training use models executive leaders must strike balance realizing potential helping reduce risk harm children youth ultimately brand building foundation established world economic forum empowering leadership toolkit checklist intended help executives corporate reflect upon act create support responsible vulnerable population trusted responsible children youth checklist executives attracted extraordinary opportunity innovate companies moving record pace incorporate toys broadcast social media smart speakers education technology virtual worlds ranges complexity impact simple recommendation customization engines deeply immersive experiences imitate simulate human behaviour emotions interactions implemented thoughtfully systems delight teach evoke interaction young users enabling grow develop pace according learning styles implemented without careful forethought guidance child development experts ethicists hinder development infringe rights vulnerable users checklist leaders learn even companies mean well overlook potential issues mitigate risks associated adoption executives aspire highest possible ethical social standards regarding child development suitability purpose nonbias accessibility privacy provides tremendous potential beyond opportunity good elevate brand enable position company trustworthy steward products services primary buyers parents grandparents teachers educators care providers artificial intelligence children given acceleration adoption lag broadly accepted standards guidance leaders might caught guard riskiest behaviours teams avoid disclosing used companies think buyers may object may conceal downplay use transparent use using perpetuating bias modelling contain inaccuracies oversimplifications lead inaccessibility bias marginalized groups disabled communities users different cultural backgrounds validation bypassing user expert validation suitability purpose design prototyping stages diminish potential value cause harm privacy security gaps data security privacy consent collect use data complicated due cybersecurity threats patchwork regulations vary geographically concerns reach past useful life product minors parents provide consent children may claim right data forgotten get older potential stumbling blocks mind steps corporate leaders take protect enhance brand leveraging remarkable potential companies fall short executive leaders create culture responsibility backed resources enable responsible design use beyond artificial intelligence children executive leaders create culture responsibility backed resources enable responsible design use beyond steps recommended know legal duties regulatory constraints leverage existing guidance institute electrical electronics engineers ieee code unicef policy guidance world economic forum well guidance contained toolkit guidelines product team labelling system resources parents guardians children youth commit internal possible external oversight report compliance leadership measures publicly simple language buyers understand build diverse capable team include ethicists researchers privacy specialists educators child development experts psychologists designers data scientists collaborate organizations educational research institutions expertise train team provide resources success checklist educate team members importance responsible trustworthy provide access skills tools time need execute vision open dialogue unintended consequences possible scenarios reasons ensuring teams considering five characteristics critical putting children youth first figure information refer product team guidelines offers detailed guidance five areas offer expertise inform development regulations standards guidance contribute public forums used products services share experience proposing guidance requirements welcome principled efforts label products services done according potential impact users endorse participate activities develop labelling rating standards label offerings help consumers make informed choices based recommendations example user age accessibility factors whether camera microphone used additional information labelling recommendations see labelling putting children youth first checklist figure company culture processes address ethics bias concerns regarding models developed people impact models use models interact equitably users different cultures different abilities product testing includes diverse users offerings reï¬‚ect latest learning science enable healthy cognitive social emotional physical development technology protects secures user purchaser data company discloses collects uses data protects data privacy users may opt time data removed erased company explains terms buyers users used works decisions explained company also admits limitations potential risks welcomes oversight audits source world economic forum artificial intelligence children rewards leading deliver responsible offerings engage development standards much affect bottom line help young users grow best versions generation empowered references ruha race technology abolitionist tools new jim code polity books mark ethics mit press markus frank pasquale sunit das eds oxford handbook ethics oxford university press neil cathy weapons math destruction big data increases inequality threatens democracy crown publishing group stuart human compatible artificial intelligence problem control penguin publishing group nations young people help draw digital protection recommendations news march artificial intelligence children product team responsible design starts product teams continues ongoing responsibility throughout product life cycle introduction product teams design develop deploy technology children youth use responsible design starts product teams continues ongoing responsibility throughout product life cycle guidelines designed help develop responsible products children youth entire product team developers programme managers technical writers product owners software architects designers marketing managers anyone else hand product development dive five categories putting children youth first fair inclusive responsible safe transparent figure theme also organized three sections goals greatest potential harm mitigate risks use categories resources starting point responsible journey want form diverse dynamic team develop children youth source world economic forumputting children youth first figure ethics bias liability accessibility feedback kids reflects latest learning science designed kids mind harm cybersecurity addiction mitigation explain works used novice lay audience artificial intelligence children foundational principles united nations convention rights child lays numerous principles protecting rights dignity autonomy safety children first principle article guides many others actions concerning children whether undertaken public private social welfare institutions courts law administrative authorities legislative bodies best interests child shall primary best place start simple question system building best interests children mind perhaps answer sure emphatic yes matter answer important consider whether positive impact clearly articulated establish strategies determining whether system intended impact goal guidelines help identify risks uncover potential blind spots product envisioned built tested deployed design act starting first person product built way possible prioritize needs desires scenarios use capabilities technology building products children entails going step taking childcentred design take responsibility development stage customers risks may encounter technology role limiting harm help ask right questions desirability product also fitness safety guidelines product teams building children youth mind relevant products children youth might use social media gaming even productivity platforms highly likely used children youth independent expressed implied target hope guidelines applied across narrowly defined market smart toys children youth member product team developing technology customers beholden greatest potential riskiest vulnerabilities guidelines five characteristics explored developers engineers designers professionals programme managers apply work designing children youth must put first technology built fairly inclusively responsibly safely transparently five characteristics includes elements goals potential harm risk mitigation guidance checklist figure well applying principles easy intended easy way great product work invited dig reflect perhaps get uncomfortable come side technology respects celebrates precious cherished vulnerable users children youth best place start simple question system building best interests children mind artificial intelligence children checklist putting children youth first goals greatest potential harmmitigate risksfigure fairness user dignity paramount bias training expression feedback assumed actively addressed effort spent understanding liability threat analysis includes could weaponized harmbreaches trust consent emotional developmental harm bias unequal access impactemploy proactive strategies responsible governance use ongoing ethical thinking imagination employ ethical governance fairness test train data understand behaviour model areas bias accessibility afterthought inclusive accounts celebrates neurodiversity technology development cycle testing includes feedback children youthexclusion design bias bias bias internalizedbuild research plans advisory councils participant pools represent high variability target audience actively seek user experience failures create experiences exclusion test train data understand behaviour model areas bias technology ageappropriate design technology reflects latest learning science technology created children youth centre design development processtechnology gone rogue unsophisticated inflexible models built small silly adultsbuild advisory councils research participant pools represent high variability target audience actively seek user experience failures create negative experiences overcommunicate privacy security implications build conviction around behaviour might adjust user development stageresponsible technology harm customers used harm others cybersecurity including privacy security customer data high priority potential acknowledged addiction mitigation actively built malicious oblique naive usage unsafe community callous observer demographics allowed define user data privacy security breachesconduct user research inform scenario planning nefarious use cases mitigation strategies build multivariate measurement strategy build transparent explainable user relationship model child guardian technology identify mitigate harm product team develop expertise technology concerns related children youth build security plan takes children youth cognitive emotional physical safety accountsafe everyone team explain works used novice lay audience anyone wants understand easily able solack obfuscation informed consent skirted ignored governmental rules regulations burden security privacy left user excluded guardiansconfirm terms use clear easy read accessible literate user clearly disclose use technologies facial recognition emotion recognition data managed explicitly mention geographic regions whose data protection privacy laws honoured technology use secure options default allow guardians opt advanced features reading specific terms use clearly specify age group application built provide guidelines environment technology meant used create alert mechanisms guardians intervene case risk identified usagetransparent source world economic forum fair inclusive artificial intelligence children challenge people active technology ethicists user researchers software developers programme product managers designers wrote guidelines people like mind developers programme managers technical writers product owners software architects designers marketing managers anyone else hand product development objective guide risks associated building children youth admittedly little time spent addressing value machine learning goodness technology bring lives children youth purpose guidelines discourage use product design instead help bring balance propensity see positive potential outcomes products built challenge consider side products building guidelines used interrogate work undertaken help uncover mitigate deficiencies possible risks introduced design customers find hope helping product teams confident proud celebrated responsible bring lives children youth definition children youth single definition children youth people whose bodies brains still developing yet drive car hold job defines children people years age even possible consider children youth since prefrontal cortex completes development children shorter attention spans limited vocabulary cases age measured years planet abilities tests cognitive skills physical dexterity emotional intelligence age like human concepts absolute due variability human capability relative age important think beyond age groups leverage instead reliable concepts cognitive emotional physical way understand target communicate market product spending much time children youth reveals result brain development varies function developmental excellent morph something unpleasant children youth encounter negative experiences quick take credit sky blue child might also take credit parents divorce means everything fault good things bad vulnerability especially viewed lens overstated child youth customers likely internalize good bad parts technology product team job work means mitigate accordingly artificial intelligence children social networks depending product goals may connecting building social network inside product guidelines deeply explore risks social networks children youth product includes social component however following recommended safety guard nefarious actors exploit system gain access children youth gains computer viruses child exploitation bullying fairness design creative alternatives embedding implicit social hierarchies experiences custom avatar clothes cost money accumulation likes followers following information help initiate thinking risks social networks children youth children network australia social media benefits risks children teenagers december kids safety dangers social networks february university division information technology tips safe social networking important think beyond age groups leverage instead reliable concepts cognitive emotional physical stages overarching limitations comes researching working children youth experience engineers probably limited strongly recommended formally consult experts fields child development developmental science psychology learning sciences among others evaluate used children youth experts needed objectively ask questions value safety utility product help understand biases within also ways mitigate user research take multivariate approach product questions qualitative quantitative methods longitudinal research traditional usability work contextual inquiry interviews benchmarking scorecarding additionally among resources listed technology design researchers whose work focuses technology children cited particular jason yip julie kientz alexis hiniker work captures much depth nuance risks affecting children possible include guidelines artificial intelligence children whenever data collected systems engineered products sold ethical obligations arise fair honest good work avoid harm obligations pressing working children youth among vulnerable members society adults special responsibility help flourish shield harm technologies systems powered could transform people interact also bring potential bias exclusion lack fairness users potential change shift power also comes requisite moral duties result designers developers maintainers researchers tools children youth urged mindful sensitivity ethical ramifications work design fair systems greatest potential harmputting children youth first news full examples biased discriminatory models without careful design models biased unfair violate trust consent cause emotional developmental harm child youth users breaches trust consent product teams always endeavour worthy users trust safeguarding health safety children requires even vigilant consent guardians children solicited collecting data guardians children must informed data collected used control data circulates standards general data protection regulation gdpr right forgotten secure access data developmental harm adults responsibility confirm material shown children directed towards flourishing children rapidly developing autonomy agency habits relationships technology way systems designed negatively affect development without care bias unequal access impact algorithmic often reinforce existing societal biases prejudices cause unequal impacts across different populations single aggregate performance metric accuracy may fail capture recognize people punished left mistreated system risk mitigation employ proactive strategies responsible governance pilots surgeons preflight checklist simple set factors dwell starting project produce significant benefits help reduce risk approach favoured loukides mason patil ethics data checklist instantiated software repositories via templating libraries checklists ethics questions drawn work simon draw many existing ethical frameworks happy decision public record would happen everybody would like someone proposed course action bring good result proposed course action character character organization proposed course action consistent espoused values principles inclusive responsible safe transparent artificial intelligence children ethical governance practice understanding evaluating questioning updating technology based stated ethical goals connected ethical checklists vision documents manifestos sets principles lay virtues strive building systems helpful examples include giorgia data humanism revolution visualized ignazio catherine lauren klein data feminism mit press capitalism data black lives checklists start incorporating ethics design complete descriptions project ethical implications sufficient proof project designed ethically checklists conversation starters rather conversation enders designers also cognizant specific contexts work checklists one type design may extend others preflight checklist pilot checklist surgeon look different obligation creator product research leverage relevant work done others confirm ethical treatment use ongoing ethical thinking imagination build ongoing ethical evaluation development making sure include stakeholders outside team ideally external stakeholders included affected technology strategies carrying ongoing reflections found data children collaborative ethical assessment employ ethical governance fairness ethical product procedure managers might regularly check employees see work progressing assess overall health project need regularly consider ethical health project ethical governance practice understanding evaluating questioning updating technology based stated ethical goals periodic internal assessment crucial scope execution work changes time people often limited individual perspectives work going review require periodic external assessment governance councils ethics review boards public feedback identify concerns would missed provide external metrics criteria avoid bad outcomes product development biased bias comes ethical concerns identify potential harm kind exercise indication failure instead problem understand manage potential harms explored documented early revisited throughout design process product life cycle ethical considerations stakeholders various disciplines particularly experts child development case participate processes stage governance practice include mitigation plan potential harms potential harm end product development cycle ends besides confirming adhere applicable laws regulations related product ethical governance requires considered potential harms may result discontinued product support availability test train data understand behaviour model areas bias questions consider product defined measured biases biases remediated gaps benefits uncovered synthesis research conducted artificial intelligence children inclusion essential ingredient people sense emotional psychological physical safety humans social animals struggle make progress developmental scales without sense community people crave sense belonging naturally attuned feelings exclusion inclusion resulting children youth often lack coping skills necessary manage negative feelings exclusion real perceived focusing building inclusive experience may cause cognitive emotional social distress feelings exclusion harm child confidence feelings development technology teams may inclined equate inclusion accessibility smart toy developed collaboration world economic forum defines accessibility aipowered toy accessible children physical mental learning disabilities including neurodiversity children speaking languages english cultures type inclusivity important emotional inclusivity already noted model internalizes bias programmers data cause unintentional exclusion design practice particularly harmful problematic children youth vulnerable require even greater care exclusion design technology many forms words used interface complexity learning curve features lack accessibility features ways products actively exclude people would otherwise customers unlike children adults able reason states others exclusion built mind accessibility expensive early product cycle localize strings reasoning reduces psychological emotional physical harm adults feel excluded children youth however may always perspective exclusion experience may unchecked could result negative feelings abilities bias bias bias internalized data collection sampling methods result models training data reflect inevitable flaws system bias cause harm assumes attitudes abilities capabilities beliefs different user technology concludes something user runs risk insulting confusing embarrassing excluding demeaning person something obvious giving users flower patterns bulldozers avatars clothes risk child sense personal identity enforces potentially harmful societal norms standards even worse child born cleft lip might excluded camera filter bias training data isolates experience result biases manifesting experience cause user confusion negative reinforcement bullying experiences concept bias well documented several resources help address limitations work michael machines trust mitigate bias toptal developers james jake silberg brittany presten biases harvard business review october understanding algorithmic bias build trust january deepti breaking gender bias artificial intelligence linkedin april feelings exclusion harm child confidence feelings responsible safe transparent greatest potential harm artificial intelligence children risk mitigation build research plans advisory councils participant pools represent high variability target audience product roadmap include robust feedback loops users education professionals stage development critical feedback collected early ideally code written feedback continues product shipped plan collect explicit verbal behavioural sentiment feedback development stage target customers children youth well feedback stage age appropriateness experts cadence level rigour user testing finally stages development team must able answer included product every risk identified able justify risks introduces relative rewards actively seek user experience failures create experiences exclusion need include children youth step development cycle continually document product enabled variety children youth successfully participate may decide exclude user type exclusions documented shared discussed internally build consensus reflected marketing product testing design user research studies target areas already identified could exclude children youth using product intended desired purposely push bounds product customers test train data understand model behaviour areas bias acknowledge biased seek understand limitations document biases could harm children youth able mitigate bias could said mitigation inevitably introduce new bias gaps benefits uncovered deeper understanding disclosed customers artificial intelligence children greatest potential harm introducing intelligence otherwise static system introduces characteristics part makes attractive consumers also makes dangerous brains children youth seek signals love belonging signals significantly salient adults therefore children youth read signals way product teams must understand children youth customer could building something may introduce harm result carefully analyse risks seek greater understanding develop mitigation techniques technology gone rogue comes society vulnerable citizens skirting ignoring established regulations related treatment unethical children youth deemed capable understanding implications data sharing personal identifiable information leaks risks associated granting access lack compliance local state regional country regulations catastrophic technology developers unsophisticated inflexible models human physical emotional cognitive development sync consistent speed example body emotional intelligence cognitive abilities turns could body emotional intelligence cognitive abilities due concussion sustained unpredictability speed fluidity human development necessitates sophisticated children youth reasonably flex across stages development achievable guidance authorities experts child development psychology ethics built small silly adults children youth physically smaller versions adults limited vocabulary less intelligence product team similar failures pink shrink approach feminizing products made men mind treating children legitimate holistic independent target audience carries brains children youth different adults means less capable adult myriad cognitive social physical factors ideally able leverage abilities deliver great user experience unpredictability speed fluidity human development necessitates sophisticated children youth reasonably flex across stages goal theme confirm product teams internalized responsibilities towards children youth use products starts product teams considering mitigating possibility may skills expertise adequately evaluate risks introducing product children youth next product ideation design planning development testing grounded age appropriateness methods test appropriateness reflects latest learning science layered traditional product cycle considerations emotional psychological physical safety children youth targeting responsible design act collaboration product team customers guardians well experts learning science ethics developmental psychology relevant research fields inclusivefair safe transparent artificial intelligence children risk mitigation build advisory councils research participant pools represent high variability target audience questions consider product business model mind development stage age appropriateness confirmed included product justify risks introduces relative rewards often research testing product included kids teachers subjectmatter experts confirm developmental stage age appropriateness product confirm feedback loop user education professionals future iterations features product roadmap actively seek failures create negative experiences recommendations consider children youth step development cycle document product ensured children youth participate product testing well directed usage focus areas team already identified risky could exclude children youth using product privacy security implications questions consider management data comply governing data laws policies related consumers specifically children children online privacy protection act coppa age appropriate design among others users informed notified commercial activities related product third parties product use enable user interact safely others build conviction around behaviour might adjust user development stage questions consider articulate product addresses variability expect see user development stage may may accommodate variability adjust behaviour based implicit signals developmental stage physical dexterity solving ability language ability users able correct incorrect conclusions made users developmental stage artificial intelligence children psychosocial development typically predicated feelings safety children youth whose environments chaotic dangerous unpredictable struggle meet developmental milestones including learning milestones emotional regulation bonding makes sense brain child risk allocate precious resources keeping alive acquiring next developmental milestone steep price children youth pay however matter severity experience children easily find harm way underdeveloped prefrontal cortex means less able predict consequences impulsive lack lack experience know seek instant gratification may interest limiting things like screen time purchases interaction online strangers reasons product team must consider ally children youth guardians jointly taking responsibility protecting users technology harm greatest potential harm sadly many people organizations technology actors great lengths harm children youth exploit vulnerabilities personal gain product team job consult experts think may unintentionally helping malicious actors harm children youth technology build ways prevent mitigate harm greatest potential harming children youth technology include malicious oblique naive usage technology unintentionally support negative behaviours outcomes several often unintended oversights product teams nevertheless responsibility certain categories use particularly concern children youth intent individual express intent causing harm using product way dangerous others happens user ignores safety warnings intentionally takes risks without recognizing consequences particularly concerning among children youth without fully developed frontal lobes alternative learning styles see transparent section advice mitigate issues use people always use creations way intended make wrong demonstrate creator lack imagination use opportunity mitigate risk make safer product unsafe community product teams naive technology used social situations recent years potential threat toxicity risk social technology illustrated people able hide behind technology say unsavoury people ill intent exploit technology access vulnerable communities social currency followers likes used indicators personal lack thereof adults struggle consequences reality controlling behaviour online environment managing emotional fallout upsetting online encounters struggles amplified children youth callous observer technology facilitates conversations child youth machine must anticipate cases user divulges information related potential harm risky situations abuse committed adult want product ignore diminish joke emphasize overreact input instead must decide product development relationship involved teacher therapist emergency services clearly articulate actors course escalation resolution harmful scenario detected another way technology ignore needs vulnerable users failing address overuse addiction child youth obsessively using product know know harm obsessive use overuse could introduce user eye strain repetitive product team must consider ally children youth guardians jointly taking responsibility protecting users technology responsible transparent artificial intelligence children strain injury emotional instability sleep disruption vertigo diminished capacity distinguish fantasy reality among unintended consequences overusing technology demographics allowed define user people demographics know intellectually fall victim assuming much others demographic data available people tend forget behaviour one robust data sources predicting technology risk product teams invest variety data triangulate predictions demographic data supplemented tempered behavioural inputs explicit indicators preference data privacy security breaches first line defence keeping customers safe privacy security features built technology need robust feature development around protection customers data overemphasized includes limited security privacy data methods others access resell data exploit embarrass bully harm otherwise hurt customers modelled mitigated revisited product life cycle risk mitigation conduct user research inform scenario planning nefarious use cases mitigation strategies intent detect malicious use cases informed detected child youth role notification versus guardian technology able suspend happens negative consequences occur autodetection malicious use wrong detect use cases redirect accommodate user different interaction path built conviction model interpretability potential cases physical emotional harm child youth could occur technology used naively risks need addressed guardian child youth use substitute user research detect oblique use cases ideally ethnographic usage early development cycle continuing release team external stakeholders brainstorm potential ways creation may used resulting unintended consequences data supplemented actual child youth users given opportunity use technology however desire build multivariate measurement strategy single metric measure fairness inclusivity responsibility safety transparency product accordingly need multiple indicators product health quantitative happened qualitative happened scepticism towards traditional product metrics adoption usage also employed traditional metrics net promoter artificial intelligence children score daily active user based adult users lack considerations children youth recommendations build measurement strategy consult include user studies ethnography community consequence scanning judgment professional user researcher design workshops identify address risks encourage engineering teams strategies solutions use microsoft harms modeling metrics optimization used interactions inadvertently addictive example ask questions happens metric hits intended unintended consequences metrics hit much right amount answer question build transparent explainable user relationship model child guardian technology identify mitigate harm mentioned building children youth also building parents teachers guardians design guardian experience technology level careful consideration child youth experience key questions consider verifying customers taken account tool learns potential harm child hurting others hurt guardian adult child youth tool case security privacy breaches hacking viruses guardians informed action taken behalf guardian child youth reporting risks risks tool report cadence data logged regulation auditing purposes refer coppa understand parents guardians control control technology child uses controls asynchronous available real time mechanism place automatically shut tool risk identified product team develop expertise technology concerns related children youth members development team engaged building personal expertise child youth development however replace need engage experts fields child psychology development technology design children youth proactive ways increase sensitivity ability identify risk include actions work design experts wrong even design delivered children youth cautionary tale friend cayla smart success metrics paired balance among user business technology needs build security plan takes children youth cognitive emotional physical safety account plan hacker gets access system customers data personal information data encrypted encrypted transit rest sort personal data necessary collect anonymized protect privacy data highly protected case hacking etc protected data categories children building children youth also building parents teachers guardians artificial intelligence children transparency take many forms first clear disclaimers products must deliver customers based local state regulations product teams encouraged include proposed labelling system part toolkit product physical packaging accessible online code products children youth include following six categories explanations create transparency among product buyer adult end user children youth transparency around security privacy permissions helps reduce prevent unintended consequences arise naive age developmental stage would product recommended material could potentially expose user material determined accessibility product accessible children youth different ages diverse disabilities educational backgrounds trained tested inclusion mind camera microphone product use either turned device always observing user people using product networks product allow user socialize users networked play social network product create safe healthy social experience community rules regulations place confirm child put dangerous situation use product use product use benefit user experience product use pose potential risks user data use user data used holds information shared user data stored protected product communicate use user data product developers also consider build encourage responsible use transparency around security privacy permissions helps reduce prevent unintended consequences arise naive usage designing goal transparency also manifest experience build helping establish trust comfort likely want audiences feel towards finally transparency achieved throughout lifetime product day customer first unboxes uses technology fertile ground establish honest disclosure user day technology takes major update enhanced functionality ignored another opportunity transparency inclusivefair responsible safe artificial intelligence children greatest potential harm models inherently opaque difficult understand including children youth well parents guardians want design black box impossible understand explain without proper transparency ignore laws obfuscate consent exclude parents guardians process lacks transparency also put undue burden privacy security user remember transparency breeds trust leads greater engagement enjoyment success product greatest potential harm transparent includes lack obfuscation informed consent technology usually built feedback loop flow information user technology back technology intends learn user social legal contract implicit conversation accordingly developers must acquire informed consent user guardian capacity knowingly willingly agree terms contract accept reject penalty time common practice technology include informed consent license agreement adults practice works way gather informed consent children seen attempt obfuscation stakes high kids youth recommended informed consent explicit even celebrated act technology might also need act consent user guardian reason important think customer consenting capability consent design mechanisms actively provide ignored governmental rules regulations responsibility comply local rules regulations related technology product team company selling product country regional state local rules follow development product clear consumer burden security privacy left user ideally able build still works well even security privacy settings enabled turned maximum settings even imperative technology kids default settings restrictive conservative protection customers responsibility disclose advantages risks adjusting security privacy levers stage use customers able understand implications good bad related data experience technology decisions excluded guardians technology targeted children youth two primary users child guardian relationship technology builds guardian important safe use technology inform integrate possible listen guardians user inform product consideration know technology right child see inform learn parameters use boundary cases risk finally collaborate keeping tabs usage boundaries crossed risky behaviour detected risk mitigation confirm terms use clear easy read accessible literate user avoid using complicated technical legal jargon explaining terms conditions use keep terms use reasonable length either unavoidable present simplified perhaps even fun engaging version user explains important points everyday language accessible disclose use technologies facial recognition emotion recognition data managed technologies used application must presented guardian upfront analysis storage data collected technology must clearly explained along options opting security privacy options transparency breeds trust leads greater engagement enjoyment success product artificial intelligence children design scenarios informed consent day use well day technology may take update expanded functionality confirm new requests consent camera included experience well designed include guardians exact technologies classified high risk vary time thus need revisited product design methods disclosure user must informed ideally given option opt data collected purposes technology whether used sent third party stored cloud explicitly mention geographic regions whose data protection privacy laws honoured technology regions whose data protection privacy laws considered design development application specific mentioning legal rather using vague language regular intervals since laws currently framed updated nations use secure options default allow guardians opt advanced features reading specific terms use default options secure least intrusive add additional layer safety every user detailed information technology used guardians decide opt feature uses matrix user experience based security feature options instance technology behave microphone disabled camera allowed explain outcome matrix customers clearly specify age group application built children different age groups different responses stimuli due developing thus essential guardians given accurate information developmental stage age group technology built disclosing level detail help guardians decide introduce particular child technology provide guidelines environment technology meant used product teams must confirm guardian informed environment intended use school part group activity home supervision adult helps purchase decisions also increases probability technology used properly greatest chance customer success satisfaction also useful include details recommended hours usage per week indicators misuse create alert mechanisms guardians intervene case risk identified usage product development cycle build threat models include methods misuse risky behaviour overuse bullying inappropriate content outcome threat modelling solutions allow detection misuse methods intervention example high number hours used friend requests unrecognized contacts product documentation include potential threats features guardians users leverage mitigate risk data consumption monitoring visibility messages ability suspicious users exact technologies classified high risk vary time thus need revisited product design methods disclosure artificial intelligence children references grant hilary makes internet trolls tick psychology today august thomas child tracker app leaks million texts million photos kids phones forbes february stephen boris johnson retreats exam debacle new york times september update adversity information sponsored global children fund disadvantaged makes kids vulnerable ishita jason yip alexis hiniker intentional technology use early childhood education proceedings acm interaction vol issue cscw november article devin breach exposing millions parents kids toymaker vtech handed fine ftc techcrunch january sense technology addiction concern controversy finding balance children collaborative unicef ethical assessment live april placido dani youtube elsagate illuminates unintended horrors digital age forbes november consequence scanning agile practice responsible innovators children rights guide trade commission children online privacy protection rule coppa children online privacy protection act children privacy abubakar frustrating reality getting grades without exams vice august kashmir aaron krolik photos kids powering surveillance technology new york times october anna lauren data ethics times september workshop equity inclusivity outcomes june organization standardization iso popular standards information security management online browsing platform information technology security techniques code practice information security controls iso std consulting art gdpr right erasure right forgotten julie praise small data might consider studies getmobile mobile computing communications vol issue december professional standards computing machinery acm code ethics professional conduct adopted june consulting general data protection regulation gdpr feifei designing kids cognitive considerations nielsen norman group december nations human rights office high commissioner convention rights child department health human services children information special protections children research subjects march update sapna youtube kids startling videos slip past filters new york times november artificial intelligence children azure community jury november azure foundations assessing harm november azure judgment call november ethics institute state ethics january shannon dawn maree bruno oliveira jayme joanna black disaster capitalism rampant edtech opportunism advancement online learning era critical education vol society public health young gamers get debt buying loot boxes december jason yip baxter know name exploring failure designing robots intelligent technologies children interaction design children workshop creating opportunities children reflections robotics intelligent technologies ben bridging gap ethics practice guidelines reliable safe trustworthy systems acm transactions interactive intelligent systems vol megan parents students teachers give britain failing grade exam results new york times august shea remote testing monitored failing students forced undergo nbc news november checklists institute algorithmic accountability policy toolkit october frameworks guidelines toolkits technology ten rules technology june children collaborative unicef ethical assessment live april mike hilary mason patil ethics data science reilly media july dillon algorithmic impact assessments practical framework public agency accountability institute april shannon ethical toolkit practice santa clara university markkula center applied ethics june cynthia attachment theory definition stages thoughtco october amy baby room hacker took baby monitor broadcast threats parents say washington post december meredith disability bias institute new york university usa november jason laughing scary farting cute conceptual model children perspectives creepy technologies chi proceedings chi conference human factors computing systems paper artificial intelligence children labelling system promotes transparency trust child youth users parents guardians labelling system figure designed included products physical packaging online accessible code like nutritional information food packaging labelling system intended concisely tell consumers including parents guardians well children youth works options available users companies encouraged adopt tool help create greater trust transparency purchasers child users products artificial intelligence children figure labelling system age age technology content designed accessibility users different abilities backgrounds use sensors watch listen users cameras microphones networks users play talk people using use use interact users data use collect personal information recommended ages years children hearing impaired visually impaired neurodiverse users designed include autism dyslexia physical disabilities designed include fine motor skills mobility languages supported turn turn play socialization function turned recognition recognition recognition data data others control whether data shared children online privacy protection act coppa compliant general data protection regulation gdpr compliant information commissioner office ico age appropriate design code compliant data collection create customized curriculum yyy nnn source world economic forum artificial intelligence children guide parents guide helps buying using products children youth guide designed educate parents guardians figure help understand considerations buying toys devices apps video games smart toys smart speakers education technology products also designed supplement labelling system may accompany product service products use sensors inputs collect information whoever uses information collect includes images videos patterns use data products use algorithms interpret information make predictions suggestions users benefits risks products benefits example recommend content users might like products also risks might collect information consumers want use keep risks carry even weight users children may may ready make decisions digital rights may fully know understand impact lives artificial intelligence children guide parents guardians consider figure things matters know developmental stage appropriate child toys devices designed certain ages users young technology content might difficult use could expose risk old technology content might interesting fun technology work equally despite differences users abilities able use technology physical mental disabilities require accommodations modification users look different speak different languages could cause problems well designed find technology protects privacy allowing users turn cameras microphones secure information passwords preferences regarding data collected devices products use input cameras microphones sensors watch recognize learn users products might use facial recognition identify child face voice recognition detect voice devices products might also store send information another location hacked criminals children never share personal information engage people know beware people acting malicious intent products enable users play games talk people online playing online others fun sure children proceed caution times know strengths limits decisions suggestions remember decisions wrong products might make predictions based data collected child prior activity might help child make decisions also might label misread users change settings preferences protect child data know kind information products collect long keep access products collect data children store family child information important protected visit product website learn sources like common sense media choosing right products different ages developmental stages visit product website read user reviews visit product website call company customer service read online etiquette online safety talk children use resources like google safety center families internet awesome resources read user reviews learn facial voice recognition work visit product website call company customer service learn kind information products collect long keep access age designed accessibility users different abilities backgrounds use sensors watch listen users cameras microphones networks users play talk people using use use interact users data use collect personal information source world economic forum artificial intelligence children contributors acknowledgementslead authors carla aerts director digital change hodder education founder refracted amy alberts senior director user research tableau software jianyu gao world economic forum youth council member united states yakaira nÃºÃ±ez research insights platform salesforce aimee kendall roundtree professor associate dean research promotion texas state university debra slapak lead edge thought leadership innovation dell technologiesproject lead seth bergeson pwc fellow world economic forum llc world economic forum llc kay head artificial intelligence machine learning patrick hynes lead partner engagement eddan katz platform curator emily rattÃ© specialist artificial intelligence machine learning conor sanchez specialist artificial intelligence machine learning maria luciana axente lead responsible good pwc kathy baxter principal architect ethical practice salesforce alex beard senior director teach bouÃ©e managing partner alpha intelligence capital jasmina byrne chief public policy united nations children fund unicef sam coates head innovation interactive business lego group ronald dahl director institute human development university california berkeley ilana golbin director lead responsible pwcalison gopnik professor psychology university california berkeley dave graham lead technology advocacy dell technologies beeban kidron founder chair foundation priya lakhani founder chief executive officer century tech rose luckin professor learner centred design ucl knowledge lab university college london gary meltzer managing partner pwc illah nourbakhsh gates professor ethics computational technologies carnegie mellon university sallie olmsted lead global communications media christopher payne director digital responsibility government public affairs lego group artificial intelligence children michael preston executive director joan ganz cooney center sesame workshop anand rao global leader artificial intelligence pwc aza raskin center humane technology karen silverman founder chief executive officer cantellus group matthew studley wallscourt associate professor technology ethics university west england sherry turkle abby rockefeller mauzÃ© professor social studies science technology massachusetts institute technology angela vigil partner executive director pro bono practice baker mckenziesteven vosloo policy specialist digital connectivity united nations children fund unicef alan winfield professor robot ethics university west england world economic forum also thanks following project community members youth council members individuals contributed time insights sandrine amahoro rutayisire danielle benecke bianca bertaccini kathleen esfahany joy fakude marine formentini matissa hollister grace knickrehm nupur ruchika kohli oliver leiriao mariam muhairi candice odgers melanie penagos chloe poynton guido putignano arwa qassim pia ramachandani ana rollÃ¡n sundar sundareswaran ecem yilmazhaliloglu artificial intelligence children endnotes institute electrical electronics engineers ieee ieee code ethics june accessed december dignum virginia melanie penagos klara pigmans steven vosloo policy guidance children version united nations children fund unicef november accessed december world economic forum empowering leadership oversight toolkit boards directors accessed december united nations human rights office high commissioner convention rights child adopted opened signature ratification accession general assembly resolution november entry force september accordance article accessed november kalliomeri reetta design save children accessed december toy association new national survey finds parents always follow important toy safety guidelines press release november accessed december klein cynthia maturation prefrontal cortex bridges understanding march accessed december stanborough rebecca ages stages monitor child development healthline december accessed december cell press kids blame immature brains sciencedaily march accessed december yukti important research methods accessed december society american archivists saa saa core values statement code ethics august revision accessed december general data protection regulation gdpr art gdpr right erasure right forgotten accessed december hourcade juan pablo interaction design children foundations trends interaction vol accessed december loukides mike hilary mason patil ethics data science reilly media july accessed december deon ethics checklist data scientists accessed december longstaff simon ethical issues decision making james ethics centre accessed december madaio michael checklists understand organizational challenges opportunities around fairness proceedings chi conference human factors computing systems chi accessed december gogoll jan ethics software development process codes conduct ethical deliberation philosophy technology accessed december data children collaborative unicef ethical assessment live april accessed december mittelstadt brent principles alone guarantee ethical may accessed december winfield alan marina jirotka ethical governance essential building trust robotics artificial intelligence systems philosophical transactions royal society mathematical physical engineering services october accessed december association psychological science harlow classic studies revealed importance maternal contact june accessed december artificial intelligence children orphanage research team effects early relationship experience development young orphanage children monographs society research child development vol accessed december smart toy awards collaboration world economic forum smart toy awards shaping future childhood accessed december stemler sam top common accessibility issues avoid solve accessibility metrics july accessed december whittaker meredith disability bias institute new york university usa november accessed december reddy shivani unfortunate history racial bias photography accessed december hess robert virginia shipman early experience socialization cognitive modes children child development vol december accessed december kolitz daniel kids feel stronger emotions adults gizmodo september accessed december booker karene age changes young children read social cues cornell chronicle november accessed december federal trade commission children online privacy protection rule compliance plan business june accessed december kinedu children development linear august accessed december contrera jessica end shrink pink history advertisers missing mark women washington post june accessed december calvert sandra children consumers advertising marketing future children vol spring accessed december complete guide gdpr compliance accessed december federal trade commission children online privacy protection rule coppa accessed december ico introduction age appropriate design code accessed december vinney cynthia attachment theory definition stages october accessed december children adversity information sponsored global children fund disadvantaged makes kids vulnerable dark patterns accessed december brenner grant hillary makes internet trolls tick psychology today august accessed december common sense technology addition concern controversy finding balance accessed december microsoft azure community jury november accessed december doteveryone consequence scanning agile practice responsible innovators accessed november microsoft azure judgment call november accessed december microsoft azure foundations assessing harm november accessed december federal trade commission children online privacy protection rule coppa accessed december designing children rights guide accessed december museum failure friend cayla spying doll accessed december artificial intelligence children phadnis shree develop correct six sigma project metrics isixsigma accessed december future privacy forum federal trade commission updates coppa faqs october accessed december simple eula project fair eula new step bridge gap corporate consumer accessed december cragg lucy development stimulus response interference control midchildhood developmental psychology vol november accessed december artificial intelligence children world economic forum route capite switzerland tel fax contact world economic forum committed improving state world international organization cooperation forum engages foremost political business leaders society shape global regional industry agendas
