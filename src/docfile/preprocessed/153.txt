study panel future science technology eprs european parliamentary research service scientific foresight unit stoa april governance framework algorithmic accountability transparency eprs european parliamentary research service governance framework algorithmic accountability transparency algorithmic systems increasingly used part processes public private sectors potentially significant consequences individuals organisations societies whole algorithmic systems cont ext refer combination algorithms data interface process together determine outcomes affect end users many types decisions made faster efficiently using algorithms significant factor adoption algorithmic systems capacity process large amounts varied data sets data paired machine learning methods order infer statistical models directly data properties cale complexity autonomous model inference however linked increasing concerns many systems opaque people affected use lack clear explanations decisions make lack transparency risks und ermining meaningful scrutiny accountability significant concern systems applied part decision processes considerable impact people human rights critical safety decisions autonomous ehicles allocation health social service resources study develops policy options governance algorithmic transparency accountability based analysis social technical regulatory challenges posed algor ithmic systems based review analysis existing proposals governance algorithmic systems set four policy options proposed addresses different aspect algorithmic transparency accountability awareness raising education watchdogs whistleblowers accountability use algorithmic decision regulatory oversight egal liability global coordination algorithmic governance stoa panel future science technology author study written fol lowing authors request panel future science technology stoa managed scientific foresight unit within directorate parliamentary research services eprs secretariat european parliament ansgar koene main author university nottingham chris clifton purdue university yohko hatada emls helena webb menisha patel caio machado jack laviolette university oxford rashida richardson dillon isman institute administrator responsible mihalis kritikos scientific foresight unit stoa contact publisher please mail stoa linguistic version original manuscript completed arch disclaimer copyright document prepared addressed members staff european parliament background material assist parliamentary work content document sole responsibility author opinions expressed herein taken represent official position parliament reproduction translation non purposes authorised provided source acknowled ged european parliament given prior notice sent copy brussels european union isbn doi stoa website intranet internet blog governance framework algorithmic accountability transparency executive ummary report presents analysis social technical regulatory challenges associated algorithmic transparency accountability including review existing proposals governance algorithmic systems current state dev elopment related tandards consideration global human rights dimensions algorithmic governance motivation algorithmic systems increasingly used part decision processes potentially significant consequences individuals organisations societies whole used appropriately due care analysis impacts people lives algorithmic systems including artificial intelligence machine learning great potential improve human rights democratic society order achieve however vitally necessary establish clear governance frameworks algorithmic transparency accountability make sure risk benefits equitably distributed unduly burden benefit particular sectors society growing concern unless appropriate governance frameworks put place opacity algorithmic systems could lead situations individuals negatively impacted computer says recourse meaningful explanation correction mechanism way ascertain faults could bring compensatory processes governance aspect society extent algo rithmic accountability required considered within context good harm risks systems present background definitions drivers algorithmic transparency accountability study present two landscapes explore conceptual roles uses transparency accountability context algorithmic systems primary role transparency identified tool enable accountability known organisation held accountable regulate transparency may relate data algorithms goals outcomes compliance influence usage automated decision making systems algorithmic systems often require different levels detail general public regulatory staff third forensic analysts researchers degree transparency algorithmic systems often depends combination governance processes technical properties system importa difference transparency accountability accountability primarily legal ethical obligation individual organisation account activities accept responsibility disclose results transp arent manner challenges algorithmic accountability arise complex interactions sub data sources might control entity impossibility testing possible conditions formal proofs system performance difficulties translating algorithmically derived concepts human understandable concepts resulting incorrect interpretations nformation asymmetries arising algorithmic inferences accumulation many small individually non algorithmic decisions ifficult detect injections adversarial data considering governance transparency accountability important keep mind larger tivating drivers define meant achieved recognising fairness immensely complex concept different sometimes competing definitions nevertheless seen fundamental component underpinning responsible systems suggested algorithmic processes seek minimise potential unfair maximise potential fair transparency accountability provide two important ways achieved airness discussed thr ough lens social justice highlighting stoa panel future science technology potential algorithmic systems systematically disadvantage even discriminate different social groups demographics series real life case studies used illustrate fairness arise explor ing consequences lack fairness plus complexities inherent trying achieve fairness given societal context study describes ways lack fairness outcomes algorithmic systems might caused developmental making design features embedded different points lifecycle algorithmic decision making model connection made problem fairness tools transparency accountability highlighting value responsible research innovation rri approaches pursuing fairness algorithmic systems technical challenges solutions viewing transparency explaining steps algorithm likely lead informative outcome one hand could result description captures general process used make decision extreme would provide complete set steps taken complete detail algorithm machine learned model may enable outcome reconstructed provided input data complexity even experts may unable provide satisfying explanations particular res ult obtained order appreciate nature challenges confronting algorithmic transparency accountability necessary take consideration technical properties algorithmic decision systems give rise opacity key issues complexity linked scale data modularity algorithms iterative processing randomised tiebreaking interconnection decisions processes learned data result issues simply releasing source code algorithmic system would often provide meaningful transparency also reasons simply releasing model learning algorithm data often feasible solution transparency ata privacy coul compromised since may possible reverse engineer model determine data used construct ontinuous frequently updated learning capture incorporate new data changing trends also poses challenge howev technical methods reducing algorithmic opacity extracting explanations system behaviour despite lack transparency consider helpful divide transparency explanation two categories understanding overall system understanding particular outcome may require quite different approaches key idea keep mind goal transparency understand system works behaves understanding overall system goal obtain general understanding process algorithmic system makes decisions approaches include code review input data analysis tatistical analysis outcomes analysis ensitivity inputs one challenge approaches likely difficult impossible without direct involvement system developers least provision sandbox testing environment understanding system works likely little value transparency individual outcomes case approaches providing explanation become important systems designed provide explanation basis individual outcomes either specific design criteria incorporated entire system accomplished techniques sensitivity analysis meaningful transparency outcomes reached technically challenging given modern computing systems regulatory requirements transparency may significantly limit ability use advanced computing techniques regulated purposes meaningful transparency behavio computing systems feasible provide important benefits governance framework algorithmic accountability transparency iii mechanisms behavio ural transparency may need designed systems typically require participation developers operators systems technical issues algorithmic accountability largely question system behaves according specification accountability issues redress beyond technical challenges algorithm question actions implied specifications accountability actions taken algorithmic systems may need differe human actions differences largely governed particular application governance frameworks review governance frameworks algorithmic transparency accountability structured hierarchically begins perspective fundamental approaches technology governance provides detailed consideration various categories governance options finally review specific proposals governance algorithmic systems discussed existing literature high level two aspects considered principles ules approaches regulation related algorithms single regulatory category rather kind helper technology regulated component technologies consideration principles ules approaches context technology governance reveals much existing focuses risks principles based approaches methods emp hasise maximising benefits minimising risks arise use technology allocating resources proportion risks society considering impacts likelihood happen order establish appropriate levels control one common tool used support risk approaches impact assessment considering whether algorithms considered single regulatory category rather component kinds technologies arguments favour least would need strong coordination agencies regulating algorithms order ensure lessons learned developing regulatory solutions one set algorithms readily available agencies developing solutions identical highly similar algorithms level governance mechanisms analysis made five governance categories demand side market solutions upply side market solution companies self organisation branches tate intervention review made current practices related algorithms associated technologies likely role governing algorithmic transparency accountability brief conclude demand supply side market solutions mostly effective regulatory mechanisms algorithmic transparency accountability movement towards self organisation self regulation much appears reactive response threats company reputation due media reports whi stleblowers investigative journalism self level industry standards setting started take shape still development stages completed industry standards may provide useful vehicle level state intervention consideration given possible roles information measures public algorithmic literacy ncentives funding taxes strategic investment increase research algorithmic methods transparent accountable well support investigative journalism legislative measures possible role regulatory body among legislative measures consideration given role general data protecti regulation gdpr concluding likely sufficient roposals intain outcomes transparency noted means provid third auditing also stoa panel future science technology suggestion based applying tort iability possible modification liability levels depending transparency criticality algorithmic systems possib roles regulatory body include involvement standards along lines regulation regu latory body involved monitoring use best standards regulator powers intervene ranging touch nudging algorithm designer means incentives intervention requiring market approval testing existing governance proposals review existing governance proposals algorithmic systems attention given proposals right reasonable inferences possible role consumer protection agencies establishment fda algorithms proposals based tort liability combination algorithm certification regulatory agency algorithmic impact based proposal accountability algorithmic systems used public authorities developmen ndustry standards development industry standards relating algorithmic transparency accountability methods important shaping potential branch self reference possible setting regul atory requirements review current status standards development area however suggests take four years first international standards completed human rights many technical cademic communit ies discussing algorithmic accountability transparency framed language human ngos researchers started pick issues matter human rights early toronto declara tion protecting right equality non machine learning systems published aim drawing attention relevant well framework international human rights law standards binding actiona ble laws provide tangible means protect human rights individuals implementation level uman rights impact assessments provide framework designed identify intended unintended impact enjoyment human rights tate ability protect fulfil global dimensions algorithmic governance much digital economy use algorithmic systems characterised high borde nature global reach services built technologies successfully govern algorithmic systems therefore requires global dialogue collaboration across borders among rich poor countries avoid patchwork country regional approaches context global dialog attention drawn tensions arising narrative around development artificial intelligence counter point however note made global response gdpr increasing number states enacting inspired data privacy legislation suggesting may well positioned take lead establishing new framework international coordination algorithmic accountability transparency policy options based review analysis current literature regarding algorithmic transparency accountability successes failures challenges different governance frameworks applied technological developments especially ict four policy options proposed addresses different aspect algorithmic transparency accountability governance framework algorithmic accountability transparency awareness raising education watchdogs whistleblowers accountability public use algorithmic decision regulatory oversight egal liability private sector lobal dimension algorithmic governance stoa panel future science technology table ontents introduction motivation scope objective methodology resources used resources synthesis research work findings definitions concept ual landscape uses transparency transparency transparency fit purpose conclusion concept ual landscape accountability algorithmic fairness guiding purpose transparency accountability understand algorithmic fairness sources unfairness opportunities barriers towards achieving fairness algorithmic systems responsible approach design algorithms fair political legal human machine bias technical challenges transparency complexity relationship among decisions governance framework algorithmic accountability transparency vii machine learning conclusions technical solutions reducing opacity understanding overall system transparency individual outcomes reverse engineering black putting together conclusions collateral implications imposing fairness accountability transparency requirements high perspective governance frameworks algorithmic systems principles rules based governance governance algorithmic systems systems algorithmic components governance framework options demand side market solutions supply side market solutions companies self branches self state intervention existing proposals governance algorithmic systems right reasonable inferences consumer protection authorities fda algorithms agency certification tort liability accountability measures algorithmic system use public authorities development industry standards algorithmic decision systems human rights foundation algorithm governance global dimension algorithm governance stoa panel future science technology viii policy options awareness raising education watchdogs whistleblowers accountability public sector use algorithmic decision regulatory ersight legal liability global coordination algorithmic governance conclusions references governance framework algorithmic accountability transparency introduction motivation algorithmic systems increasingly used part decision processes potentially significant consequences individuals organisations societies whole ways systems reach conclusions may reflect amplify existing biases may offer explanations satisfy accustomed social judicial expectations growing concern traditional frameworks implementing transparency accountability may suffice mechanisms governance one key areas concern centres around opacity algorithmic systems highly complex potentially involve machine learning system behaviour come depend design choices time creation also data trained input evaluated unless appropriate governance frameworks put place real risk situations may arise individuals negatively impacted computer says recourse meaningful explanation correction mechanism way ascertain faults could bring compensatory processes linked pervasive automated data collection individual longer asked explicitly provide data used algor ithmic system become difficult impossible individuals identify data used reach particular decision outcomes thus impossible correct faulty data assumptions even ascertain error made important element concern inherent consequence algorithmic making implicitly biases social value limited things measured since algorithmic decision systems take account things measured fed system blindly applied without democratic human rights safeguards risks driving ever increasing levels corporate surveillance name improved algorithmic decision outcomes som voices community also expressing concern current high reliance purely empirical methods methods rely observing responses sampled test data evaluating system performance underlying forma model support validity system behaviour sacrificing scientific rigour rapid gains potential long term costs reliability resulting systems could compared concerns school education teach ing methods produce students increasingly good taking school exams without truly understanding material taught increased requirements algorithmic transparency accountability might contribute greater focus scientifically rigorous algorithm evaluation methods could lead significant gains future developments algorithmic systems artificial intelligence time algorithmic systems permeating aspects lives handwriting analysis real navigation systems hurricane prediction medical diagnosis logistics simple reasons work better systems replacing augmenting governance aspect lives extent algorithmic accountability required considered within context goods harms risks systems provide require decisions made appropriate stakeholders involve often difficult particular questions social goals values rights models fairness compensatory structures risk tolerance etc stoa panel future science technology used appropriately due care analysis impacts people lives algorithmic systems including machine learning great potential improve human rights democratic society order achieve however vitally necessary establish clear governance frameworks algorithmic transparency accountability make sure risk benefits equitably distributed way unduly burden benefit particular sectors society frameworks assume transparency ultimate goal means support social values governance machine learning therefore also tolerance transparent systems bring desirable social benefit carry demonstrably limited acceptable risks transparency one tool governance toolbox tool crucial wielder understand uses limitations offs involved scope report reviews possible governance frameworks accountability transparency algorithmic systems including discussion challenges opportunities associated implementation based assessment current atus algorithmic system governance comparison governance technological systems view question three dimensional multiple points process multiple structural elements algorithmic systems might made transparent various tools implements algorithmic systems governed benefits harms risks governing leaving ungoverned first two dimensions review includes governance frameworks terms legal regulatory mechanism impact assessments auditing requirements high systems internal frameworks organisational level within public private sector organisations rules governing public procurement algorithmi systems adoption industry standards algorithmic transparency supporting frameworks promoting third investigatory oversight support mechanisms public interest investigative journalism use algorithmic systems objective beyond providing review current potential governance frameworks algorithmic accountability transparency report aims provide understanding technical challenges solutions algorithmic transparency clarify relationship fairness provide recommendations algorithmic impact assessment metric assessin degree regulatory scrutiny algorithmic system would appropri particular context use governance framework algorithmic accountability transparency methodology resources used methodology based literature review sourcing primary secondary scientific literature including white papers reports government inquiries civil investigations current state proposed future directions algorithmic governance news articles included part discussion role investigative journalism well illustration perspectives concerns wider population first step involved review technical approaches algorithmic transparency algorithmic accountability including concepts accountability design remedial accountability second step included review types degrees impact algorithmic systems social justice fair decision associated technological societal algorithmic literacy transparency oversight information symmetry third step review existing proposals governance frameworks algorithmic systems including relevant sections gdpr national french digital republic local government legislation new york city law creating task force review government use algorithmic systems industry self standards resources literature databases google scholar web science key phrase searches algorithmic governance technology ethics regulation algorithmic literacy algorithmic disclosure key phrase searches followed citation reference based searches types literature primary literature review papers computer science law social science grey literature standards documents ieee standards industry reports media reports propublica compas government reports french law digital republic stoa panel future science technology synthesis research work findings present analysis cial technical regulatory challenges associated algorithmic transparency accountability including review existing proposals governance algorithmic systems current state related standards development considerations global human rights dimensions algorithmic governance start definitions algorithmic transparency accountability elaborated two conceptual landscapes explore conceptual roles uses transparency accountability context algorithmic systems underlying motivation governance framework algorithmic transparency accountability explored review issues regarding algorithmic fairness rounding background context setting overview technical challenges possible technical solutions identified algorithmic transparency review governance algorithmic transparency accountability struct ured hierarchically start level perspective fundamental approaches technology governance provide detailed consideration various categories governance options finally review specific proposals governance algorithmic systems discussed existing literature final two subsections take detailed look current state international standards development related algorithmic making systems consider global human rights dimensions algorithmic governance definitions following concise definitions transparency provided reference clarify meaning key terms used document transparency depen ding type use algorithmic decision system desire algorithmic transparency may refer one following aspects code logic model goals optimisation targets decision variables aspect considered provide insight way algorithm performs algorithmic system transparency global seeking insight system behaviour kind input local seeking explain specific input output relationship account ability set mechanisms practices attributes sum governance structure involves committing legal ethical obligations policies procedures mechanism explaining demonstrating ethical implementation internal external stakeholders remedying failure act properly derived used detailed consideration nuances meanings associated terms provided subsequent conceptual landscape sections conceptual landscape uses transparency context ensuring responsible development use algorithmic systems improve human rights benefit society transparency tool tools four properties directl relevant transparency use mechanism governance algorithmic systems governance framework algorithmic accountability transparency tool valuable goals serves useful cans opened tool right every job misusing tool costs even using appropriately often requires offs simply assume matter indifference uses tool transparency tool limits use costs trade others tools might sometimes better job transparency transparency transparency implied basic conception accountability know organisation hold accountable regulate demand transparency algorithmic systems goes beyond simple assumed sense ask transparent algorithmic systems becoming central lives economies yet use models algorithms workings complex human mind follow black box metaphor clearly evocative sense impenetrable mystery systems acting upon important consider making box transparent see gears within truly needed satisfy concerns systems depending aspect algorithmic system question usually calls transpar ency really aim seven broad areas machine learning systems transparency might demanded data transparency data used algorithmic system particular machine learning deep learning algorithm refer raw data data sources data preprocessed methods verified unbiased representative including looking features proxies information protected classes processes data updated system retrained algorithms transparency systems algorithms refer testing output inputs know proper output reducing variables significant validate testing system counterfactuals see prejudicial data infecting output third party code review analysis algorithms work inspection internal external bug reports assuranc software development processes sound goals algorithmic systems also transparent goals system multiple goals would mean transparent relative priorities example driving autonomou vehicles avs might aimed reducing traffic fatalities lowering avs environmental impact reducing serious injuries shortening transit times avoiding property damage providing comfortable ride manufacturer could required transparent goals priority outcomes manufacturers operators could required transparent outcomes deployment algorithmic systems including internal states system worn bra kes much electricity used effects external systems many accidents times caused another swerve computer interactions algorithmic systems communications avs data fed nto traffic monitoring systems stoa panel future science technology compliance manufacturers operators may required transparent overall compliance whatever transparency requirements imposed upon many instances may insist mpliance reports backed data inspectable regulators general public influence public interest knowing article newspaper fact paid interested party public may interest knowing element process purposefully bent favour particular outcome example trusted search platform artificially boosting results paid flagging fact users users manipulated regulators might want insist influence conspicuously acknowledged usage users may want know personal data system using either personalise outcomes data train system refine update knowing personal data used may want control usage perhaps make personalised results accurate urgently feel usage violates privacy even though data question may already desired part system purchase search history grey areas well collecting anonymised highly detailed information trips made autonomous vehicles often car brakes swerves example could important optimizing traffic safety fuel efficiency regulators may face difficult decisions well drawing relatively obvious lines note transparency different meanings categorisation mean access upon request public authorised people public posting information direct inspection internal processes results manufacturer operator tests system accuracy fairness delivery complete subsystems data testing authorised people results reported public regulatory bodies access computer scientists managers explain algorithmic operational processes transparency therefore single property app lied blindly every element every algorithmic system applied differently different systems depending upon nature algorithmic system complex circumstances lead need governance goals gove rnance transparency often always costs risks matters gets see illuminated considering regulating transparency potential viewers include everyone fully open access data algorithms utcomes etc regulatory staff third forensic analysts whose reports made public made selectively public kept private researchers possibly limited affiliated accredited organisations funding bodies transparency want systems transparent satisfy idle curiosity help achieve important social goals related accountability want inspect algorithmic system data algorithms governance framework algorithmic accountability transparency check bias data algorithms affect fairness system mechanics costs secondary effects different checking data algorithms check system drawing inferences relevant representative data see learn anything machine way connecting weighting data perhaps meaningful correlation aware look fix bugs guard data injection want hierarchy goals outcomes transparent debated possibly regulated regulators public assess well algorithmic system performed relative goals compared pre systems may replacing supplementing want organisation comp liance status public regulators hold organisation accountable case failure public evaluate trustworthiness organisation people make informed decisions users services offered citizens become better informed benefits risks offs algorithmic services overall fit purpose transparency good struggle online personal privacy makes evident transparency algorithmic systems even clearly prima facie good practice need special justification require justification denial transparency algorithmic systems costs associated substantial potential costs include regulatory bodies staff sufficient oversee compliance businesses organisations create maintain processes code legal oversight required regulatory bodies transparency might justifiable trade secrets risk public access data flame driven controversies via untutored unscrupulous misuse data requirement transparency lead use algorithms suboptimal purp oses resulting serious harms compared achievable goods access data seems innocuous lead breaches personal privacy clever determined hackers increased transparency algorithms make easier hack malicious purposes potential costs mitigated choosing transparency interventions necessary example rather providing direct public access data used train machine learning system independent data scientists could examine data private publish conclusions forensic research transparency absolute stoa panel future science technology good thus needs negotiated depending purpose balance benefits costs considerations include examination tools remedies achieve desired goals example system producing results replicate even amplify existing biases allowing owners system adjust rights might acceptable solution could done basis transparency system results without requiring transparency data algorithms used individual believes discriminated ainst black algorithmic system evidence systematic bias system might tested see discriminatory factors determinative particular outcome testing might require transparency example input ting counterfactual data say loan application factor changed time identify impact possibly prejudicial data without requiring full transparency costs benefits requiring transparency therefore sho uld weighed based benefits costs direct indirect using availability alternatives conclusion transparency tool tool whether best used depends upon goals requiring transparency elements process made transparent type transparency beneficial least costly alternative ways achieving goal judgement potential risk benefit system could bring compared system replacing augmenting transparency tool used responsibly means accepting applying means sensitive complex contexts used balance benefits harms use inevitably entails conceptual landscape accountability accountability like transparency ultimately tool accountability serves ensure responsible development use algorithmic systems improve human rights nefit society important difference transparency accountability accountability primarily legal ethical obligation individual organisation account activities accept responsibility sclose results transparent manner transparency logs data provenance code changes record keeping important technical tools ultimately accountability depends establishing clear chains responsibility accountability ultimately lies legal person context algorithmic systems challenges arise complex interactions sub data sources might control entity systems relying acquired data brokers rely data sources use algorithmic inference aggregate similar data subjects governance framework algorithmic accountability transparency unexpected outcomes associated impossibility testing possible input conditions methods generating formal proofs system performance difficulties translating algorithmically derived concepts clustering algorithm results segment populations based large numbers input variables human understandable oncepts ethnic affiliation resulting incorrect interpretations meaning algorithmic results information asymmetries arising algorithmic inferences black box processes make impossible data subjects gage ich potentially false information might resulted particular algorithmic outcome affecting including lack knowledge algorithmic processes even involved ubiquity small algorithmic decisions systematically biase may accumulate significant impacts people even though single decision would achieved legal threshold impact personal development due reinforcement stereotypes algorithmic recommendations purposef injections adversarial data fool system making errors often ways difficult detect addition basic function accountability act deterrent reckless irresponsible illegal behavi part humans algorithmic systems accountability algorithmic systems potential generate self feedback loop citizens society exposing existing biases power dynamics andrew tutt summarised challenge follows even algorithms programmed specific attention well legal norms could extremely difficult know whether algorithm behaved according legal standard given circums tance highlighted following example engage discrimination offer good example suppose company used machine algorithm screen promising job candidates algorithm could end discri minating basis race gender sexual tracing discrimination problem algorithm could nearly impossible sure discrimination could result bug design training algorithm typo programmer could also problem training data product latent society discrimination accidentally channelled algorithm even discrimination instead low event happened observed regards pinpointing human responsibility illegal unethical decisions algorithmic system identified algorithmic system pose challenges since sliced numbe ways many products company sell algorithm code even give away algorithm could copied modified customised reused put use variety applications initial author never uld imagined figuring much responsibility original developer bears particular harm arises road difficult question consider second company sells training data use developing one learning algorithms sell algorithms depending algorithm customer trains use purchaser wishes put data data efficacy could highly variable responsibility data seller could well imagine third company sells algorithmic services package algorithm offers relies partially extensively human interaction determining final decisions outputs stock trading algorithm man must confirm proposed trades divvying responsibility algorithm human likely prove complicated stoa panel future science technology systems become prevalent integrated increasing use input systems perhaps highly dynamic ways example autonomous vehicles networked decisions may result embedded scores hundreds vehicles also relies upon independent systems providing predictions micro traffic congestion pedestrian flow based local events etc tracing errors assessing responsibility may surpassingly complex especially since errors may arise individual sources state transient net works passing vehicles algorithmic fairness guiding purpose transparency accountability fairness immensely complex concept different sometimes competing definitions contrast transparency accountability suggest fairness considered tool facilitate best practice algorithmic systems rather see fundamental component underpinning responsible systems suggest algorithmic processes seek minimise potential unfair maximise potential fair transparency accountability provide two important ways achieved section emphasise importance assessing questioning fairness algorithmic systems used decision discuss fairness lens social justice highlight potential algorithmic systems systematically disadvantage even discriminate different social groups demographics draw series real life case studies illustrate lack fairness arise explore consequences lack fairness plus complexities inherent trying achieve fairness given societal context describe ways lack fairness outcomes algorithmic systems might caused developmental making design features embedded different points lifecycle model connect problem fairness tools transpar ency accountability also highlight value responsible research innovation rri approaches pursuing fairness algorithmic systems understand algorithmic fairness fairness everyday concept ble understand intuitive level least usually feel confident recognizing unfair situations mean share coherent idea fairness fairness turns multi inherently complex concept given difficult articulate single definition may also subject competing definitions fairness reflects appreciation situation based set social values promoting equality society assessment fairness depends facts events goals therefore understood situation task necessarily addressed within scope practice therefore purposes report fairness appreciates social effect algorithms sociotechnical structures considering case specific actions consequences fit broad social values given importance understanding fairness within context present series relevant case studies recent controversies regarding fair operation algorithms contemporary society use cases highlight core general issues require careful attention discussions fairness algorithmic systems concept fairness context algorithmic implementations appears balance mutual interests needs values different stakeholders affected algorithmic decision however varying levels importance depending final app lication purpose friedler claim important stated purpose given deployment algorithmic decision articulated purpose serves benchmark governance framework algorithmic accountability transparency algorithmic performance legitimizing force since relationship means ends becomes verifiable section interested impact algorithmic systems citizens individuals collectively societal level therefore also understand fairness within lens social justice opposed individual cases perceived imbalance goods penalties get cookies uneven applications rule let throw ball turn case discrimination based irrelevant factors subject rights claims pick team even though faster person pick etc social justice another complex term many potential definitions oadly speaking course century come understood referring framework provides means achieve fair distribution societal goods intangible discussions social justice academic policy public discourses typically recognise ensuring fair distribution complicated inherent inequalities contemporary society various differences perspective extent fair distribution accommod ate attempt address inequalities also pointed values goods distributed part complex social systems practice values context report worth noti new technologies regardless application generally dominated elites wealthier social classes large corporations case algorithmic systems making design knowledge systems access ability influence concentrated hands hindrance ensuring socially similarly popular disdain technocratic domination real perceived also form serious imp ediment following number examples algorithmic making applications urgently driving pursuit governance structure algorithmic systems ask useful tool transparency could addressing sues type transparency applied parts system facial recognition systems facial recognition technologies identify verify human faces digital video image typically work via algorithms identify facial features source image compare across dataset facial recognition technologies numerous applications particularly used security purposes including policing national security activities including counter terrorism recent years advances artificial intelligence machine learning increased capacity sophistication technologies making standard part consumer goods apple iphone lets users sign faces increasing competency scalability function given rise various controversies concerns recent years several companies microsoft ibm criticised rolling facial recognition sof tware accurate demographics others specifically systems tend accurately identify skinned men far often identify skinned women similarly controversy arose google automatic photo software identified many pictures african americans gorilla discussed later section cause errors likely lie development algorithmic models models presumably trained datasets photos predominantly white people thus trained sufficient data identify white people particularly women inaccuracies labelled producing inequalities variety activists one profile campaigner joy buolamwini computer scientist mit founder algorithmic justice league work prompted multiple companies release statements addressing criticisms reform models stoa panel future science technology publicity abo shortcomings services motivate service providers whatever necessary fix problem public services informal outcome transparency likely enough users activists vet systems services face public facial recognition systems used police forces identify criminals dissidents requiring forensic analysis outcomes might called inverse facial recognition represented videos essence model trained footage celebrity face dynamically superimpose face onto body another person often verisimilitude far beyond prior generation faked celebrity nudes deepf akes gained widespread infamy users social media platform distributed pornographic videos famous actors faces superimposed pornographic actors bodies forging videos celebrities way raises obvious gal concerns personal data protections sexual harassment defamation copyright also possible technology could used forge political speeches soundbites creating photorealistic videos politicians oing saying things never occurred example researchers university washington developed system manipulates video speaker demo barack obama speaker whatever audio provi ded deepfakes aim non deepfakes fake news general society feels fakes degrading trust public institutions society may demand transparency governments might require ads look like news articles labelled ads could version influence transparency necessarily require inspection knowledge processes fakes created although inspection might required order determine undue influence exercised search recent years number concerns expressed results searches made internet search platforms mirror wider societal stereotypes prejudices bes illustrated examples image searches june kabir alli posted video conducting google image searches showed searched images three white teenagers query returned results showing smiling wholesome looking individuals contrast searched three black teenagers query returned images mug shots see figure also mba student contrasted results received searches unprofessional versus profe ssional hairstyles see figure images suggested difference along racial lines governance framework algorithmic accountability transparency figure bias image search results three white teenagers three black teenagers professional hairstyles commentators also noticed image search results reflect gender stereotypes instance search nurses show women men search doctors men women results search ceo consisted women time ceos usa female search algorithms creating content simply ranking content already exists online kinds stereotyped prejudicial results reflection existing societal inequities expressed content posted often linked viewed tagged users however public reliance search engines source information raised concerns influence commentators argued search results apacity alter users perception reinforce societal prejudices turn leads questions whether platforms google therefore responsibility monitor results search algorithms correct necess ary section conceptual landscape referred outcome transparency algorithmic transparency may also called problem may algorithm plus clear search platforms tend give little information exactly criteria algorithms use least part would enable commercial interests game system making results ranking less useful reliable therefore algorithmic transparency odds public commercial interest producing reliable accurate search results addressed keeping algorithmic inspection limited trusted experts permitted disclose learn course also risks disclosure accident corruption another issue algorithmic transparency comes search engines however even algorithms understood humans unless relatively clear signs corru intent wilful tampering processing algorithms incredibly complex inspection algorithm going lets predict fake news going slip women going searches imag professionals rigorous testing outcomes likely flag problem service provider could required ameliorate outcomes without requiring algorithmic transparency regulators public case utcome transparency goals transparency influence transparency seem likely effective tools algorithmic transparency personalised online content personalisation algorithms online platforms designed sift data order supply users content apparently personally relevant appealing instance results google search may influenced past searches user made content order items user personal facebook wsfeed shaped facebook algorithms calculated interest user amazon recommends products based past purchases searches platform personalisation mechanisms therefore curate shape much brow sing experience seen helpful online users avoids sort vast amounts content available online instead directs towards might find useful interesting helps local businesses preferring search results services within user local vicinity also brings many advantages internet companies increase user numbers drive purchasing advertising revenues however concerns raised around gatekeeping role played personalisation algorithms issues include stoa panel future science technology creation online echo chambers social network facebook personalisation algorithms ensure likely see content sim ilar previously liked commented mean repeatedly see content reaffirms existing views exposed anything might challenge thinking recent political events ection donald trump presidency led much debate role echo chambers modern democratic societies results personalisation algorithms may inaccurate even discriminatory despite sophisticated calcul ations underpinning algorithms recommend advertise purchase present content might want see might fact reflect interests annoyance distraction seriously algorithms might ternatively curate content different users ways perceived discriminatory particular social groups instance researchers carnegie mellon university ran experimental online searches various simulated user profiles found significantly fewer female users males shown advertisements promising help getting high paid jobs simila rly researcher harvard experimented entering names google search platform observing kinds advertisements shown alongside results search results indicated searches names associated americans likely companied advertisements including word arrest suggesting name search may someone arrested past searches white sounding names personalisation algorithms function collate act information collected online user means large amounts information individual users might collected users often unaware amounts personal informatio collected become aware may feel uncomfortable instance feeling constitutes breach privacy impact perception seen emergence options opt personalisation advertisements platforms google growth platforms claim track concerns exacerbated opaque nature personalisation algorithms lack regulation protecting users cases providers offer weak form algo rithmic transparency telling users least personalisations based search purchase history location etc may provide control users considered algorithmic decisions example amazon lets users exclude purchases consideration google lets users exclude search history computations see figure forms usage transparency absence third verification explanations however concerns raised incomplete transparency regarding reasons personalisati outcome misleading governance framework algorithmic accountability transparency figure portion google search settings page united states version concerns use targ eted advertising connection personalised content discussed next context cambridge analytica case cambridge analytica personalisation privacy targeted advertising cambridge analytica scandal high profile case highlights particular concerns around impact personalisation algorithms particular relate privacy targeted advertising facebook launched platform called open graph third apps llowed external developers create tools could engage facebook users elicit consent access certain types personal data social network data might include user name gender location birthday relationshi status political religious views educational history instances private messages tools could also built allow access personal data facebook friends original user aleksandr kogan mpany global science research created app called thisisyourdigitallife app drew open graph platform invited users answer series questions return receiving psychological profile users required give permis sion personal data friends personal data collected order install app around users installed enabled kogan harvest data million facebook profiles facebook announced changes imited dev elopers access user data changes meant longer possible user give permission third party access friends data former manager facebook reported bloomberg discontinued pote ntially hundreds thousands developers making use third party access feature kogan global science research breach facebook policies sold personal data harvested cambridge analytica british political consulting firm firm used methods based psychometric profiling data individuals collected variety stoa panel future science technology sources personality profiles created profiled individuals could targeted personalised advertisements would highly tailored terms content tone etc match preferences profiled individual cambridge analytica worked support number high profile campaigns including donald trump presidential camp aign campaign european union referendum march whistleblower exposed cambridge analytica use harvested facebook data subsequent media coverage public debate focused number issues including two highly relevant report ethics acquisition personal data time use third party app collect personal data user friends allowed facebook policies due lack age transparency regarding data transfers users could prevent occurring changing account privacy settings would unlikely aware need similarly would unlikely realise installing app would enable large amount data collected described users often unaware extent online platforms organisations collecting information purposes targeted advertising become aware often feel constitutes breach privacy awareness also impact business users losing trust organisations instance reputation facebook damaged revelat ion apparent willingness allow others access user data something network working address case facebook cambridge analytically arguably would better transparent might los participants would centre scandal ultimately led disbanding company impact ethics targeted advertising much debate extent cambridge analytica use targeted advertising helped secure victory donald trump presidential campaign whilst profiling techniques use long time combinat ion algorithmically personalised advertising viewed particularly troublesome first allows far greater reach across population methods might excessively manipulative individuals unaware much message advertisement tailored perceived preferences second success testing evidence people susceptible non persuasion placing model left product might result clicks model right may able discover even effective rational triggers particularly troublesome political campaigns third high cost form advertising advantage wealthi campaigns result concerns raised targeted advertising damage integrity democratic institutions cambridge analytica become symbol potential political actors make use technologies psycholog ically predatory ways fourth use called ads targeted specific small groups people raises concerns act secret messaging opposition unaware therefore unable respond especially concerning case negative messaging exaggerated even false depictions opposing party unchallenged communicated secret cambridge analytica case prominent example debate ethics targeted advertising online business business context lack transparency advertising algorithms led concerns companies automated bidding allocation process personalised advertisements resulted products associated objectionable content instance newspaper investigation revealed advertisements well brands placed alongside videos showing extremist content hate speech youtube platform risked companies associated governance framework algorithmic accountability transparency content also portion advertising revenue passed video creators following revelations several companies withdraw advertisements google network response google apologised pledged offer eater control advertisers reasons regulators may consider requiring usage transparency along degree control users data used lways entail trade possibly overall efficiency system overall using search histories may make search algorithms less precise using automobile data might reduce effectiveness safety algorithms well system performance individuals algorithm based decision criminal justice system early criminal justice system began using risk assessmen assist decision making assessments based algorithmic calculations predict instance likely individual fail attend court sentencing drawn courts help determine whether individual granted bail long sentence low risk offenders given shorter sentences perhaps even kept jail entirely risk assessments used across wide number states stages legal process advocates suggest provide objectiv measure offender risk overcomes potential human bias help reduce prison overcrowding risk assessment scores usually made available defendant legal team criteria scores generated typically regarded proprietary companies develop released investigativ journalism site propublica published report suggested risk assessment algorithms might inaccurate raci ally biased journalists obtained risk scores people arrested broward county florida assessments generated profit company called northpointe using algorithm known compas risk scores sed score derived questions either answered defendants pulled criminal records questions related factors personal offender history family offender history drug taking amongst friends personal views fending race one questions propublica checked see many charged new offences two year period since arrest found predicted commit violent crime gone deemed likely offend went arrested misdemeanours driving expired license included black people almost twice likely falsely labelled risk future offending white people white people mislabelled low risk often black people even statistical tests run isolate effect race criminal history recidivism age gender black people still likely labelled risk committing future violent crime white people likely labelled risk committing kind crime northpointe countered propubli analysis criticisms stating algorithm racially neutral rate accuracy white black people since much debate occurred definitions fairness applied assess lgorithms kind example observers pointed propublica claims algorithm unfair unequally wrong wrong blacks white making false positives whereas northpointe claim fair equally right stoa panel future science technology predicting recidivism deas fairness correspond roughly equal oppor tunity algorithmic fairness accuracy fairness defendant given long prison sentence challenged sentence grounds legal team able assess compas algorithm however loomis wisconsin case state supreme court rejected challenge reasoned knowledge algorithm output sufficient level transparency necessary defendants know criteria scores calculated algorithmic risk assessment scores continue used assist decision courts police constabulary began trial appr oach using machine learning tool called hart harm assessment risk tool written evidence submitted government inquiry algori thms used decision head criminal justice durham constabulary reported early make conclusions accuracy hart research conducted order support evidence based good practice results research would made available discussed later section case raises number crucial points discussion regarding apparent lack transparency compas algorithm lack opportunity challenge decisions made using commentary understanding unfairness algorithmic systems case studies provide useful means understand social effects algorithmic systems decision particular demonstrate need clear mechanisms accountability due potential bring consequences detrimental number levels detrimental individual individual citizens might become recipients inaccurate decisions facial recognition software treated harshly comparison others relates decisi ons instance prison sentences serious consequences individuals might also receive information result online searches alter perceptions behaviours perhaps including voting behaviours collection collation information necessitated algorithmic processes might also considered breach privacy detrimental groups algorithmic processes appear produce different results different demographic groups often places groups disadvantage instance case studies suggest blacks might vulnerable whites longer prison sentences lack access facial recognition technologies stereotyping online advertisements representations online searches detrimental consequences groups outcom processes reinforce wider societal prejudices detrimental society entire societies disadvantaged outcomes algorithmic processes relied accurate neutral incorrect decisions societal effects instance wrongful arrest individuals based facial recognition technologies places society risk actual offenders overlooked stereotyped online content risks reinforcing prejudices furthermore outcomes may lead los trust amongst population well concerns companies utilising systems allowed much power returning understanding fairness outlined observe detrimental consequences might considered unfai case studies illustrate algorithmic processes sometimes social effects promote equality align fundamental social values also sometimes appear hinder rather uphold equal distribution governance framework algorithmic accountability transparency societal resources might also considered socially unjust particular highlight following social values potentially undermined operation algorithmic systems decision equality tcome algorithmic systems outcomes biased may block equality opportunity outcome systematically disadvantage certain social groups equity argued bias algorithms discriminatory disadvantages demographic groups protected characteristics freedom choice justice citizens feel algorithms biased even discriminatory compromise feeling live society truth algorithmic processes distort reality present false information fact undermines citizens ability determine true act accordingly autonomy citizens ability act make decisions may undermined vari ous features algorithmic processes may lack freedom choose decisions made human automated process even know decisions affecting made therefore lack transparency accountabil ity algorithmic systems particularly harmful societal value autonomy consent even instances individuals required give consent subject algorithmic processes may information put way means unlikely fully aware agreement entails cambridge analytica case particular example since online users arguably unlikely expect agreement use online app confers consent access private messages details friends accounts neral much concern terms conditions online platforms etc overlong full technical terms even users read full may hard understand meaning genuine informed consent unlikely furthermore also concern regarding mutability dynamism algorithms system one consent service even regularly updated reflect consenting data processing algorithms constantly tweak privacy privacy fundamentally linked consent key concern expansion scope effects personal privacy fundamental human right controversial include integration facial recognition technologies public spaces degree advertisements online personalised individual users trust risk algorithmic processes may detrimental uneven outcomes undermines citizens feelings security trust processes institutions utilise particularly heightened instances algorithmic processes viewed socially unjust featu res threaten values absence transparency accountability citizens see decisions made opportunities address incorrect decisions less likely trust feel secure processes values closely entwined understandings fairness social justice therefore one values undermined possible protests arise stating algorithmic process connect way unfair stoa panel future science technology sources unfairness unfairness algorithmic systems might result number sources highlight four key potential sources biased values design biased training data biased data inappropriate implement ation algorithmic system first type bias could described biased values design algorithm might considered biased designed favour one feature another many cases might done deliberately trivial consequences example one point google thought reduced weight gave blog posts presumably favour vetted sources however problems arise algorithmic systems applied social contexts decisions made regarding features algorithm told associate outcomes extreme cases developers intentionally construct model discriminate certain groups favour others although cases presumably rare common scenario human value judgements assumptions play unintentional role consider design software filter job applications heart software questions qualified candidate profile look like would want hire principles developer decides use measure qualities could introduce bias however unintentionally instance decision software favour candidates also ivy league oxbridge graduates would disproportionately advantage white individuals higher socio groups similar implicit assumptions types individuals seek certain professional roles vote certain political candidates cou also lead kinds controversies discussed case studies instance socio assumptions made developers embedded algorithm kind values bias even particular contentious features voided bias design might still occur compas case known race specific feature included algorithm likely features included acted proxies race family history incarcerati edu cational history etc could cause different results black white populations absence transparency make difficult identify assess role bias algorithm design known features included system possible trace might result disadvantageous treatment individuals groups comparison others extension also makes problem bias algorithm design harder solve goal transparency also required make judgments second type bias also occur development algorithmic system form stems data used train model models learn classify unseen cases based training dataset means potential model learn biased data reproduce biases example job application machine learning system trained current data many fields would learn low correlation woman job senior management might well replicate amplify problem version bias lies heart controversies facial recognition technologies technologies less accurate white users training dataset include enough white faces learn turn oversight caused human bias developers lacking awareness need diversity third problem source also relates biased data algorithmic system developed functioning outcomes might problematic data working problematic problem source concerns outcomes searches google search platforms described multiple reported concerns ways online searchers appear reflect arguably reinforce traditional gender racial stereotypes instance search images nprofessional hair might show many images black women natural afro hair searches female football fans show sexualised images searches three black teenagers return images prison mugshots governance framework algorithmic accountability transparency contrast wholesome images shown searches three white teenagers socially biased results necessarily caused algorithm design instead algorithms driving search platforms work existing online content desi gned prioritise features popularity frequency sharing metatagging existing images means stereotyped assumptions gender race etc evident elsewhere across web picked reflected functioning search engine algorithms due biased data algorithmic systems reproduce potentially amplify existing societal biases final area relates application implementation model case unfairness results design model way applied deepfakes provide excellent example application bias sense deepfake pornography could considered another example online misogyny neither data used create deepfakes videos celebrities algorithm design common libraries like tensorflow based machine learning problematic issue arises case rogue apply technology another instance compas case could argued inappropriate application system algorithm used broader ways originally designed similarly sentencing might used definitively determine sentences recommend sentences check judge independent decision bias gravity unfairness embedded use goals see sources unfairness identified play crucial part reinforcing perpetuating exis ting discrimination society affecting access available resources opportunities addressing kinds allocative representational harms main topic initiatives algorithmic impact assessment proposal discuss detail section opportunities barriers towards achieving fairness algorithmic systems controversies unfair socially unjust algorithmic systems focus much debate academic policy public discourses attention also given potential solutions various means achieve fairness social justice algorithms suggested summarised offer valuable opportunities beneficial change certain rriers exist achieved understand fairness stated start section fairness nuanced inconsistent concept open different interpretations make overall conclusions agreements accomplishing fairness difficult reach social research indicates presented set algorithms asked select preferred one applied particular context participants routinely select one feel fai context however selection differences occur participants draw different understandings constitutes fairness instance relation algorithm design kleinberg observe impossible fully accommodate different concepts fairness simultaneously competing rather compatible work focused probabilistic risk assignments formalised three fundamental conditions might need satisfied ssignment considered fair found possible satisfy three constraints time except highly constrained conditions unlikely map onto real world scenarios conclude way forward consider trade made notions fairness one domains kleinberg considered use algorithmic decision making criminal justice system note controversy surrounding use ompas court system compas provides highly useful case study consider complexities around constitutes fairness public discussions around apparent bias algorithm stoa panel future science technology propublica northpointe able cite idence support alternate positions propublica argued compas algorithm unfair potentially discriminatory carried higher risk false positives blacks however northpointe stated algorithm fair cause correct predictions recidivism equally accurate whites blacks argument draws different conceptualisations fairness unequally wrong equally right work recidivism prediction instruments rpis alexandra chouldechova also draws compas case makes distinction social ethical conceptualisation fairness statistical concepts underpinning operation algorithm notes higher false positive low false negative rates black defendants compared white defendants drawn critics compas evidence algorithm racially biased outcomes however finds difference result applying rpi satisfies predictive parity population recidivism rates differ recorded rates reoffending differed blacks whites essence recidivism rates uneven across groups possible algorithm multaneously equally right equally wrong black white defendants result disparate impact indirect discrimination occurs rpi disproportionate negative consequences one demographic group pact unintentional may occur regardless whether rpi designed fulfil specific fairness criteria concept disparate discrimination links gdpr discussed sections similarly ifferent interpretations applied issue search engine results search algorithms identify existing online content typically prioritise give higher ranking content viewed widely users ranking content higher open greater visibility users likely click links top search results search engines multiplier effect make already highly visible content even vis ible could seen entirely fair process content treated equally start process sorted criteria alternatively could argued process unfair outcome confers additional advantage content viewed often case interpretations fair differ along lines equity opportunity equity outcome debates become particularly crucial discussions deal online search results appear reinforce stereotyped prejudicial views case goal transparency least help users evaluate search results presented mittelstadt state algorithms inescapably value ope rational parameters specified developers configured users desired outcomes mind privilege values interests others human values often unconsciously embedded algorithms process design decisions categories data include exclude already stated values highly subjective appear neutral rational one person seem unfair discriminatory another subjec tivities invoke different understandings fairness given algorithms values embedded transparency values help users interpret results guard biases choose systems rely engage useful deba fairness outcomes practical perspective therefore important understand different concepts elements fairness conflict promoting equity practice directly opposed promoting equality many cases outcomes viewed socially desirable different actors sense defining governing sense fairness heart many political disputes required operationalise fairness programming computer given complexities subjectivities involved hard reach consensus obviously unfair harmful discriminatory cases first step toward addressing issue however needs transparency regarding fact choice choice fairness measure taking place governance framework algorithmic accountability transparency responsible ensuring fairness questions arise responsibility lies resolve different forms unfairness example google culpable algorithm translates word doctor masculine form feminine form language grammatical gender even though results underlying dat google algorithm microsoft responsible chatbot learns sexist racist discourse internet microsoft case apologised ultimately blamed trolls attacked technology abdication responsibility despite knowing attacks possible even highly likely expect governments legislate matters expect industries pursue best practices could scope standards industry proactive establishing best practices rather apologisin case ultimately deflecting accountability could users assumed enough awareness processes potential outcomes exercise judgement critical thinking sense responsible behaviour multiple sources unfairness multiple solutions unfairness algorithmic systems potential arise number sources multiple potential solutions address multiplicity sources solutions creates challenge ethicists regulators one size fits remedy instead type unfairness invites different regulatory responses industry academia policymakers solutions proposed address biased design values development algorithms often centre calls greater transparency development process diversity amongst developers controversies around biased training data active response typically focusing efforts ensur inclusive datasets academic researchers begun take challenge actively create training datasets inclusive different demographic groups especially automated language image tasks source unfairness potentially lies data algorithms work several commentators suggested possibility adjusting algorithms accommodate known bias instance search algorithms could tweaked avoid ranking onli content way reflects gender racial stereotypes etc sentencing algorithms could adjusted ensure different subpopulations treated evenly even baseline characteristics skewed finally addressing unfairness resulting application algorithmic systems often discussed terms post facto laws use anti laws seek redress cases systematic unfairness individuals groups protected characteristics expansion general data protection regulation provides right explanati data processed legislation could address algorithms general internet bill rights adapting rights context scale algorithmic decision accommodate legitimate disagreements various forms fairness bring bear particular case another approach preclude previous addressing specific algorithmic practices legislation european union algorith high frequency trading regulating opacity algorithms mostly established confidentiality agreements establishing blic agencies oversight even pushing sectorial self seen advertising industry good example new york bill algorithmic accountability current terms proposal seek establish agency responsibl fairness accountability transparency algorithms used public authorities citizens may solicit action agency order seek explanation eventually contest algorithmically driven decisions authorities ency would also responsible policing discriminatory practices within algorithmic decision systems providing information stoa panel future science technology algorithm functions impacts city return proposal section discusses proposa algorithmic impact assessment detail different suggested solutions inevitably raise debate necessarily simple achieve technical practical procedural terms datasets could theoretically audited self regulated combat bias resulting training data bias resulting design values generally subjective difficult regulate many cases transparency neither necessary sufficient ascertain whether values intent behind algorithmic system biased given legal social complexities associated establishing intent always possible draw straight line design values outcomes compas case clearly illustrates similarly likely disagreement among different parties values stake one person pragmatic efficiency might another person technocratic racism many biased discriminatory outcomes algorithmic decision technologies began good neutral intentions one person fairness minimises false positives may another person unfairness minimise false negatives fairness complex industry standards risk fairness escape regulation consequence various controversies arising application algorithmic systems decision calls industry take initiative develop standards codes conduct ensure fair ethical socially beneficial practice major technology companies recognise importance dedicated teams looking challenges facebook fair example effort directed exclusively understanding developing artificial intelligence similarly june google published set principles use first steps towards establishing socially goals development technology well benchmarks expected behaviour however recent article ben wagner warns limitations steps describing ethics technology industry escape regulation states companies strongly adhering narrative value ethics means avoid gulation display minimal self keep threshold political legislative intervention claiming adhesion ethics way companies wave flag positive neutral social impacts without entailing formal institutions could restrict liberties given limitations positive step lies development standards guidelines industry associations example ieee global initiative ethical consideration artificial intelligence autonomous systems published report committees identified major debates around artificial intelligence autonomous systems report presents issues candidate solutions deba ranging general principle design codes conduct standards provide level rules orient development deployment algorithms benefits quickness specialisation rules rely solely industrial technical consensus provide society formalised institutions regulation activity important first step implementation institutionalisation social values fairness one caveat though provision concrete guidance fairness algorithmic systems course also made difficult complexities around various types fairness responsible approach design algorithms may solution help facilitate develop ment fair algorithms ensure responsible research innovation process particular inclusive process field responsible research innovation rri emerged concerns surrounding societal ethical consequences novel technologies notions responsibility fairness core aspects field could seen potential solutions relation design use algorithms central rri enable inclusive reflexive acco untable research governance framework algorithmic accountability transparency innovation process part achieved development processes mechanisms ensure involvement relevant stakeholders throughout entirety research innovation life cycle relation development algorithms would likely involve contextualised consideration algorithm determine relevant stakeholders following determination mechanisms stakeholder workshops focus groups could integrated research innovation cycle stakeholders could share views developers meaningful way importantly developing algorithm would take perspectives concerns account find ways bed ongoing development responsible procedure would help ensure resulting algorithm would fair possible given real consideration integration multiple stakeholder viewpoints concerns design development algorithms lens rri would first glance seem help mitigate key issues surrounding algorithms particular problems like raised earlier case studies would emerge thus could addressed ongoing development algorithm potentially problematic consequences related training data sets engendering potential bias discrimination would likely picked stakeholders wever important point undertaking responsible process would also challenges firstly would likely exist tension transparency accessibility algorithms issues related transparency would inva riably emerge given proprietary nature algorithms stakeholders feasibly involved development life cycle without concerns surrounding institutional privacy secondly even unlikely circumstances institutions make algorithms transparent could understood multiple stakeholders varying technical literacy information presented allow stakeholders meaningful discussion procedural issues fas temporality development life cycles versus time would take assess include stakeholders viewpoints well costs including stakeholders process would also additional complexities overcome relation solu tion fair political legal discussion around fairness set isolation social systems important understand fairness defined within set existing legal social norms political deliberati therefore comprehension fairness simultaneous inquiry appropriate outcomes algorithmic decision also political debate seeks establishment rules conduct producing higher order rules detach fairness debate regard first caveat discussion fairness relation institutionalised norms mittelstadt mapped ethical challenges pertaining algorithmic decisionmaking concerns regarding autonomy discrimination bias opacity decisions many issues already addressed existing rules laws example prohibiting racial discrimination anti market practices fairness orients action towards outcomes respect existing social constraints constraint deemed unfair changed though political discussion fairness low institution override higher level instit utions indiscriminately second caveat fairness political effects algorithmic making fairness concerned exclusively algorithms transforming society example reinforcing discrimination tools shape social understanding views algorithms affect information circulates society indirectly affects social views perceptions potential shaping debate threaten individual liberties example determining users exposed political propaganda facebook therefore fairness stoa panel future science technology concerned exclusively material outcomes also algorithms organise society way values preserved balanced reg ard elements transparency accountability solely tools identifying contesting biased decisions also mechanisms enable people ensure absence threats unfairness society rawls describes justice encompasses overall acceptability existing institutions generate mutual benefit cooperation society algorithms understood tools automate enforce decisions made encoded developers decisions oncealed user accountability transparency enable users access take part process agreeing institutions enforced algorithms therefore mechanisms promote awareness recognition protection soc ial values essential part fairness since enable people participate trust ensure reliability algorithmic decision human machine bias also important consider algorithmic fairness isolation issues surrounding human fairness specifically human bias versus machine bias many algorithmic systems employed contemporary society initiated least part overcome shortcomings human making instance comp algorithm broadly welcomed introduced seen means address potential bias reasoning judges similarly departments increasingly use algorithmic tools process filter employment application advocates systems argue save time reduce human bias particular promised free discrimination based race colour religion gender gender identity expression sexual orientation national origin genetics disability age factors unrelated legitimate business interests already described inherent value nature algorithm development seen undermine claims neutrality furthermore evaluating whether machines improve decision making superior proven extremel difficult render visible given issues selective labelling data selection bias problem decision making usually foreshadows highly integrated use algorithm making difficult quantify measure impact machine decision relation compared human counterpart however important question remains evaluate algorithmic systems ideal perfect fairness enough less unfair humans confidentiality industrial practices trade secrets noted throughout lack transparency complicating factor able assess fairness algorithms also barrier ensuring fairness particularly refers confidentiality industrial practices trade secrets since confidentiality way preventing companies copying algorithms protection method directly related technology company competitive edge moreover exposure details algorithm society could sabotage service workings since would make easier users game algorithms advantage legal terms still satisfa ctory mechanism obliges companies disclose algorithms without harming competitive strategies ensuring public scrutiny little discussion around changing law sense pressing disclosure algorithms confident iality agreements though important literature demanding auditability transparency algorithms governance framework algorithmic accountability transparency technical challenges transparency order appreciate nature challenges confronting algorithmic transparency accountability necessary take consideration technical properties algorithmic decision systems give rise opacity often think algorithms sequence steps arriving outcome sense decision tree see figure figure simple decision tree patent socioeconomic group classific ation based user features suggests transparency simple explain algorithm clear outcome arr ived strictly true naive view way algorithms arrive outcomes systems expert systems built way using step approach may useful trying explain outcomes moder computing systems manner would productive even ignoring intellectual property challenges approach disclosing algorithms unlikely effective providing meaningful transparency key issues complexity intercon nection decisions processes learned data give examples techniques used algorithms well types algorithms show issues make explanations difficult stoa panel future science technology complexity modularity often used deal ith complexity algorithms different modules perform different parts task results combined arrive final outcome module may understandable complexity arises put together example credi scoring algorithm may include modules scoring customer ability pay total debt load history payment likely profitability customer etc consumer record prior payment likely goes modules affects final credit decision may less clear example record prior payment may help score based history payment since consumes income could used pay new loan may decrease score total debt load module modularity also source error different modules may actually fundamentally different meanings data example predictive policing predictors might relate probability specific individual might iminal coin head trail side giving chance heads others relate population probability certain number people within group criminals coins two heads coins two tails take specific coin chance specific outcome latter gets included model kind prediction former iterative algorithms repeatedly run sequence steps algorithm converges stab outcome single pass steps may provide insight process explain final decision convergence criteria may give insight overall goals may independent individual outcomes example advertising placement algorithm may target maximizing overall revenue placing package ads gives little insight particular shown particular individual randomised algorithms may run way every time often steps taken decided flip however typically shown converge result time given inputs randomness introduced change outcome overcome problems mputational complexity however fact algorithm may achieve result different way time makes step explanation challenging noted however software generated random numbers typically produce use pseudo number generators prng generate numbers look random actually part complex deterministic number generation process number generated case depends seed initiate com plex prng process common method changing seed successive number generations prng derive seed continuously changing input internal clock fixed value used prng seed behaviour result execution algorithm reproduced relationship among decisions certain types algorithms particularly optimisation often used solve batch problems simultaneously example would college admissions limited number slots available decision applicant admitted depends compare applicants makes explaining single decision difficult particularly challenging problem involves multiple optimisation criteria example admitting students based computed score also based likelihood particular majors machine learning machine learning applies different approach algorithm development basic approach build model based data model becomes algorithm used obtain final result see figure governance framework algorithmic accountability transparency figure machine learning modelling process machine learning algorithm gives little insight outcome tells data used build model transparency machine learning algorithm thus little use really needed explanation model model viewed algorithm typically quite complex often functions differently way human would make decision example take decision tree learning one early types machine learning one straightforward presumably could disclose model decision tree would provide transparency outcome unfortunately machine learned decision trees rarely straightforward figure figure example decision tree produced sing machine learning approach used based gini coefficient choosing splitting criteria minimum cost complexity pruning see details note keep coming back features different points uniform ity cell size bare nuclei logic behind decisions often unclear relatively simple learned decision tree stoa panel future science technology figure machine decision tree diagnosing breast cancer decision trees relatively simpl model one measure complexity machine learning model vapnick dimension dimension decision tree linear number nodes tree modern machine learning techniques deep learni much higher dimension even simple neural network binary output quadratic number parameters network convolutional network quadratic number nodes network result machine learning models often opaque even developers releasing model unlikely provide significant transparency addition complexity lack understandability model reasons simply releasing model learning algorithm data feasible solutions transparency data privacy could compromised data used train model typically similar used model cases data abo individuals training data may protected would preclude releasing data disclosing learning algorithm without data provides little transparency actual decisions also poses problems releasing model may possible reverse engineer model determine data used construc thus violating privacy methods prevent differential privacy using privacy protection methods isadvantages terms accuracy although imp act accuracy debatable complexity system development continuous learning also poses challenge many applications machine learning models frequently even continu ously updated capture incorporate new data changing trends continuous learning models increasingly becoming norm industry machine learning pipelines allowing deployment different models many times conceivably model used particular result could captured time model would likely require new explanation given difficulty explaining model likely requirement expert human involvement least current technology complicates issues governance framework algorithmic accountability transparency conclusions viewing transparency explaining steps algorithm unlikely lead informative outcome one hand could end description captures general process used make decision example description patent machine learning module uses machine learning techniques train one models input information trained models socioeconomic group classifier determines probability given user belongs socioeconomic group provides little insight individual decision made extreme would provide complete set steps taken complete detailed algorithm machine learned model may enable reconstructing outcome provided input data complexity even experts may unable understand particular result obtained mean situation hopeless section technical solutions discuss alternative methods understand outcomes algorithms technical solutions reducing opacity technical reasons opacity algorithmic systems technical methods reducing algorithmic opacity extracting explanat ions system behaviour despite lack transparency first divide transparency explanation two categories understanding overall system understanding particular outcome may require quite different approaches category list several approaches briefly discuss provide key idea keep mind goal transparency understand system works behaves regulatory viewpoint primar issue likely outcome fair appropriate behaviour critical regulatory issues governing process likely straightforward gdpr example forbids processing certain types personal information except prescribed circumstances simply requires determining information used system cases use allowed onus could placed developer explain ensure use proper key challenge transparency system behaviour evaluate methods respect support explanation understanding overall system goal obtain general understanding process algorithmic system makes decisions challenge approaches described likely difficult impossible without direct involvement system developers design review code review design code reviews methods software engineering used enhance reliability system developed ensure satisfies requirements various techniques used mapping specific requirement code modules address requirement provide opport unity transparency research showing traditional code reviews often find issues code understandability rather specific defects suggest viability code reviews improving transparency unfortunately design cod reviews expensive consuming typically operate level involves proprietary information furthermore noted section system using machine learning provides little transparency review may show stoa panel future science technology process building machine learning model expected provides little insight model actually input data analysis input data analysis used determine data used make decisions appropria consistent legal requirements process analyse system either design code level determine information provided system making decision useful determining regulatory compliance system access race gender etc input may capable direct discrimination thus violation gdpr article provides little insight system behaviour useful step provided issues roprietary information resolved statistical analysis outcomes addressing concerns overall analysis outcomes useful example used identify indirect discrimination protected group disproportionately affected negative way challenge often requires obtaining data would otherwise used example machine learning model may make use race gender avoiding direct discrimination store information yway conflicts principle data minimisation places individual data risk requiring could potentially considered violation gdpr article alternative approach create test datasets either protected reg ulatory environment using synthetic data used evaluate overall statistical outcomes suggest issues example standard statistical evaluation techniques could used determine outcomes accuracy different specific subgroups individuals suggesting fairness problems particularly useful static models although may difficult continuous learning systems one caveat absolute standards constitutes acceptable statistical outcomes may problematic many definitions fairness proposed shown impossible simultaneously satisfy multiple definitions hard requirement fairness may unintended impac statistical analysis approach suggested useful determining scale issues system needing exploration rather specific means providing transparency making process criteria sensitivity analysis also opportunity test systems providing carefully crafted inputs better understand systems react example providing multiple test cases one attribute changed provide insight attribute used algorithmic decision process particular important machine learning approaches even developers may little insight particular decisions made useful techniqu means complete many algorithms including modern machine learning approaches take account order interactions attributes evaluating possible multi interactions prohibitive result testing may fail reveal particularly interesting cases potential direction arises development adversa rial manipulation techniques identify minimal changes result different outcome thus identifying particularly sensitive combinations inputs second issue care must taken distinguish causation correlation growing research literature making distinction still open questions results need used carefully governance framework algorithmic accountability transparency algorithmic accountability technical issues algorithmic accountability largely question system behaves according specifications accountability issues redress really beyond technical hallenges algorithm question actions implied specifications accountability actions taken algorithmic systems may need different human actions differences largely governed particular application result section look mechanisms ensuring algorithmic systems satisfy specifications traditional software design processes include design review code review testing procedures ensure gorithmic systems meet specifications beyond formal verification techniques making significant advances formal verification demonstrated significant software artefacts likely techniques wil become part standard oftware engineering practice second aspect accountability process standards certification jtc standa rds software engineering capability maturity model integration discuss processes procedures organisations follow systems design within area algorithmic transparency accountability ieee series standards currently development particularly ieee transp arency autonomous systems may provide good options transparency individual outcomes second type transparency understanding particular outcome understanding system works likely little value approaches providing explanation become important input data analysis understanding data used determine outcome useful establishing confidence fairness individual outcome furthermore ability evaluate correctness data identify incorrect outcomes gdpr article already requires data subjects access personal data processed provide explanation outcome important determine individual outcome based correct incorrect data combined explanation methods provides useful recourse individuals concerned outcomes numerous cases however access data produced outcome might available data often considered valuable asset organisations reluctant share gdpr instance compel access non data statistical data large population groups might played important role decision furthermore unless efforts put place ensure data retained instance data audit purposes might get overwritten new inputs typical example deliberate efforts ade retain data would otherwise disappear flight data recorders mandatory inclusion vehicle data recorders autonomous vehicles instance suggested order help future accident investigators get access input data preceded self car crashes static explanation systems designed provide explanation basis individual outcomes either specific design criteria incorporated entire system accomplished thro ugh techniques sensitivity analysis systems already exist practice even without regulatory requirements example corporation fico score commonly used financial credit decisions united states provides rep orts individuals explaining individual credit score provide top stoa panel future science technology factors affected fico score bureau detailed analysis factors remediable individual woman often late making credit card payment design code review statistical analysis techniques design code review little direct relevance understanding individual outcome however disclos ing synopses reviews part process setting meaningful information logic involved helping satisfy gdpr article sensitivity analysis overall outcomes sensitivity analysis used determine led particular outcome perturbing inputs sometimes referred testing counterfactuals evaluating change outcomes insight gained particular outcome arrived ability start particular set inputs enables wide variety perturbations tried potentially even capturing multi factors previously discussed techniques sensitivity analysis study overall outcomes may provide appropriate starting poin analysis furthermore enabling sensitivity analysis individual outcomes provides greater transparency gives data subject opportunity determine actions might result different outcome information useful contesting outcome analyses provide useful information individuals well identify fairness issues require investigation many cases tractable approach example already offers consumers fico score simulator shows different financial decisions like getting new credit card paying debt may affect score example powerful model agnostic explanation approach machine learning classifiers uses input feature based sensitivity analysis lime local interpretable model explanations technique lime derives easily interpretable model linear regression cally faithful machine learning classifier vicinity around individual predictions seeking explain achieved fitting simplified model input pairs generated machine classifier inpu sample instances vicinity prediction reverse engineering putting together reverse engineering black relies varying inputs paying close attention outputs becomes ossible generate theory least story algorithm works including transforms input output kinds inputs using sometimes inputs partially observable controllable instance algorithm driven public data clear exactly aspect data serves inputs algorithm general observability inputs outputs limitation challenge use reverse engineeri practice many algorithms public facing used behind organisational barrier makes difficult prod cases partial observability outputs foia web something like crowdsourci still lead interesting results governance framework algorithmic accountability transparency conclusions meaningful transparency outcomes reached technically challenging given modern computing systems regulatory requirements transparency may significantly limit ability use advanced computing techniques regulated purposes meaningful transparency behaviour computing systems feasible provide important benefits mechanisms behavioural transparency may need designed systems typically require participation developers operators systems fairness accountability fastest growing research areas algorithmic decision systems especially machine learning academic funding bodies also industry increasing investment domai resulted production increasing number open source libraries tools help developers address fairness accountability transparency requirements collateral implications imposing fairness accountability transparency requirement provide brief overview collateral implications effects may occur fairness accountability transparency fat requirements imposed algorithmic decision systems detailed analysis collateral implications however beyond scope current report performance tradeoffs applied development algorithmic system fat requirements become additional performance criteria modify goals system optimization best optimization outcome defined including fat requirement might therefore score lower fulfilment non system requirements system optimized without tak ing fat requirements consideration inherent property occurs time system optimized satisfy multiple requirements fully independent resulting need make tradeoffs optimizing thickness motor vehicle chassis simultaneously maximum impact strength efficiency requirements inherently leads tradeoffs kinds problems referred literature multi object ive optimi sation trust trustworthiness trustworthiness algorithmic systems trust algorithmic performance vital elements successful growth applications algorithmic systems public private sectors trust trustworthiness likely enhanced application fat requirement trustworthiness algorithmic systems relates questions reliability predicable behavio normal use conditions robustness ability maintain predictability unexpected conditions resilience ability recover reliable behaviour disruption transparency explainability algorithmic systems benefits trustworthiness factors helping better understand systems behaves beyond discrete data points provided trials fairness accountability requirements indirectly support trustworthiness due increased rigor system behaviour inspection needed control fairness establish accountability trust behaviour algorithmic system refers human perception system worthy trust judgements trust based assessments regarding factors stoa panel future science technology reasonableness algorithmic outcomes facilitated algorithmic perceived ethical values service provider built system expressed fairness accountability requirement enhanced agency users basic prerequisites human agency capacity make choice oneself awareness going capacity meaningfully engage process compliance fat requirements generally decrease information asymmetry citizens service providers impact cost distribution implementing fat requirements system development likely require additional efforts system potentially fat related based certification name potential additional development costs time however increase rigor system development may result improved reliability robustness resilience might reduce maintenance costs high perspective governance frameworks algorithmic systems regarding fundamental approaches opposed implementations governance briefly review dichotomies principles rules based approaches context technology related governance principles rules based governance rule regulation prescribes detail behave dutch highways speed mit rules provide certainty follow rule know compliant based regulation formulates norms guidelines exact implementation left subject norm drive responsibl snowing principles provide flexibility enables regulatory regime durability rapidly changing environment enhance regulatory competitiveness stakeholders benefit improved conduct firms focus improving substantive compliance achieving outcomes less simply following procedures box working avoid rule substance whilst complying form creative compliance principles based regulation criticised failing provide certainty predictability allowing firms backslide get away minimum level conduct possible thus providing inadequate protection consumers others regulatory systems contain mixture rules principles rules may become principle addition qualifications exceptions whereas principles may become like addition best requirements legal theory cunningham uses three dimensions distinguish principles rules temporal dimension rules define boundaries ante adoption implementation whereas principle settled post compliance audited conceptual dimension rules specific clearly defined boundaries indicating scope principles contrast general universal abstract lead appear relatively vague governance framework algorithmic accountability transparency functional discretionary dimension rules defined regulator leaving little room discretionary interpretation principles tend give space interpretation subjects auditors addition general distinguishing dimensions apply rules based principles based regulatory systems highlights additional four characteristics apply level single rules principles declarative representation specifi situation required achieved left discretion implementer procedural descriptions specify actions objective achieved generally principles formulated declarative way ypical rules procedural knowledge needed apply regulation applying rules requires relatively little knowledge knowledge rule instantiation concepts involved suffices applying principles requires owledge knowledge context relevant principles exceptions handled form reasoning may defeasible sense exceptions may occur overrule original line reasoning strict sens exceptions allowed modelled defeasible logic resolve conflicts different exceptions need kind priority der weight words principles conflict resolution mechanism rules conflicts possible seven distinguishing characteristics summarised table table distinguishing characteristics rules principles dimensions domains algorithmic transparency accountability similar data privacy application conditions rapidly dynamically evolving governance frameworks largely principles gdpr likely resilient future developments rigid rules based governance order avoid problem regulatory backsliding organisations get away minimum level conduct possible regulatory agencies tasked monitoring hence interpreting principles based regulation need adeq uate support addition principles based much existing governance technology focused risks approach emphasising methods maximise benefits minimise risks arise technology allocating resources proportion risks society health safety environmental risks considering impacts likelihood happen order establish appropriate levels ntrol one common tool used support risk approaches impact stoa panel future science technology assessment environmental impact assessment example impact assessment tool currently developed algorithmic systems presented section governance algorithmic systems systems algorithmic components algorithmic systems used stand systems part larger integrated devices digital personal assistant services credit assessment machines autonomous vehicles two mutually exclusive ways consider governance frameworks algorithms regulate accountability transparency algorithmic system component considered isolation rest system embedded regulate accountability transparency complete system including algorithmic non component regarding need match accountability transparency requirement capabilities algorithmic system different requirements adaptive machine learning systems static decision rules domain used domain specific certification algorithm certified use product inventory tracking interacting customers regarding algorithmic system considered component part larger system introduction algorithmic component system must allowed break existing accountabil ity transparency requirement governance framework applies overall system example inclusion algorithmic system optimising parts procurement costs within production process must result failure able trace back origin parts used required order able issue product recall fault detected parts particular supplier principle already applied various industr sectors aviation overall system requirement guarantees system behaviour imposing verification validation certification challenges adaptive flight control system software current challenge plication existing regulatory frameworks systems significantly changed use new algorithmic components often lack clarity level impact system citizen product incorporates algorithmic behav iour example vacuum cleaners traditionally recognised pose certain health risks electrocution possible dispersion fine matter particles tested part certification vacuum cleaner must pass sold within eea upgrading vacuum cleaner product line inclusion autonomous navigation camera image processing communication algorithms making robot vacuum change potential negativ impact product additional tests need applied robotic system might include issues cybersecurity potential violations privacy associated communications features sensory capabilities device board algorithmic image processing extract non sensitive information information sent internet information potentially accessible device gets hacked regulatory challenges introduced algorithmic decision part products services exhibit similarities impact moving online digital service provision order maintain principle online offline equivalence legal moral rights obliga tions need update existing laws regulations international agreements assume governance framework algorithmic accountability transparency application digital environment observed similar updates may necessary order maintain level playing field services incorporate algorithmic decisions held equally accountable outcomes discriminate curtail freedom undermine consumers legal moral rights etc considering whether algorithms considered separately single regulatory category instead kind helper technology regulated component kinds technologies tutt argues separate unified regulatory category basis machine learning algorithms pose syste matic complex challenges transcend particular technology associated underlying machine learning algorithm could deployed drive car fly airplane case ibm watson could used yield expert guidance fields ranging medicine finance least would need strong coordination agencies regulating algorithms order ensure lessons learned developing regulatory solutions set algorithms readily available agencies developing solutions identical highly similar algorithms coordination would also necessary provide consistency clear context based reasoning support algorithm regulated two different ways depending application deployed governance framework options institutional perspective governance options located five stages continuum ranging market mechanisms one end via self single companies collective self industry branches state authorities industry command control regulation tate authorities table ummarises governance options application regarding risks associated algorithms mediate access information online search engines newsfeeds important additional dimension governance landscape explicitly highlighted table investigative journalism associated public opinion shaping activities whistleblowers civil activism influence reputation industry government thus indirectly impacting forms governance demand side market solutions demand side solutions refers market self changes consumer behaviour citizen sector institutional clients threatens sufficient loss stoa panel future science technology customers motivate changes provider conduct order demand side market solutions viable imperative alternative solutions competing services exist maintaining plurality solution providers however challenging markets due inherent dynamics performance personalisation algorithms machine learning systems improves number data points available system frequently linked number current users based current levels digital awareness past failures achieve significant demand side arket solutions data privacy iot cybersecurity seems highly unlikely citizen consumer behaviour provide driving force increased algorithmic transparency accountability important contributing factor lack consumer action match privacy demands information power asymmetries service providers consumers often means citizens unaware extent data collection algorithmic manipulation expo sed prevents individuals making kinds choice would normally expected lead market pressure better solutions efforts inform users journalism well social networking could pote ntially help social movements demand side pressure business customers public procurement better position help shape algorithmic products services large brands like unilever procter gamble instance put pressure facebook fix aberrant behaviour advertising placement algorithms resulted advertising brand products getting paired toxic content racism sexism terrorists hate messages part however corporate activism tends reactive responding public embarrassment threats brand reputation potential concerns legal liability business interests always align ose customers society broadly demand side market solutions driven public procurement contrast likely implement proactive approaches based ethical societal concerns codified prerequisite requirements ord bid government contracts take form regulation example impact assessments currently developed canadian government proposed see section detailed discussion new york task force examining automated decis ion systems used city include public procurement key regulatory implementation mechanism weakness governance based public procurement requirements setting measures vulnerable criticism removal basis fiscal responsibility requirements reducing cost public procurement expense ethical considerations supply side market solutions supply side solutions refers innovation aim capture market share providing solutions improvements shortcomings existing examples supply side solutions include services implement privacy default design address concerns abo data privacy services designed avoid filter bubbles bias integrating elements serendipity response mounting number news articles algorithmic bias discrimination ethical security dilemmas well increasing numbers governmental inquiries task forces reports topics supply side market solutions starting emerge primarily solutions taking form algorithm auditing support services fairness toolkit pymetrics facebook fairness flow orcaa algorithms auditing company set cathy neil acclaimed author weapons math destruction big data increases inequality threatens democracy governance framework algorithmic accountability transparency within academic research community also increase research related algorithmic transparency accountability evidenced creation dedicated conferences fat fairness accountability transparency aies artificial intelligence ethics society number ethics toolkits use case based educational material also developed order encourage development supply side solutions however vital maintain governmental journalistic pressure corporate investment development transparency accountability algorithmic systems still marginal compared overall invest ment sector much investment represents bet companies government regulations happen near future companies self refers measures taken indi vidual companies reduce risks measures company principles standards reflect public interest internal quality assessment relation certain risks ombudsman schemes deal complaints self organ isation often part company broader corporate social responsibility csr strategy serves increase reputation avoid reputation loss company self issues concern regarding algorithmic systems frequently follows similar pattern recent developments supply side market solutions action response pressures threats company reputation following revelations news algorithmic misconduct government inquiries perceived threats absence external pressure hardly incentives companies proactively engage efforts increasing transparency accountability algorithmic systems unless shown contribute improved system performance public disclosure information workings algorithmic systems especially sensitive disclosure increases danger manipulation imitation results dilemma moreo ver company reputation affects willingness engaging self measures great attention companies business markets amazon might promote self public interes little public attention companies markets data brokers acxiom corelogic datalogix reduces reputation sensitivity thus incentives voluntary self organisation recent dev elopment increase employee led activism aimed changing company projects perceived unethical examples include internal protest google involvement developing systems pentagon project maven work censored search engine chinese market project dragonfly included resignations threats resignations employees well whistleblowing media generate pressure anagement result actions google published code ethics govern work cancelled plans renew project maven contract pentagon valley employees speaking forming pressure groups use design smartphone apps online platforms resulting projects google apple offer versions phone operating systems less addictive employees amazon demanding company stop selling face recognition technology rekognition law enforcement cancel provision amazon cloud services aws big data firm palantir work intelligence agenc ies stoa panel future science technology law enforcement primary means putting pressure management speaking media perhaps due internal pressure increasing public awareness threat government regulation genuine recognition issues machine learning poses social fairness major companies including amazon facebook google ibm microsoft introduced announced open source tools detecting systems bias unfairness systems also promulgated principles development supports social values although principles high level difficult enforce branches self typical instruments self codes conduct organisational technical industry standards quality seals certification bodies ombudsmen boards ethic codes conduct established profe ssional organisations include software engineering remit acm ieee provide guidance high principles behaviour people developing algorithmic systems software development however codes nduct lack enforcement power since branch industry contrast medicine law regulated profession requires license practice many practitioners therefore member professional association corporate codes rofessional conduct may carry possibility sanctioning ultimately loss job violated degree codes enforced within organisations vary widely often transparent external monitoring abo however many ethical principles cited codes conduct abstract level using language value alignment propensity responsibility transparency bias mitigati provide little actionable help practitioners navigating daily ethical problems practice subject interpretation academia responding identified need software developers greater understanding ethical social implications work introducing new courses universe robots society blessing curse delft ethics governance artificial intelligence mit intelligence philosophy ethics impact stanford university technical standards play important role software industry ensure system interoperability web provide ality software testing security information cyber security control good documentation requirements user documentation maintenance review audits general governance areas currently still development include standards expressly address ethical considerations including bias transparency specific issues related artif icial intelligence machine learning discuss ongoing efforts detail section industry standards relating algorithmic systems software product certification provides number potential benefits developers helps establish certainty confidence software may stimulate sales especially dealing organisational buyers sensitive mains like medical certification also help veri certify legislative compliance moreover help outsourcing partners outsourcers well subcontractor convince party deliverables acceptable nevertheless software goes debugging testing deployment competitive time pressure cost considerations typically limit rigorous standards conformance certification testing critical systems governance framework algorithmic accountability transparency heavily regulated domains medical aviation applicatio financial services cybersecurity evaluation practices software certification reported case consumer software certified cybersecurity standard common criteria time pressure often results softwa vendors shipping product releases later versions one evaluated standard study reported inherently longer development times aviation industry meant concerns time required performing certification assessment case aviation software standard much less limiting factor number software product certification models developed order facilitate faster cost effective certification software conformant specifications especially context base software service saas comes ethical societal impacts algorithmic semi autonomous decisi systems however yet established certification models procedures services partially due lack existing standards issues certify signs however change cathy neil algorithmic auditing company recently started offer algorithmic accuracy bias fairness certification certification algorithmic systems yet acquired significant mainstream support article gdpr introduce idea voluntary certification systems demonstrate compliance regulation report refers compliance transparency although would primarily certify compliance data privacy principles absence unjustified algorithmic decision bias similar certification algorithmic systems around big data due process rights also proposed emphasis two main aspects algorithmic systems certification algorithm software object directly specifying either design specifications process design expertise involved technology standards specifying related requirements monitored eval uated based standards certification whole person process using system system controller make decisions would consider algorithms situated context use importance internal ethics ommittees increasingly acknowledged large technology companies part response controversies deepmind royal free health data transfer microsoft tay chatbot emotion manipulation experiment led public announce founding coordinated effort develop codes conduct ethical partnership september also including amazon google ibm extent ethi committees impact work done companies difficult assess outside leading public frustration lack visible impact ethics committees concerns primary function ethics committees may fact manage public image avoid government regulation january partnership invited civil rights organisations aclu join order establish broader multi older platform remains seen partnership effective online privacy alliance opa group formed mid consist ing leading internet firms establish branch guidelines onli privacy policie guidelines failed prohibit collection sensitive data protect harmful uses data means ther policy backed government pressure monitoring ind ustry self self regulation takes characteristics either involve objectives set regulatory body implementation details delegated industry administration stoa panel future science technology right rgotten google involve bottom approach industry develops administers arrangements government provides legislative backing enable arrangements enforced case instanc noncompulsory rules industry standards used basis mandatory conformity certification requirements marking related certification example transparency related content information labels pegi games content rating examples failed accountability related harbour principles commercial data transfers usa invalidated european court jus tice ecj ruled company self practices safeharbour failed provide sufficient priva safeguards citizens due dependence implementation private sector suited cases fundamental rights major political choices called question form top proven effective number domains mandatory impact assessments environmental impact asses sment regulator sets assessment criteria industry include reporting assessment impact expected activities gdpr article includes requirement type ocessing using new technologies likely result high risk rights data subjects must prior data protection impact assessment dpia conditions consultation regulator noted dpias potentially tremendous implications increasing transparent accountable machine learning based algorithmic systems proposal mandated algorithmic impact assessment part procurement process major component current proposal consideration new york city task force set examine automated decis ion systems used city see section accountability measures order fully address concerns lack credibility transparency accountability effectiveness enforceability sanctions frequently associated self regulation needs establish certain guarantees ensure greater degree government invo lvement would self mechanism would need following components balanced constitution bodies equal participation different partners government industry users possibly represented civil society groups systems ensure bodies accountable government act outside scope competences clear unambiguous legal basis easily accessible arrangements reg arding operation bodies clear division tasks competences bodies government fact state impose sanctions non established regul atory rules major difference self even certain issues require resolution well model potential effectively enforced since reduces burdens personnel required expertise regulatory body counter argument critics reported reveal insider knowledge regulators instead use informational upper hand obtain weaker standards moreover reduction public opportunity participate regulatory initiatives lead less creativity collaborative discussions often take place outside public eye thi system could also facilitate agency capture whereby government begins pursue industry agenda rather public agenda furthermore business representatives may enforce rules vigorously absence enforcement firms may free ride efforts others established firms could also unfair advantage could use collaborative negotiations establish standards discriminate new entrants finally industry representatives participate process conflicted strong governance framework algorithmic accountability transparency even legal obligation shareholders put bottom concerns ahead public interest critics express profound scepticism process gives industry greater voice government regulation yield improved social outcomes state intervention typical state intervention instruments information measures promote people awareness knowledge risks support appropriate behaviour incentives european fund strategic investments alcohol tax command control regulation gdpr important reason turning state intervention instead fully relying previously mentioned market led self solutions concerns network scale effect driving massive concentration information industries removes market led pressures toward self information measures previously discussed one contributing reasons lack demand side market pres sure accountability algorithmic decision lack understanding regarding ways algorithmic making impacting lives true many highly skilled technical professionals judges lawyers information measures conceptualised consisting two components general understanding algorithmic literacy algorithmic processes fundamentals data analytics machine learning required order algorithmic transparency enable accountability context algorithmic accountability literacy serves provide users algorithmic decisio systems public private service providers including judges doctors subjects algorithmic decisions citizens customers patients basic skills necessary critically evaluate decisions without algorithmi literacy unreasonable expect citizens able know make use transparency mechanisms gdpr laws might confer understanding algorithmic systems general however wil little provide people ability judge merits algorithmic decision unless combined form public disclosure type properties algorithms data goals etc associated specific decision specific information regarding particular application algorithmic decision required order make possible citizens professionals effectively apply literacy minimum could take form alg type label notification analogous nutrition labels restaura inspection scores nutrition labels however level information disclosure would carefully calibrate avoid problems information overload causing vulnerabilities manipulation malicious actors information included label therefore limited potential either impact individual user decision processes wider public understanding aggregate system behaviour persistent problems developing meaningful privacy policy notifications clearly communicate data collection handling information citizens sta nds warning challenges operationalizing algorithm notifications since transparency aims simply making information available rather making information useful advancing social aims attention paid various stoa panel future science technology audiences information end experts attached regulatory bodies regard level detail assumptions expertise differing restrictions access use make disclosed information useful possible without violating privacy trade secrets linked sources useful contexts example top user label might link data presents underlying sources transparency made usefu reliable trustworthy lead information cul incentives funding taxes tax incentives used boost eco technologies electric cars solar panels could used part incentivi sing structure promoting use transparency enabling methods voluntary certification transparency standards performance auditing could applied systems medium impact qualify inv esting resources regulatory bodies would required monitoring mandatory certification far appear research possible advantages disadvantages scheme related form financial incentive aforementioned see demand side market solutions use transparency requirements part public procurement algorithmic services strategic investment funds could used boost development new algorithmic decisionmaking methods optimised explainability accountable audit trails could direct investment research successors incentivising promoting solves accountability problems nota ble efforts along line data transparency lab darpa explainable artificial intelligence xai project part strategic investment could targeted developing maintaining open source library transparent explainable auditable algorithms accompanying repository training validation data sets could done analogous existing efforts research community international neuroinformatics coordinating faci lity incf considering potential malicious use look towards cybersecurity community inspiration suggesting financially legally support teaming independent groups assume adversaria roles challenge organisations improve effectiveness actively probe robustness reliability algorithmic decision systems another area consider strategic direct investment would provide funding skills training technical staff computing infrastructure support investigative journalism domain algorithmic accountability clearly highlighted cambridge analytica case controversy around compas recidivism algorith used various courts many investigative journalism frequently led way highlighting societal implications automated decisions see appendix journalists combining interviews right information requests investigative reporting computationally intensive methods like box testing command regulation legislative measures direct regulatory state intervention technology space legislative measures often resisted industry due fears limit ability freely explore innovate novel technologies market pressures dominant business models investor group think may however result ation lock also limits free innovation may require external pressures government regulation order open new avenues innovation prominent examples ecological technology development improv governance framework algorithmic accountability transparency combustion efficiency alternatives engine types vehicle engines required government regulation mandated catalytic converters subsidies trigger development improvements remains seen successful introduction gdpr stimulating privacy innovation opportunity important similarity ecological considerations engine development privacy online services transparency algorithmic dec ision well cybersecurity internet things despite importance societal wellbeing constitute functional requirements requirements specifically concerned functionality system absence state regulation requirements determine ability technology fulfil primary design function tempting look towards gdpr specifically article often referred right explanation certain provisions articles meaningful information logic involved automated decisions article data protection impact assessment data protection authorities dpas means enforcing algorithmic accountability even though exact operationalisation many clauses gdpr yet established legal challenges rulings ecj various analyses legal scholars already pointed narrow focus gdpr personal data combined built restrictions article applies significant decisions made meaningful human input make highly unlikely gdpr confers sufficient rights obligations enforce transparent accountable algorithmic decision beyond gdpr french loi pour une republique numerique digital republic act law drawn attention way addresses algorith mic transparency accountability digital republic act gives right explanation administrative algorithmic decisions made individuals apply private sector specifying case decisions based algorithmic treatment note includes decisions fully automated involve algorithmic recommendations rules define treatment characteristics must communicated upon request detail added decree march elaborating administration shall provide information degree mode contribution algorithmic processing decisionmaking data processed source trea tment parameters appropriate weighting applied situation person concerned operations carried treatment analysis draws special attention point seems imply explanation must particular decision subject explanation rather general overview complex model model explanation focus area local specific query vastly simplifies system needs explained unlike complexity entire network might display recognisable patterns knowing particular factors features machine learning terms weighted may help explain systems means complete fast trac interpretability least two occasions court might say weights useful explaining decision human user therefore appropriate order disclosure weighted inputs map real world features user find intelligible older restricted systems retrofitting explanation system infeasible several experts proposed use counterfactuals way assess fairness machine learning systems without requiring explanations technique inputs small differences data run system way isolating effect particular stoa panel future science technology features example two job applications run system differ gender applicant applicant name changed one typical white americans americans outcome significantly different system presumed biased without perform full forensic analysis another alternative focuses goal outcome transparency organisation managing system announces optimised results system monit ored possibly publicly announced failure meet objectives trigger remedial action organisation fact default making classifications predictions immediate impact fairness exa mple recent project able predict cardiovascular risks retinal scans using deep learning type machine learning even less amenable demands explanations system put practice goal presu mably would diagnose risk factors accurately human experts goal would completely specified terms levels false positives false negatives achieves goals forms transparency seem unnecessary even hypothetically system turn assess cardiovascular risk accurately human experts white patients dramatically less accurately human experts people colour might still want allow used white patients fix might involve finding explanation devised make useful people fix found social decision would made whether want conti nue use system white people note entire hypothetical scenario played goal outcome transparency play situation becomes complicated cases particular categories people bear disproportionate weight harm example might use goal transparency ensure autonomous vehicles achieving social objectives reducing traffic fatalities lowering environmental impact cars goals met talities born disproportionate percentage poor people people colour example unlikely solve problem prohibiting categories people using avs thus regulatory disposition situation fferent nevertheless inequity outcomes fixed without explanations case goal outcome transparency may judged sufficient one recent article summarised idea systems ought required declare optimised optimisations systems significantly affect public ought decided companies creating systems bodies representing public interests optimisations always also support critical societal values fairness alternative approach algorithmic accountability proposed various legal scholars order provide citizens recourse compensation absence algorithmic transparency apply liability algorithmic decisions order subject algorithmic decisions receive compensation regime strict liability citizen would need show arm occurred denied insurance would prove algorithmic decision faulty hence liability applying strict liability algorithmic decision reverses burden proof placing pressure organisations developing using algorithmic making systems implement algorithmic transparency order prove system fault prove insurance denied valid grounds command rol regulation regulatory bodies detailed analysis possible roles regulatory body algorithmic systems presented roles summarised acting standards body possibly coordinating standards setting organisations develop classifications algorithmic complexity performance design liability standards best practices algorithm complexity classification reflecting governance framework algorithmic accountability transparency characteristics predictability explainabi lity could serve set level required regulatory scrutiny making algorithms significant scrutiny requirement deployment certification might reserved opaque complex dangerous term impact human rights society types algorithmic leaving untouched vast majority algorithms relatively deterministic predictable outputs lacking significant impacts table illustrated example high algorithm complexity classification scheme table possible classifications algorithmic complexity performance standards could establish guidance design testing performance ensure algorithms developed adequate margins safety accordance expected use types critical versus acceptable errors might make suggested predicted legal standard apply accidents involving algorithm design standards could look establish satisfactory measur predictability explainability liability standards could develop procedures distributing responsibility harms among coders implementers distributors end light regulator nudging algorithm designers imposing regulations low enough cost preserve freedom choice substantially limit kinds algorithms developed released light regulations could involve imposing requirements opennes disclosure transparency tailored scrutiny classification associated algorithmic system see table table spectrum disclosure hard regulation imposing substantive restrictions use certain kind machinelearning algorithms even sufficiently complex critical algorithms requiring market approval algorithms deployed market approval among aggressive positions agency could take would require certain algorithms slated use certain applications receive approval agency deployment agency could work applicant develop studies would prove agency satisfaction algorithm meets required performance standard stoa panel future science technology algorithms could also conditionally approved subject usage restrictions use algorithm marketing unapproved algorithm could subject legal sanctions approach may problematic systems learn usage world may used complex unpredictable systems autonomous vehicles existing proposals governance algorithmic systems following subsections summarise number specific proposals related governance algorithmic decision systems published right reasonable inferences analysis proposal framed around observation oncerns algorithmic accountability often actually oncerns way technologies draw privacy invasive non inferences predict understand refute elaborated pointing ounterintuitive unpredictable inferences drawn data controllers without individuals ever aware thus posing risks privacy identity data protection reputation informational self determination position also summarised big data world calls scrutiny often accuracy raw data rather accuracy inferences drawn data clarify point provides example even bank explain data variables used make decision banking records income post code decisions turns inferences drawn sources thus actual risks posed data analytics underpinning inferences determine data subjects viewed evaluated third parties observations contrasted focus gdpr proposed eprivacy regulation digital content directive aim give data subjects control personal data collected processed little control evaluated address accountability gaps tene polonestsky propose new right reasonable inferences would inferences based non counterintuitive predictions invade individual privacy damage reputation right would require justification given data controller establish whether inference reasonable disclosure would address certain data relevant basis draw inferences inferences relevant chosen processing purpose type automated decision whether data methods used draw inferences accurate statistically reliable mechanism would allow data subjects challenge unreasonable inferences support challenges automated decisions exercised art gdpr one consequence introducing right would use machine learning methods deep learning currently amenable explanation would ruled conditions right applies proposed right reasonable inferences would focus data evaluated collected apply irrespective identifiability data subjects require justification data sources intended inferences prior deployment inferential analytics scale give data subjects ability challenge unreasonabl inferences noted right reasonable inferences must however reconciled jurisprudence counterbalanced trade secrets law well freedom expression article charter funda mental rights freedom conduct business governance framework algorithmic accountability transparency consumer protection authorities algorithmic governance considered perspective consumer protection rules possible role consumer protection authorities based analysis information asymmetry consumers ervice providers larsson desteel challenge feasibility asking consumers protect consent mechanisms instead argue broader application consumer protection regulation user agreements order increase accountability operators turn requires consumer protection legislation applied pragmatically responsible supervisory authorities recommendation consumer protection authorities therefore develop synergies particular data protection authorities provide expertise consumer protection transparency would likely include audits control data targeting software operates order consumer protection authorities develop ability assess perhaps outsourced expertise combination algorithms use big data sources leading disco ver use erroneous data form transparency could way forward keep proprietary software specific design algorithms business secrets may need time provide necessary protective mechanism worst case detriment consumers algorithms analysis specific challenges come machine learning type systems rather programmed develops proposal centralised fda type regulator body algorithms analogy food drug administration fda motivated observation explainability predictability new problems technologies pharmaceuticals operate extremely complex systems long confronted companies begin developing drugs hypotheses might prove effective little better smart guesses even drug proves effective intended use hard predict side effects body biochemistry complex pfizer developing viagra treatment heart disease discovered drug actually far effective treatment erect ile dysfunction rogaine first came market loniten drug used treat high blood pressure discovered could regrow hair cause aspirin analgesic effects understood many decades bayer started selling sometimes drug discovered mechanisms including reasons side effects easily explained sometimes efficacy side effects difficult predict advance necessity singular new regulatory body argued based three characteristics algorithmic decision systems especially based machine learning complexity opacity dangerousness opacity first kinds algorithms concerning nature opaque benefits harms difficult quantify without extensive expertise feature market algorithms contrasts sharply market products individuals easily able assess benefits safety risks posed product highly opaque complex products benefit expert evaluation regulator products complexity second difficulties assigning tracing responsibility harms algorithms associating responsibility human actors distinguish algorithms products algorithms could commit small severe term harms may commit grievous errors low probability therefore unlike many products combination tort regulation reputation correct accidents acceptable pace market tort regulatory system likely prove slow respond algorithmic harms stoa panel future science technology dangerousness third least circumstances algorithms likely capable inflicting unusually grave harm whether machine learning algorithm responsible keeping power grid ope rational assisting surgery driving car algorithm pose immediate severe threat human health welfare way many products simply based observations argues central regulatory ency market review would better able contend problems subject agencies working independently degree significant expertise required understand possible dangers algorithms pose single central regulat ory agency likely able pool top talent together multiple agencies seeking hire experts help make sense problem single regulator could grapple dangers algorithms pose holistically rather piecemeal distinguishing algorithms basis stakeholder feedback expert judgment single agency would able maximise centralised expertise brought bear issue offering agility flexib ility responding technological change developing granular solutions agency certification tort liability proposal put forward constructs algorithmic accountability around agency tasked certifying safety broadly defi ned include societal discriminatory harms algorithmic decision systems combination legal liability framework designers manufacturers sellers agency systems would subject limited tort liab ility uncertified systems offered commercial sale use would subject strict joint several liability agency staffed specialist would tasked assessing safety algorithmic systems courts experienced adjudicating individual disputes would tasks determining whether algorithmic system falls within scope agency design allocating responsibility interaction multiple components stem gives rise tortious harm strong based system would compel designers manufacturers internalise costs associated harm caused algorithmic decisions ensuring compensation victims forcing designers programmers manufacturers examine safety systems systems successfully complete agency certification process would enjoy partial regulatory compliance defence effect limiting rather precluding tort liability whenever negligence suit involving design certified system succeeds agency would required publish report similar reports national transportation safety board prepares aviation accidents incidents accoun tability measures algorithmic system use public authorities algorithmic systems currently used government reshaping criminal justice systems work via risk assessment algorithms predictive policing optimizing energy use critical infrastructure resource allocation changing government resource allocation monitoring practices researchers advocates policymakers debating algorithmic systems propriate including whether appropriate particularly sensitive domains questions raised fully assess short long term impacts systems whose interests serve sufficiently sophisticated contend complex social historical contexts questions essential developing strong answers hampered part lack information access systems deliberation public auth orities urgently need practical framework assess algorithmic systems ensure public accountability governance framework algorithmic accountability transparency algorithmic impact assessments framework algorithmic impact assessm ent aia framework designed support affected com munities stakeholders seek assess claims made systems determine use acceptable simply affected communities lack necessary information assess algorithmic systems orking governments also struggling assess systems used whether producing disparate impacts hold accountable instead impacted communities public large governments left rely journalists researchers public records requests able expose aias offer practical accountability framework combining public authority review public input aias solve problems algorithmic systems might raise provide important mechanism inform public engage policymakers researchers productive conversation aias draw directly impact assessment frameworks environmental protection human rights privac data protection policy domains aias resemble environmental impact assessments data protection impact assessments privacy impact assessments differ important ways example data protection impact assessm ents dpias like mandated gdpr similarly serve highlight data protection risks automated systems used evaluate people based personal data data controller finds system high risk must nsult local governmental data protection authority however dpias apply public private organisations shared public built external researcher review individualised challenge mechanisms aias hand explicitly designed engage public authorities people serve areas concern various review public participation right elements allows wide range individuals communities researchers policymakers participate accountability efforts review aia covers algorithmic system deployed matter acquired developed internally procurement aia ves public authority opportunity engage public proactively identify concerns establish expectations draw expertise understanding relevant stakeholders although framework agreements often used easier alternative complying procurement directives ideal procedure acquiring algorithmic systems would hinder ability public government identify address concerns aia gives public authority opportunity evaluate adoption automated decision system public authority committed use allows public authority public identify concerns may need negotiated otherwise addressed contract signed also public elected officials push back deployment potential harms occur implementing aias authorities consider incorporating aias processes already use procure algorithmic systems existing pre assessment processes public authority already undertakes finally pre aias may also allow member states identify relevant training policy architecture accordance european commission recommendation professionalisation public procurement creating definition aia process public authorities must first publish definition automated decision system practical appropriate particular context mean public authority must effort redefining automated decision system particular system reach working definition choose republish future stoa panel future science technology aias long continues accurately describe systems ways reinforce public trust accountability public authorities also regularly revisit definition necessary incorporate new types systems new applications old systems research advances relevant fields process defining specifying algorithmic systems would help build public authority capacity procurement assessment future systems experience aias would help guide budgeting key milestones acquisition process decisions algorithmic systems subject aia process particular public authority context interests communities serve overly broad definition could burden authorities disclosing systems main sources concern public servant uses word processor type notes meeting key decisions made checks program spell public authority perform aia spell alternatively overly narrow definition could undermine efforts include high profile systems like deciding students schoo housing opportunities allocated review analytical models focused models used inform public authority decisions review went inform government aqua book idance producing quality analysis government offers one possible method defining automated decision system also essential systems defined terms broader software aias address human social factors histories bias discrimination context use input training data bias algorithmic systems ari much human choices design train system human errors judgment interpreting acting outputs evaluating risk assessment tool instance matter understanding math behind algorithm must understand judges police officers makers influence inputs interpret outputs gdpr automated profiling defined form automated processing personal data consisting use personal data evaluate certain personal aspects relating natural person particular analyse predict aspects concerning natural person performance work economic situation health personal preferences interests reliability behaviour location movements gdpr language good starting point authorities require shaping match appropriate contexts contexts may sufficient predictive policing tools example necessarily profile individuals instead focus locations using statistics try understand predict crime trends across geographical areas potential disparate impact definition might acco unt systems tools algorithms attempt predict crime trends recommend allocation policing resources non individualised terms general definition certainly cover systems might disparate impact vulnerable communities pay careful attention broad terms like processing specified practice public authorities also learn borrowing definitions domains governments better tested already public approval perhaps even withstood challenges court archive systems decisions public authority published definition automated decision system need determine systems meet definition subject aia requirements even public authority strikes right balance definition automated decision system subsequent systems decisions subjective influenced considerations governance framework algorithmic accountability transparency intentional avoid ance performing aias therefore public authorities keep public archive systems decisions public archive provide much needed transparency public authority decisions public aware challenge deci sions automated decision system improperly excluded aia requirements transparency mechanism novel within impact assessment frameworks instance environment impact assessment context proposed federal acti excluded detailed environmental analysis determined action individually cumulatively significant effect human environment public authority develops procedures perform assessment often take form detailed checklist determination document explaining exclusion additionally federal authorities maintain database decisions resulted proposed actions excluded environm ental analysis public authorities determine level detail archive minimum provide adequate documentation public authority decision exclude systems aia requirements public authority publish decisions excluded systems system deployed meaningful opportunity public scrutiny public authority assessment systems aias increase internal capacity public authorities better understand explicate potential impacts systems implemented public authorities must experts algorithmic systems ensure public trust public authorities aias must include evaluation sys tem might impact different communities plan authorities address issues arise ideally public authorities pre issues potential harms evaluated self example former attorney general eric holder urged sentencing commission study use data analysis front sentencing issue policy recommendations based careful independent analysis standardi sing process authorities ensure evaluation comprehensive comparable evaluation detailed outside researchers experts adequately scrutinise system potential impact provide non summary general public dual explanation used types impact assessment frameworks encourages robust public engagement self public authorities identify potential impacts public proactively enga affected communities ensure system meets given community goals assessment articulate light goals system net positive impact communities fulfilling requirement aia rocess would require public authority engage communities early even formal notice comment process authorities could also use aia opportunity lay procedures help secure public trust systems appropriate public authority might want identify individuals appeal decisions involving algorithmic systems make clear appeals processes might cover given system decision share mitigation strategy system behave unexpected harmful way harm undesirable outcome error identified public authority explain intends correct remedy issue self process also opportu nity public authorities develop expertise commissioning purchasing algorithmic systems vendors foster public trust systems authorities better able assess risks benefits associated different type stoa panel future science technology systems work vendors researchers conduct share relevant testing research automated decision system including limited testing potential biases could adversely impact individual group ind eed researchers already developing resources materials authorities use ask appropriate questions systems noted vendors raise trade secrecy confidentiality concerns addressed aia responsibility accountability ultimately falls upon public authority benefits self assessments public authorities beyond algorithmic accountability encourages authorities better manage technical systems become leaders responsible integration increasingly complex computational systems governance benefits vendors aias would also benefit vendors prioritise fairness accountability transparency offerings companies best equipped help authorities researchers study systems would competitive advantage others cooperation would also help improve public trust especially time scepticism societal benefits tech companies rise new incentives encourage race top accountability spectrum among vendors benefits public records request processes increasing public authority expertise aias also help promote transparency accountability public records requests today public authorities receive open records requests information algorithmic systems often mismatch outside requestor thinks authorities use classify technol ogies reality result requests may take scattershot approach cramming overly broad technical terms numerous requests hopes one hit mark make difficult records officers responding good faith understand requests let alone provide answers public needs even open records experts willing reasonably narrow requests may unable lack roadmap showing systems given publi authority planning procuring deploying example project university maryland faculty students working media law class filed numerous general public records requests information regarding criminal risk assessment lgorithm usage fifty states responses received varied significantly making difficult aggregate data compare usage across jurisdictions also revealed lack general knowledge systems among authorities leading situations students explain criminal justice algorithms public servants charge providing records use accountability processes aia would help correct mismatch sid equation researchers journalists legal organisations concerned members public could use aias reasonably target requests systems enumerated described saving public records staff significant time resou rces public authority staff would also gain better understanding systems records could help requestors understand documents public records potentially available alignment would increase efficiency lower public authority burden processing requests increase public confidence course basic requests preempted aia disclosure requirement saving researchers authorities burden engaging public records request process governance framework algorithmic accountability transparency considering allocative representational harms anticipated challenge governments performing aias assessment potential cultural social harms challenge exists impact assessment processes req uires public authority make assumptions predictions cultural social factors vary enormously within communities geographic areas practice often results findings reflecting potential impacts dominant culture omitting misinterpreting impacts marginalised communities individuals instance france protests predominantly black muslim neighbourhoods often represented act criminality delinquency rather esponses poverty exclusion abusive police power prevailing viewpoint unfortunately resulted greater police presence questionable police practices neighbourhoods france highest court ruled police racially based checks illegal discriminatory avoiding sorts harms key goal aia public participation process existing literature bias algorithmic systems tended rely heavily could called allocation groups denied access valuable resources opportunities course addressing allocative harms crucial authorities also consider harms representation way system may unintent ionally underscore reinforce subordination social cultural groups example researchers classify google photo platform automatic labelling images black people gorillas representational harm denial mortgages people live within particular zip code allocative harm algorithmic systems used public sector susceptible kinds harm embedded demographic data serve proxies partic ular groups reinforce past harms economic identity impacts datasheets requirement technical research community studying fairness accountability transparency machine learning begun consider standard ways acc ount data history biases skews one proposal called data creators produce datasheets datasets datasheet semi document asks questions like dataset created data collected relates people unfairly advantage disadvantage particular social group prompts data creator publish information data provenance biases potential societal impacts datashe ets could become part aia one two ways first public authority acquisition development algorithmic system requires use government data collection new data aia process could require public authority create datasheet second public authority purchases algorithmic system third vendor vendor contract authority could require vendor provide public authority datasheets data used vend development system datasheets alone would meet level analysis needed public authority self potentially valuable public documents public authority could include aia public participation fundamental aspect government transparency accountability notice rights may affected government agencies actors algorithmic systems play significant role government decisions public given notice substantive public engagement requires access accurate timely information thus important component aia public authority publicly disclose proposed existing automated decision systems including purpose reach internal use policies potential impacts communities individuals requirement would long way towards shedding light technologies deployed accountability research community advocacy stoa panel future science technology focused aia disclosures would also help governments proactively avoid political turmoil backlash involving systems public may ultimately find untrustworthy may cause direct indirect harm also provides opportunity meaningful public participation aia process includes opportunity public engage public authority regarding content initial aia disclosure public authorities decide want organise public partici pation process could choose separate component aia definition access separate public participation periods release aia single document one overarching public participation period one document might advantage agencies public separating definition automated decision systems disclosure systems moving discuss internal assessments external researcher access protocols initial disclosure provides strong foundation building public trust appropriate levels transparency subsequent requests solicit information presentation new evidence research inputs agency may adequately considered creating implementing mitigation corrective measures public authorities self assessment identify potential impacts public proactively engage affected mmunities ensure system meets given community goals assessment articulate light goals system net positive impact communities public authorities could also use aia opportu nity lay procedures help secure public trust systems appropriate public authority might want identify individuals appeal decisions involving algorithmic systems make clear appeals processes ght cover given system decision share mitigation strategy system behave unexpected harmful way harm undesirable outcome error identified public authority explain intends correct remedy issue proposed plan mitigating corrective measures implemented trade secrecy public authorities need commit accountability internal technology development plans endor procurement relationships example disclosure algorithmic systems meaningful information systems feasible essential information shielded review blanket claims trade secrecy certainly core aspects systems competitive commercial value unlikely extend information existence system purpose acquired results public authority internal impact assessment trade secret claims stand obstacle ensuring meaningful external research systems aias provide opportunity authorities raise questions concerns trade secret claims acquis ition period entering contractual obligations vendor objects meaningful external review would signal conflict vendor system public accountability scenarios may require authorities ask potentia vendors waive restrictions information necessary external research review minimum vendors contractually required authorities waive proprietary trade secrecy interest information related accountabilit surrounding testing validation verification system performance disparate impact also encourages competitive landscape among government technology vendors meet accountability requirements aias want business public authorities governance framework algorithmic accountability transparency meaningful access outside researchers aias provide comprehensive plan giving external researchers auditors meaningful ongoing access examine specific systems gain fuller account workings engage public affected communities process plan give experts rapid access system deployed within six months however situations internal public authority assessments insufficient particular risks harms gone unaddressed external researchers auditors could raise need deployment review comment period certain individuals communities may wish examine systems thems elves relied upon would unreasonable assume everyone time knowledge resources testing auditing algorithmic systems incredibly complex issues like bias systematic errors may easily determined review systems ndividual case basis plan grant meaningful access qualified researchers would allow individuals communities call upon trusted external experts best suited xamine monitor system assess whether issues might harm public interest well important recognise appropriate type level access may vary public authority public authority rom system system community community risks harms issue different systems may demand different types assessment auditing using different methods disciplines right explanation concerning specific automated decision could prove useful situations many systems may require group community analysis example explanation single racial profiling incident reveal greater discriminatory pattern many system may require analysis based inputs outputs simple information algorithms used without needing access underlying source code expect many systems authorities would provide training data record past decisions researchers believe best way authorities develop appropriate research access process initially would work community stakeholders interdisciplinary researchers notice comment proces importantly given changing technologies developing research field around accountability shifting social political contexts within systems deployed access system almost certainly need ongoing take monitoring time individual public authority works researchers community members design research access provisions number elements place research auditing performed syst ems accountable public include public log researchers experts provided access basis public authorities ensure affected communities able suggest researchers feel represent interests work researchers ensure communities voice formulating questions asked addressed research auditing importantly ensure public accountability thriving research ield research findings conclusions published openly even embargo period held standards scrutiny peer review within appropriate research domains ongoing auditing research access would allow public auth orities researchers affected communities work together develop approaches testing interrogating systems especially important given research algorithmic accountability young technological develop ment proceeds rapidly yet know future tools techniques perspectives might best keep systems accountable external experts wide variety disciplines need flexibility adapt new methods accountability new rms automated decision emerge stoa panel future science technology funding resources issues also real danger relying external auditing become unfunded tax researchers affected communities engage might expected take responsibility testing monitoring algorithmic systems without resources compensation alternatively house auditors relied could become captured incentives clients face conflict issues wever approaches legislation could adopt address aia framework could fund independent government oversight body like inspector general office support research access community engagement community institutional review boards could supported help steer review research proposals funding could set aside compensation external auditors fortunately many options jurisdictions could consider needs growing community computer scientists journalists social scientists engaged community advocates already proven appetite research public algorithmic systems work continue strongly suppo rted funding bodies research authorities enhanced due process mechanisms challenge inadequate assessments failure mitigate aia process provides needed basis evaluating improving public authority systems without ove rsight aias could become checkbox authorities mark forget potentially sidelining community concerns aia process also provide path public challenge public authority fails comply requirements self process deficient adequately identifying addressing key concerns example public authority fails disclose system reasonably considered algorithmic system allows vendors make overbroad trade secret claims blocking meaningful system access public chance raise concerns public authority oversight body directly court law public authority refuses rectify problems public comment period aia process give public opportunity effectively challenge public authority adoption system prevent system used fails benefit affected ommunities santa clara california instance law passed requires local board supervisors explicitly approve new surveillance technology moving forward use renewing algorithmic impact assessments aias order ensure assessments remain current incorporate latest information research authorities required renew aias regular schedule renewed aia also renewed comment due process challenge periods examp authorities could required conduct new aia systems every two years however significant changes system context deployment need external research access public aut hority allowed minimally update original aia content part renewal process algorithmic impact assessments practice aia framework goes beyond components described parts aia definition algorithmic system public authority self public participation external meaningful researcher access must structured process ensures preacquisition review algorithmic systems opportunity public input solicited addressed governance framework algorithmic accountability transparency practice aia process necessarily look identical different national contexts existin government procurement development practices local interests laws relevant individual member states description possible aia process describes model aia framework look like public authority publishes defin ition algorithmic system public authorities first define algorithmic system public understand authority decides systems subject aia process outset happen rest aia give public authority opportunity work definition committing full review system may need definition published authority may choose solicit public participation definition lone outside scope single aia example even agency believe algorithmic systems separate process necessary authority still publish definition public comment necessary challenge subsequent aias could use new definition going forward public authority publicly discloses purpose scope intended use associated self assessment potential implementa tion timeline system public authority publishes decision review potential system systems decision archive public authority first give public basic notice potential new system proceeding sel public authority use opportunity solicit early external feedback early feedback help public authority focus self pertinent public concerns committing particular analysis public authority decided need conduct full aia public authority record decision systems decision archive lieu publishing self assessment timeline functions similarly isting environmental impact assessment frameworks require authorities first decide proposed action requires assessment excluded assessment requirement like full self decision publishe system entered use exclusion challenged public authority performs publishes self system focus inaccuracies bias harms affected communities describes mitigation plans potentia impacts self analyse algorithmic system study potential sources bias inaccuracies harms public concern learn public concerns early start address issues public raises publ agency conducting assessment proactively engage public better scope assessment public authority publishes plan meaningful ongoing access external researchers review system deployed ideally stak eholders may helped public authority self include sorts researchers given ongoing access algorithmic system stakeholders input self likely reveal concerns potential problems require ongoing monitoring challenges exist studying particular algorithmic system public participation period full aia conducted final period public participation must set aside allow stakeholders comment final product final public participation period allows public voice concerns issues may missed aia process public authority required address finalizing aia ideally public authority stoa panel future science technology already addressed public concerns proactive engagement defining system scoping self designing researcher access final version released aia finalised concerns issues raised public participation period addressed documents pertaining aia made publicly available renewal aias regular timeline public authorities must required renew algorithmic impact assessments regular schedule algorithmic systems used may change time requiring new round analysis revisit changes significantly impacted algorithmic system operates new concerns may come light addressed original aia researchers might develop new techniques analyse algorithmic systems blic authority could leverage future review opportunity challenge failure mitigate issues raised public participation period foreseeable outcomes aia finalised public given opportunity chall enge public authority failure implement mitigating corrective measures raised aia process public also able challenge public authority decision conduct aia particular system public thority decides system meet definition system accountability transparency requirements public procurement algorithmic systems promulgated three public procurement directives set fram ework procedures procurement public authorities specification stage contracting authorities define requirements product services intend procure public contracts directive expan ded scope issues covered specification include performance equality issues well relevant processes methods linked issues many algorithmic systems come gover nment via procurement procedures procedures serve powerful moments raise address transparency accountability concerns algorithmic system vendors given expanded scope issues covered specification stage procurement contracting authorities establish variety transparency accountability requirements particularly relate performance equality social issues order public authority adequately assess algo rithmic system performance require significant information system often authorities lack necessary information assess performance vendors use intellectual property claims avoid providing necessary information authorit ies fail inquire relevant information variety requirements public authority explore ensure enough information assess performance algorithmic system ensure maintenance optimal performance following recommendations seek address performance transparency issues public authority require vendor produce materials used explain systems general stakeholders technical manual including user desi code documentation governance framework algorithmic accountability transparency public authority require vendor provide notice claims lawsuits actions related algorithmic system may impact public authority use public authority require vendor prov ide comprehensive list proposed data sets methodologies vendor intends use design production configuration system public authority also require vendor provide datasheet assessing quality data set explanation proposed manipulation data plan account possible sources bias data collection manipulation finally public authority require vendor disclose evidence analysis reports known discovered flaws system relevant data sets public authority require vendor produce test version system conduct performance analysis performance analysis study potential operator use system understand patterns use operator interprets acts system outputs vendor agree assert legal claims public authority third parties conducting research test aud examine otherwise understand system effect individual group individuals impacted system outputs algorithmic systems often use produce sensitive government information sometimes individuals companies wish keep sensitive information private seek services private sector address privacy equality concerns public authority develop requirements clarify ownership confidentiality mechanisms following recom mendations seek address privacy accountability equality issues public authority require materials processes products related technical use materials exclusively owned public authority vendor uses services individuals organisations subcontractors public authority require vendor use subcontract agreement ensure copyrightable work product remains property public authority vendor responsibility actions subcontractors public authority require materials supplied public authority held strict confidence public authority prohibit copying duplicating disseminating discussing public authority materials anyone persons authorised public authority development industry standards algorithmic decision making systems industry standards developed national afnor din uni bsi ansi etc international standards setting bodies iso iec itu ieee etc play important role establishing common reference structures enable successful industry self regulation iso family qual ity management system standards instance facilitates trust procurers suppliers global supply chains exist number standards related decision currently international standards deal direct institute electrical electronics engineers ieee launched ieee global initiative ethics autonomous intelligent systems address growing concerns unintended consequences algorithmic systems part initiative launch development ieee series ethics based standards transparency stoa panel future science technology autonomous systems algorithmic bias considerations first standards developments expected reach completion late start joint technical committee information systems jtc international standards organisation iso international electrotechnical commission iec set new subcommittee jtc identify necessary standards projects artificial intelligence average development time international standards three five years second study group set jtc tasked inv estigating approaches establish trust systems transparency verifiability explainability controllability etc focusing terminology september proposal submitted artificial intelligence subcommittee jtc request service management governance subcommittee establish joint working group pursue work governance implication use organisations current lack established standards algorithmic decision systems poses challenge regulatory authorities seeking references identifying best current stage standards development process provides opportunities signalling priority areas stand ards setting organisations human rights foundation algorithm governance many concerns driving demands algorithmic accountability directly related inadvertent violations fundamental human rights algorithmic systems automating complex procedural tasks lack capacity human makers understand human condition notice decision would infringe upon human rights unless tes deliberately coded developers outcomes evaluation routine fact fears wholly unjustified evident large number prominent examples infringements human rights reported ranging racism invasions privacy interference freedom expression restrictions due process criminal justice proceedings many technical academic community discussing issu framed problems language concerns around ethical behaviour also referring legal concepts discrimination differential impact rights ngos researchers started pick issues matter human rights may leading conference human rights digital age rightscon featured dedicated conference track intelligence automation algorithmic accountability saw launch decla ration protecting right equality non machine learning systems relation establishing governance frameworks algorithmic transparency accountability key message toronto declaration discourse around ethics artificial intelligence continues declaration aims draw attention relevant well framework international human rights law standards universal binding actionable laws stand ards provide tangible means protect individuals discrimination promote inclusion diversity equity safeguard equality human rights universal indivisible interdependent interrelated assessment theoretical practical human rights law based approaches assessing regulating algorithmic systems summarised submissions human rights big data technology project response call evidence house lords select committee artificial intelligence starting point assessment observation international human rights framework much broader right privacy freedom expression association equality places legally binding obligation nation states respect protect fulfil human rights additionally governance framework algorithmic accountability transparency guiding principles business human rights businesses responsibility respect human rights human rights approach provides system applied plans policies processes order ensure centrally affected considered centrally involved flowing obligations responsibilities imposed human rights law human rights approach offers increased transparency within policy formulations empowers people communities hold duty act accountable practical level mcgregor presents following specific unique human rights approach analysis order identify human rights claims holders corresponding human rights obligations duty well immediate underlying structural causes realisation rights assessment capacity holders claim rights duty fulfil obligations followed development strate gies build capacities monitoring evaluating outcomes processes guided human rights standards principles programming processes policies planning informed recommendations international human rights bodies mechanisms illustrate human based approach accountability would apply realm algorithmic decision mcgregor described context human rightsbased approach requires using international human rights standards norms means identifying defining elements within algorithm cycle give rise human rights concerns establishing impact upon rights addressing questions responsibili identifying human rights concerns addressed human rights approach accountability algorithmic decision proposed mcgregor would include tools initial ongoing human rights impact assessments test review impact algorithmic decision human rights rights impact assessments instruments examining policies legislation programmes projects prior adoption identify measure impact human designed identify intended unintended impact enjoyment human rights state ability protect fulfil planning tool prevent human rights violations asse ssing formal apparent compatibility laws policies budgets measures human rights obligations well likely impact practice thus creating opportunity reconsideration revision adjustment prior adoption global dimension algorithm governance one defining characteristics digital economy technologies based including internet platforms cloud computing algorithmic systems high degree crossboarded glo bal reach services built technologies successfully govern technologies therefore requires global dialogue collaboration across borders among rich poor countries avoid patchwork country regional approaches section review international dimensions governing algorithmic transparency accountability geopolitical competition introduction algorithmic processes increase machine autonomy automate much services sector globally accepted represent significant shift society akin stoa panel future science technology industrial revolution perception raised spectre sharp rise economic military political power countries managed first industrialise century many nations including china various states responded view publishing ambitious national artificial intelligence strategies intended ensure among leaders winners new industrial revolution led commentators raise alarm global arms race special concerns regarding dual civilian military nature algorithmic methods potential plication cyber autonomous weapons systems competitive environment strong narrative strong pressures push mputational efficiency functional performance algorithmic systems cost non considerations considerations directly contribute ability system perform task transparency within hypercompetitive environment regulatory intervention mandate algorithmic transparency likely met similar suspicions protectionist interventionism case gdpr counter point however gdpr also inspired various countries either enact similar legislation brazil china india south africa california etc increased motivation join council europe convention senegal mauritius tunisia cabo verde mexico modernised form closely aligned gdpr represents viable basis truly global data privacy framework example presented gdpr uggests regulatory interventions geared towards strong protections citizen rights position viable leader many states willing engage racial cultural bias algorithms algorithmic systems created latively homogenous groups developers using data sets frequently groups representing others imagenet data set instance core data set creation computer vision applications popu lated images united states whereas images china india together contribute date lack diversity partially responsible failures image recognition algorithms interpret asians eyes always blinking capable labelling photograph traditional bride dressed white bride photograph north indian bride art misclassify darker women gender error rate lighterskinned men misclassified rate biases relatively easy notice case image recognition systems algorithms deeply embedded within services may contain severe cultural biases difficult detect without access knowledge system works illustrative example bias brought light revealed database used faceboo trending topics app since discontinued selected news items recommend readers consisted trusted news sources many world major news outlets missing list many countries especially africa eastern europe even single outlet listed result despite active countries around globe recommendations facebook trending topics app heavily skewed towards news items reported anglophone media order lim unintended cultural racial discrimination algorithmic systems deployed different context developed may necessary obtain transparency reports document development team addressed localisation challenges governance framework algorithmic accountability transparency foreign interference usually unintentional types algorithmic bias discussed previous paragraph introduce undesirable cultural interference sinister deli berate form foreign interference represented targeted use algorithmic systems social media bots big data analytics psychological micro political ads intervene informa tional integrity national electoral processes offensive cyber operations corporate espionage disruption national services interference elections counter forms reign interference vital establish highly confident attribution mechanisms order hold true offending party account national counterintelligence work beyond scope document worth noting important role hat transnational bodies europol cyber crime units nato cooperative cyber defence centre excellence play vital information coordination response cyber incidents shown cambridge analytica case see also section important element combating foreign interference ability obtain cooperation necessary legally compel transparency accountability corporate actors facebook case cambridge nalytica incidents whose algorithmic systems involved interference operations trade negotiations context global dynamics geopolitical interference algorithmic cultural bias use algorithmic systems foreign interference important note current commerce proposals discussed wto well regional trade negotiations regional comprehensive economic partnership rcep others include proposals rotect intellectual property restricting access information regarding proprietary algorithms japanese proposal wto exploratory work electronic commerce initiative instance includes clause prohibition disclosur important information trade secrets including source codes proprietary algorithms similar statement electronic commerce initiative filed day united states also includes clause protection proprietary information sections protecting source code barring forced technology transfer barring discriminatory technology requirements degree similar clauses free trade agreements might cause problems accountability regulatory oversight algorithmic systems depend details agreements finally produced necessary find workable balancing point trade secrets transparency similar policies domains agreements may need indicate factors metrics algorithm would disclosed frequency disclosure daily monthly real vehicle communicating information separate document integra ted gorithmic output way international coordination algorithm governance discussed earlier section many aspects algorithmic accountability involve global transnational interactions states globally operating corporate actors order structurally address issues transparency accountability algorithmic systems therefore require ongoing coordination international level current international efforts deal issues arising use algorithmic systems highly dispersed across multiple sector specific initiatives led efforts stoa panel future science technology encourage development good address sustainable development goals sdgs managed itu ban lethal autonomous weapon systems primarily discussed banner convention certain conventional weapons unccw multi dialog ethics governance systems frame internet governance forum igf umbrella unesco also efforts council europe committee experts internet intermediaries msi net innovation ministers oecd time bilatera multilateral trade negotiations asserting importance intellectual property rights trade secrets relative transparency accountability order establish consistent international governance algorithmic systems establish cooperative alternative arms race narrative may necessary establish new international body possibly within agency body could help coordinate national regulations establishing common interests alues accountable use algorithmic systems drawing existing international human rights standards norms provide enhanced certainty ensure international perspectives based universal values though still early stage development efforts towards establishment trans national coordination governance algorithmic starting emerge fora oecd artificial intelligence expert group aigo world governm ent summit global governance rou ndtable activities council europe preliminary analyses requirements potential frameworks global coordination forum governance explored recent publications erdelyi goldsmith wendell marchant erdelyi goldsmith propose international artificial intelligence organization iaio would serve international forum discussion well international standards setting similar role itu telecommunications paper wendell marchant proposes approach framed around global coordinating committees gccs international gcc would work complementary regional bodi reinforce governance initiatives organizations ieee wef partnership various research centres governance framework algorithmic accountability transparency policy options based review analysis current literature regarding algorithmic transparency accou ntability successes failures challenges different governance frameworks applied technological developments especially ict propose set four policy options addresses different aspect algorithmic transparency accountability awareness raising education watchdogs whistleblowers accountability public sector use algorithmic decision regulatory oversight legal liability private sector global dimension algorithmi governance awareness raising education watchdogs whistleblowers decade struggle consent based approaches data privacy shown information asymmetries service providers consumers limited ability citizens successfully exercise rights interacting digital services comes algorithmic decision prevailing consensus literature suggests struggling understand systems work impact critically evaluate decisions true many highly skilled technical professionals judges lawyers lack algorithmic literacy limiting ability people express agency interaction systems thereby undermining functioning demand side market pressure self sector order algorithmic transparency enable accountability general understanding algorithmic functioning however little provide accountability unless combined form public disclosure types properties algorithms associated specific decision order useful notifications standardised short akin nutrition labels restaurant inspection scores information included disclosure label limite potential either impact individual user decision processes wider public understanding aggregate system behaviour beyond helping citizens navigate personal interactions algorithmic decision systems literacy also important help understand media reports related algorithmic decisions participate public dialog use system investigative journalism whistleblowers play important role unco vering questionable uses outcomes algorithmic decision challenging lack accountability clear examples cambridge analytica case revelations edward snowden regarding questionable reliability algorithmic targe ting drone strikes controversy around compas algorith used various courts many including importance whistleblowing media part employee led activi aimed changing company projects perceived unethical see also appendix examples public scrutiny much journalist led new york times investigation revealed ride sharing company uber used algorithm flag evade regulators cities world journalists learned algorithm existence purpose speaking current former uber employees reviewing documents sources provided times investigation led broad media coverage department justice inquiry potential criminal behaviour company beyond role independent watchdogs journalists help present relevant aspects algorithms wider audi ence plain language understandable narratives several stoa panel future science technology journalistic investigations listed sparked broad public conversations important normative debates including triggeri series academic studies propublica report ias compas algorithm instance triggered series studies meaning fair algorithmic systems impossibility producing system would simultaneously unbiased measures misclassification positive rates negative rates order uncover cases algorithmic malpractice journalists combining interviews right information requests investigative reporting computationally intensive methods reverse engineering algorithms box testing developed small active field algorith mic accountability journalism grew established field journalism reverse engineering process focuses system performance inuse therefore tease consequences might apparent even journalist speak directly designers algorithm legally however reverse engineering commercial software prohibited trade secrets copyright dmca software vendors also typically add anti engineering clauses end user license agreements eulas forcing decision okay breach contract gets closer truth algorithm raises need establishing exemption clauses public interest reverse engineering software algorithmic accountability journalists something similar whistleblower protection directive proposed earlier year developing skills algorithmic reporting takes dedi cated efforts learn computational thinking programming technical skills needed make sense algorithmic decisions growing awareness complex algorithms among data journalists number computational journalists technical skills deep investigation algor ithms still rather limited supporting computationally literate reporters providing computational infrastructure savvy computer scientists team would help facilitate quality algorithmic accountability reporting another way would provide support scholarships dedicated courses train journalists computational techniques besides technology skills legality reverse engineering investigative reporting algorithms also requires understanding ethical questions arise possible ramifications publishing details certain algorithms work would publishing information negatively affect individuals publishing details algorithm functions specifically information inputs pays attention uses various criteria ranking criteria uses censor might allow algorithm manipulated circumvented would benefit manipulation order help investigative journalism algorithms perform watchdog function minimising negative side financial logistical sup port coordinated fact vetted algorithms journalism similar collaborative journalism efforts behind publications snowden files panama papers paradise papers recommendations order people agenc able critically evaluate results given algorithmic systems must basic understanding algorithmic decision works therefore recommend provision literacy teaches core concept computational thinking role data importance optimisation criteria introduction standardised notification practices communicate type degree algorithmic processing involved decisions governance framework algorithmic accountability transparency order democr atic society function power political otherwise must held accountable much critical discourse use abuse algorithmic making relies investigative reporting whistleblowers identify existence issues algorithmic bias manipulation surveillance etc therefore recommend provision computational infrastructure access technical experts support data analysis algorithm reverse engineering efforts algorithmi accountability journalists whistleblower protection expanding current proposal include violation human rights protection prosecution grounds breaching copyright terms service served public interest accountability public sector use algorithmic decision making algorithmic systems increasing used public authorities improve efficiencies implement complex processes support based policy making due nature public sector responsibilities uses algorithmic systems potentially far reaching impacts sometimes involving weakest members society use algorithmic systems public services therefore requires extra levels transparency accountability public sector procurement also major source business many companies provides route incentivising commercial development transparent accountably systems therefore recommend algorithmic impact ass essments part public sector use procurement algorithmic systems algorithmic impact assessments framework designed help policymakers constituents understand algorithmic systems used within government assess intended use proposed implementation allow community members researchers raise concerns require mitigation framework draws history development assessments areas environmental policy privacy law ata protection also builds growing important research algorithmic accountability framework requires public authorities perform self algorithmic systems intends use likely require additional info rmation vendors order perform assessment adequately practice exact steps algorithmic impact assessment aia likely depend national context sensitivities specific public sector branch however general shape process likely include following publication public authority definition algorithmic system allows public understand authority decides systems subjected aias definition must periodically reviewed involve public participation definition published gone public review used asses currently used systems bid response tender procurement algorithmic system public authority public disclosure purpose scope intended use associated self assessm ent potential implementation timeline algorithmic system publication archiving decision review potential system publication start assessment process provides opportunity early external feedback help focus assessment pertinent public concerns performing publishing self system focus inaccuracies bias harms affected communities describes mitigation plans potential impacts stoa panel future science technology include proactive engagement public affected intended use system order better scope assessment publication plan meaningful ongoing access external researchers review system deployed even though aia attempts anticipate mitigate potential negative impacts introducing algorithmic decision system likely effects correctly anticipated therefore important ake sure system set way facilitates external monitoring ongoing basis public participation period evidence self system collected needs communicated public understandable way public given change voice concerns publication final algorithmic impact assessment issues raise public participation addressed documents pertaining aia must made publicl available renewal aias regular timeline algorithmic systems used may change time requiring new rounds analysis revisit changes significantly impacted algorithmic system operates new concerns may light addressed original aia researchers might develop new techniques analyse algorithmic systems public authority could leverage future review opportunity public challenge failure mitigate issues raised public participation period foreseeable outcomes aia finalised public given opportunity challenge public authority failure implement mitigating corrective measures raised aia ocess public also able challenge decision public authority decides system meet system criteria set triggering aias therefore recommend member states adopt algorithmic mpact assessments following process outlined report member states work public authorities ensure agency develops meaningful public education engagement process ensure stakeholders participate lgorithmic impact assessment recommend member states review existing recommendations public engagement including recommendations recently submitted new york city automated decision systems task force include appendix member states must develop implement accountability transparency procurement requirements acquisition algorithmic systems requirements allow public authorities access necessary technical information ill allow authorities perform robust algorithmic impact assessment regulatory oversight legal liability commercial development application algorithmic decision systems undergoing rapid growth times uncertain implica tions citizens society industry standards best practice largely yet exist space interpretation existing laws sometimes uncertain applied algorithmic making judicial experience context short supply much simply result rapid dynamic growth must allowed limit rights legal protections citizens business customers entitled governance framework algorithmic accountability transparency one approach protecting citizens negative impacts arising algorithmic decision making might impose private sector uses systems similar algorithmic impacts assessment regime recommending public sector authorities might make sense impact applications autonomous passenger vehicles political elections related services private sector applications financial administrative burden requirement would proportionate risks low uses algorithmic decision defined large extent ability algorithmic decision permanence impacts would preferable establish legal liability framework allows service providers accep greater tort liability exchange reduced transparency algorithmic impact assessment requirements order facilitate tiered regulatory regime would necessary establish specialised regulatory body expertise analysi algorithmic decision systems network external expert advisors primary tasks regulatory bod would establishing keep updated threat matrix assessing level regulatory oversight necess ary algorithmic decision system based factors impact outputs human rights implications scale use reversibility consequences etc application domain verify behaviour including ilure modes explainability decision outcomes transparency processing etc coordinating existing domain regulators data protection authorities consumer protection authorities etc regarding application existing laws involve use algorithmic decision processes coordinating standards setting organisations ieee industry civil society organisations identify relevant standards best procedures could used third certification algorithmic systems assessed requiring higher levels regulatory oversight quite requiring algorithmic impact assessments certification could become mandatory requirement similar certification less critical systems certification could serve communicate system trustworthiness end users reduce tort liability provider facilitating effectiveness tort liability mechanism eans regulating accountability algorithmic systems providing contact point citizens familiar legal procedures auditing algorithmic impact assessments high impact systems approve reject proposed uses algorithmic decision highly sensitive safety critical application domains private health algorithmic impact assessment private sector applications could follow similar process one proposed ublic sector possible difference various stages public disclosure could handled confidential communication regulatory body non disclosure agreement order safeguard vital trade secrets investigating suspecte cases rights violations algorithmic decision systems individual decision instances singular aberrant outcomes statistical decision patterns discriminatory bias investigations could triggered following lodg ing complaints basis evidence provided whistleblowers investigative journalists independent researchers including ngos academics stoa panel future science technology therefore recommend creation regulatory body algorithmic decision task establishing risk assessment matrix classifying algorithm types application domains according potential significant negative impact citizens investigating use algorithmic systems suspicion evidenc provided whistleblower infringement human rights advising regulatory bodies regarding algorithmic systems apply remit agencies systems classified causing potentially severe non impact requ ired produce algorithmic impact assessment similar public sector applications systems medium severity non impacts require service provider accept strict tort liability possibility reducing liability system certified compliant yet determined best standards global coordination algorithmic governance much digital economy use algorithmic systems characterised high degree cross global reach services built technologies successfully govern algorithmic systems therefore requires global dialogue collaboration across borders among rich poor countries avoid patchwork country regional approaches narrative industrial revolution dynamics however triggered refer arms race hypercompetitive environment strong pressures push computational efficiency functional performance algorithmic systems cost non considerations considerations directly contribute ability system perform task tra nsparency without multilateral negotiation risk competitive conditions regulatory intervention mandate algorithmic transparency may interpreted protectionist interventionism intended block market access foreign companies context global dynamics proposals new commerce trade agreement discussed wto well regional trade negotiations regional comprehensive economic partnership rcep others whi include clauses intellectual property protection would restrict access information regarding proprietary algorithms details restrictions remain determined due care required ensure clauses fre trade agreements cause problems accountability regulatory oversight algorithmic systems international tensions also arise use algorithmic systems social media bots micro political ads interventions informational integrity national electoral processes well offensive cyber operations order effectively respond interference without resorting bilateral escalation cyber operations important broad international community involved publicly establishing methods guidelines around attribution attacks defining proportionate responses though still early stage development efforts towards establishment trans national coordination governance algorithmic starting emerge fora oecd artificial intelligence expert group aigo world government summit lobal governance rou ndtable activities council europe governance framework algorithmic accountability transparency building international recognition leader data privacy legislation established introduction gdpr exemplified various gdpr inspired national privacy laws implemented globally currently uniquely positioned take lead establishing new international body help coordinate approaches algorithmic transparency accountability global level preliminary analyses requirements potential frameworks global coordination forum governance explored recent publications erdelyi goldsmith wendell marchant erdelyi goldsmith propose international artificial intelligence organization iaio would serve international forum discussion well international standards setting similar role itu telecommunications paper wendell marchant proposes approach framed around global coordinating committees gccs international gcc would work complementary regional bodies reinforce governance initiatives organizations ieee wef partnership various research centres therefore recommend establishment permanent global algorithm governance forum agf multi stakeholder dialog policy expertise related algorithmic systems associ ated technologies based principles responsible research innovation agf would provide forum coordination exchanging governance best related algorithmic decision adoption strong position trade negotiations protect regulatory ability investigate algorithmic systems hold parties accountable violations european laws human rights stoa panel future science technology conclusions algorithmic decision systems play increasingly import ant part public private sector decision processes potentially significant consequences individuals organisations societies whole used appropriately due care analysis impacts people lives algor ithmic systems including machine learning great potential improve quality efficiency products services order achieve however vitally necessary establish clear governance frameworks transparency accountability make sure risk benefits equitably distributed way unduly burden benefit particular sectors society within context transparency accountability tools promote fair algorithmic decisions providing foundations obtaining recourse meaningful explanation correction ways ascertain faults could bring compensatory processes level technical properties algorithmic systems reat deal discourse regarding inscrutability black box algorithms especially relation machine learning systems true complexity algorithmic processing combined scale variety data involved computations makes transparency sense explaining step algorithm unlikely lead directly informative outcome especially true system also involved use achine learning methods inferring statistical models directly data however technical method reducing algorithmic opacity extracting explanations system behaviour despite lack transparency understanding overall system understanding particular outcome may however require quite different approaches key idea keep mind goal transparency aim understand system works behaves understanding overall system obtain general understanding algorithmic decision process approaches include code review nput data analysis tatistical analysis outcomes analysis sensitivity inputs one challenge approaches likely difficult impossible without direct involvement system developers underst anding system works likely little value transparency individual outcomes case approaches providing explanation become important meaningful transparency outcomes reached technically challenging given mod ern computing systems regulatory requirements transparency may significantly limit ability use advanced computing techniques regulated purposes meaningful transparency behavio computing systems feasible prov ide important benefits mechanisms behavio ural transparency may need designed systems typically require participation system developers operators algorithmic accountability redress cases unfair treatment beyond technical challenges algorithm question actions implied specifications organisational structure surrounding algorithmic system accountability actions taken algorithmic systems may need different human actions differences largely governed particular application high level fast pace developments absence clearly established best practice technology standards suggests gov ernance framework following flexible rinciples approach likely provide better balance rules approach protecting fundamental rights citizens retaining freedom innovate new algorithmic methods based sys tematic consideration five governance categories emand market solutions side market solutions ompanies self organisation ranches coregulation tate intervention conclude dynamics digital economy currently lend demand side market solutions improving algorithmic transparency accountability efforts self organisation relating ethics algori thmic decision making currently convincing evidence governance framework algorithmic accountability transparency sufficient provide necessary safeguards citizens branch self possibly regulation supervisory involvement regulatory agencies starting take shape sector require establishment industry standards currently still development schemes certifying algorithmic decision systems exhibit unjustified bias also developed overa however role found state intervention guide innovation towards greater focus transparent explainable accountable methods type level state intervention carefully adjusted match algorithmic accounta bility required within context good harm risk systems bring despite problems consent mechanisms data privacy information measures including algorithmic literacy education label style notification algorithmic decisions scrutiny investigative journalism including whistleblowers remain vital elements delivering democratic agency citizen funding incentives research explainable decision algorithms well investigations impact algorithmic systems society would also provide important stimuli greater algorithmic accountability probably one important direct incentives related financial incentives role public service procurement algorit hmic systems strong potential push greater transparency accountability introducing measures lgorithmic impact assessment requirements systems significant impact public requirements eeping democratic responsibilities public service provision level direct intervention legislative means regulatory bodies potential approach combines risk assessment regulatory bod corresponding levels tort liability final element assessment governance frameworks algorithmic systems global nature developments algorithmic decision need global coordination highlighted order implement assessments four mutually reinforcing policy options proposed addressin awareness raising education watchdogs whistleblowers accountability public sector use algorithmic decision regulatory oversight legal liability private sector lobal dimension algorithmic governance stoa panel future science technology references burrell jenna machine thinks understanding opacity machine learning algorithms big data society dutton david gerard conroy review machine learning knowledge engineering review kinsella clare john mcgarry computer says technology accountability policing traffic stops crime social change wihlborg elin hannu larsson karin computer says case study automated decision public authorities system sciences hicss hawaii international conference ieee lahlou saadi marc langheinrich carsten röcker privacy trust issues invisible computers communications acm schneier bruce data goliath hidden attles collect data control world norton company medaglia carlo maria alexandru serbanati overview privacy security issues internet things internet things springer new york martínez fernando shahar avin miles brundage allan dafoe sean héigeartaigh josé hernández neglected dimensions progress arxiv preprint galliers robert sue newell shanks heikki topi datification human organisational societal effects strategic opportunities challenges algorithmic decision cohen nicole valor isation surveillance towards political economy facebook democratic communiqué lindh maria jan nolin information collect surveillance privacy implementation google apps education european educational research journal sculley jasper snoek alex wiltschko ali rahimi winner curse pace progress empirical rigor baum seth ben goertzel ted goertzel long human results expert assessment technological forecasting social change backer larry catá algorithm bind social credit data driven governance emergence operatin system global normative orders zambonelli franco flora salim seng loke wolfgang meuter salil kanhere governance smart cities conundrum potential pervasive computing solutions ieee techn ology society magazine yeung karen algorithmic regulation critical interrogation regulation governance velázqu yazdani pablo suárez supporting human rights arxiv preprint colaresi michael zuhaib mahmood robot lessons machine learning improve conflict forecasting journal peace research lepri bruno nuria oliver emmanuel letouzé alex pentland patrick vinck fair transparent accountable algorithmic decision processes philosophy technology governance framework algorithmic accountability transparency ananny mike kate crawford seeing without knowing limitations transparency ideal application algorithmic accountability new media society felici massimo theofrastos koulouris siani pearson acco untability data governance cloud ecosystems cloud computing technology science cloudcom ieee international conference vol ieee ieee global initiative ethics autonomous intelligent ystems discussion ethics autonomous intelligent systems version accessed september pasquale frank black box society secret algorithms control money information harvard university press ziewitz malte governing algorithms myth mess methods science technology human values lawrence lessig transparency new republic michael kearns seth neel aaron roth zhiwei steven preventing fairness gerrymandering auditing learning subgroup fairness brent mittelstadt sandra wachter could counterfactuals explain algorithmic dec isions without opening black box oxford internet instsitute blog jan counterfactuals nissenbaum helen computing accountability communications acm wendell wallach dangerous aster betsy cooper judges jeopardy could ibm watson beat courts game yale online louis matsakis researchers fooled google thinking rifle helicopter wired dec fooled yvonne baur brenda reid steve hunt fawn fitter end bias digitalist magazine jan tutt andrew fda algorithms march admin rev available ssrn barocas solon andrew selbst big data disparate impact cal rev ryan calo robotics lessons cyberlaw cal rev mittelstadt allo taddeo wachter floridi ethics algorithms mapping debate big data society forsyth conflict forsyth oup dynamics belmont wadsworth cengage learning friedler scheidegger venkatasubramanian possibility fairness arxiv preprint hayek new studies philosophy politics economics history ideas london routledge held justice care essential readings feminist ethics boulder westview press nussbaum sex social justice oxford oxford university press pérez unveiling meaning social justice colombia mexican law review stoa panel future science technology rawls justice fairness restatement cambridge belknap press harvard universit press reisch defining social justice socially unjust world families society novak defining social justice first things rasinski fair fair lue differences underlying public views social justice journal personal social psychology michael walzer spheres justice basic books foster rosenzweig microeconomics tec hnology adoption annual review economics gupta smart cities privacy trust ethics new cities retrieved kamgar lawson kamgar toward development face recognition system watchlist surveillance ieee transactions pattern analysis machine intelligence buolamwini gebru gender shades intersectional accuracy disparities commercial gender classification proceedings conference fairness accountability transparency pmlr simonite january comes gorillas google photos remains blind wired retrieved photos noble algorithms oppression new york nyu press cathy weapons math destruction big data increases inequality threatens democracy broadway books algorithmic justice league accessed september puri february mitigating bias models retrieved levin beauty contest judged robots like dark skin guardian retrieved intelligence contest oswald marion jamie grace sheena urwin geoffrey barnes algorithmic risk assessment policing models lessons durham hart model experimental proportionality information communications technology law roettgers february deepfakes create hollywood next sex tape scare variety retrieved romano aja peele simulated obama psa edged warning ake news australasian policing ibekabir june look twitter post retrieved hererorocher april saw tweet saying google unprofessional hairstyles work checked ones twitter post retrieved cohn october google image search gender bias problem huffington post retrieved governance framework algorithmic accountability transparency langston april ceo google image results shift gender biases university washington news retrieved vaidhynathan googlization everything berkeley berkeley press koene perez webb patel ceppi jirotka mcauley editorial responsibilities arising personalization algorithms orbit journal internet creating personalized web experience swayy shayna hodkin wired internet accessed internet thinks knows eli pariser new york times accessed better accounting algorithms choose news david sutcliffe oxford internet institute accessed trouble echo chamber online natasha singer new york times accessed colleone rossa arvidsson echo chamber public sphere predicting political orientation measuring political homophily twitter using big data journal communication hong kim political polarization twitter implications use social media digital governments government information quarterly algorithms discriminate claire cain miller upshot accessed datta tschantz datta automated experiments privacy settings arxi preprint sweeney discrimination online delivery communications association computing machinery cacm boyd crawford critical questions big data provocations cultural technological scholarly phenomenon information communication society dewey personal data points facebook uses target ads hington post retrieved data facebook google analytics opt browser add accessed september duckduckgo search engine track accessed september protonmail get encrypted email account accessed september andreou athanasios giridhari venkatadri oana goga krishna gummadi patrick loiseau alan mislove transparency mechanisms social media case study facebook expl anations network distributed system security symposium ndss meredith april facebook analytica timeline data hijacking scandal cnbc retrieved stoa panel future science technology lapowsky april facebook exposed million users cambridge analytica wired retrieved hogan social media giveth social media taketh away facebook friendships apis international journal communication chang june former facebook exec holding social media giant accountable bloomberg technology retrieved facebook gonzález hacking citizenry personality profiling big data election donald trump anthropology today rosenberg confessore cadwalladr march trump consultants exploited facebook data millions new york times retrieved analytica confessore april cambridge analytica cebook scandal fallout far new york times retrieved analytica scandal depre joseph may may production projection end democracy mcclenaghan dark ads election political parties targeting facebook bureau investigative journalism retrieved dark solon march google bad week youtube loses millions advertising row reaches guardian retrieved youtube extremist kehl guo kessler algorithms criminal justice system assessing use risk assessments sentencing responsive communities retrieved simourd use dynamic assessment instruments among long incarcerated offenders criminal justice behavior angwin larson mattu kirchner may machine bias propublica retrieved larson mattu kirchner angwin may analyzed compas recidivism algorithm propublica retrieved recidivism dieterich mendoza brennan compas risk scales accuracy equity predictive parity northpointe research department retrieved propublica speicher heidari hlaca gummadi singla weller bilal zafar unified approach quantifying algorith mic unfairness measuring individual group unfairness via inequality indices arxiv preprint spielkamp june inspecting algorithms bias mit technology review retrieved dwork cynthia moritz hardt toniann pitassi omer reingold ichard zemel awareness proceedings innovations theoretical computer science conference acm governance framework algorithmic accountability transparency berk richard hoda heidari shahin jabbari michael kearns aaron roth fairness criminal justice risk assessments state art arxiv preprint beriain use risk assessments sentences respect right due process critical analysis wisconsin loomis ruling law probability risk durham constabulary police written evidence submitted durham constabulary algorithms decision inquiry technology html noack may long would take read terms smartphone apps norwegians tried washington post retrieved yang ran chuang lin fujun feng time mutable attribute access control model jcp meyer may big privacy problem europe new data protection law expose fortune retrieved cutts may pagerank matt cutts gadgets goog seo retrieved ranking grgic zafar gummadi weller beyond distributive fairness algorithm decision feature selection procedurally fair learning proceedings thirty second aaai conference artificial intelligence new orleans louisiana usa alexander april google unprofessional hair result show racist guardian retrieved ssional results topping belam june campaign change stereotypical search engine images female football fans guardian retrieved fans guarino june google faulted racial bias image search results black teenagers washington post retrieved faulted webb patel rovatsos davoust ceppi koene dowthwaite portillo jirotka cano would pretty immoral choose random algorithm opening algorithmic interpretability transparency ethicomp kleinberg jon sendhil mullainathan manish raghavan trade fair determination risk scores chouldechova alexandra fair prediction disparate impact study bias recidivism prediction instruments larson angwin july technical response northpointe propublica retrieved nikhil sonnad google translate gender bias pairs lazy examples quartz translates hardworking lee march tay microsoft issues apology racist chatbot fiasco bbc news retrieved stoa panel future science technology courtland june bias detectives researchers striving make algorithms fair nature retrieved glauner valtchev state impact biases big data arxiv preprint hautala google removes autocomplete suggestions jews women cnet retrieved removes suggestions miller july algorithms discriminate new york times retrieved goodman flaxman european union regulations algorithmic decision explanation magazine doi čuk van waeyenberge european legal framework algorithmic high frequency trading mifid mar global approach anaging risks modern trading paradigm european journal risk regulation bernard december first bill examine bias government agencies passed new york city business insider retrieved acebook research accessed september artificial intelligence google principles google access september wagner ethics escape regulation ethics ethics hildebrandt profiling cogitas ergo sum amsterdam amsterdam university press ieee ethically aligned design ieee global initiative ethical considerations artificial intelligence autonomous systems retrieved owen macnaghten stilgoe responsible research innovation science society science society society science public policy von schomberg vision responsible innovation owen heintz bessant eds responsible innovation london john iley forthcoming dressel farid accuracy fairness limits predicting recidivism science advances doi himabindu lakkaraju jon kleinberg jure leskovec jens ludw sendhil llainathan selective labels problem evaluating algorithmic predictions presence unobservables proceedings acm sigkdd international conference knowledge discovery data mining kdd acm new york usa doi mehta pimplikar singh varshney visweswariah efficient multifaceted screening job applicants proceedings international conference extending database technology new york acm kroll barocas felten reidenberg robi nson accountable algorithms university penns ylvania law review patent socioeconomic group classification based user features retrieved parser jackson peter introduction expert systems addison longman publishing governance framework algorithmic accountability transparency cross industry standard process data mining crisp consortium azar neural comput applic vapnik chervonenkis theory pattern recognition nauka moscow yishay mansour pessimistic decision tree runing proceedings machine learning koiran pascal eduardo sontag neural networks quadratic dimension advances neural information processing systems murat kantarcio ǧlu jiashun jin chris clifton data mining results violate privacy proceedings tenth acm sigkdd international conference knowledge discovery data mining kdd acm new york usa dwork mcsherry nissim smith calibrating noise sensitivity private data analysis halevi rabin eds theory cryptography tcc lecture notes computer science vol springer berlin heidelberg cynthia dwork vitaly feldman moritz hardt toniann pitassi omer reingold aaron roth guilt data reuse commun acm march doi mitchell cohen hruschka talukdar yang betteridge carlson dalvi gardner kisiel krishnamurthy lao mazaitis mohamed nakashole platanios ritter samadi settl wang wijaya gupta chen saparov greaves welling ending learning commun acm april doi sullivan brendan gopikrishna karthikeyan zuli liu wouter lode paul massa mahima gupta group classification based user features patent application filed february doshi finale mason kortz ryan budish chris bavitz sam gershman david stuart schieber james waldo david weinberger alexandra wood law role explanation arxiv preprint pfleeger shari lawrence joanne atlee software engineering theory practice pearson education india mäntylä mika casper lassenius types defects really discovered code reviews ieee transactions software engineering moritz beller alberto bacchelli andy zaidman elmar juergens modern code reviews open source projects problems fix proceedings working conference mining software repositories msr acm new york usa doi saltelli andrea stefano tarantola francesca campolongo marco ratto sensitivity analysis practice guide assessing scientific models john wiley sons chen hongyi dundar kocaoglu sensitivity analysis algorithm hierarchical decision models european journal operational research iman ronald jon helton investigation uncertainty sensitivity analysis techniques computer models risk analysis ling huang anthony joseph blaine nelson benjamin rubinstein tygar adversarial machine learning proceedings acm workshop security artificial intelligence aisec acm new york usa szegedy christian wojciech zare mba ilya sutskever joan bruna dumitru erhan ian goodfellow rob fergus intriguing properties neural networks arxiv preprint stoa panel future science technology fawzi fawzi frossard mach learn zhang junzhe elias bareinboim fairness decision causal explanation formula aaai conference artificial intelligence america association advancement science book new science cause effect pressman roger software engineering practitioner approach palgrave macmillan fabian benduhn thomas thüm lte lochau thomas leich gunter saake survey modeling techniques formal behavioral verification software product lines proceedings ninth international workshop variability modelling intensive systems vamos acm new york usa pages pages xavier leroy formal verification realistic compiler commun acm july doi gerwin klein june andronick kevin elphinstone toby murray thomas sewell rafal kolanski gernot heiser comprehensive formal verification microkernel acm trans comput syst article february pages white neil stuart matthews roderick chapman formal verification seedling ever flower phil trans soc jtc software systems engineer ing international organization standardization iso retrieved capability maturity model integration cmmi institute ieee standards transparency autonomous systems ieee winfield alan marina jirotka case ethical black box conference towards autonomous robotic systems springer cham amant robert ralph brewer maryanne fields tracing moral agency robot behavior arl army research laboratory aberdeen proving ground united states fair isaac corporation fico score fico marco tulio ribeiro sameer singh carlos guestrin trust explaining predictions classifier proceedings acm sigkdd international conference knowledge discovery data mining kdd acm new york usa doi diakopoulos nicholas investigation black boxes tow center digital journalism accountability mukherjee arjun yelp fake review filter might proceedings international conference weblogs social media icwsm shirriff ken hacker news ranking really works scoring controversy penalties november guha saikat challenges measuring online advertising systems proc internet measurement conference imc baker paul amanda potts white people thin lips google perpetuation stereotypes via complete search forms critical discourse studies governance framework algorithmic accountability transparency list open source tools machine learning interpretability hosted github machine ibm research trusted fairness open source toolkit chiandussi codegone ferrero varesio comparison multi optimization methodologies engineering applications computers mathematics applications optimization mandal mukhopadhyay dutta multi optimization evolutionary hybrid framework springer francis bekera metric frameworks resilience analysis engineered infrastructure systems reliability engineering system safety pieters explanation trust tell user security ethics inf technol tufekci algorithmic harms beyond facebook google emergent challenges computational agency telecomm high tech ethics certifications program autonomous intelligent systems ecpais burgemeestre brigitte joris huls tijn yao tan rule versus principle regulatory compliance jurix korobkin behavioral analysis legal form rules principles revisited oregon law review black julia forms radoxes principles based regulation september lse legal studies working paper available ssrn naic response treas november available ojo building trust management overcoming paradoxes principles based regulation banking financial services policy report ford newgoverna nce compliance principles securities regulation american business law journal schwarcz principles paradox european business organization law review cunningham prescription retire rhetoric principles systems corporate law securities regulation accounting technical report boston college law school florian saurwein natascha michael latzer governance algorithms opti ons limitations info vol issue doi permanent link document rothstein henry phil irving terry walden roger yearsley risks risk regulation insights environmental policy domain environment international posiva final disposal spent nuclear fuel environmental impact assessment report general summary helsinki finland posiva available knight john safety critical systems challenges directions proceedings international conference software engineering acm stoa panel future science technology wiad joseph software reuse safety primer ieee aerospace electronic systems magazine jacklin stephen johann schumann pramod gupta lowry john bosworth eddie zavala kelly hayhurst celeste belcastro christine belcastro verification validation certification challenges adaptive flight control system software aiaa guidance navigation control conference exhibit mitka eleftheria antonios gasteratos nikolaos kyriakoulis spyridon mouroutsos safety certification requirements domestic robots safety science reed chris online offline equivalence aspiration achievement international journal law information technology ibm watson health accessed september ibm watson regrach regulatory technology banking financial markets accessed september latzer saurwein slominski selbst und mediamatiksektor alternative regulierungsformen zwisc hen markt und staat westdeutscher verlag wiesbaden latzer saurwein slominski regulation remixed institutional change self mediamatics sector communications strategies vol bartle vass self regulatory state survey policy practice university bath school management nicholas diakopoulos algorithmic accountability journalistic investigation computational power structures digital journalism doi report aaron rieke miranda bogen david robinson february public scrutiny automated decisions early lessons emerging methods upturn omidyar network report omated katz michael carl shapiro systems competition network effects journal economic perspectives zittrain future internet stop new yale university press master switch rise fall digital empires new york knopf brown ian christopher marsden regulating code good governance better regulation information age mit press breese john david heckerman carl kadie empirical analysis predictive algorithms collaborative filtering proceedings fourteenth conference uncertainty artificial intelligence morgan kaufmann publi shers domingos pedro useful things know machine learning communications acm awad naveen farag mayuram krishnan personalization privacy paradox empirical evaluat ion information transparency willingness profiled online personalization mis quarterly heng xin robert luo john carroll mary beth rosson personalization privacy paradox exploratory study decision process location marketing decision support systems governance framework algorithmic accountability transparency ebenezer mercy elizabeth devakirubai impact consumer privacy behavior purchase decision process smart home internet thin iot devices phd hull gordon successful failure foucault teach privacy self world facebook big data ethics information technology wilson dave oseph valacich unpacking privacy paradox irrational decision within privacy calculus kollewe marmite maker unilever threatens pull ads facebook google guardian last accessed september unilever steurer reinhard role governments corporate social responsibility characterising public policies csr europe policy sciences implement automated decision system draft government canada digital playbook draft decision reisman dillon jason schultz kate crawford meredith whittaker algorithmic impact assessments practical framework public agency accountability mayor blasio announces first task force examine automated decision systems used city official website city new york accessed september examine schaar privacy design identity information society vol cavoukia privacy design origins meaning prospects ensuring privacy trust information era available accessed august munson resnick presenting diverse political opinions much proceedings acm chi conference human factors computing systems atlanta georgia schedl hauger schnitzer model serendipitous music retrieval proceedings workshop context retrieval recommendation lisbon resnick kelly garrett kriplean munson stroud bursting filter bubble strategies promoting divers exposure proceedings conference computer cooperative work companion san antonio texas chowdhury tackling challenge ethics digital perspectives accenture blog accessed september power tester accenture testing service accessed septemb matching talent opportunity bias pymetrics accessed september shankland facebook starts building ethical compass cne accessed september neil risk consulting algorithmic uditing accessed september acm conference fairness accountability transparency acm fat accessed september stoa panel future science technology artificial intelligence ethics society conference accessed september vallor ethical toolkit practice markkula center applied ethics santa clara university digital decisions center democracy technology cdt accessed september dialogues ethics princeton university center human values accessed september deepmind ethics society accessed september deepmind ethics society lin selinger inside google mysterious ethics board forbes availab googles accessed september bracha pasquale federal search commission access fairness accountability law search cornell law review vol granka politics search decade retrospective information society vol rieder control search engines symmetry confidence international review information ethics vol ftc federal trade commission data brokers call transparency accountability available accountabili tyreport trade accessed august anthes gary data brokers watching communications acm tiku tech workers dissent going viral wired accessed september tech murdock project maven google urged abandon military drone program newsweek accessed september urged military conger wakabayashi google employees protest secret work censored search engine china new york times accessed september simonite google sets limits use allows def ense work wired accesses september sets cong google plans renew contract project mave controversial pentagon drone imaging program accessed september plans former google facebook staff launch anti lobby red herring accessed evangelista check phone times day tech insiders say design san francisco chronicle accessed september phone wilson google plan make tech less addictive fastcompany accessed september weber apple trying make iphone less addictive gizmodo accessed september governance framework algorithmic accountability transparency sandoval amazon employees including senior software engineers gned letter asking jeff bezos stop selling facial recognition software police accesses september amazon bezos recognition wexler james tool free probing machine learning models google blog code fairness open source toolkit ibm accessed septemb teich paul intelligence reinforce bias cloud giants announce tools fairness forbes force anderson ronald code ethics professional conduct communications acm chatila raja kay firth john havens konstantinos karachalios ieee global initiative ethical considerations artificial intelligence autonomous systems standards ieee robotics automation magazine schwab logo like organic sticker algorithms fastcompany accessed september hern alex partnership formed google facebook amazon ibm microsoft guardian last accessed ttps acm code ethic professional conduct acm accessed september ieee code conduct ieee accessed september future life institute asilomar principles future life institute online available fuerguson thornley gibb beyond codes ethics international journal information management journal information professionals journal available top five ethical moral principles digital transformation blog april accessed mind universe robo society blessing curse delft accessed september zittrain ito ethics governance artificial intelligence mit media lab accessed september artificial intelligence philosophy ethics impact stanford university accessed september baron justus daniel spulber technology standards standard setting organizations introduction searle center database journal economics management strategy attia john dhadesugoor vaman matthew sadiku engineering standards introduction electrical computer engineering students european scientific journal esj standards accessed september stoa panel future science technology software testing international software testing standard accessed september ieee ieee standard system software hardware verification validation ieee standards association accessed september mily information security management systems international standards organization iso accessed september information html cybersecurity standards governance accessed september systems oftware engineering life cycle processes requirements engineering international standards organization iso accessed september eee ieee standard software user documentation ieee standards association accessed september international standard software engineering software life cycle processes maintenance ieee standards association accessed september ieee computer society ieee std ieee standard software reviews audits ieee standards association accessed september standards governance accessed september ieee standards algorithmic bias considerations accessed september jtc artificial intellig ence international standards organization iso accessed september forsstrom certification medical software would useful medical informatics research centre university turku turku december heck klabbers van eekelen software qual ferreira gabriel software certification practice standards applied software engineering companion icse international conference ieee common criteria information technology security evaluation version revision online available rtca considera tions airborne systems equipment certification radio technical commission aeronautics anisetti marco claudio ardagna ernesto damiani filippo gaudenzi semi trustworthy scheme continuous cloud service certi fication ieee transactions services computing stephanow philipp koosha khajehmoogahi towards continuous security certification software applications using web application testing techniques advanced informati networking applications aina ieee international conference ieee edwards lilian michael veale enslaving algorithm right explanation right better decisions ieee securi privacy citron technological due process washington university law review vol governance framework algorithmic accountability transparency crawford schultz big data due process toward framework redress predictive privacy harms boston college law review vol hunter philip big health data sale trade personal health medical data expands becomes necessary improve legal frameworks protecting patient anonymi handling consent ensuring quality data embo reports neff gina peter nagy automation algorithms talking bots symbiotic agency case tay international journal communication kramer adam jamie guillory jeffrey hancock experimental evidence scale emotional contagion social networks proceedings national academy sciences partnership accessen september shead biggest mystery right ethics board google set buying deepmind business insider accessed september aiethics hern whatever happened deepmind ethics board google promised guardian accessed september deepmind board meet partners partnership accessed september hirsch dennis law policy online privacy regulati self seattle rev guidelines online privacy policies online privacy alliance last visited sept lee edward recognizing rights real time role google right forgotten ucdl rev albareda laura corporate responsibility governance accountability self coregulation corporate governance international journal business society mandelkern group better regulation final report november available hanson david marking product standards world trade edward elgar publishing marking europe european union accessed september felini damiano beyond today video game rating systems critical approach pegi esrb proposed improvements games culture brand jeffrey comparative analysis ratings classification censorship selected countries around world weiss martin kristin archick data privacy safe harbor privacy shield tracol xavier privacy shield saga continues computer law security review european governance white paper com final july available environmental impact assessment eia euro pean commission environment accessed september stoa panel future science technology glasson john riki therivel introduction envi ronmental impact assessment routledge brown ian christopher marsden regulating code good governance better regulation information age mit press senden soft law self regulation european law meet electronic journal comparative law hüpkes eva regulation self journal business law lievens eva jos dumortier patrick ryan minors new media european approach davis juv pol frydman hennebel lewkowicz public strategies internet united states europe china tarlach mcgonagle practical regulatory issues facin media online spreading word internet answers questions christiane hardy christian möller eds neil gunningham darren sinclair leaders laggards next environmental regulation lyle scruggs sustaining abundance environmental performance industrial democracies joseph rees reforming workplace study self occupational safety bert koops miriam lips sjaak nouwt corien prins maurice schellekens self starting point starting point itc regulation deconstructing prevalent policy one liners bert koops corien prins maurice schellekens miriam lips colin bennett charles raab governance privacy policy instruments global perspective lemley mark david mcgowan legal implications network economic effects rev varian hal industries market structure university california berkeley browne glenn nirup menon network effects social dilemmas technology industries ieee software peo ple power technology digital understanding report doteveryone accessed spetember lepri bruno nuria oliver emmanuel letouzé alex pentland patrick vinck fair transparent accountable algorithmic decision processes philosophy tec hnology klawitter erin eszter hargittai like learning whole language role algorithmic skills curation creative goods international journal communication boyd crawfo critical questions big data provocations cultural technological scholarly phenomenon information communication society bhargava deahl letouze noonan sangokoya shoup bey ond data literacy reinventing community engagement empowerment age data data alliance white paper series url literacy burrell machine thinks understanding opacity machine learning algorithms big data society governance framework algorithmic accountability transparency elvira perez vallejos ansgar koene virginia portillo liz dowthwai monica cano young people policy recommendations algorithm fairness proceedings acm web science conference pages isbn doi eslami rickman vaccaro aley asen vuong karahalios sandvig always assumed really close reasoning invisible algorithms news feeds proceedings annual acm conference human factors computing ystems new york association computing machinery papsdorf christian sebastian jakob ein kampf gegen windmühlen jugendliche und junge erwachsene umgang mit algorithmen und überwachung internet kommunikation gesellschaft moses lyria bennett algorithm dangerous leading edge ieee technology society magazine baker jamie beyond information age duty technology competence algorithmic society scl rev buchanan taylor machine learning policymakers paper cyber security project belfer center learning oliver nuria tyranny data bright dark sides algorithmic decision public policy making assessing impact machine intelligence human behaviour interdisciplinary endeavour pasquale black blox society secret algorithms control money information harvard university press rainie lee anderson janna need grows algorithmic literacy transparency oversight transparency kaminski margot right explanation explained lawarxiv june selbst andrew julia powles information right explanation international data privacy law ananny mike kate crawford seeing without knowing limitations transparency ideal application algorithmic accountability new media society holland sarah ahmed hosny sarah newman joshua joseph kasia chmielinski dataset nutrition label framework drive higher data quality standards arxiv preprint yang julia stoyanovich abolfazl asudeh bill howe jagadish gerome miklau nutritional label rankings proceedings international conference management data acm perel maayan niva elkin box tinkering beyond disclosure algorithmic enforcement rev ananny mike kate crawford seeing without knowing limitations transparency ideal applicat ion algorithmic accountability new media society diakopoulos nicholas accountability algorithmic media transparency constructive critical lens transparent data mining big small data springer cham tesfay welderufael peter hofmann toru nakamura shinsaku kiyomoto jetzabel serna read agree privacy policy benchmarking using machine learn ing gdpr companion web conference web conference international world wide web conferences steering committee stoa panel future science technology jones rhianne neelima sailaja lianne kerlin probing design spac usable privacy policies qualitative exploration reimagined privacy policy proceedings british computer society human computer interaction conference bcs learning development cranor hoke leon worth reading analysis online advertising companies privacy policies presented research conference communication information internet policy available rader emilee kelley cotter janghee cho explanations mechanisms supporting algorithmic transparency proceedings chi conference human factors computing systems acm john mcginnis accelerating rev data transparency lab accessed september gunning explainable artificial intelligence xai darpa accessed september international neuroinformatics coordinating facility incf accessed september brundage miles shahar avin jack clark helen toner peter eckersley ben garfinkel allan dafoe malicious use artificial intelligence forecasting prevention mitigation arxiv preprint cambridge analytica guardian accessed september winston palantir secretly using new orleans test predictive policing echnology verge accesses september predictive new lecher happens algorithm cuts health care verge accessed september cerebral openschufa shedding light germany opaque credit scoring algorithmwatch accessed september howard alexander benjamin art science data journalism arthur brian technologies increasing returns lock historical events economic journal foxon timothy technological lock role innovation handbook sustainable development jaffe adam karen palmer environmental regulation innovation panel data study review economics statistics horbach jens christian rammer klaus rennings innovations type environmental impact role regulatory technology push market pull ecological economics van lieshout marc sophie emmert innovation opportunity goodman bryce seth flaxman european union regulations algorithmic decision right explanation arxiv preprint gulbenkoglu build explainable dataethics accessed september governance framework algorithmic accountability transparency kotonya gerald ian sommerville require ments engineering processes techniques glinz martin functional requirements requirements engineering conference ieee international ieee chung lawrence julio cesar ampaio prado leite functional requirements software engineering conceptual modeling foundations applications springer berlin heidelberg wachter sandra brent mittelstadt luciano floridi right explanation automated decision exist general data protection regulation international data privacy law edwards lilian michael veale slave algorithm right explana tion probably remedy looking duke tech rev vedder anton laurens naudts accountability use algorithms big data environment international review law computers technology loi octobre pour une république numérique circulation des données savoir legifrance accessed september ribeiro trust explaining predictions classifier proceedings acm sigkdd international conference knowledge discovery data mining montavon nonlinear classification decisions deep taylor decomposition pattern vol ryan poplin avinash varadarajan katy blumer yun liu michael mcconnell greg corrado lily peng dale webster predicting cardiovascular risk factors retinal fundus photographs using deep learning nature biomedical engineering vol march preprint available weinberger david optimization explanation maximizing benefits machine learning without sacrificing intelligence ation čerka paulius jurgita grigienė gintarė sirbikytė liability damages caused artificial intelligence computer law security review schmehl ian stephen lunce culpabilities medical diagnostic software review legal implications amcis proceedings price nicholson medical malpractice black medicine february glenn cohen big data health law bioethics cambridge university press michigan public law research paper available ssrn ryan calo robotics lessons cyberlaw cal rev cass sunstein ethics nudging yale reg eric posner glen weyl fda financial innovation applying insurable interest doctrine first financial markets rev wachter sandra mittelstadt brent right reasonable inferences thinking data protection law age big data september columbia business law review forthcoming availab ssrn brent daniel mittelstadt luciano floridi ethics big data current foreseeable issues biomedical contexts science eng ineering ethics stoa panel future science technology paul ohm fourth amendment world without privacy miss pauline kim data discrimination work mittelstadt luciano floridi informational nature personal iden tity minds machines sandra wachter privacy primus inter pares privacy precondition self personal fulfilment free enjoyment fundamental human rights social science research network ssrn scholarly paper accessed september urteil des ersten senats vom bverfg dezember bvr volkszählungsurteil url judgement german constitutional court bverfg urteil vom dezember bvr bvr bvr bvr bvr bvr volkszählungsurteil omer tene jules polonetsky big data privacy user control age analytics tech intell prop xxvii joris van hoboken search engine freedom implications right freedom expression legal governance web search engines kluwer law international den haag joris van hoboken proposed right forgotten seen perspective right remembe freedom expression safeguards converging information environment prepared european commission amsterdam larsson stefan governance need consumer empowerment data markets internet poli review streel alexandre lise sibony towards smarter consumer protection rules digital services larsson giants blindfolded dwarfs information data driven markets lith new economic models tools political decision makers dealing changing european economies brussels belgium european liberal forum asbl available larsson sustaining legitimacy trust data society ericsson technology review available rhoen beyond consent improving data protection consumer protection law internet policy review pasquale september exploring fintech landscape written testimony frank pasquale united states senate committee banking housing urban affairs available european data protection supervisor meeting challenges big data call transparency user control data protection accountability opinion brussels european data protection supervisor available king forder data analytics consumer profiling finding appropriate privacy principles disco vered data computer law security review naveen kashyap pfizer united states lost canada challenges pharmaceutical industry cooley prac clinical john joseph enforcement related marketing use drugs devices going health life sci governance framework algorithmic accountability transparency nicholson price making making drugs innovation policy pharmaceutical manufacturing rev daniel goldberg aspirin turn century wonder drug distillations summer accessed september miracle scherer matthew artificial intelligence systems risks challenges competencies strategies harv tech aviation accident reports national transportation safety board accessed september jack smith crime tool predpol amplifies racially biased policing study shows mic accessed september prediction study andrew ferguson rise big data policing surveillance race future law enforcement new york nyu press james vincent uses deepmind cut center energy bills verge july deepmind dutchnews dutch councils use algorithms identify potential social security fraudsters april kade crockford risk assessment tools criminal justice system inaccurate unfair unjust aclu massachusetts march system virginia eubank automating inequality high tools profile police punish poor new york martin press nazgol ghandnoosh black lives matter eliminating racial inequity criminal justice system washington sentencing project insha rahman state bail breakthrough year bai reform vera institute justice pretrial dillon reisman jason schultz kate crawford meredith whi ttaker impact assessments practical framework public agency accountability april ali winston transparency advocates win release nypd predictive policing documents intercept nypd crime leonard ortolano anne shepard environmental impact assessment challenges opportunities impact assessment united nations guiding principles business human rights implementing united nations protect respect remedy framework kenneth bamberg deirdre mulligan privacy decision administrative authorities chicago rev protection impact assessments information commissioner office accessed march data stoa panel future science technology protection impact assessment art regulation european parliament counci april protection natural persons regard processing personal data free movement data repealing directive general data protection regulation catherine crump policy making procurement rev european commission commission recommendation atila abdulkadiro yeon che yosuke yasuda expanding choice school choice american economic journal microeconomics neil thakral public allocation problem technical report harvard university quality assurance government analytical models final report treasury march aaron reike miranda bogen david robinson public scrutiny automated decisions early lesson emerging methods upturn omidyar network methods april glaser trained slate batya friedman helen nissenbaum bias computer systems acm transactions information systems tois steven chanenson jordan hyatt use risk assessment sentencing plications research policy villanova policy research paper tions art regulation european parliament council april protection natural persons regard processing personal data free movement data repealing directive general data protection regulation department energy eere project management center nepa determination department agriculture forest service nepa categorical exclusion checklist new york city council hearing testimony federal trade commission big data tool inclusion exclusion understanding issues january david mccabe lawmakers trying understand giants algorithms work axios tech eric holder speech national association criminal defense lawyers annual meeting state criminal justice network conference philadelphia department justice defense governance framework algorithmic accountability transparency john fry anne maxwell sarah apere paddy mcaweeney luke mcsharry ainhoa gonz technical summaries care attention iaia annual conference saunders predictions put practice danielle keats citr data regulated technological due process times july due citron technological due process citron pasquale scored society crawford schultz data due process diakopolous principles accountable algorithms social impact statement algorithms fatml accessed march erin griffith tech bubble wired tech katherine fink opening government black boxes freedom information algorithmic accountability information communication society nicholas diakopoulos need know algorithms government uses make important decisions conversation may kamira laachir france ethnic minorities question exclusion mediterranean politics march frédérick douzet jérémy robine les jeunes des banlieues neighborhood effects immigrant youth experience france journal ltural geography clare foran france built inequality cities citylab november philippe sotto top french court police illegally checked minority men associated press november solon barocas kate crawford aaron shapiro hanna wallach problem bias allocative representational harms machine learning sigcis conference paper october kate crawford trouble bias nips conference keynote december tom simonite comes gorillas google photos remains blind wired january photos kenneth harney code redlining sweeping view risk washington post february timnit gebru jamie morgenstern briana vecchione jennifer wortman vaughan hanna wallach hal daumeé iii kate crawford datasheets datasets arxiv preprint jessica saunders priscillia hunt john hollywood predictions put practice quasi experimental evaluation chicago predictive policing pilot journal experimental criminology danielle keats citron big data regulat technological due process times july due wexler life liberty trade secrets ram innovating criminal justice stoa panel future science technology david levine people trade secrets telecomm tech rev jan whittington ryan calo mike simon jesse woo push pull spill tran sdisciplinary case study municipal open government berkeley tech mike ananny kate crawford without knowing limitations transparency ideal application algorithmic accountability new media society christian sandvig kevin hamilton karrie karahalios cedric langbort auditing algorithms research methods detecting discrimination internet platforms data discrimination converting critical concerns productive inquiry devin pope justin sydnor implementing anti policies statis tical profiling models american economic journal economic policy kristian lum william isaac predict serve significance conference fairness accountability transparency symposium july symposium july executive office president big data report algorithmic systems opportunity civil rights may pdf department justice office inspector general phoebe friesen lisa kearns barbara redman arthur caplan extending ethical strides tribal irbs bronx community research review board american urnal bioethics checking box mentality common critique workplace sexual harassment training yuki noguchi lawyers say sexual harassment training fails things considered npr fails rebecca wexler life liberty trade secrets intellectual property criminal justice system stan forthcoming natalie ram innovating criminal justice northwestern rev forthcoming nicole ozer santa clara county passes landmark law shut secret surveillance aclu northern california june landmark environmental policy act review process environmental protection agency accessed june ental directive european parliament council february public procurement public contracts directive directive european parliament council february award concession contracts concessions contracts directive directive european parliament council february procurement entities operating ter energy transport postal services sectors utilities directive governance framework algorithmic accountability transparency iso family quality management international standards organization iso accessed october quality ieee global initiative ethics autonomous intelligent systems ieee standards association acces sed october jtc artificial intelligence internationa standards organization iso accessed september guynn jessica google photos labeled black people gorillas usa today july accessed october apologizes black hill kashmir target figured teen girl pregnant father forbes february figured algorithms censorship carte edri july freeman katherine algorithmic injustice wiscon sin supreme court failed protect due process rights state loomis north carolina journal law technology rightscon toronto toronto canada toronto declaration protecting rights equality non machine learning systems accessnow may rightscon toronto canada declaration discrimination evidence submitted human rights big data technology project available house lords inquiry ariticial intelligence kent human rights digital age perils big data technology part available rights last accessed ohchr human rights based approach data leaving one behind development agenda guidance note data collection disaggregation available last accessed harris wyndham data rights responsibilities human rights perspective data sharing journal empirical research human research ethics office united nations high commissioner human rights frequently asked questions human rights approach development cooperation united nations new york geneva available last accessed human rights approach development cooperation towards common understanding among united nations agencies second inter workshop stamford usa may available annex last accessed harrison james human rights measurement reflections current practice future potential human rights impact asse ssment journal human rights practice schwab klaus industrial revolution world economic forum new york crown business dutton tim overview national strategies medium june stoa panel future science technology hughes mark artificial intelligence arms race bad guys win world economic forum november earms tomasik brian international cooperation arms race foundational research institute december updated february horowitz michael artificial intelligence international competition balance power may texas national security review brundage miles shahar avin jack clark helen toner peter eckersley ben garfinkel allan dafoe malicious artificial intelligence forecasting prevention mitigation arxiv preprint stevens tim cyberweapons emerging global governance architecture palgrave communications volume article number sparrow robert plowshares arms control robotic weapons ieee technology society magazine cave stephen seán sohéigeartaigh race strategic advantage rhetoric risks conference artificial intelligence ethics society chung lawrence brian nixon eric john mylopoulos non requirements software engineering vol springer science business media downes larry gdpr end internet grand bargain mishra eha localization laws digital world data protection data protectionism forward laws botha johnny grobler jade hahn mariki eloff high comparison south african protection personal information act international data protection laws international conference management leadership governance academic conferences publishing limited forward greenleaf graham influence european data privacy standards outside europe implications globalization convention international data priva law stackowiak robert diversity matters remaining relevant tech career apress berkeley zou james londa schiebinger sexist racist time make air nature doi topics africa woolley samuel automating power social bot interference global politics first monday governance framework algorithmic accountability transparency forelle michelle phil howard andrés monroy saiph savage political bots manipulation public opinion venezuela arxiv preprint matz michal kosinsk gideon nave david stillwell psychological targeting effective approach digital mass persuasion proceedings national academy sciences forelle michelle phil howard andrés monroy saiph savage political bots manipulation public opinion venezuela arxiv preprint howard philip samuel woolley ryan calo algorithms bots political communication election challenge automated political communication election law administration journal information technology politics lin herbert offensive cyber operations use force nat sec pol patton cliffard impact cyber espionage changing perceptions vis transatlantic phd blank stephen cyber war information war russe understanding cyber conflict analogies hamilton logan beyond ballot current gaps international law regarding foreign state hacking influence foreign election int lam christina slap wrist combat ting russia cyber attack presidential election bcl rev buse mihaiela european union cyber security globalized world international scientific conference strategies xxi vol carol national defence university väisänen teemu christian braccini michael sadloň hayretdin bahşi agostino panico kris van der meij digital forensics digital intelligence evidence collection special operations common mackenzie facebook cambridge analytica let high mark impunity lse business review council commerce council commerce fung archon mary graham david weil full disclosu perils promise transparency cambridge university press copeland damian luke reynoldson demon legal review weapons artificial intelligence pandora box contribute twomey paul building hamburg statement roadmap digitalization toward framework artificial intelligence workplace economics discussion papers stoa panel future science technology vienna declaration programme action adopted world conference human rights vienna june available last accessed office united nations high commissioner human rights core international human rights instruments monitoring bodies undated available last accessed oecd artificial intelligence expert group aigo global governance roundtable world government summit dubai council europe artificial intelligence erdelyi olivia johanna goldsmith judy regulating artificial intelligence proposal global solution february conference ethics society aies february new orleans usa available ssrn wallach wendell marchant gary agile model international national governance robotics february conference ethics society aies february new orleans usa wilson dave joseph valacich unpacking privacy paradox irrational decision within privacy calculu lepri bruno nuria oliver emmanuel letouzé alex pentland patrick vinck fair transparent accountable algorithmic decision processes philosophy technology klawitter erin eszter hargittai like learning whole language role algorithmic skills curation creative goods international journal communication boyd crawford critical questions big data provocations cultur technological scholarly phenomenon information communication society bhargava deahl letouze noonan sangokoya shoup beyond data literacy reinventing community engagement empowerment age data data alliance white paper series url literacy burrell machine thinks understanding opacity machine learning algorithms big data society elvira perez vallejos ansgar koene virginia portillo liz dowthwaite monica cano young people policy recommendations algorithm fairness proceedings acm web science conference pages isbn doi eslami rickman vaccaro aleyasen vuong karahalios sandvig always assumed really close reasoning invisible algorithms news feeds proceedings annual acm conference human factors computing systems new york association computing machinery papsdorf christian sebastian jakob ein kampf gegen windmühlen jugendliche und junge erwachsene umgang mit algorithmen und überwachung internet kommunikation gesellschaft moses lyria bennett algorithm dangerous leading edge ieee technology society magazine baker amie beyond information age duty technology competence algorithmic society scl rev governance framework algorithmic accountability transparency buchanan taylor machine learning policymakers paper cyber security project belfer center learning naughton john drone strike dished algorithm guardian february drones nick hopkins revealed facebook internal rulebook sex terrorism violence guardian may mike isaac uber deceives authorities worldwide new york times mar mike isaac justice department expands inquiry uber greyball tool new york times mar chouldechova alexandra fair prediction disparate impact study bias recidivism prediction instruments big data wadsworth christina francesca vera chris piech achieving fairness adversarial learning application recidivism prediction arxiv preprint flores anthony kristin bechtel christopher lowenkamp false positives false negatives false analyses rejoinder machine bias software used across country predict future criminals biased gainst blacks fed probation zafar muhammad bilal isabel valera manuel gomez rodriguez krishna gummadi fairness beyond disparate treatment disparate impact learning classification without disparate mistreatment proceedings international conference world wide web international world wide web conferences steering committee howard alexander benjamin art science data journalism eilam eldad reversing secrets reverse engineering wiley mateski mark cassandra trevino cynthia veitch john michalski mark harris scott maruoka jason frye cyber threat metrics sandia national laboratories beginning analysis social technical regulatory challenges posed algorithmic systems study explores policy options governance algorithmic transparency accountability extensive review analysis existing proposals algorithmic system governance points four policy options addressing awareness raising accountability public sector use regulatory oversight global coordination algorithmic governance publication scientific foresight unit stoa eprs european parliamentary research service document prepared addressed members sta european parliament background material assist parliamentary work content document sole responsibility author opinions expressed herein taken represent official position parliament isbn doi
