authors editors recommendations introduction research emerging population corporate challenges conclusion work licensed creative commons international license recommendations workshop welfare high testing data results accommodate datasets report expand bias research mitigation strategies beyond narrowly technical approach bias issues long term structural contending necessitates deep interdisciplinary research technical approaches look fix fairness risk oversimplifying complexity social systems within domain education healthcare criminal justice legacies bias movements toward equality histories practices legacies bias solved without drawing domain expertise addressing fairness meaningfully require interdisciplinary collaboration methods listening across different disciplines strong standards auditing understanding use systems wild urgently needed creating standards require perspectives diverse disciplines coalitions process standards developed publicly accountable academically rigorous subject periodic review revision companies universities conferences stakeholders field release data participation women minorities marginalized groups within research development many recognize current lack diversity serious issue yet insufficiently granular data scope problem needed measure progress beyond need deeper assessment workplace cultures technology industry requires going beyond simply hiring women minorities toward building genuinely inclusive workplaces industry hire experts disciplines beyond computer science engineering ensure decision making power moves diverse social institutional domains influencing increasingly high stakes decisions efforts must made integrate social scientists legal scholars others domain expertise guide creation integration systems established practices norms ethical codes meant steer field accompanied strong oversight accountability mechanisms work needed substantively connect high level ethical principles guidelines best practices everyday development processes promotion product release cycles report executive summary artificial intelligence technologies phase rapid development adopted widely concept artificial intelligence existed sixty years applications accelerated last decade due three concurrent developments better algorithms increases networked computing power tech industry ability capture store massive amounts data systems already integrated everyday technologies like smartphones personal assistants making predictions determinations help personalize experiences advertise products beyond familiar systems also introduced critical areas like law finance policing workplace increasingly used predict everything taste music likelihood committing crime fitness job educational opportunity companies promise technologies create automate toil repetitive work identify subtle behavioral patterns much however analysis understanding artificial intelligence limited technical capabilities design implementation next generation computational tools presents deep normative ethical challenges existing social economic political relationships institutions changes already underway simply put exist vacuum must also ask broader phenomena like widening inequality intensification concentrated geopolitical power populist political movements shape shaped development application technologies building inaugural report report addresses recent scholarly literature order raise critical social questions shape present near future year long time research report focuses new developments four areas labor automation bias inclusion rights liberties ethics governance identify emerging challenges areas make recommendations ensure benefits shared broadly risks identified mitigated labor automation popular media narratives emphasized prospect mass job loss due automation widescale adoption robots serious scenarios deserve sustained empirical attention best recent work labor focused instead specific sectors tasks jobs completely automated near term researchers estimate third workplace tasks automated majority workers new policies universal basic income ubi designed address concerns job loss need much study underexplored area needs urgent attention related algorithmic systems already changing balance workplace power machine learning techniques quickly integrated management hiring report decisions including gig economy technical systems match workers jobs also across traditional white collar industries new systems make promises flexibility efficiency also intensify surveillance workers often know tracked evaluated hired fired furthermore forms management may replace democratic forms bargaining workers employers increasing owner power guise technical neutrality bias inclusion one active areas critical research past year study bias formal statistical sense wider legal normative senses best systems used augment human judgement reduce conscious unconscious biases however training data algorithms design choices shape systems may reflect amplify existing cultural assumptions inequalities example natural language processing techniques trained corpus internet writing may reflect stereotypical dated word word female might associated models used make educational hiring decisions may reinforce existing inequalities regardless intentions even knowledge system designers researching designing developing systems tend male highly educated well paid yet systems working predict understand behaviors preferences diverse populations different life experiences diversity within fields building systems help ensure reflect broader variety viewpoints rights liberties application systems public civil institutions challenging existing political arrangements especially global political context shaped events election donald trump united states number governmental agencies already partnering private corporations deploy systems ways challenge civil rights liberties example police body camera footage used train machine vision algorithms law enforcement raising privacy accountability concerns technologies also deployed legal institutions designed safeguard rights liberties proprietary risk assessment algorithms already used help judges make sentencing bail decisions potentially amplifying naturalizing longstanding biases rendering opaque oversight scrutiny privacy rights represent particularly sensitive challenge current applications especially domains like healthcare used help make diagnoses deliver promises requires large amounts data likely means increase data collection scale granularity without contextual knowledge informed consent due processes mechanisms systems create risks threaten expose already vulnerable populations ethics governance areas ethics governance attempt address many challenges opportunities identified track growing report interest ethical codes conduct principles noting need tied closely everyday design development military use artificial intelligence takes special urgency case lethal autonomous weapons systems multiple signs progress development professional legal ethical codes govern design application technologies however face rapid distributed often proprietary development implementation forms soft governance face real challenges among problems coordination among different ethical codes well questions around enforcement mechanisms would beyond voluntary cooperation individuals working research industry new ethical frameworks need move beyond individual responsibility hold powerful industrial governmental military interests accountable design employ following report develops themes detail reflects latest academic research already faced important choices designed applied promisingly approaches described report demonstrate growing interest developing attuned underlying issues fairness equality report introduction july kate crawford meredith whittaker first symposium collaboration obama white house office science technology policy national economic council event brought together experts members public discuss social economic impacts artificial intelligence systems already integrated social political economic domains implications complex unpredictable symposium focuses core social implications bringing together leading experts across sectors disciplines aim better understanding systems already working world symposium identified instances challenged current thinking professional responsibilities accountability following report reflected expert discussion provided recommendations future research policy interventions symposium deepened examination social economic implications accompanying report provides overview key issues symposium addressed labor automation bias inclusion rights liberties ethics governance selecting four themes building report introducing new areas concern close attention developments occurred last months first section labor automation considers need granular sectoral approach understanding automation impacts labor practices big questions implications automation labor overall still wide open also important questions distinct roles automation play within specific industries sectors tasks particularly used tool employee hiring firing management second section focuses bias inclusion growing concern among looking design social implications systems address problem diversity inclusion within industry also share new technical advances pioneers stuart russell peter norvig point history artificial intelligence produced clear definition seen variously emphasizing four possible goals systems think like humans systems act like humans systems think rationally systems act report use term refer broad assemblage technologies early algorithmic systems deep neural networks rely array data computational infrastructures technologies span speech recognition language translation image recognition predictions determinations tasks traditionally relied human capacities across four goals russell norvig identify new recent developments ability collect store large quantities data combined advances computational power led significant breakthroughs field last ten years stuart russell peter norvig artificial intelligence modern approach englewood cliffs prentice hall report social economic implications artificial intelligence technologies ibid report help better understand mitigate biases systems may perpetuate even amplify due biased training data faulty algorithms factors third section rights liberties begins recognizing recent rise political authoritarianism asks role systems either supporting eroding citizens rights liberties areas like criminal justice law enforcement housing hiring lending domains last section ethics governance connects see today history research development also looks whose concerns ultimately reflected ethics ethical codes strategies could developed time political volatility early stages discussion accordingly many new questions answers old ones hope report provides productive grounding extraordinary challenges opportunities current moment helps spur research inquiry social economic implications turn labor automation editors nature argued need match technical research funding solid research anticipate scenarios could bring study possible political economic reforms allow usurped machinery contribute labor primer described forms automation based machine learning robotics potential increase productivity labor exacerbate existing inequalities distribution wealth economic context characterized low productivity growth historically high levels inequality important find ways use promote equality shared prosperity still considerable attention focused large structural changes labor markets economy whole new research focusing specific industries impact systems particular tasks within profession section describes new developments application within various labor sectors suggests directions research could productively explore future research sector task beginning mckinsey global institute mgi released report looking specific workplace tasks whether less susceptible automation specifically involving predictable physical activities involving data collection processing relatively current jobs totally automated anticipating artificial intelligence nature april labor new york july jason furman time different opportunities challenges artificial intelligence expanded remarks expert workshop july new york university report today technology mgi estimates percent occupations potential third activities automated similar vein analysts deloitte human capital division predict future human skills augmented collaboration machines capable performing routine tasks prepare changes essential policymakers access robust data advances machine learning robotics automation perceptual tasks changing nature organization work changes manifest across different roles different sectors data necessary robust policy proposal however recent report national academies sciences engineering medicine identifies lack data finding existing federal statistical data limited capacity answer questions report recommends new multidisciplinary qualitative research methods capture present future transformations work series economic studies begun investigate effects robots labor markets empirical perspective paper george graetz guy michaels used new data international federation robots estimate changes productivity employment due robot adoption finding increases productivity slightly lowered working hours low workers using data daron acemoglu pascual restrepo analyzed developments labor markets across united states estimated number jobs lost due robots period ranged trend could accelerate intensive adoption automation across sectors model assumptions play important role empirical analyses need continually tested employment data end management professor former senior economist white house council economic advisers robert seamans argues even data necessary understand whether automation systems replacing complementing human workers jeff schwartz laurence collins heather stockton darryl wagner brett walsh future work augmented workforce deloitte human capital february national academies sciences engineering medicine information technology workforce washington national academies press georg graetz guy michaels robots work iza discussion paper institute study labor iza march daron acemoglu pascual restrepo robots jobs evidence labor markets working paper cambridge national bureau economic research march instance economists economic policy institute argue restrepo acemoglu estimates unemployment localized media distorted conclusions regarding job loss also ignoring productivity increases see lawrence mishel bivens zombie robot argument lurches evidence automation leads joblessness inequality washington economic policy institute may robert seamans even know robot takes job forbes january report nature work displacement entire occupations taxi truck drivers clearly important concern also transforming wide range occupations roles across sectors automated management hiring technologies introduced promising increase worker productivity flexibility also exposing workers new forms monitoring manipulation control changes labor processes power relations research topic needed address transforming nature work transformations manifesting specific occupations within specific sectors luke stark alex rosenblat research uber drivers suggests one model approach listening drivers identified algorithmic forms management used company driver platform acts kind remote management console helps make efficient use driver time digital matching market platform also exposes fundamental informational asymmetries worker platform owner example drivers seconds accept ride requests via platform shown rider destination drivers dark know accept short unprofitable fares meanwhile uber furthers goal providing service prospective riders uber designs platform change conflicts interest worker platform owner systematically settled favor uber via platform collective bargaining processes allow worker participation flatly contradicts argument platform interesting see comes recent new york administrative law judge ruling classified uber drivers employees new york law contrary uber claims otherwise course asymmetrical forms workplace management control long predate task researchers determine specifically makes asymmetries different forms monitoring taylorist scientific management audit culture total quality control one clear difference reliance workplace surveillance data produces thus normalization workplace surveillance truckers like drivers also subject forms surveillance control karen levy contexts control information power work information society march alex rosenblat luke stark algorithmic labor information asymmetries case study uber drivers international journal communication july eduardo azevedo glen weyl matching markets digital age science may rosenblat stark algorithmic labor information asymmetries dana rubenstein state labor judge finds uber employer politico may ifeoma ajunwa kate crawford jason schultz limitless worker surveillance california law review hugh aitken taylorism watertown arsenal scientific management action cambridge harvard university press marilyn strathern audit cultures anthropological studies accountability ethics academy london routledge report practices systems provide employers expansive often invasive data workplace behaviors employees data management systems rely generate insights management becomes common data collection worker surveillance practices relies worryingly employee monitoring necessarily limited workplace spill private life fitness trackers ubiquitous productivity apps smartphones equipped monitoring features might assume would held check privacy laws existing policy ifeoma ajunwa kate crawford jason schultz published study existing legal frameworks assessing meaningful limits workplace surveillance found already threat trump administration degree surveillance potential transform key features prior management systems potentially ways workers aware say employers could easily use machine learning techniques identify behavioral patterns outside work hours exploit insights increase profits manipulate behaviors potentially negative effects workers uber platform demonstrates workers directly indirectly manipulated service instant customer gratification company wants keep number available cars even times low demand drivers make less money address company drew behavioral economic research psychological tendency taxi workers set round earnings goals stop working reach uber access vast data driver activities quickly test theories using machine learning identify exploitable behavioral patterns even individual level uber discovered drivers quickly abandon mental income targets favor working times high demand combat tendency uber sent tailored nudge messages drivers indicating close revenue target times advantageous uber keep drivers road recent feature new york times drivers unaware subjects large behavioral experiment sought modify actions benefit company goals given opacity systems may many experiments ifeoma ajunwa kate crawford jason schultz limitless worker surveillance california law review june colin camerer linda babcock george loewenstein richard thaler labor supply new york city cab drivers one day time quarterly journal economics may use nudge technical term emerged work decision choice sciences influentially behavioral economist richard thaler legal scholar cass sunstein headed obama administration office information regulatory affairs turn draw psychological studies people make decisions conditions uncertainty avoid errors due earnings biases first identified influential psychologists amos tversky daniel kahneman richard thaler cass sunstein nudge improving decisions health wealth happiness new york penguin books amos tversky daniel kahneman judgment uncertainty heuristics biases science september noam scheiber uber uses psychological tricks push drivers buttons new york times april report workers public never know case illustrates management might differ past forms control companies gather data workers longer need rely generalized psychological theories assessments merit instead exploit information asymmetries identify behavioral patterns individual level nudge people toward profitable activities platform owners even operate best interests workers selectively exploiting workers behavior often without workers consent even knowledge technologies potential make workers complicit exploitation address emerging imbalances workplace power likely necessary unions labor rights advocates individual workers participate design worker platforms also likely necessary give workers democratic voice shaping whether monitored machine learning techniques used process data rich area research design technical architects management systems labor organizers advocates explore management systems also provide new invasive methods evaluating employees making retention decisions example employee monitoring firm veriato captures information nearly task worker performs computer browsing history email chat even taking periodic screenshots workers monitor displays firm software aggregates information uses machine learning detect anomalous behaviors program send warning messages employees deviate norm consequences deviance workers employer veriato software also offers features score email chats sentiment using natural language processing language program determines negative interpreted company indication productivity risk employee getting ready leave company similarly another company workday assigns employees individualized risk score based factors many employees use computer mobile already subject type monitoring ranking assessment additionally many likely idea value employee determined part software systems scoring everything emotional content emails frequency accepting meeting requests beyond employee surveillance combination customer surveillance potential turn previously stable employment sectors like food service retail form gig work scheduling software allowed retailers switch standard shifts call model based algorithmic predictions whether customers store given time use software cut employer costs reducing staff customer hours solon barocas ted greenwald transforming workplace wall street journal march sec business ibid report karen levy observed highly destabilizing workers never know ahead time whether called work use predictive scheduling software whether gig employers like uber traditional employers collapses boundaries also puts workers risk underwork gives workers little control shift times provides little ability predict income flows plan ahead things like child care second job recognizing negative impacts precarious schedules workers oregon state senate house recently passed bill mandating large employers retail manufacturing hospitality provide workers written estimate schedule least days start work week barring veto state governor oregon join new york san francisco seattle also passed laws mandating predictable scheduling increasing role automation within various labor sectors potential revise understanding labor expectations goods services consumers grow accustomed dealing automated systems potential ignore devalue human labor remains essential many instances labor primer emphasized often demands human caretakers vary workers maintain repair data centers moderators check results even sophisticated computer vision algorithms since labor primer facebook announced hiring workers monitor live video streaming services violence exploitation hate speech acknowledgement systems always work intended example essential human work happening behind scenes complex systems often invisible surprisingly work tends outsourced countries wages low maintenance repair work valued consumers led believe services entirely automated companies promote fully automated magic treat recognize workers within systems additionally lack visibility impact workers ability organize shape working conditions managers need rethink formulate goals use data acknowledging limits risks automated systems michael luca jon kleinberg sendhil mullainathan argue systems miss contextual details may solon barocas karen levy customer data collection could mean workers harvard business review august hillary borrud oregon way become first state guarantee predictable work schedules oregonian june sec oregon live human caretakers labor automation prime labor sarah roberts commercial content moderation digital laborers dirty work intersectional internet race sex class culture online safiya umoja noble brendesha tynes new york peter lang kathleen chaykowski facebook hiring moderators push curb violent videos forbes accessed may report provide clear reasoning decisions advise managers ask employees stakeholders articulate concerns systems democratic input often improve performance similarly recommend diverse used pursuit goals values instead focusing narrowly fruit often produce unintended consequences like clickbait search social media engagement inequality redistribution happens workers jobs automated potential systems exacerbate inequality widely acknowledged address turning models resource redistribution idea universal basic income ubi past year seen number experiments redistributive social welfare based assumptions automation require resource distribution explicitly tied sale individual labor visible efforts come governments private actors running small trials people receive direct cash transfers form basic income stipend bears noting payments made part experiments considered universal insofar provided limited number people thus experiments gather informative data tells individual reactions receipt funds account impact universal payment example april government ontario began ubi pilot research program participants provide per year single person per year couple less percent earned income combinator silicon startup incubator began one year ubi pilot study oakland one hundred families receive per month course year combinator president openai sam altman explicitly references job displacement due technology motivating factor ubi research ubi remains politically contentious idea significant variations approach implementation currently one commonly proposed policy responses job losses deserves close assessment bias inclusion word bias multiple meanings intersect applications ways overlap occasionally contradict add unnecessary confusion critically needed domain research many machine learning michael luca jon kleinberg sendhil mullainathan algorithms need manage harvard business review january ministry community social services ontario basic income pilot april michael coren combinator running basic income experiment oakland families quartz june sam altman moving forward basic income combinator may report bias specific meaning differs popular social scientific definitions example idea selection bias refers errors estimation result members population likely sampled others machine learning program trained recognize say faces particular racial group applied larger diverse populations may produce biased results sense lower measure accuracy word bias also normative meanings colloquial legal language refers judgement based preconceived notions prejudices opposed impartial evaluation facts impartiality core value many legal systems governs many legal processes juror selection limitations placed judges example united states sixth amendment constitution mandates right impartial jury fourteenth mandates equal protection law sense word bias closely linked normative ethical perspectives fairness idea different groups treated equally examining technical systems temptation vested interest limiting discussion bias first neutral statistical sense term however practice rarely clear demarcation statistical normative definitions biased models learning algorithms defined statistically lead unequal unfair treatments outcomes different social racial groups danger bias increases systems applied often ways critical institutions like criminal justice healthcare social sciences critical humanities decades research bias within social systems much offer current debate bias algorithmic systems since deeply interested social political implications report use word bias broader normative sense following section acknowledging close relationship statistical usages potential impact biases extremely worrying solutions complicated part biased result number factors alone combination develops systems goals system developers mind development training data use whether systems work well different parts population section addresses latest research bias discusses emerging strategies used address bias comes systems taught know training data training data barocas crawford shapiro wallach problem bias allocative versus representational harms machine learning sigcis conference october solon barocas andrew selbst big data disparate impact california law review june sarah bird solon barocas kate crawford fernando diaz hanna wallach exploring exploiting social ethical implications autonomous experimentation report incomplete biased otherwise skewed often drawing limited samples poorly defined use problems training data may obvious datasets may constructed ways additionally given humans must label much training data hand human biases cultural assumptions transmitted classification choices exclusion certain data turn mean exclusion able see pernicious biases difficult find understand especially systems proprietary treated black boxes taken face value computer scientists noted complexity machine learning systems must face difficulties interpreting opaque unsupervised models may also take technical debt makes maintenance improvement situations bias may difficult identify mitigate collection data also produce bias data expensive data scale hard come thus want train system drawn use easily available data often scraped otherwise gathered existing apps properties type data easily privilege socioeconomically advantaged populations greater access connected devices online services types bias also exist data collected particular groups others recent example comes experiment openai year worth messages discussion forum reddit used data train model reddit skewed internet users experiment give sense types bias occur small david beymer karen brannon ting chen moritz hardt ritwik kumar tanveer machine learning incomplete data sets patent issued may lisa gitelman raw data oxymoron mit press ishan misra lawrence zitnick margaret mitchell ross girshick seeing human reporting bias visual classifiers noisy labels proceedings ieee conference computer vision pattern recognition josh attenberg prem melville foster provost maytal selective data acquisition machine learning machine learning crc press christian beyer georg krempl vincent lemaire select information matters comparative study active learning strategies classification proceedings international conference knowledge technologies business acm moritz hardt nimrod megiddo christos papadimitriou mary wootters strategic classification proceedings acm conference innovations theoretical computer science matthew zook solon barocas kate crawford emily keller seeta peña gangadharan alyssa goodman rachelle hollander barbara koenig jacob metcalf arvind narayanan alondra nelson frank pasquale ten simple rules responsible big data research plos computational biology frank pasquale black box society secret algorithms control money information harvard university press sculley machine learning high interest credit card technical debt software engineering machine learning nips workshop amanda levendowski copyright law creates biased artificial intelligence josh terrell andrew kofink justin middleton clarissa rainear emerson chris parnin jon stallings gender differences bias open source pull request acceptance women versus men peerj preprints ananya bhattacharya elon musk openai using reddit teach speak like humans quartz october report nonrepresentative group used whole problems may also result disconnect context system used assumptions built system designed group researchers recently assessed mapping apps often provide indirect routes users way accomplish traffic system able tell person asking directions driving hospital emergency decontextualized assumptions put unaware populations risk providing little opportunity direct input widely acknowledged problem bias within beyond difficult measure unintended consequences inequalities nature collective relative contextual making measurement baseline comparisons difficult information biases particular difficult measure given many possible reference points context content users ranking access potential biases measurement distributions given limits observable circumstances individuals problems population gaps possible measurement errors given difficulty sometimes even technical impossibility understanding exactly systems reached given decision bias often revealed demonstrating inequality outcomes examples familiar recent news stories julia angwin propublica piece northpointe compas system used make sentencing decisions courts across united states exemplar genre similarly bloomberg found amazon delivery service bypassing zip codes predominantly black decision may made many reasons result racial bias field diverse bias also emerge systems narrow subset population design developers mostly male generally highly paid similarly sarah bird solon barocas kate crawford fernando diaz hanna wallach exploring exploiting social ethical implications autonomous experimentation workshop fairness accountability transparency machine learning marco haenssgen proochista ariana social implications technology diffusion uncovering unintended consequences people mobile phone use rural india china world development frank cowell measuring inequality oxford university press evaggelia pitoura panayiotis tsaparas giorgos flouris irini fundulaki panagiotis papadakos serge abiteboul gerhard weikum measuring bias online information arxiv preprint ashton anderson jon kleinberg sendhil mullainathan assessing human error benchmark perfection arxiv preprint jenna burrell machine thinks understanding opacity machine learning algorithms big data society doi angwin larson kirchner machine bias software used across country predict future criminals biased blacks propublica may david ingold spencer soper amazon consider race customers bloomberg april report technically educated interests needs life experiences necessarily reflected create bias whether conscious unconscious reflects problems inclusion representation lack women minorities tech fields artificial intelligence particular well known always case early programming data entry work characterized secretarial women called computers often undercompensated rarely credited responsible things like maintaining sophisticated systems targeted bomb strikes world war tabulating decades census data history reflects pattern gender exclusion dartmouth summer research project artificial intelligence initiated concept artificial intelligence exclusively attended men pioneering work natural language processing computational linguistics key contemporary systems credited male colleagues students rather margaret masterman founded cambridge language research unit one leaders field intentional exclusion unintentional bias responsible continued lack demographic representation within field within tech industry women hispanics african americans gender racial disparities among developer cohorts tech companies even skewed demographics students academics united states women make percent computer science graduates yet percent computer engineers female african americans hispanics represent percent total technology sector employees although comprise percent overall population representation context wide reaching implications given percent knowledge technology intensive kti jobs worldwide based firms contribute percent global gdp percent based efforts address gender biases google settings revealed failed cathy neil weapons math destruction big data increases inequality threatens democracy new york crown publishing group kate crawford artificial intelligence white guy problem new york times june ellen van oost making computer masculine women work computerization nathan ensmenger making programming masculine gender codes women leaving computing margaret ann boden mind machine history cognitive science clarendon press ronald kline cybernetics automata studies dartmouth conference artificial intelligence ieee annals history computing margaret masterman personal background early years machine translation memoirs biographies pioneers william williams frank knowles margaret masterman memoriam computers translation google gallup diversity gaps computer science exploring underrepresentation girls blacks hispanics retrieved additional reports google computer science education research available national science foundation science engineering indicators chapter national science foundation science engineering indicators chapter amit datta michael carl tschantz anupam datta automated experiments privacy settings proceedings report stop inequality presentation stem job ads even language ads controlled language impartial neutral technologies much products context created potential agents change machine predictions performance constrained human decisions values design develop maintain systems shape systems within understanding world many biases embedded systems products complex history respect diversity equality recent developments bias research year since symposium bumper crop new research bias machine learning one promising development many studies reflexively used techniques understand ways systems introduce perpetuate unequal treatment new research word embeddings shown ways language used within complex often biased social contexts reflects bias word embeddings set natural language processing techniques map semantic relationship words creating model predicts words likely associated researchers looking word embeddings showed predictable gendered associations words female queen reflected models stereotypes female receptionist man typically masculine names associated programming engineering stem professions biases daily impacts recent analysis search results advertisements similarly reveals persistent gendered racial cultural biases privacy enhancing technologies anja lambrecht catherine tucker algorithmic bias empirical study apparent discrimination display stem career ads october available ssrn zdenek smutny social informatics concept widening discourse journal information science kenneth bamberger deirdre mulligan public values private infrastructure internet things case automobile journal law economic regulation jon kleinberg himabindu lakkaraju jure leskovec jens ludwig sendhil mullainathan human decisions machine predictions national bureau economic research brent daniel mittelstadt patrick allo mariarosaria taddeo sandra wachter luciano floridi ethics algorithms mapping debate big data society aylin caliskan joanna bryson arvind narayanan semantics derived automatically language corpora contain biases science anthony greenwald stereotype catcher science tolga bolukbasi chang james zou venkatesh saligrama adam kalai quantifying reducing stereotypes word embeddings arxiv preprint tolga bolukbasi chang james zou venkatesh saligrama adam kalai man computer programmer woman homemaker debiasing word embeddings advances neural information processing systems datta tschantz datta tarleton gillespie algorithmically recognizable santorum google problem google santorum problem information communication society safiya umoja noble algorithms oppression search engines enforce racism nyu press forthcoming report new work also highlighted way poses risks significant impacts educational context educators subject children treatment discipline tracking decisions based characterizations abilities behaviors analysis large data sets reflecting stem education classrooms reveals racial disparities disciplinary actions recommendations advanced coursework data along biases reflect likely used train educational systems would reproduce normalize biases study examined potential bias human rights data analysis group demonstrated commonly used predictive policing system predpol used oakland would reinforce police practices recommending increased police deployment neighborhoods color decades policing research shown foot patrols community rapport decrease policing biases studies driving black hot spots illustrate biases routine strategies new technologies appear prevent former amplify latter reproducing extreme racial stereotyping legal scholarship also explored applications machine testimony criminal trials among many possible instances identified skewed systems biased data could negatively impact human lives due reproducing stereotypes added challenge systems poorly understood proprietary bias embedded health applications incredibly high cost worryingly data sets used train often rely clinical trial data historically skewed toward white men even health conditions studied primarily affect people color women even without amplifying biases african americans sickle cell anemia overdiagnosed unnecessarily treated diabetes based insights studies excluded prevalence biases combined opacity inscrutability leads lack trust currently benjamin herold algorithmic bias rising concern field rand researchers say education week april kristian lum william isaac predict serve significance prashan ranasinghe rethinking place crime police patrol classic police ethnographies british journal criminology patricia warren donald william smith matthew zingraff marcinda mason driving black bias processes racial disparity police stops criminology david weisburd hot spots policing inevitably lead unfair abusive police practices maximize fairness effectiveness new proactive policing university chicago legal forum andrew guthrie ferguson rise big data policing surveillance race future law enforcement nyu press forthcoming andrea roth machine testimony yale law journal forthcoming anita kurt lauren semler jeanne jacoby melanie johnson beth careyva brian stello timothy friel mark knouse hope kincaid john smulian racial differences among factors associated participation clinical research trials journal racial ethnic health disparities mary lacy gregory wellenius anne sumner adolfo correa mercedes carnethon robert liem james wilson david saks david jacobs april carson luo annie gjelsvik alexander reiner rhaki naik simin liu solomon musani charles eaton association sickle cell trait hemoglobin african americans jama report developed neuroscience mental health applications prospect misdiagnosis improper treatment leading patient death motivates avoid systems entirely health context emerging strategies address bias urgent need expand cultural disciplinary ethnic diversity within field order diminish groupthink mitigate bias broaden intellectual frames reference beyond purely technical suggested systems used address diversity problems companies development inclusive success bootstrapped approach doubtful positive developments prompting inclusion within community sailors summer camp program helps high school girls acquire comfort experience similarly association computing machinery acm increasingly recognizes need address algorithmic bias emphasize diversity various conferences also sought explore accountability transparency issues surrounding algorithmic systems way better understand evaluate biases among conferences fairness accountability transparency machine learning fat conferences notable focus technical research experimentation dedicated making inclusive legible representative steps made understand combat bias sectors bias also profitable insurance financial lending long discriminated financial advantage choosing serve least risky sometimes leaving vulnerable behind systems used make credit lending decisions underwriting decisions made systems trained data reflects past biased practices calibrated detect nuanced signals risk creditors able make profitable loans leaving precarious situations behind due misaligned interests information asymmetry exacerbates industries new incentives fairness new methods validating fair practices need andreas holzinger interactive machine learning health informatics need brain informatics rich caruana intelligible machine learning critical applications health care aaas annual meeting february aaas min ten ways tech leaders make artificial intelligence personnel today april marie vachovsky grace sorathan chaturapruek olga russakovsky richard sommer toward gender diversity artificial intelligence summer program high school girls proceedings acm technical symposium computing science education acm kieth kirkpatrick battling algorithmic bias ensure algorithms treat fairly communications acm algorithms explanations information law insitute new york university april workshop fairness accountability transparency machine learning new york november schumacher linear versus nonlinear allocation rules risk sharing financial fairness march report developed part fundamental difficulty defining understanding measuring bias stems contentious conceptually difficult task defining fairness tradeoffs inherent adoption particular fairness definitions possibly perpetuating particular biases service addressing others recent efforts sought implement fairness mathematically specifying social norms values using specifications constraints training systems hopeful developments none methods cleanly solve problem bias understanding purely technical implementation combination norms technical systems strategic interests important step toward addressing bias continues deep need interdisciplinary socially aware work integrates long history bias research social sciences humanities field research rights liberties period since symposium global political landscape shifted considerably election donald trump part larger wave populist political movements across globe shares number hallmark traits governing populists seek delegitimize political opposition parties institutions like media crack perceived threats imagined homogeneous people claim represent regional instantiations vary share opposition existing political elites nationalist approach claims moral imperative represent silent majority election emmanuel macron france gains labour may indicate coming backlash global populist wave given strong showing germany alternative für deutschland party elections means certain remains necessary ask systems likely deployed governing hamid ekbia bonnie nardi heteromation stories computing capitalism mit press sampath kannan michael kearns jamie morgenstern mallesh pai aaron roth rakesh vohra steven fairness incentives myopic agents arxiv preprint julia lane perspective fix incentives nature jon kleinberg sendhil mullainathan manish raghavan inherent fair determination risk scores arxiv preprint yiling chen arpita ghosh michael kearns tim roughgarden jennifer wortman vaughan mathematical foundations social computing communications acm shahin jabbari matthew joseph michael kearns jamie morgenstern aaron roth fair learning markovian environments arxiv preprint matthew joseph michael kearns jamie morgenstern seth neel aaron roth rawlsian fairness machine learning arxiv preprint mike ananny toward ethics algorithms convening observation probability timeliness science technology human values müller populism philadelphia university pennsylvania press report might used within populist authoritarian contexts effects systems vulnerable individuals minorities systems used law enforcement national security agencies use criminal justice system affect understanding due process principle equal justice law might complex systems centralize authority power section examines questions describes applications pose challenges rights liberties touches technical normative frameworks might construct ensure force good face contemporary political realities population registries computing power political contexts minorities opposition points view seen threats imagined homogeneous people information technology used monitor control segments population projects often build older colonial histories censuses population registries well racialized modes surveillance control rooted atlantic slave trade plantation system dark matters simone browne connects deep history surveillance contemporary biometric techniques governing black bodies book life registry project apartheid south africa useful modern example project ran ibm assisted south africa classifying population racial descent system used move citizens homes segregated neighborhoods book life plagued technical operational problems eventually abandoned however paul edwards gabrielle hecht note technopolitical projects need fully achieve technical goals order work politically registries worked establish racialized personal identities elements kate crawford recently argued registries like book life reinforcing way thinking autocratic recent computerized registries like national security registration system nseers proliferated united states among allies following attacks september nseers centralized documentation united states hailed list predominantly muslim countries bush administration deemed dangerous book life nseers effectiveness see kate crawford dark days rise fascism sxsw featured talk march one example colonial india radhika singha settle mobilize verify identification practices colonial india studies history august simone browne dark matters surveillance blackness durham duke university press national complex american friends service committee automating apartheid computer exports south africa arms embargo philadelphia friends service committee paul edwards gabrielle hecht history technopolitics identity case apartheid south africa journal southern african studies kate crawford dark days rise fascism sxsw featured talk march report stated goal stopping domestic terrorism questionable dismantled final days obama administration although data collected program still exists consistent edwards hecht analysis nseers set motion state projects muslim surveillance deportation history political efficacy registries exposes urgent need lines research examine way citizen registries work currently enhanced data mining techniques may work future contemporary systems intensify practices surveillance control systems require collection massive amounts data possible large scale via internet connected devices practices carried private enterprise addition states discuss next section introduce new forms value extraction population control unregulated often unacknowledged current legal frameworks corporate government entanglements remains critically important understand history shifting relationship state century advanced computing projects tended closely associated state especially military agencies funded fundamental research development although emerged context present characterized collaborative approach state agencies private corporations engaged research development gary marchant wendell wallach argue governance expanded far beyond governmental institutions legal codes include wide range industry standards practices shape systems implemented trump supporter advisor peter thiel seed money cia venture capital fund dynamic gotham palantir national security government software allows analysts easily combine query visualize structured unstructured data large scales used palantir products activities lead generation including bank ability identify david goodman ron nixon obama dismantle visitor registry trump revive new york times december raza city new york legal challenge nypd muslim surveillance program american civil liberties union march kate crawford letter silicon valley harper magazin feb julie cohen biopolitical public domain legal construction surveillance economy philosophy technology march paul edwards closed world computers politics discourse cold war america cambridge mit press gary marchant wendell wallach coordinating technology governance issues science technology issues science technology xxxi summer sam biddle peter thiel palantir helped nsa spy whole world intercept february ibid report anomalous credit card activity fraud protection advanced capabilities available national security clients well rights liberties need understood reconfigured face opaque systems still open question immigration law enforcement critical within debate united states immigration customs enforcement ice expanding technological reach tools like investigative case management icm platform allows agents access wide variety previously separate databases including information suspect schooling family relationships employment information phone records immigration history foreign exchange program status personal connections biometric traits criminal records home work another palantir system first procured obama administration scheduled become operational late law enforcement agencies currently integrating related algorithmic systems private sector existing arsenals axon formerly taser international publicly traded maker law enforcement products including famous electroshock weapon company shifted toward body camera technologies recently offering free police department axon started division following acquisition two machine vision companies among goals efficiently analyze petabytes data already acquired existing camera systems video expands axon existing digital evidence management system signaling larger shift beyond machine learning natural language processing textual sources axon ceo rick smith argued vast scale existing law enforcement data could help drive research machine vision whole got law enforcement information videos one richest treasure troves could imagine machine real concerns forms bias embedded data sets would subsequently function training data system argue favor body camera machine vision systems supporting civil liberties including enhanced law enforcement transparency accountability axon promises techniques reduce time officers currently spend data entry however axon new focus spencer woodma palantir provides engine donald trump deportation machine intercept march laurel wamsley taser changes name axon offers free body cameras police npr arpil taser makes two acquisitions create axon police magazine february doug wyllie taser acquisition companies means future policing policeone february jay stanley police cameras right policies place win aclu alex pasternack police body cameras record fast company march report predictive methods google embrace deep learning increase new civil liberties concerns instead purchasing patterns systems looking much vague targets like suspicious behind appearances technical neutrality systems rely deeply subjective assumptions constitutes suspicious behavior counts suspicious person unsurprisingly machine vision techniques may reproduce present objective existing forms racial bias researchers affiliated google machine intelligence group columbia university make compelling comparison machine learning systems designed predict criminality facial photos discredited theories problematically claim able predict character behavioral traits simply examining physical features generally cathy neil identifies potential advanced systems law enforcement create pernicious feedback loop systems built top policing practices training data reflect existing biases integrate bias logic decision making prediction ethical questions bias accountability become even urgent context rights liberties systems capable violent force humans developed deployed law enforcement military contexts robotic police officers example recently debuted dubai carry weapons new questions would arise determine use force appropriate drawing analysis black lives matter movement peter asaro pointed difficult ethical issues involving lethal autonomous weapons systems laws detect threats gestures cooperation especially involving vulnerable populations concludes robotics researchers adopt ethical legal standards maintain human control accountability systems similar questions apply military use laws heather roff argues fully autonomous systems would violate current legal definitions war require human judgment proportionate use force guard targeting civilians furthermore argues learning systems may make difficult commanders even know weapons respond battle situations given legal ethical ava kofman taser use police body camera videos anticipate criminal activity intercept april clare garvie jonathan frankle software might racial bias problem atlantic april blaise agüera arcas margaret mitchell alexander todorov physiognomy new clothes medium may kofman taser use police body camera videos anticipate criminal rory robot police officer goes duty dubai bbc news may sec technology peter asaro hands shoot hri automation police use force journal interaction december heather roff meaningful human control appropriate human judgment necessary limits autonomous report design concerns researchers call strict limitations use weapons systems predictive policing use force always important issues take new salience populist authoritarian contexts systems promise new forms technical efficiency service safety may need confront fundamental tension technological efficiency commitment ideals justice legal system legal system institution tasked defending civil rights liberties thus two separate questions consider regarding legal system legal system serve functions expected system produces unfair result legal system incorporate scholars like kate crawford jason schultz identified series conflicts techniques constitutional due process requirements techniques affect procedural considerations equal justice law proliferation predictive systems demands new regulatory techniques protect legal rights danielle citron frank pasquale argue safeguards rights introduced stages implementation system safeguarding privacy rights data collection public audits scoring systems critically affect public areas like employment healthcare similar vein andrew selbst argued impact assessment requirement force building buying systems make explicit normative choices making implementing lilian edwards michael veale pointed new general data protection regulation gdpr includes requirement data protection impact assessments import unclear yet also rapidly emerging scholarly debate value requiring explanation interpretation machine learning systems regulatory technique ensure individual rights operationalize requirement whether weapons geneva review conference convention certain conventional weapons december kate crawford jason schultz big data due process toward framework redress predictive privacy harms boston college law review january danielle keats citron frank pasquale scored society due process automated predictions washington law review andrew selbst disparate impact big data policing georgia law review forthcoming ssrn preprint lilian edwards michael veale slave algorithm right explanation probably remedy looking ssrn preprint ibid kiel plausible cause explanatory standards age powerful machines vanderbilt law review vol andrew selbst mild defense new machine overlords vanderbilt law review banc vol katherine strandburg decisionmaking machine learning value explanation human use machine learning interdisciplinary workshop december report requirement presently exists gdpr generally competing interpretations explanations might technically formulated understood different stakeholders criminal justice system implementation risk assessment algorithms provides example legal system use attendant risks proponents sentencing argue machine learning techniques used concert expertise judges improve accuracy prior statistical actuarial methods risk forecasting regression analysis along lines recent study computer scientist jon kleinberg sendhil mullainathan showed predictive machine learning algorithm could used judges reduce number defendants held jail await trial making accurate predictions future crimes algorithmic tools show promise many researchers caution misleading performance measures emerging legal techniques example value recidivism means evaluate correctness risk score questionable judges make decisions risk sentencing turn influences recidivism assessed low risk subsequently released ones opportunity making difficult measure accuracy scoring meanwhile rebecca wexler documented disturbing trend trade secret doctrine expressly adopted courts prevent criminal defendants asserting rights trial sandra mayson recently written risk assessment bail reform movement proponents bail reform argue risk assessment used spare poor defendants onerous bail requirements pretrial incarceration arguments tend miss potential risk assessment legitimize entrench problematic reliance statistical correlation lend assessments aura scientific mayson argues also need ask deeper questions andrew selbst solon barocas regulating inscrutable systems progress bryce goodman seth flaxman european union regulations algorithmic right explanation icml workshop human interpretability machine learning arxiv preprint forthcoming magazine sandra wachter brent mittelstadt luciano floridi right explanation automated exist general data protection regulation international data protection law zachary lipton mythos model interpretability arxiv preprint stat june richard berk jordan hyatt machine learning forecasts risk inform sentencing decisions federal sentencing reporter april berk hyatt machine learning forecasts risk inform sentencing decisions jon kleinberg human decisions machine predictions working paper national bureau economic research february jon kleinberg jens ludwig sendhil mullainathan guide solving social problems machine learning harvard business review december rebecca wexler life liberty trade secrets intellectual property criminal justice system ssrn preprint sandra mayson bail reform restraint dangerousness defendants special case ssrn scholarly paper report pretrial restraints justified first place words policymakers hope employ risk assessment bail reform pretrial forms detention need publicly specify types risks justify restraints liberty defendants receiving scores convicted anything restraints imposed dangerous individuals rest society separately criminologist richard berk colleagues argue intractable tradeoffs accuracy occurrence false positives populations base rates percentage given population fall specific category vary different social groups difficult decisions need made value fairness accuracy risk assessment merely technical problem one involves important value judgments society work left unchecked legal system thus susceptible perpetuating harm institution finally machine learning data analysis techniques also used identify explain abuses rights working human rights advocates mexico human rights data analysis group created machine learning model help guide search mass graves privacy challenges current understandings privacy strains laws regulations place protect personal information established approaches privacy become less less effective focused previous metaphors computing ones adversaries primarily human systems intelligence depends ingesting much training data possible primary objective adverse goals privacy thus poses significant challenges traditional efforts minimize data collection reform government industry surveillance practices course privacy right always unevenly distributed discourses regularly critiqued disproportionately beneficial privileged leaving many vulnerable populations partially entirely exposed yet different privacy individualistic conceptualizations privacy remain important systems work today computational systems operating outside data collection metaphors privacy law built new terrain one century models privacy designed contend example privacy discourse sufficiently accounted growing power asymmetries institutions accumulate data people generate rochester social science research network august richard berk hoda heidari shahin jabbari michael kearns aaron roth fairness criminal justice risk assessments state art march porup hunting mexico mass graves machine learning ars technica april report data even approaching threshold levels may make asymmetries hard reverse models privacy based data tradable good fail contend power difference people trade effectively systems understand particularly system understands well knows manipulate preferences additionally adaptive algorithms changing constantly even designers created fully explain results generate new model computational privacy adversaries power knowledge gaps continue widen must ask notice consent possible would mean access data control data much unknown flux also shift quality data used order help develop sophisticated diagnostic models designers often seek use inputs extremely sensitive nature example case deepmind partnership national health service company acquired large amounts sensitive public health data even though data may required project goals resulting backlash government censure illustrate emerging tensions related industry use data current limits democratic processes address questions agency accountability oversight endeavors expansion diverse realms like urban planning also raises privacy concerns deployment iot devices sensors arrayed throughout daily lives tracking human movements preferences environments devices sensors collect data requires function realms expansion significantly increase amount type data gathered individuals also raises significant questions around security accuracy iot devices notoriously insecure often difficult update maintain capacity prediction inference also adds set privacy concerns much value offers ability predict imagine information individuals groups otherwise difficult collect compute distribute systems deployed focus granular levels detail predictive privacy harms become greater concerns especially due process constraints information impacts vulnerable individuals part promise predictive techniques make accurate often intimate deductions based pieces data information detecting substance abusers facebook posts identifying gang members based twitter data significant information commissioner office royal free google deepmind trial failed comply data protection law july see example nvida deep learning smart cities several serious attacks network infrastructure logistics hacked iot networked devices last months example andrew peterson internet things compounded friday hack major web sites washington post october kate crawford jason schultz big data due process toward framework redress predictive privacy harms boston college law review january tao ding warren bickel shimei pan social substance use prediction may report shifts needed legal regulatory approaches privacy keep pace emerging capacities systems ethics governance far report addressed issues power markets bias fairness rights liberties subjects closely tied ethics section presents distinct discussion ethics uses deployment creation ethical questions surrounding systems spanning creation uses outcomes important questions set values interests reflected well machines recognize values ethical paradigms important distinction area called machine ethics wider domain ethics machine ethics narrowly explicitly concerned ethics artificially intelligent beings systems isaac asimov laws robotics one example captured popular imagination ethics concerns wider social concerns effects systems choices made designers users mostly concerned latter approach certainly unique among emerging technologies creating ethical quandaries similar computational technologies ethics roots complex history military influence computing development recent commercialization corporate dominance networked technologies yet ethical questions research development present unique challenges ask consider whether machines make decisions human lives whose values guide decisions ethical concerns articulating ethical values systems never simple pioneer joseph weizenbaum created early chatbot system eliza technical demonstration system capable maintaining interrogative conversation human counterpart rudimentary today standards psychologists adopted tool treatment much creator concern dismay response weizenbaum raised ethical concerns around reflexive reliance trust automated systems may appear objective intelligent ultimately simplistic prone error see lakshika balasuriya finding street gang members twitter international conference advances social networks analysis mining asonam vincent conitzer walter jana schaich borg yuan deng max kramer moral decision making frameworks artificial intelligence association advancement artificial intelligence hans pruijt social interaction computers interpretation weizenbaum eliza heritage social science computer review joseph weizenbaum computer power human reason judgement calculation harmondsworth penguin report currently heated debates whether systems used sensitive contexts gets make important decisions proper degree human involvement various types ethical questions longstanding history examining questions must also look power dynamics current development deployment way systems people build often obscured public view accountability practices last year learned facebook mines user data reveal teenagers emotional state advertisers specifically targeting depressed teens cambridge analytica controversial data analytics firm claims able shift election results reported expansive individual profiles million adult americans fake news instrumented gain traction within algorithmically filtered news feeds search rankings order influence elections multiple approaches using machine learning techniques synthesize representations public figures news events examples shows interests deploying advanced data systems overshadow public interest acting ways contrary individual autonomy collective welfare often without visible affected reflects origins military one single influential institutions shaping modern darpa funding among visible indeed historically shaped largely military goals capabilities incentives defined military objectives desires development continues supported darpa national defense agencies particularly area lethal autonomous weapons systems discussed however current research technology highly proprietary systems supplementing classified systems research increasingly sue newell marco marabelli strategic opportunities challenges algorithmic call action societal effects datification journal strategic information systems darren davidson facebook targets insecure young people australian may hannes grassegger mikael krogerus thedata turned world upside motherboard chengcheng shao giovanni luca ciampaglia alessandro flammini filippo menczer hoaxy platform tracking online misinformation proceedings international conference companion world wide web international world wide web conferences steering committee simon adler breaking news radiolab july kate crawford meredith whittaker artificial intelligence hard see medium september sidney reed richard van atta seymour dietman darpa technical accomplishments historical review selected darpa projects defense advanced research projects agency vol sidney reed richard van atta seymour dietman darpa technical accomplishments historical review selected darpa projects defense advanced research projects agency vol alex roland philip shiman strategic computing darpa quest machine intelligence mit press report taking place industry settings often without peer review oversight accordingly user consent privacy transparency often overlooked favor frictionless functionality supports business models based aggregated data profiles advocating clearer laws policies ambiguous space information rights governed clearly regulate favor individual control personal technologies online services make researchers considered research also history influences current state ethical parameters beginning dartmouth conference researchers established community boundaries participation community relatively closed privileged mathematics computer science engineering perspectives would provide rigorous discussion ethical implications producing technologies work within complex social realities existing systems requires understanding social legal ethical contexts done incorporating diverse perspectives disciplinary expertise ethical codes decades research cited asimov three laws robotics applied systems designed comply biomedical ethics tools available developers contend social ethical questions relatively limited ethical codes gradually developed research space discuss necessarily incomplete always need evolve ways sensitive rapidly changing contexts conditions systems deployed codes constitute one form soft governance industry standards technical practices serve alternatives traditional hard forms government regulation legal oversight systems woven growing number domains needs approach ethics governance grows two related problems emerged tracking adherence ethical guidelines soft governance standards industry developed ways link adherence ethical guidelines ultimate impact systems elaine sedenberg ann lauren hoffmann recovering history informed consent data science internet industry research ethics september available ssrn united states executive office president jason furman john holdren cecilia muñoz megan smith jeffery zients artificial intelligence automation economy technical report national science technology council washington october pdf nils nilsson quest artificial intelligence cambridge university press susan leigh anderson asimov three laws robotics machine metaethics society raymond heatherly privacy security within biobanking role information technology journal law medicine ethics robert rosenberger phenomenological approaches technological ethics ethics technology methods approaches report world examples intertwined practice ethics found biomedical uses bioethics already offers series standards values procedures along enforcement accountability mechanisms apply medical systems often unclear researchers tracking disparities also true privacy requirements given modern capability make personal inferences given limited data increasingly insufficient ethical standards aimed protecting patient privacy proposed biomedical researchers rejected seeing impediment innovation intentional approach ethics needed working toward teaching ethics practitioners one example blue sky agenda education collection ideas ethics education seeks democratization education emphasizes inclusiveness development toward goal respecting values rights diverse populations education enough opportunities must open ethics integrated early stage design incentives designing implementing ethically must built companies institutions currently driving development ethical values norms around accountability social political responsibility inclusion connectivity legibility security privacy embedded every system via default settings whether intentionally often values reflect status quo context interests developers matters convenience profit set implicit values hard change variety reasons even tend shape capabilities roles systems within various lived contexts ethical codes work ensure stephen brotherton audiey kao crigger professing values medicine modernized ama code medical ethics jama jake metcalf kate crawford human subjects big data research emerging ethics divide big data society stephen tipton sara forkey young choi toward proper authentication methods electronic medical record access compliant hipaa cia triangle journal medical systems wendy lipworth renata axler towards bioethics innovation journal medical ethics judy goldsmith emanuelle burton teaching ethics practitioners important eric eaton sven koenig claudia schulz francesco maurelli john lee joshua eckroth mark crowley richard freedman rogelio tiago machado tom williams blue sky ideas artificial intelligence education eaai new future educator program arxiv preprint wendell wallach dangerous master keep technology slipping beyond control basic books anna lauren hoffmann nicholas proferes michael zimmer making world open connected mark zuckerberg discursive construction facebook users new media society john wilbanks public domain copyright licenses freedom integrate science public communication science technology ian kerr devil defaults critical analysis law dylan wesley mulvin embedded dangers history year problem politics technological repair oir selected papers internet research narendra kumar nidhi kharkwal rashi kohli shakeeluddin choudhary ethical aspects future artificial intelligence innovation challenges cyber security international conference ieee report values expressly designed systems processes open center populations affected nascent efforts address concerns emerged recent years series white house reports president obama examined tensions social interests ethical values one hand business industry objectives recent soft governance efforts ieee future life institute acm oxford internet institute produced principles codes ethics perspectives diverse industry intellectual leaders often reflected documents positive steps real limitations key among share assumption industry voluntarily begin adopt approaches rarely mention power asymmetries complicate underlie terms like social good means term would defined measured codes necessarily limited address much insider information access mechanisms would used monitoring enforcement efforts set moral precedents start conversations provide little help practitioners navigating daily ethical problems practice diagnosing ethical harms little directly change ethics design use challenges concerns going forward current framings ethics failing partly rely individual responsibility placing onus appropriate information flow users concentrating power individual developers designers order achieve ethical systems wider implications addressed must united states executive office president holden smith preparing future artificial intelligence technical report national science technology council washington october ieee ethically aligned design vision prioritizing human wellbeing artificial intelligence autonomous systems ieee global initiative ethical considerations artificial intelligence autonomous systems december asilomar principles acm code version mike wooldridge peter millican paula boddington towards code ethics artificial intelligence research oxford brinkman catherine flick gotterbarn keith miller kate vazansky marty wolf listening professional voices draft acm code ethics professional conduct communications acm eugene schlossberger engineering codes ethics duty set moral precedent science engineering ethics stuart ferguson clare thornley forbes gibb beyond codes ethics library information professionals navigate ethical dilemmas complex dynamic information environment international journal information management christian sandvig kevin hamilton karrie karahalios cedric langbort automation algorithms algorithm racist diagnosing ethical harm basic components software international journal communication mike ananny toward ethics algorithms convening observation probability timeliness science technology human values florencia competition privacy policies journal legal studies report institutional changes hold power accountable yet obvious challenges approach disagreement risks potential greenwashing ethical superficial marketing strategy rather substantive commitment practical challenges stopping unethical research designed privilege interests many current economic system within incentives driving development embedded addition effective invisibility many systems people act obscurity algorithmic mechanisms ambiguity origins inescapable pervasiveness make public discourse difficult impossible responsibility strive better outcomes thus falls squarely creators regulators beginning establish dialogue even incentives change significant tension ethics brings wider political landscape created trump administration affect use technologies prior election technology sector leaders articulated priorities freedom expression openness newcomers equality opportunity public investments research infrastructure respect rule law embrace optimistic vision inclusive country american innovation continues fuel opportunity prosperity president trump policies reflect priorities rather significant defunding research increase deportations heightened screening personal communications social media national borders among many concerning policy shifts simply put appear current administration counted support creation adoption ethical frameworks ira rubinstein future october cambridge handbook consumer privacy cambridge university press forthcoming available ssrn vincent müller risks artificial intelligence crc press michael stocker wary artificial intelligence nature federico pistono roman yampolskiy unethical research create malevolent artificial intelligence arxiv preprint jatin borana applications artificial intelligence associated technologies proceeding international conference emerging technologies engineering biomedical management science ira rubinstein big data end privacy new beginning international data privacy law fred turner write cultural history internet internet histories kate darling ryan calo introduction journal interaction special issue law policy journal interaction kate crawford ryan calo blind spot research nature gary merchant wendell wallach emerging technologies ethics law governance ashgate publishing marvin ammori adrian aoun greg badros clayton banks phin barnes niti bashambu open letter technology sector leaders donald trump candidacy president report conclusion systems adopted across multiple sectors social effects already felt far benefits risks unevenly distributed often effects simply happen without public understanding deliberation led technology companies governments yet understand broader implications technologies released complex social systems urgently need rigorous research incorporates diverse disciplines perspectives help measure understand short effects across core social economic institutions fortunately researchers turning tasks time research beginning advocates members affected communities practical domain expertise included center decision making around deployed assessed governed processes must developed accommodate act perspectives traditionally far removed engineering product development practices pressing need understand technologies context existing social systems connect technological development social political concerns develop ethical codes force accountability diversify field integrate diverse social scientific humanistic research practices core development industry ensure decisions practices sensitive complex social domains technologies rapidly moving
