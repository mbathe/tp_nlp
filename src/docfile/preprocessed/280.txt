big data artificial intelligence machine learning data protectiondata protection act general data protection regulation big data artificial intelligence machine learning data protection version contents information commissioner foreword chapter introduction mean big data machine learning different big data analytics benefits big data analytics chapter data protection implications fairness effects processing expectations transparency conditions rocessing personal data consent legitimate interests contracts public sector purpose limita tion data minimisation collection retention accuracy rights individuals subjec access rights security accountability governance data controllers data processors chapter compliance tools anonymisation privacy notice privacy impact assessments privacy design privacy seals certification ethical approaches personal data stores algorithmic transparency chapter discussion big data artificial intelligence machine learning data protection version chapter conclusion chapter key recommendations annex privacy impact assessments big data analytics big data artificial intelligence machine learning data protection version information commissioner foreword big data fad since office first paper subject published application big data analytics spread throughout public private sectors almost every day read news article capabilities effects lives home appliances starting talk artificially intelligent computers beating professional board players machine learning algorithms diagnosing diseases fuel propelling advances big data vast disparate datasets constantly rapidly added exactly makes datasets well often personal data online form filled car insurance quote statistics fitness tracker generated run sensors passed walk ing local shopping centre social postings made last week list goes clear use big data implications privacy data protection associated rights individuals rights strengthened general data protection regulation gdpr implemented gdpr stricter rules apply collection use personal data addition transparent organisations need accountable pers onal data different big data machine learning however implications barriers case big data data protection big data versus data protection would wrong conversation privacy end enabling right embedding privacy data protection big data analytics enables societal benefits dignity personality community also organisational benefits like creativity innova tion trust short enables big data good things yet say someone hold big data account world big data machine learning office relevant ever oversee legislation demands fair accurate use personal data legislation also gives power conduct audits order corrective action issue monetary penalties furthermore gdpr office worki hard improve standards use personal data implementation privacy seals certification schemes uniquely placed provide right framework regulation big data machine learning strongly bel ieve efficient joined approach exactly needed pull back curtain space big data artificial intelligence machine learning data protection version time right update paper big data taking account advances made meantime imminent plementation gdpr although primarily discussion paper recognise increasing utilisation big data analytics across sectors hope practical elements paper particular use thinking already involved big data paper gives snapshot ituation see however big data machine learning fast world far end work space continue learn engage educate influence things expect relevant effective regulator elizabeth denham information commissioner big data artificial intelligence machine learning data protection version chapter introduction discussion paper looks implications big data artificial intelligence machine learning data protection explains ico views start defining big data machine learning identifying particular characteristics differentiate traditio nal forms data processing recognising benefits flow big data analytics analyse main implications data protection look tools approaches help organisations ensur big dat processing complies data protection requirements also discuss argument data protection enacted current legislation work big data analytics highlight increasing role accountability relation ore traditional principle transparency main conclusions data protection challenging big data context benefits achieved expense data privacy rights meeting data protection requirements wil benefit organisations individuals conclusion present six key recommendations organisations using big data analytics finally paper annex discuss practical ities conduct ing privacy impact assessments big data context paper sets views issues intended contribution discussions big data machine learning guidance document code practice complete guide relevant law refer new general data protection regulation gdpr apply may relevant discussion paper guide gdpr organisations consult website full suite data protection guidance second version paper replacing published received useful feedback first version writing paper tried take account new developments versions based extensive desk research discussions business government stakeholders grateful contributed views big data artificial intelligence machine learning data protection version mean big data machine learning terms big data machine learning often used interchangeably subtle differences concepts popular definition big data provided gartner glossary high high information assets demand cost innovative forms information processing enhanced insight decision making big data therefore often described terms three volume relates massive datasets velocity relates real data variety relates different sources data recently suggested three definition become tired multiple forms big data share whil unassailable single definition big data think useful regard data due several varying characteristics difficult analyse using traditional data analysis methods comes government office science recently published paper provides handy introduction defines analysis data model aspect world inferences models used predic anticipate possible future gartner glossary big data accessed june jackson sean big data big numbers time forget look figures computing february accessed december accessed kitchin rob mcardle gavin makes big data big data exploring ontological characteristics datasets big data society january vol sage february government office science artificial intelligence opportunities implications futu decision making november big data artificial intelligence machine learning data protection version may sound different standard methods data analysis difference programs linearly analyse data way originally programmed instead hey learn data order respond intelligently new data adapt outputs society study artificial intelligence simulation behaviour put therefore ultimately computers behaviours whic would thought intelligent human unique ability means cope analysis big data varying shapes sizes forms concept existed time rapidly increasing computational power phenomenon known moore law led point application becom ing practical reality one fasting achieved machine learning intel tech culture magazine defines machine learning set techniques tools allow computers think creating mathematical algorithms based accumulated data broadly speaking machine learning separated two types learning supervised unsupervised supervised learning algorithms developed based labelled datasets sense algorithms trained map input output provision data correct values already signed initial training phase creates models world predictions made second prediction phase outlook big data artificial intelligence idg research november accessed december society study artificial intelligence simulation behaviour artificial intelligence aisb website accessed february bell lee machine learning versus difference wired december accessed december landau deb artificial intelligence machine learning computers learn august accessed december big data artificial intelligence machine learning data protection version conversely unsupervised learning algorithms trained instead left find regularities input data without instructions look cases ability algorithms change output based experience gives machine learning power summary big data thought asset difficult exploit seen key unlocking value big data machine learning one technical mechanisms underpins facilitates combination three concepts called big data analytics recogn ise data analysis methods also come within scope big data analytics techniques paper focuses alpaydin ethem introduction machine learning mit press big data artificial intelligence machine learning data protection version different big data analytics big data machine learning becoming part business usual many organisations public private sectors driven continued growth availability data including data new sources internet thin iot development tools manage analyse growing awareness opportunities creates business benefits insights one indication adoption big data analytics comes gartner industry analysts oduce series hype cycles charting emergence development new technologies concepts ceased hype cycle big data considered data sources technologies characterise big data analytics becoming widely adopted moves hype background growing market big data software hardware estimated grow billion worldwide billion although use big data analytics becoming common still possible see step change data used particular characteristics distinguish traditional processing identifying different big data analytics helps focus features implications data protection privacy distinctive aspects big data analytics use algorithms opacity processing tendency collect data repu rposing data use new types data sharwood simon forget big data hype says gartner cans hype cycle register august heudecker nick big data obsolete normal gartner blog network august accessed february big data market worth within three years dataiq news may accessed june big data artificial intelligence machine learning data protection version view potentially implications data protection use algorithms traditionally analysis dataset involves general terms deciding want find data constructing query find identifying relevant entries big data analytics hand typically start predefined query test particular hypothesis often involves discovery phase running large number algorithms data find uncertainty outcome phase processing described unpredictability design relevant correlations identified new algorithm created applied particular cases application phase differentiation etween two phases regarded simply thinking data acting data form machine learning since system learns relevant criteria analysing data algorithms new use way feature big data analytics opacity processing current state art machine learning known deep involves feeding vast quantities data non neural networks classify data based outputs successive complexity processing data massive networks creates black box effect causes inevitable opacity makes difficult understand reasons decisions made result deep take instance google alphago centre information policy leadership big data analytics seeking foundations effective privacy guidance hunton williams february accessed june edwards john ihrai said communique international conference data protection privacy commissioners icdppc october information accountability foundation iaf consultation contribution consent privacy iaf response consent privacy consultation initiated office privacy commissioner canada iaf website july consent accessed february abadi martin deep lear ning differential privacy proceedings acm sigsa conference compu ter communications security acm october marr bernard difference deep learning machine learning forbes december accessed december castelvec chi davide open black box nature october accessed december big data artificial intelligence machine learning data protection version computer system powered deep learning developed play board game although alphago made several moves evidently successful given victory world champion lee sedol reasoning actually king certain moves infamous move described inhuman lack human comprehension decision rationale one stark differentials big data analytics traditional methods data analysis using data analyse data research often necessary find statistically representative sample carry random sampling big data approach collect ing analys ing data available sometimes referred example retail context ould mean analysing purchases made shoppers using loyalty card using find correlations rather asking sample shoppers take part survey feature big data analytics made easier ability store analyse ever amounts data repurposing data feature big data analytics use data purpose different originally collected data may supplied different organisation analytics able mine data new insights find correlations apparently disparate datasets companies take data twitter via twitter gnip service facebook social media make available analysis marketing purposes ffice national statistics ons experimented using geolocated twitter data infer people residence mobi lity patterns supplement official population geotagged photos flickr together profiles contributors used reliable proxy estimating visitor numbers tourist sites visitors come presence data wood georgie google viewed move human could understand wired march underst accessed december mayer viktor cukier kenneth chapter big data revolution transform live work think john murray swier nigel komarniczky bence clapperton ben using geolocated twitter traces infer residence mobility gss methodology series ons october form smart meters ons accessed february wood spencer using social media quantify nature tourism recreation nature scientific reports october accessed february big data artificial intelligence machine learning data protection version used analyse footfall retail data shoppers come used plan advertising campaigns data patterns movement airport used set rents shops restaurants new types data developments technology iot together developments power big data analytics mean traditional scenario people consciously provide personal data longer main way personal data collected many cases data analytics generated automatically example tracking online activity rather consciously provided individuals ons investigated possibility using data domestic smart meters predict number people household whether include children older sensors street shops capture unique mac address mobile phones passers data used big data analytics may collected via new channe alternatively may new data produced analytics rather consciously provided individuals explained taxonomy developed information accountability distinguishes four types data provided observed derived inferred provided data consciously given individuals filling online form observed data recorded automatically online cookies sensors cctv linked facial recognition derived data produced data relatively simple straightforward fashion calculating customer profitability smart steps increase morrisons new return customers telefonica dynamic insights october accessed june anderson ben newing andy using energy metering data support official statistics feasibility study office national statistics july accessed february rice simon shops use phone track every move video display screens target using facial recognition nformation commissioner office blog january shops accessed june abrams martin origins personal data implications governance oecd march origins accessed june big data artificial intelligence machine learning data protection version number visits store items bought inferred data produced using complex method analytics fin correlations datasets using categorise profile people calculating credit scores predicting future health outcomes inferred data based probabilities thus said less certain derived data iot devices source observed data derived inferred data produced process analysing data sit alongside traditionally provided data discussions various organisations raised question whether big data analytics really something new qualitatively different danger term big data applied indiscriminately buzz word help understanding happening particular case always easy indeed useful say whether particular instance processing big data analytics cases may appear simply continuation processing always done example banks telecoms companies always handled large volumes data credit card issuers always validate purchases real time furthermore noted start section technologies tools enable big data analytics increasingly becoming part business usual reasons may difficult draw clear line big data analytics conventional forms data use nevertheless think features identifi represent step change important consider implications big data analytics data protection however also important recognise many instances big data analytics involve personal data examples non personal big data include world climate weather data using geospatial data gps buses predict arrival times astronomical data radio telescopes square kilometre data sensors containers carried ships areas big data analytics enable new discoveries improve services business processes without using personal data also big data analytics may involve personal data reasons particular may possible successfully anonymise originally personal data individuals square kilometre array website accessed june big data artificial intelligence machine learning data protection version identified discuss detail section anonymisation chapter still obvious examples big data analytics involve personal data data may directly identify individual may identified apparently anonymous datasets combined cases question whether processing complies data protec tion principles unavoidable big data artificial intelligence machine learning data protection version enefits big data analytics centre economics business research estimated cumulative benefit economy adopting big data technologies would amount billion period billion would come gains business obvious commercial benefits companies example able understand customers gra nular level hence making marketing targeted effective consumers may benefit seeing relevant advertisements tailored offers receiving enhanced services products example process applying insuran made easier fewer questions answer insurer broker get data need big data analytics big data analytics also helping public sector deliver effective efficient services produce positive outcomes improve quality people lives shown following examples health public health england phe aware cancer survival rates poor compared europe suspecting might due later diagnosis requests cancer research quantify people came diagnosed cance routes diagnosis project conceived seek answers question big data project involved using complex algorithms analyse million records million patients several data sources analysis revealed ways patients diagnosed ncer key discovery results published almost cancer cases diagnosed emergen patient came patients diagnosed via route lower chances survival compared routes phe able put place initiatives increase diagnosis routes centre economics business research data equity unlocking value big data cebr april equity accessed june big data artificial intelligence machine learning data protection version latest results published show cancers diagnosed emerge understan ding gained study continues inform public health initiatives phe clear cancer campaigns raise awareness symptoms lung cancer help people spot symptoms education learning analytics higher education involves combination static data traditional student records fluid ata swipe card dat entering campus buildings using virtual learning environmen vles downloading analysis information reveal trends help improve processes benefit ing staff students examples include foll owing prevent ing via early intervention students ident ified disengaged studies analys ing vle login campus attendance data ability tutors provide high specific feedback students regular intervals opposed wait late exam instance feedback based pictures student performance gleaned analysis data systems used student study increased self students desire improve performance based access performance data class averages giving students shorter precise lecture recordings based data analysis revealed patterns regarding parts full lecture recordings repeatedly watched assessment req uirements example lucy big data action story behind routes diagnosis public health matters blog november accessed february public health england press release november accessed december big data artificial intelligence machine learning data protection version benefits seen institutions including nottingham trent university liverpool john moores university university salford open transport transport london tfl collects data million journeys every day including million ticketing system taps location prediction information buses traffic information traffic signals cameras big data analytics applied data reveal travel patterns across rail bus networks identifying patterns tfl tailor products services create benefit travellers london informed planning closures diversions ensure travellers possible affected restructuring bus routes meet needs travellers specific areas london instance new service pattern buses new addington neighbourhood introduced october building new entrances exits platforms increase capacity busy tube stations hammersmith tube station february clear therefore big data analytics bring benefits business society individuals consumers citizens recognising benefits intend set paper contest benefits big data rights given data protection look big data data protection lens reductive although implications data protection discuss hapter also solutions discussed hapter case big data data shacklock xanthe bricks clicks potential data analyti higher education higher education commission january accessed june weinstein uren tfl uses big data plan transport services eurotransport june accessed december alton larry improved public transport london thanks big data internet things london datastore june accessed december big data artificial intelligence machine learning data protection version protection big data data protection benefits delivered alongside big data artificial intelligence machine learning data protection version chapter data protection implications fairness types big data analytics profiling intrusive effects individuals organisations need consider whether use personal data big data applications within people reasonable expectations complexity met hods big data analysis machine learning make difficult organisations transparent processing personal data first dpa principle processing personal data must fair lawful must satisf one conditions listed schedule dpa schedule sensitive personal data defined dpa importance fairness preserved gdpr article says personal data must processed fairly lawfully transparent manner relation data subject contrast big data analytics sometimes characterised sinister threat privacy simply creepy involves repurposing data unexpected ways using complex algorithms drawing conclusions individuals unexpected sometimes unwelcome key question organisations using personal data big data analytics whether processing fair fairness involves several elements transparency information people processing essential assessing fairness also involves looking example naughton john big data made privacy thing past guardian online october privacy richards neil king jonathan three paradoxes big data stanford law review online september leonard peter big data business evolving business models privacy regulation august international data privacy law december accessed june big data artificial intelligence machine learning data protection version effects processing individuals expectations data effects process ing big data used important factor assessing fairness big data analytics may use personal data purely research purposes detect general trends correlations may use personal data make decisions affecting individuals decisions obviously affect individual others displaying particular advert internet individual based social media likes purchases browsing history may perceived intrusive unfair may welcomed timely relevant interests however circumstances even displaying different advertisements mean users service profiled way perpetuates discrimination example basis research usa suggested internet searches black names generated advertisements associated arrest records far often white also similar reports discrimination instance female doctor locked gym changing room automated security system profiled male due associating title profiling also used ways intrusive effect upon individuals example usa federal trade commission found evidence people credit limits lowered based analysis poor repayment histories people shopped scenario people discriminated information commissioner office guide data protection ico may accessed december rabess cecilia esther big data racist bold italic march accessed june sweeney latanya discrimination online delivery data privacy lab january accessed june fleig jessica doctor locked women changing room gym automatically registered everyone title male mirror march accessed december federal trade commission big data tool inclusion exclusion ftc januar issues accessed march big data artificial intelligence machine learning data protection version belong particular social group treated certain way based factors identified analytics share members group gdpr cludes provisions dealing specifically profiling defined article form automated processing personal data consisting using data evaluate certain personal aspects relating natural person particular analyse predict aspects concerning natural person performance work economic situation health personal preferences interests reliability behaviour location movements recital gdpr also refers examples automated decision making automatic refusal credit application practices without human intervention wording reflects potentially intrusive nature types automated profiling facilitated big data analytics gdpr prevent automated decision making profiling give individuals qualified right subject purely automated decision also says data controller use appropriate mathematical statistical procedures profiling take measures prevent discrimination basis race ethnic origin political opinions religion beliefs trade union membership geneti health status sexual data protection directive dpa already contained provisions automated decision making instances decision making purely automated means without human intervention hitherto relativ ely uncommon new capabilities big data analytics deploy machine learning mean likely become issue detailed provisions gdpr reflect yet processing unlooked unwelco effect people necessarily unjustified insurance big data analytics used micro risk groups may possible identify people within high therefore high group actually represent slightl gdpr article gdpr recital big data artificial intelligence machine learning data protection version lower risk compared others group premiums adjusted accordingly favour case big data used give accurate assessment risk benefits individuals well insurer corollary given insurance pooling risk remaining high group members may find pay higher premiums arguably fair result overall inevitably winners losers losers process may seem creepy unfair means big data organisations using personal data part assessing fairness need aware factor effects processing individuals communities societal groups concerned given sometimes novel unexpected ways data used analytics may less straightforward conventional data scenarios privacy impact assessments provide structured approach discuss use section privacy impact assessments chapter expectations fairness also expectations would particular use personal data within reasonable exp ectations people concerned organisation collecting personal data generally provide privacy notice explaining purposes need data may necessarily explain detail data used still important organisations consider whether people could reasonably expect data used ways big data analytics facilitates also difference situation purpose processing naturally connected reason people use service one data used purpose unrelated delivery service example former retailer using loyalty card data market research would reasonable expectation would use data gain better understanding customers market operate example latter social company making data available market resear people post social media reasonable expect information could used unrelated purposes mean use necessarily unfair depends various factors make people overa expectations reasonableness suc big data artificial intelligence machine learning data protection version told join use social service deciding reasonable expectation linked issue transparency use privacy notices also principle purpose limitation whether furth use data incompatible purpose obtained discuss transparency purpose limitation also important organisation consider general terms whether use personal data big data application within people reasonable expectations inevitably raises wider question people attitudes use personal data view often put forward people becoming less concerned organisations use personal data said particularly true digital natives younger people grown ubiquitous internet access happy share persona information via social media little concern may used example direct marketing association commissioned future foundation look attitudes use personal data found percentage fundamentalists share data fell percentage concer ned increased true people simply unconcerned personal data used would mean expectations potential data use open leaving wide margin discretion big data organisations however research suggests view simplist reality nuanced international institute communications iic research commissioned showed people willingness give personal data attitude data used context context depends number variables far individual trusts organisation information asked combemale chris taking leap faith dataiq september accessed march international institute communications personal data management user perspective international institute communications september big data artificial intelligence machine learning data protection version boston consulting group bcg found consumers countries privacy personal data remains top issue young people aged slightly less cautious abou use personal online data older age groups kpmg global survey found whil attitudes privacy varied based factors types data data usage consumer location average respondents reported concerned extremely concerned companies using personal data studies pointed privacy paradox people may express concerns impact privacy creepy uses data practice contribute data anyway via online systems use words provide data price using internet services instance findings pybus cot blanke study mobile phone usage young people two separate studies shklovski looking smartphone usage western europe supported idea privacy paradox also argued prevalence web tracking means practice web users choice enter unconscionable contract allow data suggests people may resigned use data feel alternative rathe indifferent positively welcoming finding study consumers annenberg school rose john trust advantage win big data boston consulting group november accessed june kpmg crossing line staying right side consumer privacy kpmg november accessed january pybus jennifer cote mark blanke tobias hacking social life big data big data society vol accessed march shklovski irina leakiness creepiness app space perceptions privacy mobile app use proceedings annual acm conference human factors computing stems acm peacock sylvia web tracking changes user agency age big data used user big data society vol accessed march big data artificial intelligence machine learning data protection version study criticised view consumers continued provide data marketers consciousl engaging trading personal data benefits discounts instead concluded americans believe futile try control companies learn want lose control personal data simply resigned situation cases fact people continue use services extract analyse personal data may also mean invest certain level trust organisations particularly major serv ice providers familiar brands trust organisation put data bad use given practical difficulty reading understanding terms conditions controlling use one data least pragmatic time obliges organisation exercise proper stewardship data exploit people trust return point section ethical approaches chapter survey digital showed generally low level trust public sector trusted use personal data responsibly respondents financial services next trusted sector respondents ectors much lower rating hand survey found significant proportion people happy data shared purposes education health themes feeling resignation despite general lack trust combined willingness data used socially useful purposes reflected report summarised several recent surveys public attitudes data use previous suggested people concerns data use particularly companies really turow joseph hennessy michael draper nora tradeoff fallacy marketers misrepresenting american consumers opening exploitation university pennsylvania annenberg school communication june accessed march trust personal data review digital catapult july accessed march big data public views collection sharing use big data governments companies sciencewise april views accessed march forbes insights turn promise privacy respecting consumers limits realizing marketing benefits big data forbes insights big data artificial intelligence machine learning data protection version security data privacy however borne european surveys referred sciencewise report identified several concerns surveillance study wellcome trust consisting focus groups telephone interviews found widespread wariness spied government corporations criminals discrimination study revealed concerns possible discrimination people based medical data instance data shared employers might make discriminatory decisions people mental health issues consent online survey con ducted demos found people top concern personal data use companies using without permission data sharing institute insight public services conducted telephone survey revealed ile people generally happy personal data held one organisation concerned shared others concerns centred loss control personal data fear errors data would perpetuated sharing also evidence people trying exercise measure privacy protection deliberately giving false data study verve found consumers intentionally provide incorrect information submitting personal details online problem even younger people attitudes seem changing trend among generation towards using social media apps appear privacy accessed june chahal mindi consumers databases false details marketing week july databases accessed march williams alex move millennials comes generation new york times september move accessed march big data artificial intelligence machine learning data protection version microsoft digital trends repor noted trend called right identity means rather simply wishing preserve privacy hrough anonymity significant percentage global consumers want able control long information shared stays online also interested services help manage digital identity suggests consumers increasing expectations organisations use data want able influence people continue provide personal data use services collect data necessarily mean happy data used simply indifferent many people may resigned situation feel real control evidence people concerns data use also desire control data used leads conclusion expectations significant issue needs addressed ass essing whether particular instance big data processing fair transparency complexity big data analytics mean processing opaque citizens consumers whose data used may apparent data collected mobile phone location processed search results filtered based algorithm filter bubble similarly may unclear decisions made use social data credit scoring opacity lead lack trust affect people perceptions engagement organisation processing issue public sector lack public awareness become barrier data sharing inadequate provision information public data use seen barrier roll project study wellcome trust public digital trends microsoft march advertising accessed march pariser eli beware online filter bubbles ted talk march language accessed april house commons science technology committee big data dilemma fourth report session stationery office february big data artificial intelligence machine learning data protection version attitudes use data found low level understanding awareness anonymised health medical data used role companies medical research people expectations use data dealing company though unaware uses social data differe expectations using public services however aware health data might also used companies research report referred example context collapse private sector transparency also mean companies miss competitive advantage comes gaining consumer trust stresses portance informed trust inevitably means open processing personal data collected businesses treated mere property transferred irrevocably like used car data subject data user data sharing succeed organizations involved earn informed trust customers many arrangements today murky furtive undisclosed many treat data subject product resold customer served busi nesses risk ferocious backlash competitors grabbing competitive advantage establishing trust legitimacy customers use big data implications regarding transparency processing personal data still key element fairness dpa contains specific transparency requirement form fair processing notice simply privacy notice privacy notices discussed detail chapter tool aid compliance transparency principle big data context accessed april ipsos mori social research institute one mirror public attitudes commercial access health data ipsos mori march accessed april evans philip forth patrick borges map navigating world digital disruption boston consulting oup april accessed april big data artificial intelligence machine learning data protection version conditions processing personal data obtaining meaningful consent often difficult big data context novel innovative approaches help relying legitimate interests condition soft option big data organisations must always balance interests individuals concerned may difficult show big data analytics strictly necessary performance contract big data analysis carried public sector may legitimised conditions instance processing necessary exe rcise functions government department first dpa principle processing personal data must fair lawful must also satisfy one conditions listed schedule dpa schedule sensitive personal data defined dpa applies equally big data analytics use personal data schedule conditions likely relevant big data analytics particularly commercial context consent ether processing necessary performance contract legitimate interests data controller parties guide data explains conditions detail consider relate big data analytics specifically consent organisation relying people consent condition processing personal data consent must freely given specific informed indication agree means people must able understand organisation going data specific information commissioner office guide data protection ico may accessed june directive european parliament council october protection individuals regard processing personal data free movement data article big data artificial intelligence machine learning data protection version informed must clear indi cation consent gdpr makes clearer consent must also unambiguous must clear affirmative action ticking box website choosing particular technical settings information society services servic delivered internet social app furthermore data controller must able demonstrate consent given data subject must able withdraw suggested tice consent model organisation tells data subjects going data practical big data context opaque nature analysis using techniques make difficult meaningful consent consent also criticised binary gives people choice outset seen incompatible big data analytics due experimental nature propensity find new uses data als may fit contexts data observed rather directly provided data however new approaches consent beyond simple binary model may possible process graduated consent ich people give consent different uses data throughout relationship service provider rather simple binary choice start linked time notifications example point app wants use mobile phone location data share data third party user asked give consent recent report european union agency network information security enisa found positive developments way consent obtained real barrier usability called technical innovation methods obtaining consent gdpr article recital gdpr article buttarelli giovanni smart approach counteract bias artificial intelligence european data protection supervisor november accessed december nguyen carolyn user approach data dilemma context architecture policy digital enlightenment forum yearbook big data artificial intelligence machine learning data protection version practical implementation consent big data beyond existing models provide automation collection withdrawal consent software agents providing consent user behalf based properties certain applications could topic explore moreover taking account sensors smart devices big data types usable practical user positive actions could constitute consent gesture spatial patterns behavioral patterns motions need analysed royal academy engineering oked benefits big data analytics several sectors risks privacy health sector suggested cases personal data used consent anonymisation possible consent could time limited hat data longer used time limit addition principle people given consent also withdraw time said seeking consent government nhs take patient approach explain societal benefits effect privacy examples suggest complexity big data analytics need obstacle seeking consent organisation identify potential benefits using personal data big data analytics able explain users seek consent condition chooses rely must find point explain benefits analytics present users meani ngful choice respect choice processing personal data organisation buys large dataset personal data analytics purposes becomes data controller regarding data organisation needs sure met condition dpa use data relying original consent obtained supplier giuseppe privacy design big data overview privacy enhancing technologies era big data analytics enisa december accessed april royal acad emy engineering connecting data driving productivity innovation royal academy engineering november accessed april big data artificial intelligence machine learning data protection version condition ensure covers processing plans data issue often arises ontext marketing databases guidance direct explains dpa privacy electronic communications regulations apply issue indirect third party consent people put data onto social media without restricting access necessarily legitimise use fact data viewed mean anyone entitled use purpose person posted implicitly consent use particularly issue social analytics used profile indivi duals rather general sentiment analysis study people company using social data profile individuals recruitment purposes assessing insurance credit risk needs ensure data pro tection condition processing data individuals may consented specifically joined social service company may seek consent example part service help people manage online presence company consent needs consider data protection conditions may relevant processing personal data meet one conditions dpa gdpr consent one condition processing persona data condition available greater status others circumstances consent required example electronic marketing calls others different condition may appropriate legitimate interests condition schedule condition dpa processing necessary legitimate interests organisation collecting data others made available however process ing must unwarranted prejudice rights freedoms legitimate information commissioner office direct marketing ico may accessed june liu bing zhang lei survey opinion mining sentiment analysis mining text data springer see direct marketing guidance detail point big data artificial intelligence machine learning data protection version interests data subjects gdpr condition expressed follows processing necessary purposes legitimate interests pursued controller third party except interests overridden interests fundamental rights freedoms data subject require protection personal data particular data subject child organisation may several legitimate interests could relevant including profiling customers order target marketing preventing fraud misuse services physical security however meet condition processing must necessary legitimate interests means must potentially interesting processing necessary another way meeting legitimate interest interferes less people privacy established legitimate interest organisation must balancing exercise interests rights legitimate interests individuals concerned organisations seeking rely condition must pay particular attention analytics affect people privacy complex assessment involving several factors opinion article working legitimate interests current data protection directive sets deta assess factors balancing exercise legitimate interests condition one alternative seeking data subjects active consent organisation relying legitimise big data processing need seek consent individuals concerned still tell line fairness requirement furthermore european data protection supervisor big data cases difficult strike gdpr article article data protection working party opinion notion legitimate interests data controll article directive european commission april accessed june european data protection supervisor meeting challenges big data opinion edps november big data artificial intelligence machine learning data protection version balance legitimate interests organisation rights interests data subject may helpful also give people opportunity opt opt would necessarily satisfy dpa requirements valid consent belt braces approach could help safeguard rights interests data subjects legitimate interests condition soft option organisation means takes responsibility consent condit ion organisation must ensure processing fair satisfies data protection principles individual responsible agreeing processing may proceed without consent contrast legitimate interests condition places responsibility organisation carry assessment proceed way respects people rights interests means big data organisatio framework values test proposed processing method carrying assessment keeping processing review also able demonstrate elements place cas objections data subjects investigations regulator also noted gdpr data controller relying legitimate interests explain privacy larger organisation least may need form ethics review board make assessment form internal regulation line trend noted business government towards develop ing ethical approaches big data discuss section ethical approaches chapter given difficulties associated consent big data context legitimate interests may provide alternative basis processing hich allows balance commercial societal benefits rights interests individuals example paper information accountability holistic governance model big data gives examples different nterests play iot scenarios suggests consent important accessed april gdpr article cullen peter glasgow jennifer crosley stan introduction hgp framework information accountability foundation october accessed april big data artificial intelligence machine learning data protection version uses data others may appropriate cases legitimate interests condition inherent balancing test may alternative con tracts condition schedule dpa processing necessary performance contract data subject party gdpr also contains similar provision relevant example someone makes purchase online website process name address credit details complete purchase specific consent required problem applying big data context processing must nece ssary big data analytics nature likely represent level analysis goes beyond required simply sell product deliver service often takes data generated basic provision service repurpo ses may difficult show big data analytics strictly necessary performance contract public sector issues regarding conditions processing may different case public authorities administrati data used big data analytics unlikely collected basis consent legitimate interests conditions available example processing necessary exercise functions conferred law functions government departments public functions public provisions also reflected furthermore nder gdpr legitimate interests condition available public authorities since apply processing carry performance tasks hmrc connect example big data analytics public sector based statutory powers rather consent used identify potential tax fraud ringing gdpr article dpa schedule gdpr article gdpr recital article bdo hmrc evolution digital age implications taxpayers bdo march pdf accessed april big data artificial intelligence machine learning data protection version together billion items data sources including tax returns paye interest bank accounts benefits tax credit data land registry dvla credit card sales online marketplaces social media cases use data public sector may require consent administrative data research network makes large volumes public data available research systems place ensure data used analysis ano nymised task force led said administrative data linked survey data supplied voluntarily individuals consent would normally required linkage even linked data analysis another belt braces approach would support interest safeguarding rights freedoms data subjects administrative data taskforce administrative data research network improving access research policy administrative data taskforce december pdf accessed april big data artificial intelligence machine learning data protection version purpose limitation purpose limitation principle necessarily create barrier big data analytics means assessment compatibility processing purposes must done fairness key factor determining whether big data analysis incompatib original processing purpose second data protection principle creates two test first purpose data collected must specified lawful gdpr adds explicit second data processed purpose must incompatible original purpose big data challenges principle purpose limitation principle barrier development big data analytics reflects view big data analytics fluid serendipitous process analysing data using many different algorithms reveals unexpected correlations lead data sed new purposes sugg est purpose limitation principle restricts organisation freedom make discoveries innovations purpose limitation prevents arbitrary need insuperable barrier extracting value data issue assess compatibility article working party opinion purpose current directive says providing processing authorised long incompatible requirements lawfulness simultaneously also fulfilled would appear gdpr article example world economic forum unlocking value personal data collection usage world economic forum february accessed june article data protection working party opinion purpose limitation european ommission april accessed june big data artificial intelligence machine learning data protection version legislators intended give flexibility regard use use may fit closely initi purpose different fact processing different purpose necessarily mean automatically incompatible needs assessed basis opinion sets detailed app roach assessing whether processing incompatible purpose also addresses directly issue repurposing data big data analytics identifies two types processing first done detect trends rrelations second done find individuals make decisions affecting first case advocates clear functional separation analytics operations second says free specific informed unambiguous consent would almost always required otherwise use considered compatible also emphasises need transparency allowing people correct update profiles access data portable user machine format view key factor deciding whether new purpose incompatible original purpose whether fair particular means considering new purpose affects privacy individuals concerned whether within reasonable expectations data could used way also reflected gdpr says assessing compatibility necessary take account link original new processing reasonable expectations data subjects nature data consequences processing existence example information people put social media going used assess health risks credit worthiness market certain products unless informed asked give consent unlikely fair compatible new purpose uld otherwise unexpected involves making decisions individuals cases organisation concerned need seek specific consent addition assessing whether new purpose incompatible original ason processing data ibid gdpr recital big data artificial intelligence machine learning data protection version organisation buying personal data elsewhere big data analytics needs practi due diligence need assess whether new processing incompatible original purpose ata collected well checking whether needs seek consent provide new privacy notice big data artificial intelligence machine learning data protection version data minimisation collection retention big data analytics result collection personal data excessive processing purpose organisations may encouraged retain personal data longer necessary big data applications capable analysing large volumes data data protection legislation embodies concept data minimisation organisations minimise amount data collect process length time keep data principle dpa says personal data shall adequate relevant excessive relation purpose purposes processed principle says personal data processed purpose purposes shall kept longer necessary rpose purposes gdpr says personal data shall adequate relevant limited necessary relation purposes processed contrast big data analytics tends involve collecting analysing data possible many cases ata points particular set rather sample issue regarding data minimisation simply amount data used whether necessary purposes processin excessive hypothetical problem study businesses france germany said gathered data subsequently excessive data collection data protection issue also make difficult businesses locate work data actually need big data also variety data sources used analysis terms principle raises questions whether relevant big data analytics may discov unexpected correlations example data people lifestyles credit gdpr article pure storage big data big failure struggles businesses ace accessing information need pure storage december ata accessed april big data artificial intelligence machine learning data protection version worthiness mean information obtained necessarily relevant purpose assessing credit risk finding correlation retrospectively justify obtaining data first place principle requirement personal data shall kept longer necessary purpose processed supports data privacy indiv iduals also reflects good practice records management however world big data may problematic two reasons first capacity store data increases time cost storing falling words technology historian george dyson big data happened cost storing information became less cost throwing away second ability big data analytics process huge volumes data may encourage data controllers keep long runs historical data beyond period required normal business purposes gdpr introduces right forgotten data subjects right data erased several situations apply example data longer necessary purpose collected processed basis consent data subject withdraws consent particularly issue business rather public sector since right forgotten apply processing necessary legal obligation exercise official authority may practically difficult business find erase someone data stored across several different organisations therefore need able articulate outset need collect process particular dataset need clear expect learn able processing data thus satisfy data relevant excessive relation aim challenge define purposes processing establish data relevant warner andrew george dyson seminar media long foundation march accessed april gdpr article becoming analytics organisation create value ernst young january accessed april big data artificial intelligence machine learning data protection version big data organisations also need adopt good information governance particular enforce appropriate retention schedules retention periods may specified general records management accounting stand ards sectors regulatory requirements long records kept research contexts clinical trials long studies important commercial context businesses likely interested analysing current data rather historical records understand following principles may harder big data context would argue well relevant data acquiring keeping data case may useful helps improve data quality assists view supported ibm white paper information lifecycle governance big data environment ibm january accessed april big data artificial intelligence machine learning data protection version accuracy implications regarding accuracy personal data stages big data project collection analysis application results data analysis may representative population whole hidden biases datasets lead inaccurate predictions individuals fourth principle dpa requires personal data accurate necessary kept date obviously good practice terms information management also linked rights individual people right inaccurate data corrected contrast suggested big data analytics tolerate certain amount messy inaccurate data volumes data processed generally certain level messiness incorrect name address may problem analytics used detect general trends much likely problematic processing used profile particular individuals may thought able analyse vast amounts data identif correlations inevitably lead better analysis trends accurate predictions however even data recorded accurately content tweet location mobile phone necessarily mean concl usions drawn accurate using available data feature big data analytics may exclude certain groups growing interest using data social media study behaviour natural disasters example analysis made tweets postings foursquare new york indicators people behaviour around time hurricane sandy however social messages originated fro manhattan rather storm areas power mayer viktor cukier kenneth big data revolution transform live work think john murray big data artificial intelligence machine learning data protection version blackouts limited mobile stark illustrat obvious fact analysis based social media necessarily representative whole population even ther obvious gaps data collected represent particular population may discrepancy people express social media behave real world issues accurately big data represents population whole limited social sources city boston makes available street bump app mobile phones car journey app uses phone accelerometer gps positioning record unusual movements due probl ems road potholes transmits data council analysis council aware varying levels mobile ownership among different socioeconomic groups means data may collected affluent areas rathe worst machine learning may contain hidden bias common phrase used discussion machine learning garbage garbage essentially input data contains errors inaccuracies outp data whil supervised machine learning particular often involve stage improve quality input human training dataset create opportunity inaccuracies bias creep hypot hetically predictive model used recruitment may achieve overall accuracy rate may accurate majority population make applicants wholly inaccurate minority groups make oth would necessary test build corrective examples given even raw data used analysis recorded accurately may issues representative dataset whether nalytics contain hidden bias potentially data protection issue crawford kate hidden biases big data harvard business review april accessed may crawford kate hidden biases big data harvard business review apri accessed may marinov svetoslav get machine learning systems itproportal june accessed december kotsiantis kanellopoulo pintelas data preprocessing supervised leaning international journal computer science ajunwa ifeoma hiring algorithm predicting preventing disparate impact ssrn march accessed june big data artificial intelligence machine learning data protection version application phase acting data results analytics used profile individuals profiling people way involves creating derived inferred data given issues highlighted data may inaccurate lead incorrect predictions behaviour health creditworthiness insurance risk also raises questions general fairness rocessing big data artificial intelligence machine learning data protection version rights individuals vast quantities data used big data analytics may make difficult organisations comply right access personal data organisations need appropriate processes place deal gdpr extension rights regarding decisions based automated processing subject access dpa gives individuals powerful rights access personal data rights still apply world big data people right told personal data processed purposes processed may disclosed right rece ive copy information constitutes personal data well information sources right limited exemptions set dpa associated secondary legislation gdpr data controller provide example say long keep personal data least explain criteria determining furthermore person makes request electronically data controller must provide information commonly used electronic form unless requester specifies otherwise volume variety big data complexity analytics could make difficult organisations meet obligation however reasons excuse disregarding legal obligations existence right access compels organisations practi good data management need adequate metadata ability query data find information individual know ledge whether data processing truly anonymised whether still linked individual historically common problem organisations dealing subject access requests informati held gdpr article big data artificial intelligence machine learning data protection version different places discussions industry suggested organisation move big data means disparate data stores brough together may make easier find data individual organisation using buying range data sources including unstructured data difficult produce data one individual moreover incr easing use observed derived inferred data means data held may provided directly data subject however cases actual data held individual may necessarily extensive hard identify even though analytics applied complex extensive example data question may record phone calls also available customer itemised phone bill organisations already make data available custo mers request proactively online secure usa data broker acxiom web portal enable people see data held marketing purposes sources likely become comm gdpr encourages possible controller able provide remote access secure system would provide data subject direct access personal data personal data made available like help organisation meet data protection obligations could also help reassure people amount type information held rights dpa individuals already several rights regarding prevention processing likely cause damage distress prevention direct right subject purely automated decision making gdpr recital guidance direct marketing dpa privacy electronic communications regulations see information commissioner office direct marketing ico may marketing accessed may big data artificial intelligence machine learning data protection version rectification inaccurate data organisatio using big data need ensure systems allow people exercise rights gdpr extend rights particular deal specifically profiling defin ing form automated processing personal data consistin using data evaluate certain personal aspects relating natural person particular analyse predict aspects concerning natural person performance work economic situation health personal preferences interests reliabil ity behaviour location movements people right subject decision based solely automated processing including profiling significantly affects automated decisions made online credit applications right qualified apply profiling necessary contract data subject data controller authorised law people given explicit consent neverthele given feature big data ability profile individuals make decisions applying algorithms large amounts granular data likely significant affect individuals right may apply cases linked right explanation decision based automated processing discussed detail section accountability governance gdpr also contains new rights data portability discussed section personal data stores chapter gdpr article gdpr article recital big data artificial intelligence machine learning data protection version security several information security risks specific big data analytics organisations need recognise new risks put place appropriate security measures big data analytics used improve information security ability analyse huge volumes data quickly means used analyse network traffic transactions log files big handle technologies analytics detect patterns anomalies rapidly identify security time questions raised whether big data creates new security risks enisa produces regular report big data threat landscape latest recognised big data analytics powerful tool detecting secu rity risks also identified several potential security risks specific big data processing example high level replication big data storage frequency outsourcing analytics increase risk breaches data leakages degradation also creation links different datasets could increase impact breaches leakages enisa looked security big data three sectors financial services energy telecoms enisa identified threats access controls ability securely restore datasets validation data sources enisa proposed measures mitigat threats reports clearly indicate addition security issues associated system specific security threats arise big data working group big data analytics security intelligence cloud security alliance september accessed june curry sam big data fuels intelligence security rsa security brief emc january security accessed may damiani ernesto big data threat landscape good practice guide enisa january accessed may naydenov rossen big data security good practices recommendations security big data systems enisa december acces sed may big data artificial intelligence machine learning data protection version nature big data processing need addressed data controllers part risk assessme order meet requirement dpa gdpr put place appropriate security measures protect personal data cases practical carry big data analytics cloud case organisations obtain sufficient guarantees cloud provider security measures uses guidance use cloud explains data protection issues involved information commissioner office guidance use cloud computing ico october accessed june big data artificial intelligence machine learning data protection version accountability governance accountability increasingly important big data analytics become explicit requirement gdpr big data organisations may need make changes reporting structures internal record keeping resource allocation machine learning algorithms potential make decisions discriminatory erroneous unjustified data quality key issue information governance responsibilities big data context concept accountability always implicit requirement dpa however gdpr importance elevated introduc ing explicit accountability principle requires organisations demonstrate compliance principles emphasised several provisions throughout gdpr promote accountability requirements new principle several implications organisations undertaking big data analytics one accountability requirements records processing activities must maintained circumstances among others organisations mor employees processing personal data could result risk individuals rights freedoms likely organisations involved big data analytics may fall within one situations one records must maintained purposes processing personal may problematic big data context initial analysis data often experimental without predefined hypothesis business unique feature big data analytics discussed detail privacy notices section chapter means ultimate reasons gdpr article gdpr article andreev alexei death hypothesis investing big data analytics deep learning harr harris group september accessed december big data artificial intelligence machine learning data protection version processing may unclear may make difficult state purposes part internal record keeping furthermore purpose organisation initially records may change new correlations data discovered prompt different uses accountability provision gdpr requirement appoint data rotection fficer dpo necessity almost public authorities also organisations systematic ally monitor individuals large scale including using big data analytics purposes online behaviour tracking profiling although mainly affect smaller organisations may currently appointed dpo also implications big data organisations already dpo gdpr places new obligations orga nisations regarding dpo position tasks may require changes reporting structures provision additional importance accountability limited explicitly stated provisions gdpr extends aspects organisation processing operations involving personal data given growing popularity types big data analytics machine learning recently increasing discussion role algorithm decision making often referred algorithmic accountability essence able check algorithms used developed machine learning systems actually think producing iscriminatory erroneous unjustified results regards discrimination associated issues relating effects processing personal data discussed fairness section autonomous opaque nature machine learning algorithms mean decisions based output may identified discriminatory afterwards effects already felt people discrimina ted instance propublica analysed risk scores produced machine learning tool used states predict future criminal behaviour defendants findings revealed discrimination based race black defendants falsely classified future criminals nearly twice many occasions gdpr article gdpr article taneja hemant need algorithmic accountability techcrunch september accessed december big data artificial intelligence machine learning data protection version white detecting discriminatory decisions hindsight sufficient comply accountability provisions big data analysts need find ways build discrimination detection machine learning systems prevent decisions made first place regards erroneous algorithmic decisions clear implications data protection principle accuracy inaccurate predictions based biased profiling discussed accuracy section however profiling decisions need held account accuracy association algorithms find links data applied real world situations instance autocomplete functionality google search engine suggests words machine learning algorithms determined associated user type decision problematic regarding accuracy autocomplete associations twice contested german courts one case involv businessman discovered google linked scientology fraud another involv wife former german president sued google autocomplete suggestions words linked escort nicholas diakopoulos article accountability algorithmic decision making makes following point associations one issue church big data overriding faith correlation king correlations certainly create statistical associations data dimensions despite popular adage correlation equal causation people often misinterpret correlational associations causal distinction correlation causation important organisations using machine learning algorithms discover associations need appropriate consider distinct ion potential accuracy inaccuracy resulting decisions angwin julia make algorithms accountable new york times august accessed december gdpr recital rangaswami shanta analysis optimized association rule mining algorithm using genetic algorithm ijca proceedings international confer ence information communication technologies icict october bbc news germany tells google tidy auto bbc may accessed december diakopoulos nicholas accountability algorithmic decision making communications acm big data artificial intelligence machine learning data protection version regards justification decisions based machine learning algorithms issues fairness discussed also mplications new right gdpr obtain explanation decision based automated suggested right easily circumvented restricted solely automated processing decisions significa ntly affect however still many situations right likely apply credit applications recruitment insurance circumstances may difficult provide meaningful response individua exercising right explanation jenna burrell notes paper opacity machine learning algorithms computers learn make decisions without regard human comprehension big data organisa tions therefore need exercise caution relying machine learning decisions rationalised human understandable terms insurance company work intricate nuances cause online application system tur people away accept others however reasonable underlying reasons may hope explain individuals affected related concept accountability data quality information governance data quality key issue organisations using big data analytics linked often seen fourth big data veracity words reliability senior managers big data organisations need know whether tru data apparently telling involve looking example sources data accurate whether sufficiently date securely kept whether restrictions used forrester carried survey senior executives companies dealing big data asking best describes govern big data today top issues gdpr recital jaakonsaari liisa sets agenda algorithmic accountability euractiv october accessed december burrell jenna machine thinks understanding opacity machine learning algorithms big data society example ibm institute business value analytics real world use big data ibm october accessed june forrester consulting big data needs agile information integration governance forrester research inc august accessed june big data artificial intelligence machine learning data protection version identified included following case also identif ied relevant data protection provisions information overnance issue data protection provision security monitoring princip security protectio masking sensitive data sensitive data definition conditions processing profiling data sources lineag traceability format etc anonymisation definition personal data principle fairness data lifecycle management archiving data principle retention clear information management issues implications data protection means data protection seen simply matter complying external legal requirements addressing data protection issues supports good practice information governance forrester study ound mature information governance linked business success essential realising benefits big data data protection seen enabler success barrier growth big data led ganisations create position chief data role typically includes overall responsibility data quality data security suggest also involves consideration data protection may traditionally seen mpliance function terlink marc new hero big data analytics chief data officer ibm june accessed june big data artificial intelligence machine learning data protection version data controllers data processors big data analytics make difficult distinguish data controllers data processors organisations outsourcing analytics companies specialising machine learning need consider careful control processing personal data dpa distinction made data controllers data processors data controller name suggests overall control processing personal data determines purposes manner processing either jointly common another data controller however data processor contro merely processes personal data data controller behalf data controller uses data processor dpa says written contact must place ensure data processor acts upon instructions ultimate responsibility compliance dpa lies data controller guidance differences governance implications data controllers data processors goes definitions data controllers data processors similar gdpr however data processors share responsibility compliance regulation pecifically regarding adoption appropriate security measures possibility regulatory action failure comply gdpr also sets certain details contracts data controllers data processors must contain types data purpose duration processing categories data distinguishing data controllers data processors relatively straightforward certain circumstances instance organisation chooses store stomer data cloud cloud provider likely data processor simply acting data protection act part section information comm issioner office data controllers data processors difference governance implications ico may accessed february gdpr article big data artificial intelligence machine learning data protection version original organisation behalf determining purposes processing however hen personal data processed context big data machine learning make difficult distinguish data controllers data processors typically big data analytics finding correlations making predictions aiding decision blur lines actually determining purposes manner processing organisation chosen outsource analytics another company one specialises example therefore outsourcing big data analytics companies careful consideration given control processing personal data actually lies implications compliance liability organisation intends cond uct big data outsourcing data controller processor relationship important contract includes clear instructions data used specific purposes processing however existence con tract would automatically mean company analysis dat processor company enough freedom use expertise decide data collect apply analytic techniques likely data cont roller well instance forthcoming article transfer data royal free london nhs foundation trust google deepmind julia powles argues despite assertions contrary deepmind actually joint data controller opposed data powles julia google deepmind healthcare age algorithms forthcoming journal health technology big data artificial intelligence machine learning data protection version chapter compliance tools previous chapter discussed several key data protection implications arise use big data analytics turn compliance tools help organisations meet data protection obligations protect people privacy rights big data context anonymisation often data analytics require use data identifies individuals anonymisation successful tool takes processing data protection sphere mitigates risk loss personal data organisations using anonymisation techniques need make robust assessments risk persona data fully anonymised longer personal data context anonymised means possible identify individual data data combination data taking account means reasonably likely used identify data longer personal data covered data protection legislation gdpr makes principles data protection therefore apply anonymous information namely information relate identified identifiable natural person personal data rendered anonymous manner data subject longer identifiable therefore key question big data organisations whether need use data identifies individuals many examples use anonymised data big data analytics telefonica gdpr recital big data artificial intelligence machine learning data protection version smart tool uses data location mobi phones network track movement crowds people used retailers analyse footfall particular location data identifies individuals stripped analysis anonymised data aggregated gain insights population whole combined market research data sources another example medical research data clinical trials rigorously anonymised bei made available analysis practice anonymised data may used several scenarios organisations may bring anonymised data may seek irreversibly anonymise data using sharing others commentators pointed exa mples apparently possible identify individuals anonymised datasets concluded anonymisation becoming increasingly ineffective world big hand cavoukian found shortcomi ngs main studies view based recent mit study looked records three months credit card transactions million people claimed using dates locations four purchases possible identify ercent people dataset however khalid emam pointed researchers able identify unique patterns spending actually identify individuals also suggested practice access data set would controlled also anonymisation techniques applied dataset particularly sophisticated could improved may possible establish absolute certainty individual identified particular dataset taken together data may exist elsewhere issue telefonica smart steps accessed june example president council advisors science technology big data privacy technological perspective white house may accessed june cavoukian anne castro daniel big data innovation setting record straight work office information privacy commissioner ontario june ussion accessed june emam khaled safe anonymise data bmj february haled accessed june big data artificial intelligence machine learning data protection version eliminating risk altogether whether mitigated longer significant organisations sho uld focus mitigating risks point chance identification extremely remote range datasets available power big data analytics make difficult risk underestimated make anonymisation impossible ineffective organisations using anonymised data need able show robust assess risk adopted solutions proportionate risk may involve range technical measures data masking pseudonymisation aggregation well legal organisational safeguards ico anonymisation code practi explains detail anonymisation may used data shared externally within organisation example organisation may hold dataset containing personal data one data store produce anonymised version used analytics separate rea whether remains personal data depend whether anonymisation keys relevant data enable identification kept organisation even data remains personal data still relevant safeguard consider processing comply data protection principles administrative data research network example identified data used made four administrative data research centres adrcs provid secure environment accredited researchers working approved projects access administrative data collected government adrcs hold personal identifiers data instead personal identifiers sent trusted ird parties third parties match records individual across different datasets send results matching adrc hold research data individuals means researchers see data need including matchings across different datasets without personal identifiers information commissioner office anonymisation managing data protection risk code practice ico november accessed june administrative data research network accessed june big data artificial intelligence machine learning data protection version anonymisation network ukan originally funded ico also important role providing expert advice anonymisation techniques consortium universities manchester southampton open data institute ons anonymisation seen merely means reducing regulatory burden taking processing outside dpa lso means mitigating risk inadvertent disclosure loss personal data tool assists big data analytics helps organisation research develop products services also enables organisations provide assurance indi viduals data identif ying used analytics part process building trust key taking big data forward anonymisation network website accessed june big data artificial intelligence machine learning data protection version privacy notices several innovative approaches providing privacy notices including use videos cartoons notifications standardised icons using combination approaches help make complex information big data analytics easier understand dpa says apart certain specified circumstances processing personal data considered fair unless data subject given basic information including data controller identity purpose proce ssing information necessary processing fair privacy notices code explains wit practical examples gdpr expands requires data controller provide detailed information includes existence automated decision including profiling case data controllers explain logic volved significance envisaged consequences profiling data subject refers decisions based solely automated processing rather decisions made people may relevant big data scenarios algori thms developed initial discovery phase applied make decisions individual cases example credit scoring case data controllers find ways describe meaningful terms decision made big data context requirements problematic suggested privacy notices feasible regarding big data analytics argued several grounds people unwilling read lengthy privacy notices context data collected smartphone apps iot devices make practically difficult give information commissioner office privacy notices code practice ico december accessed april gdpr article big data artificial intelligence machine learning data protection version information analytics used big data difficult explain terms people understand given big data analytics often involves repurposing data data controller foresee outset uses may made data people read privacy notices ticking box say read agreed terms conditions bee described biggest lie web clearly people want buy something online download app often tick agree without reading privacy notice reluctance read privacy tices well documented house com mons science technology committee heard evidence read terms conditions encountered internet would take month per white house report big noted phenomenon privacy fatigue found even though advertisers provided information use data people read understood report ofcom wik consult says little incentive people read privacy policies using internet since would take significantly time spend using content however would wrong infer people indifferent data used requirement provide privac information therefore irrelevant inapplicable big house commons science technology committee responsible use data stationery office ltd november accessed june executive office president big data seizing opportunities preserving values white house may accessed april arnold rene hillebrand annette waldburger martin personal data privacy wik consult may accessed april big data artificial intelligence machine learning data protection version data context discussed section expectations chapter people attitudes use data complex simplistic approach would suggest rather studies referred previous paragraph suggest problem lies format many privacy notices nderstandable people unwilling read privacy notices long written legalistic terms intended primarily protect organisation using data rather informing data subject view rather making privacy ices irrelevant big data challenges organisations innovative area using analytics find new ways conveying information concisely privacy notices written plain english person average rea ding age mind context important recognise data subjects concerned may well young people textual information accompanied ways delivering information form channel use youtube accompany viewer promise one example innovative approach use cartoons explain privacy policies combination different approaches used make information easier understand house commons science technology committee called government take lead encouraging clarity simplicity privacy two years later noted combination consumer demand reputational concerns leg islative pressure beginning effect gave examples improved practice google report british standards institution bsi said clearer simpler privacy information would benefit consumers businesses channel website accessed april guardian website accessed june website accessed april house commons science technology committee responsible use data stationery office ltd november accessed june house commons science technology committee big data dilemma fourth report session stationery office ltd february accessed june big data artificial intelligence machine learning data protection version planning develop set standards specifically big data including terms conditions several organisations abroad currently working practical ways make privacy notices well advocating use plain language approaches include identifying defining commonly used terms creating database different contexts standard icons suggested since nutrition informati conveyed standardised ways food packaging similar approach could applied privacy notices gdpr encourages clarity new approaches says information addressed public data subject concise easily accessible easy understand clear plain language additionally appropriate visualisation used says particularly relevant situations online advertising proliferation actors technological complexity practice make difficult data subject know understand personal data relating collected purpose also says standardised icons used explain new methods data collection big data includes data collected observed apps devices rather provided directly individuals challenging provide privacy notice possible addr ess issue following examples show guidance privacy mobile gives examples notice within app store notices including layered privacy notice brief summary information given along link detailed circle research big data standards market research bsi standards ltd january accessed april example biggest lie common terms meaningful consent project gdpr recital gdpr recital article information commissioner office privacy mobile apps ico december accessed june big data artificial intelligence machine learning data protection version policy notification point data collected article working party looked data protection issues associated iot devices focusing wearable computing watches glasses quantified self devices activ ity trackers devices home smart thermostats suggested privacy information could provi ded device broadcasting information via making available publish guidance location collection mac addresses devices trying connect network provided businesses customers use premises recommends giving privacy information rough signage building location data processed port page network recognise contexts may difficult provide information required dpa gdpr way encourages people read advice documents privacy notices code practice suggests possible important consider early stage development information provided look relationship usability privacy big data hard explain may argued difficult explain processing privacy notice big data tends rely complex analytics algorithms however would misunderstand purpose privacy notice dpa require privacy notice describe data processed technical details algorithms work purposes processed dpa also clear article data protection working party opinion recent developments internet things european commission september accesse june information commissioner office location analytics ico february accessed june privacy commissioner ontario privacy design user interfaces accessed june big data artificial intelligence machine learning data protection version processing fair people deceived misled even difficult explain simple terms analytics works possible explain purposes way deceive mislead unforeseen purposes given propensity big data find unexpected correl ations datasets therefore find new uses data may difficult organisation foresee outset uses may make data collects big data may involve discovery phase thinking data organisation analyses data find useful correlations implies bottom approach starting data rather specific business need recommendation consultants report big data telecoms industr operators seeking make initial inroads big data advised avoid usual top approach sets business problem solved seeks data might solve instead operators begin data experimenting hand see kinds connections correlations reveals approach may feature big data remove requirement provide privacy notice personal data bei processed big data organisations must identify purposes processing earliest possible stage communicate data subjects people misled data used alternatively individuals need entified initial discovery phase organisation consider using anonymised data instead ability analyse data different purposes using location mobile phones plot movements people traffic important characteristic benefit big data analytics organisation collected personal data one data protection act schedule part acker olaf blockus adrian ptscher florian benefiting big data new approach telecom industry strategy april accessed april big data artificial intelligence machine learning data protection version purpose wants start using completely different purpose needs update privacy notice accordingly ensure people aware obtain consent use data new purpose organisation buys personal data another organisation use big data analytics also needs ensure original privacy notice given individuals seller covers use data buyer need give individuals concerned privacy notice making clear new purpose data processed limited circumstances thi needed chiefly would involve disproportionate effort furthermore difference people told originally buyer intends data buyer obtain consent data used new purpose additionally privacy notices also important tool situations organisation merged acquired another organisation especially relevant technology sector mergers acquisitions often notabl facebook acquisition microsoft acquisition circumstances data protection obligations follow data organisations need ensure individuals made awar happening reassured personal data used line reasonable expectations purposes data originally obtained providing copy original privacy notice along urther information identify new organisation explain happening help meet requirement ico data sharing code says mergers dpa schedule part ragraph gdpr article winkler rolfe steele anne technology busiest sector merger deals year wall street journal june busiest accessed december olson parmy facebook closes billion whatsapp deal forbes october whatsapp accessed december lunden ingrid microsoft officially close acquisitions linkedin techcrunch december closes accessed december information commissioner office data sharing code practice ico may accessed december big data artificial intelligence machine learning data protection version use social data growing area data collected one organisation used another social media platforms facebook twitter make data subscribers posted available thi parties certain conditions social company may make data available via application programming interface api twitter cases third party may gather information web scraping data mig used sentiment analysis identifying general trends cases profiling individuals assessing credit risk may difficult anonymise data transferred third party may processing personal data case consider whether necessary provide privacy notice individuals con cerned social company terms service may include reference use third parties reality people may aware data used research ipsos mori showed fewer two five adults aware data could shared companies government research three five thought oxford internet institute use social media research analysis feasibility study department work pensions december accessed april evans harry ginnis steve bartlett jamie socialethics guide embedding ethics social media research ipsos mori december accessed april big data artificial intelligence machine learning data protection version privacy impact ssessments privacy impact ssessment important tool help identify mitigate privacy risks processing personal data gdpr highly likely privacy impact assessment known data protection impact assessment requirement big data analytics involving processing personal data unique features big data analytics make steps privacy impact assessment difficult challenges overcome big data analytics involve novel complex sometimes unexpected uses personal data establish whether processing fair particularly important assess processing begins extent likely affect individuals whose data used ide ntify possible mitigation measures tool analysis privacy impact assessment pia code practice conducting privacy impact gives practical advice pias links pia standard risk method ologie currently good practice pia projects involve new uses data require pia referred data protection impact assessment dpia certain instances likely create high risk people rights freedoms particular processing uses new technologies highly likely big data applications involving rocessing personal data fall category gdpr ref ers systematic extensive evaluation individuals based automated processing including profiling decisions based significant affect individuals information commissioner office conducting privacy impact assessments code practice ico february accessed june gdpr article gdpr article big data artificial intelligence machine learning data protection version discussions certain industry sectors potential privacy risks associated big data identified example use inferred data predictive analytics organisations said significant differences bet ween using existing pia methodology address big data risks using normal data processing however others suggested may particular issues big data make challenging follow methodology example one early pia stages describe information flows data used shared dpias gdpr similar requirement seen big data likely involve discovery phase new uses exi sting data new data sources investigated often finding new unexpected correlations may clear outset data useful used make difficult map information lows furthermore noted discussion privacy notices consent may practically difficult legitimise processing seeking consent annex paper discusses issues giving guidance overcome inherent challenges conducting pias big data context would still recommend using privacy impact assessments code practice full detailed guide conducting pias hope annex help organisations consider conduct pia big data analytics understa dpia requirements gdpr affect big data artificial intelligence machine learning data protection version privacy design benefits big data need come cost privacy embedding privacy design solutions big data analytics help protect privacy range technical organisational measures gdpr privacy design known data protection design default become legal requirement basis privacy design approach privacy risk particular project identified opportunity find creative technical solutions deliver real benefits project protecting privacy stated benefits section chapter ico firmly supports approach data protection privacy rights foundations big data analytics successfully built implement ing privacy design solutions mutually beneficial individuals big data organisations society concept privacy design often associated implementation techniques anonymise pseudonymise personal data discusse anonymisation section one technique area differential privacy originally conceived gaining momentum due advancing capabilities differential privacy involves jecting noise answers dataset queries noise great enough provide anonymity individual level enough affect utility criticised differential privacy basis appropria trade privacy utility unachievable however quickly dwork cynthia differential privacy international colloquium automata languages prog ramming part springer verlag july accessed january lipton zac hary chase differential privacy make privacy data mining compatible kdnuggets january accessed january bambauer jane muralidhar krishnamurty sarathy rathindra fool gold illustrated critique differential privacy vanderbilt journal entertainment technology law vol big data artificial intelligence machine learning data protection version becoming popular privacy design technique among large technology companies however rivacy design solutions involv anonymisation techniques range measures technical organisational including security measures prevent data misuse access controls audit logs encryption data minimisation measures ensure personal data needed particular analysis transaction validating customer processed stage purpose limitation data segregation measures example personal data kept separately data used processing intended detect general trends correlations sticky policies record individual preferences corporate rules within metadata accompanies much initial work privacy design done fice information privacy commissioner ontario recently enisa produced wide report use privacy design techniques big includes example privacy design approach could plied various smart city use cases smart apps smart metering citizen platforms called conceptual shift big data versus privacy big data privacy viewpoint strongly shared ico concluded achieving easy greenberg andy apple differential privacy collecting data data wired june privacy accessed january erlingsson lfar pihur vasyl korolova aleksandra rappor randomized aggregatable privacy ordinal response proceedings acm conference computer communication security acm accessed january nguyen roline user approach data dilemma context architecture policy digital enlightenment yearbook value personal data digital enlightenment forum september data accessed june accessed june giuseppe privacy design big data overview privacy enhancing technologies era big data analytics enisa december accessed june big data artificial intelligence machine learning data protection version work needed priv technologies pets concept privacy design key identifying privacy requirements early big data analytics value chain subsequently implementing necessary technical organizational measures concept privacy design included gdpr heading data prot ection design default therefore become legal requirement data controllers obliged take appropriate technical organisational measures ensuring default personal data necessary specific purpose processing processed gdpr article big data artificial intelligence machine learning data protection version privacy seals certification certification schemes used help demonstrate data protection compliance big data processing operations gdpr encourage establishment schemes recent years idea system certifying particular instance personal data processing complies data protection requirements often described trust mark privacy seal gain support suggested could helpful big data context promote consumer trust reported huawei obtained form certification offered german company eprivacy hadoop based fus ioninsight certification included gdpr encourages establishment data protection certification mechanisms data protection seals marks demonstrate processing operations comply regulation hese would awarded data protection authorities accredited certification ico looking feasibility setting privacy seals scheme data protection idea seal ould certify particular serv ice product process rather organisation whole show complies data protection requirements award would based rigorous testing follow established certification body applying guidelines laid ico considering original idea relates new provisions gdpr information accountability foundation argued big data organisations need make ethical assessments processing pro posed framework taylor simon data new currency european voice june accessed june nunns james complian data regulation big data analytics vendors tackling data protection computer business review january accessed june gdpr articles recital big data artificial intelligence machine learning data protection version suggest accountability agents certification bodies could important role monitoring respect would supplement work data protection authorities would need cons idered light new gdpr provisions require data controllers consult data protection authority undertaking processing operations likely result high risk cases proposed mitigating measures reduce risk acceptable abrams martin time accountability agents summit information accountability foundation blog june accessed june gdpr article big data artificial intelligence machine learning data protection version ethical approaches ethical approach processing personal data big data context important compliance tool ethics boards organisational national level help assess issues ensure application ethical principles ethical approaches use personal data help build trust individuals role setting big data standar encourage best practice across industries recent trend towards develop ing ethical approaches use personal data big data processing several commentators concerned privacy impact big data advocated need ethical approach supports goes beyond compliance legal requirements example european data protection supervisor said today digital environment adherence law enough consider ethical dimension data processing information accountability foundation working big data ethics proposes set ethical values assessing big data initiatives summarised organisations define benefits analytics incur risks big data analytics benefits could achieved less risky means insights sustainable processing respect interests stakeholders outcomes processing fair individuals avoid discriminatory impacts european data protection supervisor towards new digital ethics opinion edps september accessed june information accountability foundation big data ethics init iative iaf website accessed june big data artificial intelligence machine learning data protection version seeing examples publ private sector organisations developing sets ethical principles essentially ground rules etting organisation use people data typically stress values fairness transparency usually intended guide employees using data developing new projects means reassuring stomers building relationship trust sometimes principles condensed simple litmus test remind employees think planning new uses data example would want data member family used way company caesar entertainment applies sunshine test details use data made public would strengthen threaten customer relationships ethical approaches private sector aimia aimia global company field loyalty management run nectar loyalty programmes developed set data values acronym tact transparency added value control transparency means telling customers data collected collected used added value means making customers aware receive rewards participation control giving customers control data provide enabling share opt trust means giving customers confidence data used way say use share partners identified ibm ibm published ethical framework big data takes account context etlinger susan groopman jessica trust imperative framework ethical data use altimeter group june report accessed june johnson david henderson jeremy new data values aimia accessed june chessell mandy ethics big data analytics ibm big data analytics hub accessed june big data artificial intelligence machine learning data protection version data collected used whether people choice giving data whether amount data done rea sonable terms application reliability data owns insights gained data whether application fair equitable consequences processing people access data accountability mistakes unintended consequences vodafone vodafone publish set privacy cover respe people data openness honesty customers giving people meaningful choices applying privacy design minim ising privacy impacts hen balancing privacy righ obligations complying privacy laws accountability international developments usa alliance automobile manufacturers global alliance automakers produced set privacy rinciples consumer data derived new vehicle international level gsma represents mobile operators worldwide produced guidelines use mobile phone data responding ebola end towards spelling ethical principles evident among private companies also public sector ethical principles research place time example universities growth big data means applied challenging situations particularly data collected directly individual participants use social data vodafone privacy security vodafone website june accessed june consumer privacy protection principles privacy principles vehicle technologies services alliance automobile manufacturers inc association global auto makers november accessed june gsma guidelines protection priv acy use mobile phone data responding ebola outbreak gsma november guidelines accessed jun big data artificial intelligence machine learning data protection version cabinet office cabinet office publ ished dat science ethical aims help researchers big data methods starting used research public sector puts forward six principles start clea user need public benefit use data tools minimum intrusion necessary create robust data science methods alert publ perceptions open accountable possible keep data secure role councils boards ethics within organisations national level arge organisation may board ethics could ensure ethical principles applied could make assessments difficult issues balance legitimate interests privacy rights use internal ethics oards advocated council europe consultative mmittee convention recently published big data important issue scenario organisational relationship ethics board employees responsibilities data analytics chief data officer data protection officer royal statistical house commons science technology stc called council cabinet office data science ethical framework cabinet office may accessed june consultative committee convention protection individuals regard automatic rocessin personal data guidelines protection individuals regard processing personal data world big data council europe january documenti accessed february royal statistical society opportunities ethics big data rss february accessed jun house commons science technology committee big data dilemma fourth report session stationery office february big data artificial intelligence machine learning data protection version data ethics give national lead guidance issues government agreed consider established probably auspices alan turing subsequent report stc also called creation standing commission artificial intelligence work closely council data ethics social ethical legal implications application government response stopped short agreeing set commission detail similar work way royal society british academy implications machine learning data example advisory board dealing privacy issues public sector seattle seattle set privacy advisory board oversees city uses personal data particularly context smart city initiatives publishes set privacy principles encourages use pias seem several factors pushing adoption ethical principles public sector evidence lack public awareness data use suspicions data sharing led calls ethical policies made private sector commercial impera tive mitigate risk would harm company reputation subject media stories misuse personal data consumers also publicise accessed june house commons science technology committee big data dilemma government response committee fourth report session stationer office april accessed june house commons science techn ology committee robotics artificial intelligence fifth report session stationery office october accessed december house commons science technology committee robotics artificial intelligence government response committee fifth report session stationar office december accessed january kitchin getting smar ter smart cities improving data privacy data security data protection unit department taoiseach dublin ireland january accessed june evans harry ginnis steve bartlett jamie socialethics guide embedding ethics social media research ipsos mori december summary accessed april big data artificial intelligence machine learning data protection version views world instantly important consi deration competitive nvironment positively companies may also seek develop relationship customer trust company data happy provide data return enhanced services benefits esearch shows people trust businesses personal data appealing find new product offers smart thermostats telematics devices international study consumer attitudes personal data reported harvard business found people willing accept potentially intrusive uses data profiling return enhanced benefits service like google however simply value trust also import ant two organisations offer service value people likely allow data used one trust study found transparent customers teaching data use giving control data key elements building trust suggests business case developing approach aims build trust based transparency fairness notable ethical frameworks developed regulators companies organisations nevertheless many aspects frameworks echo key data protection principles requirements reflect importance telling people done data shared considering whether uses data within people expectations giving people access data control use considering impact analytics people data relates developing ethical principles frameworks big data job data controllers rather data protection authorities welcome development helps organisation ensure use big data complies data protection principles particular helps meet see key issues fairness transparency addition ethical frameworks also role develop ing common standards big data analytics organisati ons citizenme annual track ico june accessed june morey timothy forbath theod ore schoop allison customer data designing transparency trust harvard business review may accessed june big data artificial intelligence machine learning data protection version international telecommunications international organisation working towards set big data standards help establish best practice reduce risk organisations involved data processing ico supports idea big data standards encourages development especially among trade associations industry groups strong influence members circle research big data standards market research bsi standards ltd january accessed december acharya sanjay itu members agree international standard big data international telecommunications union december accessed december jtc information technology big data preliminary report international organisation standardization january accessed december big data artificial intelligence machine learning data protection version personal data stores use personal data stores address issues fairness lack transparency giving individuals greater control personal data personal data stores support concept data portability beco law gdpr certain conditions regard ing individual personal data control suggested one way increase individual control use data usually called personal data stores sometimes personal information management services third services hold people personal data behalf make available organisations individuals wish early proponen concept saw way embedding privacy controls managing organisations access personal data building privacy preferences european data protection supervisor also sees personal data stores potential tackling concerns individuals loss control recently criticised idea individuals effectively control personal data used big data environment fallacy data privacy self says people aware data collected used time read privacy notices instead argues representative data management system intermediaries would manage perso data behalf rubinstein ira big data end privacy new beginning international data privacy law january accessed june european data protection supervisor meeting challenges big data opinion edps november accessed june obar jonathan big data phantom public walter lippmann fallacy data privacy self big data society vol accessed june big data artificial intelligence machine learning data protection version evidence public support personal data stores survey digital people surveyed said would welcome service help collect manage preserve personal data services type already exist example provides free encrypted personal data stores enables individuals share data personal data store apply service make purchase online also enables provide verified digital identity proposals setting personal data stores basis individuals keep data store could benefit financially growth personal data stores also support government midata initiative initiative currently focuse banking telecoms energy sectors enables individuals receive data organisations sectors hold machine electronic form use example find better deals using comparison gdpr puts concept data portability law data controller processing personal data basis consent contract data subject right receive data provided structured commonly used machine readable format also right transmit another data developing personal data stores offer individuals degree control personal data across different services least help address issues fairness lack transparency identified potentially problematic big data digital catapult trust personal data review digital catapult july accessed june open data manchester open data building data open data manchester april accessed june davies sean midata change personal banking forever gocompare march accessed june gdpr article big data artificial intelligence machine learning data protection version algorithmic transparency auditing techniques used identify factors influence algorithmic decision interactive visualisation systems help individuals understand recommendation made give control future recommendations ethics boards used help shape improve transparency development machine learning algorithms combination technical organisational approaches algorithmic transparency used one implications discussed accountability governance section chapter need algorithmic accountability ensure demonstrate data protection compliance black box big data processing activities machine learning consensus simple one type lution increasing debate best achieve algorithmic transparency several approaches emerged popular approach championed several commentators algorithmic auditing mit technology review article auditability one five principles suggested accountable idea auditability baked algorithms development stage enable third parties check monitor review critique behaviour companies private sector concept algorithmic audit likened accounting audit whil carried confidence protect proprietary information still provide public assurance lack technical capability computa tional resources cited potential barrier auditing yet diakopoulos nicholas friedler sorelle hold algorithms accountable mit technology review november accessed december mittelstadt brent automation algorithms politics auditing transparency content personalization systems internation journal communication october big data artificial intelligence machine learning data protection version also evidence good progress implementation paper presented international conference data mining showed technique algorithm auditing evidenced effective identifying discre factors influence decisions made furthermore consultant companies already set specialise providing algorithmic auditing ser vices one applications big data analytics natural language generation nlg ability create human understandable narrative analysis various sources data ibm slamtracker system example nlg practice converts data tennis matches wimbledon real automated stories twitter nlg commonly associated type use news weather reports may also possible apply algo rithmic decision making view increasing transparency decisions made according article written association computing machinery methods developed natural language generation nlg put text explains decision reached imagine favorite machine learning library say scikit learn could explain sentence particular input case classified way would useful debugging nothing else organisations may wish look ways integrat ing nlg new existing big data processing activities would enable give individuals explanations decisions based automated processing different approach algorithmic transparency combine visualisation interactivity much research done particularly use big data analytics recommendation adler philip auditing black models indirect influence ieee international conferenc data ning december neil risk consulting algorithmic auditing accessed december marr bernard big data algorithms tell better stories humans forbes july accessed december diakopoulos nicholas accountability algorithmic decision making communications acm big data artificial intelligence machine learning data protection version systems studies found instance visualisat ion tools allowed individuals better understand recommendations made enabled create accurate recommendations visual explanations interactivity systems facilitated features bookmark interrelation charts venn diagrams adjustable sliders change importance recommender methods interactive visualisation systems might prove difficult implement certain types big data analytics similar simplified approach could adopted whereby individuals given opportunity check correct outputs machine learning algorithms example organisation undertakes automated profili customers determine insurance premiums could allow inspect profiles correct inaccurate labels assigned beyond demonstrating compliance data protection principle accuracy could also lead overall improvement precision machine learning another non approach algorithmic transparency use ethics boards discussed ethical approaches section part general approach data protection compliance also used specifically appraise make decisions development application machine learning algorithms instance european implementation algorithmic video surveillance system used ethics board researcher reported regular regarding algorithm allowed board understand development algorithm raise relevant questions matt ers concern could taken back project team adjustments make transparent algorithm step development ethics board minutes made public well example use ethics board algorithmic context google ethics board set originally acquired company deepmind however google criticised lack verbert katrien visualizing recommendations support exploration transparency controllability proceedings international conference intelligent user interfaces acm parra denis brusilovsky peter christoph trattner see want see visual user approach hybrid recommendation proceedings international conference intelligent user interfaces acm diakopoulos nicholas accountability algorithmic decision making communications acm neyland daniel bearing accountable witness ethical algorithmic system science technology human values big data artificial intelligence machine learning data protection version transparency regarding board members focus machine learning constantly evolving areas research practice consequently discussions around transparency accountability therefore claim approaches algorithmic transparency complete list stated start section single approach algorithmic transparency would work every big data organisation rather combination complementary approaches technical organisational adopted suit desi purpose particular big data application view reflected findings research algorithmic transparency shead sam deepmind staying silent sits google ethics board business insider december accessed december burrell jenna machine thinks understanding opacity machine learning algorithms big data society saurwein florian natascha michael latzer governance algorithms options limitations inf big data artificial intelligence machine learning data protection version chapter discussion chapters shown use big data analytics several implications data protection privacy rights implications insurmountable barriers legal ethical application analytic techniques various tools approaches available help compliance rather restricting use big data analytics tools encourage innovation support delivery benefits flow big data however recognise emerging view data protection principles embodied law longer adequate deal big data world world economic forum characterised traditional data protection approach one individual involved consenting ata use time collection organisation collected data used specified use based user consent deleted data longer needed specified purpose model critics data rotection mind notice consent model criticised grounds users lack time willingness ability read lengthy privacy notices therefore even give consent basis effectively mea also argued practical difficulties giving privacy notices situations data collected observing recording actions individuals rather individuals consciously providing discussed issues sections privacy notices consent notice consent model fundamental facet data protection principle transparency criticism model mirrored wider criticism role transparency evolving world big data analytics suggest instance concept transparency inadequate comes complex opaque nature lead gaming decisionmaking process world economic forum unlocking value personal data collection usage february accessed june usa executive office president president council advisors science technology big data privacy technological perspective white house may accessed june ananny mike crawford kate seeing without knowing limitations transparency ideal application algorithmic accountability new media big data artificial intelligence machine learning data protection version addition arguments limitations transparency view problems big data analytics potential harms arise data collect used example commentators questioned harm caused case individual simply collection data example mass surveillance increased focus use data led championing accountability answer big data issues opposed rather focusing providing people hows whys processing personal data accountability concentrates monitor ing use mechanisms scrutin ising technical design software emerging importance accountability reflected gdpr includes explicitly new data protect ion part introduced address implications processing personal data big data world new provisions regarding data protection design data protection impact emphasise growing role accountability play within organisations also externally noted instance gdpr society cember accessed december kroll joshua accountable algorithms university nnsylvania law eview march vol example chapter van der sloot bart broeders dennis schrijvers erik exploring boundaries big data netherlands scientific council government amsterdam university press april accessed june beresford tom algorithmic transparency solution looking algorithmic accountability gamification work november looking accessed december bomhof freek order trust big data transparency enough datafloq october accessed december diakopoulos nicholas friedler sorelle hold algorithms accountable mit technology review november taneja hemant need algorithmic accountability techcrunch september accessed december gdpr article gdpr article gdpr article gdpr articles big data artificial intelligence machine learning data protection version data protection regulators role giving prior authorisation certain forms high risk prominence accountability exemplified large volume discussion features use among freely acknowledge increased weight placed accountability big data context see death transparency data protection principle return example cited mass collection personal dat even processing held account regarding potential issues arising use data instance increased severity likelihood data breaches internal misuse rogue employees undesirable secondary lack transparent process collection personal data would still cause problems quite simply people informed processing personal data unlikely able exercise rights even would regard processing unfair would aware shown chapter particularly privacy notices section achieving transparency impossib big data orld methods achieved altering shift towards layered approach transparency approach exemplified layering privacy notices individuals purposes collecti ing personal data emerge also layering information inner workings big data analytics greater level detail access given regulators auditors accredited certification bodies shown points thro ughout paper big data analytics data protection viewed simple binary terms also applies principles transparency gdpr article butin denis chicote marcos metayer daniel strong accountability beyond vague promises reloading data protection multidisciplinary insights contemporary challenges springer bellamy bojana heyder markus protecting privacy world big data role enhanced accountability scl law community may accessed december burgess matt holding account algorithms ever free bias created humans wired december transparent accessed december brookman justin hans collection matters surveillance facto privacy harm big data privacy making ends meet future privacy forum stanford law school january accessed june big data artificial intelligence machine learning data protection version accountability somewhat paradigm shift regarding emerging importance accountability wholesale replacement transparency fact centre information policy leadership lists transparency part one essential elements view combination approaches help ensure protection privacy rights delivering benefits big data view supported regulators jurisdictions usa overarching data protection legislation ame way speech big data chair federal trade commission said focusing consumer choice time collection critical use restrictions place australian information commissioner also stressed continuing importance notice consent big data context well need organisations robust accountable privacy governance framework centre information policy leadership data protection accountability essentia elements document discussion hunton williams llp october ccountability accessed february ramirez edith privacy challenges big data view lifeguar chair federal trade commission august challenges accessed june pilgrim timothy big data privacy regulator perspective office australian information commissioner june accessed june big data artificial intelligence machine learning data protection version chapter conclusion big data machine learning becoming widespread public private sectors may increasingly seen business usual key characteristics big data analytics still represent step change processing personal data analysis big data using techniques made possible creates implications data protection challenging apply data protection principles using personal data big data context implications arise volume data ways generated propensity find new uses complexity processing possibility unexpected consequences individuals paper tried map dat protection principles features big data analytics highlight areas potential difficulty however also discussed several tools approaches including anonymisation pias privacy design help organisati ons ensur processing complies data protection legislation minimises impact privacy welcome trend towards organisations developing ethical principles building relationships trust public tting practice assist compliance data protection requirements recent moves towards setting councils ethics within organisations nationally positive development also support recognise many enefits flow use big data individuals public services business society general benefits truly felt privacy rights data protection embedded methods achieved crucial organisations clear potential benefits steps taken address privacy risks yet data protection simply legal requirement big data analytics also prudent vantageous reasons creativity innovation encourages also argue getting data protection right helps ensure data quality becoming ever critical businesses public sector organisations data world therefore organisations rely big data data protection important legal compliance department also people working data analytics marketing research need aware data big data artificial intelligence machine learning data protection version protecti implications big data analytics tools pias also suggests data protection part higher education curriculum people going ese roles aware view given challenges applying data protection principles big data analytics different legal regulatory approach required however accept idea data protection currently embodied legislation work big data context maintain big data game played different rules acknowledge increasing importance accountability addressing challenges see replacement traditional principle transparency transparenc still significant role play argue still achieved even complex world machine learning throughout paper referred relevant provisions gdpr gdpr intended partly address questions raised big data analytics aims strengthen privacy rights context refers specifically issues profiling tools data protection impact ass essments data protection design default ico role helping big data organisations meet new existing data protection obligations although paper intended primarily discussion document add practical dimension particularly exploring compliance tools chapter conducting pias annex also pulled six key recommendations discussions present chapter however paper end work data protection big data analytics several current planned activities linked work area particularly regarding gdpr provisions matters profiling risk especially relevant big data machine learning outputs work published linked website promoted monthly continue work area help encourage organisations meet obligations also role responding breaches data protection legislation proportionate regulatory action include issuing enforcement notic monetary penalty notices different world big data machine learning big data artificial intelligence machine learning data protection version continue use powers necessary line regulatory action information commissioner office data protection regulatory action policy ico august accessed january big data artificial intelligence machine learning data protection version chapter key recommendations based discussions regarding compliance tools chapter paper pulled six key recommendations feel help organisations achieve beyond data protection compliance big data world organisations consider whether big data analytics undertaken actually requires processing personal data often case circumstances organisations appropriate techniques anonymise personal data dataset anonymisation section transparent processing personal data using combination innovative approaches order provide meaningful privacy notices appropriate stages throughout big data project may include use icons noti fications layered privacy notices privacy notices section privacy impact assessment framework big data processing activities help identify privacy risks assess necessity proportionality given project privacy impact assessment involve input relevant parties including data analysts compliance officers board members public privacy impact assessment section annex privacy design approach development application big data analytics include implement ing technical organisational measures address matters including data security data minimisation data segregation big data artificial intelligence machine learning data protection version read privacy design section ethical principles help reinforce key data protection principles employees smaller organisations use principles reference point working big data projects larger organisations create ethics boards help scrutinise projects asses complex issues arising big data analytics ethical approaches section innovative techniques develop auditable machine learning algorithms internal external audits undertaken view explaining rationale behind algorithmic decisions checking bias discrimination errors algorithmic transparency section big data artificial intelligence machine learning data protection version annex privacy impact ssessments big data analytics introduction feedback version paper subsequent discussions industry sectors identified interest development specific guidance conducting privacy impact assessments pias big data context pias particular importan area capabilities big data analytics potential data protection implications arise identified discussed paper furthermore although pias require dpa required gdpr situations processing likely result high risk rights freedoms individuals particular using new spec ifically gdpr states pia referred data protection impact assessment dpia required case systematic extensive evaluation personal aspects relating natural persons based automated processing including profiling decisions based produce legal effects concerning natural person similarly signifi cantly affect natural person therefore highly likely gdpr dpia legal required big data applications involving processing personal data share view guidance pias big data analytics would use ful seek provide gdpr sets structure roadly speaking maps pia framework used conducting privacy impact assessments code practice pia cop shown table guidance provided uses existing pia cop framework basis discussion issues play followed checklist key points conducting pia big data analytics gdpr article gdpr article gdpr article information commissioner office conducting privacy impact assessments code practice ico february big data artificial intelligence machine learning data protection version step pia cop identify need pia step pia cop describe information flows gdpr systematic description envisaged processing operations purposes processing including applicable legitimate interest pursued controller step pia cop identify privacy related risks gdpr assessment necessity proportionality processing operations relation purposes gdpr assessment risks rights freedoms data subjects step pia cop identify evaluate privacy solutions gdpr measures envisaged address risks including safeguards security measures mechanisms ensure protection personal data demonstrate compliance regulation taking account rights legitimate interests data subjects persons concerned step pia cop sign record pia outcomes step pia cop integrate pia outcomes back project plan big data artificial intelligence machine learning data protection version step pia cop identify need pia discussions organisations conducting pias big data context argument made ethical assessment probably already done big data team would little oint data protection officer dpo waving pia raises two key points identifying need pia first point whil form assessment general risk assessment ethical assessment may already hav done gdpr comes force legal require certain big data activities dpia covers several specific areas detailed table organisations therefore need ensure existing assessmen methodology addresses areas amend processes accordingly second point identif ying need pia rest solely dpo compliance department dpo consulted throughout pia process gdpr ctually require important big data analysts able recognise need pia outset paper highlighted whil several features make big data analytics unique still subject data protection principles processing operation therefore terms identifying need pia screening questions detailed pia cop remain relevant appropriate use involved big data analytics particular following three questions specific ally releva big data dpia requirements set gdpr using information individuals purpose currently used way currently used project involve using new technology may perceived privacy intrusive project result making decisions taking action individuals ways significant impact gdpr article big data artificial intelligence machine learning data protection version key issue arose discussions organisations reluct ance start pia process soon often lack clarity direction big data project take early stages discussed detail step case would encourage big data analysts err side caution start pia process soon possible reasonably foresee analysis may lead work would result one screening questions answered yes example insurance company may planning run unsupervised machine learning algorithms dataset hope finding interesting correlations data outset insurer know potential correlations might show know one possible outcome additional piece work adjust premiums based correlations even though sure case insur begin pia process anyway ensure already thinking privacy risks project begins develop note innovative ways help big data analysts recognise need pia instance discussions organisations telecoms sector one company mentioned uses matrix different types data operative easily identify types high risk starting project another company sector highlighted mportance data champions departments whil necessarily dpo data champion would know data protection could help properly identify areas concern checklist dpo available consultation pias big data analysts use appropriate screening questions help identify need pia direction big data project seems unclear err side caution begin pia process anyway big data artificial intelligence machine learning data protection version step pia cop describe information flows dpia gdpr systematic description envisaged processing operations purposes processing including applicable legitimate interest pursued controller discussions ganisations highlighted step difficult complete context conducting pias big data analytics consensus describ ing information flows often much harder discovery phase big data analytics thinking ata involves finding unexpected correlations opposed testing particular set hypotheses additionally companies insurance telecoms highlighted difficult mapping information flows using agile project management methodology clear step challenging big data analytics gdpr explicit part furthermore legitimate interests condition relied processing personal data gdpr requires described part step requirement link new accountability principle gdpr among things liges organisations maintain internal records processing therefore realistic outcome big data project decisions significantly affect individuals every effort needs made observe requirements step describing relevant information flows purposes processing necessary organisation legitimate interest although discussions organisations revealed common theme difficulties step several companies telecoms sector emphasised need clarity aims data processing importance end product mind view reflected paper information accountability foundation refers big data analytics beginning sense purpose opposed encourage organisations undertaking big data analytics gdpr article gdpr article abrams martin unified ethical frame big data analysis information accountability foundation october big data artificial intelligence machine learning data protection version think carefully sense purpose given project even may change project dev elops help illuminate potential information flows could arise big data project progresses also complements advice pia cop agile project management description information flows describe information flows part user story refer implementing project project progresses record stage changed use personal big data projects genuinely aims jectives outset potential solution may take processing outside data protection sphere using anonymised datasets discovery phase correlations interest discovered organisation would able identify aims processing starting analysis original dataset containing personal data point organisation therefore able describe envis aged information flows purposes processing necessary legitimate interests checklist possible clearly describe predicted information flows big data project purposes processing uncertain use anonymised data describe information flows project progresses accessed november information commissioner office conducting privacy impact assessments code practice ico february big data artificial intelligence machine learning data protection version step pia cop identify privacy related risks dpia gdpr assessment necessity proportionality processing operations relation purposes dpia gdpr assessment risks rights freedoms data subjects discussions organisations step similar issues identified step also highlighted namely discovery phase big data analytics make particularly difficult identify privacy risks stage clear analysis might reveal pia cop gdpr set specific frameworks pia seen rigid process restrains progress particular big data project rather pias treated scalable living procedures develop alongside project evolution therefore step identification risks take place project moves forward potential risks become clearer based research paper discussions organisations developed following questions may help identify record relevant risks individuals organisations big data context list meant complete questions relatively high level broad organisations develop questions bas specifics big data analytics undertaking individuals made aware use personal data could analysis involve sensitive personal data example analysis social posts datas representative accurate retention policies data datasets held across multiple disparate systems big data artificial intelligence machine learning data protection version systems appropriate inbuilt security measures proposed analysis involve cloud processing third organisation analytics could anonymised data able explain reasons behind decisions make result big data analytics regards wording step dpias gdpr assessing risks right freedoms data subjects largely covered discussed however addition assessment necessity proportionality processing operations also explicit part dpia process organisations involved big data analytics assessing necessity mean considering whether proposed type analytics method achieving project purposes whether another les privacy method could used instance organisation may need consider traditional research project using sample total population would sufficient achieve project objectives additionally assessin proportionality involve considering whether proposed analytics justified circumstances put another way project purposes important enough compensate potentially privacy methods used exa mple big project objective target offer particular group people value offer group justify profiling people application phase analytics consultation internal external key successful pia take place throughout process highlight value seeking views individuals identifying privacy risks discussions organisations seemed uncertainty need consult customers big data projects would encourage consultation remind organisations potential commercial benefits increased trust competitive advantage council europe nsultative del vecchio steve thompson chris galindo george trust verify transparency competitive advantage pricewaterhousecoopers view issue accessed january big data artificial intelligence machine learning data protection version committee convention guidelines big data recommend involvement individuals groups part risk assessments use big data may affect fundamental furthermore gdpr consultation data subjects require dpias circumstances would appropriate gdpr define circumstances requirement likely apply situations data subjects significantly affected outcomes big data analytics checklist ask questions proposed big data analysis identify record associated privacy risks project develops regularly return questions develop new questions identify record new risks assess whether proposed big data analytics method project could conducted assess whether proposed big data analytics justified relation potential benefits consult internally externally throughout big data project consultative committee convention protection individuals regard automatic rocessing personal data guidelines protection individuals regard processing personal data world big data council europe january documenti accessed february gdpr article big data artificial intelligence machine learning data protection version step pia cop identify evaluate privacy solutions dpia gdpr measures envisaged address risks including safeguards security measures mechanisms ensure protection personal data demonstrate compliance regulation taking account rights legitimate interests data subjects persons concerned questions developed part step helped identify relevant privacy risks associated big data project next step consider risks addressed analytics begin using example questions relevant identifying privacy risks big data context listed potential solutions solutions merely examples organisations identify record list solutions appropriate specifics big data analytics undertaking individuals made aware use personal data yes provided privacy notice point collection obtained consent use personal data analysis identify provide relevant offers discounts individuals could analysis involve sensitive personal data example analysis social posts developed algorithm identify omit instances sensitive personal data dataset analysis references race ethnicity religion health dataset representative accurate dataset unlikely representative total population use analysis results purposes profiling significant decis ion making regularly check samples dataset individuals make sure accurate date retention policies data big data artificial intelligence machine learning data protection version maintain appropriate retention schedules datasets use big data analysis regularly reviewed enforced records management team datasets held across multiple disparate systems systems appropriate inbuilt security measures yes employ information security experts implement appropriate security measures including encryption access controls proposed analysis involve cloud processing third party organisation analytics yes make extensive assessment cloud providers data analy sis organisations select provide secure environment data processing put contractual agreements place regarding security use data could anonymised data follow guidance ico anonymisation code practice reduce likelihood anonymised data identified able explain reasons behind decisions make result big data analytics yes audit machine learning algorithms check bias decision rational recognise several unique features big data analytics make difficult identify practicable privacy solutions would appropriately address risks question discussions organisations two particular areas concern emerged first several organisations talked using consent mitigation measure uncertainty whether consent could truly informed context big data organisation may know exactly data point obtaining consent said consent section chapter rather treating consent one transaction start relationship organisation individual graduated consent model could used instead obtain consent individual new uses big data artificial intelligence machine learning data protection version personal data part ongoing relationship thus purposes particular big data project defined organisation could individuals informed consent part business activities involve contact customers second area concern transparency difficulties ensuring people understand therefore expect happening personal data given complexities big data analytics referring main paper particular privacy notices section chapter innovative layered approach providing clear concise intelligible information big data analytics may involve using notifications icons videos visual representations help explain complex concepts easy way additionally individuals expectations use personal data linked trust organisation trust fostered several ways transparency important compo organisation therefore completely honest individuals use personal data may even mean explaining outset relationship individual exact purposes data analysis may yet defined information provided purposes become apparent line graduated consent odel useful reiterate fluid process pia limit identification privacy solutions specific phase big data project project progresses objectives shift new privacy risks emerge organisat ions need able continu consider ing address emerging risks checklist identify record appropriate measures address privacy risks previously identified big data analysis progresses new ris identified continue identify record measures address risks direction big data project unclear use novel methods obtaining consent providing privacy notices morey timothy forbath theodore schoop allison customer data designing transparency trust harvard business review may accessed january big data artificial intelligence machine learning data protection version step pia cop sign record pia outcomes fifth step pia involves recording process signing measures identified address privacy risks explicit part dpia framework gdpr link new accountab ility principle requires organisations maintain internal records processing line view information security considered boardroom recommend sign big data pia sought board level equivalent senior level smaller organisations view reflected discussions organisations technology sector said engagement privacy issues board level varies saw need buy level properly address privacy risks pia cop state ico take role approving signing pias however dpias gdpr organisations circumstances need consult ico process personal data instance uch consultation require proposed big data project involve high processing organisation undertaking project unable identify way mitigat ing risk part case ico provide written advice organisation within weeks weeks matter particularly complex recei ving request consultation necessary may also use powers prohibit propos processing operations finally pia cop would still encourage organisations make pia reports publicly available business information redacted help increase transparency big data processin operations contribute data protection compliance help build customers trust gdpr article information commissioner office talktalk gets record fine failing prevent october attack ico october accessed january gdpr article recital big data artificial intelligence machine learning data protection version checklist obtain board sign measures identified address privacy risks proposed big data analytics keep record sign whole pia process identified high risks measures mitigate consult ico starting data processing produce publish pia report big data artificial intelligence machine learning data protection version step pia cop integrate pia outcomes back project plan important sixth final step pia forgotten privacy solutions identified step signed step actually folded back big data project organisations compliance functions role vital analysts actually undertaking big data project understand solutions necessary impl emented view echoed discuss ions insurance companies suggested pia owned business opposed compliance department may last step pia process organisations see point longer need consider privacy risks regular reviews ensure privacy solutions implemented working expected furthermore discussed aims objectives applicati ons big data operations may subject change project lifecycle regular reviews help pinpoint changes check whether outcomes pia still appl earlier steps pia revisited new pia undertaken new privacy risks addressed checklist ensure agreed privacy solutions folded back big data project regularly review big data processing operations check whether privacy solutions working expected
