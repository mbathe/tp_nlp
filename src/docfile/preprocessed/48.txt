dgi study human rights dimensions automated data proce ssing techniques parti cular algorithms possible regulat ory implications prepared committee experts internet intermediar ies algorithms human rights study human rights dimensions automated data processing techniques possible regulatory implications english edition opinions expressed work responsibility authors necessarily reflect official policy council europe rights reserved part publication may translated reproduced transmitted form means without prior permission writing directorate communications strasbourg cedex publi shing cover page photo hutterstock published council europe strasbourg cedex council europe march council europe study algorithms human rights table contents composition introduction scope study automation data analysis adaptability social constructs around algorithms iii impacts algorithm human rights fair trial due process privacy data protection freedom expression freedom assembly association effective remedy prohibition discrimination social rights access public services right free elections possible impacts regulatory implicati ons use tomated data processing technique algorithms transparency accountability ethical frameworks improved risk assessment main findings nclusions bibliography references council europe study algorithms human rights terms reference steering committee media information society cdmsi biennium committee ministers asked cdmsi undertake work study human rights dimensions automated data processing techniques particular algorithms possible regulatory implications approved committee experts internet intermediaries msi subordinate structure facilitate work cdmsi first meeting march expert committee decided appoint benjamin wagner rapporteur study members msi expressed wish support rapporteur small working group composition msi wolfgang schulz professor faculty law university hamburg hans institut chair karmen turk partner trinity tallinn estonia vice bertrand chapelle internet jurisdiction france julia hörnle professor internet law queen mary university london tanja kerševan principal advisor director general agency comm unication networks services slovenia gender equality rapporteur matthias kettemann postdoc fellow cluster excellence normative orders univer sity rapporteur recommendation dörte nielandt division legal framework digital services media industry federal ministry economic affairs energy germany arseny nedyak deputy director department media state policy ministry telecommunication russian federation pēteris podvinskis ministry foreign affairs international organisations directorate department public policy related internet latvia thomas schneider deputy director international affairs international information society coordinator federal department environment transport energy communication etec federal office ommunications ofcom switzerland sophie stalla associate professor information technology intellectual property law director ilaws southampton law school university southampton dirk voorhoof lecturer european media law ucph copenhagen university professor ghent university member cmpf scientific committee centre media pluralism press freedom benjamin wagner assistant professor institute management information systems vienna university economics busines rapporteur study council europe study algorithms human rights introduction information made available users facebook newsfeeds basis person risk profile determined profiles provide best chances obtaining health insurance employment regarded potential criminal terrorist automated data processing techniques algorithms enable internet users seek access information also increasingly used decision processes previously entirely remit human beings algorithms may used prepare human decisions take immediately automated means fact boundaries human automated decision often blurred resulting notion quasi semi decision use lgorithms raises considerable challenges specific policy area operated also societ whole safeguard human rights human dignity face rapidly changing technolog ies right life right fair trial presumption innocence right privacy freedom expression workers rights right free ele ctions even rule law impacted respond ing challenges associated algorithms used public private sector particular internet platforms currently one hotly debated questions increa sing perception software eating world andreessen human beings feel control understand technical systems surround disconcerting always negative product phase modern life globali sed economic technological development produce large numbers software technical artefacts coded objects kitchin dodge embed key human rights relev ant decision capacities split choices software vehicle make knows going crash racial ethnic gender bias likely less likely automated system societal inequalities merely replicat amplified automated data processing techniques historically private companies decided develop software line economic legal ethical frameworks deemed appropriate emerging framework development systems processes lead algorithmic decision implementation thereof still early stage usually explicitly address human rights concerns fact uncertain whether exte existing legal concepts adequately capture ethical council europe study algorithms human rights challenges posed algorithms moreover unclear whether normative framework regarding use algorithms effective regulation automated data processing techniques even feasible many technologies based algorithms still infancy greater understanding societal implications needed issues arising use algorithms part decision process manifold complex time debate algorithms possible consequences individuals groups societ ies early stage however prevent efforts towards understanding algorithms actually consequences society flow possible human rights oncerns could addressed study identifies number human rights concerns triggered increasing role algorithms decision depending types functions performed algorithm level abstraction complexity automated processing used impact exerc ise human rights vary responsible hen human rights infringed based algorithmically decisions person programmed algorithm operator algorithm human implemented decision difference decision human made decision effects way human rights exercised guaranteed accordance well human rights standards including rule law principles judiciary processes challenges related human rights impact algorithms automated data processing techniques boun grow related systems becoming increasing complex interact outputs ways become progressively impenetrable human mind report intend comprehensively address aspects related human rights mpact algorithms rather seeks map main current concerns council europe human rights perspective look possible regulatory options member states may consider minimise adverse effects promote good practices number related themes require detailed research systematically assess challenges potential human rights point view including questions related big data processing machine learning art ificial intelligence internet things council europe study algorithms human rights scope study assessing automated data processing techniques algorithms use important clear types algorithms discussed study build existing well definitions particular work tarleton gillespie nicholas diakopoulos frank pasquale important keep mind term algorithm applied widely varied set meanings depending whether used computer science community among mathematicians information technologists communication cultural media studies public including political social discourse mapping human rights dimensions algorithms must also con sider divergence formal definitions algorithms popular usage term fact many debates algorithms focus less algorithms broadly role technology society bucher study basic approach starts tarleton gillespie assumption algorithms need software broadest sense encoded procedures transforming input data desired output based specified calculations procedures name problem steps solved gillespie algorithms thus perceived series steps undertaken order solve particular problem accomplish def ined outcome diakopoulos report discuss algorithms automate manufacturing processes perform routine tasks rather seems reasonable limit discussion algorithms digital affect public large thus focussing mainly algorithmic decision implications human rights without exhaustive aiming predict potential properties algor ithms decision making future following characteristics algorithms engage automated data processing semi automated decision making considered key issues human rights perspective report automation data analysis adaptability addition algorithms data processing techniques produced human operated human implications therefore understood without acknowledgement social constructs exist around automation automation one core aracteristics associated algorithmic decision making ability automated computing systems replace human beings council europe study algorithms human rights growing number situations key characteristic practical implementation algorithms reasons replacing human automated computing systems usually traced back issues large data processing speed volume scale decision many cases expectations lower error rates compared human beings automated decision alg orithms used across variety domains simplistic models help online service providers carry operations behalf users kim complex profiling algorithms hildebrandt filter systems per sonalised content automated algorithmic decision usually difficult predict human logic difficult explain fact data analysis data analysis algorithms applied large amounts data find patterns correlation within dataset without necessarily making statement causation grindrod use data mining pattern recognition without unde rstanding correlation causal relationships may lead errors raise concerns data quality algorithms replicate functions previously performed human beings involve quantitatively qualitatively different decision logic much larger amounts data input noteworthy effects automated decision framed interplay applied analytics based algorithms data sets used assessment human rights impacts take elements account since take example bias may hidden data set thus found analysing algorithm assessing human rights impacts algorithms must considered esigners algorithmic systems varying levels discretion deciding instance training data use respond false positives power operator algorithm may lie knowledge structure data set rather insight exact workings algorithms adaptability adaptability demonstrated algorithms use data develop novel patterns knowledge generate new decision rules chine learning techniques williamson adopting various learning styles algorithms model problems based data sets produce new solutions tha may impossible council europe study algorithms human rights human grasp essentially constant trial error techniques algorithms detect patt erns existing data identify similar tterns future data make data driven predictions machine learning techniques used among others search engines auto spelling mistakes well complex fields fraud prevention risk analysis advancement insight customer behaviour enhancement medical science predictabil ity algorithm outcome operator important considering accountability design adequate governance structures progress deep learning technologies may lead systems understood using ntal model mechanical machines considerable debate academic community degree systems made intelligible human beings consequences intelligibility could social constructs around algorithms algorithmic decision increasingly adept replacing human decision making important elements discretion decision processes automated often become lost human decision processes automated spiekermann without judging respective quality ecision making processes humans algorithms fundamentally categorically different make different mistakes might different outcomes therefore consequences societ governments considerable experience understanding human decision failures beginning understand flaws limitations boundaries algorithmic decision one key challenge frequent perception algorithms able create neutral non discriminatory independent predictions future events frenzy surrounding operation google flu trends later turned unjustified prediction ability far lower claimed one example struggle assertions regarding accuracy predict ive algorithms lazer lazer kennedy challenge however relates less algorithm see example yuan stevens promises perils artificial intelligence human rights rule law matter september council europe study algorithms human rights tool design well human perception interpretation implementation results thus key promotin human rights compliance use algorithms may understand algorithms achieve let use dictated merely considerations efficiency effectiveness alone traditionally developers programmed algorithms hand process transform input data desired output based specified calculations gillespie technological evolution however systems like algorithms becoming increasingly opaque technically necessary rather frequent design choice leading algorithmic systems whose inner workings made transparent accountable outside world even human formally takes decision instance decision remove certain content social media platform see human may often led rubber stamp algorithmically prepared decision time context skills make adequate decision individual case thus may seem logical draw distinction fully automated decision semi decision practice boundaries two blurred neither case human able provide reasoned argument certain decision needed taken specific case repercussions right concerned individual seek effective remedy human rights violation see noted algorithms discussed exist meaningfully without interaction human beings mathematic computational construct adverse human right impacts implementation application man interaction technologies application human interaction deeply social constructs winner considerable political implications denardis decision software example may biased ambivalent mccarthy meaning without social system around provides meaning impact thus simple lame algorithm suggest longer resort computers computing rather social construct specific norms values embedded algorithms need questioned critiqued challenged indeed algorit hms decision processes around algorithms must scrutinised terms affect human rights council europe study algorithms human rights question whether quality decisions respect human rights differs taken human taken based algorithmic calculation answered know human decision function evidence special tversky kahneman regards use tacit knowledge tacit norms schulz dankert take example enables humans notice exceptional cases plication rule appropriate even though case falls within scope increasing importance algorithm decision calls better understanding design characteristics decision making procedures council europe study algorithms human rights iii impact algorithms human rights reservations algorithms automated data processing techniques usually point opacity beyond general concerns however increasing awareness specific human rights particular affected referenced practical examples use algorithms may lead rights violations may otherwise undermine effective enjoyment human rights fair trial due process trend towards using automated processing techniques algorithms crime prevention criminal justice system growing indeed may benefits use massive data sets may processed speedily flight risk assessed accurately moreover use automated processing techniques determination length prison sentence may allow even approaches comparable cases yet growing national security concerns led ever ambitious applications new technologies following string terrorist attacks europe politicians call online social media platforms use algorithms identify potential terrorists take action accordingly rifkind toor platforms already using algorithms identify accounts generate extremist content apart significant impact application algorithms freedom expression see also raise concern fair trial standards contained article echr notably presumption innocence right informed promptly cause nature accusation right fair hearing right defend oneself person concerns may also arise respect article echr protects arbitrary dep rivation liberty article punishment without law field crime prevention main policy debates regarding use algorithms relate predictive policing approach goes beyond ability human beings draw conclusions past offences predict possible future patterns crime include developed automated see tim reilly great question century whose black box trust september available last visited september council europe study algorithms human rights systems predict individuals likely become involved crime perry likely become repeat ffenders therefore requir severe sentencing also includes systems meant predict crime likely take place given time used prioritising police time investigations arrests approaches may ghly prejudicial terms ethnic racial backgrounds therefore require scrupulous oversight appropriate safeguards often systems based existing police databases intentionally unintentionally reflect systemic depen ding crimes recorded crimes selected included within analys analytical tools used predictive algorithms may thus contribute prejudicial decision discriminatory outcomes addition considerable concern exist operation assessments context crime prevention likely create echo chambers within prejudice may cemented bias prejudice related example racial ethnic background may recogni sed police integrated automated computer program deemed independent neutral see also result bias may become standardised may less likely identified questioned unclear prevalent decisions created algorithms criminal justice system generally mere potential use raises serious concerns regard article echr principle equal ity arms adversarial proceedings established european court human furthermore algorithms increasingly used context civil criminal justice systems artificial intelligence developed event ually support replace decision human judges systems currently tested identify decision outcomes view detect patters complex judicial decision making thus far reliable prediction rate relatively low therefore see also article algorithms automated decision content crime prevention briefing paper see example william issac kristian lum kristian lum william isaac predict serve significance october royal statistical society available last visited september see instance jespers belgium october salduz turkey november blokhin russia april council europe study algorithms human rights considered premature current time imagine systems replacing nevertheless suggested systems support assist judges lawyers given pressure high caseloads insufficient resou rces judiciaries uffer danger support systems based artificial intelligence inappropriately used judges delegate decisions technological systems developed purpose perceived objective even case great care therefore taken assess systems deliver conditions may used order jeopardise right fair trial particularly case systems introduced mandatorily case parole decisions united states concerns judicial bias around parole decisions led mandatory introduction software predict likelihood offenders reo ffending many however independent investigation software suggests software used predict future criminals biased blacks angwin mattu kirchner privacy data protection longest sustained human rights debate automated data processing algorithms relates right privacy algorithms facilitate collection processing repurposing vast amounts data images may seri ous consequences enjoyment right private family life including right data protection guaranteed article echr algorithms online tracking profiling individuals whose browsin patterns recorded cookies nikolaos altreas predicting judicial decisions european court human rights natural language processing perspective peerj computer science open access published october available see also law society gazette monidipa fouzder artificial intelligence mimics udicial reasoning june available ticle last visited september ibid see gcn kevin mccaney prisons turn analytics software parole decisions november available last visited september see sills cookie small amount data generated website saved web browser purpose remember information user similar preference file created software application cookies may serve many functions common purpose store login information specific site cookies also used store user preferences specific site example search engine may store search settings cookie council europe study algorithms human rights similar technologies digital fingerprinting aggregated search queries search engines assistants moreover behavioural data processed smart devices location sensor data apps mobile devices tene polonetsky raising increasing challenges privacy data protection applications online tracking profiling also used targeted advertising based profile person presumed interests user consent important regulatory concern research berkeley established instance use privacy tracking technologies observed users digital fingerprinting behavioural data generated sensors increased following greater awareness consumers growing practice deleting disabling cookies part choice settings internet moreover extensive data processing use algorithms may aggravate infringements rights personal data used target individuals context insurance employment applications one particular challenge algorithmic processing personal data generation new data data subject shares discrete pieces data often possible data rged generating second even third generations data individual two innocuous pieces data assessed comparison much larger data set breed generate baby data nature entirely unpredictable data subject raises major issues notions consent transparency personal autonomy research cambridge stanford universities illustrate scale challenge efforts ongoing modernise council eur ope convention protection individuals regard automatic processing personal data convention ets line technological evolution define rights data subject respect implications rivacy contemporary tools data collection processing repurposing profiling article draft modernis convention establishes explicit right every individual hoofnagle behavioural advertising offer refuse harvard policy law review see stanford news new stanford research finds computers better judges personality friends family available last visited september council europe study algorithms human rights subject decision significantly affecting based solely automated processing data without views taken consideration right obtain knowledge reasoning underlying data processing results processing applied ject time grounds relating situation processing personal data concerning unless controller demonstrates legitimate grounds processing override interests rights fundamen tal freedoms modernisation proposals aim provide complementary safeguards regards transparency article need examination likely impact data processing rights fundamental freedoms person prior commencing processing article guidelines protection individuals regard processing personal data world big data recently adopted committee convention protection individu als regard automatic processing personal data provide general framework apply appropriate policies measures continue make effective data protection principles context big data data protection regulat ory frameworks level general data protection regulation april regulation protection natural persons regard processing personal data free movement data apply may also establish standards use algorithms data collection including possibly limited right information even right explanation goodman flaxman respect decision processes although exact scope right explanation heavily contested wachter see draft modernised convention protection individuals regard processing personal data september available last visited september council europe guidelines protection individuals regard processing personal data world big data january available last visited september see wachter mittelstadt floridi see also lilian edvards michael veale available last visited october council europe study algorithms human rights mittelstadt floridi well rig access knowledge logic involved automatic processing data concerning particular concerns arise use data brokers aggregate information contained personal profiles profiling means extrapo lation data available internet processes automated information gathering subsequent construction application profiles profiling techniques benefit individuals society instance leading better market segme ntation permitting analysis risks fraud yet also important concerns usage technique council eur ope recommendation addresses risk profiles attributed data subject make possible generate new data including data aggregation information may mined use algorithms creates risk large surveillance private entities governments alike rubinstein lee schwartz view echoed united nations huma rights council march noted concern automatic processing personal data individual profiling may lead discrimination decisions otherwise potential affect enjoyment human rights including economic social cultural rights concern using data profiles different purposes algorithms data lose original context repurposing data likely affect person informational self search engines may similar effect right privacy data protection also cilitat aggregation data specific individual use data profiles including established based data collected search algorithms search engines directly affects right person informational self data subject usually aware see details european data protection supervisor ethics webpage available last visited september directive protection natural persons regard processing personal data competent authorities purposes prevention investigation detection prosecution criminal offences execution criminal penalties free movement data provides framework processing data course actions fall community law judicial cooperation criminal matters police cooperation recommendation com mittee ministers member states protection individuals regard automatic processing personal data context profiling human rights council resolution right privacy digital age doc mar council europe study algorithms human rights profiling subsequent repurposing data beyond original context making easier find information reducing practical obscurity anonymous data addition results obtained search algorithms incomplete inaccurate thereby placing individuals distorted light may profiles may particularly serious consequences children future finally increasing evidence data harvested order gain behavioural insights used target voters ultimately even manipulate elections see another key aspect related usage algorithms automated data processing focuses cloud data storage refers solutions whereby files data longer stored local storage stored remotely servers accessible via internet however virtue engaging non storage practices data users may processed algorithms stored remotely intrusive ways would usually practiced automated data processing take place two places transit remote network storage location remote serv ers data stored may ncreasingly difficult users ascertain whether using local remote services modern operating systems gradually becoming deeply enmeshe cloud remote services regard data transit may therefore difficult determine whether sufficiently protected technologies strong end encryption whether manipulated freedom expression operation algorithms data processing techniques tremendous effects right reedom expression includes right receive impart information positive effects search algorithms search engines see solove regards data processing course judicial cooperation criminal matters police cooperation fall community law directive protection natural persons regard processing personal data competent authorities purposes prevention investigation detection prosecution criminal offences execution criminal penalties free movement suc data establish data protection safeguards see also guardian great british brexit robberty democracy hijacked may available hijacked last visited september example microsoft cloud service skydrive operates automated process designed remove certain content nudity see clay council europe study algorithms human rights human right freedom pression repeatedly referred potential harming freedom information freedom expression individuals groups whole segments societies increasingly discussed concerns arise respect ndividual right freedom expression also respect inherent aim article creating enabling environment pluralist public debate equally accessible inclusive moreover privacy data protection concerns raised significantly impede individuals ability freely express search engines act crucial gatekeepers human wish seek receive impart information content indexed ranked highly internet search engine less likely reach large audience seen result use algorithms may lead fragmentation public sphere creation echo chambers favour certain types news outlets thereby enhancing levels polarisation society seriously jeopardise social cohesion search algorithm might also biased towards certain types content content providers thereby risking affecting related values media plu ralism diversity particularly case context dominant online search engines pasquale algorithmic predictions user preferences deployed ocial media platforms guide advertisements individuals might see also personalise search results dictate way social media feeds including newsfeeds arranged see instance council europe recommendation committee ministers member states protection human rights regard search engines adopted committee ministers april meeting ministers deputies paragraph available last visited september observing earch engines enable worldwide public seek receive impart information ideas content particular acquire knowledge engage debate participate democratic see instance report special rapporteur promotion protection right freedom opinion expression david kaye thirty session human ights council pointing search engine algorithms dictate users see priority may manipulated restrict prioritise content see also arstecnica roheeni saxena social media echo chamber real available last visited september according unesco world trends freedom expression media development publication internet technologies enabled many voices heard lack gender statistics thus far prevents better understanding gender impacts algorithms controlled search tools exercise right freedom expression appears regional gender patterns communications replicated also new volume voices see unesco world trends freedom expression media development publication last visited september council europe study algorithms human rights given size platforms google facebook centrality many experience internet quasi sphere york abil ity massively amplify certain voices bucher means trivial matter contrary personalisation information users receive bas predicted preferences interests create filter bubbles may substantially compromise freedom expression includes right information filter bubbles echo chambers plausible therefor widely concept noted empirical evidence existence europe mixed nguyen zuiderveen borgesius individuals usually inform using repertoire source via social media nternet search according article echr measure blocks access content filtering removal content must prescri bed law pursue one legitimate aims foreseen article must necessary democratic society line jurisprudence european court human rights restriction freedom expression must correspond pressing social need proportionate legitimate aim pursued however content removal social media platforms often takes place semi automated automated processes algorithms widely used content filtering content emoval processes urban karaganis schofield including social media platforms directly impacting freedom expression raising rule law concerns questions legality legitimacy proportionality large social media platforms like google facebook frequently claim human remove content buni chemaly large parts process automated wagner based processes according report british yildirim turkey march european court human rights emphasised dangers inherent prior restraints call careful scrutiny part court news perishable commodity delay publica tion even short period may well deprive value interest therefore blocking access internet removal online content requires legal framework ensuring tight control scope bans effective judicia review prevent abuse power regard judicial review measure based weighing competing interests stake designed strike balance inconceivable without framework establishing recise specific rules regarding application preventive restrictions freedom expression council europe study algorithms human rights intelligence security committee parliament various automated techniques exist identifying content believed break terms service respective provider extremist content child exploitation illegal acts incitement violence techniques may also used disable automatically suspend user account rifkind particular challenge context intermediaries encouraged remove content volun tarily without clear legal basis lack legal basis voluntary automated content removal makes even difficult ensure basic legal guarantees accountability transparency due process upheld fernández pérez obama administration advocated use automated detection removal extremist videos additionally proposals modify search algorit hms order hide websites would incite support extremism automated filtering mechanism extremist videos adopted facebook youtube videos however information released process criteria adopted establish videos extremist show clearly illegal content wake reports times ndon wall street journal ads appearing youtube videos espoused extremism hate speech youtube reacted tighter use algorithm operated detect advertiser content reportedly affected independent media outlets including comedians political commentators similar initiative developed europe intermediary service providers response public political pressure committed actively counter online hate speech automated techniques detect delete illegal content disputing necessit effectively confront hate speech uch arrangements criticised delegating law enforcement responsibilities see intelligence security committee parliament report privacy security modern transparent legal framework march availab last visited september see article algorithms automated decision context crime prevention december available decision last visited september see reuters joseph menn dustin volz exclusive google facebook quietly move toward automatic blocking extremist videos available exclusive last visited september see new york times amanda hess youtube shifting algorithms hurt independent media april available last visited september council europe study algorithms human rights state private companies creating risk excessive interference right freedom expression lack compliance principles legality proportionality due process requiring intermediaries restrict access content based vague notions extremism obliges monitor flows communication data online order able detect may illegal content therefore goes tablished principle monitoring obligation intermediaries enshrined relevant council europe policy guidelin due significant chilling effect monitoring freedom expression principle also reiterated draft recommendation roles responsibilities internet intermediaries prepared council europe committee experts internet intermediaries september moreover ordering intermediary decide remove extremist public authority passes choice tools measures onto private party implement solution content removal restriction public authorities could legally prescribe public partnerships may thus allow public actors impose regulations expression could fail ass constitutional muster mueller contravention rule law standards moreover kinds demands public institutions private actors lead overbroad automated monitoring filtering content europol internet referral unit one year launch july assessed processed messages containing violent extremist content materials across online platforms eight languages reportedly leading removal total content steps reportedly taken automate system introduction joint referral platform announced april see article directive june directive electronic commerce principle limited liability service providers intern content council europe declaration freedom communication internet may see draft recommendation committee ministers member states roles responsibilities internet intermediaries finalized msi september recommendation see europol internet referral unit one year press release july available last visited september see communication commission european parliament european council council delivering european agenda security fight terrorism pave way towards council europe study algorithms human rights imperative acting decisively spread hate messages incitement racially offences indisputable uch practices raise considerable concerns related foreseeability legality interferences freedom expression notably data extremist online content europol processing refers content illegal council europe member states also material violates terms service internet intermediary moreover many situations extremist content material inciting violence difficult identify even trained human complexity disentangling factors cultural context humor algorithms today capable detecting irony critical analysis filtering speech eliminate harmful content algorithms therefore faces high risk removing speech harmless contribute positively public debate according european court human rights article also protects shoc king offensive disturbing algorithmic blocking filtering removal content may thus significant adverse impact legitimate content already highly prevalent dilemma large amounts legal content removed terms service internet platforms exacerbated pressure placed actively filter according vague notions extremist hate speech clearly illegal content according european court human rights obligation filter remove certain types comments users online platforms puts excessive impracticable burden operators risks oblige install monitoring system capable undermining right impart nformation venice commission equally called efforts strengthen human rights safeguards effective genuine security union available last visited september see also article algorithms automated decision context crime prevention briefing paper demonstrated jurisprudence domestic courts also case european court human rights exercise qualifying speech ill egal hate speech delicate several judgments court concerning question whether certain speech could qualified criminal hate speech resulted divided votes turkey september lindon otchakovsky july france october féret belgium july perinçek switzerland october see also vejdeland others sweden february magyar tartalomszolgáltatók egyesülete zrt hungary february council europe study algorithms human rights avoid excessive burdens placed providers electronic communication networks public concern europe grown following elections respect dissemination misinformation via fabricated intentionally false misleading news fake news including automated techniques social media platforms thereby possibly significant influence democratic decision processes see also result renewed calls traditional media responsibility standards applied social media platforms scholars likened facebook acting news editor editorial responsibility trending topics helberger trilling question follows whether social media platform algorithms rank curate third submissions exert form editorial control traditionally performed media professionals therefore engage specific media freedom assembly association internet particular social networking services vital tool exercise enjoyment right freedom assembly association offer ing great possibilities enhancing potential participation individuals political social cultural freedom individuals use internet platforms social media establish associations organise purposes peaceful see joint opinion venice commission directorate information society action crime directorate human rights dhr directorate general human rights rule law dgi council europe draft law amending completing moldovan legislation mandate security adopted venice commission plenary session venice march available last visited september see example power big data psychographics available last visited september das magazin hannes grassegger und mikael krogerus ich habe nur gezeigt dass die bombe gibt december available last visited september although exact role techn iques used cambridge analytica others elections heavily disputed see also reuters institute emma goodman editors algorithms want choosing news available last visited september code conduct countering llegal hate speech online may facebook microsoft twitter tube see also guardian year facebook became bad guy available last visited september see recommendation committee ministers member states protection human rights regard social networking services council europe study algorithms human rights assembly including protest line article echr equally around globe social media algorithmically advanced dissemination networking potential suggested play promi nent role organising motivating activists line article restriction right freedom peaceful assembly freedom association must prescribed law pursue legitimate aim necessary democratic society operation algorithms social media platforms vast amount personally identifiable information individuals available may course also used track identify human beings may lead automatic sorting certain individuals groups calls assemblies could significant negative impact freedom assembly profiling crowd control protesters take place internet also extends data crowd control methods theoretically algorithms used predict possible conflict protest situations could also used pre tool prevent demonstrations protests arresting certain individuals bef ore even effective remedy article echr stipulates everyone whose rights violated shall effective remedy national authority available remedy effective practice law states must therefore ensure individuals access judicial procedures impartially decide claims concerning violations human rights online including effective non mechanisms administrative means seek ing remedy national human rights institutions primary responsible entity rights contained echr states must take appropriate steps protect human rights violations including see recommendation committee ministers member states internet fre edom recommendation committee ministers member states guide human rights internet users see among others pablo barberá megan metzger tweeting revolution social media use euromaidan protest available last visited september see also zeyne tufekci twitter tear gas power fragility networked protest yale university press see tim chant inevitability predicting future available last visited september council europe study algorithms human rights privat actors must ensure within jurisdiction affected hav access effective remedy includes ensuring private actors respect human rights throughout operations particular establishing effective complaint mechanisms omptly remedy grievances individuals automated decision processes lend particular challenges individuals ability obtain effective remedy include opaqueness decision basis whether ndividuals consented use data making decision even aware decision affecting difficulty assigning responsibility decision also complicates individuals understanding turn address decision nature decisions made automatic without little human input primacy placed efficiency rather human thinking means even larger burden organisations employing stems provide affected individuals way obtain remedy wide variety sectors automated decision systems employed serious repercussions human rights whether related health treatments job opportunities predictive policing otherwise rendering capability obtain effective remedy even essential increasing number companies especially larger ones use algorithms automated data processing techniques running complaints procedures context automated content removal process social media platforms see use algorithms particularly evident response different types content receive content prioriti sed process evidently automated true threshold user complaints required piece content reviewed strong suggestions complete response system internet platforms facebook google microsoft user queries automated many types inquiries complaints wagner zhang stalla gilbert often many users need complain spe cific type content automated algorithm identifies relevant referr uman operator content review operators reported working often council europe study algorithms human rights considerable time pressure minimal instructions line internal deletion rules right effective remedy implies right reasoned individual decision historically decisions taken human beings exercise functions based comprehensive training line applicable decision making processes granted margi discretion principle judge government minister administrative official task decide accordance criteria developed court balancing individual rights freedom expression protection violence protection rights others shall put practice decision must based careful analysis specific context taking consideration chilling effect interference may entail considering proportionality interference today however increasingly algorithmic data processing techniques preparing influencing decision complaints procedures addition serious ncerns exist whether automatic response processes complaints constitute effective remedy famous removal youtube video european parliament debate related torture reinstated hours following mep compl aint even received public apology google considerable doubts whether complaints treated rather algorithms often obscure access reasoned explanation certain steps taken particular case cases right effective remedy demands access escalated system dispute resolution provided first step may operated automated means must possibility complain outcome higher internal review mechanism complainant satisfied outcome must possibility challenge judicial remedy line article european however suggestions judicial redress mechanism alone insufficient need government see süddeutsche zeitung till krause hannes grassegger inside facebook available last visited september see marietje schaake tube took dow video available last visited september see among others keefe ireland january council europe study algorithms human rights supervision collaborative negotiations bet ween consumers corporations loo respect right privacy automated techniques algorithms cilitate forms secret surveillance data impossible affected individual know european court human rights underlined absence notification point undermines effectiveness remedi measures prohibition discrimination another key human right frequently cited relation operation algorithms automated processing techniques right enjoy human rights fundamental freedoms without discrimination terms speed volume data processed algorithmic decision considerable advantages certain types human decision however algorithms may well inbuilt biases may hard detect correct sandvig particularl case individual variables big data algorithms serve proxies protected categories race gender age algorithm may choose discriminate group users correlates even varia ble race gender age without time search algorithms search engines definition treat information equally processes used select index information may applied consistently search resul typically ranked according perceived relevance ccordingly different items information receive different degrees visibility depending factors taken account ranking algorithm see also result data aggregation profiling search algorithms search engines rank advertisement smaller companies registered less affluent neighbourhoods lower large entities may put commercial disadvantage search engines search algorithms also treat users equally different users see roman zakharov russia december algorithm may also deliberately impacted variety external factors may relate business models legal constraints copyright contextual factors council europe study algorithms human rights may presented different results basis behavioural profiles including personal risk profiles may developed purpose insu rance credit scoring generally differential pricing offering different prices goods services different consumers based profile see biased algorithm systematically discriminates one grou society example based age sexual orientation race gender socio standing may raise considerable concerns terms access rights individual endusers customer affected decisions also societ whole authors even suggest online services use personalised rating systems inherently likely lead discriminatory practices rosenblat argued result individuals right view unbiased personally targeted version search results seen way individual exit filter bubble see untargeted version search content social media timeline internet service product using ory algorithms could useful tools reduce bias places common hiring processes yet experts warned automation machine learning potential reinforce existing biases unlike humans algorithms may unequipped consciously counteract learned biases one potentially helpful consideration discern whether algorithms promote prevent discriminatory treatment refer legal distinction direct indirect discrimination direct discrimination occurs decision bases decision directly criteria factors regarded unlawful race ethnicity religion gender sexual orientation age disability frequently unlawful biases made sub basis information external dataset form basis decision example interviewer noticing age racial origin person standing ont arguably algorithm systems better excluding direct biases indirect see also relevant provisions regulation related profiling automated data processing rights data subject see instance guardian programs exhibit racial gender bias research reveals available last visited september guardian algorithms rule working lives available last visited september council europe study algorithms human rights discrimination occurs certain characteristic factor occurs frequently population groups unlawful discriminate person certain racial ethnic background living certain geographical area women fewer pensionable years career breaks since algorithmic decision systems may based correlation data sets efficiency consideration danger systems perpetuate exacerbate indirect discrimination stereotyping indirect discrimination present differential treatment justified using algorithmic decision systems erefore important seek prevent unjustified differential treatments design systems accordingly particular differential treatment unjustified unlawful relies biased data generate risk assessment case decision directly indirectly discriminatory relies data information may instance racially biased example criminal system uses risk assessment tools decide whether person shoul granted bail system generate risk profiles based police data number offence fact however consequence direct discrimination racial bias algorithmic dec systems based previous human decisions likely biases potentially undermine human decision replicated multiplied algorithmic decision systems diffi cult identify correct social rights access public services workplace another key area wher automated decision become increasingly common recent years algorithms may involved decisions hiring firing staff staff organi sation management well individual evaluation employees automated feedback loops sometimes linked customer input may decide performance evaluation staff kocher hensel see laurel eckhouse big data may reinforcing racial bias criminal justice system available last visited september propublica angwin julia surya mattu lauren kirchner machine bias softwar used across country predict future criminals biased blacks available last visited september council europe study algorithms human rights decision processes means perfect humans conduct bias related race bertrand llainathan class gender altonji blank goldin rouse demonstrated repeate dly human resources management practices processes companies moving towards algorithmic recruitment methods rosenb lat kneese others however new concerns related lack transparency decisions make hiring process beyond raised moreover many automated decision processes based data received via internet platforms allowing wisdom crowd make decisions individuals employment highly questionable ethical point view also limits ability workers contest decisions seem objective measures performance tufekci individual employment platforms transforming people human computation irani questions arise rkers rights employee self societies whole believe human beings treated notably increased automation workplace also raises considerable challenges relation privacy rights hendrickx van bever employees safeguarded workplace systems automated data collected workplace employees rights article danger even directly targeted general data collection measures see finally additional challenges related algorithms public private sector organisations monitor staff communications conduct internal rankings employees may part formal evaluation process possibly decisive respect individual career opportunities practices typically employed ensure staff represent well either company bureaucracy evident implications freedom expression employees voorhoof humblet human rights article convention see government agencies services increasingly automating decision use algorithms van haastert heavily debated whether systems increase efficiency evident operation see dorssemont lörcher schömann eds european convention human rights employment relation hart publishing oxford council europe study algorithms human rights systems pose considerable questions transparency accountability public decision must held gher standard private non sector present public sector europe employing automated decision areas diverse social security taxation health care justice system van haastert tufekci considerable danger social sorting medical data algorithms sort specific citizen groups human profiles thereby possibly preventing access social services another example relates practice profiling unemployed analysed researchers effort assess social political implications algorithmic decision associated social benefits jędrzej niklas karolina sztandar katarzyna szymielewicz analysis identified several challenges relevant also algorithms areas public sector service delivery non transparent algorithmic rules applied distribution public services computational shortcomings triggering arbitrary deci sions instance respect receipt social benefits right free elections operation algorithms automated recommender systems may create filter bubbles echo chambers individuals see pieces information confirm opinions match profile bozdag pariser zuckerman momentous effects democratic processes society actual impact filter bubbles targeted misinformation formation political opinion difficult determine accura echo chambers pose danger creating ideological bubbles callaghan may latively easy enter hard exit salamatian may crucial effects particular context elections argued ince advent internet online campaigning social media networks ikely change way litics elections run recently academic research revealed extent see nguyen tien pik hui harper loren terveen joseph konstan exploring filter bubble effect using recommender systems content diversity proceedings international conference world wide web new york usa acm available zuiderveen borgesius frederik worry filter bubbles internet policy review journal internet regulation retrieved september available council europe study algorithms human rights curation manipulation online content social media platforms may tip elections ections esearchers reportedly manipulated facebook platform influence users voting behaviour telling friends said voted without users knowledge able convince statistically significant segment population vote congressional mid elections november bond strong indications since facebook selling related political advertising services political parties around world similar behaviour observed local elections griffin whether facebook similar dominant online platforms may deliberately use power influence human voting less point fact principle ability influence elections recent research suggests elections may candidates best political argument use efficient technology manipulate voters sometimes emotionally irrationally may altogether new phenomenon certainly increased scale effect leading shift paradigm could jeopardise democracy data inconspicuously amassed harvested stored algorithmic technologies likened new currency power directly employed micro voters possibly decisi effects elections indeed less candidates may means afford effective manipulation technologies help predict voter preferences political advertising nowadays regulated impartiality requirements imposed public broadcasters equivalents exist experiment facebook researchers showed graphic users news feed indicating many friends voted day providing button click voted well users prompted news frien voting turned likely vote others decision effect voting behavior friends researchers concluded single message facebook strategically delivered increased turn directly voters thanks ripple effect ultimately caused additional votes cast amongst overall million day see jonathan zittrain engineering election harvard law review forum vol see also guardian great british brexit robberty democracy hijacked may available hijacked last visited september arguing brexit referendum decided end votes total registered vot ers targeted firm introduced mass data psychological warfare techniques bringing together psychology propaganda technology powerful new way hannes grassegger mikael krogerus data turned world upside available last visited september council europe study algorithms human rights use algorithmic predictions preferences voter behavior may equally powerful impact voters context particular role played cial bots shaping political public debate leading elections scussed particular context elections brexit referendum social bots algorithmically controlled accounts emulate activity human users operate much higher pace automatically producing content engaging social interactions successfully keeping artificial identity undisclosed research extent resence social media bots affect political discussion around presidential election suggests negatively affect democratic political discussion rather improving turn potentially alter public opinion endanger integrity lection right free elections established article protocol acknowledged european court human rights fundamental principle truly democratic political importantly noted feasibi lity study use internet elections committee experts media pluralism transparency media ownership msi council europe regulatory challenges related elections due rise intermediaries ather lack adequate regulation study otes fundamental pernicious simultaneously difficult detect implication shift social media rising power intermediaries inability regulation level playing field political contest limit role money elections possible impacts list specific human rights may impacted use automated processing techniques algorithms exhaustive rather aims project obviously implicated rights stronger lesser degree already public discussion human rights fundamental freedoms universal indivisible inter inter result human rights fundamental freedom potentially impacted use algorithmic technologies bessi alessandro emilio ferrara social bots distort presidential election online discussion first monday volume november available last visited september see feasibility study use internet electoral campaigns msi public council europe study algorithms human rights given limited scope study engaged discussion right life context smart weapons algorithmically operated drones context health related research explored poss ible effects systematis ation views opinions algorithms may right hold opinions right freedom ought conscience religion indeed increasing use automation algorithmic decision spheres pub lic private life threatening disrupt concept human rights protective shields state interference traditional asymmetry power information state structures human beings shifting towards asymmetry power information operators algorithms may public private acted upon governed council europe study algorithms human rights regulatory implications use automa ted data processing tech niques algorithm growing concern political public level globally regarding increased use algorithms automated processing techniques considerable impact exercise human rights result calls made introduce tighter control regulati already numerous cases governments independent auditors engage form regulation algorithmic development usually operation commenced software data processing systems including algorithms used slot machines australia new zealand must government regulation fair secure auditable woolley developers machines required submit algorithmic systems regulators presented consumers zealand gaming machine national standard recent revision defines extraordinary technical detail machines operate example nominal standard deviation nsd game must greater hashing algorithm verification gaming equipment softw firmware psds hmac algorithm gambling equipment united kingdom controlled specific licensing regime level regulatory technical standards adopted specifying organisational requirements investment firms engaged algorithmic section german federal law data protection provides scientifically proven mathematical process calculation probability specific behaviour individual algorithm used making decision see instance vote january french national assembly new bill digital rights bill includes provisions relating algorithmic transparency duty loyalty fairness online platforms algorithmic decision rosnay zealand gaming machine national standard available following link last visited september see last visited september see german federal law data protection promulgated january federal law gazette amended article august federal law gazette available last visited september council europe study algorithms human rights licensing systems algorithms used certain sectors resemble quality control assurance schemes employed production manufacturi industry prepared relevant experts know control respective quality standards given field doubtful however extent regulatory methods exported multiple evolving spheres public private life automated data processing techniques algorithms operated british police child exploitation online protection centre demanded instance facebook button provided default internet users wagner attempt pressure facebook changing default code british facebook website unsuccessful suggests kind regulatory responses may expected states seek define functioning algorithms large online platforms fundamental legal ethical questions surround legal personhood automated systems algorithms easily resolved report wishing exculpate involved development programming implementation autonomous systems must knowledged automation vast data analysis adaptability self create considerable challenges accountability algorithmic decisions february european parliament adopted resolution calling european commission develop legislative proposal civil law rules robotics proposal expected address amongst things general principles concerning development robotics artificial intelligence civil use ethical principles liability issues tellectual property rights flow data safety security historically challenges related automated data processing addressed data protection legislation today relevant innovative approaches introduction limited right explanation goodman flaxman wachter rights internet users also product data protection legislation however significant difference right privacy data protection regulation end still governance mechanism safeguard privacy personal data protection rights importantly privacy see european parl iament resolution february recommendations commission civil law rules robotics inl available bkmd last visited september council europe study algorithms human rights exercise human ghts requires effective enforcement greatest challenges area data protection come lack willingness provide sufficient resources data protection authorities clear challenges around discrimination content manipulation elections beyond privacy data protection raise fundamental questions large set issues expertise data protection community may well drawn attempting identify suitable regulato responses algorithmic governance suggested echnologists think trust assurance computer systems bit differently policymakers seeking strong formal guarantees trustworthy digital evidence system rks intended complies rule policy objective rather simple assurances piece software acts certain way kroll turn feeds wider debate auditing algorithms zero knowledge proofs could conceivably generated algorithms demonstrate conform certain properties without individu engaging proof able see actual algorithm kroll beyond zero knowledge proofs new types technical accountability may able support common human notions trust accountability could therefore used future supportive technological approaches establishing trust ansparency accountability states adopted strategies regulation content require internet intermediaries restrict content knowingly relying upon automated means rather flagging end users raises transparency account ability human rights issues attempts regulation may raise human rights concerns may also problematic sense regulators may developed sufficiently comprehensive expertise mulate standards reflect technological engineering perspectives also legal ethical considerations efforts towards promoting greater transparency accountability surrounding use algorithms council europe study algorithms human rights seem appropriate initi steps direct standards would also need combined high technology neutral regulations regulatory restraint therefore warranted stage implementation algorithms automated processing techniques implications human rights ethical considerations must carefully examined particular current cademic discourse centred concepts human autonomy individual agency related right privacy informational autonomy congruent privacy therefore autonomy agency considered separately ref human capability set one goals human capability make decisions exercise discretion may conflict use algorithms automated processing techniques may mean human rights may extended reinterpreted protect individual autonomy agency transparency algorithms often viewed black boxes consumers regulators alike pasquale demands algorithmic transparency thus growing public political including government requests companies regarding algorithms reviewed independent auditors regulators general public diakopoulos rosnay importantly challenges exist professionals develop algorithms also groups data scientists different levels abstraction complexity prompt distinct challenges opacity transparency frequently argued much usage algorithms machine learning takes places without understanding causal relationships correlation instead causation may lead bias errors raise concerns data quality neil examples see chapter pasquale frank black box society secret algorithms control money information harvard university press angela merkel instance called major internet platforms divulge information algorithms internet users right know basis information received via search engines channeled see guardian angela merkel internet search engines perception available last visited september see also tufekci note common ethical oncern algorithmic decision opaque nature many algorithms algorithms employed make straightforward decisions case medical diagnostics aviation lack transparency raises important questions ccountability tufekci council europe study algorithms human rights challenge however relates also way human beings use perceive interpret resu lts belief computer algorithms produce neutral unbiased results chun without form politics denardis heart problem accordingly would helpful ensure critical engagement public debates algorithms attem change provision entire algorithms underlying software code public unlikely solution context private companies regard algorithm key proprietary software however may possibility demanding key subsets information algorithms provided public example variables use goals algorithms optimised training data average values standard deviatio results produced amount type data processed algorithm key context provision data imaginable rather notion effective transparency underlying goal increasing transparency must actually met data disclosed implies demand data may always helpful may worst case even serve counteract goal enhancing transparency effective transparency automated systems complicated however frequent changes algorithms used google examp changes algorithm hundreds times per year tufekci also danger manipulation gami algorithms made public moreover machine learning techniques complicate transparency point provision source codes algorithm may even sufficient instead need actual explanation results algorithm produced since algorithms may actively obscure consequential decision taken transparency promotion measures may also targeted decision process given algorithms meaningfu lly studied outside social organisational context decision january german ederal supreme court bundesgerichtshof rejected claim information concerning credit agency algorithm protected business secret however allowed claim information concerning data used calculate creditworthiness thro ugh means algorithm see german federal supreme court bundesgerichtshof judgment january available council europe study algorithms human rights transparency enhancement measures finally may facilitate scrutiny public also independent experts commissions specialised agencies turn may support efforts promote compliance consumer protection human rights standards accountability accountability principle person legally politically responsible harm provide form justification compensation however someone accountable degree control sense facilitated caused harm position prevent mitigate legally accountability manifests concept liability provide remedy damages law usually imposes liab ility person position prevent harm mitigate risk example insurance allocation accountability algorithmic decision complicated fact frequently clear necessary egree control imputed legal political accountability one aspect developer algorithmic tools may know precise future use implementation person implementing algorithmic tools applications turn fully understand algorithmic tools operate developing programming algorithm held accountable authors suggested algorithmic accountability regulation impossible programmer unable predict fully understand algorithm takes decisions makes kroll another avenue explore whether existing product liability regulation extended include software rather public private actors held accountable purchase algorith introduce services even without understanding operation governance failure automobile emissions scandal also exemplifies wider challenge enhancing accountability algorithms across numerous different sectors whether criminal justice social media healthcare insurance banking sector name examples area need specific regulatory responses ensure greater transparency accountability automated data algorit hmic decision systems algorithmic accountability must safeguarded due process rule law effective redress mechanisms individuals whose rights infringed automated decision systems also essential council europe study algorithms human rights approach places challenging duty operators algorithms automated data processing techniques whether public private ensure basic standards human rights fundamental principles offset arguments possib greater efficiency opaque technological systems wagner similar issues arise relation private actors employ algorithms automat data processing techniques operations particularly market owing size scale activities deliver services important public service value turn may also important impact enjoyment human rights accountability individuals companies respect algorithms implement depends much nature algorithms outputs cases outputs defamatory infringe copyright raise legal concerns existing governance mechanisms ensure kinds outputs limited staab stalla carmichael however mechanisms typically regard outputs algorithms algorithms fact general lack regulatory frameworks ensure algorithms first place programme produce results uphold protect fundamental values basic ethical societal principles touches upon fundamental ethical questions respect operation automated data processing techniques algorithms add ressed study normative values reflected automated system ethical discussions surrounding self car provide insight complexity challenge algorithm decide hypothetica situation likely accident may either threaten life young child life elderly person number lives possibly stake play role right wrong decisions situation legal conse quence held accountable case wrong decision taken ethical frameworks improved risk assessment aside direct regulatory mechanisms influence code algorithms indirect mechanisms influence algorithm codes could also considered address production process producers algorithms attempt ensure aware legal challenges ethical dilemmas human rights concerns arise automated data decision techniques instrument council europe study algorithms human rights achieve goal could consist standardised professional ethics forms licensing system data engineers algorithm designers similar exist professions like doctors lawyers architects anoth suggestion frequently made existing mechanisms management development processes software could improved spiekermann may particularly concern agile software development techniques modularity temporality capture pose considerable challenges privacy gürses hoboken well human rights mannaro use algorithms decision potentially prejudices rights individuals additional oversight mechanisms could contribute ensuring algorithm operates fair sustainable manner order asses understand human rights risks involved operating automated decision making systems companies exercise human right due diligence take form human rights impact assessments investigating concrete potential impacts individuals employment systems may whether direct indirect preventing mitigating harms identified assessments examples emerging standards industry associations ieee institute electrical electronics engineers algorithms transparency privacy bias broadly ethical system design internet engineering task force ietf ieee model process addressing ethical concerns system des ign ieee transparency autonomous systems ieee data privacy process ieee algorithmic bias considerations ietf research human rights protocol considerations draft examples relev ant industry frameworks could support greater levels human rights compliance include fat fairness accountability transparency machine learning principles accountable see last visited september council europe study algorithms human rights see frequent use word ethic connection algorithms among experts also public debate may indicator tactical move actors want avoid strict regulation pointing non normative concepts may however also point need deeper reflection interplay different types norms role responsibility various actors order shape governance structure algorithmic decision ethics new set applicable meta council europe study algorithms human rights main indings conclusi ons notion algorithmic processing decision diversely interpreted understood legal technological social science circles differently amongst public addition field comparativel new awareness impacts exercise human rights broader societal development grown recently yet translate wider inclusive public policy debate possible regulatory implications authors stud acknowledge far little information available make well decisions topic thus considerable additional research analysis required including respect characteristics human decision making process decision processes human beings necessarily better simply different automated decision systems different kinds bias risk error likely develop automated decision thus needs openly dis cussed criteria developed measure quality automated decision making highly welcome increasing research topics however academic research insufficient essential ensure mem bers professional technological engineering legal media philosophical ethical communities engage discussions debates must also include general public order promote active engagement human beings lively public bate issue affects human beings communities adequate media information literacy promotion activities organised facilitate empowerment public critically understand deal logic operation algorithms notably public entities governments must access sufficiently comprehensive information properly understand algorithmic decision systems already deeply embedded societies across world provide one concrete example problem automobile emissions scandal demonstrates happen small piece frequently used software widely implemented without adequate independent regulatory scrutiny undesirable human rights rspective powerful publicly algorithmic systems lack meaningful form public scrutiny application human rights framework crucial goes beyond ensuring transparency accountability ensur rights effectively considered automated decision systems algorithms simple task require combination developing industry standards put human beings human rights centre technology design process effective council europe study algorithms human rights regulatory measures ensure industry standards fail governments able step promote protect human rights human beings right effectively scrutinise decisions made publ authorities issues related algorithmic governance regulation public policy prerogatives left private actors alone may engage voluntary measures promote transparency accountability within perations duty care towards users responsibility respect human rights task devising comprehensive effective mechanisms ensuring algorithmic accountability lies states crucial important impact automated data processing techniques algorithms exercise enjoyment human rights also capacity expand reinforce redistribute power authority resources society importantly may areas societal human interaction algorithmic decision systems appropriate automated data processing decision making systems relied upon heavily promote societal development resolv complex new challenges future generations likely harm good therefore critical ensure key areas automation appropriate human rights perspective take place view authors study public debate multiple human rights dimensions algorithms lagging behind technological evolution must strengthened rapidly ensure human rights interests individuals effectivel sustainably safeguarded line values laid european convention international treaties use algorithms automated data processing techniques potentially positive negative impacts exercise enjoyment human rights must aim policy makers ensure technologies used line principle primacy human increasingly technology societies designed first foremost effective exercise enjoyment rights human beings mind see also human rights robot age challenges arising use robotics artificial intelligence virtual augmented reality report rathenau institut commissioned funded parliamentary assembly council europe adopted pace april council europe study algorithms human rights consequence study comes following conclusions public entities independent non actors initiate support research hel better understand respond human rights ethical legal implications algorithmic decision therefore support engage trans problem evidence based research well exchan best practices public entities held responsible decisions take based algorithmic processes adoption mechanisms encouraged enable redress individuals negatively impacted algorithmical informed decisions human rights impact assessments conducted making use algorithmic decision areas public administration technological development monitored closely reviewed potential negative mpacts particular attention paid use algorithmic processing techniques elections election campaigns effective responses negative impacts could include experimental regulatory approaches best protect rights others guarantee regulatory goals provided accompanied systematic monitoring effects public awareness discourse crucially important available means used inform engage general public ers empowered critically understand deal logic operation algorithms include limited information media literacy campaigns institutions using algorithmic processes encouraged provide easily accessible explanations respect procedures followed algorithms decisions made industries develop analytical systems used algorithmic decision data collection processes particular responsibil ity create awareness understanding including respect possible biases may induced design use algorithms certification auditing mechanisms automated data processing techniques algorithms developed ensure compliance human rights public entities actors encourage promote development human rights design ethical approaches council europe study algorithms human rights adoption stronger risk appro aches development software states impose general obligation nternet intermediaries use automated techniques monitor information transmit store give access monitoring infringes users privacy chilling effect freedom expression public entities engage sector insurance credit reference agencies banks others develop specific standards guidelines ensure able respond challenges use automated decision algorithms taking account interests consumers general public considering complexity field awareness general public important suffice evident need additional institution networks spaces different forms algorithmic decision making analysed assessed relevant stakeholders engage endeavour counci europe continent leading human rights organisation appropriate venue explore impacts effective exercise human rights increasing use automated data processing decision making systems particular algorithms public private spheres continue endeavours regard view developing appropriate standards instruments guidance member states council europe study algorithms human rights bibliography altonji blank race gender labor market handbook labor economics elsevier retrieved andreessen marc software eating world wall street journal august retrieved september angwin julia surya mattu lauren kirchner machine bias software used across country predict future criminals biased propublica retrieved august bertrand marianne sendhil mullainathan emily greg employable lakisha jamal field experiment labor market discrimination american economic review bond robert experime social influence political mobilization nature bozdag engin bias algorithmic filtering personalization ethics information technology bucher taina want top algorithmi power threat invisibility facebook new media society bucher taina algorithmic imaginary exploring ordinary affects facebook algorithms information communication society buni catherine soraya chemaly secret rules internet verge retrieved september facebook chun wendy hui kyong control freedom power paranoia age fiber optics cambridge mass mit press clay kelly microsoft spying skydrive users forbes retrieved august denardis laura architecting civil liberties global internet governance academic network annual meeting hyderabad andra pradesh india giganet retrieved denardis laura hidden levers internet control information communication society september diakopoulos nicholas algorithmic accountability digital journalism edwards lilian veale michael slave algorithm explanation probably remedy looking duke law technology review forthcoming available fernández pérez maryant parliamentarians encour age online platforms censor legal content edri retrieved june encourage council europe study algorithms human rights gillespie tarleton relevance algorithms media technologies essays communication materiality society edited gillespie boczkowski foot cambridge mass mit press goldin claudia rouse cecilia orchestrating impartiality impact blind auditions female musicia national bureau economic research retrieved september goodman bryce seth flaxman european union regulations algorithmic decision right explanation icml workshop human interpretability machine learning new york arxiv griffin andrew facebook manipulating vote independent retrieved august grindrod peter mathematical underpinnings analytics theory applications data science customer industries oxford oxford univ press gürses seda joris hob oken privacy agile turn cambridge handbook consumer privacy edited selinger retrieved van haastert hugo government platform public values age big data oxford internet stitute helberger natali damian trilling facebook news editor real issues concerned media policy project retrieved september hendrickx frank aline van bever article echr judicial patterns employment privacy protection european convention human rights employment relation edited dorssemon lörcher schömann oxford hart publishing hildebrandt mireille serge gutwirth general introduction overview profiling european citizen springer dordrecht retrieved september hoofnagle chris jay behavioural advertising offer refuse harvard policy law review irani difference dependence among digital workers case amazon mechan ical turk south atlantic quarterly jędrzej niklas karolina sztandar katarzyna szymielewicz poland panoptykon foundation retrieved kim giacomin macredie qualitative study stakeholders perspectives social network service environment international journal human computer interaction kitchin dodge oftware everyday life kocher eva isabell hensel herausforderungen des arbeitsrechts durch digitale plattformen ein neuer koordinationsmodus von erwerbsarbeit neue zeitschrift für arbeitsrecht kroll joshua accountable algorithms retrieved september council europe study algorithms human rights kroll joshua accountable algorithms provocation media policy project retrieved september lazer david ryan kennedy gary king alessandro vespignani parable google flu traps big data analysis science lazer david ryan kennedy learn epic failure google flu trends loo van corporation courthouse rochester social science research network retrieved june mannaro katiuscia adopting agile methodologies distributed software development universita degli studi cagliari cagliari italy retrieved mccarthy daniel open networks open door american foreign policy narration internet foreign policy analysis mueller milton networks states global politics internet governance mit press nguyen tien pik hui harper loren terve joseph konstan exploring filter bubble effect using recommender systems content diversity proceedings international conference world wide web www new york usa acm retrieved nikolaos altreas predicting judicial decisions european court human rights natural language processing perspective peerj computer science open access published october callaghan greene conway carthy cunningham white rabbit hole extreme right online recommender systems social science computer review social science computer review neil cathy weapons math destruction big data increases inequality threatens democracy new york crown pariser eli filter bubble internet hiding new york penguin press pasquale frank black box society secret algorithms control money information harvard university press pasquale frank platform neutrality enhancing freedom expression spheres private power rochester social science research network retrieved june perry walt predictive policing role crime forecasting law enforcement operations rand corporation retrieved september erry rifkind malcolm report intelligence relati murder fusilier lee rigby rosenblat alex tamara kneese others networked employment discrimination open society foundations future work commissioned research council europe study algorithms human rights papers retrieved september rosenblat alex karen levy solon barocas tim hwang discriminating tastes customer ratings vehicles bias retrieved june rosnay mélanie dulong algorithmic transparency platform loyalty fairness french digital republic bill media policy project retrieved september rubinstein ira ronald lee paul schwartz data mining internet profiling emerging regulatory technological approaches rochester social science research net work retrieved september salamatian kavé big data banality evil retrieved september sandvig christian kevin milton karrie karahalios cedric langbort algorithm racist diagnosing ethical harm basic components software international journal communication schulz wolfgang kevin dankert governance things challenge regulation law internet policy review sills arthur automated data processing issue privacy seton hall law review spiekermann sarah ethical innovation value system desig approach crc press staab steffen sophie stalla laura carmichael observing recommending social web biases arxiv preprint retrieved september tene jules polonetsky track track advancing transparency individual control online behavioral advertising retrieved september toor amar automated systems ight isis propaganda cost verge retrieved september twitter tufekci zeynep jillian york ben wagner frederike kaltheuner ethics algorithms radical content self cars berlin germany european university viadrina retrieved tufekci zeynep twitter tear gas power fragility networked protest yale university press tversky amos daniel kahneman judgment uncertainty heuristics biases science urban jennifer joe karaganis brianna schofield notice takedown everyd practice available ssrn retrieved october voorhoof dirk humblet eds right freedom expression workplace article echr european convention human rights employment relation oxford hart publishing council europe study algorithms human rights wachter sandra brent mittelstadt luciano floridi right explanation automated decision exist general data rotection regulation rochester social science research network retrieved june wagner ben efficiency accountability bureau helling retrieved march wagner ben global free expression governing boundaries internet content cham switzerland springer international publishing williamson ben computing brains learning algori thms neurocomputation smart city information communication society winner artifacts politics daedalus winner whale reactor search limits age high technology woolley richard charles livingstone kevin harrigan angela rintoul house edge hold percentage cost egm gambling international gambling studies york jillian policing content quasi sphere boston open net initiative bulletin berkman center harvard university zhang pei sophie stalla lester gilbert content context model notice procedures acm press retrieved september zittrain jonathan engineering election harvard law review forum vol zuckerman ethan digital cosmopolitans think internet connects rewire norton company zuiderveen borgesius frederik worry filter bubbles internet policy review journal internet regulation retrieved september council europe study algorithms human rights references council europe instruments european convention human rights ets automatic processing personal data convention ets declaration committee ministers freedom communica tion internet may recommendation committee ministers member states protection individuals regard automatic processing personal data context profiling adopted november recommendation committee ministers member states protection human rights regard search engines adopted april recommendation committee ministers member states prote ction human rights regard social networking services adopted april recommendation committee ministers member states guide human rights internet users adopted april recommendation committee ministers member states internet freedom adopted april guidelines protection individuals regard processing personal data world big data january draft recommendat ion committee ministers member states roles responsibilities internet intermediaries finalized msi september available european union instruments directive june european parliament council june certain legal aspects information society services particular electronic commerce internal market directive electronic commerce regulation protection natural persons regard processing personal data free movement data directive protection natural persons rega processing personal data competent authorities purposes prevention investigation detection prosecution criminal offences execution criminal penalties free movement data establish data pro tection safeguards european parliament resolution february recommendations commission civil law rules robotics inl available bkmd council europe study algorithms human rights iii newspapers online articles great question century whose black box trust available article algorithms automated decision content crime prevention briefing paper das magazin hannes grassegger und mikael krogerus ich habe nur gezeigt dass die bombe gibt december available reuters institute emma goodman editors algorithms want choosing news available gcn kevin mccaney prisons turn analytics software parole decisions november available stanford news new stanford research finds computers better judges personality friends family available knows guardian great british brexit robberty democracy hijacked may available robbery roheeni saxena arstecnica social media echo chamber real available article algorithms automated decision context crime prevention december available making joseph menn dustin volz reuters exclusive google facebook quietly move toward automatic blocking extremist videos available video guardian year facebook became bad guy available pablo barberá megan metzger tweeting revolution social media use euromaidan protests available tim chant inevitability predicting future available till krause hannes grassegger süddeutsche zeitung inside facebook available marietje schaake tube took video available council europe study algorithms human rights guardian programs exhibit racial gender biases research reveals available biases guardian algorithms rule working lives available laurel eckhouse big data may reinforcing racial bias crim inal justice system available propublica machine bias available hannes grassegger mikael krogerus data turned world upside available alessandro bessi emilio ferrara social bots distort residential election online discussion first monday volume number november available guardian angela merkel internet search engines perception available miscellaneous unesco world trends freedom expression media development publication available intelligence security committee parliament report privacy security modern transparent legal framework march availabl communication commission european parliament european council council del ivering european agenda security fight terrorism pave way towards effective genuine security union available report special rapporteur promotion protection right freedom opinion expression david kaye thirty session human rights council joint opinion venice commission directorate information society action crime directorate human rights dhr directorate general human rights rule law dgi council europe draft law amending completing moldovan legislation mandate security adopted venice commission plenary session venice march human rights council resolution right privacy digital age doc mar human rights robot age challenges arising use robotics artificial intelligence virtual augmented reality report rathenau institut commissioned funded parliamentary assembly council europe adopted pace april
