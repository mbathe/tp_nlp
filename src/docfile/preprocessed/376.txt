part part part table contents behind codes data practical guide ethical part part part table contentscontents practical guide ethical sommaire initative editorial partners guide use part framework pointers stake ethical exactly talking bibliography part practical recommendations governance highest level company assessing ethical risks project ethical sensitivity matrix good practices principle life cycle solution respectful controlled measured use personal data confidentiality personal data unbiased preventing risks discrimination diversity design teams accessibility systems des systèmes transparent explainability results traceability processes data fair disclosure reliability results controlled operation human control reliable robustness resilience part use cases examples use case example project acknowledgments practical guide ethical part part part table contentsthe initative ambition numeum partners translate general ethical principles based existing work practical methods collective intelligence workshops involving participants conducted november december allowed gather contributors proposals recommendations topic identified work consolidated formalised period january april supervision review committee made academic partners different professionals important note reflection deliberately focused simple systems making easier project onto concrete application cases complex systems involving fully automated processes autonomous vehicles robots operating without human intervention excluded work practical guide officially presented public authorities also forms basis manifesto ethical find information website dedicated ethical initiative document completed regularly updated keep technological developments new requirements regulatory societal economic initative practical guide ethical part part part table contentsbringing unprecedented progress kinds areas articifical intelligence spreading daily lives phenomenal expansion raises legitimate question trust humans put answer question solutions developed must respect fundamental rights defended particular france european union fulfil promise therefore ethical one essential conditions bring benefits promises many people possible comes putting theory practice task easy determination put moving technology forward specialists mobilised devise operational framework creation dissemination ethical systems numeum formed network partners different worlds academia public authorities companies voluntary sector civil society numerous exchanges sharing experience culminated creation practical guide proposes useful method implementing main ethical principles designing developing deploying guide therefore constitutes voluntary code conduct developing thetrustworthy systems encouraged european commission thanks credibility partners backing initiative believe potential become accepted baseline france beyond initiative give tangible ethical credentials enhances approach developing accountable digital world constitutes key step anticipation preparation compliance future general regulation recently proposed european commission renaud vedel coordinator france national strategy katya lainé director chair numeum artificial intelligence committeeno responsible digital technology without ethical aieditorial see practical guide ethical part part part table contentspartners laurence devillers professor institut dataia magali barnoin digital data facilitator telecom valley charles bouveyron director institut côte azur antoine trotet head digital revolution department grand est regional authority roxana rugina general secretary impact gaëlle pinson general manager hub france sophie viger general manager école nicolas viallet chief operating officer aniti university toulousepartners tawhid chtioui founding president dean aivancity alexis steiner digital project manager grand clic picture launch associated video practical guide ethical part part part table contentsguide use part part contains definitions background initiative part part describes methodology form practical recommendations put practice three setting governance system within company assessment ethical risks involved project identification areas efforts concentrated using ethical sensitivity matrix measure project sensitivity ethical issues application recommendations based areas chosen focus stage life cycle partie part contains examples projects use cases illustrate implementation use guide practical guide ethical part table contents part part part part table contents part part framework pointers stake ethical exactly talking bibliography framework pointers part table contents part part part notes framework pointers part table contents part part part amazon recruiting tool found discriminate women microsoft tay chatbot started spout insults uber car responsible fatal accidentai promises much help meet great societal environmental challenges ahead optimise way companies operate take strain discomfort certain activities customers make diagnoses faster better make daily lives easier etc yet technologies especially recent ones known deep learning raising questions among public aura mystery shrouds probably something excesses systems physical injuries caused exacerbated mistrust among users asking whether designers systems able control stake framework pointers part table contents part part part stake avoid wariness turning systematic massive rejection would obliterate potential benefits technologies stroke urgently need rethink way design solutions want systems effective also ethical say designed operated way ensure use effects harm either dignity integrity human beings must also respect fundamental ethical values right privacy fair treatment freedom act make professionals whose jobs consist designing developing operating decommissioning solutions first concerned issues numeum partners proposing practical guide detailing methodology creating systems compliant ethical values able meet society expectations price build rebuild trust technologies one condition indispensable widespread use framework pointers part table contents part part part legislation always keep pace technological change sometimes correspond ethical standards simply prove inappropriate faced certain trustworthy systems also ethical care taken align ethical guidelines ethics trustworthy gehn exactl talking system qualified ethical able preserve fundamental human rights throughout life cycle right dignity mental physical integrity freedom autonomy equal treatment intimacy privacy rights theory protected current french european laws regulations gdpr governs protection personal data system whether claims ethical course abide law illegal unable access market must technology progressing faster law nature systems emerging especially using deep learning technologies considerable impact lives producing high concentration risks ethical point view discrimination dehumanisation social relations opaque deduction processes abusive use personal data errors caused cyber attacks etc risks taken consideration seriously inevitably occur resolve contradictions performance objectives ethical situation therefore calls specific measures precautions avoid deliberate unintended abuses excesses end day humans alone accountable systems create framework pointers part table contents part part part analysing number different texts see bibliography numeum endeavoured characterise ethical number principles qualities must possess system qualified ethical respectful personal data unbiased endeavours create reproduce discrimination favours transparent operation conclusions explained fair relations human beings expected discloses controlled remains control reliable secure robust face cyber qualities reflects certain number requirements methodological guide meant put operational use describes requirements proposes good practices meet company assess risks inherent systems ethical point view decide degree application measures recommended based risks purpose system nota bene furthermore make positive contribution society people purpose good subject addressed document aims list practical measures implemented create deploy ethical design irrespective system designed every person involved creation stepis accountable considering system impact everyday ethics artificial intelligence ibm reinforcement learning measures built based robots achieve outcome also robots align human values accomplish particular result ethics code exactl talking framework pointers part table contents part part part algorithmes contrôle des biais svp white paper published institut montaigne march montréal declaration responsible development artificial intelligence written multidisciplinary scientific team montréal process ofcitizen consultation ethically aligned design establishing standards ethical technology two papers published ieee everyday ethics artificial intelligence guide published ibm ethics guidelines trustworthy april assessment list trustworthy artificial intelligence altai july two texts issued independent expert group artificial intelligence set european commission responsable principes approches mise action guide issued microsoft building trust artificial intelligence communication european commission european parliament council european economic social committee committee regions com april contains guidelines mentioned responsible global policy framework proposed itechlaw rome call ethics pledge document vatican february bibliography provide framework initiative decide areas would work numeum started consulting corpus existing ethics charters reference publications framework pointers part table contents part part part ethics code developing business five core principles charter drawn publisher sage engagement collectif pour usage responsable charter drawn impact artificial intelligence european approach excellence trust white paper issued european commission com february regulation laying harmonised rules artificial intelligence artificial intelligence act first legal framework proposed european commission april partie sommaire partie partie framework pointers part table contents part part part part practical recommendations governance highest level company assessing ethical risks project ethical sensitivity matrix good practices principle life cycle solution respectful controlled measured use personal data confidentiality personal data unbiased preventing risks discrimination diversity design teams accessibility systems des systèmes transparent explainability results traceability processes data fair disclosure reliability results controlled operation human control reliable robustness resilience part sommaire part part practical recommendations part part part part table contentsyour notes practical recommendations part part part part table contentsai governance highest level company stakes involved ethical risks system high left company data scientists technical specialists subject often highly complex requires perspective especially start getting impact assessments may require decisions made highest level need draw skills project team may involve reputational legal risk company first recommendation guide set specific governance system highest level responsible defining applying company policy reflecting company ethical values complying regulations policy lay principles rest based set framework within projects developed set standardised project management processes methods intended secure treatment ethical issues governance system task defining method assessing ethical risks ensuring necessary impact assessments conducted depending projects role also consist arbitrating tensions performance ethical security issues establishing thresholds limits specifying criteria fairness explainability referred examining critical cases organisation scope governance vary one company another certain cases matters gdpr nis network information system security compliance could also part remit refer guide digne confiance guide trustworthy published impact set governance system company chapter also see chapter also assess governance see questionnaire sur gouvernance des algorithmes dans secteur financier questionnaire governance financial sector used acpr french prudential supervision resolution authority practical recommendations part part part part table contentsa things governance need raise awareness among project teams data specialists data scientists data analysts etc business specialists ethical challenges well regulatory issues establish principle data controller project company single point contact issues internally externally set process escalation ethical risk arises measure requires creation climate confidence within company relations partners anyone chain feels able raise alert example microsoft special communication channel alerting local ethics committee allows anyone spots ethics risk system development make heard example report conclusions system question could lead substantial service refused cause harm violate person rights governance thehighest level company practical recommendations part part part part table contentsassessing ethical risks project creating ethical design first foremost means designing system whose risk dangerous prejudicial consequences ethical level reduced minimum eliminated altogether project assessment ethical risk essential analysis cover qualities described page associated requirements concern risks induced use case inherent technology linked context project assess risk terms likelihood severity compare purpose use case study must also take account general risks company business market main types risks assessed concerning use case major risk risk result system could cause individuals society environment risk result leading refusal limiting person access fundamental right refusal access essential service risk creating addiction locking person behaviour risk occurrence unforeseen potentially uncontrolled cases could detrimental human integrity dignity environment risk appear systems certain degree autonomy risk discrimination etc concerning system main risks risk current data protection regulations gdpr europe certain data turn personal data eyes cnil even though seem directly identify person address risk cyber attacks leading disclosure personal information purpose diversion risk opacity decision path system risk linked absence traceability prevents correction system identification responsibilities etc concerning context project main risk risk linked failure governance company risk teams company misconstruing actually stake risk lack correction repair process risk absence leads resource persons etc practical recommendations part part part part table contentsthe results assessment serve orient reflections decide measures taken reduce risk allow define among things threshold human intervention becomes necessary comprehensive risk assessment tool ethics algorithms toolkit produced american team targets use public sector ethical sensitivity matrix presented guide provides interpretative framework recommendations listed pages follow intended help developers orient efforts based sensitivity systems ethical extra toolkits questionnaires used tangibly measure ethical impact system ethics guidelines maif included melusine automatic email classification project référentiel évaluation maturité une organisation framework assessing organisation maturity substra foundation assessment list trustworthy artificial intelligence altai questionnaire independent expert group artificial intelligence set european commission box ethics lab used gauge based different criteria strengths weaknesses system ethical point view read conjunction article operationalizing ethics principles responsible toolkit evaluation toolkit offered pwc artificial intelligence impact assessment comprehensive guide independent dutch platform ethical risks project practical recommendations part part part part table contentsethical subjects consider specifically data protection bias transparency fairness control reliability system purpose implementation framework applies project confidentiality personal data controlled measured use personal data prevention risks discrimination diversity project team accessibility solution explainability model results traceability data processes reliability results disclosure operation human control robustness resilience solution business needthe system automates decision helps make decision concerning physical persons system automates performance tasks system destined deployed large within organisation general system destined deployed new system interacts directly end user ethical sensitivity matrix practical recommendations part part part part table contentsethical subjects consider specifically data protection bias transparency fairness control reliability system purpose implementation framework applies project confidentiality personal data controlled measured use personal data prevention risks discrimination diversity project team accessibility solution explainability model results traceability data processes reliability results disclosure operation human control robustness resilience solutionthe technical solutionthe system embedded larger system training system requires large volume data training system requires use sensitive personal data system requires machine learning datasets public system draws single source build machine learning machine learning dataset built different heterogeneous databases terms quality quantity etc system uses technologies nature liable system uses technology bricks system processes sensitive data personal data confidential data etc system processes sensitive data personal data confidential data etc practical recommendations part part part part table contentsethical subjects consider specifically data protection bias transparency fairness control reliability system purpose implementation framework applies project confidentiality personal data controlled measured use personal data prevention risks discrimination diversity project team accessibility solution explainability model results traceability data processes reliability results disclosure operation human control robustness resilience solutionproject governancethe project team refer body charge ethics project team refer set project governance project team lacks diversity gender origin culture business etc project team made aware cybersecurity issues linked particular data poisoning adversarial attacks etc project team made aware ethical certain actors system creation chain external practical recommendations part part part part table contents practical recommendations part part part part table contentsgood practices principle part describes good practices ensure meet requirements details implementation every step life cycle system ethical respectful fundamental human rights reliablerespectful transparent unbiased faircontrolledrobustness resiliencecontrolled measured use personal datadata conﬁdentiality preventing risks discrimination accessibility systems explainability results model traceability data processes disclosurereliability resultsoperation human controldiversity indesign teams practical recommendations part part part part table contentslife cycle solution understanding need phase members project team data scientists particular apprised subject framework project principal moment ethical issues broached different risks criteria thresholds defined design iterative cycle data scientists build different datasets necessary machine learning testing prepare test model development step consists integrating model environment developing complementary modules bolt onto module interfaces phase generally requires computing skills production system operational monitored updated end life need design produc tion development practical recommendations part part part part table contentsrespectful examples requirements definition constitutes personal data varies one region world another applies regulations protection data company designing system must obviously comply regulations force country operating european union regulation applied gdpr rests principles must guide design implementation systems personal data used precise specified purpose system collects personal data strictly necessary storage time personal data reasonable decommissioning planned confidentiality security mechanisms protect data data subjects access modify erase data move one processing operation another system must also respect privacy intimacy individuals must use data produced without data subjects knowledge systems must guarantee respect privacy data protection throughout entire life cycle system covers information initially provided user well information generated user course interactions system results generated system specific users way users responded specific recommendations guidelines ethics trustworthy gehn practical recommendations part part part part table contentscontrolled measured use personal data respectful feeding huge quantities data systems operate machine learning exacerbate risks abuse concerning personal data defy principles existing data protection regulations like gdpr based developer compliance principles therefore raises whole series questions balance struck strictly necessary data performance purpose mean experimental process path tread retaining data track erasing etc ideas solutions understanding need incite actors project minimise use personal data ideally without altogether however personal data necessary time solution life cycle define legal basis collection processing personal data obligation gdpr reminder legal bases allowed gdpr source cnil consent data subject consented processing data contract processing necessary performance preparation contract data subject obligation processing required law practical recommendations part part part part table contents respectful public interest task processing necessary performance task carried public interest legitimate interest processing necessary purposes legitimate interests pursued organisation processing data third party whilst strictly respecting rights interests person whose data processed protection vital interests processing necessary order protect vital interests data subject third party carry privacy impact assessment pia assess impact processing data certain use cases example health data constant surveillance persons personalisation targeting tools etc involved pia obligation gdpr cnil provides tool purpose carry assessment privacy impact loss alteration unauthorised disclosure data handled even personal data practical recommendations part part part part table contents respectful design generally control sources test machine learning data avoid breaching obligation process data lawfully regulatory constraints gdpr example avoid web scraping consists collecting data less randomly without applying vigilance minimise possible eliminate use personal data using synthetic data early possible development process measure especially useful provider involved development system needs access data use personal data unavoidable development test phases collect process according chosen legal basis gdpr requirement make sure treated confidential see different possible approaches set access control systems monitor system production via logging feature prevent diversion data purposes developers gdpr requirement document different measures taken comply gdpr particular justify use personal data design development process purpose application gdpr accountability requirement see tool datasheets datasets note retention data used design model machine learning tests may necessary tracing purposes accountability possible condition however virtue principle data storage period gdpr justifying storage data providing information duration limiting storage strictly length time necessary achieve purpose implies planning decommissioning idea create multiple profiles corresponding different training datasets adapt user requirements system production approach requires technical economic feasibility study practical recommendations part part part part table contents development plan possibility ending collection data time user requests idea stop collect button would mean ready offer limited service user similar currently happens refuse cookies website caution however refusal data collection leads refusing restricting access essential service fundamental right need provide alternative allow user access service question develop clear interfaces describing use made personal data allowing user data time production control models deployed check regularly depending sensitivity system risks initial purpose still compliant measures taken respect personal data still gdpr requires checks made one year consistency check prevent reuse models purposes developers avoid purpose diversion gdpr requirement setting access control systems monitoring system production via logging feature see section resilience put place process alerting data controller requirements met respectful practical recommendations part part part part table contentsconfidentiality personal data respect data confidentiality requires setting security systems prevent unauthorised access databases see section resilience also involve using techniques preventing individual traced personal data several possible solutions taken individually however none totally foolproof furthermore use tend reduce system performance also noted cases possibility persons model issued conclusions may prove necessary algorithms applied personalised medicine often best solution combine several approaches giving weight one according purpose application performance solutions design combination methods keep datasets confidential anonymisation several techniques choose choice depend purpose use case characteristics datasets basic techniques enough make possible data subjects information databases sophisticated methods tried differential privacy consists adding noise around data points collected order drown another technique known avatar anonymisation used wedata company recently approved cnil pseudonymisation methods consist replacing directly identifying data dataset surname first name etc indirectly identifying data aliases sequential numbers also possible envisage collecting less precise data age group rather exact age postcode instead full address respectful practical recommendations part part part part table distributed federated learning approaches aim reduce centralisation data keep close entity generates possible expose distributed learning algorithm accesses database remains located owner premises federated learning algorithm accesses distributed network databases collaborative operation see approach recommended substra foundation data encryption common approach projects confidential data pooled example would health data health data hub encrypted detail subject see methods described substra foundation also protect confidentiality models could inference reveal data used machine learning example carrying machine learning knowledge distillation added advantage compressing model measure effectiveness anonymisation analysing risk example using tools like arx risk analysis data anonymization tool protect datasets transferred partners using methods described document vulnerabilities techniques used overcome respectful practical recommendations part part part part table contents audit requirements personnal data processing activities involving guide méthodologique autorité espagnole protection des données pour évaluer conformité système rgpd rgpd développeur cnil difficulté technique anonymisation comment mal anonymiser ses données article publié sur medium par wavestone rapport sur les enjeux éthiques des algorithmes intelligence artificielle que peut trouver sur site éthique intelligence artificielle cnil subject partie sommaire partie partie practical recommendations part part part part table contentsunbiased examples requirements system must operate impartially particular must aim reinforce create discrimination due biases introduced training process algorithm must reflect diversity user population concerne must comply common standards accessibility foster diversity datasets used systems training operation distorted accidental historical bias omissions defective governance models persistence biases could source involuntary indirect discrimination guidelines ethics trustworthy gehn practical recommendations part part part part table contents unbiased preventing risks discrimination machine learning system include biases trained dataset biased risk case producing false discriminatory therefore prejudicial results hence requirement strive achieve unbiased systems nevertheless attempting find complete final solution issue amounts trying square circle start notion eminently comes different forms sometimes incompatible depending use case therefore necessary establish criteria whilst ensuring compatible ethical framework laid company attempt measure risks bias try get close optimum situation solutions understanding need conclusions system concern people carry analysis risks discrimination impact assessment see section risk assessment risk appears examine parameters variables could directly indirectly generate risk discriminatory bias cause drift model initially defined use possible contact specialists human scientists sociologists anthropologists etc contribute expertise help identify risks potential biases statisticians work structure machine learning datasets circumvent statistical pitfalls practical recommendations part part part part table contentsdesign building datasets idea make criterion success par performance order orient work keep issue top mind forward always make sure control datasets used machine learning testing ask come built know source distribution dataset data collected transformations undergone several construction possibilities create datasets calling upon experts field concerned use documented existing training datasets datasets representative extensive enough use different statistical techniques available make deficiency augmentation etc test use generative adversarial networks gans generate synthetic data envisage pooling data companies field national european level see voice data example model integrate constraints algorithm measuring correcting instrument test process facilitate implementation validate representativeness dataset using existing reference standards institutional open data test algorithm criteria initially defined approach defended institut montaigne white paper algorithmes contrôle des biais svp calls active fairness consists using datasets containing protected variables approach requires submitting impact assessment cnil make sure introduced new biases trying correct initial ones adjust machine learning algorithm necessary idea build algorithms processing bias bias using gans production plan continuously monitor drift using automated supervision systems appropriate metrics thresholds appoint single point contact users submit observations unbiased practical recommendations part part part part table contents unbiased aim diversity requirement help project teams consider risks bias products best conditions keeping open mind possible also tends encourage teams embody ethical values products ideas solutions foster diversity teams gender culture background work recruit inclusive educational design teams practical recommendations part part part part table contents équitable accessibility systems des systèmes real potential facilitating access digital world disabled experienced difficulties digital technology beyond regulatory accessibility functions graphical user interface must equipping systems interact humans image recognition text analysis technologies example would also facilitate accessibility inclusiveness solutions design comply regulatory obligations graphical user interface accessibility use référentiel général amélioration accessibilité rgaa french standard improvement accessibility practical recommendations part part part part table contents algorithmes biais discrimination équité white paper produced patrice bertail david bounie stephan clémençon patrick waelbroeck télécoms paristech february lgorithmes contrôle des biais svp white paper published institut montaigne march unfair biases machine learning obliterate article origin discriminatory biases machine learning algorithms overcome paul irolla security tutorial fairness machine learning atechnical post ziyuan zhong towards data science subject partie sommaire partie partie practical recommendations part part part part table contents individuals must able understand systems make decisions especially impact daily notre approche responsable fiable examples requirements causes criteria lead conclusions must able made known users people affected concerned conclusion explanations must intelligible order shed light final decision act input data process system must documented description data collection labelling algorithm used business model etc purposes verification audit tool process collecting storing using data must also documented line gdpr different effect ethical requirements must justified practical recommendations part part part part table contents transparent explainability resul system ability make impact variable result explicit generally comprehension processing carried system decisive factors acceptance society sometimes also compliance security requirement cnil requires information provided least data used arrive result gdpr requires explanation whether personal data involved result unfortunately systems currently perform highest level turn soon substantial quantities data begin processed opaque yet solutions resolve question implemented many research projects underway area bear fruit pistes solutions understanding need estimate need degree explainability required depending use case purpose product problem less acute according use case example likely give less importance explainability book recommendation service site rating algorithm granting bank loans yet quite possible service might want set apart backing recommendations explanation based ethical goal combating intellectual clearly need explainability work relevant experts define made accuracy results transparency many cases least outset use naturally explainable less precise algorithm enough meet need envisage hybrid systems embed less opaque machine learning algorithms algorithms based perfectly interpretable rules question explainability raised regular intervals throughout design development process results improve practical recommendations part part part part table contentsdesign necessary use complex algorithm naturally explainable look explainability methods lime shap choice approach depend use case target explanation customer consumer end user want explanation based precise variables corresponding specific context system must provide local explanation lime anchor professional want understand model whole expect global explanation view improving shap regulator supervisor want proof need global explanation shap test different explainability approaches draw common conclusions document different approaches tested record different results draw common use graphic tools allow visualise dominant criteria tool like shapash designed maif insurance company makes results provided common explainability tools lime shap etc accessible transparent practical recommendations part part part part table contents transparent traceability processes data tracking datasets design processes methods used different versions model prerequisite able check absence bias purpose reliability systems means documenting everything connected system noted fact amounts nothing nothing less applying quality approach common practice areas solutions design development document machine learning phase data used sources transformation parameters hyperparameters algorithm versions etc could take inspiration google model card sort card model could use datasheets datasets method suggested team researchers developed different performance explainability confidentiality security people involved constructing system roles set reference base store information idea create family tree system along lines model developed substra foundation practical recommendations part part part part table contentsproduction continue documenting data behaviours system operation set logging system record contexts results obtained algorithm version model parameters hyperparameters dataset bearing mind system quickly get extremely complex system continually learning example versioning tool version control system machine learning projects plan conditions storage information logs contain personal sensitive data storage time purpose specified security measures taken access rights granted etc see respectful section noted certain cases strict application gdpr comes serious operational difficulties example application cybersecurity system records thousands addresses minute may considered personal data cnil transparent practical recommendations part part part part table contents interpretable machine learning make black box models explainable regularly updated guide christoph molnar datasheets datasets guide tracking datasets produced team researchers google actually timnit gebru microsoft different universities subject transparente maîtrisée transparente équitable partie sommaire partie partie practical recommendations part part part part table contentsexamples requirements user must unambiguously understand interacting machine area intervention well limits capacities system must made known person going use user must aware whether system involved result calculation could decisive orient decision concerning make system must expected person must aware interacting rome call practical recommendations part part part part table contentsdisclosure system ability disclose say reveal key factor establishing users trust reducing risks abuse ignorance issue concerns systems interact directly chatbots indirectly system embedded tool humans nonetheless noted system says much exposed inference solutions understanding need ensure stakeholders project informed issues linked disclosure system provide information communicated areas channels communication user defined design set system method inform user dealing system example case chatbot inform human outset interacting robot design interface sufficiently explicit avoid ambiguity avoiding using human avatar generally provide summary easily read understood user informing fact system involved solution used type work area intervention objectives limits potential margin error conditions must used risks involved using applicable use made system personal data asked gdpr purpose requirements see section controlled measured use personal data fair practical recommendations part part part part table contentsreliability resul subject goes disclosure system reveals system deemed fair reliable says issue one complicated deal nature systems operating machine learning guarantee reproducibility result even less continually learning complex systems handling large number parameters one problems arises impossibility able test therefore validate possible cases ideas solutions understanding need establish binding rules limits exceeded regard results risk impact assessments carried earlier design write detailed set specifications system specify results expected provide least partial proof reliability model code make compromises simplicity performance better control reliability results prefer documented open source academic codes bearing mind though brings risk becoming target cyber attackers also access code idea pair systems voting methods smooth errors training test datasets use documented training datasets audit sets particular assess representativeness data tracking tracing see traceability section document everything sources data processing data model algorithm training methods create model develop time fair practical recommendations part part part part table contentsdevelopment results systems checked business experts guarantee reliability results automate tests standardise make easier perform test possibilities system possible whether possible implement measure course depend complexity use case envisage using gans generate test data necessary production establish test behaviour checking protocols throughout entire service life system ensure drift viability tests fair practical recommendations part part part part table contents loyale reproducible operations commitment principle pages website british institute ethical machine learning reliability machine learning systems site comprehensive covers ethical issues around machine learning guidelines development responsible conversational subject loyale maîtrisée transparente équitable part part part table contents practical recommendations part part part part table contents practical recommendations part part part part table contents human beings held responsible decisions stemming recommendations made ais actions proceed montréal declaration areas decision affects person life quality life reputation must made time circumstance permit final decision must taken human decision free montréal examples requirements user system made aware recommendations made must still able make autonomous decisions personal choices system conclusion lead decision affects one persons final decision must rest one person human must able decide use believe ethical security conditions met system must allow person contest report anomaly practical recommendations part part part part table contents controlled operation human control risk dehumanisation societies loss autonomy individual issues around accountability human must remain solely accountable actions decisions system reasons behind requirements many varied providing contact button restricting amount automation system measures taken depend use case ideas solutions design results consequences humans keep automation minimum system must remain aid development systems aimed general public provide possibility adjusting parameters data model concern user interactive way real time set system enabling user validate parameters time use certain contexts involving general public particular field public services inform user part system disclosure requirement provide possibility user choosing use element rgpd practical recommendations part part part part table contents maîtrisée production create contact button allowing user interact transfer information lodge appeal set internal process allowing users appeals feedback dealt idea show user scores final result approach supposes user learn functioning system practical recommendations part part part part table contents maîtrisée transparente fully automated decision making systems right human intervention safeguard methodological guide consulted auditing framework website british data protection subject équitable partie sommaire partie partie practical recommendations part part part part table contents systems environments operate must safe secure must technically robust care must taken ensure exposed malicious use guidelines trustworthy gehn example requirement system must include mechanisms allowing protect risks wrongdoing identified risk impact assessments protect cyber attacks purpose diversion data theft block correct effects attacks malicious actions practical recommendations part part part part table contentsrobustness resilience like computer system systems concerned cybercrime must therefore protected rules principles systems information system also subject certain specific cyber threats data poisoning attacker seeks skew behaviour model modifying learning data continually learning systems particularly exposed type attack evasion attacker tampers imperceptibly application inputs deceive system induce decision different one normally expected panda systems processing complex input data images particularly sensitive type attack inference attacker bombards system queries understand works grasp key parameters aim imitating system systems disseminate lot information easily exposed type protect threats guarantee operation system without damaging integrity persons breaching ethical values first measure take irrespective projects consists raising data scientists data analysts awareness cybersecurity issues unlike computer scientists population generally background mathematics statistics naturally less preoccupied matters see governance section ideas solutions design secure machine learning process reduce exposure data poisoning attacks control sources machine learning data protect access access control accreditation systems reduce quantity data minimum especially sensitive data necessary machine learning use synthetic data possible reliable practical recommendations part part part part table contents reliable apply techniques reinforce confidentiality sensitive data anonymisation techniques using differential privacy pseudonymisation distributed federated learning see data confidentiality section continually monitor progress learning changes behaviour models put safeguards place chatbot create blacklist terms block input output apply practices like roni reject negative impact consist rejecting data causes drift model reinforce robustness models reduce sensitivity different types attack particular inference evasion attacks different techniques exist knowledge distillation adversarial learning noise addition input data etc applied according level precision want achieve reduce minimum information could reveal model works score precision etc reduce inference attacks measure applied according level disclosure deemed test set automated processes tools ibm art toolkit code alteration approach production monitor set process log monitoring particular check drift results regularly business experts check behaviours results create contact button user alert data controller idea create bug bounty platform practical recommendations part part part part table contents artificial intelligence cybersecurity white paper wavestone subject partie sommaire partie partie recommandations pratiques part part part part table contents part use cases examples use case example project acknowledgments part part part table contents use cases examples part part part part table contentsyour notes use cases examples part part part part table use case designing implementing recommendation algorithm site selling cultural goods online potential customer prospect goes onto site selling cultural browse catalogue products offer find looking site recommends products browsing ethical risks identified examples specific issues company address discrimination according customer standard etc enclosed personal bubble personalised content influenced interface use customer unconscious biases influence purchases nudge description use case aims regarding user enrich customer experience personalising content presented thwem meet needs without distorting selection submitted way limit choice purposes company using system increase sales maximise conversion rate optimise average basket howby turning prospect customer achieving effective purchase therefore necessary offer product corresponds best actually looking terms product price access etc actions takenoptimisation presentation product level product description photos similar complementary products solution adopted type recommended usedcollaborative filtering proximity product type association model association products buying act concerned understanding need stage product marketing distributors product producers design stage data scientists data engineer designer development stage developer deployment stage supervisor testers use cases examples part part part part table contentssystem purpose implementation frameworkapplicable project business needthe system automates decision helps make decision concerning physical persons yes system automates performance tasks user system destined deployed large scale within organisation general public yes system destined deployed new market system interacts directly end user yes technical solutionthe system embedded larger system yes training system requires large volume data yes training system requires use sensitive personal data system requires machine learning datasets public databases system draws single source build machine learning datasets machine learning dataset built different heterogeneous databases terms quality quantity etc yes system uses technologies nature liable system uses technology bricks yes system processes sensitive data personal data confidential data etc system constantly learning yes governance projectthe project team refer body charge ethics subjects yes project team refer set project governance rules yes project team lacks diversity gender origin culture business etc yes project team made aware cybersecurity issues linked particular data poisoning adversarial attacks etc project team made aware ethical issues yes certain actors system creation chain external partners yesassessment solution sensitivity ethical issues based ethical sensitivity matrix use cases examples part part part part table contentssubjects address according ethical sensitivity matrix ideas solutions identified subject addressed ethical subjects consider specificall respectconfidentiality personal data controlled measured use personal data unbiasedprevention risks discrimination diversity project team accessibility solution transparencyexplainability model results traceability data processes fairnessreliability results disclosure control operation human control reliability robustness resilience solutionaction design pseudonymisation personal data setting secure access data list features inputs algorithms work customer identifier data considered sensitive within meaning gdpr design two separate data processing operations learning use model development validation data relevant operation final minimisation design introduction random data deliberate diversity recommendation development diversity test team test roles design design accessibility audiences outset design need transparency tester customer deployment propose different parameter settings user relevance dates etc design development creation data catalogue project documentation cdm data input process etc guarantee traceability governance tool design definition objective metrics development measurement initiation monitoring deployment performance monitoring transfer alerts design development provide alert message end user deployment supervision chain monitoring user feedback loop via customer relationship design define metrics deployment set monitoring alert handling processes regular backtesting models use cases examples part part part part table contents use cases examples part part part part table contentsexample project certain artificial intelligence development scenarios require particular precautions use typical example case would critical projects operates real time without human intervention leading risk damage customer reputation material damage even injury persons system drift course another scenario requires particular precautions arises team charge integrating model team created potentially lead communication problems risk higher particular open source world projects comprising separate operational units deal issues strict control concerning learning use artificial intelligence models also use standardised organisation form model cards developed research teams google whose aim document model succinctly comprehensively model card takes form summary twenty lines bit like readmes come software containing following information details model particular identity developers publication date parameters model version licence use cases planned nominal conditions use characteristics datasets used machine learning characteristics model datasets used assessment ethical considerations warnings recommendations adopting standard means common template documentation artificial intelligence system thereby allowing transmission maximum information engineers developers ensure models used result reduces risk unforeseen behaviour associated automated systems mathis hammelhead cybersecurity sogeti groupe capgemini implementation traceability system use cases examples part part part part table contents practical guide ethical part part part table contents committee céline bayle sage bénédicte linares bdl conseil valentin hueber numeum katya lainé kwalys astek mentors coordinators magali barnoin telecom valley benoît bouffard wavestone marine brogli dpo consulting david cortes laurence devillers sorbonne sébastien jardin ibm france mouchira labidi freelance charlotte lischer catalix alice louis cabinet dicé mainguy seenapsys fabrice marque zebravalley emmanuel nars docaposte vincent perrin ibm france françoise soulié hub france florence tressols ibm france félicien vallet cnil pouvoirs publics renaud vedel nicolas amar martin bieri cnil contributors sonia abecassis ibm france cindy accolas grand enov didier aït optim ease marianne allanic althenas aziz amal astek nadia anglessy netsystem solutions nicolas andréa arzotto leadin marion balac esam franck bardol diag renaud bauvin criteo julie bec air france klm group jérôme beranger adeliaa numeum partners warmly thank took part practical guide ethical part part part table gwenaëlle bodilis dpo system marina boechat mydatamodels eric boniface substra foundation guillaume buffet change carpentier gfii pierre charara tessi lucas charron sportintech edouard choplain tawhid chtioui aivancity eugénie clément occitanie data sophie compagnon critéo conan keyrus nathalie costa ysance rébecca dadi dpo consulting guillaume roche renault nathalie delbecq renault paul desigaud wavestone alix fauques jonquieres aniti sébastien foret grand enov mickaël gadoud wavestone mithuran gajendran wavestone nicolas georgeault asi guillaume gimonnet wavestone emmanuel goffi institut sapiens amélie heliou criteo laëtitia kameni accenture françois klieber bouygues construction djémila kohil lpce biobank côte azur bradreddine ladjemi ankaboot pascal lainé kwalys yanelle laribi impact yann biannic sap fabrice guel ritm frédéric leblan outscale xavier leclerc dpms bertrand lejeune cap digital simon leroy keyrus clément lombard wavestone daphné marnat twisting laura marti bouygues construction maud marquis mio didier mascarelli kadlog clément mayer substra foundation igor mekhov consort stéphan mir wavestone assia mouloudi sap claire nicodeme sncf bernard ourghanlian microsoft acknowledgments guide pratique pour des éthiques part part part table pierre parrend epita alexandre pascault astek stéphane cnrs gaëlle docaposte estelle pinchezon human design group gaëlle pinson hub france marc platini grand enov timothée raymond linedata bernardo resende thales services sas bettina reveyron impact caroline richard natixis laurent risser aniti céline rodap ecole roxana rugina impact laura sarriot kiloutou céline tessi anthéa serafin occitanie data emilie orange camille souillart hub france thomas souverain dreamquark alexis steiner grand enov aurélia szymanski linedata lucien tanghe assuractis sarl eric tordjeman inria institut dataia stéphanie toussaint grand enov david keyrus laura velasco avisbal laboratoires servier eric vessier oracle france richard vidal accenture clément vidon société civile coline yvergniaux devoteam acknowledgments guide pratique pour des éthiques part table contents part part part led supported haussmann paris france contact numeum
