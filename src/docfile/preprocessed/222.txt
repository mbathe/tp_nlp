fra focus recognition technology fundamental rights considerations context law enforcementhelping make fundamental rights reality everyone european union fra focus facial recognition technology frt makes possible compare digital facial images determine whether person comparing footage obtained video cameras cctv images databases referred live facial recognition technology examples national law enforcement authorities using technology sparse several testing potential paper therefore looks fundamental rights implications relying live frt focusing use law enforcement purposes law recognises sensitive data people facial images form biometric data images also quite easy capture public places although accuracy matches improving risk errors remains real particularly certain minority groups moreover people whose images captured processed might know happening challenge possible misuses paper outlines analyses fundamental rights challenges triggered public authorities deploy live frt law enforcement purposes also briefly presents steps take help avoid rights violations contents facial recognition technology fundamental rights setting scene facial images unique biometric identifier law facial recognition technology accuracy facial recognition technology assessing risks wrong identification use facial recognition technology public authorities fundamental rights implications using live facial recognition gen eral oints fundamental rights affected conclusions facial recognition technology fundamental rights considerations context law enforcement facial recognition technology fundamental rights setting scene focus paper explores fundamental rights impli cations taken account developing deploying using regulating facial recognition technologies draws recent analy ses data section section evidence interviews conducted experts rep resentatives national authorities test ing facial recognition technologies section last sections section section provide brief legal analysis summarising applicable euro pean union council europe law paper forms part fra larger research pro ject artificial intelligence big data fundamen tal first paper focus uses facial recognition technology builds agency extensive past work fundamental rights implications use biometric data information systems field migration asylum facial recognition technology frt allows auto matic identification individual matching two faces digital images detecting measuring various facial features extracting image second step comparing features taken private sector facial recognition technology widely used advertisement marketing purposes individual customers profiled identified predict preferences towards fra carried eleven interviews march may member states germany france united kingdom gain better insight current testing potential use facial recognition technology following published far part research project fra bigdata discrimination datasupported decision making luxembourg publications office may fra data quality artificial intelligence mitigating bias error protect fundamental rights luxembourg publications office june project consult fra webpage project see example fra watchful eyes biometrics systems fundamental rights luxembourg publications office march fra interoperability fundamental rights implications opinion european union agency fundamental rights fra opinion interoperability vienna april detail facial recognition technology works see introna nissenbaum facial recognition technology survey policy implementation issues lancaster university management school working paper products based facial examples private sector include foot ball club using stadium identify peo ple banned attending club matches using facial recognition technol ogy analyse facial expressions job candidates interviews major internet social media companies facebook deploying facial rec ognition technologies improve systems tagging recent evolution artificial intelligence powered facial recognition technology attrac tive private sector also opens new possibilities public administration including law enforcement border management consid erable increase accuracy achieved past years prompted many public authorities private businesses start using testing planning use facial recognition technologies across world turn sparked intense debate potential impact fundamental rights exam ple use facial recognition tech nology combination surveillance cameras people republic china led many discussions concerns potential human rights violations particularly respect detect ing members certain ethnic follow ing increased use facial recognition national survey published september pew research centre finds slightly every second american trusts law enforcement agencies use technologies responsibly smaller shares public say see example italy garante per protezione dei dati personali installazione apparati promozionali del tipo digital signage definiti anche totem presso una stazione ferroviaria december see edri danish dpa approves automated facial recognition june see telegraph used first time job interviews find best applicants september see wired facebook find face even tagged december human rights council surveillance human rights report special rapporteur promotion protection right freedom opinion expression david kaye new york times one month face scans china using profile minority april fra focus trust technology companies advertisers number european countries facial recogni tion technologies tested used differ ent contexts private public spheres paper examines specific aspect comparing foot age obtained video cameras cctv databases facial images watchlist lawenforcement purposes often referred live facial recognition tech nology specific form video surveillance analyses fundamental rights implica tions lacking date examples national law enforcement authorities using live facial recogni tion technology europe defining law enforcement authorities term law enforcement authorities refers member state agencies encompass com petent authorities purposes pre vention investigation detection prosecu tion criminal offences execution criminal penalties including safeguarding prevention threats pub lic security source law enforcement directive article united kingdom tested facial recognition technology identify people real time using street cameras european union member states engaged testing made plans using facial recognition technology example hungary project called szitakötő dragonfly plans deploy cameras facial recogni tion capabilities budapest across country cameras capture drivers license plates facial images maintaining public order including road czech government approved plan expand use facial recognition cam eras prague international police germany france car ried extensive testing sweden data protection pew research center half adults trust law enforcement use facial recognition responsibly see hungary today cctv big brother eye providence january multiple legal primarily data concerns raised hungarian data protection authority connection project see letter available authority website see expanded use facial recognition prague international airport approved march authority recently authorised use facial recognition technology police help identify criminal suspects allows police compare facial images cctv footage watchlist containing processing facial images expected introduced systematically systems used asylum migration security outlined section systems process facial images future necessary legal technical steps completed images taken controlled environments example police stations points quality images higher compared cctv cameras fra already pointed fundamental rights risks processing facial images systems earlier despite strong push private industry stakeholders use facial recognition technol ogy strong opposition emerged citing weak nesses led example world largest corporate supplier police body cameras axon announce year would deploy facial recognition technology prod ucts unreliable law enforce ment work could exacerbate existing inequi ties policing example penalising black lgbtq communities similar vein city san francisco united states among cit ies banned use technology excessively intrusive nature people pri vacy avoid possible abuse law enforce ment backdrop number questions arise fundamental rights perspective technology appropriate law enforcement border management use example used identify people wanted law see datainspektionen polisen får använda ansiktsigenkänning för att utreda brott october neweurope sweden authorises use facial recognition technology police october information see table fra interoperability fundamental rights implications opinion european union agency fundamental rights fra opinion interoperability vienna april fra revised visa information system fundamental rights implication opinion european union agency fundamental rights fra opinion vis vienna august fra watchful eyes biometrics systems fundamental rights luxembourg publications office march fra fundamental rights interoperability information systems borders security luxembourg publications office june crawford regulate technology nature august new york times san francisco bans facial recognition technology may facial recognition technology fundamental rights considerations context law enforcement fundamental rights affected technology deployed measures public authorities take guarantee rights violated risk errors matching faces fre quently raised fundamental rights concern ever fundamental rights concerns also stem weak position individuals whose facial images captured processed fundamental rights affected include among others human dig nity right respect private life pro tection personal data rights child elderly rights peo ple disabilities freedom assembly association freedom expression right good administration right effec tive remedy fair trial example facial recognition technology higher error rates used women peo ple colour producing biased results ultimately result discrimination use facial recognition technology also negative impact freedom assembly people fear facial recognition technology used identify chilling effect moreover possible implications within scope focus paper curtailing privacy processing large amounts personal data including particular individual faces may ultimately affect functioning democracy since privacy core value inherent liberal democratic pluralist society cornerstone enjoyment fundamental rights civil society private companies advocated clear regulatory framework facial recognition furthermore european commis sion expert group artificial intelli gence hleg specifically recommends pro portionate use facial recognition technology suggests application must clearly war ranted existing given growth fuelled increasing use artificial intelligence case law still virtually one recent exception adjudicated united kingdom judg ment final see example big brother watch face campaign may microsoft facial recognition time action december big brother watch supported several members parliament rights race equality technology organisations well technology academics experts lawyers published joint statement police private company use facial recognition surveillance september european commission independent expert group artificial intelligence ethics guidelines trustworthy april high court justice queens bench division divisional court cardiff queen otao bridges chief constable south wales police others ewch admin september fra focus facial images unique biometric identifier law people facial images constitute biometric data less unique changed easily hidden facial images also easy capture contrast biometric iden tifiers fingerprints dna person typi cally unable avoid facial image cap tured monitored public law regulates processing facial images data protection acquis table provides view relevant data protection instruments subject matter whether govern process ing facial images biometric data field police judicial cooperation criminal matters law enforcement directive directive relevant instrument establishes com prehensive system personal data protection context law law enforcement directive specifically refers facial images biom etric data used biometric matching purposes unique identification authentica tion natural sectorial instruments governing information systems field migration security listed table section complement data protection acquis biometric data defined personal data result ing specific technical processing relating physical physiological behavioural characteristics directive european parliament council april protection natural persons regard processing personal data competent authorities purposes prevention investigation detection prosecution criminal offences execution criminal penalties free movement data repealing council framework decision law enforcement directive gdpr recital see fra council europe edps handbook european data protection law edition luxembourg publications office june chapter law enforcement directive art see also regulation european parliament council april protection natural persons regard processing personal data free movement data repealing directive general data protection regulation gdpr art well regulation european parliament council october protection natural persons regard processing personal data union institutions bodies offices agencies free movement data repealing regulation decision art natural person allow confirm unique identification natural person facial images dactyloscopic fingerprint data protection law recognises two categories infor mation biometric data characteristics pertain bodily characteris tics facial features fingerprints retina iris characteristics behavioural characteris tics like deeply ingrained habits actions personal ity traits addictions includes behavioural characteristics could permit unique identifi cation person signature way walking moving digital facial images belong first category recital gdpr makes distinction legal nature simple photographs biom etric facial images definition biometric data applies photographs processed specific technical means allowing unique identification authentication natural special categories personal data ersonal data revealing racial ethnic ori gin political opinions religious philosophical beliefs trade union membership pro cessing genetic data biometric data purpose uniquely identifying natural per son data concerning health data concerning natural person sex life sexual source law enforcement directive article gdpr article regulation article due sensitive nature facial images fall special categories personal data sensi tive data data protection law provides enhanced protection additional safeguards compared personal law enforcement directive art gdpr art regulation art article data protection working party opinion developments biometric technologies brussels april misra face recognition tech gdpr compliant october gdpr recital see also regulation recital see fra council europe edps handbook european data protection law edition luxembourg publications office june facial recognition technology fundamental rights considerations context law enforcement law instruments data protection provisions facial images applicability legal instrument data protectiondefinition biometric data including facial image personal scope material scope law enforcement directive dir yes art member states law enforcement authoritiesautomated processing personal data schengen member states processing personal data means form part filing system prevention investigation detection prosecution criminal offences within scope law general data protection regulation reg yes art private actors established public institutions operating well controllers processors established offer services data subjects euautomated processing personal data european economic area processing personal data means form part filing system within scope law gdpr applicable national data processing data protection regulation institutions bodies agencies reg yes art institutions bodies agenciespersonal data processing institutions bodies agencies directive privacy electronic communications dir amended dir individual whose personal data processed electronic communication sector via internet telephony via accompanying networks transmission data public electronic communication services except activities falling outside scope law activities concerning public security defence state security activities state criminal law source fra based law instruments listed table fra focus facial recognition technology facial recognition technologies biometric sys tems allow automatic identification matching person face technology extracts processes biometric data creating biometric template facial images biome tric template detects measures various facial facial recognition facial recognition automatic processing digital images contain faces indi viduals identification cation categorisation individuals source article data protection working party opinion facial recognition online mobile services brussels march facial recognition refers multitude technol ogies perform different tasks different purposes regard key distinction whether facial recognition used verification identifi cation categorisation verification identifi cation deal matching unique characteristics individuals determine individual iden tity categorisation deals deducing whether individual belongs specific group based biometric characteristics example sex age race past years facial recognition technolo gies strongly benefitted increased data availability computing power development sophisticated machine learning algorithms article data protection working party opinion developments biometric technologies brussels april biometric template means mathematical representation obtained feature extraction biometric data limited characteristics necessary perform identifications verifications see art regulation european parliament council may establishing framework interoperability information systems field police judicial cooperation asylum migration amending regulations verification comparison verification authentication often referred matching enables comparison two biometric templates usually assumed belong two biometric templates compared determine person shown two images person procedure example used automated border control abc gates used border checks airports person scans passport image live image taken spot facial recognition technology compares two facial images likelihood two images show person certain threshold identity verified verification demand biometric features deposited central data base may stored example card document individual identification comparison identification means template person facial image compared many templates stored database find image stored facial recognition technology returns score comparison indicating likelihood two images refer person sometimes images checked databases known reference person database identification sometimes known identification latter operation would applied persons checked watchlists using facial recog nition technology identification sometimes referred automated facial recognition afr identification used based facial images obtained video cameras purpose system first needs detect face video footage smart phone users might know see also kindt privacy data protection issues biometric applications comparative legal analysis edn springer governance technology series iglezakis data protection legislation regard biometric application aristotle university thessaloniki june example davies innes dawson evaluation south wales police use automated facial recognition cardiff university september facial recognition technology fundamental rights considerations context law enforcement taking pictures sometimes camera automatically draws rectangles faces faces video footage extracted com pared facial images reference database identify whether person video footage database images watchlist systems referred live facial recognition technology lfrt quality facial images extracted video cameras controlled light distance position person captured video footage limit facial features therefore live facial recogni tion technologies likely result false matches compared facial images taken controlled environment border crossing point police station categorisation matching general characteristics apart verification identification facial rec ognition technology also used extract infor mation individual characteristics sometimes referred face analysis therefore also used profiling individuals involves categorising individuals based personal characteristics com monly predicted facial images sex age ethnic origin categorisation means tech nology used identify match individu als characteristics individuals necessarily allow identification however several characteristics inferred face potentially linked data location data could facto enable identification individual fussey murray independent report london metropolitan police service trial live facial recognition technology university essex human rights centre july see fra preventing unlawful profiling today future guide luxembourg publications office december use facial recognition technology stop researchers companies exper imented inferring characteristics facial images sexual tests highly controversial ethics perspective facial recognition technology also used infer emotions anger fear happiness detect whether people lying telling truth latter researched selected external borders greece hungary latvia framework integrated portable con trol system iborderctrl project integrates facial recognition technologies detect person saying serious fundamental rights implications categorisation individuals based facial images beyond scope paper focuses use facial recognition technology iden tification purposes wang kosinski deep neural networks accurate humans detecting sexual orientation facial images journal personality social psychology see european commission smart system tighten busy borders october website iborderctrl fra focus accuracy facial recognition technology assessing risks wrong identification technological developments performance assessment high level attention given facial recognition technology recent past stems strong accu racy gains achieved since accuracy gains mainly attributed availability increased computational power massive amounts data dig ital images people faces use modern machine learning determining necessary level accuracy facial recognition software challenging many different ways evaluate assess accuracy also depending task purpose context use applying technology places visited mil lions people train stations airports relatively small proportion errors still means hundreds people wrongly flagged addition certain categories people may likely wrongly matched others described section different ways calculate interpret error rates caution addi tion comes accuracy errors questions relation easily system tricked example fake face images called spoofing important particularly law enforcement facial recognition technologies like machinelearning algorithms binary outcomes meaning two possible outcomes fore useful distinguish false positives false negatives see grother ngan hanaoka ongoing face recognition vendor test frvt part identification nistir galbally ferrara haraksim psyllos beslay study face identification technology implementation schengen information system luxembourg publications office july facial image recognition success mostly stems use deep convolutional neural networks algorithms learn generic patterns images splitting images several areas detailed discussions evaluation metrics see grother ngan hanaoka ongoing face recognition vendor test frvt part identification nistir galbally ferrara haraksim psyllos beslay study face identification technology implementation schengen information system luxembourg publications office july see example parkin grinchuk recognizing face spoofing face recognition networks false positive refers situation image falsely matched another image watchlist law enforcement context would mean person wrongly identi fied watchlist system crucial consequences persons fun damental rights false positive identification rate gives proportion erroneously found matches number people watchlist identified fact watchlist among watchlist negatives deemed matches watchlist fact matches corresponding false negative identification rate miss rate indicates proportion erroneously identified among identified issue false positives false negatives also connected data quality accuracy data processing addressing requires regular correction updating facial images stored watchlist order ensure accurate processing discussing error rates three important con siderations need kept mind algorithm never returns definitive result probabilities example likelihood person shown one image person another image watchlist means thresholds need defined making decisions matches consequence always tradeoff false positives false negatives decision probability thresh old threshold higher false positives decrease false negatives increase way round rates usually reported rate fixed level miss rate reported fixed false positive identification rate rates need evaluated quan tities real cases mind large number people checked mass potentially small false positive identification rate still means grother ngan hanaoka ongoing face recognition vendor test frvt part identification nistir facial recognition technology fundamental rights considerations context law enforcement number people incorrectly identi fied example false positive identification rate means among people erroneously flagged assessments accuracy usually done basis specified training data sets easily evaluated deployed one reasons missed real world scenario known finally accuracy assessments need made different population groups general accuracy rates might misleading apart issues related varying performance facial recognition technology depending people sex age children elderly ethnic group technology accuracy applied people disabilities another important aspect rarely considered data quality training databases accuracy frt strongly influenced data quality used create software quality data used deployed principle data accuracy reflected article gdpr well article law enforcement directive authorities must use information accurate date several factors influence quality facial images include background object occlusion illumi nation light reflection ergonomics age aging gen der skin colour skin existing standards facial images define properties images showing faces ensure high quality example number pixels eyes standards ways conducting quality checks still discussed researched frt often differ entiates images based quality high quality images taken controlled circumstances usually referred facial images portraits mug shots images considered lower quality considered cautiously quality images serious issue applying facial rec ognition technologies images retrieved video cameras quality image eas ily controlled sanchez del rio conde recognition systems abc fra watchful eyes biometrics systems fundamental rights luxembourg publications office march international civil aviation organization icao created standards facial images included travel documents icao technical report portrait quality reference facial images mrtd international standard organization iso together international electrotechnical commission iec released standard best practices face images recognition software based mod els meaning software develops rules iden tification faces based database facial images possible increase availabil ity facial images higher quality increase computing power process large amounts data fundamental rights perspective important know datasets used build facial recognition software influences perfor mance software example although pretrained software adapted current use per sistent problems reported gender ethnic groups software facial recognition often trained mainly facial images white men much less women people belonging ethnic everyone access large data bases facial images developing software due data protection property rights hence large companies distinct advantage develop ing facial recognition software yet even among major vendors facial recognition software performance problems highlights importance high quality training data development facial recogni tion technologies general use systems might lead discrimination individuals certain characteristics notably women reality may difficult obtain information training data used developing software software might build already existing algorithms models makes difficult track back original training data importantly vendors facial recognition soft ware might want disclose information training data experienced expert civil society organisation copyright issues trade secrets could used block access information needed assess quality systems finally quality images included watchlists checked facial images crucial discus sion relation use facial recognition technol ogies low quality images watchlists considera bly increase number errors wrong matches buolamwini gebru gender shades intersectional accuracy disparities commercial gender classification proceedings machine learning research conference fairness accountability transparency grother ngan hanaoka ongoing face recognition vendor test frvt part identification nistir fra bigdata discrimination decision making luxembourg publications office may fra data quality artificial intelligence mitigating bias error protect fundamental rights luxembourg publications office june institute report fra focus use facial recognition technology public authorities date comprehensive overview use facial recognition technology many companies offer facial recognition technologies strong interest use technol ogy public administrations different purposes section focuses use law enforce ment number tests facial recog nition technologies carried past years law enforcement authorities different member states although information available limited apart test deployments live facial recognition technologies public authorities member states increased planned use facial images databases fields migration security see section meanwhile research possible use facial recognition technologies continues see section testing facial recognition technologies law enforcement member states fra interviewed representatives public authorities germany france united kingdom possible use plans using live facial rec ognition technologies law enforcement purposes far police united kingdom active experimenting live facial rec ognition technologies united kingdom member state testing live facial recogni tion technologies field real watchlists example south wales police using major london metropolitan give another example swedish municipality used facial recognition technology monitor attendance pupils schools led swedish data protection authority fine municipality violating gdpr see european data protection board facial recognition school renders sweden first gdpr fine august similar vein french data protection authority cnil also held use facial recognition technology entrance two high schools marseilles nice security reasons appears neither necessary proportionate given purpose violates gdpr see cnil expérimentation reconnaissance faciale dans deux lycées cnil précise position october south wales police also tested criminal investigation purposes based cctv materials retrospectively full list deployments technology available south wales police website carried several live trials facial recognition technologies south wales police first use live facial recognition technology united kingdom large sporting events police used uefa champions league final june brought people cardiff tech nology also used several events including sports events music concerts several cctv cameras placed different preselected locations depending size events police constructed watchlists including several hundreds people interest according independent evaluation report trials four different watchlists used uefa champions league final include small number individuals per ceived pose serious risk public safety previous convictions serious offense types possible interest police whose presence pose immediate risk threat public safety police officers test effective ness system watchlists contained individuals different events selection based different possible criteria however information creation watchlists shared evaluators absence information watchlists cre ated makes difficult assessment real pur pose necessity social need employing live facial recognition technology first case issue come court european union judgment final arose divisional court cardiff ruled case directed south wales police current national legal regime adequate ensure appropriate trary use facial recognition technology called davies innes dawson evaluation south wales police use automated facial recognition cardiff university september addition deployments locate people south wales police used frt identify suspects past crime scenes images captured crime scenes via cctv mobile phone cameras compared large database police custody images investigation purposes facial recognition technology fundamental rights considerations context law enforcement afr locate south wales police use date afr locate consistent requirements human rights act data protection london metropolitan police conducted ten live facial recognition technologies test deployments order test effec tively facial recognition technologies identify individuals watchlists include notting hill carnivals selected venues tests carried using existing watchlists additional images police staff test accuracy creating watchlists described relatively complex using different sources watchlists tests included outstanding arrest warrants believed likely carry violent crimes known police could pre sent threat safety public figures london policing ethics panel highlighted cen tral importance watchlists com piled raised concerns respect integ rity databases images taken watchlists fact images drawn sources civil society criti cised lack information watch lists due absence legislation guidance germany hamburg police used facial recogni tion technologies framework sum mit july based video material eight train stations well image video mate rial sources buses underground police officers manually identified criminal activity related individuals second step tried identify individuals potentially involved criminal activity material available event using facial recognition technologies data protection commissioner hamburg hamburgische beauftragte für datenschutz und informa tionsfreiheit issued report use facial recognition technologies found use technology comply data high court justice queens bench division divisional court cardiff queen otao bridges chief constable south wales police others ewch admin september para fussey murray independent report london metropolitan police service trial live facial recognition technology university essex human rights centre july ibid london policing ethics panel interim report live facial recognition law raised particularly problematic absence legal basis berlin police carried large trial live facial recognition technologies train station test main aim assess tech nical performance using three different facial recognition software systems potential use facial recognition technologies justified impossibility able review video mate rials cctv cameras available berlin searching people police published compre hensive report test results september test included volunteers included artificial watchlist volun teers facial images taken software tried identify passing certain area train station people watchlist could choose whether walk areas marked test facial recognition technologies terms accuracy results satisfactory police three software systems combined however potential use soft ware sense include possible watchlist cases deployed determined police police stated legislator needs decide adopting law deploying live facial recognition technologies includes definition could included watchlists example people searched con nection terrorism sexual offenders people escaped prison serving long sentences missing children according information provided experts using facial recognition technologies identification also considered context border management germany however yet implemented context police nice france conducted trial live facial recognition technologies carnival purpose test assess technolo efficiency watchlist trial consisted images volunteers people carnival could choose whether enter area live facial recognition technologies deployed gendarmerie france using facial rec ognition technologies criminal investigations use live facial recognition technologies due absence legal basis experts fra interviewed mentioned potential future use facial recognition technologies police could target large events gatherings well every der hamburgische beauftragte für datenschutz und informationsfreiheit datenschutzrechtliche prüfung des einsatzes einer gesichtserkennungssoftware zur aufklärung von straftaten zusammenhang mit dem durch die polizei hamburg far german court decision lawfulness police use technology polizeipräsidium potsdam biometrische gesichtserkennung fra focus security public places experts stated facial recognition technologies could make current sys tems control efficient searching wanted people sum german french authorities tested live facial recognition technologies volunteers without clearly indicating would included watchlists technology used real deployments due absence legal basis deployment live facial recognition tech nologies could currently used legally two countries limited information currently available possible use tests live facial recognition tech nologies member states austrian author ities bought facial recognition software running facial recognition technologies data bases identify unknown perpetrators criminal offences images available cctv cameras netherlands tests initiated use facial recognition technologies tests show number member states interested potential use facial recognition technologies whether live cctv cameras cases testing evaluated either independent entities contracted police police civil society data protection authorities academics raised several fundamental rights concerns respect use facial recognition fundamental rights concerns relation potential use facial recognition technologies focus live facial recognition technologies discussed section section facial recognition systems area migration security recent years developed upgraded sev eral systems field migration security process ongoing leg islative proposals still pending final adoption reply parliamentary enquiry anfragebeantwortung see example united kingdom fussey murray independent report london metropolitan police service trial live facial recognition technology university essex human rights centre july big brother watch joint statement police private company use facial recognition surveillance big brother watch face campaign may system regulation introduced facial images biometric identifiers provided use facial recognition technology verification purposes first time table shows processing facial images meanwhile included systems except european travel information authorisation system etias processing facial images supports biometric verification check person identity example applying visa crossing border requesting asylum cases individual concerned aware authorities taking facial image different situation live facial recognition applied identification purposes without knowledge person affected processing facial images systems complements processing biometric identifiers particular fingerprints table provides overview type biometric data processed six systems new legal basis two eurodac visa information system place five six systems process facial images systems collection processing facial images along biome tric data strictly regulated law safeguards limit collection processing personal data strictly necessary operationally required access data restricted persons operational need process personal data legal instruments setting systems provide rights data subjects line data protection furthermore legal instruments upgraded systems strengthen data quality safeguards require met biometric searches facial images carried typically regulation european parliament council november establishing system ees register entry exit data refusal entry data nationals crossing external borders member states determining conditions access ees law enforcement purposes amending convention implementing schengen agreement regulations ees regulation arts see example arts read conjunction recitals regulation european parliament council november establishment operation use schengen information system sis field border checks amending convention implementing schengen agreement amending repealing regulation sis checks see arts sis checks regulation listing data subjects rights see art sis checks regulation facial recognition technology fundamental rights considerations context law enforcement systems migration security processing facial images system main provisions collection processing facial imagespurpose legal basis schengen information system sis sis police specific rules entering biometric data art specific rules verification search biometric data art facial images photographs identification purposes initially used context regular border crossing points recital enter process alerts arrest missing persons discreet specific checks objects etc safeguard security schengen member statesreg sis border specific rules entering biometric data art specific rules verification search biometric data art facial images photographs identification purposes initially used context regular border crossing points recital enter process alerts purpose refusing entry stay schengen member states support implementation policies border checks immigrationreg sis return facial image inserted alerts return confirm identity person art enter process alerts thirdcountry nationals subject return decision support implementation policies border checks immigrationreg system ees facial image third country nationals art use data data verification borders art use ees examining deciding visas art use ees examining applications access national facilitation programmes art access data verification within territory member states art calculating monitoring duration authorised stay thirdcountry nationals admitted identify added purpose law enforcementreg visa information system vis vis yes art facilitate exchange data schengen member states visa applications added purpose law enforcementreg july vis proposal quality facial images art searches based alphanumerical data facial images art specific rules entering data art proposal revision com final may fra focus dactylography eurodac eurodac none determine member state examine international protection added purpose law enforcementreg june eurodac recast obligation take fingerprints facial images art storage personal data including facial images arts comparison transmission categories data arts new purpose assist control irregular immigration secondary movements added purpose law enforcementproposal revision com final may european criminal records information system nationals facial image confirm identity person result alphanumerical fingerprint data search art possibility use facial images automated biometric matching future provided necessity proportionality safeguards readiness technology art share information previous convictions nationalsreg apr interoperability queries based alphanumerical biometric data including facial images launched european search portal esp art interoperability borders visa art interoperability police judicial cooperation asylum migration biometric templates facial images stored searched biometric matching service arts interoperability borders visa arts interoperability police judicial cooperation asylum migration facial images stored common identity repository art interoperability borders visa art interoperability police judicial cooperation asylum migration establish framework interoperability ees vis etias eurodac sis allow communication border management security international added purpose law enforcementreg borders visa may reg police judicial cooperation asylum migration may notes facial image legislative proposals yet adopted presented italics source fra based existing proposed legal instruments facial recognition technology fundamental rights considerations context law enforcement automated processing facial images done soon technically feasible guarantee reliable match european commission report readi ness additional safeguard agency operational management informa tion technology systems responsible quality assurance safeguards reports regularly overview role tasks see chapter regulation european parliament council november european union agency operational management largescale systems area freedom security justice amending regulation council decision repealing regulation regulation automated data quality control mechanisms respect system european commission adopted technical specifications quality resolution use biometric data including facial regard schen gen information system joint research centre european commission assessed whether face recognition technology mature enough inte gration context schengen information see regulation arts annex commission implementing decision laying specifications quality resolution use fingerprints facial image biometric verification identification systm ees final brussels february table biometric identifiers systems migration security none yschengen information system sis police yschengen information system sis borders yschengen information system sis return system ees yeuropean criminal records information system yinteroperability information systems yeuropean dactylography eurodac recast proposal yvisa information system vis proposal yeuropean dactylography eurodac yvisa information system vis yeuropean travel information authorisation system etias fingerprints palm prints facial image dna profileblack adopted blue adopted source fra based adopted pending legislation fra focus study lists recommendations rollout technology including different meas ures ensure highest possible quality stored data ensuring safeguards particularly important since developments interoperability largescale systems allows strict controls national authorities including law enforcement access additional identity data stored central identity repository would otherwise able including purpose curbing irregular migration fighting serious crime terrorism searchable facial images strict con trols always comply principle pur pose limitation access must necessary proportionate objectives defined research field facial recognition technology funds within framework hori zon programme secure societies several research projects potential application facial recognition technology area security border management following examples show field border management pervasive user focused biometrics border project pro tect explored application facial recognition technologies development enhanced contactless person identification system external border crossings project also looked privacy requirements con cerns technology could raise pro jects focused novel mobility concepts land border security framework iborderctrl galbally ferrara haraksim psyllos beslay study face identification technology implementation schengen information system luxembourg publications office july information national law enforcement access systems fra interoperability fundamental rights implications opinion european union agency fundamental rights fra opinion interoperability vienna april fra revised visa information system fundamental rights implication opinion european union agency fundamental rights fra opinion vis vienna august fra fundamental rights interoperability information systems borders security luxembourg publications office june fra opinion impact proposal revised eurodac regulation fundamental rights fra opinion eurodac vienna december programme official name secure societies protecting freedom security europe citizens information see commission webpage security research project studied system could speed border control procedures identifica tion requirements made combination arts technologies face matching tool automatic deception detection system research tests whether technology could help border guards detecting bona fide travellers also passengers saying truth furthermore research ongoing understand societal acceptability public attitudes facial recognition technologies project privacy ethical regulatory social crossing point solutions acceptance persona example aims design tailored impact assessment methods appropriately assess effects new contactless crossing technologies including facial recognition technologies also look acceptability taking account human behav iour gender legal frameworks privacy concerns societal issues potential risk field security part evaluation ten year implementation prüm european commission conducting feasibility study improving capabilities system improve information mem ber states also discussing expansion system include biometric data austria lead focus group facial recognition european commission also funding project called towards european level exchange facial images telefi research project examine facial recognition currently used investigation crime across mem ber also give particular consideration potential implementing exchange facial images within prüm pro ject implemented forensics departments finland latvia sweden netherlands leadership estonian ministry justice project funded ensure privacy freedom including internet enhance societal legal ethical understanding areas security risk management topic acceptance gate crossing point solutions prüm decisions allow exchange fingerprints dna profiles vehicle registration numbers parties prüm convention member states purposes law enforcement national security see council decision stepping cooperation particularly combating terrorism crime council decision implementation decision june council july ibid monroy european union plans borderless query facial images july see website towards european level exchange facial images telefi project facial recognition technology fundamental rights considerations context law enforcement fundamental rights implications using live facial recognition general points use facial recognition technology entails risks opportunities fundamental rights entails many fundamental rights chal lenges result weak position individuals whose facial images captured checked watchlist time facial recognition technology offer timely protection example helping find missing children help detect fraud identify theft many unanswered questions linked technology use accuracy major concerns use facial recognition technologies particularly live facial recognition technolo gies voiced civil society sec tion presents facial recognition perceived analyses fundamental rights implications technology general section discusses individual fundamental rights affected public perceptions detailed assessment across extent people find use facial recognition technologies intrusive however indications certain share popula tion strongly objects subjected facial recognition survey conducted fra involving nationals seven border crossing points respondents indicated feeling uncomfortable facial image used crossing border see figure considered providing facial image border intrusive privacy said humiliating dif ferences across nationalities russians citizens united states less concerned chinese citizens people areas world concerned clear dif ferences respect level feeling humil iated based age gender emerged figure travellers level feeling comfortable providing facial images borders notes question comfortable use facial images crossing border source fra based survey carried seven points fra focus results survey might change rapidly time given fast development technology people often exposed technology according experts interviewed fra another survey conducted framework live facial recognition technologies tested nice france three percent respondents opposed use frt larger survey among general population views facial recognition carried based fra fundamental rights agency survey results annexed smart borders pilot project technical report annexes volume united results survey show among general population united kingdom feel completely uncom fortable facial recognition used policing purposes used airports ever feel comfortable use facial recognition public transport schools supermarkets workplace appears people generally tend feel comfortable use facial recognition technologies policing purposes many happy use technologies every day life figure shows according sur vey united kingdom main reasons ada lovelace institute beyond face value public attitudes facial recognition technology reasons people feeling comfortable uncomfortable facial recognition used united kingdom notes upper panel includes respondents indicated values question feeling comfortable use frt policing scale means comfortable lower panel includes respondents indicated feeling comfortable values source data ada lovelace institute based online survey united kingdom facial recognition technology fundamental rights considerations context law enforcement comfortable linked increased security whereas main reasons feeling uncomfortable related interferences people privacy requirements justified interference fundamental rights full compliance fundamental rights prereq uisite law enforcement activities irrespective technologies used international human rights law provide normative framework design development deployment facial rec ognition technologies help determine whether specific use facial recognition technology human rights section examines main fundamental rights affected facial recognition technologies typically absolute rights subject presents steps need followed determine whether charter right limited requirements specific individual right particular relating interferences right respect private life protection personal data ana lysed section far tests deployments facial recognition technologies member states public authori ties mainly focused technical accuracy assess fundamental rights implications broadly strong focus put image quality error rates results important one aspect facial recognition technology perfect terms accuracy questions would none theless remain example live facial recognition technology involves subjecting people facial recognition potentially without informed con sent puts weak potentially humiliat ing position use live facial recognition technologies thus also relates broadly right human dignity human dignity foundation fundamental rights guaranteed charter fundamental see also fussey murray independent report london metropolitan police service trial live facial recognition technology university essex human rights centre july mcgregor murray international human rights law framework algorithmic accountability international comparative law quarterly scheinin sorell surveille deliverable synthesis report merging ethics law analysis discussing outcomes article charter states human dignity inviolable must respected protected court justice cjeu confirmed case law fundamental right dignity part biometric data including facial images must pro cessed manner respects human dignity processing facial images may affect human dignity different ways following examples illustrate may feel uncomfortable going public places surveillance may change behaviour withdrawing social life visit ing central places surveillance avoiding train stations declining attend cultural social sports events depending extent live facial recognition technologies applied impact people may perceive surveillance technologies lives may significant affect capacity live dignified life documented examples authorities used excessive force take fingerprints peo ple arrived similar situations may hypothetically also occur force people places facial images cap tured prohibition excessive use force deriving article charter pro hibits torture inhuman degrading treatment key safeguard taking biometric data law enforcement authorities obtain many hits deploying facial recognition technologies example large public event may need stop check larger number peo ple poses high demands police staff par ticularly many people wrongly stopped due erroneous match may likely case facial image extracted cctv cameras risk inappropriate police behav iour due stress increases potentially undermin ing dignity person stopped interacting people subject match requires particular attention officers need ade quate training need ensure full respect right human dignity avoid risk tensions including dealing barak human dignity framework right motherright barak human dignity constitutional value constitutional right cambridge cambridge university press chapter cjeu netherlands european parliament council october paras fra watchful eyes biometrics systems fundamental rights luxembourg publications office march fra fundamental rights report luxembourg publications office june fra watchful eyes biometrics systems fundamental rights luxembourg publications office march fra focus people media united kingdom reported case concerning person avoided facial recognition technology cameras lon subsequently got fined public order offense concrete circumstances inci dent contested though important way promote compliance fun damental rights oversight independent bodies applies many different areas ranging oversight child protection authorities case children risk exploitation abuse neglect international monitoring bodies established pre vent torture inhuman degrading treatment inde pendent supervision also essential component european data protection article charter making express reference light fundamental rights issues stake com plexity independent supervision essential gen uinely protect people whose rights may affected facial recognition technology turning fundamental rights may subject restriction article charter sets frame work interferences fundamental rights justified respect requirements charter echr case charter rights cor responding rights guaranteed echr article charter pursuant article charter limita tion fundamental rights must provided law meet objectives general interest rec ognised union need protect rights freedoms others essence right proportionate fussey murray independent report london metropolitan police service trial live facial recognition technology university essex human rights centre july law enforcement directive chapter gdpr chapter charter art far charter contains rights correspond rights guaranteed convention protection human rights fundamental freedoms meaning scope rights shall laid said also reiterated explained cjeu see example satakunnan markkinapörssi satamedia december para joined cases volker und markus schecke eifert gbr hartmut eifert november para joined cases digital rights ireland ltd minister communications marine natural resources others kärntner landesregierung others april para maximillian schrems data protection commissioner october para webmindlicenses kft nemzeti vámhivatal kiemelt vám főigazgatóság december paras cjeu underlined require ments must complied court also emphasised limitation exercise rights freedoms recognised char ter must respect essence rights means fundamental rights limited certain extent completely disregarded established inalienable essential core right violated measure necessity proportionality test outlined charter conducted next step respect aspects objective general interest crime pre vention public security sufficient justify interference interference charter right needs examined whether given legitimate aim could obtained means interfere less right guar anteed similar requirements also imposed echr interpreted european court human rights ecthr test developed ecthr requires rights interference pursue legitimate aim accordance law necessitating appropriate legal basis meeting qualitative requirements public precise foreseeable well necessary demo cratic society necessity proportionality test fourth test ecthr also used essence right concept derived object purpose echr case law ecthr identified following elements determining whether measure necessary democratic society exam ple interference needs correspond pressing social need must proportionate reasons given justify interference see cjeu maximillian schrems data protection commissioner october paras refer article charter see also scheinin sorell surveille deliverable synthesis report merging ethics law analysis discussing outcomes april see brkan essence fundamental rights privacy data protection finding way maze cjeu constitutional reasoning german law journal cjeu joined cases digital rights ireland ltd minister communications marine natural resources others kärntner landesregierung others april requirements quality law see ecthr gorlov others russia nos july para see ecthr marper united kingdom nos december paras scheinin sorell surveille deliverable synthesis report merging ethics law analysis discussing outcomes april facial recognition technology fundamental rights considerations context law enforcement relevant respect use new technologies ecthr observed marper states strike right balance protecting fundamental rights developing new also applies introducing facial recognition tech nologies help support law enforcement bor der management assessment needs carried way using technology must cover rel evant fundamental rights take account elements ranging legitimate purpose technology wants achieve way facial images captured cctv cameras bodyworn cameras mobile phone applications etc degree errors entails enable informed assessment necessity propor tionality use intrusive technol ogy stricter test must regards legitimate objective results necessity proportionality test different depending whether supports verification identity person example border checks airports comparison whether used criminal investigations run facial image person watchlist comparison second case seriousness crime investigated plays important role examples use listed section indicate general terms authorities deployed tested technology enhance efficiency police work terms increased success finding wanted people reducing costs authorities also mentioned inability human work force video footage produced cctv cameras justification testing facial recognition technologies fra able obtain comprehensive picture types crimes law enforcement authorities used tested technology concerning accuracy results tests nice reported worked perfectly errors however use facial recog nition technologies usually comes errors largest accuracy test facial recognition technol ogies available department com merce national institute standards tech nology nist conducting ongoing vendor test see instance ecthr khelili switzerland october ecthr marper united kingdom nos december ecthr finland july ecthr finland february ecthr huvig france april ecthr leander sweden march ecthr marper united kingdom nos december para verification identification results show strong increase accuracy rates currently galleries million yet complex relationship false posi tives stopping innocent people false neg atives able find person interest proportionality assessment needs balance two illustrated question number innocent people flagged system stopped police acceptable sake possi bly succeeding finding person interest outcome assessment varies depending importance finding specific person harm done stopping innocent people vivid example comes test carried germany using three different facial recogni tion software systems parallel analysing matches cases least one three systems pro vided match tests berlin average miss rate false negatives among negative false positive identification rate means one ten cases aver age long run person interest would missed nine ten cases identi fied time every people crossing system three four people would wrongly identified matches sys tem according german authorities acceptable considering number peo ple crossing train stations every day would lead large number people incorrectly stopped least flagged police system also used provide match three software systems agree would increase miss rate meaning one three cases long run person interest would missed reduce false positive identification rate considered low authorities con ducting used station people crossing every day rate would mean period ten days two people would flagged despite grother ngan hanaoka ongoing face recognition vendor test frvt part identification nistir polizeipräsidium potsdam biometrische gesichtserkennung important mention results tests subject uncertainty due statistical variation true values fra focus fundamental rights affected section discusses specific fundamental rights affected using facial recogni tion technologies context law enforce ment focuses live facial recognition technol ogies facial images extracted cctv cameras compared database watch list section exhaustive analysis fundamental rights affected facial recogni tion technologies rather pertinent examples respect private life protection personal data rights respect private life data protec tion central deployment facial recogni tion technology public places although two closely related distinct rights also described clas sic right protection privacy modern right right data strive protect similar values autonomy human dignity individuals granting personal sphere freely develop personalities think shape opinions thus form essential prerequisite exercise fundamental rights freedom thought conscience religion arti cle charter freedom expression information article charter free dom assembly association article charter using live facial recognition technologies implies collecting comparing storing facial images system identification purposes fore constitutes interference right protection personal data set article charter embodying data protection law right private life article charter article echr facial images constitute personal data also confirmed ecthr also stated person facial image constitutes one cjeu joined cases volker und markus schecke eifert gbr hartmut eifert opinion advocate general sharpston june para fra council europe edps handbook european data protection law edition luxembourg publications office june cjeu schwarz stadt bochum october paras ecthr szabó vissy hungary january para attributes personality reveals person unique characteristics distinguishes person peers right protection one facial image thus one essential components personal concept private life broad term susceptible exhaustive definition covers physical psychological integrity person therefore embrace multiple aspects person physical social also zone interaction person others even public context may fall within scope private life contexts ecthr used concept reasonable expectation privacy referring extent people expect privacy public spaces without subjected surveillance one factors albeit necessarily conclusive one decide violation right respect private life relevance scope application however appears similarly according experts mere fact participants assem blies public mean pri vacy processing facial images databases may facial rec ognition technology develops raise unchartered issues rights protection private life well personal data given two rights absolute rights subject limitations interference needs ade quately compromise event essential inalienable core right explained section live facial recognition technology involves bio metric processing facial images taken pub lic place purpose determining person ecthr guide article european convention human rights right respect private family life home correspondence strasbourg council europe august para ecthr lópez ribalda others spain nos october para ibid para vermeulen surveille deliverable scope right private life public places july human rights committee draft general comment article right peaceful assembly draft prepared rapporteur christof heyns july para see also fra council europe edps handbook european data protection law edition luxembourg publications office june european court human rights guide article european convention human rights right respect private family life home correspondence strasbourg council europe updated august paras facial recognition technology fundamental rights considerations context law enforcement identification poten tial retention images consequently initial biometric processing facial images subsequent retention video footage compar ing data watchlist alongside populating watchlist facial images constitute inter ferences right respect private life protection personal given processing personal data constitutes limitation rights needs subjected strict necessity proportionality test including clear legal basis legitimate aim pursued test take account context circumstances hand hence sensitivity data way data used impor tant next fundamental rights safeguards key data protection principles flowing article charter interpreted cjeu specific guaran tees data protection acquis cor roborate necessity proportionality test lined section pursuant article gdpr processing biometric data allowed processing necessary reasons substantial public interest basis union member state law shall proportionate aim pursued respect essence right data protection provide suitable spe cific measures safeguard fundamental rights interests data subject article law enforcement directive lays similar albeit bit permissive collecting processing facial images pur pose frt needs strictly line european data protection law following main legal prin ciples data protection processing facial images must lawful fair transparent follow specific explicit legitimate pur pose clearly defined member state union law comply requirements data minimi sation data accuracy storage limitation data security fussey murray independent report london metropolitan police service trial live facial recognition technology university essex human rights centre july edps assessing necessity measures limit fundamental right protection personal data toolkit elaborated detailed presentation necessity proportionality test european law consult fra preventing unlawful profiling today future guide luxembourg publications office december law enforcement directive art gdpr art fair transparent transparent clear provision information utmost importance context live facial rec ognition technologies since people facial images usually captured cameras public places without knowledge consent gdpr law enforcement directive include provisions guaranteeing principle transparency right information right personal data pro tection requires fair processing includes ade quately informing persons whose facial images taken article gdpr stipulates per sonal data shall processed lawfully fairly transparent manner relation data sub ject recital law enforcement directive echoes requirements also right information precondition child exer cise right heard judicial adminis trative proceedings affect pro tected article crc article charter provision information transparency requirement european data pro tection law also promotes respect dignity individual controllers must take appropriate measures pro vide information related processing data subject concise transparent intelligible eas ily accessible form using clear plain language articles gdpr article law enforcement directive require individuals informed identity contact details controller purpose processing data retention times right request access stored data erasure rectification well right lodge complaint supervisory authority however law enforcement directive carves possible exceptions obli gation article avoid obstructing prej udicing ongoing investigations protect public security national security scenarios major importance facial recognition technolo gies considered potential purposes currently discussed invoked use facial recogni tion technologies might work without informed consent without possibility opt case searching terrorists suspected criminals hence limitation fundamental right informed consent processing data paired restrictions right access stored data needs strongly justified european data protection board edpb clarifies member states obligation inform individuals existing video surveillance devices information provided warning law enforcement directive art gdpr art fra focus reasonable distance monitored places information accessible without enter ing area surveillance may include information sheet link website detailing information surveillance telephone num ber receive information app map ping location video process extracting biometric features face makes face available process ing ways changes level intrusion due availability new technological means consequence availability facial image database different applying software extracts unique features facial image irre spective whether extracted features fact run watchlist following argumenta tion data protection commissioner city hamburg previously legally specified balance authorities interference purpose law enforcement right informational changed massively det riment latter moreover data protection commissioner sees facial recognition technologies providing entirely new way intrusion opportunities persecution requires specific specific explicit legitimate purpose principle purpose limitation one funda mental principles european data protection mirrored article charter well article gdpr article law enforcement directive requires personal data processed specified pur poses must explicitly defined law person concerned able foresee pur pose data principles equally apply context processing data via facial recognition technologies princi ple purpose limitation also implies prohibition unlimited retention data european data protection board guidelines processing personal data video devices version public consultation brussels july der hamburgische beauftragte für datenschutz und informationsfreiheit fra council europe edps handbook european data protection law edition luxembourg publications office june article data protection working party opinion purpose limitation brussels april cjeu productores música españa promusicae telefónica españa sau opinion advocate general kokott july para context purpose processing facial images via facial recognition technologies must strictly determined high threshold essen tially consisting purpose combat terrorism forms serious crime wellestablished purpose limitation law law enforcement access various data bases additional purpose could also used identify missing persons victims crime including children designing systems including facial recognition systems combating serious crimes terrorism improving public safety curbing irregular migra tion risk function creep meaning personal data facial images may used purposes initially envisaged case interoperability databases safeguards need implemented ensure facial image recognition technology unlawfully used access data minimisation data accuracy storage limitation data security accountability data must also safely collected processed stored unlawful data processing must pre vented related issue pre vention unauthorised access use personal data processed facial recognition tech nologies article gdpr article law enforcement directive require mem ber states take necessary measures avoid personal data disclosed accessed unau thorised persons organs facial recognition sys tems made interoperable systems future ensuring purpose limitation sce nario particularly challenging avoid poten tial data leakages ongoing research looks ways protect privacy biometric data hence increasing data security current research assesses technological solutions protect biometric iden tifiers templates fundamental rights implications interoperability systems see fra interoperability fundamental rights implications opinion european union agency fundamental rights fra opinion interoperability vienna april comprehensive overview european legal framework data protection see fra council europe edps handbook european data protection law edition luxembourg publications office june general framework evlauate unlinkability biometric template protection systems ieee transactions information forensics security vol facial recognition technology fundamental rights considerations context law enforcement law requires data controllers protect data design meaning measures need put place integrate safeguards protect rights people consequence plan ning use facial recognition technologies fullyfledged analysis plan process protecting rights needs made outset pursuant gdpr law enforcement directive use facial images requires data protection impact assessment dpia including prior consul tation data protection authority dpa data protection impact assessments important tools comprehensively assess legal permis sibility risks involved using facial recogni tion technologies need thoroughly done role dpas crucial respect safeguarding fundamental rights indepen dently acting bodies established law enforcement directive art gdpr art law enforcement directive arts gdpr arts information conduct data protection impact assessments including context video surveillance included article working party guidelines data protection impact assessment dpia determining whether processing likely result high risk purposes regulation brussels last revised adopted october tests facial recognition technologies made efforts conduct impact assessment german test included data protection plan set dpa purpose test data protection impact assessment south wales police also assessment london metropolitan police france informed dpa weeks trial plans carrying test south wales police data protection impact assessment version october london police ethics panel interim report live facial recognition automated decision making right human review article gdpr article law enforcement directive generally forbid automated deci sion making meaning decision based solely automated processing including profiling produces legal effects concerning similarly significantly affects exception prohibition authorised union member state law provides appro priate safeguards rights freedoms data subject least right human interven tion part controller special data involved facial images suitable measures safeguard data subject rights freedoms legitimate interests must place trials deployments envisaged member states provide human intervention means matches based facial recognition technologies flagged humans police offic ers evaluate match based evaluation take action many false positives already ruled stage however concept automated decision making elusive needs discussion research example cases human intervention might simply outcomes system hence rendering virtually automated contrary another example humans review potentially override outcomes system needs evaluated well research indicates humans overrule outcomes algorithms mainly result line stereotypes example putting minority groups disadvantage behaviour threatens possible added value automated processing potentially accu rate cases even fairer humans veale edwards clarity surprises questions article working party draft guidance automated profiling computer law security review vol april green chen disparate interactions analysis fairness risk assessments fat conference fairness accountability transparency fat january fra focus discrimination one person treated less favourably another would treated comparable situation basis perceived real personal called protected article charter prohibits discrimination based ground sex race colour ethnic social origin genetic features language religion belief political opinion member ship national minority property birth disability age sexual orientation charter prohibition reflects corresponding rights echr article protocol echr article even broader formulation established open list extending protection wide range new grounds unlike article echr charter right freestanding right applying situations need covered charter pro article charter provides everyone equal law justification different less favourable treat ment possible echr law differ ential treatment may justified pursues legitimate aim means pursue aim necessary boundaries may vary basis depending circumstances individual case instance ecthr jurisprudence differen tial treatment relating matters core personal dignity race ethnic origin gen der private life difficult justify areas discrimination algorithmic deci sion making occur due several reasons dis crimination occur design testing implementation algorithms used facial recog nition biases incorporated con sciously algorithm well council directive june implementing principle equal treatment persons irrespective racial ethnic origin art council directive november establishing general framework equal treatment employment occupation art fra coe handbook european law edition luxembourg publications office june see example ecthr burden united kingdom april para ecthr guberina croatia march para justification test law see cjeu wolfgang glatzel freistaat bayern may cjeu case gmbh karin weber von hartz may fra coe handbook european law edition luxembourg publications office june officers decide action take following match differences performance algorithm usually difficult times impossible remove bias math ematical programmatic important cause discrimination quality data used develop algorithms effective accurate facial recognition software needs fed large amounts facial images facial images lead principle accurate predictions however accuracy deter mined amount facial images processed also quality facial images data quality requires also representative set faces reflecting different groups yet date facial images used develop algorithms western world often white men lower numbers women individuals ethnic backgrounds result facial rec ognition systems worked well white men black phenotypical characteristics expression genes observable way hair skin colour might influence outcome biometric matching facial recognition systems reflection light affects quality facial images persons enough light affects quality comparing facial images database watchlist people therefore exposed higher likelihood wrongly matched false positives may result certain groups persons wrongly stopped frequently due colour skin article charter guarantees rights persons disabilities disability must result unequal treatment discrimination prohibited fra preventing unlawful profiling today future guide luxembourg publications office december fra bigdata discrimination decision making luxembourg publications office may however ongoing research looking aspect particularly privacy point view see example sensitivenets website morales fierrez sensitivenets learning agnostic representations application face recognition fra data quality artificial intelligence mitigating bias error protect fundamental rights luxembourg publications office june ibid center privacy technology georgetown law perpetual buolamwini gebru gender shades intersectional accuracy disparities commercial gender classification proceedings machine learning research conference fairness accountability transparency fra watchful eyes biometrics systems fundamental rights luxembourg publications office march facial recognition technology fundamental rights considerations context law enforcement equality law crimination charter lack research little discussion facial recognition tech nologies artificial intelligence broadly affect people disabilities types disabili ties manifold much information available extent facial recognition technolo gies work accurately different forms disabil ities injuries face people whose face altered result accident paralysis people facial surgeries peo ple craniofacial research needed understand whether facial recognition technologies may discriminate people certain disabilities although awareness risk discrimina tion facial recognition technologies increased considerably past years many profession als still see issue public offi cials fra interviewed indicated discrimination problem technology neutral confident system works equally different groups people different groups included testing fact none tests described paper analysed results terms different performance ethnic origin sex age tests even enough people among volunteers test differ ences performance therefore much larger sample people would needed test possible discrimination largest test facial recognition technologies united states shows error rates differ according demographic char acteristics including age sex country ori gin moreover results terms differences characteristics also differ across software discrimination facial recognition technologies might adverse effect group cohesion peo ple specific ethnic groups disproportion ally often erroneously stopped sig nificantly affect trust police border management rights child elderly people facial recognition systems affect rights children different ways article char ter rights child emphasises best see medium disability july grother ngan hanaoka ongoing face recognition vendor test frvt part verification fra preventing unlawful profiling today future guide luxembourg publications office december child must primary considera tion actions public authorities private actors take concerning children member states must provide child protection care necessary child devel opment best interests child one four core principles convention rights child crc child best inter ests must also given primary consideration context using facial recognition technology law enforcement border management pur poses cjeu also expressly recognised need respect children rights requires mem ber states take due account crc implementing data protection acquis provides special protection children regard personal due particular vulnerability children processing biometric data including facial images must subject stricter necessity proportionality test compared adults addition child grows time passes accuracy biometric match diminishes risk wrong match increases facial images recorded young age compared five years present tech nologies facial recognition guarantee reliable match child least six years old biometric facial image captured match happened within time frame five years general research indicates accu racy facial recognition technology significantly lower children younger software tests clearly indicate images younger people united nations convention rights child new york november cjeu european parliament council european union june paras cjeu dynamic medien vertriebs gmbh avides media february para comprehensive overview protection children rights law see fra coe handbook european law relating rights child luxembourg publications office november see gdpr recitals fra watchful eyes biometrics systems fundamental rights luxembourg publications office march joint research centre european commission institute protection security citizen fingerprint recognition children luxemburg publications office september chaudhary sahni saxena survey techniques aging problems face recognition mit international journal computer science information technology vol august ramanathan chellappa biswas computational methods modelling facial aging survey journal visual languages computing galbally ferrara haraksim psyllos beslay study face identification technology implementation schengen information system luxembourg publications office july fra focus considerably false negatives misses compared age groups probably due rapid growth change facial appearance ageing time image taken compared negatively affects accuracy facial recognition scientific research allow conclusions reliability match five years passed holds true facial images older people compared images taken many years earlier addressing issue blanket retention biometric data law enforcement purposes per sons convicted crime ecthr empha sised marper may especially harmful case children given special situation importance devel opment integration moreover facial recognition used prevent detect investigate terrorism serious crime difficult see may justify pro cessing facial images children age criminal time cases impact facial recognition technology best interests child may also positive facial recogni tion systems contribute protecting right child preserve line crc child deprived elements identity states must pro vide appropriate assistance protection view quickly identity facial recognition systems used police border guards may help trace missing abducted children including child victims crime prevent child abduction fra smallscale survey border posts shows children reported missing frequently encountered grother ngan hanaoka ongoing face recognition vendor test frvt part verification galbally ferrara haraksim psyllos beslay study face identification technology implementation schengen information system luxembourg publications office july ecthr marper united kingdom nos december paras fra revised visa information system fundamental rights implications opinion european union agency fundamental rights fra opinion vis vienna august crc art crc art fra watchful eyes biometrics systems fundamental rights luxembourg publications office march result facial recognition technologies carefully take account considerations processing images children children also older persons put situa tion would result age disproportionately affected negative con sequences facial recognition technologies processing needs fully respect article rights child article rights elderly charter freedom expression freedom assembly association freedom expression information cornerstone democratic right enshrined article charter arti cle echr evident article charter cjeu meaning scope right echr interpreted ecthr limitations may imposed may therefore exceed provided article article charter recognises protects freedom assembly association corresponds right enshrined article echr article echr restrictions right allowed prescribed law pursue one legitimate aims expressly listed therein national security public safety prevention crime necessary democratic society limitations equally apply charter right guaranteeing freedom assembly association accordance article charter using facial recognition technologies process facial images captured video cameras public space may interfere person freedom opin ion expression including necessary aspect exercising freedom group anonym regard court germany declared illegal publication pictures taken demon strations via social media due negative effect ecthr mouvement raelien suisse switzerland july para cjeu case société neptune distribution ministre économie des finances december explanations relating charter fundamental rights explanation article international justice public safety network privacy impact assessment report utilization facial recognition technologies identify subjects field june facial recognition technology fundamental rights considerations context law enforcement freedom knowing peo ple watched facial recognition tech nologies public spaces creates chilling effect may lead individuals change behaviour may express thoughts infringes freedom expression people discouraged attend demonstrations goes variance freedom expression also represents serious inter ference freedom assembly right peaceful assembly enables people participate collectively shaping societies powerful yet peaceful way freedom assembly protects ability people exercise autonomy experiencing solidarity using facial recognition technologies peaceful assem blies may discourage people demonstrating applied violent protests technology may still affect protests peacefully along side rioting deployment facial recog nition technologies may generate chilling effect whereby individuals refrain lawfully exercis ing freedom assembly association due fear negative consequences may fol might thus discouraged meet ing particular individuals organisations attending particular meetings taking part certain dem onstrations ability engage forms activity protected charter chill ing effect also clear implications effective functioning participatory democracy thus directly interferes freedom assembly civil society experts indicate facial recognition technologies may negatively impact willingness protesters engage activism hence deploying facial rec ognition technology demonstrations would need meet even higher threshold neces sity proportionality public spaces fra highlighted civil society organisations member states already highly concerned work subject state verwaltungsgericht gelsenkirchen ecli human rights council surveillance human rights report special rapporteur promotion protection right freedom opinion expression david kaye human rights committee draft general comment article right peaceful assembly draft prepared rapporteur christof heyns july para fussey murray independent report london metropolitan police service trial live facial recognition technology university essex human rights centre july ibid laperruque facing future surveillance task force facial recognition surveillance washington pogo march therefore vital authorities transparent use facial recognition technologies robust legislation place use surveillance right good administration right good administration general principle law elaborated cjeu binding member also fundamental right enshrined article charter although actions insti tutions bodies general prin ciple law requires member states apply requirements right good admin istration public action right includes limited right individual access file obligation public authority give reasons access file facilitates understanding eviden tiary basis decision made reasons underlying thereby plac ing individual better position put forward exercising right obligation give reasons makes perspective individuals affected process transparent person concerned know measure action taken according cjeu context individual decisions made important determining extent duty give right good administration also applies law enforcement authorities process facial images using facial recognition technologies although right good administration may subjected certain limitations question arises ensure fra challenges facing civil society organisations working human rights luxembourg publications office see also privacy international privacy international contribution general discussion article iccpr february recent case law see cjeu minister justice equality law reform ireland attorney general may para also confirmed cjeu joined cases minister voor immigratie integratie asiel minister voor immigratie integratie asiel july paras components initially developed cjeu case law codified article charter right leading academic literature see craig article right good administration hervey kenner peers ward eds charter fundamental rights commentary oxford portland oregon hart publishing ibid ibid fra focus potentially huge number individuals access files personal data stored another question make sure police public authorities always give reasons someone stopped searched based facial recognition match exercising right access one file including personal data stored systems requires person aware personal data stored people oftentimes aware fact faces recorded pro cessed database comparison aware processing also position request access data key components right good administra tion right access one file obligation administration give reasons decisions also translated specific provisions data protection law article charter data protec tion acquis provide right access correc tion deletion one personal data stored possibility exercise right access part right effective remedy purpose data processing concerns pre vention investigation detection prosecution criminal offences execution criminal penal ties safeguarding public security right access personal data request correction erasure may limited following cases according law enforcement avoid obstructing official legal inquiries investigations procedures avoid prejudicing prevention detection investigation prosecution criminal offences execution criminal penalties protect public security protect national security protect rights freedoms exemptions stem obligation law enforcement authorities work within cer tain degree confidentiality secrecy order ensure effectiveness work arts see also fra preventing unlawful profiling today future guide luxembourg publications office december highlighted fra previous independent accountability mechanisms key ensure effective access remedies combination internal external monitor ing bodies active different stages process use facial recogni tion technologies would guarantee individu als rights properly effectively protected according fra research still lack awareness understanding exercise right access correction deletion inac curate personal data stored applies facial recogni tion databases used law enforcement purposes situation exacerbated fact lawyers specialised seeking enforce right access correction deletion per sonal data systems including facial images used facial recognition right effective remedy article charter guarantees right effective remedy tribunal including fair trial fundamental right horizontal charac ter empowers individuals challenge measure affecting right conferred law respect fundamental rights guar anteed right effective remedy also covers decisions taken sup port facial recognition technologies example measure police stop solely significantly informed facial cjeu underlined article charter constitutes reaffirmation principle effec tive judicial protection characteristics see fra surveillance intelligence services fundamental rights safeguards remedies volume members states legal framework luxembourg publications office november fra surveillance intelligence services fundamental rights safeguards remedies volume field perspectives legal update luxembourg publications office october fra watchful eyes biometrics systems fundamental rights luxembourg publications office march network independent experts fundamental rights commentary charter fundamental rights european union june see also fra coe handbook european law relating access justice luxembourg publications office june council europe commissioner human rights unboxing artificial intelligence steps protect human rights recommendation council europe strasbourg may facial recognition technology fundamental rights considerations context law enforcement remedy must determined manner consistent precondition exercise right effec tive remedy person must aware facial image processed cjeu noted context security measures affect ing right private life right protection personal data national law enforce ment authorities must notify persons affected applicable national procedures soon notification longer capable jeopardis ing investigations undertaken author situation occurs example law enforcement authorities populate watchlist used facial recognition great number facial images cjeu found notification fact necessary enable persons affected measures exercise inter alia right effective legal remedy guaranteed article data protection law reconfirms right effective judicial remedy must provided relation decisions controller proces well supervisory data processed facial recognition technologies exception people might want challenge facial image included watch list done way without consent seek redress false positive match entailed negative consequences unlawful stop search arrest including seeking compensation damage individual missed flight connection wrongly prevented entering country missed business meeting cjeu unibet london ltd unibet international ltd justitiekanslern march para cjeu stoyanov izpalnitelen direktor darzhaven fond zemedelie razplashtatelna agentsia june para cjeu centre public action sociale moussa abdida december para cjeu joined cases sverige och telestyrelsen secretary state home department tom watson others december para see also mutatis mutandis seda kücükdeveci swedex gmbh january para maximillian schrems data protection commissioner october para cjeu joined cases sverige och telestyrelsen secretary state home department tom watson others december para law enforcement directive art gdpr art law enforcement directive art gdpr art law enforcement directive recital art gdpr recital art crucial note possibility lodge administrative complaint supervisory authority provided gdpr law enforcement considered effec tive judicial remedy article charter since court involved review judicial review always remain available acces sible internal alternative dispute settle ment mechanisms prove insufficient person concerned opts judicial law enforcement directive art gdpr art council europe draft recommendation committee ministers member states human rights impacts algorithmic systems committee experts human rights dimensions automated data processing different forms artificial intelligence msiaut june para fra focus using facial recognition technology technology developing quickly past years increasingly used multiple actors affects range fundamental rights however limited information way extent technology used law enforcement impact use fundamental rights working new technologies yet fully understood much experience yet gathered requires involvement relevant stakeholders experts different disciplines facial images constitute biometric data law rec ognises used identify individuals facial recognition technology used many different ways verifying identity person checking whether person among list people even categorise people accord ing different characteristics live facial recogni tion technology detects faces video footage compares faces watch lists potentially used public spaces much information available actual use facial recognition technology several member states considering test ing planning use technology law enforcement purposes actively police united kingdom carried several tests real life situations sports events even using real watch lists law enforcement agencies tested accuracy technology larger tests volunteers police berlin germany nice france lack comprehensive information actual use technology limits opportunities analyse fundamental rights implications particular laws guidance information included potential watch lists fundamental rights implications using facial recognition technology vary considerably depending purpose context scope use fundamental rights implications stem technology lack accuracy accuracy strongly increased technology still always comes certain rate error negatively impact fundamental rights moreover importantly several fundamental rights concerns would remain even complete absence errors notwithstanding varying context purpose scope use facial recognition technology several fundamental rights considerations apply way facial images obtained used poten tially without consent opportunities opt negative impact people dignity relatedly rights respect private life protection personal data core fun damental rights concerns using facial recog nition technology addition use tech nology needs thoroughly assessed terms potential impact rights special groups children older persons persons disabilities times unknown varying accuracy technology groups according protected characteristics moreover freedom expression association assembly must undermined use technology lastly paper highlights essential consider procedural rights facial recognition technology used public administrations includ ing right good administration right effective remedy fair trial given novelty lechnology well lack experience detailed studies impact facial recognition technologies multiple aspects key consider deploying sys tem real life applications example systems clear sufficiently detailed legal framework must regulate deployment use facial recognition technologies determin ing processing facial images nec essary proportionate depend pur pose technology used safeguards place protect individuals whose facial images subjected automated pro cessing possible negative consequences forms facial recognition involve high degree intrusion fundamental rights compromising inviolable essential core one fundamental rights unlawful distinction must made pro cessing facial images verification purposes two facial images compared verify appertain person processing identification purposes facial image run database watchlist facial images risk interferences fundamental rights higher second case therefore necessity proportionality test must stricter live facial recognition technologies facial images extracted video cameras deployed public spaces particu larly challenging use triggers different facial recognition technology fundamental rights considerations context law enforcement among population raises fears strong power imbalance state versus individual fears need taken seriously given individuals may aware facial image matched watch list considering higher error rate com pared facial images taken controlled envi ronment airport police station use remain exceptional strictly limited combatting terrorism forms serious crime detect miss ing people victims crime facial images extracted video cameras deployed public areas assessing necessity proportionality facial recogni tion must also consider cameras placed difference sports cultural event events people exercise one fundamental rights deployment facial recognition technologies demon strations may generate chilling effect whereby individuals refrain lawfully exercising freedom assembly association due fear negative consequences may follow difficult imagine situations deploy ment facial recognition technologies peo ple participating demonstration may nec essary proportionate recognition technology algorithms never provide definitive result probabilities two faces appertain person context law enforcement thus certain margin error leading people wrongly flagged deploying technol ogy risks wrongly flagging people must kept minimum everyone stopped result technology must treated dignified manner authorities typically rely private compa nies procuring deploying technology industry scientific research community play important role developing tech nical solutions promote respect funda mental rights including protection personal data however fundamental rights con siderations need built technical spec ifications contracts public procure ment directive strengthened member states commitment towards socially responsible public procurement purchas ing product service following spirit directive member states could apply similar approach procuring facial recognition technology commissioning innovative research placing fundamental rights particular data protection ination requirements centre technical specifications would ensure industry pays due attention thereto possible measures could include binding requirement involve data pro tection experts human rights specialists teams working development tech nology ensure fundamental rights compliance design furthermore technical specifications could make reference high quality standards minimise false identification rates adverse impacts gender ethnicity age fundamental rights impact assessment essential tool ensure fundamental rights com pliant application facial recognition technolo gies whatever context employed assessment needs evaluate affected rights including listed paper comprehensive manner enable carry assessment public authorities need obtain necessary information indus try required assess technology impact fundamental rights trade secrets confidentiality considerations hinder light constantly developing technology interferences fundamental rights easy predict close monitoring independent super visory bodies facial recognition developments therefore essential article charter protection personal data requires oversight data processing independent authority prevent fundamental rights viola tions effectively support people whose fundamental rights affected facial recogni tion technology oversight authorities must sufficient powers resources expertise see also council europe commissioner human rights unboxing artificial intelligence steps protect human rights recommendation council europe strasbourg may fra european union agency fundamental rights schwarzenbergplatz vienna austria tel fax european union agency fundamental rights print isbn pdf isbn print pdf information following fra publications offer information relevant topic paper data quality artificial intelligence mitigating bias error protect fundamental rights bigdata discrimination decision making watchful eyes biometrics systems fundamental rights fundamental rights interoperability information systems borders security impact fundamental rights proposed regulation european travel information authorisation system etias
