assessment list trustworthy altai independent expert group artificial intelligence set european commission assessment list trustworthy artificial intelligence altai self assessment assessment list trustworthy altai table contents introduction use assessment list trustworthy altai requirement human agency oversight human agency autonomy human oversight requirement technical robustness safety resilience attack security general safety accuracy reliability plans reproducibility requirement privacy data governance privacy data governance requirement transparency traceability explainability communication requirement diversity non fairness avoidance unfair bias accessibility universal design stakeholder participation requirement societal environmental well environmental well impact work skills impact society large democracy requirement accountability auditability risk management glossary document written level expert group hleg third deliverable hleg follows publication group deliverable ethics guidelines trustworthy published april members hleg named document contributed formulation content throughout running mandate work informed piloting phase original assessment list contained ethics guidelines ustworthy conducted european commission june december support broad direction assessment list trustworthy put forward document although necessarily agree every single statement therein level expert group independent expert group set european commission june disclaimer assessment list altai self tool individual collective mbers high level expert group offer guarantee compliance system assessed using altai requirements trustworthy circumstances individual collective members high level expert group liable direct indirect incidental special consequential damages lost profits result directly indirectly use reliance results using altai contact charlotte stix hleg coordinator cnect european commission brussels document made public july book isbn pdf isbn neither european commission person acting behalf commission responsible use might ade following information contents publication sole responsibility level expert group rtificial intelligence hleg although commission staff facilitated preparation thereof views expressed document reflect opinion hleg may circumstances regarded reflecting official position european commission information high expert group artificial intelligence available reuse policy european commission documents regulated decision use reproduction photos material copyright permission must sought directly cop yright holders assessment list trustworthy altai introduction high expert group artificial intelligence hleg set european commission published ethics guidelines trustworthy artificial third chapter guidelines cont ained assessment list help assess whether system developed deployed procured used adheres seven requirements trustworthy artificial intelligence specified ethics guidelines trustworthy huma agency oversight technical robustness safety privacy data governance transparency diversity non fairness societal environmental well accountability document contains final assessment list trustworthy altai presented hleg assessment list trustworthy altai intended self purposes provides initial approach evaluation trustworthy builds one outlined ethics gui delines trustworthy developed period two years june june period assessment list trustworthy altai also benefited piloting phase second half piloting phase hleg received valuable feedback fifty depth interviews selected companies input open work stream provide best practices via two publicly accessible questionnaires technical technica assessment list altai firmly grounded protection people fundamental rights term used european union refer human rights enshrined charter fundamental rights charter international human rights please consult text box fundamental rights familiarise concept content fundamental rights impact assessment sessment list trustworthy altai intended flexible use organisations draw elements relevant particular system assessment list trustworthy altai add elements see fit taking consideration sector operate helps organisations understand trustworthy particular risks system might generate minimize risks maximising benefit intended help organisations identi proposed systems might fundamental generate risks identify whether kind active measures may need taken avoid minimise risks organisations derive value assessment list altai active engagemen questions raises aimed encouraging thoughtful reflection provoke appropriate action nurture organisational culture committed developing maintaining trustworthy systems raises awareness potential pact society environment consumers workers citizens particular children people belonging marginalised groups encourages involvement relevant stakeholders helps gain insight whether meaningful app ropriate solutions processes accomplish adherence seven requirements outlined already place need put place could achieved internal guidelines governance processes etc trustworthy approach key enabling responsible competitiveness providing foundation upon using affected systems trust design development use lawful ethical assessment list trustworthy altai helps foster responsible sustainable innovation europe seeks make ethics core pillar developing unique approach one aims benefit empower protect individual human flourishing common good societ believe enable europe european organisations position global leaders edge worthy individual collective trust document offline version assessment list trustworthy altai online interactive version assessment list trustworthy altai use assessment list trustworthy altai assessment list trustworthy altai best completed involving multidiscip linary team people could within outside organisation specific competences expertise requirements related questions among stakeholders may find example following designers developers system data scientists procurement officers specialists staff use work system officers management know address question find useful help alliance advised seek outside counsel assistance requirement assessment list trustworthy altai provides introductory guidance relevant definitions glossary online version assessment list trustworthy altai contains additional explanatory notes many three components trustworthy defined ethics guidelines trustworthy assessment list trustworthy altai fundamental rights fundamental rights encompass rights human dignity discrimination well rights relation data protection privacy name examples prior self system assessment list fundamental rights impact assessment fria performed fria could include questions following drawing specific articles charter european convention human rights echr protocols european social system potentially negatively discriminate people basis following grounds non sex race colour ethnic social origin genetic features language religion belief political opinion membership national minority property birth disability age sexual orientation put place processes test monitor potential negative discrimination bias development deployment use phases system put place processes address rectify potential negative discrimination bias system system respect rights child example respect child protection taking child best interests account put place processes address rectify potential harm children system put place processes test monitor potential harm children development deployment use phases system social system protect personal data relating individuals line gdpr put place processes assess detail need data protection impact assessment including assessment necessity proportionality processing operations relation purpose respect development deployment use phases system put place measures envisaged address risks including safeguards security measures mechanisms ensure protection personal data respect development deployment use phases system see section privacy data governance assessment list available guidance european data protection system respect freedom expression information freedom assembly association put place processes test monitor potential infringement freedom expression information freedom assembly association development deployment use phases system put place processes address rectify potential infringement freedom expression information freedom assembly association system assessment list trustworthy altai requirement human agency oversight systems support hum agency human making prescribed principle respect human autonomy requires systems act enablers democratic flourishing equitable society supporting user agency uphold fundamental rights underpinned human oversight section systems assessed terms respect human agency autonomy well human oversight glossary system autonomous system end user human human self system subject user human agency autonomy subsection deals effect systems human behaviour broadest sense deals effect sys tems aimed guiding influencing supporting humans decision making processes example algorithmic decision support systems risk systems recommender systems predictive policing financial risk analysis also deals effect human perception expectation confronted systems like humans finally deals effect systems human affection trust dependence system designed interact guide take decisions human users affect society could system generate confusion end subjects whether decision content advice outcome result algorithmic decision users subjects adequately made aware decision content advice outcome result algorithmic decision could system generate confusion users subjects whether interacting human system users subjects informed interacting system could system affect human autonomy generating put place procedures avoid users system could system affect human autonomy interfering user making process unintended undesirable way put place procedure avoid system inadvertently affects human autonomy system simulate social interaction users subjects henceforward referred subjects definition subjects available glossary system risk creating human attachment stimulating addictive behaviour manipulating user behaviour depending risks possible likely please answer questions take measures deal possible negative consequences subjects case develop disproportionate attachment system take measures minimise risk addiction ake measures mitigate risk manipulation human oversight subsection helps self necessary oversight measures governance mechanisms hitl human hotl incommand hic approac hes human refers capability human intervention every decision cycle system human refers capability human intervention design cycle system monitoring system operation hum refers capability oversee overall activity system including broader economic societal legal ethical impact ability decide use system particular situation latter include decision use system particular situation establish levels human discretion use system ensure ability override decision made system please determine whether system choose many appropriate self autonomous system overseen human overseen human overseen human humans human given specific training exercise oversight establish detection response mechanisms undesirable adverse effects system end subject ensure stop button procedure safely abort operation needed take specific oversight control measures reflect self autonomous nature system assessment list trustworthy altai requirement technical robustness safety crucial requirement achieving trustworthy systems dependability ability deliver services justifiably trusted resilience robustness facing changes technical robustness requires systems developed preventative approach risks behave reliably intended minimising unintentional unexpected harm well preventing possible also apply event potential changes operating env ironment presence agents human artificial may interact system adversarial manner questions section address four main issues security safety accuracy reliability fall plans reproducibility glossary accuracy bias system reliability reproducibility low confidence score continual learning data poisoning model evasion model inversion pen test redteam resilience attack security could system adversarial critical damaging effects human societal safety case risks threats design technical faults defects outages attacks misuse inappropriate malicious use system certi fied cybersecurity certification scheme created cybersecurity act europe compliant specific security standards exposed system cyber assess potential forms attacks system could vulnerable consider different types vulnerabilities potential entry points attacks data poisoning manipulation training data model evasion classifying data according attacker model inversion infer model parameters put measures place ensure integrity robustness overall security system potential attacks lifecycle system inform duration security coverage updates length expected timeframe within provide security updates system cybersecurity general safety define risks risk metrics risk levels system specific use case put place process continuously measure assess risks inform users subjects existing potential risks identify possible threats system design faults technical faults envir onmental threats possible consequences assess risk possible malicious use misuse inappropriate use system define safety criticality levels related human integrity possible consequences faults misuse system assess dependency critical system decisions stable reliable behaviou align requirements appropriate levels stability reliability plan fault tolerance via duplicated system another parallel system conventional develop mechanism evaluate system changed merit new review technical robustness safety accuracy could low level accuracy system result critical adversarial damaging consequences put place measures ensure data including training data used develop system high quality complete representative environment system deployed put place series steps monitor document system accuracy consider whether system operation invalidate data assumptions rained might lead adversarial effects put processes place ensure level accuracy system expected users subjects properly communicated accuracy one performance metric might appropriate depending application monitoring false positives false negatives score help determine accuracy actually reflecting system performance confidence system users depend much expectation system performance fits actual performance communicating accuracy metrics therefore key assessment list trustworthy altai reliability fall plans reproducibility could system cause critical adversarial damaging consequences pertaining human safety case low reliability reproducibility put place well process monitor system meeti intended goals test whether specific contexts conditions need taken account ensure reproducibility put place verification validation methods documentation logging evaluate ensure differ ent aspects system reliability reproducibility clearly document operationali processes testing verification reliability reproducibility system define tested failsafe fallback plans address system errors whatever origin put governance procedures place trigger put place proper procedure handling cases system yields results low confidence score system using online continual learning consider potential negative consequences system learning novel unusual methods score well objective function performance metrics abstraction actual system behavior monitoring domain application specific parameters supervisory mechanism way verify system operates intended requirement privacy data governance closely linked principle prevention harm privacy fundamental right particularly affected systems prevention harm privacy also necessitates adequate data governance covers quality integrity data used relevance light domain systems deployed access protocols capability process data manner protects privacy glossary aggregation anonymisation system data governance data protection impact assessment dpia data protection officer dpo encryption lifecycle pseudonymisation standards use case privacy subsection helps self impact system impact privacy data protection fundamental ights closely related fundamental right integrity person covers respect person mental physical integrity consider impact system right privacy right physical mental moral integrity right data protection depending use case establish mechanisms allow flagging issues related privacy concerning system data governance subsection helps self adherence system use various elements concerning data protection system trained developed using processing personal data including special categories personal data put place following measures mandatory general data protection regulation gdpr european equivalent data protection impact assessment dpia designate data protection officer dpo include early ate development procurement use phase system oversight mechanisms data processing including limiting access qualified personnel mechanisms logging data access making modifications measures achieve privacy default encryption pseudonymisation aggregation anonymisation protection assessment list trustworthy altai data minimisation particular personal data including special categories data implement right withdraw consent right object right forgotten development system consider privacy data protection implications data collected generated processed course system life cycle consider privacy data protection implications system training processed non data align system relevant standards widely adopted protocols daily data management governance requirement transparency crucial component achieving trustworthy transparency encompasses three elements traceability explainability open communication limitations ystem glossary system end explicability lifecycle subject traceability workflow model traceability subsection helps self whether processes development system data processes yield system decisions properly documented allow traceability increase transparency ultimately build trust society put place measures address traceability system entire lifecycle put place measures continuously assess quality input data system trace back data used system make certain decision recommendation trace back model rules led decision recommendation system put place measures continuously assess quality output system put adequate logging practices place record decision recommendation system explainability subsection helps self explainability system questions refer ability explain technical processes system reasoning behind decisions predictions system makes explainability crucial building maintaining users trust systems driven decisions extent possible must explained understood directly indirectly affected order allow contesting decisions explanation model generated particular output decision combination input factors contributed always possible cases referred blackboxes require could take form standard automated quality assessment data input quantifying missing values gaps data exploring breaks data supply detecting data insufficient task detecting input data erroneous incorrect inaccurate mismatched format sensor working properly health records recorded properly concrete example sensor calibration process aims check ltimately improve sensor performance removing missing otherwise inaccurate values called structural errors sensor outputs could take form standard automated quality assessment output predictions scores within pected ranges anomaly detection output reassign input data leading anomaly detected assessment list trustworthy altai special attention circumstances explainability measures traceability auditability transparent communication system capabilities may required provided system whole respects fundamental rights degr explainability needed depends context severity consequences erroneous otherwise inaccurate output human life explain decision system users continuously survey users understand decision system communication subsection helps self whether system capabilities limitations communicated users manner appropriate use case hand could encompass communication system level accuracy well limitations cases interactive systems chatbots robo communicate users interacting system instead human establish mechanisms inform users purpose criteria limitations decision generated system communicate benefits system users communicate technic limitations potential risks system users level accuracy error rates provide appropriate training material disclaimers users adequately use system depends organisation developers involved directly user interactions workshops etc could addressed questi directly involved organisation needs make sure users understand system highlight misunderstandings developing team requirement diversity fairness order achieve trustworthy must enable inclusion diversity throughout entire system life cycle systems training operation may suffer inclusion inadvertent historic bias incompleteness bad governance models continuation biases could lead unintended direct prejudice discrimination certain groups people potentially exacerbating prejudice marginalisation harm also result intentional exploitation consumer biases engaging unfair competition homogenisation prices means collusion nontransparent market identifiable discriminatory bias removed collection phase possible systems user designed way allows people use products services regardless age gender abilities characteristics accessibility technology persons disabilities whi present societal groups particular importance glossary bias system designer developer accessibility assistive technology user fairness subject universal design use case avoidance unfair bias establish strategy set procedures avoid creating reinforcing unfair bias system regarding use input data well algorithm design consider diversity representativeness end subjects data test specific target groups problematic use cases research use publicly available technical tools state improve understanding data model performance assess put place processes test monitor potential biases entire lifecycle system biases due possible limitations stemming composition used data sets lack diversity representativeness rel evant consider diversity representativeness subjects data put place educational awareness initiatives help designers developers aware possible bias inject desi gning developing system ensure mechanism allows flagging issues related bias discrimination poor performance system establish clear steps ways communicating issues raised identify subjects could potentially directly affected system addition end users subjects assessment list trustworthy altai definition fairness commonly used implemented phase process setting system consider definitions fairness choosing one consult impacted communities correct definition fairness representatives elderly persons persons disabilities ensure quantitative analysis metrics measure test applied definition fairness establish mechanisms ensure fairness system accessibility universal design particularly business domains systems user designed way allows people use products services regardless age gender abilities characteristics accessibility technology persons disabilities present societal groups particular importance systems approach consider universal design addressing widest possible range users following relevant accessibility enable equitable access active participation people existing emerging computer human activities regard assistive technologies ensure system corresponds variety preferences abilities society assess whether system user interface usable special needs disabilities risk exclusion ensure information system user interface system access ible usable also users assistive technologies screen readers involve consult users subjects need assistive technology planning development phase system ensure univer sal design principles taken account every step planning development process applicable take impact system potential users subjects account assess whether team involved building system engaged possible target users subjects assess whether could groups might disproportionately affected outcomes system assess risk possible unfairness system onto subject communities iso std stakeholder participation order develop trustworthy advisable consult stakeholders may directly indirectly affected system throughout life cycle beneficial solicit regular feedback even deployment set longer term mechanisms stakeholder participation example ensuring workers information consultation participation throughout whole process implementing sys tems organisations consider mechanism include participation widest range possible stakeholders system design development assessment list trustworthy altai requirement societal environmental line principles fairness prevention harm broader society sentient beings environment considered stakeholders throughout system life cycle ubiquitous exposure social systems areas lives educ ation work care entertainment may alter conception social agency negatively impact social relationships attachment systems used enhance social skills equally contribute deterioration could equally affect peoples physical mental well effects systems must therefore carefully monitored considered sustainability ecological responsibility systems encouraged research fostered solutions addressing areas global concern instance sustainable development overall used benefit human beings including future generations systems serve maintain foster democratic processes respect plurality values life choices individuals systems must undermine democratic processes human deliberation democratic voting systems pose systemic threat society large environmental well subsection helps self potential positive negative impacts system environment systems even promise help tackle pressing societal concerns climate change must work environmentally iendly way possible system development deployment use process well entire supply chain assessed regard via critical examination resource usage energy consumption training opting less net negative choices measures secure environmental friendliness system entire supply chain encouraged potential negative impacts system environment potential impact identify possible establish mechanisms evaluate environmental impact system development deployment use example amount energy used carbon emissions define measures reduce environmental impac system throughout lifecycle impact work skills systems may fundamentally alter work sphere support humans working environment aim creation meaningful work subsection helps impact system use working environment workers relationship workers employers skills system impact human work work arrangements pave way introduction system organisation informing consulting impacted workers representatives trade unions european work councils advance adopt measures ensure impacts system human work well understood ensure workers understand system operates capabilities could system create risk workforce take measures counteract risks system promote require new digital skills provide training opportunities materials skilling impact society large democracy subsection helps self impact system societal perspective taking account effect institutions democracy society large use systems given careful consideration particularly situations relating democratic processes including political making also electoral contexts systems amplify fake news segregate electorate facilitate totalitarian behaviour could system negative impact society large democracy assess societal impact system use beyond user subject potentially indirectly affected stakeholders society large take action minimize potential societal harm system take measures ensure system negatively impact democracy assessment list trustworthy altai requirement accountability principle accountability necessitates mechanisms put place ensure responsibility development deployment use systems topic closely related risk management identifying mitigating risks transparent way explained audited third parties unjust adverse impacts occur accessible mechanism accountability place ensure adequate possibility redress glossary accountability ethics review board redress design auditability subsection helps self existing necessary level would req uired evaluation system internal external auditors possibility conduct evaluations well access records said evaluations contribute trustworthy applications affecting fundamental rights including applications systems able independently audited necessarily imply information business models intellectual property related system must always openly available establish mechanisms facilitate system auditability traceability development process sourcing training data logging system processes outcomes positive negative impact ensure system audited independent third parties risk management ability report actions decisions contribute system outcome respond consequences outcome must ensured identifyi assessing documenting minimising potential negative impacts systems especially crucial directly affected due protection must available whistle ngos trade unions entities reporting legitim ate concerns system implementing requirements tensions may arise may lead inevitable offs offs addressed rational methodological manner within state art entails relevant interests values implicated system identified conflict arises trade explicitly acknowledged evaluated terms risk safety ethical principles including fund amental rights decision make well reasoned properly documented adverse impact occurs accessible mechanisms foreseen ensure adequate redress foresee kind external guidance third auditing processes oversee ethical concerns accountability measures involvement third parties beyond development phase organise risk training also inform potential legal framework applicable system consider establishing ethics review board similar mechanism discuss overall accountability ethics practices including potential unclear grey areas establish process scuss continuously monitor assess system adherence assessment list trustworthy altai process include identification documentation conflicts aforementioned requirements different ethical principles explanation decisions made provide appropriate training involved process also cover legal framework applicable system establish process third parties suppliers end subjects workers report potential vulnerabilities risks biases system process foster revision risk management process applications adversely affect individuals redress design mechanisms put place assessment list trustworthy altai glossary glossary informed glossary accompanied ethics guidelines trustworthy accessibility extent products systems services environments facilities used people population widest range user needs characteristics capabilities achieve identified goals identified contexts use includes direct use use supported assistive tec hnologies accountability term refers idea one responsible action corollary consequences must able explain aims motivations reasons accountability several dimensions accountabil ity sometimes required law example general data protection regulation gdpr requires organisations process personal data ensure security measures place prevent data breaches report fail accountability ght also express ethical standard fall short legal consequences tech firms invest facial recognition technology spite absence ban technological moratorium might ethical accountability considerations accuracy goal model learn patterns generalize well unseen data important check trained model performing well unseen examples used training model model used predict answer test dataset predicted target compared actual answer concept accuracy used evaluate predictive capability model informally accuracy fraction predictions model got right number metrics used machine learning measure predictive accuracy model choice accuracy metric used depends task bias algorithmic bias describes systematic repeatabl errors computer system create unfair outcomes favou ring one arbitrary group users others bias emerge due many factors including limited design algorithm unintended unanticipated use decisions relating way data coded collected selected used train algorithm bias enter algorithmic systems result existing cultural social institutional expectations technical limitations design used unanticipated contexts audiences considered software initial design bias found across platforms including limited search engine results social media platforms impact ranging inadvertent privacy violations reinforcing social biases race gender sexuality ethnicity designer designers bridge gap capabilities user needs example create prototypes showing novel capabilities might used product deployed prior possible development product designers also work development teams better understand user needs build technology addresses needs additionally support developers designing platforms support data collection annotation ensuring data collection respects properties safety fairness developer developer someone performs ome tasks included development development process conceiving specifying designing training programming documenting testing bug fixing involved creating maintaining applications frameworks omponents includes writing maintaining source code well involved conception software final manifestation use software ethics review board ethics review board thics committee composed diverse group stakeholders expertises including gender background age factors purpose ethics board created clear organi sation establishing members invited join members independent role influenced economic considerations bias conflicts interest avoided overall size vary depending scope task authority ethics review board access information proportionate ability fulfill task best possible reliability system said reliable behaves expected even novel inputs trained tested earlier system artificial intelligence systems software possibly also hardware systems designed humans given complex goal act physical digital dimension perceiving environment data acquisition interpreting collec ted structured unstructured data reasoning knowledge processing information derived data deciding best action take achieve given goal systems either use symbolic rules learn numeric model also adapt behaviour analysing environment affected previous actions scientific discipline includes several approaches techniques machine learning deep learning reinforcement learning specific examples machine reasoning includes planning scheduling knowledge representation reasoning search optimization robotics includes control perception sensors actuators well integration techniques cyber systems separate document prepared hleg elaborating definition used purpose document titled definition main capabilities scientific disciplines system environment denotes everything world surrounds system part system technically environment described situation system operates systems get information rom environment via sensors collect data modify environment via suitable actuators information found data artificial assessment list trustworthy altai depending whether environment physical virtual world actuators hardware robotic arms software programs make changes digital structure assistive technology software hardware added incorporated within ict system increase accessibility often specifically designed assist people disabilities carrying daily activities assistive technology includes wheelchairs reading machines devices grasping etc area web accessibility common softwarebased assistive technologies include screen readers screen magnifiers speech synthesizers voice input software operate conjunction graphical desktop browsers among user agents hardware assistive technologies include alternative keyboards pointing devices audit audit independent examination required proper ties entity company product piece software audits provide third assurance various stakeholders subject matter free material misstatement term frequently applied audits financial nformation relating legal person applied anything else auditability auditability refers ability system undergo assessment system algorithms data design processes necessarily imply information business models intellectual property related system must always openly available ensuring traceability logging mechanisms early design phase system help enable system auditability autonomous systems autonomous system system performs behaviors tasks high degree autonomy without external influence confidence score much involves estimating quantity probability output correct answer given input confidence scores confidence intervals way quantifying uncertainty estimate low confidence score associated output system means system sure specific output correct data governance data governance term used macro micro level macro level data governance refers governing cross data flows countries hence precisely called international data governance micro level data governance data management concept concerning capability enables organization ensure high data quality exists throughout complete lifecycle data data ontrols implemented support business objectives key focus areas data governance include data availability usability consistency integrity sharing also regards establishing processes ensure effective data management throughout enterprise accountability adverse effects poor data quality ensuring data enterprise used entire organization data poisoning data poisoning occurs adversarial actor attacks ystem able inject bad data model training set thus making system learn something learn examples show cases data poisoning attacks neural nets effective causing signif icant drop accuracy even little data poisoning kinds poisoning attacks aim change behavior system rather insert backdoor data model designer aware att acker leverage get system want data protection impact assessment dpia evaluation effects processing personal data might individuals data relates dpia necessary cases technology creates high risk violation rights freedoms individuals law requires dpia case automated processing including profiling processing personal data revealing sensitive information like racial hnic origin political opinions religious philosophical beliefs processing personal data relating criminal convictions offences iii systematic monitoring publicly accessible area large scale data protection officer dpo denotes expert data protection law function dpo internally monitor public private organisation compliance gdpr public private organisations must appoint dpos following circumstances data proces sing activities carried public authority body except courts acting judicial capacity processing personal data requires regular systematic monitoring individuals large scale iii processing per sonal data reveals sensitive information like racial ethnic origin political opinions religious philosophical beliefs refers criminal convictions offences dpo must independent appointing organisation encryption pseudonymi sation aggregation anonymisation pseudonymisation refers idea possible attribute personal data specific data subject without additional information contrast pseudonymisation anonymisation consists preventing identification individuals personal data link individual personal data definitively erased encryption procedure whereby clear text information disguised using especially hash key encrypted results unintelligible data persons encryption key aggregation process whereby data gathered expressed summary form especially statistical analysis end person ultimately uses intended ultimately use system could either consumer professional within public private organisation user stands contrast users support maintain product system administrators database administrator information technology experts software professionals computer technicians explainability feature system intelligible experts system intelligible functionality operations explained non technically person skilled art assessment list trustworthy altai fairness fairness refers variety ideas known equity impartiality egalitarianism justice fairness embodies ideal equal treatment individuals groups individuals generally referred substantive fairness fairness also encompasses procedural perspective ability seek obtain relief individual rights freedoms violated fault tolerance fault tolerance property enables system continue operating properly event failure one faults within components operating quality decreases decrease proportional severity failure compared naively designed system even small failure cause total breakdown fault tolerance particularly sought high safety critical systems redundancy duplication provision additional functional capabilities would unnecessary fault environment consist backup components automatically kick one component fails human oversight hum oversight helps ensure system undermine human autonomy causes adverse effects oversight may achieved governance mechanisms human hitl hotl human hic approach human refers capability human intervention every decision cycle system many cases neither possible desirable human refers capability human intervention design cle system monitoring system operation refers capability oversee overall activity system including broader economic societal legal ethical impact ability decide use system particular situation include decision use system particular situation establish levels human discretion use system ensure ability override decision made system moreover must ensured public enforcers ability exercise oversight line mandate oversight mechanisms required varying degrees support safety control measures depending system application area potential risk things equal less oversight human exercise system extensive testing stricter governance required interpretability interpretability refers concept compr ehensibility explainability understandability element system interpretable means possible least external observer understand find meaning lifecycle lifecycle system includes several interdependent phases ranging design development including sub requirement analysis data collection training testing integration installation deployment operation maintenance disposal given complexity general information systems several models methodologies defined manage complexity especially design development phases waterfall spiral agile software development rapid prototyping incremental model evasion evasion one common attacks machine learning models performed production refers designing input seems normal human wrongly classified models typical example change pixels picture uploading image recognition system fails classify result model inversion model inversion refers kind attack models access model abused infer information training data model inversion turns usual path training data learned model way one two one permitting training data estimated model varying degrees accuracy attacks raise serious concerns given training data usually contain privacy information online continual learning ability continually learn time accommodating new knowledge retaining previously learned experiences referred continual lifelong learning learning continually crucial agents robots operating changing environments required acquire tune adapt transfer increasingly complex representations knowledge continuous lear ning task represented challenge machine learning neural networks consequently development artificial intelligence systems main issue computational models regarding lifelong learning prone catastrophic forgetting catastrophic interference training model new information interferes previously learned knowledge pen test penetration test colloquially known pen test pentest ethical hacking authorized simulated cyberattack computer system performed evaluate security system test performed identify weaknesses also referred vulnerabilities including potential unauthori sed parties gain acces system features data well strengths enabling full risk assessment completed red team red teaming practice whereby red team independent group challenges organisation improve effectiveness assuming adversarial role point view often used help identify address potential security vulnerabilities redress design redress design relates idea establishing design phase mechanisms ensure redundancy alternative systems alternative procedures etc order able effectively detect audit rectify wrong decisions taken perfectly functioning system possible improve system reproducibility reproducibility refers closeness results two actions two scientific experiments given input use methodology described corresponding scientific evidence scientific publication related concept replication ability independently achieve identical conclusions least similar differences sampling research procedures data analysis methods may exist reproducibility replicability together among main tools ientific method assessment list trustworthy altai robustness robustness system encompasses technical robustness appropriate given context application domain life cycle phase well robustness social perspective ensuring system duly takes account context environment system operates crucial ensure even good intentions unintentional harm occur robustness third three components necessary achieving trustworthy system self self learning systems recognize patterns training data autonomous way without need supervision standards standards norms designed industry governments set product services specifications key part society ensure quality safety products services international trade businesses seen benefit standards help cut cos improved systems procedures put place standards internationally agreed experts usually represent experts think best way something could making product managing process delivering ervice supplying materials standards cover huge range activities standards released international organizations iso international organi sation standardi sation ieee institute electrical electronics engineers andard association nist national institute standards technology subject subject person group persons affected system recipient benefits decision grant reject benefits underpinned system general public facial recognition traceability ability track journey data input stages sampling labelling processing decision making trustworthy trustworthy three components lawful ensuring compliance applicable laws regulations ethical demonstrating respect ensure adherence ethical principles values robust technical social perspective since even good intentions systems cause unintentional trustworthy concerns trustworthiness system also comprises trustworthiness processes actors part system life cycle universal design terms design universal design accessible design free design inclusive design transgenerational design often used interchangeably meaning concepts developed different stakeholders working deliver high levels accessibility parallel development mancentred design emerged within ergonomics focusing usability related concepts expressed human rights perspective design approach design approach focuses user involvement experiences desi development process achieve accessibility usability applied informed ethics guidelines trustworthy accessible single earliest possible time throughout stages life products services intended mainstream use design approach also focuses user requirements interoperability products services across chain use reach inclusive stigmatizing solutions use case use case specific situation product service could potentially used example self cars care robots use cases user user person uses supports maintains product system administrators database administrators information technology experts software professionals computer technicians workflow model workflow model shows phases needed build model interdependencies typical phases data collection preparation model development model training model accuracy evaluation hyperparameters tuning model usage model maintenance model versioning stages usually iterative one may need reevaluate back previous step point process assessment list trustworthy altai document prepared level expert group members follow pekka ala chair hleg huhtamaki sanoma wilhelm bauer fraunhofer urs bergmann zalando mária bieliková slovak university technology bratislava nozha boujemaa inria cecilia dahl digitaleurope yann bonnet anssi loubna bouarfa okra stéphan brunessaux airbus raja chatila ieee initiative ethics systems sorbonne university mark coeckelbergh university ienna virginia dignum umea university luciano floridi university oxford françois gagné element chiara giovannini anec joanna goodey fundamental rights agency sami haddadin msrm tum gry hasselbalch thinkdotank dataethics university copenhagen fredrik heintz linköping university fanny hidvegi access eric hilgendorf university würzburg klaus höckner hilfsgemeinschaft der blinden und sehschwachen laveissière orange leo kärkkäinen nokia bell labs sabine theresia köszegi wien robert kroplewski solicitor advisor polish government elisabeth ling relx pierre lucas orgalim europe technology industries raoul mallar sigfox ieva martinkenaite telenor thomas metzinger jgu mainz european university association catelijne muller allai netherlands eesc markus noga sap barry sullivan vice hleg university college cork ursula pachl beuc lorena jaume palasi algorithmwatch nicolas petit university liège christoph peylo bosch iris plöger bdi stefano quintarelli garden ventures andrea renda college europe faculty ceps francesca rossi ibm cristina san josé european banking federation isabelle schömann etuc george sharkov digital sme alliance philipp slusallek german research centre dfki françoise soulié fogelman consultant saskia steinacker bayer reinhard stolle bmw jaan tallinn ambient sound investment thierry tingaud stmicroelectronics jakob uszkoreit google thiébaut weber etuc aimee van wynsberghe delft cecile wendling axa karen yeung university birmingham hleg members contributed deliverable catelijne muller andrea renda acted following hleg members contributed depth revision specific key requirements alphabetical order human agency oversight joanna goodey fredrik heintz technical robustness safety yann bonnet raja chatila pierre lucas andrea renda george sharkov jaan tallinn cecile wendling privacy data governance cecilia dahl fanny hidvegi transparency mária bieliková ieva martinkenaite ursula pachl diversity discrimination fairness klaus höckner francesca rossi societal environmental well mark coeckelbergh virginia dignum sabine theresia köszegi accountability robert kroplewski christoph peylo stefano quintarelli glossary nicolas petit francesca rossi revisions directly informed piloting assessment list conducted second half feedback received questionnaire accessib alliance technical technical stakeholders open submission stream alliance written feedback best practices fifty indepth interviews selected organisations across european union pekka chair hleg barry chair contributed work document charlotte stix coordinates hleg provided editorial support information process available trustworthy assessment list trustworthy altai book isbn pdf isbn
