study panel future science technology eprs european parliamentary research service scientific foresight unit stoa march understanding algorithmic decision opportunities challenges understanding algorithmic decision opportunities challenges algorithms hardly recent invention nevertheless increasingly involved systems used support decision systems known algorithmic decision systems often rely analysis large amounts personal data infer correlations generally derive information deemed useful make decisions hum intervention decision may vary may even completely loop entirely automated systems many situations impact decision people significant access credit employment medical treatment judicial sentences among things entrusting ads make influence decisions raises variety ethical political legal technical issues great care must taken analyse address correctly neglected expected benefits systems may negated variety different risks individuals discrimination unfair practices loss autonomy etc economy unfair practices limited access markets etc society hole manipulation threat democracy study reviews opportunities risks related use ads present policy options reduce risks explain limitations sketch options overcome limitations able benefit tremendous possibilities ads limiting risks related use beyond providing systematic review situation study gives precise definition number key terms analysis differences help clarify debate main focus study technical aspects ads however broaden discussion legal ethical social dimensions considered stoa panel future science technology author study written claude castelluccia daniel métayer institut national recherche informatique automatique inria request panel future science technology stoa managed scientific foresight unit within directorate parliamentary research services eprs secretariat european parliament administrator responsible mihalis kritikos scientific foresight unit stoa contact publisher please mail stoa acknowledgments authors would like thank helped way whatever study particular irene maxwell clément hénin careful reading useful comments earlier draft report linguistic version original manuscript completed march disclaimer copyright document prepared addressed members staff european parliament background material assist parliamentary work content document sole responsibility author opinions expressed herein taken represent official position parliament reproduction translation non purposes authorised provided source acknowledged european parliament given prior notice sent copy brussels european union isbn doi stoa website intranet internet blog understanding algorithmic decision opportunities challenges executive ummary scope study algorithms hardly recent invention nevertheless increasingly involved systems used support decision known algorithmic decision systems ads often rely analysis large amounts personal data infer correlations generally derive information deemed useful make decisions human intervention making may vary may even completely loo entirely automated systems many situations impact decision people significant access credit employment medical treatment judicial sentences among things entrusting ads make influence cisions raises variety different ethical political legal technical issues great care must taken analyse address correctly neglected expected benefits systems may negated variety risks individuals discrimination unfair practices loss autonomy etc economy unfair practices limited access markets etc society whole manipulation threat democracy study reviews opportunities risks related use ads present existing options reduce risks explain limitations sketch options benefit tremendous possibilities ads limiting risks related use beyond providing systematic review situation study gives precise definition number key terms analysis differences help clarify debate main focus study technical aspects ads however broaden discussion legal ethical social dimensions considered ads opportunities risks study discusses benefits risks related use ads three categories stakeholders individuals private sector public sector risks may intentional optimi interests operator ads accidental effects purpose ads intent designer consequences ads errors inaccuracies people wrongly included blacklists fly lists due homonyms inaccurate inferences opportunities risks ads individuals ads may undermine fundamental principles equality privacy dignity autonomy free may also pose risks related health quality life physical integrity ads lead discrimination extensively documented many areas judicial system credit scoring targeted advertising employment discrimination may result different types biases arising training data technical constraints societal individual biases however risk discrimination related use ads compared risk discrimination without use ads huma sources bias affect decisions cases could detected avoided using ads deployment ads may also pose threat privacy data protection many different ways first related massive collection personal data required train algorithms even external attack carried mere suspicion one personal data collected possibly analysed detrimental impact people example several studies provided evidence chilling effect resulting fear online surveillance altogether scale surveillance scoring could narrow range possibilities choices available individuals affect ing thei capacity self fulfilment scoring also raises fear humans increasingly treated numbers reduced digital profile reducing complexity human personality number seen form alienation offen human dignity stoa panel future science technology opacity lack transparency ads another primary source risk individuals opens door kinds manipulation makes difficult challenge decision based result ads contradiction defence rights principle adversarial proceedings right evidence observations legal systems use ads court also raises far questions reliance predictive scores make legal decisions particular sentencing opportunities risks public sector ads currently used state public agencies provide new services improve existing ones areas energy education healthcare transportation judicia system security examples applications ads context predictive policing smart metering video protection school enrolment also contribute improving quality healthcare education job skill training increasingly used defence protect infrastructures support soldiers battlefield ads smart technologies general mobility management tools water energy management systems prove city management efficiency also help make administrative decisions efficient transparent accountable provided however transparent accountable ads also create new security vulnerabilities exploited people malicious intent since ads play pivotal role workings society example nuclear power stations smart grids hospitals cars hackers able compromise systems capacity cause major damag furthermore ads used predictive policing may become overwhelming oppressive ads mis used states control people example identifying political opponents generally interest groups states may tempted use technologies control influence citizen behaviour technologies also used distort information damage integrity democratic discourse reputation government political lead ers opportunities risks private sector opportunities presented ads private sector endless also numerous risks task repetitive pressured time could benefit analysis high volumes data prime target ads tasks concern low well high personnel example sectors banking insurance justice certain types jobs change enormously eliminated whilst new ones appear expression industrial revolution describes dramatic change desiderata algorithms define key properties required reduce risks related ads making distinction properties apply alg orithmic system safety security privacy properties specific ads latter include intrinsic extrinsic requirements intrinsic requirements fairness absence bias discrimination expressed properties algorithm application context equate fairness undesirable bias characteri particular form unfairness related use specific types data ethnic origin politica opinions gender far extrinsic requirements concerned define possibility provide understandable information link input output ads two main forms understandability considered transparency explainability transparency defined availability ads code design documentation parameters learning dataset ads relies machine learning transparency necessarily mean availability public also encompasses cases code disclosed specific actors example audit certification understanding algorithmic decision opportunities challenges iii explainability defined availability explanations ads con trast transparency explainability requires delivery information beyond ads explanations different types operational logical causal either global whole algorithm local specific results take different forms decision trees histograms picture text highlights examples counterexamples strengths weaknesses explanation mode assessed relation recipients explanation professional individual level expertise objectives challenge decision take actions obtain decision verify compliance legal obligations accountability another key desideratum often put forward ntext ads accordance previous work area see accountability overarching principle characteri sed obligation justify one actions risk sanctions justifications inadequate accountability therefore seen requirement process obligation provide justification applies intrinsic extrinsic requirements ads case corresponding specific types justification technical issues approaches report includes review technical issues available solutions safety important issue consider especially ads embedded physical systems whose failure may cause fatal damage study explores several types accidents related machine learning presents relevant research directions protect many ads failures addressed solutions strong need define unified approach prevent ads causing unintended minimum requirement perform extensive testing evaluation scale deployment also important provide accountability including possibility independent audits ensure form human oversight integrity availability increasingly ads used critical contexts therefore important guarantee secure malicious adversaries ads jeopardise integrity availability since ads rely heavily machine learning algorithms important consider security properties context algorithms adversaries threaten integrity availability ads different ways polluting training datasets fake data attac king machine learning algorithm exploiting generated model ads time argue existing protection mechanisms remain preliminary require research confidentiality privacy adversary may seek compr omise confidentiality ads example may try extract information training data retrieve ads model attacks raise privacy concerns training data likely contain personal data may also undermin intellectual property since ads model training data may proprietary confidential owner different proposals made address privacy attacks involve anonymising training datasets generate models designing privacy ads proposals rely distribution learning phase training data leave device collects privacy solutions still infancy requi work fairness absence undesirable bias ads often based machine learning algorithms trained using collected data process includes multiple potential sources unfairness unfair treatment may result content training data way data labelled feature selection shown study different definitions fairness others proposed future research shown stoa panel future science technology however many definitions fairness actu ally incompatible several research groups also started work design fair ads study introduces new projects explainability three main approaches followed implement requirements explainability black box approach approach analyses behaviour ads without opening hood without knowledge code explanations constructed observations relationships inputs outputs system possible approach operator provider ads uncollaborative agree disclose code examples category approach include lime local interpretable model explanations anchor trepan adfischer sunlight white box approach contrast black box approach approach assumes analysis ads code possible example early work direction elvira system graphical explanation bayesian networks solutions based neural networks proposed recently constructive approach contrast first two approaches assume ads already exists constructive approach design ads taking explainability requirements account design two options possible achieve explainability design relying algorithmic technique design meets intelligibility requirements oviding sufficient accuracy enhancing accurate algorithm explanation facilities generate addition nominal results classification faithful intelligible explanation results explanations generated methods take different forms number criteria proposed evaluate quality including intelligibility accuracy precision completeness consistency however criteria may tension example higher levels accuracy precision may reduce intelligibility addition evaluation difficult often partly subjective task legal instruments technical solutions necessary solve ssues raised ads must associated types measures particular legal requirements transparency explainability accountability fact various existing laws already apply ads greater sser extent address requirements identified report first discuss situation europe new general data protection regulation gdpr particular analyse highly provisions gdpr terms transparency explainability discuss possible answers questions right really set forth gdpr explanation mean exactly context right set forth gdpr conditio application likely effective also discuss recent developments european union member state france sketching proposals originate united states america proposals stem legal doctri emphasi due process accountability effective way introduce form control ads open questions remaining challenges study presents many challenges addressed reduce risks related ads classified according following three perspectives ethical political legal social technical challenges ethical political ads exacerbate existing problems force rethink issues discrimination also introduce new ethical questions difficult address examples critical complex questions raised ads include understanding algorithmic decision opportunities challenges legitima use ads certain contexts evidence sentencing lethal weapons use heavily criticised establish ing clear firm boundaries acceptable uses ads situations banned far straightforward beyond existing fairness criteria already identified anti ion laws types treatment considered undesirable line drawn relation principles online manipulation characterised distinguished acceptable influence case transparency explainability forms accountability required relation underlying principles certain types ads forbidden acceptable level transparency explainability accountability achieved example court support medical diagnosis choices design made autonomous vehicles death decision taken ethical behaviours encoded system decide upon choice ethical behaviour study sketches proposals address issues principled way legal social ethical political debates prerequisites action assuming fairly broad agreement reached issues discussed next step decide upon appropriate instruments implement agreement law discuss different types regulation state regulation self ation hard law soft law general sectorial regulation different modes enforcement regulatory agencies dedicated oversight bodies also discuss different options certification technical technical instruments presented study useful meet identified desiderata still infancy number challenges need addressed challenges conceptual defining best types explanations depending different recipients level expertise objectives challenges operational implementation explainability design fairness design privacy esign properties taken consideration beginning conception ads already required gdpr data protection however phase requires strong level technical expertise expected ads developers providing guidance assistance designers developers help implement principles remains open challenge options based existing studies present analysis put forward options listed options mostly organi sational procedural general sense term rather substantive positions matter rather result public debate issued expert groups however provide guidance criteria issues carefully considered adoption ads distinguish five complementary types options ads development dissemination knowledge ads raise complex questions entirely understood experts mention users people affected therefore prime importance develop interdisciplinary research ads research needed example ads security safety privacy fairness explainability addition stoa panel future science technology philosophers experts ethics social scientists lawyers computer scientists experts work together develop conceptual tools analyse ethical issues raised ads key condition facilitate research possibility provide research community access specific conditions strictest confidentiality datasets held public entities also private companies access right justified fact large amounts data nsidered public interest reason made clear reverse engineering purpose analysing explaining detecting biases ads considered lawful limited trade secret gen erally intellectual property right laws public debate benefits risks considering ads major impact society must subject public debate several conditions met ensure quality debate must involve stakeholders opinions interests means experts disciplines policy professionals ngos general public must conducted rigorous fashion without overshadowing key issues includ ing preliminary question legitimacy use ads context examined adapt legislation enhance accountability different types legal instruments used enhance accountability ads considering technology use evolve quickly area wise avoid hasty legislation could create problems solves new regu lation enacted matter properly understood recommended public debate taken place established existing laws insufficient address identified issues may case certain sectors quire regulation clarification application existing laws far enforcement concerned believe clear distinction made ethical committees mission stimulate discussion conduct debates publish recommendations operational bodies accreditation bodies certification agencies oversight agencies together provide framework monitoring certification oversight specific ads oversight agencies also power sanction operators non ads ethical committees operate general cross level operational bodies sectoral different application areas raise different issues different histories cultures sets practices regulations development tools enhance accountability ads designers developers experts privacy security fairness explainability therefore important provide tools meth odologies help reconcile tensions exist accuracy cost recommendation guides enough tools methodologies consider entire development cycle ads developed dis seminated similarly frameworks composed metrics methodologies tools assess impact ads test desired properties developed frameworks could used designers test ads third party entities certification authorities validate far users concerned better explanation facilities required particular interactive interfaces dialogue models effective validation monitoring measures gdpr introduc obligation data controllers conduct ata protection impact assessments dpia encourages certification mechanisms considering high stakes involved ads reason subject types precauti ons recommend particular ads deployed without prior lgorithmic impact assessment aia unless clear significant impact individuals lives certification ads encouraged even mandatory certain sectors understanding algorithmic decision opportunities challenges vii conducting aia easy task models tools proposed make easier report presents key issues considered aia legitimacy ads including legitimacy purpose techniques parameters qualities ads integration ads within human environment also clear aia focus risks using ads also assess risks ing ads words aia consider benefits risks finally certifications labels properly implemented way enhance trust ads verify comply certain rules absence bias dis crimination believe certification requirements obligations sectoral indeed needs risks vary greatly one type application another sectoral supervisory authorities agencies better position efine reference evaluation criteria control application deployment ads certification either voluntary basis encouraged gdpr mandatory certain areas justice healthcare conclusion conclusion study revisit study objectives put perspective argue transparency seen ultimate solution users people affected decisions ads since source code illegible experts transparency mainly benefits independent experts ngos evaluation bodies data protection authorities dpa audit certify ads example shown different meanings needs vary considerably according audience designers developers users affected people need level type explanation also important note requirements explainability vary one ads another according potential impact decisions made whether making process fully automated although transparency explainability essential reduce risks related ads argue accountability important requirement far protection individuals concerned fact transparency explainability may allow discovery deficiencies provide absolute guarantees reliability security fairness ads accountability achieved via complementary means aias auditing certification main virtue accountability put onus providers operators ads demonstrate meet expected requirements provide absolute guarantee either certification rigorous audits conducted regular basis potential issues discovered corrective measures taken addition sanctions significant enough accountability approach provides strong incentives ads providers careful design system perspective oversight agencies supervisory authorities play central role critical means necessary carry tasks means beyond funding expertise sho uld include right access analyse details ads including source code necessary training data finally believe appropriate accountability measures taken certain situations ads potential improve transparency reduce unfairness discrimination another benefit using ads one already observed put decisions front centre public debate decisions taken far citizens sight stoa panel future science technology viii table ontents introduction objectives methodology resources document structure scope objectives definitions examples ads opportunities risks related use algorithms opportunities risks individuals opportunities risks related principle equality benefits risks related principles privacy dign ity autonomy free opportunities risks related healthcare quality life wellbeing physical integrity opportunities risks public sector public services public safety security cyber democracy sovereignty opportunities risks private sector desiderata algorithms introduction main properties used document definitions terms used literature technical issues approaches ads safety understanding algorithmic decision opportunities challenges ads security attacks training phase attacks execution phase protections ads security attacks ads privacy extraction training data model extraction toward privacy solutions ads fairness various sources unfairness definitions fairness towards fairness algorithms ads explainability box approaches explainability box approaches explainability constructive approaches explainability qualities expl anations evaluation explainability challenges legal instruments european level general data protection regulation france law digital republic united states open questions remaining challenges ethical political debate stoa panel future science technology legal social perspective technical perspective policy options development dissemination knowledge ads public debate benefits risks ads adapting legislation enhance accountability ads development methodologies tools enhance ads accountability effective validation monitoring measures conclusion bibliography understanding algorithmic decision opportunities challenges introduction algorithms hardly recent invention nevertheless increasingly involved systems used support decision making known algorithmic decision systems systems often rely analysis large amounts personal data infer correlations generally derive information deemed useful make decisions human intervention decision may vary may even completely loop entirely automated systems many situations impact decision people significant access credit employment medical treatment judicial sentences etc entrusting ads make influence decisions raises vari ety different ethical political legal technical issues great care must taken analyse address correctly neglected expected benefits systems may counterbalanced variety risks individu als discrimination unfair practices loss autonomy etc economy unfair practices limited access markets etc society whole manipulation threat democracy different requirements transparency explainability data protection accountability often presented ways limit risks generally ill seldom required law difficult implement objectives study reviews opportunities risks related use ads present existing options reduce risks explain limitations sketch options overcome limitations able benefit tremendous possibilities ads limiting risks related use beyond providing systematic review situation report gives precise definition number key terms analysis differences helps clarify debate main focus report technical aspects ads however broaden discussion legal ethical social dimensions considered methodology resources methodology followed preparing document based traditional literature review including types scientific literature technical aspects includes articles published reviewed scientific journal conference proceedings surveys books science magazines also papers published reports pre papers scientific repositories reports recommendations studies published governmental agencies ethical committees data otection authorities dpa ngos think tanks general literature including newspapers magazines web sites information actual use ads benefits risks social acceptance distinctive feature domain covered udy rapidly evolving technical side also terms deployment impact society influenced choice analyse wide variety sources addition key issues explainability less extent fairness received enough attention research community past interest topics different research communities including computer science law increasing dramatically due development ads result large part work topic rather recent often yet appeared reviewed journals illustration first edition xai explainable stoa panel future science technology artificial intelligence workshop flagship artificial conference took place annual workshop human interpretability machine learning whi initiated workshop accountability transparency machine learning launched social political side plethora reports recommendations guidelines published various committees agencies reports rightly alert citizens policy potential risks posed artificial intelligen generally focus societal aspects discuss technical dimensions one goals study try bridge precisely gap first studying actual future uses ads associated opportunities risks analysing defining precise manner main requirements ads could reduce risks studying technical legal approaches meet aforementioned requirements analysing limitations approaches provid ing policy option address document structure chapter defines scope objectives study introducing key definitions provide examples ads categori according three classes correspond different bjectives stakes chapter analyses opportunities risks related use algorithms consider succession opportunities risks individuals section public sector section private sector section chapter defines desired properties ads reduce risks identified chapter many terms transparency explainability interpretability accountability often used different meanings context sake arity give precise definition notions considered study compare previous use literature chapter reviews technical issues solutions available meet desiderata presented chapter sections focus respectively safety security privacy sections devoted fairness explainability respectively chapter discusses briefly legal instruments enhance explainability privacy accountabil ity instruments presented chapter chapter useful far sufficient address challenges raised ads ads raise substantive issues yet fully understood need thoroughly analysed debated chapter analyses main existing challenges different complementary perspectives ethical political legal social technical finally chapter presents proposed options address challenges concludes study international joint conference artificial intelligence understanding algorithmic decision opportunities challenges scope objectives study focuses use algorithmic systems support decision practice use occur different situations different types impact example decisions may may automatic whether system used may decided affected persons imposed upon may may aware existence system etc general distinguish three types stakeholders designers algorithmic system operators users professionals individuals affected persons certain situations different roles played person example users recommendation systems also affected persons technically speaking making lgorithms also vary rely standard algorithms machine learning may involve different models decision trees bayesian networks neural networks etc decision algorithms increasingly used areas ccess information recommendation systems employment health justice policing banking insurance provide great benefits individuals organi sations public private sectors example lead better informed decisions discovery previously unknown correlations better patient treatment etc however also give rise variety risks discrimination unfairness manipulation privacy breaches objectiv report assess actual potential extent current use algorithms decision respective risks opportunities also future use report equally assesses potential solutions overc ome risks report emphasises need scrutini use algorithms decision whether algorithmic decisionmaking done transparent accountable way whilst main focus report technical aspects broaden discussion legal ethical social dimensions considered definitions algorithmic systems refer wide range applications techniques hereby consider following key concepts definitions algorithm algorithm unambiguous procedure solve problem class problems typically composed set instructions rules take input data return outputs example sorting algorithm take list numbers proceed iteratively first extracting largest element list largest element rest list list empty algorithms combined develop com plex systems web services autonomous cars algorithm hand programmer generated automatically data machine learning algorithmic decision system ads study focus specific type algorithm aimed supporting decision use generic expression algorithmic decision system ads stress fact algorithms studied general setting includes parameters context use rely machine learning training data ads whether based achine learning usually rely analysis variety data may assume varying degrees human involvement semi ads assist humans making decisions example assist doctors identifying diseases clinical setting data stoa panel future science technology complex sparse help mak ads also used take fully automated decisions automated metro systems often used make predictions estimate risks distinction sometimes drawn predictive prescriptive ads frontier two categories often fuzzy artificial intelligence although lack precise universally accept definition artificial intelligence usually conceived capacity machines resemble human intellectual abilities narrow weak designed perform specific task facial recognition product recommendation general strong aims outperforming humans across multiple domains machine learning multiple definitions machine learning andrew defines science getting computers act without explicitly programmed machine learning component provides systems ability automatically learn time generally large quantities data learning process based observations ata examples order identify patterns data make better predictions algorithm therefore seen algorithm data generates another algorithm usually referred model example amazon recommenda tion algorithm uses customers profiles learn products likely interest users visit amazon site recommendation model built system use profiles produce personali sed recommendations machine learni usually classified three types supervised learning relies labelled data train model model used predict given piece data part training data corresponding label used predic continuous value score regression discrete value word associated picture classification unsupervised learning require labelled data automatically identifies patterns structures training data example clustering reinforced learning relies exploitation feedback success failure received environment words takes actions environment maximi reward function examples ads many different ways categorise ads report propose following three classes correspond different objectives ads stake using ads aim improving general knowledge technology ads class use algorithms generate new knowledge generally analysis complex phenomena algorithms crucial context since used analyse large datasets extract knowledge example help improve climate forecasts detect zhe chong wang mei han yuan xue wei wei lia thoracic disease identification localization limited supervision peter stone rodney brooks erik brynjolfsson ryan calo oren etzioni greg hager julia hirschberg shivaram kalyanakrishnan ece kamar sarit kraus kevin leyton david parkes william press annalee saxenian julie shah milind tambe astro teller artificial intelligence life one hundred year study artificial intelligence report study panel stanford university doc daniel faggella machine learning nicola jones machine learning could help improve climate forecasts nature forecasts understanding algorithmic decision opportunities challenges discover new viruses ads used make decisions global impact impact society rather specific individuals ads aim improving developing new digital services applications category used help make predictions recommendations decisions various areas information finance planning logistics etc services aim optimi sing one several specific criteria time energy cost relevance information etc example navigation services help users identify optimal route destination taking parameters current traffic cost road conditions account new services intermediary platforms propose accommodation airbnb transportation alternatives uber exist years ago smart home applications deployed improve comfort optimi energy consumpti similarly quantified medical applications proposed help users improve health monitoring physical activities eating habits services use lot data complex algorithms models may address individuals also private publ services example new services deployed improve logistics optimal product placement stores optimal road constructions frequency refuse collection finance real auctions security automated detection vulnerabilities computer systems ads also used existing services context decisions far taken humans performed assistance directly ads example task allocation recruitment customer relationship management ads integrated within cyber physical systems within context ads used provide autonomy physical objects limiting human supervision examples autonomous cars robots weapons autonomous cars eing experimented world algorithms replace least assist users way operate vehicles make decisions behalf drivers goals essentially make roads safer optimi connection times similarly autonomous robots developed help replace humans performing difficult physical tasks work home examples include robots used factory chains domestic robots provide services humans robots batt lefield variety autonomous weapons development assist soldiers action limit collateral damage another way look ads consider users ads used individuals private public organi sations figur presents examples ads according two dimensions objectives users andre esteva brett kuprel roberto novoa justin sasan swetter helen blau sebastian thrun dermatologist classification skin canc deep neural networks nature amy maxmen machine learning spots treasure trove elusive viruses nature news compas correctional offender mana gement profiling alternative sanctions ads used jurisdictions predicts defendant risk committing crimes works proprietary algorithm considers answers questionnaire stoa panel future science technology figure examples applications ads objectives types users users objectives individuals private sector public sector improvement general knowledge drugs discovery climate weather forecast environment healthcare digital services quantified finance note taking smart home recommendations risk scoring payment systems targeting personali sed services predictive justice predictive policing hazard prediction infrastructure development planning physical systems autonomous cars home robots security personal assistants home autonomous robots autonomous weapons defence transport smart cities smart grids understanding algorithmic decision opportunities challenges opportunities risks related use algorithms chapter discuss benefits risks related use ads across three categories stakeholders ref erred previous chapter individuals private public sector note risks may intentional optimi interests operator ads accidental effects purpose ads without intent desi gner consequences errors inaccuracies ads people wrongly included blacklists fly lists due homonyms inaccurate inferences opportunities risks individuals first category stakeholders affected use ads individuals may benefit use ads may also face variety undesirable consequences distinguish three categories opportunities risks individuals opportunities risks related principle equ ality opportunities risks related principles privacy dignity autonomy free opportunities risks related health quality life wellbeing physical integrity opportunities risks related principle equality discrimination legal sense discrimination often put forward one primary risks related use ads consider ing ads used classify rank rate produce kind useful result inform decision process bound discriminate technical sense making distinctions people based certain features however certain types discrimination undesirable even prohibited law even though specific rules vary countries regulations identify specific factors must impact certain decisions example directive lays general framework combating discrimination grounds religion belief disability age sexual orien tation regards employment occupation view putting effect member states principle equal treatment similar vein convention protection human rights fundamental provides enjoyment rights freedoms set forth convention shall secured without discrimination ground sex race colour language religion political opinion national social origin association national minority property birth status fact ads lead discrimination documented many areas justice system targeted advertisements employment noted discriminations necessarily aris deliberate choices may result different types bias example bias training data case algorithm reproduces systematises already existing discriminations societal individual bias designers progra mmers ads council directive november establishing general framework equal treatment employment occupation convention protection human rights fundamental freedoms amended protocols stoa panel future science technology bias arising technical limitations computers difficulty formalise formal credit oring one domains studied use ads context significant impact individuals lives example national consumer law center released report june referring several studies dispara impact effect use credit scoring striking case figures rom missouri department showing significantly worse insurance scores residents minority zip codes even eliminating factors come education unemployment lisa rice deidre swesnik also report many examples discrimination communities colour resulting use credit systems one may argue credit scores perpetuate long history discrimination loan sector however disparate impact credit scoring goes far beyond sector credit scores fico score increasingly used different types context employment insurance rental accommodation addition stated lisa rice deidre swesnik credit mechanisms necessarily fair borrowers sense take features related individuals environment account issue bound become acute variety factors used assess risk scores increase growing amount information available web collected internet trackers example facebook filed patent could used banks decide deny loan individual average credit ranking friends given threshold spirit sentiment analysis based social network quantified information could used insurers personalise pricing example according swiss twitter data could reliable predictor heart disease traditional health socioeconomic measures discriminatory practices online services attracting increasing attention computer science community example using sunlight system mathias lecuyer colleagues show statistical confidence google services used protected attributes race religious affiliation health generate targeted advertisements spirit amit datta developed tool called adfisher used provide evidence discrimination based gender employment ads simulated males receive ads positions large salaries frequently simulated females batya friedman helen nissenbaum bias computer systems acm transactions information systems birny birnbaum credit scoring insurance costing consumers billions perpetuating racial divide national consumer law center lisa rice deidre swesnik discriminatory effects credit scoring communities color suffolk university law review robinson meyer could bank deny loan based facebook friends atlantic brenna hughes neghaiwi insurance big data could lower rates optimistic tweeters reuters stated authors however system assign intention either advertisers google targeting mathias lecuyer riley spahn yannis spiliopolous augustin chaintreau roxana geambasu daniel hsu sunlight targeting detection scale statistical confidence acm sigsac confere nce computer communications security ccs acm amit datta michael carl tschantz anupam datta automated experiments privacy settings privacy enhancing technologies pet credit scoring one studied domains use ads context strong impact individuals lives report national consumer law center shows significantly worse insurance scores residents minority zip codes missouri even eliminating factors income education unemployment understanding algorithmic decision opportunities challenges use certain ads also lead scrimination underprivileged minority neighbourhoods example geo applications designed avoid neighbourhoods could lead form redlining existing harmful negative stereotypes poor communities communities colour criticism raised predictive policing systems increasingly used police forces goal systems predict places crimes likely happen future based input data location timing previously reported crimes leaving quality predictions aside systems may produce self prophecies controls lead reported crimes reinforce disproportionate discriminatory policing practices discrimination justice another area raised much concern increasing reliance ads criminal justice system widely case system used assess individual risk levels recidivism violence failure appear compas scores used different stages criminal justice system decide whether release detain defendant trial whether grant parole offender study conducted led conclusion defendants far likely white defendants incorrectly judged higher risk recidivism white defendants likely black defendants incorrectly flagged low risk however propublica analysis received number criticisms academic community northpointe company developed compas particular alexandra shows difference false positive false negative rates identified propublica results difference proportion individuals reoffend across groups prevalence chouldochava even shows different fairness criteria satisfied simultaneously sam davies argue along lines showing error rate balance used propublica compatible predictive parity used northpointe predictive parity defined fact given threshold likelihood recidivism among high offenders regardless group membership measure ensures scores mean essentially thing regardless race reasonable expectation ads one conclusion drawn compas debate several definitions discrimination possible first sight may appear equally legitimate comment made domains application ads example credit mortgage markets different approaches discrimination rely rejection disproportionate rate rejection groups pricing different costs different groups default probabilities defaults different groups distinction also made group based measures discrimination similar acceptance rates similar levels revenues different groups joe silver turn application raci aclu correctional offender management profiling alternative sanctions jeff larson surya mattu lauren kirchner julia angwin analyzed compas recidivism algorithm propublica rebranded equivant alexandra chouldocheva fair prediction disparate impact study bias recidivism prediction instruments big data special issue social technical trad romei ruggieri multidisciplinary survey discrimination analysis knowledge engineering review example equal employment opportunity commission refers percent rule measure disparate impact success rate protected group hould less percent success rate group stoa panel future science technology individual level people similar profiles treated equally regardless group belong best done technical side state definitions clearly choice technical matter political options ethics beyond legal discrimination beyond discriminatory practices specific forms treatment considered unfair protected groups prohibited regulation ads also threaten strengthen equality different ways example certain situations personalised pricing price steering considered unfair cases sources new opportunities less favoured depending criteria used personalise process may considered acceptable example study conducted aniko hannak authors shows travel web sites reta sites personalise search results based operating system used researchers also shown online shops charge customers different prices depending another example uber users may experience big rice differences due small changes contrast discrimination personalised pricing illegal even though customers find unfair especially process opaque illustration revelat ion amazon charging different prices different customers based demographic data created discontent led ceo officially deny practices however economists also point price personalisation benefici economy also less sellers offer goods services lower price would possible uniform pricing ads reduce detect discrimination ads used support human decision making risk discrimination also compared risk discrimination without use ads human beings many sources bias affect decisions example study conducted one thousand jud icial rulings judges presiding parole boards israel shown ratio favourable rulings drops nearly zero session goes back break another area minorities often suffer discrimination police activities particular investigatory pedestrian stop sharad goel argue use ads police forces could reduce disparate racial impact increase efficiency stop practices addition would make police force accountable generally one could argue aniko hannak gary soeller david lazer alan mislove christo wilson measuring price discrimination steering web sites acm internet measurement conference imc frederik zuiderveen borgesius online price discrimination data protection law amsterdam law school legal studies research paper chen alan mislove christo wilson peeking beneath hood uber acm internet measurement conference imc matthew edwards price prejudice case consumer equality information age lewis clark law review shai danzinger jonathan levav liora avnaim extraneous factors judicial decisions pnas see also criticism paper authors reply pnas sharad goel maya perelman ravi shro david alan sklansky combatting police discrimination age big data new criminal law review one conclusion drawn compas debate several definitions discrimination possible first sight may appear equally legitimate best done technical side state definitions clearly choice technical matter political options ethics understanding algorithmic decision opportunities challenges potential benefit use ads avoid certain types human addition ads may enhance traceability therefore make easier detect bias fact decision procedure automated partly automated may also encourage public discussion criteria used system underlying logic expectations society respec particular terms fairness non several occurrences process already observed field justice compas also education public debate raised algorithm called ance apb used decide upon assignment students universities following debate apb discontinued replaced system leaving room human intervention necessary condition constructive public debate ailability minimum amount information algorithms discuss issue detail chapter conclude short review discrimination infringements principle equality clear topic great concern ads technological determinism area one hand ads used create new inequalities amplify hide discriminations hand also make discriminatory unfair practices traceable reduce chapter discuss technic instruments used realise second option benefits risks related principles privacy dignity autonomy free privacy previous sections reviewed potential impact ads terms different persons groups treated way turn attention potential impact individuals absolute terms particular autonomy free privacy ads bound source alienation threat indivi duals autonomy many detractors claim could also serve self free privacy data protection major issues respect since generally associated individual autonomy example referring german federal constitutional court census decision antoinette rouvroy yves poullet state court establishes clear direct link data protection regime two basic values enshrined constitution interpreting legal data protection regimes mere implementations fundamental constitutional rights first fundamental constitutional rights right respect protection one guaranteed article constitution second one right enacted article constitution fact court refer directly principles without mentioning already existing data protection law noticeable view major data protection principles derive directly two unless trained programmed use time key decision factor algorithms affected breaks apb stand post bac replaced new system called even though aspect privacy social dimension neglected julie cohen privacy autonomy information conf igur ing networked self ads used create new inequalities amplify hide discrimination hand also make discriminatory unfair practices traceable combat stoa panel future science technology constitutional provisions consecrate value autonomy self incommensurability dignity person society deploy ment ads may pose threat privacy data protection many different ways first related massive collection personal data required train algorithms personal data target variety attacks initiated differen parties data controllers employees cybercriminals states etc varying impact individuals financial psychological physical several frameworks proposed systematic analysis privacy perform data protection impact assessments required european general data protection one areas tremendous progress made last decade strong impact privacy image recognition techniques used many types ads particular identify people facial recognition applied images published also potentially pictures taken public places help police forces identify potential criminals generali sation would represent serious threat privacy illustration facial recognition already use shenzen chi identify fine notify jaywalkers via instant generally integration facial recognition within augmented reality glasses could lead end anonymity furthermore face recognition one amongst many ways identify people based physical features example considering human unique way walking gait analysis also applied identification authentication people technology also used legitimate reasons provide valuable support certain areas health example gait cycles provide useful information neurodegenerative diseases parkinson alzheimer disease chilling effect conformism even attack carried mere knowledge suspicion personal data people collected detrimental impact several studies provided evidence chilling effect resulting fear online surveillanc example certain wikipedia articles fall view counts observed edward snowden revelations june addition stated jonathon perrey graph still suggests ephemeral chilling effect dis sipates quickly rather data antoinette rouvroy yves poullet right informational self value self reassessing importance privacy democracy reinventing data protection serge gutwirth eds springer sourya joyee daniel métayer privacy risk analysis synthesis series morgan claypool publishers sourya joyee daniel métayer priam privacy risk analysis methodology international workshop data privacy management dpm ieee mina deng kim wuyts riccardo scandariato bart preneel wouter joosen privacy threat analysis framework supporting elicitation fulfilment privacy requirements requirements engineering david wright paul hert privacy impact assessment springer commission nationale des libertés cnil privacy impact assessment pia tools templates knowledge bases text omer faruk ince ibrahim furkan ince jang sik park gait analysis identification based joint information using rgb camera international conference electrical computer telecommunications information technology ecti jonathon penney chilling effects online surveillance wikipedia use berkeley technology law journal facial recognition applied monitor people create significant privacy threats however technology also used legi timate reasons provide valuable support certain areas health example gait cycles give information neurodegenerative diseases parkinson alzheimer disease understanding algorithmic decision opportunities challenges suggests lasting impact total article views spirit evolution towards scored society would inevitably generate conformity everybody trying comply explicit implicit norm obt benefits associated good scores example knowing suspecting banks analyse individual social network links deciding grant deny loan might tempt people adapt behaviour accordingly particular might decide stop interacting friends suspected low score would negatively impact score altogether impact scale surveillance scoring made possi ble ads would reduce range possibilities individuals therefore affect capacity reducing human beings numbers discussion scoring relate general fear humans increasingly treated numbers reduced digital profiles many signs advent scored society already observed use scores insurance banking employment many areas one extreme illustrations trend credit system currently experimented china become mandatory chinese citizen rated based wide variety informati credit history shopping habits interpersonal relationships score affect life many ways ability get loan also rent car without leaving deposit entitled faster check otels fast application get schengen visa etc addition aforementioned risks constant monitoring reduction human personality single number could seen form alienation offenc human dignity stated luciano floridi dignity rests able masters journeys keep identities choices open technology policy tends fix mould openness risks dehumanising unlike circe guests prevented leaving island filter bubble effect another surreptitious effect ads described filter bubble eli pariser according pariser personali sation web searches hinders creativity ability think limits diversity content people exposed oft quoted example result brexit vote unthinkable many anti voters based information seen campai comment made presidential election pariser states see posts folks like going surprised someone unlike wins presidency filter bubble obviou sly affect democratic life discussed section also hamper individuals reducing type information variety opinions exposed leading ideological confinement aggravating fact fact many individuals reali content see selected ranked algorithms example half participants study conducted facebook users danielle keats citron frank pasquale scored society due process automated predictions washington law review available ssrn rachel botsman big data meets big brother china moves rate citizens wired luciano floridi uman dignity foundation right privacy philosophy technology jasper jackson eli pariser activist whose filter bubble warnings presaged trump brexit guardian bubble trump stated luciano floridi dignity rests able masters journeys keep identit ies choices open technology policy tends fix mould openness risks dehumanising unlike circe guests prevented leaving island stoa panel future science technology aware news feed curation gorithm furthermore aware algorithm used filter rank information mean know ledge underlying logic algorithm reasons whcih specific piece content presented given person lack transparency opens door kinds manipulation undermine individuals autonomy either serve economic interests example case micro ads political purposes interest groups states try influenc voters little doubt potential impact content personali sation scale filter bubble effect practice still matter debate example frederik colleagues concluded study conducted observation spite serious concerns voiced present empirical evidence warrants strong worries filter bubbles indeed natural trend much amplified ads easy assess addition filtering could also used different transparent way provide individuals control content illustration approach social media aggregator allows users set param eters algorithm according want see example user define proportion political news matches challenges political perspective proportion serious fun news gobo still preliminary prototype shows ads also used broaden diversity information individuals exposed refore also contribute empowering people help reinforce rather undermine autonomy cases reason filtering compliance moral norms however precise nature considered morally acceptable may vary among cultures difficult implement automatically typical illustration issue difficulty facebook implement ban nude photographs facebook reverse decision alter results filtering algorithm face much protest censoring image venus willendorf one oldest pictures nude females history art pulitzer prizewinning photograph naked girl fleeing napalm bombs vietnam war type filtering perfectly legitimate even welcome certain situat ions example protect children certain types content concerns adults seen form paternalism restricting individuals autonomy challengin ads decisions another major issue opaque ads make difficult challenge decision based results contradiction example defence rights principle adversarial proceedings legal system majority jurisdictions judge duty state reasons decision based parties lawsuit right challenge decision beyond breach ing principle adversarial proceedings use ads courts law raises far reaching questions reliance predictive scores make legal decisions particular sentencing stated angèle christin motahhare eslami aimee rickman kristen vaccaro amirhossein aleyasen andy vuong karrie karahalios kevin hamilton christian sandvig always assumed really close reasoning invisible algorithms news feed conference human factors computing systems chi acm frederik zuiderveen borgesius damian trilling judith möller balazs bodo claes vreese tali helberger worry filter bubbles internet policy review homophily defined trend people associate others similar open information opinion confirming preconceptions influenced people similar use ads courts raises far reaching questions reliance pre dictive scores make legal decisions another major issue opaque ads make difficult challenge decision based results contradiction rights defence principles adversarial proceedings understanding algorithmic decision opportunities challenges authors even problematic theory justice impl icitly embedded algorithms point ads used context risk tools based number factors defendants criminal history sociological data demographic features provide estimation risk recidivism result privilege one objective incapacitation defined prevention reoffending detriment traditional justifications punishment law retribution taking account severity crime rehabilitation social reintegration deterrence two main approaches sentencing often distinguished deontological retributive approach utilitarian consequentialist approach deontological approach offenders punished deserve severity punishment proportional degree blameworthiness therefore risk future crime plays role sentencing decisions contrast risk assessment key instrument implement utilitari approach punishment justified ability decrease probability future crimes adverse side effects ads ads data analysis tools general provide individuals many new services example improve sel possibly adopt new healthy habits thanks quantified devices discover potential ways save money analysing shopping history learn new skills personali sed educational tools however ads used perform activities previously accomplished human beings may also adverse effects first threat employment many studies conducted types jobs threatened development contrasting conclusions seems unavoidable certain types jobs disappear many others transformed clear extent replaced new jobs data scientists ads experts issue merits study discuss study another adverse effect replacement human activities automatic systems loss skills expertise longer exercised typical example increasing number taxi dri vers unable find way city without navigation system development applications unlikely many people able write future least properly whether hand using keyboard current trend sustained experts also fear long term algorithms could outperform human beings areas possibly even take control dominate world possibility extreme scenario actually happe ning controversial relies transition weak artificial intelligence algorithms dedicated specific tasks strong artificial intelligence able perform essential human however whether unlikely unrea listic could least used dystopian scenario indication potential extreme risks assessed future artificial intelligence services tools opportunities risks related healthcare quality life wellbeing physic integrity benefits health ads impact healthcare quality life wellbeing even physical integrity individuals affected decisions ads already use medical sector potentially contribute mprove decisions taken practitioners specialists many ways angèle christin alex rosenblat danah boyd courts predictive algorithms data civil rights new era poli cing justice john monahan risk assessment criminal sentencing university virginia school law public law legal theory research paper series stoa panel future science technology medical imaging image analysis systems detect pathologies difficult identify even experts examples include quantitative retinal image analysis early identification melanomas skin cancer already detected images level accuracy comparable dermatologist diagnosis ibm watson used oncology departments suggest treatments options doctors cancer generally treatment recommendations especially useful rare diseases hat practitioners may never previously encountered surgery robots increasingly used help surgeons perform meticulous movements tight spaces greater dexterity personalised medicine easier future tailor treatment based medical history genetic lineage diet specific conditions patient similarly quantified medical applications developed help people improve health monitoring physical activities eating habits stated recent mitre report many impressive smartphone attachments apps currently available monitoring personal health devices empower individuals monitor understand health create larg corpora theory used applications capture health data shared clinicians researchers opacity issues stakes high health sector opacity often unacceptable example rich caruana report case ads based neural networks used health project lack intelligibility goal system predict level risk probability death patients pneumonia decide whether admitted hospital treated home neural network based ads predicted patients suffering asthm lower risk dying pneumonia prediction went knowledge experience doctors turns reflected bias training dataset patients asthma received intensive care effectively lowered risk dying pneumonia needless say ads used make decisions regarding admissions hospitals would put lives patients suffering asthma risk ads better respect intelligible could corrected avoid type bias produce results line experience professionals different types biases another risk use ads medical sector increase inequality due fact learning data often biased women elderly minorities less well represented control trials consequences may less likely receive right treatment symptoms match tho typical adult man generally pointed number experts use artificial intelligence also artificial intelligence health health care jason mitre corporation jsr rich caruana yin lou johannes gehrke paul koch marc sturm noémie elhadad intelligible models healthcare predicting pneumonia risk hospital readmission knowledge discovery data mining conference kdd acm image analysis systems detect pathologies difficult identify even experts examples include quantitative retinal image analysis early identification melanomas women elderly minorities less well represented control trials consequences may less likely receive right treatment sympto match typical adult man understanding algorithmic decision opportunities challenges raises ethical questions stated david magnus director stanford center biomedical ethics play health data three ways human bias bias introduced design bias ways health care systems use data easily imagine algorithms built health care system might reflective different onflicting interests algorithm designed around goal saving money different treatment decisions patients made depending insurance status ability pay hand promoting use artificial intelligence healthcare argue way overcome cognitive bias physicians biases inherent human decision typically include availability experience past cases anchoring relying initial diagnostic impression despite subsequent information contrary automatic control systems uses ads impact physical integrity individuals include automatic control systems cars planes underground rail systems ads positive negative impact situations positive impact potential lower rate accidents many situations automatic system indeed take reasonable decisions based mul tiple parameters much efficiently humans case autonomous vehicles difficult issues related fact supposed evolve human environments therefore capable reacting many unpredictable situati ons ethical discussions often based extreme scenarios dilemma running group pedestrians sacrificing driver lives passengers save pedestrians stated johannes himmelreich munda situations also raise complex subtle issues example design self cars needs balance safety others pedestrians cyclists interests cars passengers soon car goes faster walking pace unable prevent crashing child might run onto road last second walking pace course way slow everyone needs get places engineers strike balance safety mobility speed safe enough another related issue raised autonomous vehicles liability level driver control vehicle limited null take back control emergency liable case accident liable levels control characteri sed open questions kenneth abraham robert rabin make following statement verge another new era requiring another new legal regime time system transportation revolutionized time manually cars going jean bonnefon azim shariff iyad rahwan social dilemma autonomous vehicles science even though society automotive engineers sae defined levels automation see footnote stoa panel future science technology replaced automated vehicles new era automated vehicles eventually require legal regime prop erly fits radically new world auto accidents recent report future privacy forum includes summary potential harms individuals related use ads covers many issues discussed section harms listed igure grouped four broad categories loss opportunity economic loss social detriment loss liberty future privacy forum report focuses harm discuss opportunities consider certain aspects issues opacity specific risks raised automatic control systems addition distinction illegal unfair based law needs challenged nevertheless type classification useful context algorithmic impact assessments aia suggested chapter kenneth abraham robert rabin automated vehicles manufacturer responsibility accidents new legal regime new era virginia law review forthcoming understanding algorithmic decision opportunities challenges figure potential harm caused automated decision source opportunities risks public sector use ads also bring many new benefits risks public sector following section distinguish stake using ads four different public sector activities peter stone rodney brooks erik brynjolfsson ryan calo oren etzioni greg hager julia hirschberg shivaram kalyanakrishnan ece kamar sarit kraus kevin leyton david parkes william press annalee saxenian julie stoa panel future science technology public services public safety security cyber safeguard ing democracy national sovereignty public services ads currently used government public agencies provide new services improve existing ones many areas energy education healthcare transportation justice systems security examples applications ads context predictive policing smart metering video protection iversity enrolment also contribute improving quality healthcare education job skill training ads smart technologies general mobility management tools water energy management systems enhance city manag ement example help lower energy consumption reduce traffic congestion pollution improve waste management ads make government agencies efficient help increase quality services also contr ibute administration decisions making transparent accountable provided however transparent accountable see chapter ads specifically techniques also contribute society producing new know ledge example researchers used algorithms discover nearly previously unknown species virus healthcare analytics potential revolutioni medical sector analysing clinical records millions patients enable personali sed diagnosis treatment similarly mentioned section emergence mobile health exploits data collected patient smartphone promising however developments come important risks privacy data used train systems leaked misused example health insurance companies furthermore another important hindrance adoption healthcare analytics opacity ads results issue conce rns many applications ads discussed chapter ads create many new security vulnerabilities exploited people malicious intent particular hackers foreign organi sations since ads play pivotal role workings society nuclear plants smart grids hospitals cars example hackers able compromise systems capacity cause major damage furthermore systems harder protect since attacks likely become automated complex risk cascading failures harder predict smart adversary may either attempt discover exploit existing weaknesses algorithms create one later exploit could achieved poisoning attack interfering training data machine learning used addition attackers might also use algorithms automatically identify vulnerabilities optimis attacks studying learning real tim systems target shah milind tambe astro teller artificial intelligence life one hundred year study artificial intelligence repo study panel stanford university amy maxmen machine learning spots treasure trove elusive viruses nature news ads contribute making administration decisions efficient transparent accountable provided however transparent accountable understanding algorithmic decision opportunities challenges security failures may also occur accidentally without malicious intent deployment ads large scale accidents autonomous cars running pedestrians concrete threats must considered order prevent loss trust transport systems automated systems general public safety security ads help improve security infrastructures already used offer better protection sophisticated security threats help automate complex processes detect attacks undertake countermeasures example data deception technology used trick attackers analyse behaviours take defensive actions advanced attac also used detect white crimes money laundering credit card fraud many cities already using ads public safety security deploying surveillance cameras face recognition drones predictive licing applications technologies may help police target activities prioritise tasks solve crime cases however systems come significant risk privacy surveillance technologies may become overwhelming oppressive furthermore potentially amplify bias stigmatisation disparate impact citizens addition ads operate boxes therefore lack transparency making efficiency debatable example promise predictive policing tell officers areas highest risk future crimes using complex algorithms past crime data however according study system may merely reinforce bad polic ing habits historically communities thereby creating new sources tension cyber ads already use cyber bound play increasing role area existing machine learning technologies enable high degree automation intensive activities satellite imagery analysis ambitious controversial use ads context build autonomous weapon systems number countries increasing studies development systems perform increasingly elaborate functions including identifying killing targets little human oversight control autonomous weapon systems reduce casualties replacing human soldiers dangerous missions protecting example potentially harmful chemical substances furthermore may efficient certain tasks subject physical physiological mental constraints also limit collateral damage thanks grain targeting capabilities finally autonomous eapons help reduce sam levin julia carrie wong self uber kills arizona woman first fatal crash involving pedestrian guardian march accessing july amodei dario olah chris steinhardt jacob christiano paul schulman john mane dan concrete problems safety eprint even though one may argue could also mitigate human decision biases lum isaac predict serve significance doi surveillance ads may help police target activities prioritise tasks solve crime cases however systems come significant risk privacy however may also amplify bias stigmatisation disparate impact citizens july open letter calling ban autonomous weapons released artificial intelligence scientists experts stoa panel future science technology however using ads context obviously raises serious moral issues voices raised type application example july open letter calling ban autonomous weapons rele ased artificial intelligence scientists experts letter warns intelligence technology reached point deployment systems practically legally feasible within years decades stakes high autonomous weapons described third revolution warfare gunpowder nuclear arms development autonomous weapons hard control proliferation risk furthermore since powerful affordable conventional weapons may fall hands dangerous organi sations terrorist groups finally since autonomous weapons embed many algorithms prone attacks actually deployed risk malfunctioning error misuse first carefully addressed democracy sovereignty note public sector may also impacted ads deployed entities private stakeholders foreign powers illustrative example deployment waze system waze smartphone travel application find best path destination usually suggesting routes main roads side streets residential areas upsets residents goes goal city planners keep cars main axes biggest problem comes fact private organi sations like waze goals city planners source tension potential risk ads within context whereby public agencies accept certain choices made influenced private ads means may lose control sovereignty public policy decisions ads however make positive contribution democracy example allowing people express opinions social networks make accessible wide audience potentially interested people however technologies may used states control people example identifying political opponents trying timidate generally states interest groups could tempted use technologies influence citizen behaviours could lead called anticipative conformism antoinette rouvroy technologies also used distort information order damage integrity democratic discourse reputation government political leaders seems new form propaganda used alleged russian operation influence usa presidential election leverages social media targeted advertising psychological profiling propagation fake news using bots automated fake social network accounts strategic side small group nations companies investing massively research likely achieve dominance related technologies could amitai etzioni oren etzioni pros cons autonomous weapons systems military review autonomous weapons open letter robotics researchers future life institute july elizabeth weise waze traffic dodgin apps prompt cities game algorithms usa today antoinette rouvroy end critique data behaviourism due rivacy due process computational turn routledge main problem stems fact private stakeholder goals city planners source tension potential risk ads context loss control public agencies decisions understanding algorithmic decision opportunities challenges lead strong imbalance power global technological monopolies may threaten sovereignty many countries able rely technological means could lead frustration citizens create international tension opportunities risks private sector opportunities ads particular endless private sector risks also numerous task repetitive pressured time could benefit analysis high volumes data prime target ads tasks concern low well high lyskilled personnel example sectors like banking insurance justice efficient robust systems based machine learning replaced standard algorithms setting inventory levels optimi sing supply chains many companies finance ads used decide trades execute high speed trading systems increasingly credit decisions also made help ads example jpmorgan chase deployed system reviewing commercial loan contracts performing wha took loan officers hours seconds sites employ ads optimi inventory improve product recommendations customers companies mastercard using facial recognition tools allow pay ace also use elaborate analytics systems predict whether user likely click particular vertisement improve online vertising placement targeting supervised learning systems used pharmaceutical indu stry develop better personali sed drugs finally application ads concerns companies potential improve security automatically detecting malware points represent small selection examples use ads private sector general ads driving changes three levels industry tasks business processes business models example task redesign use vision systems detect degradation end life mechanical component leaving time technicians focus potential problems example process redesign modification workflow layout packing warehouses following introduction robots optimi sation algorit hms company finally car sharing services example new business model would possible without ads although ads highly beneficial come risks private sector particular results ads often difficult explain reduce consumer trust creates four main risks may biases derived data provided train system difficult detect correct cases biases characteri sed discriminations sanctioned court difficult impossible prove system always provide correct outputs especially scenarios represented training data lack verifiabil ity concern mission applications case failure might difficult given models complexity diagnose correct errors establish responsibilities stoa panel future science technology finally previously mentioned malicious adversa ries potentially attack systems poisoning training data identifying adversarial examples attacks difficult detect prevent risks real must recognised human beings also biases mak mistakes always rational decision process really transparent advantage ads respect audited systematically disadvantage amplify biases errors make difficult allocate liabilities conclude section two systemic risks related use ads first ads likely affect company organi sation management expression industrial revolution coined describe dramatic change certain types jobs change enormously longer exist whilst new ones appear economists argue automation supplant jobs manufactu ring also offer opportunities replace rewarding ones jobs might affected jobs need advanced level education expertise example hairdressers probably less likely affected tha accountants lawyers doctor using ads scan medical data monitor patients still need interact patients treat diseases impact revolution obviously limited private sector social political education training systems need adapted finally ads drive innovation making possible analyse large data sets develop new services create new business opportunities large small players said ads require lot data many datasets lie hands small group dominant players furthermore trend large tech companies buy promising productivity requires compet ition risk current concentration market vinod iyengar consolidation create worst monopoly history techcrunch human beings also biases make mistakes always rational decision process really transparent advantage ads respect audited systematically disadvantage amplify biases errors make difficult allocate liabilities understanding algorithmic decision opportunities challenges desiderata algorithms chapter review main approaches proposed literature reduce risks identified chapter approaches rely notions transparency explainability interpretability accountability used varied meanings literature sake clarity first define concepts considered report precisely section comparing definitions terms used literature section introduction main properties used document several key properties generally required enhance trust algorithmic systems safety defined absence error system especially errors cause damage algorithms safety seen capacit deliver correct results results consistent specifications absence adversarial attack security defined protection system adversarial attacks could threaten integrity disrupt services typical objectives adversary breach properties confidentiality integrity availability sometim represented cia acronym privacy relies protection personal data contrast security privacy threatened custodian personal data victim data subject rather organisation holds data requirements apply equally ads algorithmic system however ads specific types algorithms strong impact individuals discussed chapter therefore also meet additional requirements classified two main categories intrinsic requirements fairness absence bias discrimination expressed properties algorithm mathematical function inputs outputs application context discussed section different properties proposed capture requirements choice specific property technical subjective contextual political property defined checked posteriori verification established priori design report equate undesirable bias characterise discrimination specific form unfairness related use specific types data ethnic origin political opinions gender use discriminatory features prohibited law certain types context credit employment housing etc specific list prohibited attributes contexts precise means assess discrimination depend national laws jurisdictions extrinsic requirements understandability defined possibility provide comprehensible information link inputs outputs ads information take many different forms depending recipients designer ads user person affected decisions auditor etc level expertise objectives two main forms understandability considered literature legal point view privacy distinguished personal data protection make distinction refer privacy general sense stoa panel future science technology transparency defined availability ads code design documentation parameters learning dataset ads rely machine learning transparency necessarily mean public availability also encompass cases code disclosed specific entities audits verifications explainability defined availability explanations ads contrast transparency explainability requires delivery information beyond ads several explanation modes distinguished explanations three different types operational informing system actually works logical informing logical relationships inputs results causal informing causes results explanations either global whole algorithm local specific results explanations take different forms decision trees histograms picture text highlights examples counterexamples strengths weaknesses explanation mode assessed relation recipients explanations professional individual level expertise objectives understanding results make decision challenging decision verifying compliance legal obligations nutshell two forms understandability correspond two strategies show transparency explain explainability accountability another key desideratum often put forward context ads reuben defines accountability follows party accountable party respect conduct obligation provide justification may face form sanction finds justification inadequate binns also notes context algorithmic decision accountable decision must provide decision reasons explanations design operation automated decision system therefore accountability seen requirement process obligation provide justification applies two categories requirements ads discussed intrins extrinsic requirements case corresponding specific types justifications proof discrimination source code local global explanation another essential facet accountability possibility sanctions also orthogonal two intrinsic extrinsic categories requirements riccardo guidotti use expressions model explanation explanation refer respectively global explanations local explanations riccardo guidotti anna monreale franco turini dino pedreschi fosca giannotti survey methods explaining black box models reuben binns algorithmic accountability public reason philosophy technology understanding algorithmic decision opportunities challenges definitions terms used literature many papers use terms transparency explainability interpretability accountability fairness different mea nings without defining properly often without introducing clear distinctions place definitions within general context focus remainder section alternative definitions interpretations terms used literature compare summary variations presented figure fairness sometimes defined fact provider ads misrepresent functionalities divert gainst interest users ads people affected version fairness subjective requirement behaviour claims provider ads requirement ads therefore stick restrictive definition fairness introduced section transparency used different meanings literature ranging specific obligation disclose code algorithm learning dataset ads relies machine learning generic interpretation encompassing means reduce opacity ads illustration first trend mike ananny kate provide single definition transparency describe several types transparency upwards versus downwards outwards versus inwards event versus process discuss several limitations transparency tool accountability including fact seeing inside system necessarily mean understanding behavio ori gins also argue ideal transparency places tremendous burden individuals seek information system interpret information determine significance sake clarity use specific rest rictive meaning makes possible highlight differences transparency explainability accountability words respectively showing explaining justifying contrast zachary seems refer transparency explanation operational aspects ads ads actually works opposed explanation results calls post interpretability distinction makes operational transparency hoc interpretability difference processes humans make decisions explain terms report lipton hoc interpretability corresponds logical explanations opposed operational explanations explainability interpretability lilian edwards michael veale introduce two categories explanations model subject explanations according efinitions explanations provide broad information model decision input specific whereas explanations built around basis comment permettre garder main les enjeux éthiques des algorithmes artificielle cnil report mike ananny kate crawford seeing without knowing limitations transparency ideal application algorithmic accountability media society zachary lipton mythos model interpretability icml workshop human interpretability machine learning whi lilian edwards michael veale slave algorithm right explanation probably remedy looking duke law technology review available ssrn use restrictive meaning transparency makes possible highlight differences transparency explainability accountability respectivel showing explaining justifying stoa panel future science technology input record distinction corresponds notions global explanations whole algorithm local explanations specific results riccardo guidotti argue notions interpretability explainability comprehensibility strongly interrelated interpret means give provide meaning explain present understandable terms concept therefore data mining machine learning interpretability defined ability explain provide meaning understandable terms human definitions assume implicitly concepts expressed understandable terms composing explanation self need explanations essentially explanation huma decision maker time accurate proxy decision maker comprehensible humans dhurandhar also consider interpretability synonym explainability human perspective interpretability ypically means model explained quality imperative almost real applications human responsible consequences model accountability characteri sation accountability document recently issued world wide web general policy consistent interpretation usually referred duty governments authorities present whose interest represent otherwise bound justify power exercised resources used noted world wide web foundation previously nicholas diakopoulos transparency mechanism facilitates accountability distinction transparency accountability also stressed lilian edwards michael veale sometimes almost unthinking association transparency accountability two synonymous accountability contested oncept essence involves party held account justify actions field questions others face appropriate consequences transparency beginning process emphasis justification sanctions line constitutive elements accountability discussed mark bovens accountability also introduced basic principle data protection regulation since publication oecd guidelines protection privacy transborder flows personal riccardo guidotti anna monreale franco turini dino pedreschi fosca giannotti survey methods plaining black box models amit dhurandhar vijay iyengar ronny luss karthikeyan shanmugam formal framework characterize interpretability procedures icml workshop human interpretability machine learning world wide web foundation algorithmic accountabilit july nicholas diakopoulos accountability algorithmic decision making communications acm lilian edwards michael veale slave algorithm right explanation probably remedy looking duke law technology review available ssrn mark bovens analysing assessing accountability conceptual framework european law journal understanding algorithmic decision opportunities challenges however oecd guidelines contain precise definition term noted charles raab word accountability often equated responsibility liability european languages mainly differences legal systems term easily translated consequence risk varying interpretations term thereby lack harmoni sation substantial words used apture meaning accountability reinforced responsibility french rendre des comptes principle accountability article data protection working party observes term accountability comes anglo world common use broadly shared understanding meaning even though defining exactly means practice complex general terms though emphasis showing responsibility exercised making verifiable responsibility accountability two sides coin essential elements good governance responsibility demonstrated working effectively practice sufficient trust developed key aspect accountability shared definitions therefore obligation justify applies different types requirements discussed organisation economic development guidelines protection privacy transborder flows personal data precise wording guidelines following data controller accountable complying measures give effect principles stated charles raab meaning information privacy context managing privacy throu accountability daniel guagnin eds palgrave macmillan article data protection working party opinion principle accountability stoa panel future science technology figure summary alternative definitions found literature definitions terms definition used report alternative definitions found literature fairness absence undesirable bias misrepresentation functionality system transparency availability public controlled ads code design documentation parameters learning dataset generic meaning means reduce opacity including code availability explainability specific meanings focusing code availability explainability operational aspects explainability availability explanations ads explanations global local different types operational logical causal take different forms decision trees rules counterexamples etc global versus local explanations sometimes called model centric versus subject interpretabilit understandability sometimes used synonyms explainability closely related notions accountability obligation provide justification decision possibility face sanctions justifications inadequate existing efinitions focus justifications sanctions even though uses term vague seem equate accountability responsibility liability understanding algorithmic decision opportunities challenges technical issues approaches chapter review technical issues solutions available meet desiderata presented section sections focus safety security privacy respectively section devoted fairness explainability considering disclosure code design documents raise legal technical issues transparency discussed chapter ads safety safety important issue consider especially case ads embedded physical systems whose failure cause fatal damage thi section use word accident harmful behaviour may emerge systems specify wrong objective function careful learning process commit machine learning implementation errors lot discussio extreme scenarios risk super risk machine intelligence surpassing human however probably useful stage discuss risks less speculative scenarios illustrative examp failure deserves attention tesla autonomous car accident driver died fatal crash using autopilot mode case embedded sensors failed distinguish white tractor crossing highway bright sky type accident identified addressed ads deployed large scale amodei authors expl ore several types accidents related machine learning present relevant research directions protect paper illustrates type accident fictional robot designed clean office negative side effects ads trying achieve goal causes unintended negative consequences environment example robot may knock vase moving another example ads negative side effects waze service often routes uggested waze residential areas creating anger frustration residents city planners one potential solution problem develop gurses call protection optimisation technologies pots pots analyse ents affect users environments manipulate influence system outcomes altering optimi sation constraints poisoning system inputs another direction protection amodei dario olah ris steinhardt jacob christiano paul schulman john dan concrete problems safety nick bostrom superintelligence paths dangers strategies oup oxford danny yadron dan tynan tesla driver dies first fatal crash using autopilot mode guardian dario amodei chris olah jacob steinhardt paul christiano john schulman dan mane concrete problems safety elizabeth weise waze traffic dodging apps prompt cities game algorithms usa today seda gurses tebekah overdorf ero balsa pots revolution optimized tesla autonomous car using autopilot mode involved fatal crash autopilot sensors car failed distinguish white tractor crossing highway bright sky stoa panel future science technology penalise systems according detrimental impa environment approaches could mitigate accidents anticipated protect unanticipated ones reward hacking ads might game reward function increase reward unintended way example cleaning robot might hide dust materials see note ads point view strategy valid way meet objectives amodei propose several preliminary approaches prevent reward hacking suggest using multiple awards might improve robustness since might difficult game another proposed approach simply cap maximum possible reward authors admit difficult fully solve problem several protection approaches probably combined make ads robust respect scalable oversight ads need trained able solve complex tasks example cleaning robot learn handle candy wrappers differently stray cell however objective function might expensive evaluate frequently training data might available challenge ensure ads finds way right thing despite limited resources information amodei propose potential countermeasures semi reinforcement learning systems safe exploration sometimes ads need engage exploration take actions learn environment update model however exploration may involve performing dangerous act ions cleaning robot putting mop electrical outlet common exploration policies may choose actions random view unexplored actions optimistically towards ads goals anticipated known dangerous actions designers course make sure avoided however complex domains anticipating possible dangerous actions challenging impossible amodei propose several approaches mitigate risks one proposal confine exploration safe actions another one use simulated exploration robustness distributional change problems may occur training environment match operational environment shift operational environ ment time example speech recognition system trained clean speech perform poorly noisy speech similarly cleaning robot trained clean factory floors likely perform poorly used clean offices one class potential pproaches train specialised ads specific environments another approach problem assume partially specified model assumptions aspects distribution made finally another approach train multiple distributions hope ads also perform well real environment many failures described addressed hoc solutions strong need define unified approach prevent ads causing unintended harm minimum requirement perform extensive testing evaluation scale deployment also important provide accountability including possibility independent audits discussed chapter ensure form human oversight cleaning robot might hide dust materials see ads point view strategy valid way meet objectives understanding algorithmic decision opportunities challenges ads security discussed chapters ads increasingly used critical contexts therefore important guarantee secure malicious adversaries objectives adversary might breach confidentiality integrity availability ads goal confidentiality attack extract part ads internal state typically data model example adversary may want retrieve ome data used train model get information model attacks may impact privacy intellectual property attacks integrity alter results provided ads adversary may want mod ify outputs ads example make gain get advantages loan job finally attacks availability disrupt services provided ads adversary might want example prevent ads operating norma lly altering parameters performing denial service attack dos since ads rely heavily algorithms rest section consider security properties context algorithms furthermore confident ially property related privacy addressed following section illustrate one may consider ads built using algorithm trained given dataset seen igure adversary threaten integrity ailability ads different ways attacking training dataset example injecting fake data attacking algorithm exploiting generated model ads time figure different types integrity attacks systems stoa panel future science technology attacks algorithm sometimes called attacks require adversary physical access systems algorithm running attacks specific ads mitigated various security measures access control hardware security measures discussed focus attacks target training datasets section generated model section possible protections attacks section attacks raining phase goal attack training phase influence generated model compromising integrity availability integrity attacks alter generated odel towards specific goal example maliciously obtain loan intrusion detection system ids classifier goal integrity attack could assign incorrect class legitimate input contrast ava ilability attacks tend affect quality performance access system final goal may create sufficient errors make ads unusable although goals different attacks similar nature typically perform altering poisoning training dataset injecting adversarial data injection attacks removing modifying existing records modification attacks modification performed supervised setting modifying data data note attacks require adversaries access processed training dataset possible adversary poison inject training data processing example perdisci showed possible prevent work signature detection tool learning valid signatures polluting worm traffic data attacks execution phase attacks execution phase intend modify ads generated model instead seek exploit weaknesses idea compute inputs called adversarial examples trigger desired incorrect outputs ads classifier adversary seeks perturbed inputs assigned incorrect classes example image recognition system presented igure system successfully recogni ses panda however adding lit tle bit noise authors study show resulting image still looks like panda human misclassified algorithm gibbon marco barreno blaine nelson russell sears anthony joseph doug tygar machine learning secure acm symposium information computer communications security asiaccs acm battista biggio blaine nelson pavel laskov support vector machines adversarial label noise asian conference machine learning marius kloft pavel laskov online anomaly detection adversarial impact international conference artificial intelligence statistics roberto perdisci david dagon wenke lee prahlad fogla monirul sharif misleading worm signature enerators using deliberate noise injection ieee symposium security privacy ieee christian szegedy wojciech zaremba ilya sutskever joan bruna dumitru erhan ian goodfellow rob fergus intriguing properties neural networks international conference learning representations computational biological learning society patrick mcdaniel nico las papernot berkay celik machine learning adversarial settings ieee security privacy understanding algorithmic decision opportunities challenges figure demonstration fast adversarial example generation pplied googl enet imagenet source adding imperceptibly small vector whose elements equal sign elements gradient cost function respect input one change oogl enet classification image attack example exploited adversary image recognition system example sharif developed inconspicuous attacks biometric systems allow attacker evade recognition impersonate another individual attacks illustrated figure carried printing pair spectacle frames allow attacker evade recognition dodging attack even impersonate another individual mpersonation attack figure impersonation using spectacle frames left actress reese witherspoon image classified correctly probability middle perturbing frames impersonate actor russell crowe right tar get russell crowe source without much explanation technical details attacks work perturbing input smallest possible noise resulting adversarial example remains correct input domain assigned wrong label adversarial examples mahmood sharif sruti bhagavatula lujo bauer michael reiter adversarial generative nets neural network attacks state face recognition mahmood sharif sruti bhagavatula lujo bauer michael reiter accessorize crime real stealthy attacks state face recognition acm sigsac conference computer communications security acm stoa panel future science technology possible ads model perfect perfectly match actual decision model illustrated figure shows system classifies images pandas gibbons black line defines human decision boundary dotted line defines model decision boundary since ads model perfect decision boundary exactly match human decision boundary shown figure therefore possible manipulate image panda adding little bit noise moves outside model decision boundary therefore classified gibbon remains within human decision boundary seen panda human goodfellow introduced fast gradient sign method generate adv ersarial examples follow work optimis method reducing perturbation minimis ing number perturbed features figure image classification system ibbons versus andas figure generating adversarial examples images within area delimited black line pandas whereas images outside boundary gibbons images within area delimited dotted line classified mod pandas whereas images outside boundary classified gibbons ian goodfellow jonathon shlens christian szegedy explaining harnessing adversarial examples international conference learning representations computat ional biological learning society seyed moosavi alhussein fawzi pascal frossard deepfool simple accurate method fool deep neural networks nicolas papernot patrick mcdaniel somesh jha matt fredrikson berkay celik ananthram swami limitations deep learning adversarial settings ieee european symposium security privacy ieee understanding algorithmic decision opportunities challenges adversarial examples typically constructed perturbing input data however shown recent paper also possible define class adversarial examples synthesi sed entirely using conditional generative model note previous attacks assume box scenarios attackers access internal workings model however black box scenario probably realistic threat model xample attacker wants attack image recognition system spam filter rarely access internals model instead often access system oracle query ads inputs observ generated outputs attacks box systems also called box attacks challenging impossible key property respect adversarial example transferability property exploited whereby advers arial examples crafted given classifier likely misclassified models trained task intriguingly property holds even models trained different datasets papernot designed box atta based property proposed attack queries ads exploits results generate substitute model substitute model used craft adversarial examples misclassified ads protections ads security attacks attacks training phase defence mechanisms attacks training phase rely fact poisoning samples outliers typically side expected input distribution rubinstein propose solution poisoning attacks relying techniques robust statistics show poisoning little effect robust model whereas significantly distorts model produced original rincipal component analysis pca method another proposal secure training phase relies regulari sation optimi sation problems solved train models technique effect smoothing solution removes complexity adversary may try exploit authors also propose use disinformation techniques alter data seen adversary prevent learning decision boundaries finally suggest using randomi sation placement boundary order make attacks difficult attacks execution phase two main strategies used protect ads adversarial examples first strategy reactive attempts detect adversarial examples solutions category include adversarial detecting input network yang song rui shu nate kushman stefano ermon generative adversarial examples szegedy zaremba sutskever bruna erhan goodfellow fergus intriguing properties neural networks papernot mcdaniel goodfellow jha celik swami practical black attacks deep learning systems using adversarial examples rubinstein nelson huang joseph lau taft tygar antidote understanding defending poisoning anomaly detectors acm sigcomm conference internet measurement acm barreno nelson sears joseph tygar machine learning sec ure acm symposium information computer commu nications security acm metzen genewein fischer bischoff detecting adversarial perturbations international conference learning representations iclr rigazio towards deep neural network architect ures robust adversarial examples international conference learning representations iclr stoa panel future science technology second strategy proactive aims making systems robust adversarial examples solutions category include network adversarial classifier robustifying due variety adversarial examples several defence strategies performed together parallel sequentially deal scope document present solutio detail information defence mechanisms refer interested readers survey papers papernot yand however worth noting existing defence solutions unsatisfactory recent study ana lysed ten detection proposals showed defeated effective solutions still need proposed evaluated ads privacy adversary may want compromise confidentiality ads example trying extract infor mation training data retrieving ads model attacks raise privacy concerns since training data often contain personal data may also undermine intellectual property ads model training data propri etary confidential owner rest section describes two types attack presents solutions protect ads extraction training data attackers may want retrieve data used train stem two main types scenarios considered box attacks rely assumption attacker access model tries learn training data inverting box attacks assume access model adversarial client submit queries model make predictions based answers research work area focuses box attacks realistic powerful fredrikson defined model inversion attack context genomic privacy able use box access prediction models estimate aspects genotype person attack works setting whic inferred feature drawn small set follow work fredrikson demonstrated confidence katz barrett dill julian kochenderfer reluplex efficient smt solver verifying deep neural networks papernot mcdaniel jha swami distillation defense adversarial perturbations deep neural networks ieee symposium security privacy ieee goodfellow shlens szegedy explaining harnessing adversarial examples bradshaw matthews ghahramani adversarial examples uncertainty transfer testing robustness gaussian process hybri deep networks nicolas papernot patrick mcdaniel arunesh sinha michael wellman towards science security privacy machine learning ieee european symposium security privacy xiaoyong yuan pan qile zhu rajendra rana bhat xiaolin adversarial examples attacks defenses deep learning nicholas carlini david wagner adversarial examples easily detected bypassing ten detection methods acm workshop artificial intelligence security fredrikson lantz jha lin page ristenpart privacy pharmacogenetics end case study personalized warfarin dosing usenix security symposium fredrikson jha ristenpart model inversion attacks exploit confidence information basic countermeasures acm sigsac conference computer communications security acm understanding algorithmic decision opportunities challenges information returned many classifiers enables new model inversion attacks ateniese showed possible infer formation classifier training sets building novel meta training hack classifiers membership attack specific type model inversion attack attacker seeking test whether given point used training dataset shokri show conduct type attack box models proposed attack turns machine learning training attack model distinguish target model outputs members versus non members training dataset basically turn membership inference problem classification problem successfully demonstrated attack box models trained cloud using google prediction api amazon model extraction attackers may also seek recover information model ads generally assumed attackers freely query ads observe outputs model extraction attacks may undermine rivacy since discussed model used retrieve training data may also intellectual property implications model proprietary remain confidential tramer show extract parameters model successful attacks rely information returned prediction apis cloud services provided google amazon microsoft services return highprecision confidence values addition class labels querying random inputs attacker high probability solve unknown parameters defining model model extraction attack although simple non applied many systems obvious countermeasure restrict information provided services information may interest users toward privacy solutions various proposals made address privacy attacks presented sections anonymising training datasets generated models designing preserving algorithms anonymisation model frequently used context differential privacy rigorous framework anonymise analyse privacy guarantees provided algorithms example abadi introduce algorithm convex deep learning models strong differential privacy guarantees ateniese mancini spognardi vill ani vitali felici hacking smart machines smarter ones extract meaningful data machine learning classifiers international journal security networks shokri stronati shmatikov membership inferenc attacks machine learning models ieee security privacy tramer zhang juels reiter ristenpart stealing machine learning models via prediction apis usenix security dwo roth algorithmic foundations differential privacy foundations trends theoretical computer science abadi chu goodfellow mcmahan mironov talwar zhang deep learning differential privacy acm ccs stoa panel future science technology order reduce risk data leakage proposals rely distribution lear ning phase words training data leave devices collect main idea behind approach called federated learning learn shared model aggregating locally illustration shokri support distributed training deep learning networks privacy preserving way using differential privacy system relies input independent entities collaborate build model without sharing training data selectively share subsets noisy model parameters training approach makes possible provide solution multiple organisations example hospitals combine data train learning model without hav ing share another solution system based neural networks applied encrypted data allows user upload encrypted data cloud service apply neural network data without access ing plaintext encrypted prediction returned user decrypts result cloud service gain information raw data predictions since encrypted using commonly eferred homomorphic encryption ads fairness ads replace support human decision number sensitive domains justice health education important ensure result decisions considered unfair discriminatory section first discuss various sources unfairness section presenting several definitions fairness section technical solutions build aware ads section conclude comments potential tensions offs different objectives section various sources unfairness ads often based machine learning algorithms trained collected data multiple potential sources unfairness process unfair treatment result example content training data way data labelled feature selection biased training data training data contains biases historical discrimination ads inherit incorporate future decisions example illustrated igure word embeddings trained google news articles exhibit gender stereotypes propagated daily basis brendan mcmahan eider moore daniel ramage seth hampson blaise agüera arcas communication learning deep networks decentralized data shokri shmatikov privacy deep learning acm computer communication security ccs gilad ran cryptonets applying neural networks encrypted data high throughput accuracy international conference machine learning barocas solon selbst andrew big data disparate impact california review gal yona gentle introduction discussion algorithmic fairness tolga bolukbasi kai chang james zou venkatesh saligrama adam kalai man computer programmer woman homemaker debiasing word embeddings international conference neural information processing systems order reduce risk data leakage proposals rely distribution learning phase words training data leave devices collect understanding algorithmic decision opportunities challenges figure extreme occupations projected gender direction source solution mitigate issue constantly machine learning models data optimistic assumption society evolves historical bias correct time another direction try eliminate bias training data pre remove existing task challenging since biases known many indirect instance shown tolga bolukbasi fact word receptionist much closer semantically softball football may arise female associatio receptionist softball accuracy disparity jacky alciné brooklyn resident noticed browsing google photos app pictures friend black tagged label see figure mistake clearly intentional resulted error google image classification algorithm figure example accuracy disparity incorrect tagging pictures source skdkmwwbtuqq ads generally machine learning algorithms systems trained recogni leverage statistical patterns data however perfect perform assification prediction errors accuracy rate ads often related size training dataset tolga bolukbasi kai chang james zou venkatesh saligrama adam kalai man computer programmer woman homemaker debiasing word embeddings international conference neural information processing systems nips ibid stoa panel future science technology large training dataset leads less errors less data leads worse predictions minorities tend dataset therefore subject much poorer accuracy considered unfair since different groups population get different prediction error rates much recent study evaluated three commercial gender classification systems showed darker skinned females misclassified group error rates classifiers returned better results lighter skinned individuals males worst performances observed darker skinned females see igure darker females difficult classify simply underrepresented training datasets figure accuracy facial recognition systems source therefore important evaluate performance ads systems different minorities fact system achieves accuracy error may uniformly distributed whole population result good accuracy majority poor accuracy minorities since minorities definition smaller groups impact performance system negligible argument illustrated toy example figure shows simple linear binary classification classifies inputs dataset according gender male crosses fema points dataset composed members majority group blue members minority group yellow according protected attribute accuracy classification algorithm perfect equal members majority group blue points crosses perfectly separated perform poorly accuracy members minority group yellow points crosses separated line however since size minority gro small compared overall population overall accuracy remains high joy buolamwini timnit gebru conference fairness accountability transparency pmlr understanding algorithmic decision opportunities challenges figure simple classification example automated decisions tend treat belong statistically dominant groups accurately training datasets differences classification accuracy different groups major underappreci ated source unfairness definitions fairness discussions fairness ads often rhetoric lack rigour precision fact characterising notion fairness far trivial many different sometimes incompatible definitions proposed growing body work topic point reader baroc survey romei comprehensive introductions high level existing definitions fairness usually rely groups defined via sensitive attributes race gender define statistical properties require approximately equali sed across groups example definition called disparate impact statistical parity require rate positive classification equal across groups another called equalized odds requires false positive false negative rates equal across groups rest section present existing definitions greater detail disparate treatment impact anti mination laws generally distinguish disparate treatment disparate impact disparate treatment addresses intentional discrimination includes decisions explicitly based protected characteristic intentional discrimination via prox variables treatment disparate depends protected attributes formally ads suffer disparate treatment vector non attributes user sensitive attribute race expression means probability knowing simple idea achieve property remove sensitive attributes training data however removing sensitive attributes often insufficient since protected attributes redundantly encoded attributes correlated example well known certain cities strong correlation reli gion richard berk hoda heidari shahin jabbari michael kearns aaron roth fairness criminal justice risk assessments state art sociological methods research barocas solon selbst andrew big data disparate impact california law review romei ruggieri multidisciplinary survey discrimination analysis knowledge engineering review stoa panel future science technology ethnic origin individual area code part city live removing religion ethnic origin attributes dataset therefore sufficient since predicted good accuracy rea code information identifying correlated attributes challenging promising approach uses machine learning task explained attributes correlated fact ads exhibit disparate treatment necessarily mean impose disparate impacts particular group decision disparate impact disproportionately adverse effect members protected group words rate positive classific ation acceptance protected group similar example race sensitive attribute algorithm disparate impact 𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷 𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷 note disproportionately adverse often defined using rule ratio two probabilities less equalized predictive values epv epv another measure fairness widely accepted ado pted psychometrics community guarantees system fair sense free predictive biases illustration considering fico credit score mentioned section epv basically states supposing person given positive decision probability pay back loan equali sed across different groups 𝑊𝑊𝐷𝐷𝐵𝐵𝐵𝐵 𝐴𝐴𝑅𝑅𝑝𝑝 𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷 𝑊𝑊𝐷𝐷𝐵𝐵𝐵𝐵 𝐴𝐴𝑅𝑅𝑝𝑝 𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷 disparate mistreatment equali sed odds recent paper proposes definition disparate mistreatment measures misclassification rates algorithm differ different groups words instead studying comparing outcomes decision algorithm authors propose verify error rates algorithm similar different groups intuition ads potentially causes harm indivi dual misclassifies propose use five different types error rates overall misclassification rate false positive rate false negative rate false omission rate false discovery rates similarly hardt proposed alterna tive called equali sed odds also states error misclassification equali sed across different groups taking example fico credit score application following properties satisfied equali sed true positive ensures people pay back loan equal opportunity get loan 𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷 𝑊𝑊𝐷𝐷𝐵𝐵𝐵𝐵 𝐴𝐴𝑅𝑅𝑝𝑝 𝑏𝑏𝑅𝑅𝐷𝐷𝑘𝑘 𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷 𝑊𝑊𝐷𝐷𝐵𝐵𝐵𝐵 𝐴𝐴𝑅𝑅𝑝𝑝 𝑏𝑏𝑅𝑅𝐷𝐷𝑘𝑘 rich zemel kevin swersky toni pitassi cynthia dwork international conference machine learning pmlr example equal employment opportunity commission refers rule measure disparate impact chouldechova fair prediction disparate impact study bias recidivism prediction instruments big data muhammad bilal zafar isabel valera manuel gomez rodriguez krishna gummadi fairness beyond disparate treatment disparate impact learning classification without disparate mistreatment international conference world wide web www moritz hardt eric price nathan srebro equality opportunity supervised learning international conference neural information processing systems nips understanding algorithmic decision opportunities challenges equali sed false positive ensures people pay back loan equal opportunity get loan 𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷 𝐴𝐴𝑅𝑅𝑝𝑝 𝑏𝑏𝑅𝑅𝐷𝐷𝑘𝑘 𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷 𝐴𝐴𝑅𝑅𝑝𝑝 𝑏𝑏𝑅𝑅𝐷𝐷𝑘𝑘 incompatibility different definitions fairness considering several definitions fairness exist useful understand relate unfortunately many incompatible example chouldechova showed math ematical sense impossible develop system simultaneously satisfies equali sed odds sed predictive values definitions chouldechova illustrated results using compas application showed although compas satisfies epv see figure satisfy sed odds see figure therefore disparate impacts black people figure observed probability recidivism cording score provided compas system source results figure show probabilities similar black white defendants alexandra chouldocheva fair prediction disparate impact study bias recidivism prediction instruments big data special issue social technical trade stoa panel future science technology figure false positive rates across prior record count defendants charged misdemeanour offence using compas data made available source results figure show false ositive rates much larger black white defendants one lessons drawn incompatibility results experts provide precise definitions explain whereas ultimate choices terms fairness technical matter public policy towards aware algorithms several research groups focused design ads attempt address fairness discrimination detailed description schemes outwith scope report nutshell fairness adds extra constraint learning algorithm identifi parameters hypothesis minimi classification errors training data satisfying fairness constraint therefore generally fairness accuracy fairness ads rely one following approaches approach consists pre training data move sources unfairness map training data space dependencies sensitive attributes class labels disappear kamiran calders hajian adopt approach performing controlled distortion training data leads jeff larson surya mattu lauren kirchner julia angwin analyzed compas recidivism algorithm propublica algorithm michael feldman sorelle friedler john moeller carlos scheidegger suresh venkatasubramanian certifying removing disparate impact acm sigkdd international conference knowledge discovery data mining kdd hajian domingo direct indirect discrimination prevention methods discrimination privacy information society studies applied philosophy epistemology rational ethics springer dwork hardt pitassi reingold zemel fairness awareness novations theoretical computer science feldman friedler moeller scheidegger venkatasubramanian certifying removing disparate impact kdd kamiran calders classification discrimination preferential sampling benelearn kamiran calders classification discrimination preferential sampling machine learning conference belgium netherlands hajian ferrer martinez rule protection indirect discrimination prevention data mining modeling decisions artificial intelligence mdai lecture notes computer science springer understanding algorithmic decision opportunities challenges unbiased dataset main limitation approach treats learning algorithm box result unpredictable loss accuracy approach second approach modifies classifier algorithm limit discrimination example novel leaf labelling approach calders propose embedding non constraint algorithm decision tree learner changing splitting criterion pruning strategy post approach instead cleaning original dataset changing data mining algorithms approach modifies resulting data mining models example pedreschi propose altering version cpar algorithm classification based predictive association rules approaches complementary combined example zemel propose scheme applies first two approaches jointly learning fair rep resentation data classification parameters many existing proposals restricted narrow range classifiers accommodate single binary sensitive attribute words generali multiple gender race polyvalent sensitive attributes race two values however practical schemes undoubtedly proposed forthcoming years ads explainability technical solutions explainability classifie according different dimensions technically speaking three main approaches followed implement explainability requirements box approach approach consists analysing behaviour ads without hood say without knowledge code explanations constructed observations relationships inputs outputs system possible approach operator provider ads uncoll aborative agree disclose code box approach contrast box approach box approach assumes possible analyse ads code kamishima sakuma fairness classifier ith prejudice remover regularized padm goh cotter gupta friedlander satisfying real goals dataset constraints nips calders verwer three naive bayes approaches discrimination classification data ining journal special issue selected papers calders verwer three naive bayes approaches discrimination classification data mining knowledge discovery pedreschi ruggieri turini measuring discrimination socially decision records siam data mini conference sdm yin han cpar classification based predictive association rules siam icdm zemel swersky pitassi dwork learning fair representations intl conf machine learning first challenge box explanations construction explanations based observations ads cases observation also challenge ads integrated within complex system involving multiple parties stoa panel future science technology constructive approach contrast first two appro aches assume ads already exists constructive approach design ads taking account explainability requirements explainability design following sections discuss box techniques section box techniques section constructive techniques section important question means evaluate compare explanations topic section considering objective document cover field extensively provide overview main approaches challenges section focus representative examples existing techniques highlight main features reader refer one surveys published topic comprehensive account state art box approaches explainability solutions following box approach make assumption code underlying model ads except existence possibility observe outputs first challenge context construction explanations based observations ads cases observation also challenge ads integrated within complex system involving multiple parties partially observed controlled typically case ads used web services uch recommendation systems personali sed vertisement systems local interpretable model explanations lime example state box explanation system underlying idea even algorithm complex difficult explain globally may possible provide local explanations faithful understandable see figure lime generic fram ework explanation defined member set interpretable models endowed measure complexity notion faithfulness also defined measure difference explanation model ads around system draws samples around point interest build faithful explanation model vicinity lime defined general way instantiated different types interpretable models set linear func tions decision trees explanations also presented user different ways example histograms see figure sets words images illustration picture classified dog may appear head legs highlight meaning determining factors classification contrast highlighted part picture ball might sign ads produced right result wrong reasons useful desig ner improve system riccardo guidotti anna monreale franco turini dino pedreschi fosca giannotti survey methods explaining black box models carmen lacave francisco diez review explanation methods bayesian networks knowledge engineering review approach also called reverse engineering authors marco tulio ribeiro sameer singh carlos guestrin trust explaining predictions classifier knowledge discovery data mining conference kdd acm samples weighted according proximity point interest understanding algorithmic decision opportunities challenges figure local explanation complex model linear model using lime source marco tulio ribeiro sameer singh carlos guestrin trust explaining predictions classifier proceedings knowledge discovery data mining conference kdd acm figure dashed grey line approximates frontier pink blue spaces around highlighted red cross figure explanation form histograms using lime source marco tulio ribeiro sameer singh carlos guestrin trust explaining predictions classifier proceedings knowledge discovery data mining conference kdd acm figure two infl uential factors diagnosis fatigue goes diagnosis earlier box approach explainability trepan algorithm introduced technique extract decision trees neural networks fact trepan works decision tree learning algorithm using ads explained oracle trepan uses answers returned ads build decision tree thes answers labels classes instances queried trepan trepan uses first expansion strategy expand tree increase fidelity ads contrast traditional decision tree learning algorithms trepan benefit fact limited fixed set training data types explanations also extracted following box approach example mark craven jude shavlik describe techniques generate else rules neural networks used oracles trepan conditions either conjunctive rules rules main challenge approaches reduce complexi exploration since search exponential number input features marco tulio ribeiro recently proposed mark craven jude shavlik extracting representations trained network conference advances neural information processing systems mark craven jude shavlik using sampling queries extract rules trained neural networks international conference machine learning icml stoa panel future science technology optimised algorithm efficiently compute else rules algorithm implemented model explanation system called anchor solutions rely assumption ads explained used oracle possible submit queries ads observe answers however certain situations access ads issue embedded within larger system whose execution affected many parameters observed typically case ads used personali sed advertisement recommendation systems several tools recently proposed address problem particular shed light practices profiling micro targeting example adfischer tool study online tracking automated controlled experiments basically makes possible mulate new users visiting web pages corresponding particular interests analyse vertising served users adfischer uses machine learning detect differences patterns vertisement result adfischer provide features strongest impact choice vertising served user since many factors potentially influence choice vertisement control experimentation necessary conduct large mber tests measure statistical significance adfischer applied detection discrimination highlight use certain topics interest substance abuse selection vertisement sunlight another tool provides explanations web targeting statistical designers sunlight placed strong emphasis three main principles generality approach scale experiments wide variety data robustness results statistical justification interpretability understandability expert users sunlight also generates fictitious profiles analyses vertisement served outputs order enhance interpretability sunlight focuses simple explanations take form disjunctions features strongest impact result disjunction derived sparse linear model learned observations system inputs outputs sunlight also used detect targeting based sensitive topics health religious affiliation sexual orientation one strengths sunlight scalability sense able deal multiple input features box approach explainability received lot attention research community possible option code disclosed operator marco tulio ribeiro sameer singh carlos guestrin anchors high precision model explanations thirty second aaai conference artificial intelligence amit datta michael carl tschantz anupam datta automated experiments privacy settings tale opacity choice discrimination privacy enhancing technologies pet measure implemented adfischer evaluating permutation test amounts comparing observed test statistics result obained random permutation test sunlig targeting detection scale statistical confidence acm sigsac conference computer communications security ccs acm box approach explainability received lot attention research community possible option code ads available another advantage approach generality since depend derlying technique model ads understanding algorithmic decision opportunities challenges provider ads another advantage approach generality sinc solutions depend underlying technique model ads box approaches explainability contrast box approach box explanation systems rely analysis ads code addition explanations generate white box solutions differ terms ads handle bayesian networks neural networks limited depth deep neural networks etc way handle continuous data discreti sation complexity example early work direction elvira system graphical explanation bayesian networks basically user elvira change certain assumptions fever case medical ads obse rve impact assumption result example probability disease elvira also offers qualitative information pairs variables example colouring link two variables higher values first one lead igher values second elvira follows box approach sense makes possible user see edit model bayesian network box approach also explored ads based neural networks exampl tool proposed matthew zeiler rob fergus makes possible visuali input stimuli network excite individual feature maps layer model challenge context able map activities intermediate layers back input pixel space make explanation understandable information useful designers ads get insight internal erations detect potential problems improve ads also possible produce widely accessible explanations neural networks showing features strongest influence decision white box approach reach goal called propagation propagation idea consists propagating prediction score backwards network redistributing scores neurons lower level depending contributions neuron upper level backward propagation leads interpretable patterns input domains associated given classification constructive approaches explainability constructive approach applied ideal situation explainability requirements taken account design phase ads two options possible achieve explainability design relying algorithmic technique design meets intelligibility requirements whilst providi sufficient accuracy enhancing accurate algorithm explanation facilities generate addition nominal results classification faithful intelligible explanation results example first approach sed additive models gams extensions sed additive models plus interactions proposed yin lou rich caruana carmen lacave roberto atienza francisco diez graphical explanation bayesian networks ismda conference spinger lncs matthew zeiler rob fergus visualising understanding convolutional networks eccv springer lncs landecker michael thomure luis bettencourt melanie mitchell garrett kenyon steven brumby interpreting individual classifications hierarchical networks ieee symposium computational intelligence data mining cidm grégoire montavon wojciech samek klaus müller methods interpreting understanding deep neural networks digital signal processing stoa panel future science technology johannes gams defined linear combinations shape functions individual features shape functions arbitrarily complex makes possible get high level accuracy addition shape functions apply individual features combined using linear function results gam remain interpretable shape function visualised two plot contribution feature understood weights linear function result gams accurate linear models intelligible techniques deep neural networks support vector machines however fact interactions features possible makes gams less powerful techniques random forests restriction allev iate limitation yin lou rich caruana johannes gehrke giles proposed extension called sed additive models plus interactions possible express two dimensional interactions features makes model powerful maintaining high level intelligibility dimensional interaction features represented heat map two space main challenge limit number pairs features consider using statistical relevance tests authors shown accuracy intelligibility scalability real healthcare problems pneumonia risk prediction hospital readmission example second appro ach technique proposed tao lei regina barzilay tommi jaakkola produce explanations form subsets input texts justifying subsets must meet two essential requirements must correspond short coherent pieces text ensure intelligibility ensure correctness faithfulness explanation application ads subset must lead prediction application entire text illustration explanation five rating colour analysis beer review excerpt text pleasant ruby red colour technique involves two main components rationale generator used generate short sequences words encoder used minimise discrepancy true prediction whole text explanation prediction excerpt different algorithms used implement rationale generator encoder generation explana tions unsupervised learning process without explicit explanation annotations based two components another strategy followed particular bien tibshirani consists generating class prototypes representative samples input domain leading particular classification must satisfy number criteria example number must limited must varied ensure good coverage input data set piece input data must prototype class prototypes different class neighbourhood illustration handwritten digit recognition system system generates small set images corresponding digit prototypes ach set must provide sufficient variety represent corresponding class well case corresponds different ways write yin lou rich caruana johannes gehrke intelligible models classification regression knowledge discovery data mining conference kdd acm yin lou rich caruana johannes gehrke giles hooker accurate intelligible models pairwise interactions proceedings knowledge discovery data mining con ference kdd acm rich caruana yin lou johannes gehrke paul koch marc urm noémie elhadad intelligible models healthcare predicting pneumonia risk hospital readmission knowledge discovery data mining conference kdd acm tao lei regina barzilay tommi jaakkola rationalizing neural predictions conference empirical methods natural language processing emnlp understanding algorithmic decision opportunities challenges digit strategy implemented optimisation problem solved using standard optimi sation techniques qualities explanations explanations generated methods take different forms number criteria used evaluate intelligibility understandability since primary goal explanation enhance understanding ads results first yardstick intelligibility even though intelligibility highly dependent form explanation often measured using size criteria examples include size depth decision tree number rules length textual explanation complementary metrics readability availability proposed assess intelligibility however intelligibility complex subjective notion assessed precisely experimental means example larger decision trees sometimes easier understand smaller trees notion monotonicity also sometimes associated intelligibility basically monotonic dec ision function decreasing probability purchase cost increases easier grasp human monotonic function addition often corresponds intuition humans may expected results ads fidelity accuracy second key requirement explanation accuracy sense fidelity ads objective difficult meet global explanations local explanations indeed explanation absolutely accura covering whole model would reflect complexity ads would probably intelligible fidelity therefore relative rather absolute requirement explanations generally integrated within explanation syste proximity measure example lime includes notion faithfulness measure distance explanation true model ads vicinity given input value similarly encoder proposed tao lei regina barz ilay tommi jaakkola minimises discrepancy true prediction explanation precision level detail explanations also differ terms level precision provide example explanation may list features used get result without respective weights highlight excerpts text red use different colours provide information impact excerpts results ads etc compl eteness another relevant property explanations completeness indeed explanation includes factors influenced decision might misleading unless rule used choosing features made clear llustration study conducted athanasios andreou colleagues shown explanations provided facebook personali sed vertisement system incomplete misleading unique feature shown preval attribute rather interesting perspective users dayana spagnuelo cesare bartolini gabriele lenzini metrics transparency data privacy management security assurance dpm lncs springer tao lei egina barzilay tommi jaakkola rationalizing neural predictions proceedings conference empirical methods natural language processing emnlp common attribute community users athanasios andreou giridhari ven katadri oana goga krishna gummadi patrick loiseau alan mislove investigating transparency mechanisms social media case study facebook explanati ons network distributed systems security symposium ndss stoa panel future science technology consistency consistency another quality explanations defined different ways consistency may concern single explanation several explanations different inconsistent explanations provided type results content explanation relation common sense knowledge users example fact patients suffering asthma lower risk dying pneumonia consistency impact intelligibility trust ads evaluation explainability discussed section quality explanation assessed relation intended recipients level expertise objectives specific context therefore taken account determine significance criteria assessment explanation system addition emphasise criteria may tension example higher levels accuracy level precision may reduce intelligibility evaluation criteria difficult often partly subjective task order make task systematic rigorous finale doshi kim propose taxonomy evaluation interpretability taken sense explainability distinguish three levels functiona evaluations based formal definitions interpretability example use decision trees explainable models less expensive require human experiments must rely assumptions forma definitions already validated human evaluations involve simple human experiments example assess kinds explanations better understood application evaluations involve field experiments actua future users system doctors provide precise assessments also expensive challenges shown chapter designing ads safe secure privacy fair explainable still challenging deserves effort research even well computer systems result unexpected errors unexplained outcomes several reasons safety ads cause unintended negative consequences environment example may happen training environment match operational environment many failures addressed hoc solutions strong need define unified approach minimum requirement perform extensive testing deployment provide accountability security ads complex subject many different types attacks example adversary threaten integrity availability ads polluting training dataset attacking rich caruana yin lou johannes gehrke paul koch marc sturm noémie elhadad intelligible models healthcare predicting pneumonia risk hospital readmission knowledge discovery data mining conference kdd acm finale velez kim tow ards rigorous science interpretable machine learning understanding algorithmic decision opportunities challenges underlying algorithm exploiting generated model time shown earlier existing countermeasures unsatisfactory effective solutions need developed privacy ads often trained personal data several attacks devised either extract information training data retrieve ads model attacks raise privacy concerns solutions using cryptography distributed architectures proposed still prelimina often detrimental impact performance ads research required propose privacy ads achieve acceptable performance privacy trade fairness shown earlier different definitions fai rness new definitions regularly proposed example existing definitions statistical defined respect group averages definitions fairness consider individuals instead groups also worth considering final shown impossible satisfy notions fairness time maximi accuracy fairness therefore necessary consider challenging offs offs discussed stakeholders statisticians computer scientists example computer scientists decide different definitions fairness trade accuracy stated richard berk matters values ultimately political process matters science explainability ads often complex systems difficult understand hand ads code audited task always easy since generally consis complex modules made large number code lines developed groups engineers ads based machine learning even challenging understand therefore explain since models generated automatically traini data data many properties features influence generated models furthermore noted burrell datasets may extremely large possible comprehend code may written clarity interpla two mechanisms algorithm yields complexity thus opacity aaron roth notions fairness machine learning richard berk hoda heidari shahin jabbari michael kearns aaron roth fairness criminal justice risk assessments state art sociological methods research richard berk hoda heidari shahin jabbari michael kearns aaron roth fairness criminal justice risk assessments state art sociological methods research burell machine understanding opacity machine lea rning algorithms big data society stoa panel future science technology legal instruments main focus document technical dimension ads chapter briefly discuss legal instruments tha used meet objectives set forth chapter matter fact technical solutions described necessary solve issues raised ads must associated types measures articular legal requirements terms transparency explainability accountability fact various existing laws already apply ads greater lesser extent address requirements identified chapter cite laws european directives discrimination directive equal opportunities qual treatment omen men mployment occupation racial equality directive employment equality directive general consumer protection laws example directive services internal market states member states shall ensure general conditions access service made available public larg provider contain discriminatory provisions relating nationality place residence recipient without precluding possibility providing differences conditions access differences directly justified objective criteria sectoral laws regulations healthcare banking sectors example united states equal credit opportunity act ecoa enforced federal trade commission ftc provides right informed reasons rejection application another example transparency requirements highspeed trading algorithms regulations related open access administrative documents freedom information usa nited kingdom needless say list far exhaustive point existing laws address issues identified chapter addition certain laws may also constitu obstacle transparency ccountability particular laws protecting intellectual property trade secrets discuss issue section adapting strengthening existing laws often seen necessity take risks posed development new technologies account address need try meet desiderata set forth chapter number legal safeguards proposed adopted last decade exhaustive review regulations proposals beyond scope document chapter illustrate significant approaches considering two complementary dimensions substance actual rights obligations introduced new regulations proposed academics desiderata among tho listed chapter targeted new regulations proposals intended scope sectoral general means enforcement regulation would proposal legally binding would implemented throu dedicated bodies supervisory authorities would fall within regular jurisdictions first discuss situation europe new general data protection regulation section focus example recent developments member state france section sketching proposals originate united states section understanding algorithmic decision opportunities challenges european level general data protection regulation one widely discussed commented regulations passed recent years european general data protection regulation gdpr although early assess practical impact highly dependent interpretation implementation data protection authorities courts gdpr potential enhance personal data protection europe particular introduces new rights individuals right portability stricter rules information consent enhanced erasure rights etc new obligations data controllers data protection impact assessments data protection design default data breach notifications etc new action levers collective actions higher sanctions better coordination mechanisms supervisory authorities new body european data protection board edpb replac former article working party extensive powers binding decisions particular dispute resolution national supervisory authorities interest reader find details paul hert vagelis papakonstantinou analysis effectiveness gdpr terms transparency explainability topic intense debate authors claim gdpr introduces righ explanation ads others argue right exist issue whether gdpr provides true right explanation separated two questions right really set forth gdpr mean exactly context right set forth gdpr conditions application likely effective core debate article figure defines rules automated individual decision including profiling addition article provide controller shall time personal data obtained provide data subject following information necessary ensure fair transparent processing existence automated making including profiling referred article least cases meaningful information logic involved paul hert vagelis papakonstantinou new general data protection regulation still sound system protection individuals computer law security review bryce goodman seth flaxman european union regulations algorithmic decision right explanation magazine rew selbst julia powles meaningful information right explanation international data privacy law gianclaudio malgieri giovanni comandé right legibility automated decision exists general data protection regulation international data privacy law sandra wachter brent mittelstadt luciano floridi right explanation automated decision exist general data protection regulation international data privacy law effectiveness gdpr terms transparency explainability topic intense debate authors claim gdpr introduces right explanation ads others argue right exist gdpr stoa panel future science technology well significance envisaged consequences processing data subject sandra wachter legal existence feasibility right explanation gdpr far legal existence concerned argue word occurs recital concerns decisions subject based solely automated processing produces legal effects concerning similarly significantly affects recital provides case processing subject suitable safeguards include specific information data subject right obtain human intervention express point view obtain explanation decision reached assessment challenge decision however recitals legally binding provide guidance interpretation articles therefore fact word explanation occurs neither article articles significant means according sandra wachter right explanation thus currently legally mandated requirements set article exclude future jurisprudence still interpret introducing right explanation one possible future addition argue article concern explanations notifications decision made explanations spe cific decisions figure gdpr article automated individual decision including profiling authors take less restrictive interpretation argue right explanation exist gdpr example andrew selbst julia powles state one uses phrase explanation attention must paid gdpr express requirements relate background goals thought must given determining legislative text actually means legal analysis gdpr leads conclusion article data subject shall right subject decision based solely automated processing including profiling produces legal effects concerning similarly significantly affects paragraph shall apply decision necessary entering performance contract data subject data controller authorised union member state law controller subject also lays suitable measures safeguard data subject rights freedoms legitimate interests based data subject explicit consent cases referred points paragraph data controller shall implement suitable measures safeguard data subject rights freedoms legitimate interests least right obtain human intervention part controller express point view contest decisi decisions referred paragraph shall based special categories personal data referred article unless point article applies suitable measures safeguard data subject rights freedoms legitimate interests place understanding algorithmic decision opportunities challenges gdpr clearly mandates meaningful information logic decisions article applies meaningful substance appears face move direction explanation type parties debate including wachter others seem agree point may also noted right decision article would meaningful without right explanation even agree conclusion right explanation exists gdpr actual effectiveness right remains seen since applies case based solely automated processing wachter state creates loophole whereby even nominal involvement human decisionmaking process allows otherwise automated mechanism avoid invoking elem ents right access directive gdpr addressing automated decisions view supported jurisprudence countries germany provision already existed european directive tested court another potentially strong restriction article applies decisions producing legal effects concerning subject similarly significantly affecting authors gianclaudio malgieri giovanni comandé encourage optimistic interpretation article considering threshold minimum human intervention required making automated also include nominal human intervention envisaged effects individuals encompass well marketing manipulation price discrimination etc opinion line automated individual decision profiling purposes regulation published article working party october regarding restriction decisions based solely automated processing article working party states qualify human intervention controller must ensure oversight decision meaningful rather token gesture carried someone authority competence change decision part analysis consider available input output data article working rty also advocates wide interpretation significantly affecting provides following typical examples automatic refusal online credit application practices without human intervention suggest difficult precise would considered sufficiently significant meet threshold example based recital following credit decisions fall article different degrees impact individuals concerned renting bettina berendt sören preibusch toward accountable discrimination data mining importan keeping human loop looking big data guidelines automated individual decision profiling purposes regulation article data protection working party even agree conclusion right explanation exists gdpr actual effectiveness right remains seen since app lies case based solely automated processing stoa panel future science technology city bike vacation abroad two hours purchasing kitchen appliance television set credit obtaining mortgage buy first home temporary conclusion gdpr agree andrew selbst julia powles fact issues applicability right rather shape right matter future interpretation legislators data protection authorities cou rts france law digital republic countries also adopted new laws enhance transparency explainability ads recent years example law digital passed october france introduces new obligati ons two types users ads administrations digital platform operators digital platform defined online service based ranking referencing contents goods services connecting several parties view selling exchanging contents goods services contrast gdpr law restr ict obligations administrations decisions based solely automated processing refers instead decisions taken basis algorithmic processing administrations must inform persons affected decisions addition must upon request communicate rules algorithm main features implementation individuals application decree provides details requires particular information intelligible include criteria used weight decision affected person requirements pertain local global explanations however obligations adversely affect secrets protected law requirements law digital republic different less constraining platform operators platform operators must provide clear fair transparent information general conditions use services including modalities referencing dereferencing ranking existence contractual corporate relation compensation impact referencing ranking application decree adds information must include criteria main parameters used algorithm close result fact influenced contractual corporate relation compensation united states proposals legal doctrine united states emphasi due process accountability effective way introduce form control ads example danielle keats citron frank state great accomplishments legal order holding sovereign accountable decision giving subjects basic rights breakthroughs stretching runnymede glorious revolution american revolution new algorithmic decision sovereign important aspects individual lives law due process absent field essentially paving way new feudal order unaccountable reputational intermediaries loi octobre pour une république numérique jorf danielle keats citron frank pasquale scored society due process automated predictions washington university law review understanding algorithmic decision opportunities challenges citron pasquale propose two complementary strategies achieve goal full access given federal regulators ftc credit systems assess ads particular check lead unfair discriminatory decisions regulator able audit ads regular basis audits include sufficient tests systems detect biases sources unfairness audit lead civil liberties impact assessment appropriate risk mitigation measures individual level audit trails available make possible people affected ads understand decisions audit trails record correlations inferences made algorithmically prediction process protection intellectual property ads precludes public access audit trails acces sed trusted neutral experts another suggestion made citron pasquale make possible people test different assumptions understand impact decision far back danielle keats citron advocated technologic due process framework mechanisms capable enhancing transparency accountability accuracy rules embedded automated making systems focusing administrative constitutional law citron argues opardi ses procedural protections long deemed foundational administrative state proposed framework relies systematic approach based distinction two forms laws rules standards find acceptabl balance automation human discretion also includes set procedural measures line two strategies prevent procedurally defective rulemaking arbitrary government decision making danielle keats citron also stressed need release source code ads public suggested federal funding technology purchase conditioned use open code kate crawford jason schultz build work develop requirements due process redress privacy harms scholars suggest additional legislative changes improve accountability example deven desai joshua start observation discriminatory unfair treatments sometimes difficult detect either technical reasons companies believe easily evade obligations deny intent breach law based observation make several proposals including changes trade secrecy law protect whistleblowers employers scholars often use legal fields sources inspiration regulation ads example deven desai joshua refer sarbanes act stated passage oxley act ith unprecedented portion american public investing publicly companies depending upon honesty lac whistleblower protection private whistleblowers serve public good similarly unprecedented portion decision due process vital verification interests stake processed software protec tion employees blow whistle software companies knowingly violate law vital words government needs private actors aid law enforcement long history private citizens aiding law danielle keats citron technological due process washington university law review kate crawford jason schultz big data due process toward framework redress predictive privacy harms boston college law review deven desai joshua kroll trust verify guide algorithms law harvard journal law technology ibid stoa panel future science technology enforcement providing support public prosecution private enforcement private evidence gathering andrew tutt uses another source inspiration food drug administration fda advocate creation dedicated agency supervise development deployment use products fda regulates particularly complex pharmaceutical drugs vets safety efficacy similar black algorithms crises fda confronted throu ghout one hundred years existence comparable kinds crises one easily imagine occurring dangerous algorithms fda faced steep resistance every stage capacity respond prevent major health crises resulted agency becoming fixture american institutional landscape could draw fda history lessons use lessons opportunity avoid repeating history tutt argues even development ads still early stage stakeholders may worry regulation could stifle innovation regulatory agency necessary precisely use ads growing quickly raises significant risks come back issue supervisory authorities next chapter andrew tutt fda algorithms administrative law review academics often use legal fields sources inspiration regulation ads examples include sarbanes act sox whistleblower protection food drug administrati fda reference regard regulatory agencies understanding algorithmic decision opportunities challenges open questions remaining challenges instruments presented chapter undoubtedly useful far sufficient address challenges raised ads complementary measures necessary make technical legal instruments effective terms fairness explainabi lity accountability furthermore ads raise substantive issues yet fully understood must analysed thoroughly debated chapter sketch main existing challenges three different complementary perspectives ethical political accepted principles legal social rights obligations enshrined law role different stakeholders implementation rules tec hnical guarantees technical instruments provide one reconcile potentially conflicting objectives accuracy explainability ads ethical political debate illustrated chapter ads raise far reaching issues many areas justice policing healthcare democratic life etc ads exacerbate force rethink existing problems discrimination also introduce new ethical questions difficult address examples critical omplex questions raised ads include actually legitimate use ads first place certain contexts evidencebased sentencing lethal weapons use criticised however far straightforward establish firm boundaries acceptable uses ads situations banned question also raised personalisation example acceptable deny loan based fact friends requester social network deemed credit acceptable personalise prices based location consumer given country assumed capacity pay high price acceptable make access certain services conditional upon trust score score derived behaviour requester acceptable grade teachers decide renew contract based rank ing beyond existing criteria already identified anti laws types tre atment considered undesirable existing laws focus protection well social groups based gender ethnic origin religion etc ads make possible discriminate according many criteria could also considered unfair certain situations unfairness could target virtual groups necessarily identified society take random examples left people people learned foreign language lik movies line drawn principles online manipulation characterised distinguished acceptable influence manipulation based exploitation human biases identified fought reproduces existing commercial practice digital world cases transparency explainability forms accountability required principles requirement defined assessed explainability measured certain types ads forbidden certain situations acceptable level transparency explainability accountability achieved example court support med ical diagnosis stoa panel future science technology choices made design autonomous cars critical decisions taken question life death ethical behaviour encoded system abl decide upon choice ethical behaviour otherwise autonomous cars behave like human drivers would probably mean selfish way proposals made try address issues principled way example brent daniel mittelstadt proposed conceptual map based six types concerns inconclusive evidence addresses uncertainty surrounding ads results use confusing correlation causation inconclusive evidence typically lead unjustified actions inscrutable evidence corresponds lack knowledge data used lack explanation link conclusions inputs misguided evidence corresponds fact input data erroneous biased unfair outcomes includes discriminatory decisions transformative effects seen side effects use ads including impact vision world social political organisation society traceability includes difficulty identify held responsible harm caused first three concerns epistemic sense address quality evidence produced algorithm fourth fifth normative focus actions decision based ads last one traceability responsibilities daniel mittelstadt use map structure academi discussion ethics algorithms another useful conceptual framework understand different variants transparency requirements taxonomy proposed tal zarsky two grid pictured figure used analyse benefits potential drawbacks different forms transparency brent daniel mittelstadt patrick allo mariarosaria taddeo sandra wachter luciano floridi ethics algorithms mapping debate big data society ibid tal zarsky transparent predictions university illinois law review understanding algorithmic decision opportunities challenges figure transparency framework proposed tal zarsky segments information flow collection data aggregation data sets data analysis phase usage stage results analysis utilised recipients transparency information general public internal external institutions committees independent watchdog groups experts affected individuals source tal zarsky transparent predi ctions university illinois law review another example systematic analysis ethical issues useful context edps ethics advisory group proposes list foundational values digital ethi dignity freedom autonomy solidarity equality democracy justice trust edps report identifies five types conditions development digital technologies line values material conditions cultural conditions personal conditions political structural conditions legal conditions ngos also strong role play ethical debate example electronic frontier foundation eff identifies five questions address analysing risks osed algorithm influence serve basis decisions potential negatively impact people lives available data actually lead good outcome algorithm fair algorithm really used humans people affected decisions influence system stressed eff questions starting points guarantee equitable results questions organisations sking implementing making system relies algorithm legal social perspective ethical political debates suggested previous section prerequisites action assuming wide agreement reached issues discussed edps ethics advisory group report towards digital ethics jamie williams lena gun math solve everything questions need asking deciding algorithm answer electronic frontier foundation questions ibid stoa panel future science technology next step decide appropriate instruments implement far law concerned first question asked whether necessary even desirable crea new legal instruments several options considered pros cons instruments pertain state regulation self take form hard law soft law codes conduct guidelines recommendations general sectoral different options also possible terms enforcement example ads regulations may competence ordinary jurisdictions existing regulatory agencies ftc usa data protection authorities europe regulatory agencies dedicated ads fda algorithms suggested andrew tutt answers questions may different issues discussed prev ious section example pressing need legislate least clarify interpretation existing laws liability rules applicable autonomous cars robots social environments lot progress made dom technical side providing clear liability rules seems prerequisite larger scale deployment generally liability key issue uses ads especially physical systems ads entirely automated may raise even complex issues frontier automated decisions decisions taken basis ads blurred example would practitioner entirely responsible fatal decision taken basis ads widely generally recognised trustworthy medical sector complementary question development certification schemes ads certifications labels properly implemented way enhance trust ads verify hey comply certain rules absence bias discrimination certifications either made voluntary basis encouraged gdpr requirement deployment medical devices return issue cha pter another critical issue legal side potential use intellectual property rights set limits transparency accountability legally speaking ads protected three main ways copyright trade secret patents patents published concern right manufacture use invention thus obstacle transparency accountability copyright applies code software prevent explanations main hindranc may therefore protection trade secrets actually protection trade secrets already used industry argument transparency first interesting question respect whether reverse engineering linda senden soft law self regulation european law meet electronic journal comparative law andrew tutt fda algorithms administrative law review see example written evidence submitted google members parliament another case protection formulas used understanding algorithmic decision opportunities challenges techniques presented chapter could considered breaches trade secrets seems jurisdictions would disallow reverse engineering context uncertainty removed respect example article european directive protection undisclosed know business information trade secrets unlawful acquisition use disclosure states acquisition trade secret shall considered lawful tra secret obtained following means independent discovery creation observation study disassembly testing product object made available public however article also states acquisition trade secret shall considered unlawful breach contractual duty limit use trade secret therefore developer operator ads prohibit reverse engineering contractual means terms use context law ainow institute also calls clarification matter order conduct research necessary examining measuring evaluating impact stems public private institutional decision especially terms key social concerns fairness bias researchers must clearly allowed test systems across numerous domains via numerous methodologies however certain laws computer fraud abuse act cfaa digital millennium copyright act dmca threaten limit prohibit research outlawing unauthorized interactions computing systems even publicly accessible ones internet laws clarified amended explicitly allow interactions promote critical research another question whether ads provider certain circumstances required disclose code system information logic even provider argues information trade secret disclosure would undermine competitiveness company discussed recitals directive main argument trade secrets encourage innovation also worthy cause therefore answer question depends situation values stake example would sensible require spam filter chess game provider publish code ads hand seem acceptable ads used sentencing courts execute medical diagnoses could audited protected trade secrets question raised famous loomis wisconsin case wisconsin supreme court considered loomis defendant right due process violated despite fact provider compas system used calculate risk score refused disclose information even credit scoring germany according sandra wachter sandra wachter brent mittelstadt luciano flo ridi right explanation automated decision exist general data protection regulation international data privacy law judgements german federal court show data subjects allowed get information logic ads beyond features taken account system excluding weights report social economic implications artificial intelligence technologies trade secret protection already used industry argument transparency however several lawyers argued strongly trade secret privilege case ads used sentencing court stoa panel future science technology weights input variables decision confirmed united states supreme court however several lawyers argued strongly trade secret privilege context example according rebecca secrets privileged criminal proceedings criminal trade secret privilege ahistorical harmful defendants unnecessary protect interests secret holder meanwhile compared substantive trade secret law privilege overprotects intellectual property privileging trade secrets criminal proceedings fails serve theoretical purpose either trade secret law privilege law far innovation concerned rebecca wexler also points name one stated object ive trade secret law facilitate controlled information sharing therefore fact trade secret law aims least part facilitate information sharing purposes negotiation employment regulation suggests law ould also perform function criminal proceedings revealing trade secrets duties confidentiality business regulatory contexts arguably analogous revealing protective order criminal proceeding addition one argue controlled disclosure code logic ads conflated public disclosure particular risks terms loss competitiveness seems much weaker argument case controlled disclosure especially balanced fundamental rights right due process technical perspective technical instruments play essential role meet desiderata identified chapter still infancy many challenges need addressed challenges classified two main categories conceptual define complex subjective notions discrimination unfairness privacy manipul ation seen chapter concepts complex difficult formalise require work agree common definitions several definitions notion exist respective strengths weaknesses seen section veral incompatible definitions fairness proposed example definition require rate positive classification equal across groups disparate impact statistical parity false positive false negative rates equal across groups equali sed odds best types explanations depending different recipients level expertise objectives operational tensions accuracy cost reconciled feasible inherent limitations latter case confirmed would best trade particular ads best technical approaches mechanisms provide explainability fairness privacy ads seen previously different approaches taken rebecca wexler life liberty trade secrets intellec tual pro perty criminal justice system standford law review understanding algorithmic decision opportunities challenges implement properties example fairness achieved using preprocessing processing approach see section best approach specific ads far explainability concerned interactions explanation system designed improve user understanding explainability design implemented question holds fairness design privacy design properties taken consideration beginning conception ads required gdpr data protection however phase requires strong technical expertise expected ads developers guidance help provided designers developers implement principles explainability fairness privacy ads assessed metrics tools used specific risk management methodology developed ads best secured accidents adversarial attacks seen report difficult protect ads unexpected failures attacks resistance failures attacks tested acceptable level security robustness addressing challenges complicated fact researchers access huge data sets held ivate companies access algorithms imbalance significant impediment development knowledge field prashan madumal tim miller frank tere liz sonenberg towards grounded dialog model explainable artificial intelligence international workshop cognitive systems ijcai addressing technical challenges complicated fact researchers access huge data sets held private companies access algorithms imbalance significant impediment development knowledge field stoa panel future science technology policy ptions even though ads still early stage development see chapters already used many different situations soon become pervasive across professional personal activities however discussed chapter many critical questions remain solved regard many others bound arise future whole host reports studies published inform policy public precautions measures need taken address based studies analysis presented report conclusion put forward number options listed options mostly organisational procedural general sense term rather substantive since positions matter rather result fro public debate issued expert groups however provide guidance criteria issues carefully considered adoption ads distinguish five complementary types actions development dissemination knowledge ads public debate benefits risks ads adapting legislation enhance accountability ads development tools enhance accountability ads effective validation monitoring measures ads development dissemination knowledge ads discussed report ads raise complex questions entirely understood experts mention users affected people addition changing area technical perspective terms usage first step enhance accountability therefore improve disseminate knowledge ads particular means developing multidisciplinary interdisciplinary research ads philosophers experts ethics computer science social science law work together develop conceptual tools analyse ethical issues raised ads research also needed design methods tools enhance security safety priva fairness explainability ads computer scientists experts psychologists knowledge engineers join forces understand types explanations useful depending targeted audiences needs progress also made characterisation notions like explainability fairness implementation design shown chapter chapter implementing privacy aware transparent secure fair ads challenging ask deserves research work research also performed order better understand risks monitor evaluate mitigate rigorous lgorithm impact assessment aia methodologies defined following interdiscipl inary multi approach edps ethics advisory group report towards digital ethics commission nationale des libertés cnil humans keep upper hand ethical matters raised algorithms artificial intelligence center nternet human rights ethics algorithms radical content self cars gccs mike annany towards ethics algorithms convening observation probability timeliness science technology human values understanding algorithmic decision opportunities challenges key condition facilitating research possibility research community obtain access specific conditions strict confidentiality datasets held public bodies also private companies right access justified fact large amounts data may considered public interest stated european statistical system ess recent positioning paper issue access dat public interest left unanswered risk fragmented approaches across increasing making even difficult address future practical avenue would consist stage affirming law gen eral principle access privately data public interest addressing broad terms main elements access effective operational level ess positioning paper focuses use data statistical offices arguments valid research general position line report published french conseil générale économie cge internet governance forum igf general interest recent paper heta shah goes stating rights expire fixed time period similarly technology companies allowed use data gather limited period say five years data could revert national charitable corporation could provide access certified researchers would held account subject scrutiny ensure data used common good reason made clear reverse engineering purpose analysing explaining detecting biases ads considered lawful limited trade secret generally intellectual property right laws ensuring issues raised ads properly understood designers developers engineers trained supervised order consider essential requirements fairness explainability beginning design phase throughout ads development cycle guidelines describing good development practices devised published tools provided help developers implement test desired ads properties development body experts ads ability cover technical ethical aspects also encouraged experts could integrated development teams serve ads evaluation bodies enhancing level awareness users ads rofessionals individuals citizens general affected use ads ads used make decisions people prime importance everyone involved minimum knowledge underlying pro cesses potential limitations technologies stated tal zarksy automations generate erroneous aura flawless making abilities indeed serious concern doubt however whether additional transparency european statistical system position paper access privately held data public interest duchesne cytermann vachey morel aureau rapport relatif aux données général conseil général inspection générale des finances hetan shah use personal data common good nature option line report published recently french parliamentary mission led cédric villani donner sens artificielle pour une stratégie nationale européenne pdf stoa panel future science technology provides sufficient answer concern could resolved measures educating public relevant decision makers true nature automation generally digital literacy essential citizens able exercise rights digital society public debate benefits risks ads enhancing level understanding technologies involved ads necessary sufficient since many issues raised ads subjecti may approached different ways depending individual perceptions political views considering ads major impact society must subject public debate several conditions met ensure quality debate must involve stakeholders opinions interests including least experts disciplines policy professionals ngos general public must conducted rigorous way without overshadowing key issues including preliminary question legitimacy use ads indeed voices raised use ads certain contexts example kelly moffat states use risk tools sentencing especially prob lematic used courts may offend moral legal norms well country specific constitutional values trend towards using risk instruments sectors criminal justice system therefore merits theoretical eliberation empirical study vein chelsea barabas colleagues argue shift away predictive technologies towards diagnostic methods help understand criminogenic effects criminal justice sys tem well evaluate effectiveness interventions designed interrupt cycles crime contrast current emphasis machine learning techniques offer grounded way understanding underlying drivers crime methods based rigorous approach incorporates qualitative quantitative data analysis adapting legislation enhance accountability ads discussed section different types legal instruments used enhance accountability ads considering technology uses evolving quickly area wise avoid hasty legislation could end creating problems attempts solve new regulations enacted matter properly understood public debate suggested taken place established existing laws insufficient address issues may case certain sectors require tal zarsky transparent predictions university illinois law review jamie williams lena gunn math solve everything questions need asking deciding algorithm answer electronic frontier foundation everything see also principles kelly hannah actuarial sentencing unsettled proposition justice quarterly chelsea barabas karthik dinakar joichi ito madars virza jonathan zittrain interve ntions predictions reframing ethical debate actuarial risk assessment processing machine learning research understanding algorithmic decision opportunities challenges regulation clarifications application existing laws argued example liabilities area autonomous cars robots social environments better defined transparency requirements imposed use ads judges medical sector issues potential ban lethal weapons ideally regulated international level far enforcement concerned believe clear distinction made ethical committees mission stimulate discussion conduct debate publish recommendations operational bodies accreditation bodies certification agencies oversight agencies together provide framework monitoring certification oversight specific ads oversight agencies also power sanction operators compliant ads like data protection authorities non gdpr ethical committees operate general cross level operational bodies sectoral different application areas raise different issues different histories cultures sets practices regulations take one example medical sector llestablished tradition certification medical devices certification ads support diagnosis fall within framework operational bodies could still rely expertise body experts suggested section used different sectors may involve similar techniques require similar expertise development methodologies tools enhance ads accountability tools methodologies must developed order help designers developers build ads match desired properties described chapter help third parties test validate possibly certify ads help users interact meaningful way ads ads designers developers experts privacy security fairness explainability therefore important provide tools methodologies help reconcile tensions exist accuracy cost recommendation guides unfortunately sufficient tools methodologies consider whole development cycles ads developed disseminated similarly frameworks composed metrics methodologies tools assess impact ads test desired properties ads developed frameworks could used designers test ads third entities certification authorities validate far users concerned better explanation facilities required particular int eractive interfaces dialog models stated prashan madumal general prashan madumal tim miller frank vetere liz sonenberg towards grounded dialog model explainable rtificial intelligence international workshop cognitive systems ijcai stoa panel future science technology dialog model explanation takes account end user attributed one shortcomings existing explainable systems developing tools frameworks far trivial requires large amount research stud discussed chapter effective validation monitoring measures gdpr introduces obligation data controllers conduct data prote ction impact encourages establishment certification mechanisms data protection seals marks considering stakes high regarding ads reason subject types ecaution recommend particular ads deployed without prior algorithmic impact assessment aia unless clear significant impact life individuals certification ads encouraged even mandatory certain sectors dillon reisman colleagues already advocated aia practical framework public agency accountability recent ainow institute report beyond existing proposed automated ecision systems evaluating potential impacts fairness justice bias concerns across affected communities emphasi need researcher review processes system acquired also recommend agencies provi notice public ads solicit public comments clarify concerns answer outstanding questions due process mechanisms affected individuals communities challenge inadequate assessments unfair biased otherwis harmful system uses even ainow report focuses public agencies recommendations also apply sensitive ads deployed private sector outlined reisman colleagues two major differences heir aia framework dpia requirements gdpr dpia shared public built external researcher review individualis due process mechanisms agree aia ambitious matters lack external review publicity major weakness gdpr regarding dpia conducting aia simple models tools proposed make easier done even though many assessment criteria bound remain subjective aia framework provide evaluation methodology systematic rigorous possible definition aia framework outside scope documen proposed ethical committees oversight agencies suggested highlight key issues considered aia legitimacy first question addressed legitimacy use ads legitimacy addressed three levels legitimacy purpose ads example role risk prediction instruments play criminal sentencing legitimate take sanctions based crimes yet mmitted legitimate desirable type processing likely result high risk rights freedoms natural persons example seem necessary impose aia ads included consumer electronic chess game dillon reisman jason schultz kate crawford meredith whittaker algorithmic impact assessments practical framework public agency accountability ainow institute example cnil french dpa made available tool help data controllers conduct dpia understanding algorithmic decision opportunities challenges grade teachers use rank ing decide whether contract renewed legitimate use social network connections person take decision whether giv loan generally whose interests ads serve legitimacy underlying technique example use machine learning techniques topic heated debate establish correlation rather causation relations illustration chelsea barabas colleagues argue machine learning used prediction rather surface covariates fed causal model understanding social structural psychological drivers rime james greiner also argues used civil rights litigation regression suffers several shortcomings facilitates biased result oriented thinking expert witnesses encourages judges litigators believe tha questions equally answerable gives wrong answer situations might avoided difficulties several others stem fact regression begin paradigm defining causal effects drawing causal inferences legitimacy criteria used model example risk prediction instruments used criminal sentencing legitimate use demographic socioeconomic variables legitimate use geogr aphical parameters personalised pricing legitimate insurance companies use genetic data qualities system passed legitimacy test second type question exists relates intrinsic qualities model discussed chapter expected properties include fairness privacy reliability security accuracy etc property may less critical depending purpose ads case relevant properties systematica lly taken consideration rigorously assessed great care must paid particular justification choices made several properties tension accuracy fairness different definitions available iven objective fairness privacy integration within human environment third main issue integration ads within human environment including users affected persons external experts oversight agencies thi issues like transparency explainability come play believe transparency explainability defined chapter rule default broad possible restrictions applied justified burden proof lie operator ads justifications based example need protect intellectual property rights industrial secrets cases also argued blication details ads logic could defeat purpose would make easier manipulate case ads used fraud detection selecting tax payers subject manual audits example case arguments used justify minimising information disclosed general public evade independent reviews certifications accredited bodies stated ainow report ads operators also provide ways ople affected able challenge chelsea barabas karthik dinakar joichi ito madars virza jonathan zittrain interventions predictions reframing ethical debate actuarial risk assessment processing machine learning research james greiner causal inference civil rights litigation harvard law review sonja starr evidence sentencing scientific rationa lization discrimination stanford law review stoa panel future science technology decisions taken basis ads considering behaviour certain systems continuously evolves also possible oversight agencies audit regular basis types risks sho uld considered aia including individual collective risks allocative risks denying loan representational risks labelling images black people clear however aia focu risks using ads also assess risks using ads words aia consider benefits risks example several studies conducted use ads area justice focusing risks discrimination others benefits improv ing judges addition benefit risk balance applies primary functionalities ads transparency explainability features example transparency explainability generally make ads effective users understand results system may use properly however ads robust uses rough proxies number ongoing lease contracts ads used make loan decision manipulated people affected example closing merging lease contracts risks benefits identified chapter used check relevant issues considered conceptual framework proposed tal zarsky also serve inspiration enefit analysis complementary question development certification schemes ads certifications labels properly implemented way enhance trust ads verify comply certain rules sence bias discrimination implementation certification scheme must carefully thought ensure really trustworthy requires serious audits independent third parties ideally accredited national body remaining acceptable economic standpoint believe certification requirements obligations sectoral indeed needs risks vary greatly one type application another sectoral supervisory authorities agencies better position define reference evaluation criteria control application ads certification either voluntary basis encouraged gdpr mandatory certain areas justice healthcare even target official certificate label important test validate ads audited external reviewers deployment tests check desired requirements met lead recommendations improve system initiative worth mentioning respect new company called orcaa risk consulting algorithmic auditing orcaa reviews algorithms using ethical matrix including criteria accuracy consistency bias transpare ncy fairness timeliness conclusion study present number desired properties objectives ads different technical legal instruments achieve facilitate also discusse limitations proposed dillon reisman jason schultz kate crawford meredith whittaker algorithmic impact assessments practical framework public agency accountability ainow institute sonja starr evidence sentencing scientific rationalization discrimination stanford law review jon kleinberg himabindu lakk araju jure leskovec jens ludwig sendhil mullainathan human decisions machine predictions national bureau eco nomic research nbec working paper tal zarsky transparent predictions university illinois law review understanding algorithmic decision opportunities challenges instruments put forward options stage stress options general suggestions resulting analysis builds previous reports studies could serve starting point multi discussion suggested section conclude desiderata algorithms put perspective define transparency availability ads code design documentation parameters learning dataset ads relies machine earning however argued kroll many authors source code computer systems illegible non experts transparency therefore seen ultimate solution users people affected decisions ads main benefit rather independent experts evaluation bodies dpas example audit ads certify achieve goal ads code necessarily need made public avoid intellectual property issues made available evaluators bound confidentiality agreement public scrutiny community spirit open source communities detect potential bugs unacceptable features possibly suggest improvements option espe cially relevant ads used administrations kroll also argue even experts often struggle understand software code inspecting source code limited way predicting computer program behave hence need explanations users affected people also designers developers shown section explainability different meanings needs explainability vary considerably according audience designers developers may interested types explanations including operational explanations system actually works logical explanations logical relationships inputs results causal explanations causes resu lts users especially professional users medical doctors judges able understand general logic ads global logical explanations decisional criteria respective weights well reasons specific results local causal explanations affected people probably interested reasons decisions affect local causal explanations influence counterfactual explanations generally speaking explainability like transparency seen end means end end example able improve fairness ads challenge decision also important note requirements explainability vary one ads another according potential impact decisions made example finale doshi kim argue sometimes even necessary significant consequences unacceptable results problem sufficiently well validated real applications trust system decision even system perfect second condition applies example automated metro systems kroll accountable algorithms univ penn law review except ads used fraud detection whose code may remain confidential sandra wachter brent mittelstadt chris russel counterfactual explanations without opening black box automated decisions gdpr harvard journal law technology intended probably explanations general public one could argue explanations still useful expe rts validate system could also possibly useful collectivity spirit open source communities order detect potential bugs suggest improvements stoa panel future science technology validated certified independent experts however situations ads used medical doctors judges explainability absolute requirement fact one could argue ads ake automated decisions produce results used therefore interpreted human beings make decisions human makers must therefore sufficient understanding results limitations able use appropriate way finale doshi kim also argue need interpretability stems incompleteness problem formali sation creating fundamental barrier optimis ation evaluation however discussed chapter significant progress yet made provide assess explainability tools really useful non argued tim miller authors emergence explainable positive paper argues researchers building explanatory agents rather intended users explainable likely succeed researchers practitioners understand adopt implement improve models vast valuable odies research philosophy psychology cognitive science evaluation models focused people technology addition even legal obligation explainability desirable ads obligation way ads providers operators evade responsibilities described edwards veale risk right explanation puts onus users affected people challenge decisions wrong first even individuals right ask explanation right may easy exercise ads endowed explanation facilities may still require user minimal amount familiarity technology fol low administrative procedure process may lengthy demanding requiring certain level motivation persistence noted edwards veale legal right explanation may good place start means end story rights become dangerous things unreasonably hard exercise ineffective results give illusion something done fact things better second even explanation obtained may sufficient able understand decision point challenged addition bias discrimination may detected studying whole corpus users something difficult individual challenges although transparency explainability ads required cases argue far protection individuals concerned accountability important requirement fact transparency explainability may allow discovery deficiencies guarantee reliability security fairness ads accountability achieved via different means algorithm impact assessments aia auditing certification main virtue accountability put onus providers operators ads demonstrate meet expected requirements course accountability provide miller howe sonenberg explainable beware inmates running asylum ijcai workshop explainable artificial intelligence xai edwards veale eslaving algorithm right explanation right better decisions ieee security privacy legal right explanation may good place start means end story rights become dangerous things unreasonably hard exercise ineffective results give illusion something done fact things better understanding algorithmic decision opportunities challenges absolute guarantees either certification rigorous audits conducted regular basis potential issues identified corrective measures taken addition sanctions significant enough accountability approach provides strong incentives ads roviders comply requirements perspective oversight agencies supervisory authorities play central role critically important means necessary carry duties means terms funding expertise also power access analyse details ads including source code training data last least believe appropriate accountability measures taken also potential improve transparency reduce unfairness discrimination another benefit using one already observed fact put decisions front centre public debate decisions taken far sight illustration controversy compas algorithm triggered debate types evidence used sentencing usa another area ads used match students universities france apb post bac replaced given rise many discussions rules used allocate students universities level automation considered acceptable context stoa panel future science technology bibliography abadi chu goodfellow mcmahan mironov talwar zhang deep learning differential privacy acm computer communication security ccs abraha rabin automated vehicles manufacturer responsibility accidents new legal regime new era virginia law review forthcoming amodei olah steinhardt christiano schulman mane concrete problems safet annany towards ethics algorithms convening observation probability timeliness science technology human values ananny crawford seeing without knowing limitations transparency ideal application algorithmic accountability new media society andreou venkatadri goga gummadi loiseau mislove investigating transparency mechanisms social media case study faceb ook explanations proceedings network distributed systems security ndss symposium ateniese mancini spognardi villani vitali felici hacking smart machines smarter ones extract meaningful data machine learning classifiers international journal security networks barabas dinakar ito virza zittrain interventions predictions reframing ethical debate actuarial risk assessment processing chine learning research barreno nelson sears joseph tygar machine learning secure acm symposium information computer communications security asiaccs acm new york usa berendt prei busch toward accountable discrimination data mining importance keeping human loop looking big data berk heidari jabbari kearns roth fairness criminal justice risk assessments state art sociological methods research biggio nelson laskov support vector machines adversarial label noise journal machine learning research binns algorithmic accountability public reason philosophy technology birnbaum credit scoring insurance costing consumers billions perpetuating racial divide national consumer law center bradshaw matthews ghahramani adversarial examples uncertainty transfer testing robustness gaussian process hybrid deep networks arxiv preprint bonnefon shariff rahwan social dilemma autonomous vehicles science bolukbasi chang zou saligr ama kalai man computer programmer woman homemaker debiasing word embeddings proceedings international conference neural information processing systems nips bostrom superintelligence paths dangers stra tegies oxford university press bovens analysing assessing accountability conceptual framework european law journal understanding algorithmic decision opportunities challenges burell machine understanding opacity machine learning algorithms big data society calders verwer three naive bayes approaches discrimination classification data mining knowledge discovery carlini wagner adversarial examples easily detected bypassing ten detection methods acm workshop artificial intelligence security caruana lou gehrke koch sturm elhadad intelligible models healthcare predicting pneumonia risk hospital readmission proceedings acm knowledge discovery data mining conference kdd chen mislove wilson peeking beneath hood uber acm internet measurement conference imc christin rosenblat boyd courts predictive algorithms workshop data civil rights new era policing justice chouldocheva fair prediction disparate impact study bias recidivism prediction instruments big data special issue social technical trade citron pasquale sco red society due process automated predictions washington law review citron technological due process washington university law review craven shavlik extracting tree representations trained netw orks conference advances neural information processing systems craven shavlik using sampling queries extract rules trained neural networks international conference machine learning icml crawford schultz big data due process toward framework redress predictive privacy harms boston college law review danzinger levav avnaim extraneous factors judicial decisions proceedings national academic sciences pnas datta tschantz datta automated experiments privacy settings privacy enhancing technologies pet deng wuyts scandariato preneel joosen privacy threat analysis framework supporting elicitation fulfilment privacy requirements requirements engineering desai kroll trust verify guide algorithms law harvard journal law technology dhurandhar iyengar lus shanmugam formal framework characterize interpretability procedures icml workshop human interpretability machine learning diakopoulos accountability algorithmic decision making communications acm doshi kim towards rigorous science interpretable machine learning duchesne cytermann vachey morel aureau rapport relatif aux données général conseil général inspection générale des finances dwork roth algorithmic foundations differential privacy foundations trends theoretical computer science stoa panel future science technology dwork hardt pitassi reingold zemel fairness awareness proc innovations theoretical computer science edwards veale slave algorithm right explanation probably remedy looking duke law technology review edwards veale eslaving algorithm right explanation better decisions ieee security privacy edwards price prejudice case consumer equality information age lewis clark law review eslami rickman vaccaro aleyasen vuong karahalios hamilton sandvig always assumed really close reasoning invisible algorithms news feed conference human factors computing systems chi esteva andre kuppel novoa swetter blau thrun dermatologist classification skin cancer deep neural networks nature feldman friedler moeller scheidegger venkatasubramanian certifying removing disparate impact kdd floridi human dignity foundation right privacy philosophy technology fredrikson lantz jha lin page ristenpart privacy pharmacogenetics end case study personalized warfarin dosing usenix security symposium fredrikson jha ristenpart model inversion attacks exploit confidence information basic countermeasures proceedings acm sigsac onference computer communications security feldman friedler moeller scheidegger venkatasubramanian certifying removing disparate impact proceedings acm sigkdd international conference knowledge discove data mining kdd friedman nissenbaum bias computer systems acm transactions information systems gilad ran laine lauter naehrig wernsing cryptonets applying neural networks encrypt data high throughput accuracy international conference machine learning goel perelman shroff sklansky combatting police discrimination age big data new criminal law review rigazio towa rds deep neural network architectures robust adversarial examples proceedings international conference learning representations iclr guidotti monreale turini pedreschi giannotti survey methods explaining black box models goodfellow shlens szegedy explaining harnessing adversarial examples international conference learning representations computational biological learning society goodman flaxma european union regulations algorithmic decision right explanation magazine greiner causal inference civil rights litigation harvard law review overdorf kulynych balsa troncoso gur ses pots revolution optimized eprint understanding algorithmic decision opportunities challenges hajian direct indirect discrimination prevention methods discrimination privacy information society studies applied philosophy epistemology rational ethics springer hajian martinez rule protection indirect discrimination prevention data mining modeling decisions artificial intelligence lecture notes computer science hannak soeller lazer mislove wilson measuring price discrimination steering commerce web sites acm internet measurement conference imc hannah actuarial sentencing proposition justice quarterly hardt price srebro equality opportunity supervised learning proceedings international conference neural information processing systems nips hert papakonstantinou new general data protection regulation still sound system protection individuals computer law security review jones machine learning could help improve climate forecasts nature joyee métayer priam privacy risk analysis methodology ieee international workshop data privacy management dpm katz barrett dill julian kochenderfer reluplex efficient smt solver verifying deep neural networks arxiv preprint kamishima ahako asoh sakuma classifier prejudice remover regularized padm kamiran calders classification discrimination preferential sampli proc machine learning conference belgium netherlands kleinberg lakkaraju leskovec ludwig mullainathan human decisions machine predictions national bureau economic research nbec working paper kloft laskov online anomaly detection adversarial impact international conference artificial intelligence statistics kroll huey barocas felten reidenberg robinson accountable algorit hms univ penn law review lacave diez review explanation methods bayesian networks knowledge engineering review lacave atienza diez graphical explanation bayesian networks proceedings ismda conference spinger verlag lncs landecker thomure bettencourt mitchell kenyon brumby interpreting individual classifications hierarchical networks ieee symposium computational intelligence data mining cid lecuyer spahn spiliopolous chaintreau geambasu hsu sunlight fine targeting detection scale statistical confidence acm conference computer communications security ccs wang han xue wei thoracic disease identification localization limited supervision lei barzilay jaakkola rationalizing neural predictions proceedings conference empirical methods tural language processing emnlp stoa panel future science technology lipton mythos model interpretability proceedings icml workshop human interpretability machine learning whi lou caruana gehrke intelligible models classification regression proceedings acm knowledge discovery data mining conference kdd lou caruana gehrke hooker accurate intelligible models pairwise interactions proceedings acm knowledge discovery data mining conference kdd madumal miller vetere sonenberg towards grounded dialog model explainable artificial intelligence first international workshop socio systems malgieri comandé right legibi lity automated decision exists general data protection regulation international data privacy law maxmen machine learning spots treasure trove elusive viruses nature news mcdaniel papernot celik machine learning adversarial settings ieee security privacy mcmahan moore ramage hampson agüera arcas communication learning deep networks decentralized data arxiv preprint metzen genewein fischer bischoff detecting adversarial perturbations proceedings international conference learning representations iclr miller howe sonenberg explainable beware inmates running asylum proc ijcai workshop explainable artificial intelligence xai mittelstadt allo taddeo wachter floridi ethics algorithms mapping debate big data society monahan risk assessment criminal sentencing university virgi nia school law public law legal theory research paper series montavon samek müller methods interpreting understanding deep neural networks digital signal processing moosavi fawzi fro ssard deepfool simple accurate method fool deep neural networks arxiv preprint weapons math destruction big data increases inequality threatens democracy crown publishing group new york papernot mcdaniel goodfellow jha celik swami practical black attacks deep learning systems using adversarial examples arxiv preprint papernot mcdaniel jha swami istillation defense adversarial perturbations deep neural networks ieee security privacy papernot mcdaniel sinha wellman towards science security privacy machine learning ieee european sym posium security privacy london papernot mcdaniel jha fredrikson celik swami limitations deep learning adversarial settings proceedings ieee european symposium security privacy pedreschi ruggieri turini measuring discrimination socially decision records proc siam data mining conference sdm penney chilling effects online surveillance wikipedia use berkeley technology law journal understanding algorithmic decision opportunities challenges perdisci dagon lee fogla sharif misleading worm signature generators using deliberate noise injection ieee security privacy raab meaning accountability information privacy context managing privacy accountability basingstoke palgrave macmillan reisman schultz crawford whittaker algorithmic impact assessments practical framework public agency accountability ainow institute white paper ribeiro singh guestrin trust explaining predictions classifier proceedings acm knowledge discovery data mining conference kdd ribeiro singh guestrin anchors high precision model explanations thirty second aaai conference artificial intelligence rice swesnik discriminatory effects credit scoring communities color suffolk university law review xlvi romei ruggieri multidisciplinary survey discrimination analysis knowledge engineering review rouvroy end critique data behaviourism due privac due process computational turn routledge rouvroy poullet right informational self value self reassessing importance privacy democracy reinventing data protection serge twirth eds springer rubinstein nelson huang joseph lau rao taft tygar antidote understanding defending poisoning anomaly detectors acm sigcomm conference internet measuremen senden soft law self european law meet electronic journal comparative law selbst powles meaningful information right explanation international data privac law shah use personal data common good nature sharif bhagavatula bauer reiter adversarial generative nets neural network attacks state face recognition arxiv preprint sharif bhagavatula bauer reiter accessorize crime real stealthy attacks state face recognition proceedings acm sigsac conference computer communications security shokri stronati shmatikov membership inference attacks machine learning models ieee security privacy shokri shmatikov privacy deep learning acm computer communication security ccs song shu kushman ermon generative adversarial examples arxiv preprint solon selbst big data disparate impact california law review spagnuelo bartolini lenzini metrics transparency proceedings data privacy management security assurance stoa panel future science technology starr evidence sentencing scientific rationalization discrimination stanford law review stone brooks brynjolfsson calo etzioni hager hirschberg kalyanakrishnan kamar kraus leyton parkes press saxenian shah tambe teller artificial intelligence life one hundred year study artificial intelligence report study panel stanford university stanford szegedy zaremba sutskever bruna erhan goodfellow fergus intriguing properties neural networks arxiv preprint tramer zhang juels reite ristenpart stealing machine learning models via prediction apis usenix security tutt fda algorithms administrative law review wachter mittelstadt russel counterfactual explanations without opening lack box automated decisions gdpr harvard journal law technology wachter mittelstadt floridi right explanation automated decision exist general data protection regulation international data privacy law wright hert privacy impact assessment springer yin han cpar classification based predictive association rules proc siam icdm yuan zhu adversarial examples tacks defenses deep learning arxiv preprint zafar valera gomez rodriguez gummadi fairness beyond disparate treatment disparate impact learning classification without disparate mistreatment proceedings international conference world wide web www zarsky transparent predictions university illinois law review zeiler fergus visualising understanding convolutional networks proceedings eccv springer lncs zemel swersky pitassi dwork learning fair representations proc intl conf machine learning zuiderveen borgesius online price discrimination data protection law amsterdam law school legal stud ies research paper zuiderveen borgesius trilling möller bodo vreese helberger worry filter bubbles internet policy review expected benefits algorithmic decision systems ads may negated variety risks individuals discrimination unfair practices loss autonomy etc economy unfair practices limited access markets etc society whole manipulation threat democracy study present existi options reduce risks related ads explain limitations sketch policy option overcome limitations able benefit tremendous possibilities ads limiting risks related use beyond providing systematic review situation study gives precise definition number key terms analysis differences main focus study technical aspects ads however broaden discussio legal ethical social dimensions considered publication scientific foresight unit stoa eprs european parliamentary research service document prepared addressed members staff european parliament background material assist parliamentary work content document sole responsibility author opinions expressed herein taken represent official osition parliament isbn doi
