google responsible practices google responsibility responsibility principles objectives building beneficial responsible practices guiding responsible development governance operations review approval process social good addressing societal challenges policy contributions governance featured research benefit humanity examples work improving skin tone evaluation machine learning uphold principles discover discover generative overview teams google using gemini ecosystem learn models products platforms palm next generation language model leading models learn models focus areas science accelerating scientific discovery health healthcare quantum building useful quantum computer learn blogs current news stories google research publications tools datasets featured content largest capable model build responsibility responsible practices development created new opportunities improve lives people around world business healthcare education also raised new questions best way build fairness interpretability privacy safety systems general recommended practices fairness interpretability privacy safety security general recommended practices general best practices software systems always followed designing systems also number considerations unique machine learning recommended practices use design approach way actual users experience system essential assessing true impact predictions recommendations decisions design features appropriate disclosures clarity control crucial good user experience consider augmentation assistance producing single answer appropriate high probability answer satisfies diversity users use cases cases may optimal system suggest options user technically much difficult achieve good precision one answer versus precision answers model potential adverse feedback early design process followed specific live testing iteration small fraction traffic full deployment engage diverse set users scenarios incorporate feedback throughout project development build rich variety user perspectives project increase number people benefit technology identify multiple metrics assess training monitoring use several metrics rather single one help understand tradeoffs different kinds errors experiences consider metrics including feedback user surveys quantities track overall system performance product heath rate customer lifetime value respectively false positive false negative rates sliced across different subgroups ensure metrics appropriate context goals system fire alarm system high recall even means occasional false alarm possible directly examine raw data models reflect data trained analyze raw data carefully ensure understand cases possible sensitive raw data understand input data much possible respecting privacy example computing aggregate anonymized summaries data contain mistakes missing values incorrect labels data sampled way represents users used ages training data senior citizens setting used training data summer data accurate difference performance training performance persistent challenge training try identify potential skews work address including adjusting training data objective function evaluation continue try get evaluation data representative possible deployed setting features model redundant unnecessary use simplest model meets performance goals supervised systems consider relationship data labels items trying predict using data label proxy predict label cases gap problematic data bias another important consideration learn practices fairness understand limitations dataset model model trained detect correlations used make causal inferences imply model may learn people buy basketball shoes taller average mean user buys basketball shoes become taller result machine learning models today largely reflection patterns training data therefore important communicate scope coverage training hence clarifying capability limitations models shoe detector trained stock photos work best stock photos limited capability tested cellphone photos communicate limitations users possible example app uses recognize specific bird species might communicate model trained small set images specific region world better educating user may also improve feedback provided users feature application test test test learn software engineering best test practices quality engineering make sure system working intended trusted conduct rigorous unit tests test component system isolation conduct integration tests understand individual components interact parts overall system proactively detect input drift testing statistics inputs system make sure changing unexpected ways use gold standard dataset test system ensure continues behave expected update test set regularly line changing users use cases reduce likelihood training test set conduct iterative user testing incorporate diverse set users needs development cycles apply quality engineering principle build quality checks system unintended failures either happen trigger immediate response important feature unexpectedly missing system output prediction continue monitor update system deployment continued monitoring ensure model takes performance user feedback happiness tracking surveys heart framework account issues occur model world imperfect almost definition build time product roadmap allow address issues consider solutions issues simple fix blocklisting may help solve problem quickly may optimal solution long run balance simple fixes learned solutions updating deployed model analyze candidate deployed models differ update affect overall system quality user experience examples work google research beyond responsible learn data cards playbook learn imagen diffusion model learn explorables learn improving skin tone evaluation machine learning learn using study years representation learn announcements learn wordcraft writer workshop learn google research beyond responsible learn data cards playbook learn imagen diffusion model learn explorables learn improving skin tone evaluation machine learning learn using study years representation learn announcements learn wordcraft writer workshop learn fairness systems enabling new experiences abilities people around globe beyond recommending apps short videos shows systems used critical tasks predicting presence severity medical condition matching people jobs partners identifying person crossing street computerized assistive systems potential fair inclusive broader scale historical processes based hoc rules human judgments risk unfair bias systems also impact thus impact increases across sectors societies critical work towards systems fair inclusive hard task first models learn existing data collected real world model may learn even amplify problematic biases data based race gender religion characteristics second even rigorous training testing challenge build systems fair across situations cultures example speech recognition system trained adults may fair inclusive specific context used teenagers however system may fail recognize evolving slang words phrases system deployed united kingdom may harder time certain regional british accents others even system applied adults might discover unexpected segments population whose speech handles poorly example people speaking stutter use system launch reveal unintentional unfair outcomes difficult predict third standard definition fairness whether decisions made humans machines identifying appropriate fairness criteria system requires accounting user experience cultural social historical political legal ethical considerations several may tradeoffs even situations seem simple people may disagree fair may unclear point view dictate policy especially global setting said possible aim continuous improvement toward fairer systems addressing fairness equity inclusion active area research requires holistic approach fostering inclusive workforce embodies critical diverse knowledge seeking input communities early research development process develop understanding societal contexts assessing training datasets potential sources unfair bias training models remove correct problematic biases evaluating models disparities performance continued adversarial testing final systems unfair outcomes fact models even used identify conscious unconscious human biases barriers inclusion developed perpetuated throughout history bringing positive change far solved problem fairness presents opportunity challenge google committed making progress areas creating tools datasets resources larger community adapting new challenges arise development generative systems current thinking google outlined show show less recommended practices important identify whether machine learning help provide adequate solution specific problem hand single correct model tasks single technique ensures fairness every situation outcome practice researchers developers consider using variety approaches iterate improve especially working emerging area generative design model using concrete goals fairness inclusion engage social scientists humanists relevant experts product understand account various perspectives consider technology development time impact different use cases whose views represented types data represented left outcomes technology enable compare different users communities biases negative experiences discriminatory outcomes might occur set goals system work fairly across anticipated use cases example different languages different age groups monitor goals time expand appropriate design algorithms objective function reflect fairness goals update training testing data frequently based uses technology use use representative datasets train test model assess fairness datasets includes identifying representation corresponding limitations well identifying prejudicial discriminatory correlations features labels groups visualization clustering data annotations help assessment public training datasets often need augmented better reflect frequencies people events attributes system making predictions understand various perspectives experiences goals people annotating data success look like different workers time spent task enjoyment task working annotation teams partner closely design clear tasks incentives feedback mechanisms ensure sustainable diverse accurate annotations account human variability including accessibility muscle memory biases annotation using standard set questions known answers check system unfair biases example organize pool trusted diverse testers adversarially test system incorporate variety adversarial inputs unit tests help identify may experience unexpected adverse impacts even low error rate allow occasional bad mistake targeted adversarial testing help find problems masked aggregate metrics designing metrics train evaluate system also include metrics examine performance across different subgroups example false positive rate false negative rate per subgroup help understand groups experience disproportionately worse better performance addition sliced statistical metrics create test set system difficult cases enable quickly evaluate well system examples particularly hurtful problematic time update system test sets continuously update set system evolves features added removed feedback users consider effects biases created decisions made system previously feedback loops may create analyze performance take different metrics defined account example system false positive rate may vary across different subgroups data improvements one metric may adversely affect another evaluate user experience scenarios across broad spectrum users use cases contexts use tensorflow model analysis test iterate dogfood first followed continued testing launch even everything overall system design carefully crafted address fairness issues models rarely operate perfection applied real live data issue occurs live product consider whether aligns existing societal disadvantages impacted solutions examples work measuring gendered correlations nlp models learn tensorflow constrained optimization library learn project respect learn translations google translate learn mindiff fairness learn data decisions theoretical implications adversarially learning fair representations learn measuring gendered correlations nlp models learn tensorflow constrained optimization library learn project respect learn translations google translate learn mindiff fairness learn data decisions theoretical implications adversarially learning fair representations learn interpretability automated predictions decision making improve lives number ways recommending music might like monitoring patient vital signs consistently interpretability level question understand trust system crucial interpretability also reflects domain knowledge societal values provides scientists engineers better means designing developing debugging models helps ensure systems working intended issues apply humans well always easy person provide satisfactory explanation decisions example difficult oncologist quantify reasons think patient cancer may may say intuition based patterns seen past leading order tests definitive results contrast system list variety information went prediction biomarker levels corresponding scans different patients past years hard time communicating combined data estimate chance cancer recommendation get pet scan understanding complex models deep neural networks foundation generative systems challenging even machine learning experts understanding testing systems also offers new challenges compared traditional software especially generative models systems continue emerge traditional software essentially series rules interpreting debugging performance largely consists chasing problem garden forking paths extremely challenging human generally track path taken code understand given result systems code path may include millions parameters generative systems may include billions mathematical operations much harder pinpoint one specific bug leads faulty decision previous software however responsible system design millions billions values traced back training data model attention specific data features resulting discovery bug contrasts one key problems traditional software existence magic numbers rules thresholds set without explanation programmer often based personal intuition tiny set trial examples overall system best understood underlying training data training process well resulting model poses new challenges collective effort tech community formulate proactive responsible guidelines best practices tools steadily improving ability understand control debug systems like share current work thinking area show show less recommended practices interpretability accountability area ongoing research development google broader community share recommended practices date plan options pursue interpretability pursuing interpretability happen designing training model degree interpretability really need work closely relevant domain experts model healthcare retail etc identify interpretability features needed rare sufficient empirical evidence interpretability needed analyze data example working private data may access investigate input data change data example gather training data certain subsets feature space gather test data categories interest design new model constrained model providing much transparency potentially opening vectors abuse interpretability options access internals model black box white box treat interpretability core part user experience iterate users development cycle test refine assumptions user needs goals design users build useful mental models system given clear compelling information users may make theories system works negatively affect try use system possible make easy users sensitivity analysis empower test different inputs affect model output additional relevant resources designing human needs user control teaching habituation fairness representation design model interpretable use smallest set inputs necessary performance goals make clearer factors affecting model use simplest model meets performance goals learn causal relationships correlations possible use height age predict kid safe ride roller coaster craft training objective match true goal train acceptable probability false alarms accuracy constrain model produce relationships reflect domain expert knowledge coffee shop likely recommended closer user everything else choose metrics reflect metrics consider must address particular benefits risks specific context example fire alarm system would need high recall even means occasional false alarm understand trained model many techniques developed gain insights model sensitivity inputs analyze model sensitivity different inputs different subsets examples communicate explanations model users provide explanations understandable appropriate user technical details may appropriate industry practitioners academia general users may find prompts summary descriptions visualizations useful explanations informed careful consideration philosophical psychological computer science including hci legal ethical considerations counts good explanation different contexts identify explanations may appropriate explanations could result confusion general users nefarious actors could take advantage explanation system user abuse explanations may reveal proprietary information consider alternatives explanations requested certain user base provided possible provide clear sound explanation could instead provide accountability mechanisms auditing allow users contest decisions provide feedback influence future decisions experiences prioritize explanations suggest clear actions user take correct inaccurate predictions going forward imply explanations mean causation unless recognize human psychology limitations confirmation bias cognitive fatigue explanations come many forms text graphs statistics using visualization provide insights use best practices hci visualization aggregated summary may lose information hide details partial dependency plots ability understand parts system especially inputs parts work together completeness helps users build clearer mental models system mental models match actual system performance closely providing trustworthy experience accurate expectations future learning mindful limitations explanations local explanations may generalize broadly may provide conflicting explanations two examples test test test learn software engineering best test practices quality engineering make sure system working intended trusted conduct rigorous unit tests test component system isolation proactively detect input drift testing statistics inputs system make sure changing unexpected ways use gold standard dataset test system ensure continues behave expected update test set regularly line changing users use cases reduce likelihood training test set conduct iterative user testing incorporate diverse set users needs development cycles apply quality engineering principle build quality checks system unintended failures either happen trigger immediate response important feature unexpectedly missing system output prediction conduct integration tests understand system interacts systems feedback loops created recommending news story popular make news story popular causing recommended examples work explainable google cloud learn tensorflow lattice open source learn xrai learn deepdream building blocks interpretability learn tool open source learn towards rigorous science interpretable machine learning learn explainable google cloud learn tensorflow lattice open source learn xrai learn deepdream building blocks interpretability learn tool open source learn towards rigorous science interpretable machine learning learn privacy models learn training data make predictions input data sometimes training data input data quite sensitive although may enormous benefits building model operates sensitive data cancer detector trained responsibly sourced dataset biopsy images deployed individual patient scans essential consider potential privacy implications using sensitive data includes respecting legal regulatory requirements also considering social norms typical individual expectations example crucial put safeguards place ensure privacy individuals considering models may remember reveal aspects data exposed essential offer users transparency control data fortunately possibility models reveal underlying data minimized appropriately applying various techniques precise principled fashion google constantly developing techniques protect privacy systems including emerging practices generative systems active area research community ongoing room growth share lessons learned far recommended practices single correct model tasks single correct approach privacy protection across scenarios new ones may arise practice researchers developers must iterate find approach appropriately balances privacy utility task hand process succeed clear definition privacy needed intuitive formally precise collect handle data responsibly identify whether model trained without use sensitive data utilizing data collection existing public data source essential process sensitive training data strive minimize use data handle sensitive data care comply required laws standards provide users clear notice give necessary controls data use follow best practices encryption transit rest adhere google privacy principles anonymize aggregate incoming data using best practice pipelines consider removing personally identifiable information pii outlier metadata values might allow including implicit metadata arrival order removable random shuffling prochlo cloud data loss prevention api automatically discover redact sensitive identifying data leverage processing appropriate goal learn statistics individual interactions often certain elements used consider collecting statistics computed locally rather raw interaction data include sensitive information consider whether techniques like federated learning fleet devices coordinates train shared global model training data improve privacy system feasible apply aggregation randomization scrubbing operations secure aggregation rappor prochlo encode step note operations may provide pragmatic privacy unless techniques employed accompanied proofs appropriately safeguard privacy models models expose details training data via internal parameters well behavior crucial consider privacy impact models constructed may accessed estimate whether model unintentionally memorizing exposing sensitive data using tests based exposure measurements membership inference assessment metrics additionally used regression tests model maintenance experiment parameters data minimization aggregation outlier thresholds randomization factors understand tradeoffs identify optimal settings model train models using techniques establish mathematical guarantees privacy note analytic guarantees guarantees complete operational system follow processes established cryptographic software use principled provable approaches publication new ideas critical software components enlistment experts review stages design development examples work federated reconstruction partially local federated learning learn rappor open source learn prochlo learn federated learning learn tensorflow federated open source learn secure aggregation protocol learn federated reconstruction partially local federated learning learn rappor open source learn prochlo learn federated learning learn tensorflow federated open source learn secure aggregation protocol learn safety security safety security entails ensuring systems behave intended regardless attackers try interfere essential consider address safety system widely relied upon applications many challenges unique safety security systems example hard predict scenarios ahead time applied problems difficult humans solve especially era generative also hard build systems provide necessary proactive restrictions safety well necessary flexibility generate creative solutions adapt unusual inputs technology evolves security issues attackers surely find new means attack new solutions need developed tandem current recommendations learned far recommended practices safety research spans wide range threats including training data poisoning recovery sensitive training data model theft adversarial security examples google invests research related areas work related practices privacy one focus safety research google adversarial use one neural network generate adversarial examples fool system coupled second network try detect fraud currently best defenses adversarial examples yet reliable enough use production environment ongoing extremely active research area yet effective defense developers think whether system likely come attack consider likely consequences successful attack cases simply build systems attacks likely significant negative impact another practice adversarial testing method systematically evaluating model application intent learning behaves provided malicious inadvertently harmful input asking text generation model generate hateful rant particular religion practice helps teams systematically improve models products exposing current failure patterns guide mitigation pathways model putting place filters safeguards input outputs recently evolved ongoing red teaming efforts adversarial security testing approach identifies vulnerabilities attacks ethically hack systems support secure framework identify potential threats system consider whether anyone would incentive make system misbehave example developer builds app helps user organize photos would easy users modify photos incorrectly organized users may limited incentive identify unintended consequences would result system making mistake assess likelihood severity consequences build rigorous threat model understand possible attack vectors example system would allow attacker change input model may much vulnerable system processes metadata collected server like timestamps actions user took since much harder user intentionally modify input features collected without direct participation develop approach combat threats applications spam filtering successful current defense techniques despite difficulty adversarial test performance systems adversarial setting cases done using tools cleverhans create internal red team carry testing host contest bounty program encouraging third parties adversarially test system keep learning stay ahead curve stay date latest research advances research adversarial machine learning continues offer improved performance defenses defense techniques beginning offer provable guarantees beyond interfering input possible may vulnerabilities supply chain knowledge attack yet occurred important consider possibility prepared examples work adversarial examples learn evaluating adversarial robustness learn ensemble adversarial training learn cleverhans learn unrestricted adversarial examples challenge learn concrete problems safety learn adversarial examples learn evaluating adversarial robustness learn ensemble adversarial training learn cleverhans learn unrestricted adversarial examples challenge learn concrete problems safety learn privacy terms google google products cookies management controls feedback
