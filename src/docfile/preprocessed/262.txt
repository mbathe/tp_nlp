responsible key themes concerns recommendations european research innovation summary consultation multidisciplinary experts version june steve brian pickering michael bonif ace university southampton innovation centre michael anderson professor emeritus comput science university hartford usa david danks thurstone professor philo sophy psychology carnegie mellon university asbjørn følstad senior research scientist sintef matthias leese senior researcher cent security studies eth zurich vincent müller university academic fellow interdis ciplinary ethics applied centre idea school philosophy religion history ience university leeds tom sorell professor politics philosophy university warwick alan winfield professor robot ethics university west england fiona woollard associate professor philosophy university southampton contact author sjt page acknowledgements authors would like thank professor kirstie ball professor virginia dignum william mcneill professor luis moniz pereira professor thomas powers professor sophie valuable contributions consultation report supported collaborative platfo unlock value next generation internet experimentation project grant agreement disclaimer content document merely informative present formal statement individuals european commission views expressed herein commit european commission way opinions expresse document necessarily represent individual affiliated ganisations european commission document purpose provide input advisory processes determine european support research responsible innovation using takes account issues responsibility supported responsib umbrella term investigations legal ethical moral standpoints autonomous algorithms applications whose actions may impact lives citizens significant disruptive ways address purpose document reports summary results consultation experts around subject responsible chosen methodology nsultation delphi method pattern aims determine consensus highlight differe nces iteration panel selected consultees consultation resulted key recommendations grouped several main themes ethics ethical implications autono mous machines applications transparency considerations regarding transparency justification explicability autonomous machines decisions actions regulation control regulatory aspects law automated systems behaviour may monitored necessary corrected stopped socioeconomic impact society economy impacted autonomous machines design considerations autonomous machines responsibility issues considerations regarding moral legal responsibility scenarios involving autonomous machines body document describes consulta tion methodology results detail recommendations arising panel disc ussed compared recent european studies similar subjects overall studies broadly concur main themes differences specific points recommendations esented section summary key recommendations serves executive summary page key recommendations document purpose provide input advisory processes determine european support research responsible innova tion using takes account issues responsibility supported responsible umbrella term investi gations legal ethical moral standpoints autonomous algorithms applications whose actions may safetycritical impact lives citizens significant disruptive ways recommendations listed results consultation experts around subject responsible chosen meth odology consultation delphi method pattern aims determine nsensus highlight differences iteration panel selected consultees consultation highlighted number key issues summarised following figure grouped six main themes figure responsible key areas issues page determined issues order help key stakeholders research development innovation researchers applic ation designers regulato funding bodies etc discussed next categorised themes ethics disruptive potential significant possibly unknown ethical implications autonomous machines well applications research needs guided established ethical norms research needed new ethical implications especially considering different application contexts ethical implications need unde rstood considered researchers application designers ethical principles important may pend strongly application context system designers need understand expected contexts use design ethical considerations rise accordingly ethical principles need necessarily explicitly encoded systems necessary designers observe ethical norms consider ethical impact system design time ethical practical considerations need considered system design time since affect design interdependent may conflict assessment ethical impacts machine needs undertaken moral agent responsible design time responsi ble moral agent likely designer usage time responsible moral agent may user impacts may depend application context transparency considerations regarding transparency justificatio explicability autonomous machines decisions actions strongly advocated panel concert others community decisions actions need transparen explained justified explanation needs comprehensible lay people systems become exposed general public provenance information regarding decision input data well training data needs recorded order ovide audit trail decision trustworthiness system critical widespread acce ptance transparent justification system decisions well factors prov enance information training data track record reliability comprehe nsibility behaviour contribute trustworthiness regulation control investigation regulatory aspect law guidelines gove rnance needed specifically applied new challenges presented auto mated systems addition control aspects need page specifically concerning tomated systems behaviour may monitored necessary corrected stopped certification safe accompanying defini tions safety criteria recommended application context determines societal impact syst safety criteria resulting certification likely depend application put new applications existing technology may need new assessment certification determination remedial actions situations systems malfunction misbehave recommended failure modes appropriate medial actions may already understood depending application domain deployed emergency procedures needed car crashes may similar needed car crashes vestigation needed existing remedial actions appropriate situation whet need augmented important type control human monitoring constraint systems behaviour including kill switches completely stop system thes governing mechanisms must fail safe choice control system decision direct consequences may undone recognised may also side unintended effects system decision may difficult impossi ble undo careful assessment full set implications system decisions actions undertaken design time understanding law regulate needed technology law lags technical developments application context may major factor regulation application context dete rmines effects society environment even though recent discussion legal personhood robots current time foreseeable future humans need ultimately liable systems actions question human liable need investigated however application context may differe factors influencing liability socioeconomic impact already continue disru ptive impact social economic factors impacts need studied provide understanding affected affected guard negative damaging impacts understanding socioeconomic impacts autonomous machines society needed especially automation differs types disruptive mechanisation impact human workers needs inve stigated threats negative effects redundancy deskilling addressed well exp loiting benefits working dangerous environments perform ing monotonous tasks reducing errors public attitudes towards need unde rstood especially concerning factors contribute detract public trust page public attitudes also connected assessmen threats pose especially undermine human values investigation required either compatible conflicts human values specific ones research needed users entify guard discriminatory effects example users citizens educated recognise discrimination indirect social effects need investigated system decisions may affect users others may know affected systems integrate different types networks human machine important issue investigation needed system operational environment determine entities teracts affects unlikely approach social eval uation applications likely case applicat ion context need evaluated individually social impact research needed evaluation rformed case design considerations patterns autonomo machines need investigated especially concerning adaptations exist ing design considerations patterns needed specific result interdisciplinary teams necessary application design bring together technical developers experts account societal ethical onomic impacts system design ethical principles socioeconom impact need consider outset application design whilst design benefits humankind heart also cases entities animals environment may also affected ethical principles apply kinds nature forgotten design process identification recognition bias aining data important biases made clear user population responsibility issues considerations regarding moral gal responsibility scenarios involving autonomous machines regarded critical especially automation situations potential cause harm humans need ultimately responsible actions today systems closer intelligent tools sentient artificial beings concert related work says current systems humans must control responsible established near term least humans responsible actions question responsible system actions needs investigation standard mechanisms fitness purpose designer typically responsible permissible use user responsible applicatio system may need page assessment different actors responsible different application context indeed multiple actors responsi ble different aspects application context current predictions artificial general become realistic prospects human responsibility alon may adequate concept responsibility need research multidisci plinary teams understand responsibility lies participates networks need include moral responsibility translate legal responsibility pennachin artificial general intelligence vol new york springer boström superintelligence paths dangers strategies oxford university press page report purpose provide input advisory processes determine european support research responsible innovati using takes account issues responsibility enabled responsible umbrella term investigations legal ethical moral standpoints autonomous algorithms applications whose actions may safetycritical impact lives citizens significant disruptive ways report summary methodology recommendation resulting consultation multidisciplinary international panel experts subject responsible firstly brief background presented followed description consultation methodolog results discussed grouped major themes compared recent european studies similar subject areas finally brief conclu sions presented recommendat ions consultation presented summary key recommendations ction rest report serves provide detail behind recommendations background automated systems come age recent years prom ise ever powerful decision making providing huge potential benefits humankind performance mundane yet sometimes safety critical tasks wher often perform better research development areas abate functi onal progress unstoppable clear need ethical considerations applied regulatory governance systems well safety concerns responsibility autonomous well privacy threats potential prejudice discriminatory behaviours web influential figures elon stephen voiced concerns potential threats undisciplined describing existential threat human civilisation calling regulation recent studie next generation internet donath judith cultural significance artificial intelligence december ruocco katie artificial intelligence vantages disadvantages february bostrom yudowsky ethics artificial intelligence ramsey frankish eds cambridge handbook artificial intelligence scherer matthew regulating artificial intelligence systems risks challenges competencies strategies may harvard journal law technology vol spring available ssrn vincent müller legal ethical obligations comment epsrc principles robotics connection science doi bonnefon shariff rahwan social dilemma autonomous vehicles science crawford artificia intelligence whit guy problem new york times musk regulate combat xistential threat late guardian july stephen hawking warns artificial intelligence could end mankind bbc news december page concur regulation ethical governance automation necessary especially safety critical systems critical infrastructures last decade machine ethics focus increased research interest anderson anderson identify issues around increasing enablement technical significantly societal context human expectations technology acceptan transplanting human making ethical choice autonomous anderson anderson also describe different mechanisms reasoning machine mechanisms concern encoding general principles principles following pattern kant categorical ethical principles others concern selection precedent cases ethical decisions similar situations class considers conseq uences action question act utilitarianism see open research question ncerns mechanism combination mechanisms appropriate key question legal moral responsibility autonomous systems takes responsibility autonomous system actions considers question legal perspective asking whether tity regarded legal person nonbiological entity corporation regar ded legal person system question becomes one intentionality system whether gal systems incorporating penalty enforcement provid sufficient incentive syst ems behave within law poses question whether designer system held responsible system create system learns experiences therefore able make judgements beyond imagination designer discusses challenges ascribing legal personhood decision making machines arguing society perc eptions automata need change new class legal entity appear transparency autonomous systems also ncern especially given opaque nature systems neural networks discipline explainable new van lent described architecture explainable within military david overton next generation internet initia tive consultation final report march takahashi makoto policy workshop report next neration internet centre science policy cambridge computer laboratory centre science policy csap collabora tion cambridge computer laboratory march retrieved anderson anderson machine ethics cambridge university press anderson michael susan leigh anderson machine ethics creating ethical intelligent agent magazine mclaren bruce extensionally defining principles cases ethics model artificial intelligence brown donald mill philosophical quarterl calverley imagining machine legal pers society matthias responsibility gap ascribing responsibility ctions learning automata ethics information technology beck problem ascribing legal responsi bility case robo tics society van lent michael william fisher michael mancuso explainable artificial intelligence system tactical behavior proceedings nation conference artificial intelligence menlo park cambridge lond aaai press mit press page lomas demonstrated system allows robot explain actions answering types question recently response fears accountability automated systems field algorithmic accountability reporting arisen mechanism elucidating articulating power ructures biases influences computational artefacts exercise society usa importance ansparency clearly identified darpa recently proposing work programme research towards explainable xai issues others encapsul ated asilomar principles unifying set principles widely supported guid development benefi cial principles translated recommendations european research subject responsible innovation responsible applications provide answers questions consultation conducted results compared othe relevant recent lite rature report methodology consultation methodology consultation used delphi pattern aims determine consensus highlight differences panel selected nsultees properties make delphi method ideally suited purposes targeted consulta tions experts intention identifying consensuses recommendations delphi method arrives consensus iterative rounds consultations expert panel initial statements made participants collated participants statements presented back panel discussion agreemen disagreement process happens several rounds subsequent rounds refining previous round stat ements based feedback panel consensus reached controversies highlighted consultation used three rounds round selected panel experts invited participate based reputation field relevant core subject nsultation round web survey containing background briefing note set scene companied two broad questions participants made sponses text round using standard qualitative technique thematic collected corpus responses round independently coded generate assertions presented back participants broad emes also identified corpus used lomas meghann robert chevalier ernest vincent cross robert christopher garrett john hoare michael kopack explaining robot actions proc eedings seventh annual international conference teraction acm diakopoulos algorithmic accountability journali stic investigation computational power structures digital journalism darpa broad agency announcement explainabl artificial intelligence xai august gunning david explainable artificial intelligence xai defense advanced research projects agency darpa web asilomar principles propos beneficial nference asilomar california january linstone turoff delphi method techniques applications vol reading braun clarke doi page assertions participants aluated assertion marking agreement disagreement using likert made comments text round results round collated assertions significant majority sharing answer polarity agree disagr regarded reaching consensus remainder opinion divided new assertions based thematic analysis comments presen ted back panellists could agree disagree comment round results reached nsensus collated round determine final consensus disagreements recognised experts multiple relevant disciplines output recommendations consultation dire reflection thei views therefore expert selection invitation decided good target number experts panel reasoning range balance adequate cove rage subjects manageability acknowledged experts busy people result assumed response rate achieve desired expert numbers experts panel aimed invite experts order determine relevant bject fields expertise henc candidate experts panel knowledge requirements exercise performed form exploratory literature survey starting point searches incl uded subject areas legislation regulation ethics legal moral responsibility explainable transparent key works experts well related search terms found using standard tool methods google scholar microsoft academic standard google search following links wiki pedia pages gain background theme related themes well influential people contributing importan work within theme result investigations spreadsheet describing names experts affiliation contact details notes specialisms total experts roughly evenly dist ributed across subject areas invited consultation rticipants therefore drawn purposive sample based academic standing reputation within ven area expertise ethical approval consultation sought faculty physical science engineering university sou thampton application contained aspe cts disclosure purposes consultati data protection anonymity risk assessment consent briefing created describing background consultation via literature two key questions asked begin consultation research needed address issues beneficial responsible autonomous machines raise recommended research important strongly agree agree disagree strongly disagree additional relevant option university southampton ergo number hosted content briefing note forms basi background section document page briefing note sent targeted exp erts link online survey could make responses analysis total experts responded detail round panel comprised experts following subject areas algorithmic accountability explainable applications bias automated systems epistemology law specifically applie computation machine ethics philosophy robotics sociology round responses form answering two questions posed briefing note aim round analysis determine assertion statements textual responses could used input round two research ers coded original text independently standard thematic analysis methodology adop ted entirely inductive application technique respondent textual answers scrutinised opinions statements recommendations one found relevant quotation text recorded along summary form draft assertion many cases found different respondents expressed opinion albeit worded different concordant opinions clustered single summary assertion recording associated quotations many participants expressed opinion assertions determined broad themes identified serve groups assertions highlight key issues researchers met discuss agree final themes assertions overlap interim themes good themes clearl union set assertions independent analyses discussed found majority assertions appeared analyses albeit different forms assertion discussed modified necessary final set assertions agreed researche agreement formal analysis therefore felt necessary resultin set assertions presented back panellists invited agree disagree round ten experts responded round respon ses comprised agreements disagreements assertion statements expressed stru ctured format likert scale strongly disagree disagree agree strongly agree along relevant option response format analysis round quantitative counting agreements disagreements assertion determine whether cons ensus reached simple metric used compared general agreement general disagreement total agreement votes strongly agree agree compared disagreement votes strongly disagree disagree either group twice number votes consen sus deemed een achieved qualitative research methods reliability analysis checked initially chec king agreement two researchers coders attempt identify categori themes codes example howitt introduction qualitative search methods psychology page results assertions achieved consensus reviewing comments participants remainder achieve consensus resulting derived assertions round eight experts responded round selected ether agreed assertions presented similar round experts uld also make optional mments set assertions achieved consensus round assertions round reached consensus round combined making total consensus items course consultation make results reported represent recommendations based perspective recognised experts results summary discussion section contains research priorities reached consensus consultation divided six themes priorities section discussed compared three key recent european sources highlight similarities fferences differences may require investigation sources comprise european commission current approach regarding research innovation current european priorities ethics socioec onomic impacts european approach artificial intelligence european commission document describes current approach plans development assurance safe responsible hereafter referred approach european group ethics science new technologies ege independent advisory body president european commission published statement artificial intelligence robotics aut onomous systems ege statement calls launch process would pave way towa rds common internationa lly recognised ethical legal framework design production use governance artificial intelligence robotics autonomous systems statem ent also proposes set fundamental ethical principles based values laid treaties charter fundamental rights guide development hereafter referred ege statement european economic social commi ttee issued opinion stat ement consequences entitled artificial intelligen consequences artificial intelligence digital single market producti consumption employment society hereafter referred eesc opinion following themes derived thematic analysis expert comm ents round serve broad subject categories ethics ethical implications autono mous machines applications transparency considerations regarding transparency justification explicability autonomous machines decisions actions european commission european approach arti ficial intelligence april available retrieved european group ethics science new technologi ege ege statement artificial intelligence robotics autonomous system march available retrieved european economic social committee eesc artificial intelligence consequences artificial intelligence digital sing market production consumption employment society may available retrieved page regulation control regulatory aspects law automated systems behaviour may monitored necessary corrected stopped socioeconomic impact society impacted autonomous machines design considerations autonomous machines responsibility issues considerations regarding moral legal responsibility scenarios involving autonomous machines overall broad agreement different studies consultation themes shared three studies four initiatives covers different subset themes illustrate overlaps gaps following table maps three external sources areas concern consultation themes table comparison key areas different european studies eesc opinion areas poses societal challenges approach ege statement consultation themes safety alliance future europe addresses safety safety security prevention harm mitigation risks explicit theme consultation safety key aspect regulation control theme regulation liability human moral responsibility dedicated theme responsibility governance regulation investigation application existing directives regulations governance regulation design development inspection monitoring testing certification dedicated themes regulation control design transparency accountability algorithmic transparency explainability transparency autonomous systems dedicated theme transparency ethics alliance future europe addresses ethical issues ege statement concerned ethics robotics autonomous systems dedicated theme ethics education skills support upskilling use new technologies deskilling loss knowledge covered socioeconomic impact equality inclusiveness alliance future europe addresses inclusiveness discrimination covered socioeconomic impact work threats employment covered socioeconomic impact privacy gdpr alliance future europe addresses privacy privacy covered socioeconomic impact warfare weapons principle meaningful human control mhc advocated discussion responsibility page touched discussion responsibility support digital innovation hubs dih foster collaborative design design theme designtime considerations following sections present consultation result detail grouped six themes assertion statements theme presented tabular votes agreement disagreement well total votes cast order assertion statements presented corresponds strength consensus amongst panel strongest consensus first following table assertion discussed discussion centred three major aspects strength consensus issues raised comme nts made panellists comparisons three sources ethics ethics assertion statement disagree votes agree votes total votes research technical choices need take account ethical implications norms ethical choices dilemmas faced applications need investigated along factors relevant factors dilemma resolution deep ethical practical considerations design autonomous machines needs common understanding autonomy autonomous capabilities machines qualify ethical concern since potential cause harm assertion panel unanimously agreed research guided ethical norms application developers consider ethical implicat ions design time spirit principle agrees studies eesc opinion calls code ethics development application use ege statement states autonomous systems developed used ways serve global social environmental good approach plans assertion numeric identifier unambiguously identified format indicates round assertion reached consensus assert ion integer identifier reached consensus round round assertions derived reach consensus decimal identifiers example assertion reach consensus round replaced assertions round total votes assertion differs cases assertions reached consensus different rounds different numbers participants rou participants round participants panellists vote assertions occa sionally total number votes amounts less round less round eesc opinion page ege statement page page code practice ethics draft ethics guidelines developed basis charter fundamental rights key point made panel contrast ethical practices observation ethical norms design time explicit encoding ethical principles within resulting system panel commented ethical inciples need necessarily explicitly encoded systems designers need understanding ethical issues potential impacts work design accordingly assertion strong consensus supporting need invest igation ethical implications applications found panel agreeing disagreeing participant disagreed assertion commented sagreement founded assertion emphasis ethical dilemmas disagreeing summary statement rather quotations like idea trade offs ethica reasoning important consider enabling constraining factors developments resp ect foregrounding human rights concerns sentiment echoed participa agreed assertion strongly agree statement think important become erly focused solving lemmas think important think values bein taught realized technologies values guide system behaviors favour determination values factors guide ethical behaviour ethical dilemmas factors values support considerations needed designers system applications referred assertion assertion need consider relationship ethical practical cons iderations design time also strongly supported panel agreement disagreeing voting comment participant agreement concerned specifics relationship pointed ethical practical considerations may complementary contrary depending particular case inde pendently influence design choices think design needs consider ethical practical factors cons traints moreover necessarily stand opposition sometimes ethical thing also practical effective however always clean deep relationship one another rather influence technology assertion panel debated meaning autonomy three roun consultation give context concept autonomous machines ethical implications result broad agreement agree disagree caveats made whether shared understanding important even possible comment participant agreed assertion think shared understanding various kinds capab ilities would help advance debates think need worry shared understan ding autonomy full stop think shared understanding would possible comments participants disagreed doubt possible considered part autonomy construct likely diverge disciplines likely also evolve time machine need autonomy ethical impact follows nece ssary qualification ethical concern assertion related prompted discussion autonomy assertion types machine eligible ethical conc ern since potential cause harm whilst participants agreed assertion com pared disagreed comments indicated investigation likely required regarding needs concerned circumstances participant disagreed assertion statement pointed entities capable causing harm moral agents much seems depend mean approach page page ethical concern meteorite potential use harm normally think subject ethical concern normally would think would reserved moral agents relevant example moral agent concerned abou ethical impacts machine designer clearly interested parties ill ethical concerns touches aspect responsibility system actions discussed later sessing circumstances ethical concern amount potential harm clearl important participant disagreed assertion said course safety implications mach ine operations relevant operations take place near mans harm caused runaway vacuum cleaner harm caused robot need typically harms result poorly understood algorithms rather human error carelessness short interactions human beings add new dimensions harm responsibility harm another participant agreed assertion statement pointed potential harm may factor determines need ethical concern potential harm shou considered potential impact ethically relevant feat ure instance even machine impact ever good distribution good concerns justice might question transparency transparency assertion statement disagree votes agree votes total votes decisions need transparent explained justified decisions need understood lay people technical experts transparency needed data provenance algorithmic decisions transparency requires autonomous machines meet least two criteria track record reliability comprehensibility previous behaviour assertion strong support agree disagr overarching statement decisions need transparent explained stified unsurprising transparency overwhelmingly supported mmunity approach identified priority nearterm future plans algorithmic transparency topic addr essed ethics guidelines developed end year ege statement views trans parency perspective enabling humans overall control autonomous technologies must hence honour human ability choose whether delegate cisions actions also involves transparency predictability autonomous system without users would able intervene terminate would consider morally required also taking perspective human control eesc opinion advocates transparent comprehensible monitorable systems operation accountable including retrospect ively addition established approach page ege statement page page procedures transferre systems human intervention desirable mandatory bodies strongly support ansparency one comments participant agreed assertion statement referenced ieee standard transparency autonomous systems clear transparency important areas assertion decisions understandable lay people well experts received majority support agree disagree key ason given amongst supporters assertion statement people understan system output people potentially trust good way genera trust system understandable intrinsically better instead way increase trust reason people understand system tput potential candidates human loop control monitoring ntrol related comprehensibility alluded comment participant disagreeing assertion statement believe need understood greatest extent feas ible explained made available assertion transparency contributing decisi ons provenance data also received broad support agree disagree contribution decisions already discussed taken read regarding transpar ency data provenance reason broad support provided participants given context assumed provenance important two main cases training data supervised lear ning systems input data approach also emphasises importance high quality data plans support developers deployers commission also support uptake across europe toolbox potential users focusing small enterprise companies public administrations set measures include plat form giving advice easy access latest algorithms expertise network digital innovation hubs facilitating testing experimentation industrial data plat forms offering high quality datasets assertion assertion statement transparency requires autonomous machines meet least two criteria track record reliability comprehensibility previous behaviour also majority support agreeing disagreeing factors contribu trustworthiness system represent experience system fitness purpose enab ling trust judgement without key comment participant disagreed many ways transparent moreover two features important trust necessarily transparency even trust required indeed transparency contributes trustworthiness trust discussed later perspective public trust systems transparency clearly factor public trust eesc opinion page ieee standards association oject transparency autonomous systems available retrieved approach page page control regulation control assertion statement disagree votes agree votes total votes certification reliably safe needed including definitions criteria safety achievable remedies agreed place times applications malfunction mechanisms monitor constrain systems behaviour necessary including stop human override controls research needed identify factors determine liable different cases application interdisciplinary research needed determine law ensure responsible behaviour research whether systems decisions actions rolled back needed assertion panel unanimously agreed certification reliable safe needed including definitions criteria safety safety obviously paramount studies concur ege statement key estion concerning safety security prevention harm mitigation risks approach tasked eur opean alliance safety key issue eesc opinion safety key area use phys ical world undoubtedly gives rise safety issues external sources far recommend certification advocate testing compliance safety requirem ents ege statement specifically addresses testing safety dimensions safety must taken account developers strictly tested release order ensure aut onomous systems infringe human right bodily mental integrity safe secure environment eesc opinion advocates compliance safety requirements eesc believes system may used meet specific internal external safety requirements thes requirements determined safety specialists businesses civil society organisations collectively comments made panellists consultation indicate ere caveats principle certification firstly applications applications obviously needed cars others relevant playing game therefore asse ssment criterion needed determine applicat ions domains qualify subject safety testing one panellist comments difficu lties determining general definitions safety criteria advocates approach regulation think going incredibly hard produce finitions advoc ated dynamic gradual regulatory system slowly increase contexts use ther giving blanket approvals eesc opinion page ege statement page eesc opinion page page already applied examp regulatory work autonomous undertaken present time another panellist comments establishing discipline implied benefits education training quality control regulation come discipline yes need new discipline safe brings good old fashioned safety software gineering disciplines assertion panel also unanimously agreed achi evable remedies agreed place times applications malfunction discussion whether remedies meant penalties legislative tools aimi discourage certain behaviour compensate injured party penalties seen narrow remedial actions applied undo diminish harm applications outc omes ege statement broadly concurs making distinction legislative penalty harm mitigation regard governments international organisations ought increase efforts clarifying liabilities lie damages caused undesired behaviour autonomous systems moreover effective harm mitigation systems place therefore assertion statement concerned kind remedi action key point failure modes harmful outcomes application need understood actions defined recover clearly failure modes thei impacts associated remedial actions one panellist points remedial actions may already exist certain domains expect remedies ready exist many cases another points need remedial actions critical infrastructure need remedies place malfunction critical technology infrastructure also expectation remedi processes place existing critical infrastructures many applicatio domains adaptation augmentation current practice likely needed rather complete new practices key ques tion therefore determine domain application identify relevant regulations practices within example cars ere many failure modes already known associated cars well recovery actions emergency procedures response vehicle accident part still applicable cars major question concerns additional harmful outcomes caused aspect vehicles may mitigated point concerns ques tion whether malfun ction identified deliberate obfuscation informatio withholding providers platforms bigger problem lack transparen especially rge social media companies makes difficult seek redress naturally related transpar ency issue discussed also transparency contributor trust system conclusion applies providers encouraged whatever means appropriate including legisl ation penalties ensure systems transparent possible assertion assertion mechanisms monitor constrai systems behaviour necessary including stop human override controls strongly supported panel panellists agreeing disagreeing key aspects system constrained stopped overall control two external sources strongly advocate humans overall control systems third source makes comment matter ege statement asserts autonomous technologies must hence nour human ability choose whether see example retrieved see example retrieved ege statement page page delegate decisions actions eesc opinion calls approach including precondition development responsible safe useful machines remain machines people retain control machines times panellist disagreed assertion statement pointed whilst overall human control preferable need also consider human erride may counterproductive situations think usually want human loop occasional contexts human verrides actually make things worse approach also implications responsi bility system covered later assertion panel strongly supported assertion research needed identify factors determine liable different cases application panellists assertion refers legal liability closel related moral responsibility separate issue discussed later comme nts single panellist disagreed assertion following discussion concerns comments made panellists agreed assertion key point liability assi gnment legal practice factors might determined current legal practice fine main thing need know pay attention debates also assignment liability already investigated similar situations assigning liability among several actors user repairer manufacturer etc complex many technologies different previous comment also highlights given situation liability may shared amongst actors rather single actor liable clearly assignment liability depends application enviro nment stakeholders role potential consequences approach may necessary evaluate situation applications may relevant guess research needed address specifical applications cars autonomous behaviour minimize damage accidents finally panellist makes point ere may situations liable actor liable anything anyone liable confirmed discount possibility external studies eesc opinion emphatically states humans liable parties applications eesc opposed form legal status robots systems entails unacceptable risk moral hazard liability law based preventive ing function may sappear soon maker longer bears liability risk since transferred robot system also risk inappropriate use abuse kind gal status comparison limited liability companies misplaced case natural person always ultimately responsible assertion panel broadly supported assertion interdisciplinary research needed determine law ensure responsible behaviour panellists agreeing disagreeing however signific ant caveats comments amon gst agreed one panellist commented mildly agree partly think law relatively weak inefficient means ensure responsible behavior indicates mechanisms need investigated well law encourage responsibl behaviour economic drivers example amongst comments panellists disagreed assertion interdisciplinary research legal aspects applications clearly needed however goal research hardly ensure responsible behaviour tool may hence potentially used irresponsible responsible purposes refers specific school thought regarded tool like ege statement page eesc opinion page eesc opinion page page may used good cause harm thesis use tool put needs scrutiny regarding responsible behaviour furt comment indicated likely body relevant work already exists regardi responsible behaviour consulted think social science already good ideas external studies comment specifically law ensure responsible haviour ege stat ement comments regarding allocation responsibility whole range legal challenges arising field addressed timely investment devel opment robust solutions provide fair clear allocation responsibilities efficient mechanisms binding law assertion panel also broadly supported assertio research whether systems decisions actions rolled back needed panellists assertion clearly supports assertion concerning remedial actions malfunction detected ability undo acti ons system likely nerally useful even malfunction occurs one panellists disagreeing ssertion makes point rollback current technology likely similar existing automated decisions short medium term rollback hardly much different rollback automated decision long term approaching per intelligence may releva research would premature particular hardly capable understanding relevant aspects research challenge key factor needs done roll back action strongly depends application domain action consequences direct indirect actions may difficult undo espe cially indirect unobserved consequences example commercial system displays signs discrimi nation reputation damage company likely occur repairing damage ill require simply reversi discriminatory decisions ege statement page page impact socioeconomic impact assertion statement disagree votes agree votes total votes research impact human workers needed including employment deskilling humans replaced machines well psychological consequences research needed extend understand economic impacts machines society specific focus different mechanisation public attitudes towards need understood especially concerning public trust research needed users identify guard discriminatory effects application needs assessed benefits harm must consider benefits also possibly may harmed application research needs concentrate applications known outperform humans research needed integrates networks humans machines well machines interact machines research threats future may pose humankind required including human goals differ undermine human values research needed tested societal values autonomy freedom trust privacy assertion panel unanimously agreed research impact huma workers needed including employment deskilling humans replaced machines well psychological consequences unsurprising majority external sources also highlighted aspects great deal public fear automation robots taking away peoples livelihoods example approach concentrates maintaining relevant skills europeans every opportunity acquire skills owledge need master new technology important keep working population able work current technology eesc opinion concurs approach regarding upskilling maintenance acquisition digital skills necessary page order give people chance adapt rapid developments field european commission firmly committed developing digital skills digital skills jobs coalition eesc opinion also provides caveat ills development needs supported across board areas affected systems however everyone capable interested coding becoming programmer policy financ ial resources therefore need directed education skills development areas threatened systems tasks human interaction vital human machine coopera tasks would like human beings continue another aspect deskilling technology performs work previous generations humans resulting loss knowledge skills perform work increasing reliance technology may able explain actions whilst risks limited recommended recognised plans put place assessment eesc opinion addresses loss employment national governments social partners jointly identify whic job sectors affected extent timescale look solutions order properly address impact employment nature work social syst ems equality investment also made job market sectors little impact panellists comments concentrate highlighting effects working pulation need negative advocate balanced approach considering negative positive effects important research challenge however research ncern negative implications deskilling etc also opportunities brought human work opportunities opening consequence new current research area typi cally biased towards problems allenges believe balanced approach needed also need examine potential positive impacts oppor tunities need look full picture assertion panel also unanimously agreed resear needed extend understand economic impacts automation specifically focusing different forms mechanisation panellists voted regarding assertion panellists voted agreed key point many cases disruptive technological breakthroughs throughout historical records society adapted advent key estion understand differe historical cases comments made panel highlight need investigat ion new socioeconomic effects result adoption currently substantial demand interest research think replacing different kind labor previous revolutions ways potentially different perhaps existing management econ omic theory sufficient skeptical ege statement points need economic models wealth distri bution autonomous technologies participate fair equal access technologies need concerted global effort towards equal access aut onomous technologies fair stribution benefits equal opportunities across within societies includes formulating models fair distribution benefit sharing apt respond economic tran sformations caused automation digitalisation specifically addressing differences mechanisation eesc opinion eesc opinion page eesc opinion page eesc opinion page three examples spring mind gutenberg printing press threshing machine internet revolutionary gutenberg press resulted mass information dissemination threshing machine mechanised grain harvests providing huge efficiency gains cost employment internet accelerated mass information dissemin ation orders magnitude ege statement page page external source distinguishes types skills affected different types technology brynjolfsson mcafee mit refer current technological developments including second machine age however two important differences old machines predominantly replaced muscular pow new machines placing brainpower cognitive skills affects workers also medium highly skilled whitecollar workers general purpos technology affects virtually sectors simultaneously research needed test asse rtion affects virtually sectors simultaneously managed assertion panel strongly supported assertion public attitudes towa rds need understood especially concerning public trust votes expected given coverage media scare stories regarding taking away employment killer robots waging war human race oed defines trust firm belief reliability truth ability someone something clearly evidence previous reliable behaviour contributory factor towards building trustworthiness discussed assertion failures accidents involving cars detract attributes referred assertion transparency comp rehensibility previous behaviour also contribute trustworthiness people see understand behaviour less likely suspicious attitudes trust general public likely directed application per pointed panellist supporting assertion agree attitudes need investigated general broad key applications trust cars also application likely societal impact rather underlying algorithms application designed benefit may threats another panellist also supported assertion poin ted need capture full spectrum diversity public opinion kind survey work could help ful done appropriate care measure relevant factors covariates susp ect public attitudes vary widely one would need capture diversity support assertion observed already information public attitudes robotics yes although already pretty good understanding eubarometer surveys recent relevant eurobarometer survey attitudes towards impact digiti sation automation daily life perceptions attitudes towards robotics polled overall attitude general public towards mildly positive positive positive compared fairly negative negative overwhelming majority agree robots require careful management tend agree totally agree assertion panel also strongly supported research needed users identify guard discriminatory effe cts votes unsurprising considerable concern regarding bias discrimination per already work undertaken prevent systems biased first need eesc opinion page retrieved eurobarometer ebs attitudes towards impact gitisation automation daily life available retrieved see example world economic forum global future council human rights prevent discriminatory outcomes machine learning available retrieved page prevention bias widely supported ege statement comments discriminatory biases data sets used train systems prev ented detected reported neutralised earliest stage possible assertion focuses need understand users citizens empowered reco gnise discrimination comments panellists supported assertion concern need define discriminatory effects though clarity needed discriminatory effects need protect citize use affected course people able actually think important challenge helping people differentially pacted directly using opportunities learn system deeply affecting lives last point particularly important affects potentially many people idea discriminated assertion strong support assertion application needs assessed benefits harm must consider benefi also possibly may harmed application supporters dissenter sertion roots discussion round stemming asilomar beneficial principles panellist asked benefits pointed benefits one party may negatively affect discriminate harm another relating also assertion clearly general societal benefit eesc opinion supports positive societal benefit development applications benefit society promote inclusiveness improve people lives actively supported promoted publicly privately programmes european commission fund research societal impact innovations also partisan benefits core assertion specific example need protect partisan benefit resulting development given also eesc opinion vast majority development associated elements development platforms data know ledge expertise hands big five technology companies amazon facebook apple google microsoft although companies supportive open development make development platforms available guarantee full accessibility systems international policy makers civil society organisations import ant role play ensuring systems accessible also developed open environment panellist supporting assertion casts assessment terms ethical sks cites responsible research innovation rri potential home assessment practice guidelines yes ais subject risk assessment well developed thin frameworks responsible research innovation another supporting panellist points assessment benefits exclusive goes also forms tec hnology practically technological progress comes cost need make sure benefits outweights sic costs clearly true benefits specific need investigated finally supporting panellist makes plea use common sense application assessments agreed obviously sensible absurd ways approach exam ple changing color robotic arm trigger ege statement page eesc opinion page eesc opinion page see example retrieved page next assertion research needs concentrate applications known outperform humans unique consultation strong consensus amongst panellists consensus disagreed assertion agreed disagreed numerous reasons given disagreement comments one commented artificially restrict domain research lots reasons research see reason limit domain applications way others provided reasons useful research equals underperforms humans concentrate cases might replace humans whether sic sume humans outperformed still helpful even underperforms compared man behavior similar circumstances instance simple eldercare robots help people remain home comment warned reduction expectations may caused artifi cial limitation research targets inevitable developers seek low hanging fruit although thin necessarily good thing since harder problems get assertion panel broadly agreed research needed integrat networks humans machines well machines interact machines votes vote panellist voting sole comment supporting assertion dicated research already underway already large amount research sole comment felt recommendation broad sounds general eesc opinion discusses complementary systems eesc recommends stakeholders work together complementary systems workplace machine teams complements improves human performan stakeholders also invest formal informal learning education training order enable people work also develop skills acquire assertion panel broadly supported assertion search threats future may pose humankind required including human goals differ undermine human values panellists agreeing asse rtion participants disagreeing assertion alludes assessment future threats associated artificial general intelligence superintelligence technologi may able determine goals may necessarily compatible human goals indicated two comments panellists supported assertion would hasten add given threat research performed responsibl manner unduly alarm public undermine beneficial progress agree interesting questions also think focus relatively future ink focus major funding efforts time one comments panellists disagreed assertion argues soon investigate future believe know enough abou future like meaningful research topic disagreeing comment pointed risks humankind general risks specific affected parties need assessed also points affected parties may human sentient creature general humankind affected huma sentient creatures last point backs another assertion need consider impact entities animals environment assertion panel broadly supported assertion research needed tested societal values nation autonomy freedom trust privacy votes one comment support ing panellist added caveat societal eesc opinion page page static relation conceptual progress made relation selfdetermination autonomy freedom etc static concepts either comment supporting panellist pointed similarity assertion others regarding societal impact much earlier point comment panellist disagreeing assertion alluded need understand asure describe societal values convinced needs tested seems like request operationalizations terms sure else might required external sources definite acknowledgement impact society eds better understood far advocating tested agains societal values ege statement says principles human dignity autonomy centrally involve human right means democracy key importance democratic political systems value pluralism diversity accommodation variety conceptions ood life citizens must jeopardised subverted equalised new technologies inhibi influence political decision making infringe freedom expression right receiv impart information interference digital technologies rather used harness llective intelligen support improve civic processes demo cratic societies depend eesc opinion asks ensure fundamental norms values human righ remain respected safeguarded advocates programmes european commission fund research societal impact innovations ege statement page eesc opinion page eesc opinion page page design assertion statement disagree votes agree votes total votes ethical principles need embedded development inclusive interdisciplinary teams needed develop sometimes sensitive nonhuman entities agriculture fishing etc engineers need aware potential biases prejudices selection training data important design consideration advances human interests values attempting formal definition concepts may mask important nuances result may hold research important get adequate definitions debate shared understanding publicly assertion panel unanimously agreed ethical principles need embedded development unsurprising given importan given ethics one panellist made distinction embedding ethical principles respecting ethical principles design time course mean ethical princi ples need explic itly represented rather idea ethical requires changes practice notably attention ethical issues therefore assertion may interp reted ethical principles need considered design time echoes assertion similar point made panellists another panellist pointed may difficult determine ethical principles long clear idea relevant ethical ideas external studies strongly support development eesc opinion calls code ethics development application use throughout entire operational process systems remain compat ible principles human dignity integrity freedom privacy cultural gender diversi well fundamental human rights ege statement states applications robotics pose unacceptable risks harm human beings compromise human freedom autono illegitimately surreptitiously reducing options knowledge citizens geared instead development use towards augmenting access knowledge access oppor tunities individuals research design development robotics autonomous systems shou guided authentic concern research ethics social accountability developers global academic cooperation protect fundamental rights values aim designing technologies support detract eesc opinion page ege statement page page panel unanimously supported inclus ive interdisciplinary teams needed develop comments also indicated support option strongly agree would chosen best socially also technologically emerges one use broad design thinking approach employs methods many disciplines believe history shown developed also ciplinary teams however ture applications likely strengthened interdisciplinary approach important point possible develop purely techni cal perspective alone order fully realise benefits protect potential threats inte rdisciplinary teams needed comment emphasised diversity disciplines needed diverse sense interdisciplinary another pointed understanding target communities important critically important design teams fully reflect gender ethnic mix societies aiming develop ais interdisciplinary development widely supported wider community eesc opinion stated one primary objectives shape focus promote public debate coming period involving relevant stakeholders industry social partners consumers ngos educational care institutions experts academics various sciplines including safety ethics economics occupational science law behavioural science psychology philosophy approach taken steps provide support collaboration across member states centres excellence digital innovation hubs commission support fundamental research also help bring innovations market throug european innovation council pilot additionally commission support member states efforts join tly establish research excellence centres across europe goal encourage tworking collaboration centres including exchange researchers join research projects digital innovation hubs local ecosystems help companies vicinity especially small enterprises advantage digital opportunities offer expertise technologies testing skills business models finance market intelligence networking assertion panel also unanimously supported asse rtion sometimes sensitive entities agriculture shing etc often erlooked much emphasis ethical considerations related human rights needs respect domains quoted forgo tten comment emphasises point provides examples need considered cars needing recognize sic assume needing recognize animals road healthcare robots need ing recognize insect infestations lots examples see almost could succeed sensitive ege statement supports assertion technology must line human responsibility ensure basic preconditions lif planet continued prospering mankind preservation good environment future generati ons strategies prevent future technologies detrimentally affecting human life nature based policies ensure priority environmental protection sustainability assertion panel strongly supported assertion engineers need aware potential biases prejudices selection training data votes unsurprising strongly supported wider community sentiment assertion concurs assertion ege statement says discriminatory biases data sets used train run systems eesc opinion page approach page ege statement page page prevented detected reported neutralised earliest stage possible eesc opinion says general tendency believe data definition objective however misconception data easy manipulate biased may reflect cultural gender prejudices preferences may contain errors comment panel panellist voting assertion comment veals likely wording assertion objected rather sent iment preventing bias tering via training everyone know possibility sele cted members engineering team need able fully analyze problems assertion panel broadly supported assertion important design consideration advances human interests values votes external studies concur benefit society advancing values eesc opinion says development applications benefit society promote inclusi veness improve people lives actively supported promoted publicly privately programmes european commission fund research societal impa innovations need understand applicatio affect society clearly man values important panellist supporting assertion raised question regarding humans human humanity humans another panellist voted assertion asked questions regarding values pointing values universally beneficial problem statement assumes merit consistency human interests values human interests worthy consideration human values laudable clearly interests values stand consistent set principles value judgement plicit statement admirable interests good values need apply sic determine ese value judgements need made given comments need understand effects diffe rent sectors society benefit may suffer addition assertion also considered light assertion brings domains entities need considered assertion panel broadly agreed attempting rmal definition concepts may mask important nuances result may hold research effect delaying development novel applications votes assertion also states important get adequate definitions debate shared understanding publicly definitions lpful community held formal definitions agreed one panellist ted assertion commented definitions equal need formalised others need aspects different machine learning approac hes clearly require formal defi nitions however conceptualizations adequate definitions publically sic debated sufficient panellist voted assertion pointed since poor understanding natural intelligence definitions artificial intelligence extremely difficult one major problems poor understanding natural intelligence makes less theory free science need general model intelligence physics ege statement page eesc opinion page eesc opinion page page responsibility assertion statement disagree votes agree votes total votes research needed determine moral responsibility translate legal liability specifically applied situations people systems bear responsibility developers responsible tools develop concept responsibility needs researched integrated multidisciplinary teams arrive hybrid understanding key issues concerning responsibility attributed participates networks assertion panel unanimously agreed research needed determine moral responsibility translate legal liability ecifically applied tuations comments panellists alluded potential difficulties yes although think difficult question one lawyers philosophers need research ood luck getting agreement likely application situation need judged merits currently happening domains application currently investigated tested questions answered within spec ific domain obvious examples spring mind cars automated weapons ege statement concurs work important regard governments international ganisations ought increase efforts clarifying liabilities lie damages caused undesired behaviour autonomous systems moreover effective harm mitigati systems place assertion panel broadly agreed people systems bear responsibility developers responsible tools develo votes assertion contains two clauses discussed separately become clear analysis actually independent assertions people ultimate responsibility systems actions designer bears responsibility systems develop strong support panel wider community asse rtion people bear ultimate responsibility actions panellist support assertion commented strongly agree people systems bear responsibility strongly agree see epsrc principles robots robots responsible agents epsrc principles robots adv ocates robots tools human user determines use tool put beneficial harmful human ege statement page page final responsibility tool ege statement much say matter comes firmly agreement humans need responsible moral responsibility whatever sense allocated shifted autonomous technology principle meaningful human control mhc first sugges ted constraining development utilisation future weapon systems means humans computers algorithms ultimately remain control thus morally responsible eesc concurs mhc approach eesc calls approach including precon dition developmen responsible safe useful machines remain machines people retain control machines times discussions garding legal personhood systems systems could take responsibility actions rrent weight opinion eesc emphatic rejection eesc opposes introduction form legal personality robots would hollow preventive remedi effect liability law risk moral hazard arises development use creates opportunities abuse much discussion regarding legal personhood looking ahead superintelligence artificial general intelligence systems might vested rvation goals thus would incentive behave according whatever rights responsibilities society places upon current generation systems fit far better category smart tools need human charge determine tools applicatio take responsibility outcome regarding second assertion accept human needs take responsibility system need understand human humans circumstances assertion designer needs take responsib ility tools develop certainly true point many contexts use designer responsible disagreement assertion concerned ques tion responsible whether person responsible panellist agreed assertion commented strongly agree people systems bear responsibility however developers responsible quality tools develop held responsible tools used another panellist voted assertion commented agree quoted statements think summary oversimplifies complex issue developers certainly bear significant responsibility tools develop must inform practice however precisel systems may act interact ways individual designers teams could pred icted assigning responsibility difficult society need plan problems arise without one individual fault another panellist also disagreed commented depends contextual factors clearly responsibilities need assigned system designer include reliability fitness purpose basic safety etc however design responsible system used beyond original purpose liberate accidental misuse open question whether existing regulation puts onus responsibilit user adequate approach quotes plans extend existing directives incorporate liability rules defective products product liability directive dates strikes careful balance protecting consumers encouraging businesses market innovative products directive covers broad range products possible scenarios principle integrated product defect proven product boden bryson caldwell dautenhahn edwa rds kember newman parry pegman rodden sorrell wallis whitby winfield principles robotics regulating robots real world connection science ege statement page ege statement page eesc opinion page eesc opinion page page caused material damage person producer liable pay compensation actual cause events lead damage incident decisive attribution liability commission plans issue interpretative guidance clarifying concepts directive view new technologies building first assessment liability emergi digital technologies published today assignment responsibility likely promising strategy use precedents similar existing case law given discussion key recommendations aris ing two assertions made separately whilst currently well accepted people need control take responsibility systems actions may ture situations systems legal personhood foreseeable futu research clearly needed termine responsible systems actions different circum stances domains application situ ations may mean different person responsible assertion panel broadly agreed concept responsibility needs researched integrated multidisciplinary teams rrive hybrid understanding key issues concerning responsibility attributed participates networks panellists agreeing disagreeing sertion follows assertion adds recommendation question responsibility shou investigated multidisciplinary teams comment supporting panellist reinforced humans responsible principle discussed yes order attribute responsib ility among human designers conclusion document summarised results consulta tion multidisciplinary experts subject responsible artificial intelligence compared results studies resulting guidance similar fields study used delphi method iterative consultation mechanism aimed consensus building highlighting difference consensus hieved three rounds iteration undertaken total eight experts participated ree rounds result consultation assertion statements reached consensu amongst experts six broad themes ethics transparency regulation control socioeconomic impact design responsibility assertions summarised key recommendat ions summary recommendations assertion discussed compared ree external studies highlighting similarities differences overall consensus four studies good multiple studies concur major points recommendat ions however study perspective different emphasis detail points majo points consultation discussed next issues principles ffect join different themes consultation approach page page consultation advocates foreseeable ture humans need overall control consensus regarding current state technology smart tools humans must take responsibility actions humans must empowered monitor intervene prevent undo actions necessary may futu situations predictions superintelligence come true necessitate revisiting question whether human responsible current time cons ensus human responsible question humans responsible likely depends application context different application contexts may different human roles responsibilities consultation asserts application contexts key influencers many aspects responsible underlying algorithms cause application context determines societal impact whether good poses risk different application contexts may use underlying algorithms contexts may totally different risks stakeholders ethical considerations regulation requirements correla tes tool school thought says use put subject ethical concern gulation responsibility rather algorithm existing application contexts may regulations control patterns already basis stems participating context key example vehicles many regulations practices vehicles question need anged added cater vehicles significant potential disruptive socioecon omic impact lessons may learned previous examples disruptive technologies analogies may drawn historical examples disruptive mechanisation open question remains regarding sets apart previous examples technological disruption needs trustworthy generally soci ally acceptable key aspects influence trustworthiness transparency comprehensibility layperson track record reliability technologies opaque unpredictable may useful research surprising behaviour may even inspirational thes attributes contribute trustworthiness especially systems oper ate applications
