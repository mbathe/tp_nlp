opinion data ethics commission opinion data ethics commission content overview executive summary introduction ethical legal principles technical foundations governance complex data ecosystems data algorithmic systems european path appendix executive summary general ethical legal principles data algorithmic systems european path introduction guiding motifs mission basic understanding working method objectives scope report ethical legal principles fundamental value human agency relationship ethics law general ethical legal principles human dignity privacy security democracy justice solidarity sustainability technical foundations status quo system elements data definition properties data data management big data small data data processing algorithms statistical inference machine learning artificial intelligence algorithmic systems software hardware system architecture ctable contents governance complex data ecosystems general role state corporate corporate digital responsibility education boosting digital skills critical reflection technological developments ethical design research standardisation two governance perspectives data perspective algorithms perspective data general standards data governance foresighted responsibility respect rights parties involved data use data sharing public good data quality level information security transparency data rights corresponding obligations general principles data rights obligations clarification general principles reference typical scenarios scenarios involving desistance use scenarios involving access data scenarios involving rectification scenarios involving economic share collective aspects data rights data obligations standards use personal data personal data data relating legal entities digital challenge tackled legal system whole cooperative relationship applicable legal regimes interpretation applicable legal framework need clarify tighten applicable legal framework uniform supervisory activities personal data asset commercialisation personal data data ownership issue financial compensation data data basis personalised risk assessments data reputational capital data tradeable items data digital inheritance precedence living wills role intermediaries data protection special groups data subjects employees patients minors vulnerable persons data protection technical design design products services product development summary important recommendations action improving controlled access personal data enabling research uses personal data preliminary considerations legal clarity certainty consent processes sensitive data legal protection discrimination anonymisation pseudonymisation synthetic data procedures standards presumption rules ban synthetic data controlled data access data management data trust schemes privacy management tools pmt personal information management systems pims need regulation potential interface data economy data access data portability promotion data portability scope right data portability extended portability interoperability interconnectivity crowdsensing public good summary important recommendations action debates around access data appropriate data access macroeconomic asset creation necessary framework conditions awareness raising data skills building infrastructures needed economy sustainable strategic economic policy improved industrial property protection data partnerships data access existing value creation systems context presence contractual relationship absence contractual relationship data access rights open data public sector preliminary considerations legal framework infrastructures state duty protection open data private sector platforms data use additional incentives voluntary data sharing statutory data access rights role competition law data access purposes summary important recommendations action algorithmic systems characteristics algorithmic systems general standards algorithmic systems design compatibility core societal values sustainability design use algorithmic systems high level quality performance guarantee robustness security minimising bias discrimination prerequisite fair decisions transparent explainable comprehensible systems clear accountability structures result consideration recommendation regulatory approach system criticality system requirements criticality pyramid regulation algorithmic systems enshrining horizontal requirements formed sectoral instruments summary important recommendations action instruments obligations data controllers rights data subjects transparency requirements mandatory labelling duties provide information duties provide explanation access information risk impact assessment duty draw documentation keep logs requirements algorithmic systems general quality requirements algorithmic systems special protective measures use algorithmic systems context human right appropriate algorithmic inferences legal protection discrimination preventive official licensing procedures algorithmic systems summary important recommendations action institutions regulatory powers specialist expertise distribution supervisory tasks within sectoral network oversight authorities definition oversight powers according tasks involved extent oversight corporate creation code conduct quality seals algorithmic systems contact persons algorithmic systems companies authorities involvement civil society stakeholders technical standardisation institutional legal protection particular rights associations file action summary important recommendations action special topic algorithmic systems used media intermediaries relevance democratic process example social networks diversity media intermediaries example social networks labelling obligation social bots measures combat fake news transparency obligations news aggregators summary important recommendations action use algorithmic systems state bodies opportunities risks involved use algorithmic systems state bodies algorithmic systems algorithmic systems dispensation justice algorithmic systems public administration algorithmic systems public security law transparency requirements use algorithmic systems state actors risk involved automated total enforcement summary important recommendations action liability algorithmic systems significance harm caused use algorithmic systems liability electronic person vicarious liability autonomous systems strict liability product security product liability need reassessment liability law summary important recommendations action european path appendix federal government key questions data ethics commission members data ethics commission executive summar executive summary executive summar society experiencing profound changes brought digitalisation innovative technologies may benefit individual wider societal levels well potentially boosting economic productivity promoting sustainability catalysing huge strides forward terms scientific progress time however digitalisation poses risks fundamental rights freedoms raises wide range ethical legal questions centring around two wider issues role want new technologies play design want ensure digital transformation serves good society whole society elected political representatives must engage debate use shape technologies including artificial intelligence germany federal government set data ethics commission datenethikkommission july given mandate develop ethical benchmarks guidelines well specific recommendations action aiming protecting individual preserving social cohesion safeguarding promoting prosperity information age starting point federal government presented data ethics commission number key questions clustered around three main topics adm data opinion data ethics commission however merely one among many possible variants algorithmic system much common systems terms ethical legal questions raises mind data ethics commission structured work two different headings data algorithmic systems broader sense preparing opinion data ethics commission inspired following guiding motifs design technology digital skills critical reflection digital world protection individual freedom determination integrity responsible data utilisation compatible public good regulation effective oversight algorithmic systems promoting democracy social cohesion digital strategies sustainability goals digital sovereignty germany europe general ethical legal principles humans morally responsible actions escaping moral dimension humans responsible goals pursue means pursue reasons dimension societal conditionality human action must always taken account designing technologically shaped future time notion technology serve humans rather humans subservient technology taken incontrovertible fact germany constitutional system founded understanding human nature adheres tradition europe cultural intellectual history digital technologies altered ethical framework terms basic values rights freedoms enshrined german constitution charter fundamental rights european union yet new challenges facing mean need reassert values rights freedoms perform new balancing exercises mind data ethics commission believes following ethical legal principles precepts viewed indispensable socially accepted benchmarks dignity human dignity principle presupposes uncon ditional value every human prohibiting practices total digital monitoring individual humiliation deception manipulation exclusion fundamental expression freedom encompasses notion informational term digital determination used express idea human selfdetermined player data society privacy right privacy intended preserve individual freedom integrity personal identity potential threats privacy include wholesale collection evaluation data even intimate topics security principle security relates physical emotional safety humans also environmental protection involves preservation vitally important assets guaranteeing security entails compliance stringent requirements relation interaction system resilience attacks misuse executive summar democracy digital technologies systemic relevance flourishing democracy make possible shape new forms political participation also foster emergence threats manipulation radicalisation justice solidarity view vast amounts power accumulated using data technologies new threats exclusion discrimination safeguarding equitable access distributive justice urgent task digitalisation foster participation society thereby promote social cohesion sustainability digital developments also serve sustainable development digital technologies contribute towards achieving economic ecological social sustainability goals ethics equated basis law words everything relevant ethical perspective enshrined legislation conversely provisions law motivated purely pragmatic considerations nevertheless law must times heedful potential ethical implications legal provisions force well living ethical standards data ethics commission holds view regulation necessary replaced ethical principles particularly true issues heightened implications fundamental rights require central decisions made democratically elected legislator regulation also essential basis building system citizens companies institutions trust transformation society guided ethical principles time regulation must unduly inhibit technological social innovation dynamic market growth overly rigid laws attempt regulate every last detail situation may place stranglehold progress increase red tape extent innovation german companies longer keep pace rate technological development international stage yet legislation one range tools used lend tangible shape ethical principles synergistic use various governance instruments different levels governance vital view complexity dynamism data ecosystems instruments include legislative measures standardisation also various forms regulation technology technological design moreover function governance instruments applies business models options steering economy governance broader sense also encompasses decisions fields education research important consider aforesaid governance instruments national context also particular european international contexts view data ethics commission key questions presented federal government belong one two different perspectives questions concentrate mainly data data perspective questions primarily focused algorithmic systems algorithms perspective two perspectives regarded competing views two sides coin instead represent two different ethical discourses complement contingent upon different ethical discourses typically also reflected different governance instruments including different acts legislation data data perspective focuses digital data used machine learning basis algorithmically shaped decisions plethora purposes perspective considers data primarily view origin potential impact processing may certain parties involved data data subject well society large ethical legal point view important identify standards data governance typically however rights parties involved data enforce others play even significant role central distinction context personal data since determines whether provisions data protection law apply general standards data governance opinion data ethics commission responsible data governance must guided following data ethics principles responsibility possible future cumulative effects network effects effects scale technological developments changing actor constellations must taken account gauging potential impact collecting processing forwarding data individuals general public rights parties involved parties involved generation data whether data subjects different role may rights relation data rights must respected use data sharing public good resource data duplicated used parallel many different individuals many different purposes thereby furthering public good data quality responsible use data includes ensuring high level data quality fit relevant purpose level information security data vulnerable external attacks difficult recover gone astray standard information security applied must therefore commensurate potential risk inherent situation question transparency controllers must prepared position account activities requires appropriate documentation transparency necessary corresponding liability regime place executive summar data rights corresponding obligations navigation data society parties must able enforce certain rights others first foremost among rights relating individual personal data derive right informational selfdetermination enshrined fundamental right guaranteed applicable data protection law digital data society also includes economic exploitation one data includes selfdetermined manage ment data data generated one devices data ethics commission takes view principle right digital data society also applies companies legal entities least extent groups persons collectives data often generated contributions different parties acting different roles data subject owner generating device yet another role opinion data ethics commission contributions generation data lead exclusive ownership rights data rather dataspecific rights participation turn may lead corresponding obligations part parties extent individual entitled data rights kind shape take depends following general factors nature scope party contribution data generation weight party legitimate interest granted data right weight possibly conflicting interests part party third parties taking account potential compensation arrangements protective measures remuneration interests general public balance power parties rights may allow holders pursue number different goals particular following controller desist data use right require erasure data controller rectify data controller grant access data full data portability economic share profits derived help data type data right desistance rectification access economic share exists separate set conditions defining counts party legitimate interest granted data right determining whether party right require desistance particular data use key considerations include potential harm associated said use circumstances party question contributed generating data potential harm may also relevant request made rectify data benchmark lower respect party requests access data graded spectrum interests count legitimate interest granted access particularly relevant within existing value creation systems narrowly defined conditions may party independent claim economic share profits derived others rights granted data subjects general data protection regulation gdpr particularly important manifestation data rights aimed specifically protecting natural persons data pertain also extent standardised manifestation given hinge qualification data personal data considering principles data ethics commission wishes submit following key recommendations action executive summar standards use personal data data ethics commission recommends measures taken ethically indefensible uses data examples uses include total surveillance profiling poses threat personal integrity targeted exploitation vulnerabilities addictive designs dark patterns methods influencing political elections incompatible principle democracy vendor systematic consumer detriment many practices involve trading personal data data protection law well branches legal system including general private law unfair commercial practices law already provide range instruments used prevent ethically indefensible uses data however spite widespread impact enormous potential harm little done date terms harnessing power instruments particularly market giants various factors contributing enforcement gap must tackled systematically well steps make players supervisory authorities aware existing options urgent need legislative framework force fleshed clearly strengthened certain areas examples recommended measures include blacklisting unfair contract terms fleshing contractual duties fiduciary nature new torts blacklisting certain unfair commercial practices introduction much detailed legislative framework profiling scoring data trading order allow supervisory authorities take action effectively authorities need significantly better human material resources attempts made strengthen formalise cooperation different data protection authorities germany thereby ensuring uniform coherent application data protection law attempts fail consideration given centralisation supervisory activities within authority granted broad mandate cooperates closely specialist supervisory authorities authorities land level remain responsible supervisory activities relating public sector however data ethics commission believes data ownership exclusive rights data modelled ownership tangible assets intellectual property would solve problems currently facing would create new problems instead recommends refraining recognition also advises granting data subjects copyrightlike rights economic exploitation respect personal data might managed collective societies data ethics commission also argues data referred provided exchange service even though term sums issue nutshell helped raise awareness among general public regardless position data protection authorities european court justice ultimately take regard prohibition gdpr tying bundling consent provision service data ethics commission believes consumers must offered reasonable alternatives releasing data commercial use appropriately designed pay options executive summar stringent requirements limitations imposed use data personalised risk assessment black box premiums certain insurance schemes particular processing data may intrude intimate areas private life must clear causal relationship data risk difference individual prices charged basis personalised nonpersonalised risk assessments exceed certain percentages determined also stringent requirements respect transparency nondiscrimination protection third parties data ethics commission advises federal government consider issues falling heading digital inheritance settled federal court justice ruling ephemeral spoken word replaced many situations digital communications recorded less entirety possibility records handed deceased heirs adds whole new dimension privacy risk range mitigating measures taken including imposition new obligations service providers quality assurance standards digital estate planning services national regulations data protection data ethics commission recommends federal government invite social partners work towards common position legislative provisions adopted view stepping protection employee data based examples best practices existing collective agreements concerns individuals forms employment also taken account process view benefits could gained digitalising healthcare data ethics commission recommends swift expansion digital infrastructures sector expansion range quality digitalised healthcare services include measures better allow patients exercise rights informational measures could taken respect include introduction electronic health record building participatory process involves relevant stakeholders development procedures reviewing assessing digital medical apps health markets data ethics commission calls action significant enforcement gap exists regard statutory protection children young people digital sphere particular attention paid development mandatory provision technologies including effective identity management default settings guarantee reliable protection children young people also familyfriendly neither demand much parents guardians allow even encourage excessive surveillance home environment standards guidelines handling personal data vulnerable persons introduced provide greater legal certainty professionals care sector time consideration given clarifying relevant legal provisions living wills may also include dispositions regard future processing personal data far processing require person consent dementia patients position provide legally valid consent executive summar data ethics commission believes number binding requirements introduced ensure design products services principles privacy design privacy default gdpr imposes controllers already put practice upstream manufacturers service pro viders requirements would particularly important regard consumer equipment con text standardised icons also introduced consumers able take informed purchase decisions action must also taken number different levels provide manufacturers adequate incentives implement features design cludes effective legal remedies pursued parties along entire distribution chain ensure also manufacturers held accountable inadequate application principles privacy design privacy default consideration also given particular requirements built tender specifications procure ment guidelines public bodies conditions funding programmes applies product development including training algorithmic systems debates data protection tend quite rightly centre around natural persons important ignore fact companies legal persons must also granted protection almost limitless ability pool together individual pieces data used means obtaining comprehensive picture company internal operating procedures information passed competitors negotiating partners parties interested takeover bid poses variety threats inter alia digital sovereignty germany europe view significant volumes data flow third countries many data ethics commission recommendations action therefore also apply mutatis mutandis basis data legal persons data ethics commission believes action must taken federal govern ment step level protection afforded companies controlled access personal data data ethics commission identifies enormous potential use data research purposes serve public interest improve healthcare provision data protection law currently stands acknowledges potential principle granting privileges processing personal data research purposes uncertainty persists however particular regards scope research privilege secondary use data scope counts research context product development data ethics commission believes appropriate clarifications law necessary rectify situation fragmentation data protection law within germany among member states represents potential obstacle datadriven research data ethics commission therefore recommends regulations harmonised federal land level different legal systems within introducing notification requirement specific national law could also bring improvement could establishment european clearing house research projects case research involving particularly sensitive categories personal data health data guidelines produced information researchers obtain consent legally compliant manner innovative consent models promoted explicitly recognised law potential options include development digital consent assistants recognition meta consent alongside endeavours clarify scope research privilege secondary use data executive summar data ethics commission supports principle move towards learning healthcare system healthcare provision continuously improved making systematic use health data generated basis keeping principles medicine progress made direction however greater efforts must made time protect data subjects significant potential discrimination exists sensitive categories data used might involve prohibiting exploitation data beyond defined range purposes development procedures standards data anonymisation pseudonymisation central efforts improve controlled access formerly personal data legal presumption compliance standard achieved data longer qualify personal appropriate safeguards provided respect data subject rights would improve legal certainty long way measures accompanied rules pain criminal penalty prohibit anonymised data new technology becomes available would allow data subjects reversal pseudonymisation absence narrowly defined grounds also research field synthetic data shows enormous promise funding funnelled area fundamentally speaking data ethics commission believes innovative data management data trust schemes hold great potential provided systems designed robust suited applications compliant data protection law broad spectrum models falls heading ranging dashboards perform purely technical function privacy manage ment tools pmt right comprehensive data consent management services personal information man agement services pims underlying aim empower individuals take control personal data overburdening decisions beyond capabilities data ethics commission recom mends research development field data management data trust schemes identified funding priority also wishes make clear adequate protection rights legitimate interests parties involved require additional regulatory meas ures level regulatory measures would need secure central functions without operators active since scope action would otherwise limited hand also necessary protect individuals parties assume acting interests reality prioritising financial aims interests others event feasible method protection found data trust schemes could serve vitally important mediators data protection interests data economy interests far right data portability enshrined article gdpr concerned data ethics commission recommends codes conduct standards data formats adopted given underlying purpose article gdpr make straightforward change provider also allow providers access data easily important evaluate carefully market impact existing right portability analyse potential mech anisms prevented small number providers increase yet market power findings evaluation available expansion scope right example cover data data provided data subject time porting data would seem premature advisable certain sectors example messenger services social networks interoperability interconnectivity obligations might help reduce market entry barriers new providers obligations designed asymmetric basis stringency regulation increase step company market share interoperability interconnectivity obligations would also prerequisite building strengthening within europe certain basic services information society executive summar debates around access nonpersonal data access european companies appropriate personal data appropriate quality key factor growth european data economy order benefit enhanced access data however stakeholders must sufficient degree data skills necessary make use data also access data proves disproportionately advantageous stakeholders already built largest reserves data best data infrastructures hand data ethics commission therefore wishes stress factors referred always receive due attention discussing whether improve data access keeping asisa principle awareness skills infrastructures stocks access data ethics commission therefore supports efforts already initiated european level promote improve data infrastructures broadest sense term platforms standards application program ming interfaces elements model contracts support centre recommends federal govern ment efforts continue matched corresponding efforts national level would also advisable set ombudsman office federal level provide assistance support relation nego tiation data access agreements dispute settlement data ethics commission ascribes enormous impor tance holistically conceived sustainable strategic economic policy outlines effective methods preventing exodus innovative european companies acquisition compa nies also excessive dependence infrastructures server capacities balance must struck context international cooperation networking one hand resolute assumption responsibility sustaina security prosperity europe backdrop global power dynamic also perspective boosting european data economy data ethics commission see benefit introducing new exclusive rights data ownership data producer right instead recommends affording limited effects contractual agreements restrictions data utilisation onward transfer data recipient effects could modelled new european regime protection trade secrets data ethics commission also recommends adoption legislative solutions enabling european companies cooperate use data example using data trust schemes without running afoul law data partnerships data accumulated existing value creation systems production distribution chains often enormous commercial significance inside outside value creation system many cases however provisions data access appear contractual agreements concluded within value creation system unfair inefficient lacking entirely certain cases contractual agreement efforts must therefore made raise awareness among businesses sectors far outside commonly perceived data economy provide practical guidance support model contracts data ethics commission furthermore recommends cautious adaptations current legislative framework first stage process make explicit reference section german civil code b√ºrgerliches gesetzbuch bgb special relationship exists party contributed generation data value creation system controller data clarifying parties may certain duties fiduciary nature duties normally include duty enter negotiations fair efficient executive summar data access arrangements consideration also given whether additional steps taken could range blacklisting particular contract terms also transactions formulating default provisions data contracts introducing specific data access rights data ethics commission believes open govern ment data ogd concepts hold enormous potential recommends concepts built promoted also recommends series measures promote shift mindset among public authorities something yet fully taken place make easier practice share data basis ogd concepts measures include establishment relevant infrastructures platforms also harmonisation improvement existing legal framework currently fragmented sometimes inconsistent nevertheless data ethics commission identifies degree tension efforts promote ogd relying principles open default open purposes efforts enhance data protection protection trade secrets legally enshrined concepts privacy default data ethics commission submits cases doubt priority given duty protecting individuals companies entrusted data state often without given choice matter tax information state must deliver duty implementing range different measures may include technical well legal safeguards misuse data particular would beneficial develop standard licences model terms conditions sector data sharing arrangements make use mandatory least basis standard licenses model terms conditions include clearly defined safeguards rights third parties affected data access arrangement provision also made data used way ultimately harms public interests also still greater accumulation data market power part big players would likely undermine competition taxpayer pay twice regards concepts private sector priority given promoting supporting voluntary arrangements consideration must given improvement infrastructures data platforms also broad range potential incentives might include certain privileges context tax breaks public procurement funding programmes licensing procedures statutory data access rights corresponding obligations grant access considered options measures fail deliver desired outcomes generally speaking data ethics commission believes cautious approach taken introduction statutory data access rights ideally rights developed basis sectors level demand analysed include media mobility energy sectors case statutory data access right even disclosure obligation introduced full impact assessment needs carried examining weighing possible implications include implications data protection protection trade secrets investment decisions distribution market power well strategic interests german european companies compared companies third countries data ethics commission recommends considering enhanced obligations private enterprises grant access data public interest purposes cautious approach however recommended respect well algorithmic systems algorithms perspective focuses architecture algorithmic systems dynamics systems impacts individuals society ethical legal discourse area typically centres around relationship humans machines particular focus automation outsourcing increasingly complex operational making processes autonomous systems enabled algorithms perspective differs data perspective data processed system might connection whatsoever persons affected particular individuals may suffer ethically indefensible implications even data used train algorithmic system nonpersonal current debates algorithmic oversight liability central importance respect general standards algorithmic systems data ethics commission distinguishes three different levels algorithmic involvement human based distribution tasks human machine specific case question decisions human decisions based either whole part information obtained using algorithmic calculations decisions human decisions shaped outputs algorithmic systems way human factual abilities capacity restricted decisions trigger consequences automatically provision made human decision individual opinion data ethics commission following principles observed ensure responsible use algorithmic systems design systems must centred around human uses affected decisions must prioritise fundamental rights freedoms basic needs physical emotional skills development core societal values process system design must take account system impact society whole particular effects democratic process centred nature state action competition future work digital sovereignty germany europe considerations relating availability human skills participation environmental protection sustainable resource management sustainable economic activity becoming increasingly important factors design use algorithmic systems performance algorithmic systems must work correctly reliably goals pursued help achieved security robust secure system design involves making system secure external threats also protecting humans environment negative impacts may emanate system bias discrimination making patterns upon algorithmic systems based must source systematic bias cause discriminatory decisions executive summar explainable comprehensible systems vitally important ensure users algorithmic systems understand systems function explain control also parties affected decision provided sufficient information exercise rights properly challenge decision necessary accountability structures questions allo cation responsibility accountability including possible liability arising use algorithmic systems must unambiguously resolved system criticality level criticality algorithmic system dictates specific requirements must meet particular regard transparency oversight system criticality determined assessing algorithmic system potential harm basis investigation likelihood harm occur severity harm severity harm could potentially sustained example result mistaken decision depends significance legally protected rights interests affected right privacy fundamental right life physical integrity prohibition discrimination level potential harm suffered individuals including harm loss utility hard calculate monetary terms number individuals affected total figure harm potentially sustained overall harm sustained society whole may well beyond straightforward summation harm suffered individuals likelihood harm sustained also influenced properties system question particular role algorithmic system components process complexity decision effects decision reversibility effects severity likelihood predicted harm may also contingent whether algorithmic systems operated state private enterprises particularly business context market power wielded system conclusion data ethics commission wishes make following recommendations action basis principles regulatory approach data ethics commission recommends adopting regulatory approach algorithmic systems principle underlying approach follows greater potential harm stringent requirements farreaching intervention means regulatory instruments assessing potential harm sociotechnical system whole must considered words components algorithmic application including people involved development phase example training data used right implementation application environment evaluation adjustment measures data ethics commission recommends potential algorithmic systems harm individuals society determined uniformly basis universally applicable model purpose legislator develop assessment scheme tool determining criticality algorithmic systems scheme based general ethical legal principles presented data ethics commission among things regulatory instruments requirements apply algorithmic systems include corrective oversight mechanisms specifications transparency explainability comprehensibility systems results rules allocation responsibility liability using systems executive summar data ethics commission believes useful first stage determining potential harm algorithmic systems distinguish five levels criticality applications fall lowest levels level associated zero negligible potential harm unnecessary carry special oversight impose requirements general quality requirements apply products irrespective whether incorporate algorithmic systems applications fall level associated potential harm regulated basis regulatory instruments used connection may include controls obligation produce publish appropriate risk assessment obligation disclose information supervisory bodies also enhanced transparency obligations access rights individuals affected addition introduction licensing procedures may justified applications fall level associated regular significant potential harm applications fall level associated serious potential harm data ethics commission believes applications subject enhanced oversight transparency obligations may extend way publication information factors influence algorithmic calculations relative weightings pool data used algorithmic model option regulatory oversight via live interface system may also required finally complete partial ban imposed applications untenable potential harm level data ethics commission believes measures proposed implemented new regulation algorithmic systems enshrining general horizontal requirements regulation algorithmic systems horizontal regulation incorporate fundamental requirements algorithmic sytems data ethics commission developed particular group together general substantive rules informed concept system criticality admissibility design algorithmic systems transparency rights individuals affected organisational technical safeguards supervisory institutions structures horizontal instrument fleshed sectoral instruments member state level concept system criticality serving guiding framework process drafting recommended incorporate debate best demarcate respective scopes regulation gdpr number factors taken account respect firstly algorithmic systems may pose specific risks individuals groups even involve processing personal data risks may relate assets ownership bodily integrity discrimination secondly regulatory framework introduced future horizontal regulation algorithmic systems may need flexible current data protection regime executive summar instruments data ethics commission recommends introduction mandatory labelling scheme algorithmic systems enhanced criticality level upwards mandatory scheme kind would oblige operators make clear whether extent algorithmic systems used regardless system criticality operators always obliged comply mandatory labelling scheme risk confusion human machine might prove problematic ethical point view individual affected decision able exercise right meaningful information logic involved well scope intended consequences algorithmic system gdpr respect fully automated systems also situations involve kind profiling regardless whether decision taken basis later line right also expanded future apply decisions differing levels access decisions according system criticality measures may require clarification certain legislative provisions widening regulatory scope european level certain cases may appropriate ask operator algorithmic system provide individual explanation decision taken addition general explanation logic procedure scope system main objective provide individuals affected decision comprehensible relevant concrete information data ethics commission therefore welcomes work carried banner explainable efforts improve explainability algorithmic systems particular systems recommends federal government fund research development area view fact certain sectors society whole may affected well individual members also particular parties individually affected algorithmic system entitled access certain types information likely rights kind would granted primarily journalistic research purposes order take due account operator interests would need accompanied adequate protective measures data ethics commission believes consideration also given granting unconditional rights access information certain circumstances particular algorithmic systems serious potential harm level used state appropriate reasonable impose legal requirement operators algorithmic systems least potential harm level upwards produce publish proper risk assessment assessment kind also cover processing data well risks fall heading data protection particular appraise risks posed respect determination privacy bodily integrity personal integrity assets ownership discrimination encompass underlying data logic model also methods gauging quality fairness data model accuracy example bias rates statistical error overall certain exhibited system formation executive summar provide controllers processors greater legal clarity work must done terms fleshing requirements document log data sets models used level granularity retention periods intended purposes addition operators sensitive applications obliged future document log program runs software may cause lasting harm data sets models used described way comprehensible employees supervisory institutions carrying oversight measures regards origin data sets way example optimisation goals pursued using models system operators required setting body guarantee minimum level quality technical perspective procedural criteria imposed must ensure algorithmically derived results obtained correct lawful manner purpose quality criteria could imposed particular regards corrective control mechanisms data quality system security example would appropriate impose quality criteria relationship algorithmic data processing outcomes data used obtain outcomes data ethics commission believes necessary first step clarify flesh greater detail scope legal consequences article gdpr relation use algorithmic systems context human second step data ethics commission recommends introduction additional protective mechanisms systems since influence systems settings may almost significant applications prohibitory principle followed date article gdpr replaced flexible regulatory framework provides adequate guarantees regards protection individuals particular profiling concerned options individuals take action mistakes made rights jeopardised consideration given expanding scope legislation cover specific situations individual discriminated basis automated data analysis automated procedure addition legislator take effective steps prevent discrimination basis group characteristics qualify protected characteristics law discrimination often currently qualify indirect discrimination basis protected characteristic case algorithmic systems regular significant level even serious potential harm level would useful supplement existing regulations systems covered licensing procedures preliminary checks carried supervisory institutions interests preventing harm individuals affected certain sections population society whole institutions data ethics commission recommends federal government expand realign competencies existing supervisory institutions structures necessary set new ones official supervisory tasks powers primarily entrusted sectoral supervisory authorities already built wealth expert knowledge relevant sector ensuring competent authorities financial human technical resources need particularly important factor respect executive summar data ethics commission also recommends federal government set national centre competence algorithmic systems centre act repository technical regulatory expertise assist sectoral supervisory authorities task monitoring algorithmic systems ensure compliance law data ethics commission believes initiatives involving development technical statistical quality standards test procedures audits differentiated according critical application areas necessary worthy support test procedures kind provided designed adequately meaningful reliable secure may make vital contribution future auditability algorithmic systems opinion data ethics commission particular attention paid innovative forms coregulation alongside complement forms state regulation recommends federal government examine various models potentially useful solution certain situations data ethics commission believes option worth considering might require operators law inspired comply explain regulatory model sign declaration confirming willingness comply algorithmic accountability code independ ent commission equal representation must free state influence could set develop code kind would apply binding basis operators algorithmic systems appropriate involvement civil society representatives drafting code must guaranteed voluntary mandatory evidence protective measures form specific quality seal may also serve guarantee consumers algorithmic system question reliable time providing incentive developers operators develop use reliable systems data ethics commission takes view companies authorities operating critical algorithmic systems obliged future appoint contact person way companies specific size currently obliged appoint data protection officer communications authorities routed contact person also subject duty cooperation ensure official audits algorithmic systems take due account interests civil society companies affected suitable advisory boards set within sectoral supervisory authorities opinion data ethics commission technical standards adopted accredited standardisation organisations generally useful measure occupying intermediate position state regulation purely private therefore recommends federal government engage appropriate efforts towards development adoption standards system granting competitors competition associations consumer associations right file action important feature german legal landscape many years could play key role civil society oversight use algorithmic systems particular private rights kind could allow civil executive summar society players legitimate mandate enforce compliance legal provisions area contract law fair trading law law without needing rely authorities take action without needing wait individuals authorise special topic algorithmic systems used media intermediaries given specific risks posed media intermediaries act gatekeepers democracy data ethics commission recommends options examined countering risks also regard influencing legislation see recommendation whole gamut risk mitigation measures considered extending controls form licensing procedure national legislator constitutional obligation protect democratic system dangers free democratic pluralistic formation opinions may created providers act gatekeepers establishing binding normative framework media data ethics commission believes small number operators concerned obliged use algorithmic systems allow users least additional option access unbiased balanced selection posts information embodies pluralism opinion federal government consider measures take due account risks typically encountered media sector respect media intermediaries also respect providers act gatekeepers whose systems associated lower potential harm measures might include mechanisms enhancing transparency example ensuring information available technical procedures used select rank news stories introducing labelling obligations social bots establishing right post countering responses timelines use algorithmic systems state bodies state must interests citizens make use best available technologies including algorithmic systems must also exercise particular prudence actions view obligation preserve fundamental rights act role model general rule therefore use algorithmic systems public authorities assessed basis criticality model particularly sensitive entailing least comprehensive risk assessment areas dispensation justice algorithmic systems may used peripheral tasks particular algorithmic systems must used undermine functional independence courts democratic process way contrast enormous potential exists use algorithmic systems connection administrative tasks particular relating provision services benefits legislator take due account fact giving green light greater number partially fully automated administrative procedures cautious consideration therefore given expanding scope section german administrative procedures act verwaltungsverfahrensgesetz vwvfg couched overly restrictive terms corresponding provisions statutory law measures must accompanied adequate steps protect citizens executive summar decisions taken state basis algorithmic systems must still transparent must still possible provide justifications may necessary clarify expand existing legislation freedom information transparency order achieve goals furthermore use algorithmic systems negate principle decisions made public authorities must generally justified individually contrary principle may impose limits use overly complex algorithmic systems finally greater priority accorded opensource solutions since latter may significantly enhance transparency government actions ethical point view general right rules regulations time however automated total enforcement law raises number different ethical concerns general rule therefore systems designed way human override technical enforcement specific case balance struck potential transgression automated perhaps preventive enforcement measure must times meet requirements proportionality principle liability algorithmic systems liability damages alongside criminal responsibility administrative sanctions vital component ethically sound regulatory framework algorithmic systems already apparent today algorithmic systems pose challenges liability law currently stands inter alia complexity dynamism systems growing autonomy data ethics commission therefore recommends current provisions liability law undergo checks necessary revisions scope checks revisions restricted basis narrowly defined technological features machine learning artificial intelligence proposal future system legal personality would granted algorithmic systems systems would liable damages electronic person pursued far concept protagonists based purported equivalence human machine ethically indefensible far boils introducing new type company company law fact solve pertinent problems way contrast harm caused autonomous technology used way functionally equivalent employment human auxiliaries operator liability making use technology correspond otherwise existing vicarious liability regime principal auxiliaries particular section german civil code example bank uses autonomous system check creditworthiness customers liable towards least extent would used human employee perform task debate currently stands appears highly likely appropriate amendments need made product liability directive dates back connection established new product safety standards addition certain changes may need made rules relating liability new bases strict liability may need introduced case necessary determine liability regime appropriate particular types products digital content digital services exact shape regime take depending criticality relevant algorithmic system consideration also given innovative liability concepts currently developed european level european path data ethics commission examined great many different questions course work discussions questions raised new ones turn alone serve indicate opinion serve one many building blocks larger edifice debate ethics law technology continue many years come data ethics commission takes view important remember ethics law democracy must serve shaping force change broader sense specifically field technology achieve goal interdisciplinary discourse politics society required care must taken ensure rules regulations adopted open enough retain regulatory clout ability adapt even face changes technologies business models rules regulations must enforced effectively means appropriate instruments procedures structures latter must make possible intervene promptly response infringements undesirable global contest future technologies germany europe confronted value systems models society cultures differ widely data ethics commission supports european path followed date defining feature european technologies consistent alignment european values fundamental rights particular enshrined european union charter fundamental rights council europe convention protection human rights fundamental freedoms data ethics commission believes state particular responsibility develop enforce ethical benchmarks digital sphere reflect value system order deliver promise citizens must act position political economic strength global stage excessive dependence others turns nation rule taker rather rule maker resulting citizens nation subject resulting citizens nation subject requirements imposed players elsewhere world private corporations part exempt democratic legitimacy oversight embarking efforts safeguard digital sovereignty germany europe long term therefore politically necessity also expression ethical responsibility part introduction part ntroduction guiding motifs society experiencing profound changes brought digitalisation innovative technologies may benefit individual wider societal levels well potentially boosting economic productivity promoting sustainability catalysing huge strides forward terms scientific progress time however digitalisation poses risks fundamental rights freedoms raises wide range ethical legal questions centring around two wider issues role want new technologies play design want ensure digital transformation serves good society whole society elected political representatives must engage debate use shape technologies including artificial intelligence germany federal government set data ethics commission datenethikkommission july given mandate develop ethical benchmarks guidelines well specific recommendations action aiming protecting individual preserving social cohesion safeguarding promoting prosperity information age starting point federal government presented data ethics commission number key questions clustered around three main topics adm data opinion data ethics commission however merely one among many possible variants algorithmic system much common systems terms ethical legal questions raises mind data ethics commission structured work two different headings data algorithmic systems broader sense preparing opinion data ethics commission inspired following guiding motifs design technology digital skills critical reflection digital world protection individual freedom determination integrity responsible data utilisation compatible public good regulation effective oversight algorithmic systems promoting democracy social cohesion digital strategies sustainability goals digital sovereignty germany europe mission basic understanding mission basic understanding society experiencing profound changes brought digitalisation innovative technologies may benefit individual wider societal levels well potentially boosting economic productivity promoting sustainability catalysing huge strides forward terms scientific progress cases already happened digital transformation offers tremendous opportunities countries particular germany closely networked economy means german companies coming increasing competitive pressure international market time already becoming apparent digitalisation poses risks fundamental rights freedoms raises wide range ethical legal questions centring around two wider issues role want new technologies play design want ensure digital transformation serves good individuals society whole society elected political representatives must engage debate shape design technologies including july federal government set data ethics commission datenethikkommission named members see annex christiane wendehorst christiane woopen appointed data ethics commission given mandate develop ethical benchmarks guidelines aiming protecting individual preserving social cohesion safeguarding promoting prosperity information age also asked put forward specific recommendations action suggestions possible legislation view allowing ethical guidelines observed implemented supervised starting point federal government presented data ethics commission number key questions see annex clustered around three main topics iii data context understood data ethics commission term technologies related applications based digital methods involve machine processing potentially large heterogeneous data sets complex procedure mimics human intelligence results obtained procedure may applied automated way important methods underpinning one aspect much wider computer science landscape include pattern recognition machine learning knowledge representation knowledge engineering turn encompasses heuristic search methods inference techniques action planning data ethics commission however believes would wrong restrict ethical legal debate alone merely one among many possible variants algorithmic system thus represents subset field systems types algorithmic systems share number features may give rise ethical problems meaning regulations focused alone would tackle part problem feature foreground brings specific challenges due consideration must given risk assessment stage time however many features besides require special attention following arguments therefore relate algorithmic systems kinds applications rarely based single algorithm examining algorithms isolation rarely meaningful ethical appraisal must based sociotechnical system whole words components algorithmic application including people involved development phase example training data used right implementation application environment evaluation adjustment measures part ntroduction working method september september data ethics commission met monthly basis discussed examples use cases new technologies range different sectors analysed terms technology involved ethical legal issues raised findings obtained work fundamental debates made possible identify overarching topics questions used starting point development ethical appraisal framework drafting specific recommendations future political legislative action early october response policy paper federal government data ethics commission put forward two specific recommendations points included artificial intelligence strategy recommendations taken federal government november data ethics commission issued another recommendation calling electronic health record building participatory data ethics commission involved public two public conferences first took place february federal ministry justice consumer protection bundesministerium der justiz und f√ºr verbraucherschutz centred around issue selfdetermination external determination age artificial intelligence second international round table title towards ethical shaping digital future held may federal ministry interior building community bundesministerium des innern f√ºr bau und heimat events allowed data ethics commission engage discussions experts stakeholders well members public interested documents available data ethics commission website information public conferences including video recordings found data ethics commission website november federal government digitalklausur exchange views took place federal chancellor members federal government two data ethics commission discussions also held individual members federal government addition data ethics commission organised expert hearings consultation meetings institutions bodies working related topics including study commission artificial intelligence commission experts competition law federal government digital council advisory council consumer affairs many one defining features data ethics commission work advisory activities fully independent free external political influence viewpoints outlined report reflect either personal opinions expressed data ethics commission individual members opinions emerged internal discussions within institutional members data ethics commission adopted recommendations report consensus objectives scope report objectives scope report goal pursued data ethics commission publishing report development ethical legal framework order confront challenges posed digital technologies main concern ensure fundamental conditions place free democratic basic order preserved potential exists leveraged goals achieved social market economy flourish given increase volume personal data collected use automated methods process data different purposes one main priorities data ethics commission reconcile need protect individual fundamental rights freedoms including integrity need promote progress prosperity safeguarding democracy shaping society fit future protecting individuals data misuse discrimination guaranteeing security parties involved tasks fall squarely within remit state governed rule law effective regulations must adopted institutions set purpose time however state must facilitate emergence innovative business models safeguard future prosperity data ethics commission believes digitalisation particular rapidly increasing availability data use complex algorithmic systems including holds enormous potential technical social innovation achievement sustainable development goals promising avenues action include promoting health humanising world work designing sustainable cities communities providing decent education implementing effective climate protection measures time however must forget major risks may face individuals society whole free democratic basic order connection extensive use digital technologies risks include possibility granularity profiling using techniques online tracking voice analysis remote job interviews even diagnosis pathological mental conditions basis social media posts potential profiles exploited purpose controlling manipulating people either small scale individual pricing larger scale manipulating democratic processes targeting potential discrimination different social groups ability delegate human responsibility machines factors mind data ethics commission believes must actively shape future way realise potentials avoiding risks data ethics commission advocates approach achieving goals first step ethical reflection value human activity environment shaped technology reaffirmation key ethical principles precepts upon society founded part view data ethics commission key questions divided questions concentrate mainly data data perspective questions primarily focused algorithmic systems algorithms perspective two perspectives represent ethical discourses complement contingent upon also reflected different governance instruments part part ntroduction section devoted data perspective part data ethics commission outlines general ethical principles data governance particular ethical principles governing data rights data obligations serve basis series specific recommendations action regarding use data data access section devoted algorithms perspective part data ethics commission sets general ethical requirements design algorithmic systems regulation systems instruments institutions would required implement regulations kind examined detail summarised recommendations legislator shared basic understanding technical parameters relationships part serves essential foundation considerations kind report ends plea federal government follow european path part per mission data ethics commission recommendations targeted primarily german federal government associated institutions certain points however target audience widened include stakeholders example l√§nder municipalities research institutions enterprises federal government always secondary target audience recommendations given underlying recommendation encourage support stakeholders efforts recommendations also viewed context institutions rules put place international level context developments arenas cases data ethics commission suggests recommendation implemented international level interpreted recommendation german federal government make vigorous contribution debate taking place within europe across globe ethical legal principlespart part thical legal principles fundamental value human agency given development digital technologies including algorithmic systems artificial intelligence incorporate certain functions outperform abilities humans elementary question raised whether human agency poses ethically relevant value transcends considerations effectiveness efficiency inherently preferable functioning machine systems question pressing momentum internal logic international competition part dictated solely goal maximising economic efficiency human agency derives basic value moral significance human provide reasons one actions decide whether perform must bear responsibility actions taking action individuals develop realise full potential accordance capabilities preferences understanding meaningful life dimension meaning lends value human activity could never claimed functioning technical systems technology ever means achieving goal humans set even hypothetically speaking humans decide algorithmic systems could set goals allowing would goal set humans use technical systems may therefore component human activity may even ethically required certain cases never possible technical systems replace moral dimension human agency completely human agency human drive develop living characterised nature although conceptions man espoused different cultures different faiths vary significantly incorporate dimension living moral responsibility despite differences respective answers embrace question meaning life whereas technical systems merely function must weigh many different criteria identifying cases preference given human activity use algorithmic systems basic principle higher level effectivity prioritised regard performance certain limited functions effectiveness rule supreme must place material restrictions ability humans take action form must take second place basic ethical dimension meaningful flourishing life individual member society example even possible human cared effectively robot another human care robot allowed replace human element attention affection person needing care time however use robots perform tasks alongside humans may deemed expedient makes situation significantly safer person receiving care yet effectiveness gains technical systems must take back seat entail intrusion privacy personal integrity individual example force employee modify work processes order maximise effectiveness people must allowed retain subjectivity rather morphing objects acted upon machines humans morally responsible actions escaping moral dimension humans responsible goals pursue means pursue reasons dimension must always taken account designing technologically shaped future time notion technology serve humans rather humans subservient technology taken incontrovertible fact germany constitutional system founded understanding human adheres tradition europe cultural intellectual history relationship ethics law relationship ethics law exponential technical developments relating collection use digital data deployment algorithmic systems artificial intelligence increasingly shaping life every individual aspects social coexistence developments give rise profound questions answers questions must guided fundamental legal ethical principles democratic society undertakes uphold benchmarks guiding principles underpinning processes society shapes shape various sectors economy education public spaces healthcare finance transport energy fundamentally ethical nature although liberal systems characterised high degree moral pluralism common ethical framework nevertheless established constitutional law especially fundamental rights far relationship state individual concerned significance ethical legal framework relation individual case event conflict differing values fundamental rights always yet relativise binding nature fundamental importance ethical foundation community instead merely goes prove crucial importance open ongoing debate future shape society serves basis democratic processes acknowledge possibility different answers within framework constitution ethics equated basis law words everything relevant ethical perspective enshrined legislation conversely provisions law motivated purely pragmatic considerations ethically imperative nevertheless legislation must times heedful potential ethical implications must live ethical standards least requirements outlined constitutional data ethics commission holds view regulation necessary replaced ethical principles guidelines cases constitutionally developed principle materiality requires enactment form parliamentary legislation democratically legitimate rules enforced anyone internet governance also governance society algorithmic systems including artificial intelligence become increasingly normal feature daily lives lead together society must also develop enforce rules govern calls ongoing public debate also particularly cases fundamental rights threat parliamentary debate legislative initiatives given past experiences law enforcement internet sphere view experience power tends accumulated hands large corporations certain sectors markets dominated digital technologies systematic move away enforceable rules towards voluntary regulation would appear mistake time regulation must unduly inhibit technological social innovation dynamic market growth overly rigid laws attempt regulate every last detail situation may place stranglehold progress increase red tape extent innovative processes germany longer keep pace rate technological development international stage hand regulatory frameworks must protect fundamental rights freedoms create legal certainty essential first stage building system within citizens companies institutions trust fact transformation society guided ethical principles addition nature legal system options regulating matters many different levels ranging acts ordinances right codes options voluntary obligations makes suitable creating framework adaptable keep technological progress part thical legal principles however need guidance goes far beyond regulatory sphere mind many different stakeholders professional groups companies advisory boards national regional international level responded manifold upheavals drafting ethical codes sets guiding ethical principles cases ensuing public debate data ethics commission welcomes diversity stakeholders taking action number voices heard discussion process digitalisation shaped ethical way since highlights indispensability public debate everyone take responsibility flourishing future lives together keeping mission assigned coalition agreement data ethics commission based recommendations framework develop data policy deal algorithms artificial intelligence digital innovations precepts constitutional law also ethical principles apply differing degrees areas society principles briefly outlined following approach data ethics commission adhering basic principles endorsed european group ethics science new technologies ege opinion ege statement artificial intelligence robotics autonomous systems available general ethical legal principles general ethical legal principles human dignity human dignity ethical viewpoint synonymous unconditional value every human enshrined fundamental constitutional principle constitutional order foundational supreme importance follows principle human dignity every individual merits respect regardless attributes achievements protecting value inherent every human need acquired also implies human beings ranked classifying system across various spheres life activities super scoring labelled like object price treated accordingly fact human individual rather pattern made data points must also borne mind times situations human behaviour measured measurements processed algorithmic systems algorithmic systems must therefore always designed way cater human claim individuality acknowledging human dignity involves recognising humans must always superior technology must completely irrevocably subordinated technical systems opportunities configuration intervention may localised different levels specific application principle human sovereignty action must upheld humans hold responsibility interactions must regarded defective beings need optimised perfected machine instead human use algorithmic systems aims realising human ideas objectives effectively rapidly fewer human dignity also involves ensuring human relational misled technology nature relationship example would wrong human systematically deceived thinking speaking another human actually bot psychological integrity individual particularly important factor protecting human dignity rules use datadriven systems manipulative purposes particularly systems draw comprehensive highly granular personality profiles also rules use algorithmic systems discriminate systematically individuals groups example downgrading preventing using certain services ethically untenable reasons systematically misleading participate democratic discourse opportunity inextricably linked human dignity humans express freedom determining life goals way lead lives basis determining developing enacting essence self society takes freedom seriously must put place framework within citizens develop freely respect freedom despite differences example people lead life develop freedom technical systems must restrict control human avenues action without ethically meaningful reason must viewed solely individualistic lens humans relational beings whose life unfolds social interactions others basis manifold reciprocal links influences rules govern interactions shaped time cultural socionormative framework serves basis life together society also shaped law democratic society especially imbalances power information prevail part thical legal principles information third parties collected individual difficult becomes individual act unselfconsciously social situations even reinvent completely steps must taken ensure data collection evaluation practices result personal social profiles routinely created multiple locations thereby cementing particular version individual selfdetermination therefore also encompasses right develop alter one identity possibility starting one life afresh right thus also includes individual right decide perceived public prevent public misrepresentations another vital aspect people must allowed assume responsibility must justice task responsibility always lies human institutionally enshrined necessary never machine even technical system used apply inferences based automated evaluations whether loan granted responsibility developing using system ethically sound manner must lie humans important manifestation informational includes individual right determine collect use personal data may purpose informational allows individual protect freedom action privacy extent deems important also determine personality wants perceived treated era digitalisation special importance individuals actors data society goes beyond informational term digital refers encompasses skills needed individual determine content used basis interacting environment unfold personality interactive way certain circumstances may also include economic exploitation individual data assets governance data example data generated operating certain devices digital always goes hand hand digital accountability data ethics commission takes view businesses legal persons also entitled right digital legal persons invoke concept human dignity granted article paragraph german basic law grundgesetz protected framework general right personality therefore barred referring associated core area personality development enjoys absolute protection article paragraph basic law conjunction article paragraph basic law however grant legal persons protected right personality also incorporates right informational ability consumers take action conscious consumption decisions vital prerequisite optimum resource allocation maximisation public good macroeconomic level erosion skills needed consumers exercise right example excessive use assistants associated habituation effects raises ethical questions regarding external determination freedom individuals take decisions also regarding ability small number firms exert control society general ethical legal principles privacy protection human dignity closely materially linked protection privacy individual right determine may access personal information relating purpose may informational see section justified supreme ethical importance ability prevent intrusions one private sphere also appear public certainty one privacy protected efforts protect human dignity must include legislative measures regulate responsible use personal data aspect privacy need preserve integrity individual personal identity example integrity may violated algorithmic system using data collected entirely different purposes calculates personality individual together preferences proclivities system operator uses calculations purposes regardless even contrary individual given different spheres society shaped technologies important increase amount attention pay use data many people willing make personal data available public use receive certain products services return wish contribute public good merely telling public think twice disclosing personal data effective instead effective regulations must adopted people rely fact data used responsibly steps taken prevent ethically unacceptable uses security algorithmic systems also give rise crucial security questions context use may promote jeopardise user security security relevant ethical legal perspective role plays protecting values individual physical mental health privacy public security peace free equal democratic elections security relate collecting using data means concept also bearing protection privacy major data scandals hit headlines recent years made clear privacy breaches use personal data manipulative purposes sometimes political consequences consideration must also given physical emotional safety individual operates uses algorithmic system stringent requirements apply respect connection interactions robot carer used example must ensured neither person receiving care person providing care suffer harm terms physical mental integrity algorithmic systems may also impact environmental safety malfunctions algorithmically controlled public infrastructures traffic energy water supply infrastructures may cause enormous amounts damage algorithmic systems may also innately unsafe causing malfunctions even functioning gateways malicious attacks manipulation even beyond inherent system vulnerabilities kind must forgotten algorithmic system could misused harmful purposes part thical legal principles democracy digital technologies complex manner systemically relevant development fundamental rights particular freedom expression information informational confidentiality telecommunications freedom assembly association freedom occupation right property democracy safeguarding diversity open societal debate free equal elections example social media sites serve opportunity every citizen participate debates shape future principle welcomed time however risk may used manipulation radicalisation state take decisive action counter risks adopting rules setting institutions capable preventing undesirable developments misuse also undeniable fact rise internet accompanied economic decline journalism privately funded plurality yet electronic public sphere way considered valid replacement role played journalism democracy namely fourth estate watchdog democracy instance exercises control power claim truth basis systematic independent investigations criticism certain circumstances powerful media intermediaries playing gatekeeper function may exert controlling influence democratic formation posing significant threat democracy based ethical considerations provisions constitutional law must countered legislative training must also play prominent role safeguarding free democratic basic order since influence wide variety ways participation citizens shaping society process critical fundamental importance democracy citizens understanding appraisal socially relevant interrelationships developments ultimately level confidence future shaped founded values education training must impart technical mathematical skills also skills fields ethics law economics social sciences justice solidarity observance principles justice society institutions another fundamental factor allows live together peace prosperity freedom democracy data technology placed enormous influence economic clout societal sway results former hands small number large companies raised new questions fair economic order availability large volumes data digitalisation processes workplace healthcare sector raises questions relating equitable access distributive justice however example relation income provision healthcare developments may mean scarce resources distributed fairly may also mean individual groups people suffer disadvantage discrimination also close link justice opportunities participation stronger participatory processes also supported digital tools play important role promoting social innovations time social upheavals finally questions justice arise connection situations use algorithmic systems particular algorithmic systems means individuals groups people suffer discrimination justifying reason general ethical legal principles clear assignment responsibility accountability indispensable feature democratic state rule law adequate level transparency explainability essential prerequisite auditing algorithmic systems appropriately basis real potential harm opportunities seeking legal recourse necessary holding another party accountable liable must also available certain conditions world stands today access digital resources via internet fundamental requirement digital thus also social participation part public provision remit state obliged ensure citizens access internet infrastructure anywhere country adequate extent using either fixed mobile connection part educational remit must provide citizens skills needed navigation digital world accurate appraisal opportunities risks internet use opportunities participation promote social cohesion also based fundamental attitude societal solidarity integration latter institutional framework digital technologies may strengthen solidarity may also weaken destroy algorithmic systems used certain spheres society insurance sector provision opportunities social participation care must taken avoid systematic weakening solidarity may cases caused subtle effects example perfectly possible differentiation unequal treatment appears plausible justified individual cases lead overall reduction solidarity certain groups people may particularly reliant society sustainability digital technologies offer huge potential terms efficient resource management innovative business models economic aspect generally attracts lion share attention general debates topic date however less interest shown question whether digital technologies also contribute economic sustainability consideration must also given issues relating ecological social sustainability adopted sustainable development goals relating economic social ecological aspects apply member states achieved digital technologies may make easier aim pursued international telecommunication union itu good initiative example similarly german advisory council global change wissenschaftliche beirat der bundesregierung globale umweltver√§nderungen recently outlined vision highly granular network environmental sensors would allow unprecedented comprehensive monitoring natural earth systems condition development vital building block future digital sustainability policy yet digital technologies conserve resources also consume example demand electricity reliance digital products certain rare earth elements available limited quantities certain countries mining causes enormous damage environment raises questions regard sustainable economic ecological development also questions international justice concerning use natural resources global responsibility future generations part thical legal principles human knowledge human skills also resources whose sustainability must safeguarded development digital technologies concomitant reduction tasks need performed humans mean individuals gain certain new skills lose competences human debate must held responsibility towards next generation measures required preserve develop certain skills avenues independent action noted elsewhere opinion need regular comprehensive technological impact assessments assessments must also consider sustainability new technologies various manifestations incumbent upon legislator ensure responsibility sustainability incorporated rules govern data economy algorithmic systems example introduction obligation disclose entire energy footprint blockchain system pursuit sustainability goals set united nations particular focus public investments data economy algorithmic systems allocating government funding priority given economic gains nature development data algorithmic systems purposes recording monitoring environmental impacts developments systems optimising reducing energy resource consumption addition done promote social innovations foster social creativity participation part technical foundations part echnical foundations applications lasting impact living working environment economy scientific endeavours society well permanently tethered smartphones use search engines daily basis rely recommendation software send text voice messages family friends regulate temperature home remotely allow navigation devices guide one place another able series technological developments occurred past decades fundamental technical concepts underpinning developments described aim provide comprehensive account highlight key points basis identifying resulting problems starting points potential governance approaches status quo status quo entirely new fields application opened thanks improved performance miniaturisation physical components systems hardware used store process data along continual enhancements wired wireless connectivity smartphones tablets wearables gradually infiltrating workplaces homes along sensors actuators cases autonomous systems robots many locations internet always thanks mobile access making possible combination various sensors smartphones geolocators gyrosensors cameras microphones etc input text also upload image video audio recordings internet time almost anywhere penetration technology makes possible communicate use social networking sites also link devices internet things iot become impossible draw clear dividing line analogue digital worlds former contains components transfer information latter digital information becoming ever widely available analogue world bringing two closer closer together creating hybrid world volumes increasing exponentially thanks comprehensive arrays sensors iot falling price storage capacity specialised tools needed process large volumes data time accumulation much data together availability hardware promoted widespread use machine learning procedures achieved impressive results example field speech image recognition speech recognition video processing seen huge leaps forward terms performance potential boundaries reality information become blurred happens people longer sure whether talking speech bot whether watching normal video recording deep fake synthesised human image saying things real person never actually said part echnical foundations system elements data definition properties data keeping data ethics commission mission report concentrates data digital data made stream binary electrical impulses may transient signals exist instant control impulse technical system persistent stored medium data multifaceted word data umbrella term encompasses enormous range manifestations example data categorised basis data type binary nominal ordinal metric textual data process used generate data survey data sensor data sector data collected financial data weather data function digital system login data training data categorised basis level processing data yet processed referred raw data processed data referred structured unstructured depending level structuring normalisation data function input system output system output may turn function input another system data also represent digital assets multimedia content units cryptocurrency distinction enormous legal significance personal terms data information always synonymous make sense binary electrical impulses form basis digital data transform data information necessary know context semantics meaning one possible context would origin generated signal knowing precise sensor emitted signal example term semantics refers information contained certain sequence binary signals example appears survey may equally well represent number children household number tubes toothpaste bought past six months potential sources context semantics include metadata domain tables ontologies identifiers technical specifications supplement data values whenever term data used remainder report familiarity context semantics always implied data varying quality purpose data accurately information contained therein reflect reality accurately possible example done assigning attributes exhibited entities real life correct entities digital world information objects also many types data intended express likelihood something happening reality either future types data intended construct hypothetical reality others relation reality whatsoever cases pool data may contain errors distinction made errors cases data expected unsuitable achieving specific goal example performing particular analysis data insufficiently granular outdated incomplete way quality data used decisive importance systems since even perfect algorithm deliver results receives poor data input inaccurate inadequate data data quality absolute value relevant data quality dimensions quality level depend specific use see figure system elements data management data entity created process collecting preparing processing data involves many different human decisions implications future use data example potential might gained data may irretrievably lost stored without context semantics careful data management necessary avoid situations kind collating data different sources vital ensure collation possible technical semantic perspective interoperability data different sources must mapped way reflects semantics cases interoperability particularly important efforts made achieve standardisation technical specifications formats descriptive metadata reference data play important role respect standardised schemes ontologies fall remit national international institutions international classification diseases icd published doug laney data management controlling data volume velocity variety meta group big data small data term big data refer separate type data instead new methodological approach identification relationships famously used three volume velocity variety define approach still incipient stages large volumes varied data potentially variety sources generated high velocity often real time special technologies needed process large volumes rapidly changing data vary terms nature quality analysis large data sets big data particularly well suited situations necessary identify promising large number potential correlations field medical research example helpful start big data methods identify number likely candidates long list environmental factors might increase risk disease going perform costly experiments studies investigate candidates specific problem associated approach initially shows correlations rather causalities completely unsuitable candidates may therefore identified shape perfect colour brilliant surface glossy taste blemishes colour surface taste intense blemishes noneuse photographuse strawberry mousse figure example different quality requirements part echnical foundations many areas volumes data available never large enough allow analysis using big data methods example client base small company may never exceed customers number political parties one country rarely reaches three figures suitable small data analytical methods also used extract great deal knowledge information data quantity data matters instead decisive factor availability suitable tools make possible combine data adequately high quality quantities sufficient task hand basis effective data analysis data processing algorithms data protection point view term processing refers entire sequence actions data generation extraction storage transformation actual data article gdpr way contrast mathematical technical sciences mainly deploy term refer use data following arguments based latter two understandings term method digital data processing follows ipo input processing output model data enter system input processed leave output form internal processing within ipo system based algorithm words operational processing sequence specifies procedure series different processing steps aim achieving desired result successive transformations data inputs algorithms around since time euclid specified method easily calculating greatest common divisor two natural numbers word algorithm derived name arabian mathematician formerly latinised algorithmi published collection calculation rules solving algebraic equations hard overestimate importance term algorithm modern computer science solve particular problem processing data algorithm must implemented correctly also used productively presumes knowledge algorithm many cases however algorithm ultimately deliver desired result yet known first important task find suitable algorithm many situations practical relevance processing specifications derived directly deduced specialist knowledge known models legislative provisions situations understanding context yet sophisticated enough allow described using less simple mathematical formulae framework understanding absent various strategies applied identify algorithm include random chance trial error inference latter approach follows principle induction attempt made infer general rule individual cases data general rule found used solve question assumed suitable algorithm worth remembering may well several suitable rules furthermore result process induction may necessarily correct result inferred individual cases may partially wholly inaccurate system elements statistical inference central concern statistics drawing inferences data statistical inference procedures applied data sets investigate problems lack known inherent logic importantly however also used problems random chance forms integral part process modelled examples would estimating probability rain following day identifying highprobability prospects particular product many different statistical inference methods choose among starting various forms regression linear regression logistic regression regularisation ridge regression moving machines svm bayesian networks rule learners aprioiri cart random forest ending neural networks procedures suitable extracting information available data specifically designed solve regression questions example estimating future height child based height parents whereas others svm cart used question pregnant whether represent suitable means answering question depends many factors including data volume methods induction statistics offers broad set tools measuring quality results estimations obtained measurements used estimate potential errors monitor actual errors practice thus estimate child future height stated deviation range pregnancy test yields positive result result might deemed accurate pregnancy test good example need monitor two different parameters number false positives women pregnant pregnancy test positive number false negatives woman pregnant pregnancy test negative ideal statistical procedure would never result errors practice necessary weigh severity two errors decide false rate minimised worse woman find later date fact pregnant told woman told pregnant true two error types minimised time since generally case lower frequency one higher frequency balance must struck look different depending context part echnical foundations quality characteristics methods used basis assessing quality results even possible guarantee quality results obtained using certain methods example estimation procedures use uniformly unbiased estimator umvue ensure best possible results obtained using data available regression using parameters supplies result stating expected height child estimator would achieved smaller error margin similarly machine used model determined basis relevant data provided model found guaranteed best possible model method question certain cases procedures assessing quality either model estimates generated using model yet developed applies particular method class neural networks quality indications also provided neural networks however measurements well model functions using data previously unknown particularly important model taught using one data set training data assessed quality using different data set test data approach used identify models reflect general rule learned training data thoroughly cases kind referred overfitting overfitted model achieve significantly better quality values training data test data many statistical procedures solved analytically means question formulated mathematical equation system equations solved transformations even though often requires great deal skill however direct analytical solution impossible many methods example additional conditions regularisation term applied see cases use made optimisation procedures approximate solution many small steps optimisation procedures necessarily optimal example calculated result may local optimum global optimum one different classes problems analytical procedures optimisation procedures direct analytical solution possible tasks find value equation solution kind possible task solve linear equation many parameters possible equal additional regularisation term applied purpose min sum parameter optimisation procedures used find solutions system elements machine learning boundary traditional statistics machine learning term first defined difficult delineate scales tip towards machine learning latest optimisation procedures see section details used solve inductive inference problems different approaches estimation learning strategies fall heading machine learning differentiated basis formulation optimisation problem solved distinction made number different learning procedures learning supervised learning procedures require knowledge correct output ipo model piece information used input height classic example inferring height child output height parents input necessary know height child advance also necessary know correct result pregnancy test actual weather follows weather forecast properties soil predicted soil analysis etc practice real challenge often lies obtaining correct output information assessing quality output information frequently referred label majority machine learning algorithms currently use trained using supervised learning procedures tom mitchell machine learning decisive questions regard learning procedures formulate actual optimisation problem regularisation terms use define loss function errors treated different weightings levels severity comparing false negatives patients cancer incorrectly diagnosed healthy false positives healthy patients incorrectly diagnosed cancer quality labels labels also contain errors several levels complexity defined data labelling labels whose accuracy verified data collected example one correct relevant value exists physical systems properties speed object temperature room individual date birth principle therefore values ascertained labels algorithm labels whose accuracy verified data collected may certain cases verifiable later date labels construed relationship real world example concepts social milieus character types developed view achieving better understanding analytical grasp humans behaviour concepts abstractions necessarily accurate representation truth far exists part echnical foundations learning involves assessing agent actions imposing punishment reward agent selects pool different actions performs whichever action selected action changes state system functions optimisation input addition state change state system brought agent actions must also clearly defined reward function case supervised learning correct optimal solution available every input necessarily true case reinforcement learning instead optimisation goal pursued finding action strategies lead best end state reference optimisation problem actions deliver improvements may need rejected achieve goal alongside optimisation problem relevant loss factor reward function plays particularly important role learning strategy learning involves searching structures particular quantity input data need correct structures known reward function exist precise definition structure searched required however example search carried clusters groups data imposing requirement difference data points cluster minimised difference clusters maximised optimisation problem unsupervised learning identified basis unsupervised learning also referred data mining decisive factors include learning procedures also availability sufficient volumes data adequately high quality broad scope since close approximation optimisation goal otherwise achieved many cases volume quality scope data lacking way meaning avenues must pursued ensure good outcomes nevertheless obtained using machine learning techniques identifying optimisation goal public transport company planning alter bus routes reflect recent changes city operates many residents moved peripheral areas large brownfield sites developed gentrification brought huge changes composition population various districts project manager collected data form passenger usage figures attempting optimise routes served city needs met effectively possible without needing use extra buses aware range different goals constraints could imposed optimisation using fewer buses using fewer drivers avoiding creation new routes example depending optimisation problem formulated might possible achieve solution whereby densely populated neighbourhoods served bus lines compared districts anyone living suburb forced put longer travel times lower frequency buses since project manager lives affluent commuter belt personal preference optimisation strategy minimises longest travel time strategy kind would result faster connections areas city including outlying districts line manager unimpressed models believes goal transport many passengers possible puts routes plenty passengers advantage bad news longer routes four stops readily apparent decisions optimisation function social impacts many questions raised including following decide goal optimisation else say decision matter debated general public necessary meaningful certain access legal remedies feel placed unfair disadvantage compared others system elements example synthetic data used data generated artificially rather collected directly real world boast several advantages produced quantity particularly important dealing simulations data yet generated created steps taken ensure entire range possible values included synthetic data order test technical system would behave confronted unusual data combinations quality measured necessary guaranteed individual cases properties set reference data retained alternatively distortions occurring sets data pinpointed removed order avoid discrimination set synthetic data contains references persons anonymous fall within scope gdpr synthetic data also used train algorithms test systems however risk algorithm influenced properties artificially generated data counterpart reality separate functional testing must therefore carried algorithm used practical applications middle course frequently adopted form augmentation involves creating new data data greater range situations covered training stage pool data enlarged relationship data preserved term augmentation describes process generating new data deviate slightly original data example characteristic feature augmented images shifted rotated distorted way j√∂rg jentzsch synthetische daten innovationspotenzial und gesellschaftliche herausforderungen synthetic data potential innovation societal challenges stiftung neue verantwortung may available john shannon proposal dartmouth summer research project artificial intelligence artificial intelligence current parlance field machine learning specifically neural networks referred artificial intelligence term often gives rise confusion machine learning one specific procedure falls heading weak used solve tasks way contrast strong methods expected tackle single task handle broad spectrum tasks potentially without human intervention despite hopes raised term artificial intelligence machine learning methods capable feats historically speaking concept artificial intelligence first appeared dartmouth proposal published back refer broad area research within field computer science decades since first emerged field research marked repeated cycles unrealistic expectations followed disillusionment left ivory towers made inroads economy everyday life workplaces homes latest form expert systems research efforts germany stepped gear achievements chalked research include machine learning techniques also large number vitally important methods procedures pattern recognition knowledge representation inferences action planning user modelling applications procedures include speech image dialogue comprehension robotics systems part echnical foundations revision ystorage data production development search production monitoring quality assurancerecalibration figure process model algorithm based machine learning ongoing monitoring assessment process starts algorithm developed using training data algorithm identified meets desired quality standards put production ensure monitoring quality control capabilities production process must make possible record input enters algorithm output leaves algorithm relevant correct value information used basis monitoring algorithm production environment comparison carried determine extent output algorithm reflects expected value algorithm continue operated without changes event deviations values significant deviations detected may necessary recalibrate parameters algorithm critical deviations detected algorithmic redesign recommended problem understanding comprehending humans often find difficult impossible understand methods intuitively described mathematical technical terms even goes experts field modelling even case relatively simple classification methods well understood mathematically logistic regression almost one intuit result return given set input networks image recognition good example phenomenon human generally look photograph understand immediately looking human looking data structures used input neural network intended classify photograph likely understand almost nothing means even human familiar digital input values comprehends steps neural network necessarily understand recognition process error occurs example may able determine recognition failed problem fixed humans machines recognise objects patterns according different sets rules always easy translate two system elements problem understanding comprehending humans often find difficult impossible understand methods intuitively described mathematical technical terms even goes experts field modelling even case relatively simple classification methods well understood mathematically logistic regression almost one intuit result return given set input networks image recognition good example phenomenon human generally look photograph understand immediately looking human looking data structures used input neural network intended classify photograph likely understand almost nothing means even human familiar digital input values comprehends steps neural network necessarily understand recognition process error occurs example may able determine recognition failed problem fixed humans machines recognise objects patterns according different sets rules always easy translate two part echnical foundations algorithmic systems algorithmic system generally incorporates multiple algorithms work together rather single algorithm term component used describe executable part system different components algorithm might based different technical implementations architectural style known microservices good example important remember individual components system kind might subject different regulatory requirements protection objectives development addition different stakeholders might responsible different components algorithmic system example suppliers operators manufacturers borne mind different requirements different sets rules might apply individual components respect data quality freedom software algorithm formulated programming language formal language rather natural language executable automated form computer program software functioning software depends data processes also context executed concepts technology stack contains hardware software components used execution parameterisation parameters method configuring software make possible pass information software ranging simple data display options path names complex models extensive parameterisation options generally hand hand flexible software use complex development process making parameters important example software parameterised adapted different contexts relatively small amount effort without modifying source text actual implementation special variants adaptive systems time automatically adapt context individual using systems environment used order guarantee improve efficiency software development processes spite increasingly complex framework conditions order reduce communication problems processes development approaches pursued successfully many years generic software component parameterised basis complex model using language specific application context mathematical statistical models represent special case differ languages model explicitly specified programmed instead mathematical statistical model implicitly taught trained using data see section machine learning system elements hardware software executed hardware particular processors recent years processors seen steady gains performance devices seen continual reductions size meaning array potential applications become ever wider moore law according performance increase hundredfold every years subject physical constraints however chip components become small barely bigger individual atoms fulfilling moore predictions using silicon transistor material becomes increasingly costly technically challenging task researchers therefore currently investigating alternative materials graphene conjunction new computing concepts photonic quantum computing question whether suitable everyday use remains open however solutions focusing parallel computing established include processors use graphics processing units gpus order accelerate machine learning using bulk data chips tensor processing units tpus optimised handle highly parallel addition multiplication matrices neural networks developed increasingly parallel nature computing without problems however humans find difficult identify related processor errors calculations performed hardware level almost impossible reproduce system architecture applications today rarely run single computer instead many different software components run different computers interact perform task term distributed system used refer method distributing work across different hardware nodes distributed system made different software hardware components interact within network network nodes communicate wired wireless links wide range protocols standards exist network communication used basis processing data network nodes forwarding data network transporting nodes specifications outlining requests submitted server published application programming interface api example general rule steps must taken prevent interfaces used incorrectly accessed attackers infrastructures reached via internet referred cloud cloud applications accessed billions users groups related cloud applications often referred digital platforms many big four gafa google apple facebook amazon gafam microsoft also included high level name recognition part technical foundations hub smart lighting hub heating control router hub hub components controller smart home gateway internet network communication wireless early days internet things data sent directly cloud processed large digital platforms way contrast increasing number solutions currently developed involve processing least data immediately close possible place collected words edge internet practice processing data near collected referred edge computing distinguish situations data processed cloud cloud computing data particularly important since allows minimisation communication effort also creation systems since references individuals required removed point close data collected complex system landscape emerged recent years incorporating internet edge computing iot entails high level interconnection making hard distinguish individual systems one way architecture distributed systems designed also significant impact business processes supported system since acts factor decisions technology used network nodes software runs interfaces protocols used communications parties involved communications example manufacturers want use hardware data collected devices purpose efforts improve devices choice setting communication infrastructure making use user infrastructure available asking user make data available via interface way data kind handled cooperative processes transparent agreed contractually necessary technical parameters may place constraints contractual provisions governing exchange data figure example system architecture smart home system elements way architecture distributed systems designed also significant impact business processes supported system since acts factor decisions technology used network nodes software runs interfaces protocols used communications parties involved communications example manufacturers want use hardware data collected devices purpose efforts improve devices choice setting communication infrastructure making use user infrastructure available asking user make data available via interface way data kind handled cooperative processes transparent agreed contractually necessary technical parameters may place constraints contractual provisions governing exchange data figure example system architecture smart homehub smart lighting hub heating control router hub hub components controller smart home gateway internet network communication wireless wired blockchain distributed ledger technologies significant improvements field distributed systems made possible use distributed ledger technologies dlt technologies involve management multiple identical copies ledger different partners instead centralised management single ledger new ledger entries added copies current accuracy database confirmed consensus underlying architecture systems kind varies linear approaches wide range graphbased solutions depending intended purpose structure transactions consensus also achieved using different methods methods outlined consensus famous examples dlt architecture blockchain concept implementations include bitcoin ethereum blockchains used store data list records blocks blocks linked using cryptography meaning transaction stored block implicitly confirms accuracy previous transactions entire chain making extremely difficult fraudsters manipulate data modifying deleting entries use decentralised consensus protocol eliminates need additional instance confirms integrity transactions part governance complex data ecosystems part ulti governance comple data ecos ystems high level complexity dynamism data ecosystems means new challenges must overcome terms regulating controlling designing systems ethical legal framework upon data ethics commission based work implemented practice require cooperation different stakeholders interaction different governance instruments many different regulatory levels governance part examines relevant governance instruments stakeholders details provided following two parts data algorithmic systems particular regarding interplay different instruments stakeholders general role state general role state entitled exercise ethically justified rights obliged comply corresponding obligations citizens companies government agencies must actually able practice presents state wide range tasks first foremost state responsible establishing legal framework within data society geared towards public interest develop speed algorithmic systems developing infiltrating ever areas life poses major challenges legislature courts hand rulings clarifying legislative provisions state must ensure regulations adopted environment kind sufficiently steer developments time flexible enough continue fulfilling purpose even technological parameters change statutory provisions must therefore formulated manner innovative regulatory models must developed addition appropriate infrastructural technological prerequisites must place enabling technologies institutions intermediaries complemented involvement broad gamut civil society actors data ethics commission believes state must play key role guaranteeing safeguarding services general interest new opportunities opened data society also impose educational remit state necessary identify skills required take creative yet reflective approach use digital technologies determine framework conditions must put place appropriate training offered diverse range target groups state educational remit understood broad sense incorporate public outreach work aim raising awareness state also generally responsible encouraging research development particularly important support regard ethically sound technologies uphold principles accountability transparency antidiscrimination extensive research development programmes needed ensure ethical legal principles taken account funding must channelled towards programmes funding needs provided state institutions closely aligned state state must put place framework legal otherwise data society individuals businesses alike operate fashion basis ethical values principles individuals businesses provided adequate protection potential data algorithmic systems harnessed shape worthwhile future germany efforts direction ethically sound governance also include active contributions debates european international level global dimension technological developments means action single nation state regulations adopted national level alone inadequate data ethics commission therefore welcomes european international initiatives already launched european commission oecd example view ensuring future shaped basis ethical principles safeguarding digital sovereignty germany europe international context vitally important task regard see part details part ulti governance comple data ecos ystems corporate corporate digital responsibility responsibility mitigating risks digitalisation leveraging significant potential placed solely feet state legislators responsibility also shared parties develop disseminate use technologies even absence legal obligation although state must shoulder responsibility least obliged protect citizens guaranteeing confidentiality integrity systems safeguarding fundamental rights tools also vitally important particularly context digital transformation process term corporate digital responsibility cdr used theoretical practical level refer idea companies manufacturers operators digital technologies assume responsibility consequences digitalisation like corporate social responsibility csr cdr falls broader umbrella corporate responsibility case focus voluntary corporate activities digital sphere beyond currently prescribed law actively shape digital world benefit society general customers employees particular aim october federal ministry justice consumer protection launched initiative clarify principles concepts corporate digital responsibility according initiative cdr encompass many including protection personal data inclusion digital sphere transparency relation algorithms data protection development digital innovations help achieve sustainability objectives algorithmic use geared public interest open data information security corporate digital responsibility initiative shaping digitalization process responsibly joint platform available responsible development digital products services must central priority corporate decisions taken levels company ethical questions must matter legal departments compliance officers alone instead must viewed task integrated processes parties involved must aware responsibility consider ethical values participation fairness equal treatment selfdetermination transparency negative social societal impacts digitalisation digital business models employees suppliers clients society whole wider environment thus minimised new opportunities digitalisation offers achievement macrosocial goals leveraged applied correctly concept cdr lead improvements terms consumer protection digital participation sustainable development digital economy cdr fundamentally similar corporate social responsibility csr requires companies take action voluntary basis internal strategies codes values therefore particularly effective way implementing cdr respect data ethics commission welcomes proliferation professional ethical standards codes conduct published associations companies industry proviso standards codes must help clarify exactly needs done cdr must reduced metaphorical fig leaf allows companies pretend upholding principles digital ethics truth different corporate self corporate digital responsibilit data ethics commission view data protection impact assessment must relevant circumstances carried pursuant gdpr digital product still development stage accompanied comprehensive general societal impact assessment focused assumption foresighted responsibility including impact employees customers company particularly affected digital transformation process also takes account social effects business models might good idea companies commanding large market share set advisory panel along lines consumer customer advisory panels could consulted drawing impact assessments kind panel made representatives groups people affected relevant business model part ulti governance comple data ecos ystems education boosting digital skills critical reflection digital presupposes digital skills data ethics commission therefore unreservedly welcomes efforts undertaken federal government consumer protection associations legal professional groups bodies raise public awareness importance selfdetermined use data digital technologies smartphone settings digital inheritance planning provide straightforward information available options well practical guidance also welcomes steps taken raise awareness among consumers potential inherent data provide muchneeded information rights real opportunities risks involved economic exploitation data data ethics commission recommends efforts continued stepped school pupils also made aware issues connected digitalisation early possible digital skills integrated curriculum teachers must provided comprehensive training subject regular intervals way ensure new generations grow become competent digital natives able assess opportunities risks new digital applications take informed decisions assert rights effectively addition lifelong education use data digital technologies must provided age groups social groups must borne mind digital skills require basic knowledge underlying technology turn requires ongoing education technical mathematical subjects also adequate familiarity economic legal ethical social sciences broad spectrum knowledge necessary comprehend discuss assess various opportunities risks complexity education training computer science data science software development particular relevance respect well basic instruction ethical legal issues teaching statistics methodology scientific theory needed particularly important ensure questions relating data ethics research ethics embedded methodological training must major push area ensure ethical legal considerations incorporated earlystage discussions parties develop digital products services involved decisions development essential first step towards achievement goals cooperation many different entities possible including government agencies bodies closely aligned state private actors federal state bundesland municipal levels challenges involved providing general public digital skills maintaining skills long term adapting individual lived experience great could never tackled successfully single centralised body said key role must played supervisory authorities data protection authorities relevant specialist supervisory authorities foundation data protection consumer protection associations training providers media institutions involved media regulation also large part play connection must provide society information new technologies cast critical eye technical progress also establish new forums debate although government agencies must remain chiefly responsible imparting digital skills general public task realised full unless necessary civil society structures put place digital volunteering tech accountability journalism market observation data ethics commission therefore recommends federal government provide support establishment structures kind education boosting digital skills critical reflection companies also responsibility provide training staff example company attain high ethical standards employees particularly management product development adequate awareness potential ethical legal issues far education training concerned questions relating data ethics data law also included broad spectrum academic professional training routes workplace training particular attention given technical business professions view ensuring ethical legal considerations incorporated earlystage discussions parties develop digital products services involved decisions development part ulti governance comple data ecos ystems technological developments ethical design efforts impart advanced digital skills general population must end shifting weight responsibility away manufacturers digital service providers towards users least users limited opportunities grasp comprehend steps involved processing data underlying business models responsibility laid first foremost feet able exert influence development products services concept embodied principle ethics design ethics design appears gdpr reference data protection intrusions private sphere heading data protection design default aligning development technologies products including services applications ethical values principles outlined also good way increasing public confidence digital products acceptance products time however design every product must tailored target user groups involving user groups needs early stage product development participatory product development may helpful respect particularly important products targeted vulnerable less digitally literate user groups inclusive design including default settings view protecting digital user groups inclusive design allows manufacturers operators meet constitutional requirement informational enshrined article paragraph german basic law human dignity according protection must contingent upon individual capabilities personal popular methods platforms used develop technologies commonly used libraries code components rarely supported requirements ethics design date components better design perspective ethics data protection law best niche interest need change area compliance ethical principles general data protection principles particular becomes rule rather continuing exception ethics design requires gap different communities bridged certain implications professions affected goals approach could furthered information methods catalogues also concepts supporting tools development frameworks code components platforms repositories components usable pools data cases necessary prerequisite checks would make possible highlight specific properties required supply documentation needed provide opportunities exchanging experience although ethics design crucial governance instrument allows process designing products processes services aligned individual public interests outset provides guarantee resulting products services ethical ethical principles positive influence technological developments ethics task delegated technology furthermore decisions ethical principles implemented implemented example whether fairness metrics applied algorithmic systems metrics left developers alone instead decisions negotiated basis necessary involvement parties affected research research although systems ethical design frequently developed showcased researchers gulf world research real world one reasons may fact technical solutions example based cryptographic mechanisms counterintuitive nature difficult many people understand conventional methods prime example digital identification document changes appearance every time shown making impossible join dots holder observed behaviours many people attempt understand innovative technologies drawing conceptual models surrounding analogue world latter provide insufficient basis comprehending appraising added value despite advantages offered technologies terms ethics data protection law unlikely use become widespread public gains better understanding confident use many cases therefore interdisciplinary cooperation essential starting point understanding implications new developments designing ethical systems cooperation kind adequately rewarded metrics good science research many areas interdisciplinary research given due recognition shift mindset occurs applies universities peer reviews expert opinions example research funding funnelled towards interdisciplinary cooperation delivers results would impossible achieve within silos individual disciplines allow necessary institutional frameworks career paths many cases promising technical solutions already emerged research sector demand solutions currently still lacking also need methodologies technologies signpost route current implementation status improved state technology funding channelled development innovation improved solutions move drawing board reality instead providing support outstanding success stories need progress field ethical design must acknowledged part ulti governance comple data ecos ystems standardisation latest lawrence lessig coined aphorism code law thereby emphasising relevance technical reality obvious technical standardisation essential factor implementation legal ethical requirements bodies responsible technical standardisation communications networks established international level ieee ietf itu etsi european level cen national level din prime example germany alongside specific standards public bodies technical standard legal force anyone uses technical system must also comply applicable legislation even provisions legislation run counter requirements imposed global technical standard nevertheless standardisation hugely influential terms available market wherever possible therefore steps taken avoid adopting standards infringe current legislation standardisation process often criticised lack democratic legitimacy true groups within society stand affected often deprived opportunity representative participation example organisations civil society representatives seldom involved standardisation process generally speaking even data protection authorities rarely involved standardisation technical systems scenario may mean operation technical system complies standards violates legislation another point criticism number international standards manufacturers operators supposed comply available free charge public domain must instead purchased lawrence lessig code laws cyberspace standardisation efforts field information security served major contributing factor addition extra security features gradual improvements level security example online banking yet snowden revelations made clear number intelligence services government agencies deliberately attempting weaken standards including security loopholes backdoors way safeguarding access future role technical standardisation expected gain importance coming years example result requirement take due regard technology consequence german security act political influence exerted number different countries europe also expected increase impact assessment standards currently existence still debated must beyond purely technical economic considerations expanded include ethical societal factors state ensure civil society actors data protection authorities consumer protection experts spokespersons organisations representing parties affected play role standardisation process alongside stakeholders dominated date data rights data obligationsstandards algorithmic systems two governance perspectives data perspective algorithms perspective governance perspectives data perspective algorithms perspective following two parts arguments set applied algorithmic systems basis two different complementary approaches general ethical principles precepts used basis data ethics commission see part important two respects firstly must guide data governance measures particular view ensuring procedures collecting accessing using data ethically sound secondly must guide design systems used process data including artificial intelligence systems perspective focuses primarily data data perspective perspective concentrates mainly algorithmic systems algorithms perspective regarded competing views two sides coin instead represent two different ethical discourses complement contingent upon different ethical discourses typically also reflected different governance instruments including different acts legislation data perspective focuses data used train algorithmic systems basis algorithmically shaped decisions plethora purposes specifically associated context meaning semantics data part section particular requires thinking origin data potential impact processing may individuals involved context semantic content data ethical legal perspective important identify standards data governance typically however rights individuals assert others play even significant role central distinction context personal data since determines whether rights granted data subjects data protection law apply current debates pertinent connection include data ownership rights open data data perspective algorithms perspective way contrast algorithms perspective focuses architecture algorithmic systems dynamics systems impacts individuals society ethical legal discourse area typically centres around relationship humans machines particular focus automation outsourcing increasingly complex operational processes autonomous systems enabled artificial intelligence algorithms perspective differs data perspective data subjects affected system may necessarily anything original training processing data even focus attention focus objective requirements apply observance may enforced failure comply may lead liability sanctions current debate algorithmic oversight relevant important respect part data part ata data provide access information information lead knowledge knowledge bestows influence power light new capabilities automated data processing exponential increase memory computing capacity access data mean enormous increase power opportunities controlling important resources inherently associated certain level responsibility thus data like resources may used lawful ethically acceptable purposes like resources impact use individuals general public whole must always assessed yet data also exhibit certain characteristics differentiate following sections data ethics commission therefore take specific characteristics data starting point develop basis principles outlined part without claiming exhaustive general standards data governance section well data rights corresponding data obligations section set specific recommendations action relation standards use personal data section improvements controlled access personal data section general access data particular data section general standards data governance general standards data governance attempt identify specific principles data governance must start differences data traditional resources oil goods unique characteristics data include particular following created processed distributed dynamic process interaction number different players acting different roles data subject operator generating system developer process principle never fully complete resource duplicated often necessary used parallel multiple different players multiple different purposes multifunctional used across different sectors potential risks inherent depend exceptionally large extent data controller specific goals opportunities particular given importance effects scale ability combine foresighted responsibility special characteristics data unusually dynamic nature unusually high context dependence opportunities risks associated mean particular need foresighted responsibility making decisions collecting using forwarding data assessing potential impacts including risk infringing rights third parties particular consideration given following points volume emerging collections data particular focus cumulative effects network effects effects scale technological means processing data particular focus technological options available large corporations government bodies especially relation recombination decryption data purposes data processing particular focus potential changes context data use players involved result access government agencies following corporate takeover case personal data principle foresighted responsibility found standardised expression maxims data minimisation storage limitation enshrined gdpr range duties gdpr need carry data protection impact assessment mandatory requirements contracts likewise follow principle part ata respect rights parties involved use data must always underpinned respect rights others acts omissions ethically unacceptable unlawful general terms violate rights others become acceptable lawful simply committed way using data fraud criminal offence regardless whether committed use data otherwise data generated distributed processes interaction many different players parties way involved process data generation example data subject owner device may ethical possibly also legal perspective entitled genuinely rights data rights relation data details see section data rights must respected whenever data used respect rights others implies much simply avoiding intrusion legally protected spheres another party copyright needed instead ethical perspective consideration legitimate interests parties specifically linked data may therefore certain rights participation concerning data consideration may also imply duties take action example granting another party access data certain ways case personal data principle respect data rights expressed particularly clearly principles lawfulness fairness purpose limitation enshrined gdpr gdpr sets number data rights vested data subject right informed right rectification right restriction processing right erasure right data data use data sharing public good resources could used key legally protected interests individuals health promote public good particularly pursuit sustainable development goals relating economic social ecological aspects neglected basic principle ethical imperative use resources cases would increase overall prosperity overriding conflicting interests parties particularly data rights one special features make data unique resource wear even used parallel many different players many different purposes duplicated almost infinite number times sharing data mean player first shares data least worse everyone else involved however loosely better would data shared ethically responsible approach data governance must take fact account data sharing also enormously important terms safeguarding fair efficient competition time however conflicts sometimes arise principle furthering public good data use data sharing one hand principles foresighted responsibility respect parties data rights including considerations appropriate investment protection creation incentives voluntary data sharing therefore always prioritised legislative requirements share data exception general standards data governance data quality data together context semantics stored information information regularly purports accurate possible representation reality currently stands accurate possible prediction future reality situations involve automated processing data algorithmic systems immediately obvious everyone incorrect information worthless also potentially harmful soon automation comes play however common people fall prey false objectivity show foolhardy willingness rely results calculations carried using incorrect incomplete data therefore also likely share characteristics garbage garbage interests everyone therefore responsible data governance data society must also include efforts achieve standard quality appropriate intended purpose part section meaning appropriate must always determined specific basis used relation data quality however example important remember data may reflect societal preconceptions stereotypes discrimination turn influence functioning algorithmic system trained using data details see part section data accurately reflect existing deficit may therefore unsuitable use basis purposes even high statistical quality another important factor connection data used across different sectors different purposes fair principle findable accessible interoperable reusable may relevant context example regards data storage encoding methods according principle data must prepared stored way findable accessible must coded interoperable format way makes data reusable different contexts many different players possible case personal data desire achieve high level data quality manifested principle accuracy enshrined gdpr level information security data freely duplicated almost impossible recover gone astray wide range possibilities external attack many invisible outside mean data also vulnerable malicious attempts falsify destroy high level information security commensurate relevant risk potential therefore technical perspective directly related principles foresighted responsibility respect rights parties involved appropriate information security encompassing broad spectrum measures different levels vital prerequisite mutual trust part involved data society case personal data concept information security manifested principle integrity confidentiality enshrined gdpr transparency since party uses effectively controls data may gain influence power result party must principle able willing account actions one reasons protection parties whose data rights might affected even violated level transparency required parties entities enforcing data rights data law benefit others determine whether extent data rights fact affected violated lodge claims case personal data transparency ensuring data processing operations easy data subjects understand basic principle gdpr also true principle accountability many provisions gdpr example relating information documentation right request access designed improve transparency foresighted responsibility respect rights parties involved data quality riskadequate level information transparencydata use data sharing public part data figure standards data governance data rights corresponding obligations data rights corresponding obligations according ethical principle digital selfdetermination individuals merely perceived passive need protection facing actual potential threats rather actors data society navigation data society individuals requires individuals certain rights asserted others first foremost among rights relate individual personal data derive right informational enshrined fundamental freedom guaranteed data protection law currently force digital also encompasses economic exploitation one data handling data example data generated operation one devices data ethics commission takes view principle right digital also applies companies legal entities least extent groups persons collectives context data ethics commission believes possible identify general principles underpinning data rights obligations beyond data protection general principles data rights obligations complex data generation processes understood broader sense including various phases data creation enhancement refinement often involve interactions different parties may pursuing different goals playing different roles contribute respective roles generation data process contribution party natural legal person generation data may relevant following true information stored data relates terms meaning party object associated party belonging model data rights data obligations based preliminary drafts february october principles data economy european law institute eli american law institute ali made available data ethics commission preliminary drafts yet adopted either ali eli yet represent official position either data generated activity party operation object sensor belongs party data generated software another component sensors created invested party situation referred situation party subject information stored data relates natural persons particular significance since situation gives rise right informational data protection enshrined constitutional law given specific characteristics data inextricable link personal data personality rights data ethics commission believes contribution generation data give rise exclusive ownership rights said data beyond existing intellectual property rights see sections instead contribution generation data entitle party specific data rights form participation rights rights turn impose obligations actors ethical perspective result dynamic special relationship party involved generation data party controlling data duration relationship may vary may intensity far personal data concerned relationship largely determined applicable data protection law ethical perspective recognition design data rights corresponding data obligations dynamic environments depend following general factors normally also factors underlying relevant legal provisions data rights obligations already substantiated law scope nature contribution data generation party asserting data right balance power partiesweight interest granted data rightcontribution data generation weight conflicting interests part others interests general publicdata rights data part data weight party legitimate interest granted said right particular right require desistance access rectification economic share weight possibly conflicting interests part party third parties taking account potential compensation arrangements protective measures remuneration interests general public balance power party asserting data right factors interact one another described flexible system public interest data access particularly high example may compensate relatively insignificant contribution data generation consideration must always given general principles outlined part order avoid situations crucially important individual interests undermined purported actual public interest factors also determine certain details formats deadlines protective measures financial compensation fleshed put practice includes question whether action taken upon request party asserting data right data access claim also proactively obligation publish data figure general factors shaping data rights corresponding data obligations data rights corresponding obligations rights granted data subjects gdpr particularly important manifestation principles aimed specifically protecting natural persons information pertains also extent standardised manifestation given hinge qualification data personal data principles formulated also applied data however relate individuals also legal entities collectives clarification general principles reference typical scenarios data rights may number different goals include obliging another party desist using data requiring erasure data gaining access data disclosure transfer full portability arranging data rectified claiming economic share profits derived help data article article scenarios involving desistance use situations often occur party requests another party desist using data certain way gdpr even works basic assumption personal data used unless legal basis number requirements general sense beyond scope gdpr party significant legitimate interest controller desisting data use outcome ethical perspective may right require said desistance potentially even including right erasure data data processing operation might cause harm party third party inconsistent circumstances party contributed generation data particular contribution made another purpose party could reasonably expected contribute generation data foreseen present data processing operation consent party would invalid overriding reasons right require desistance use affirmed however party legitimate interest granted right must weighed factors referred section example right affirmed cases processing data way exception justified compelling interests prosecution criminal offences part ata regard data requests desist use data may become relevant example context value creation chains customer relationships data often enormous economic significance party involved may significant legitimate interest assert right section example data collected sensors modern agricultural machinery relating soil quality weather etc used manufacturers basis many services provide precision farming predictive maintenance manufacturers forward data potential investors lessors land however latter would given information might prove harmful agricultural holding negotiations land take place future assumed agricultural holding would helped generate data voluntarily known would used purpose assessing right require desistance ethical perspective consideration must given balance power parties case hand also fact agricultural holding made extremely significant contribution generation data rights deemed worthy protection would include manufacturer interest maximising profit general interest part investors lessors etc obtaining accurate ethical perspective waiver data right require desistance possible limited circumstances waiver automatically ruled cases consent data use would invalid overriding reasons within meaning requirement example illegal inconsistent public policy legal system fundamental values underpinning exists thing liberty kind harm oneself others cases waiver may possible provided stringent requirements met separate agreement linked services involve party placed pressure ensure voluntary nature waiver meaning requirement would longer apply example agricultural holding could consent data forwarded third parties basis individual agreement appropriate remuneration use tractor dependent data forwarded data rights corresponding obligations personal data obligations desist data use normally follow already provisions data protec tion law criteria outlined used determine whether substantive limits consent exceeded section guide balancing different legitimate interests example example data relating activities social network user used extensive personality profiling profile contains attributes mentally unstable esoteric tendencies result user shown advertisements companies offer personal horoscopes energy healing services significant cost almost daily basis often immediately posted content signals stress anxiety often makes purchases result set user account clicked checkbox next following statement happy data evaluated personal preferences attributes identified accurately services offered including providers personalised needs profiling consent kind make subsequent data processing operations lawful number different arguments reaching conclusion one processing data purpose may cause significant harm user would inconsistent circumstances generated data could reasonably expected known data would used purpose law allow abuse mental states kind section german civil code b√ºrgerliches gesetzbuch bgb many circumstances obligation desist use data mitigated consent balancing conflicting interests cases reference often made red lines absolute limits requirement limits example reasonable prohibit election manipulation practices incompatible principle democracy regardless whether said practices involve use data view data ethics commission example absolute limits total surveillance individuals example entering employment contract employee signs agreement stating location tracking functions smartwatch mobile telephone well number apps collect data tracking sleeping behaviours emotions kept switched times even work hand devices employer requested order relevant data accessed readily apparent arrangements taken together equivalent total almost total surveillance incompatible human dignity privacy true even employee gave consent measures even decided accord enter contract employer even offers employment available part ata conversely criteria apply scenarios involving desistance use may also bear indirect relevance situations ethical even legal obligation use data obligation may arise party general obligation protect certain legally protected interests time access data could used secure improve protection interests kind situation obligation use data arises corollary obligation protect certain legally protected interests unless third party conflicting right require desistance data use example hospital experiencing outbreak resistant pathogen wants analyse health data patients recently become infected order gain better idea certain individuals likely fall prey pathogen basis pinpointing inpatients might benefit move another hospital circumstances hospital general obligation provide new patients best possible protection infection taking available reasonable precautions end includes use health data belonging patients already infected pathogen provided said use might protect new patients obligation emanating former group patients desist use data way examples european commission building european data economy com final january seqq available european commission towards common european data space com final april seqq available scenarios involving access data comes scenarios involving request access data many situations party seeking access data party effectively controls data able reach agreement action taken voluntary arrangements kind welcomed provided conflicting overriding public interests particular provided parties right require desistance use based criteria given enormous potential value creation inherent data however discussions also held circumstances conditions access data even must granted ethical may apply situations access data required perhaps even mandated law order enable party comply special obligation task prosecution criminal offence public health concern data access right must consistent rules apply obligation task particular attention paid principle proportionality potential rights require desistance use see section must considered may also independent requests access data example within existing value creation systems systems typically involve many different parties contribute generation data different roles suppliers manufacturers retailers end users principle familiar agreed roles roles players involved see section details legitimate interests asserted party basis access request may particular include cases data required following purposes data rights corresponding obligations use asset line intended purpose within value creation system repair connected device end user monitoring improving quality service provided within framework value creation system supplier ascertain truth provide evidence legal dispute third parties avoid effects effects create new value using data developing smart service example supplier provides engines agricultural machinery referred example would extremely useful supplier access certain tractor data verify constantly improve quality engines data stored manufacturer cloud however latter unwilling allow supplier access situations kind important remember supplier made significant contribution generation engine data data urgently needed improve quality service provided within framework value creation system manufacturer also involved consideration must given balance power specific case hand also fact parties involved including general public interest engines may however also relevant economic interests manufacturer side particular relating rights also discussed situations party seeking access party effectively controls data yet part value creation system new value creation system could originate involved outcome assessment based general criteria normally different situations kind party seeking access typically contributed generation data justifications cited granting access right rather public interest considerations specific considerations safeguarding competition see section details example example manufacturer holds dominant position tractor market collecting soil weather data decades recognises potential database investors using data requests access case consideration must given fact made contribution generation data existence public interest data access significance interest depends whether manufacturer abusing market power much european economy would benefit breaking small group dominant companies presuming based europe case potential harmful effects data disclosure trade secrets legitimate interests interests manufacturer agricultural holdings example must taken account part ata generally recognised principles open government data ogd embody idea government data made available private sector include open default data anyone purpose calls many quarters expand open data concepts include data created effectively controlled private entities move towards open data however also gives rise complex ethical questions example extent generalised assessment longer looks individual case acceptable example municipality implements project collect mobility data using smartphone signals view facilitating traffic management adjusting timing public transport services example theoretically speaking data anonymised data sets combined data sets additional knowledge however owner identified confidence level number different parties interested gaining access data include researcher wants use basis identifying optimal design urban recreational areas wants establish online detective agency via users pay access mobility profile spouse competitor etc research institute tasked foreign government investigating political activities citizens assessments three access requests would deliver different outcomes therefore difficult question whether municipality may even must make data public view many possible uses data would promote public good see recital directive open data public sector information psi directive principles open data charter signed summit june principle international open data charter signed september open government partnership data ethics commission wishes emphasise context importance potential rights individual parties contributed data generation particular rights data subjects require desistance data use follows possible reasonable protective measures including anonymisation techniques improved ongoing basis taken weighing potential harm expected benefit public good also depending potential harm granting blanket access may question see section details scenarios involving rectification data high quality problems particularly likely arise include unsuitable context inaccurate encoding incomplete data sense deductions obtained using data also incorrect circumstances kind party involved generation data may ethically justified right quire rectification underlying data deductions obtained using data threshold right kind granted relatively low since principle neither protected individual interest public interest processing inaccurate incomplete data general rule following requirements must met processing inaccurate incomplete data must potentially harmful party particular party information relates rectification must disproportionate taking account severity likelihood harm one hand effort involved rectifying data data rights corresponding obligations example high error rate detected engine data stored manufacturer example problematic company supplies engines deprives company possibility fulfil quality assurance remit also data pooled data engine suppliers basis evaluations poor performance metrics engines relevant supplier might reduce latter chances securing orders manufacturers case processing inaccurate data causes harm supplier indications effort involved rectification would disproportionate amount effort involved rectifying data excessive potential harm significant right require desistance use frequently arise see section scenarios involving economic share cases party uses data create value parties contributed generation said data everyday occurrence good thing principle provided one entitled right require desistance use see section use data must normally tolerated parties contributed generation given strong affinity data rights obligations set section considerations public good potent arguments recognising general right remuneration parties contributed generation data instead parties must content existing mechanisms collective economic participation particular taxation value cases valid contract back claim remuneration financial compensation considered mitigating measure example exercising data right without compensation appears disproportionate specific case hand see section factor ethical perspective view data ethics commission party contributed generation data entitled independent remuneration use others exceptional cases cases kind might arise party contribution generation data required unusual amount effort particularly unique would hardly possible economic viewpoint replace contributions players exceptionally large amount value created using data circumstances contribution data generation made mean would impossible unreasonable party engage negotiations remuneration amount remuneration paid exceptional cases must adequate particular basic incentives using data create value must removed must also remembered party creating value typically incurred financial risks collective aspects data rights data obligations answer must found issue whether extent arguments concerning right require desistance use right access data right rectification right economic share profits derived help data also applied collectives sense defined groups persons indigenous peoples regard use genetic data whether collectives may entitled certain data rights connection use data example part ata thought must given question whether ethically speaking population nation state generated data right economic share profits form taxes transfer payments data ethics commission believes question principle answered affirmative example internet giant earns billions data generated individuals around world use services yet even though megalith company generates sums year year using data individuals pays virtually taxes question arises whether company obliged ethical grounds allow general public share taxation value creates issue raises fundamental questions distributive participatory justice economic system looks like however aspects market power unique nature contributions audio data certain language used develop new services may also taken account relational nature many data types makes particularly important include groups collectives debate relational nature apparent way many digital services require users disclose data contacts friends example far data rights corresponding obligations concerned friends may right require desistance use data right gain access data etc time potential interests must always taken account weighing whether data right granted see section however also cases party contributes generation data data indirectly provide information parties even latter played role even broadest sense word generation particularly relevant sphere genetic data also applies data types still another closely related group cases individualised data even aggregated form may implications potentially negative effects extend beyond individual supplied data example health insurance company offers reduced premiums incentive sign health tracking schemes agree disclose data benefit lower premiums refuse may end paying issues relating representativeness data used train algorithmic systems also interpreted problems relationality lack relationship parties supply training data parties trained systems applied may result systematic bias potential discrimination see part section details overcome hurdle individualistic approaches data rights ethics law technology design must expanded include relational concepts data rights also debate group privacy certain circumstances may therefore possible least viewed lens ethics one group member contribution data generation attributed group members well potentially entitling latter spite fact made individual contribution certain rights right request desistance use right gain access example standards use personal data standards use personal data personal data data relating legal entities information relating identified identifiable natural person regarded personal data identifiable natural person one identified directly indirectly particular reference identifier name identification number location data online identifier one factors specific physical physiological genetic mental economic cultural social identify natural person article gdpr even though remainder section focuses personal data legal sense term data ethics commission wishes stress protection companies legal entities valid concern relegated completely sidelines potential hazards confronting legal entities exacerbated yet networking machines exchange data factory components storage production data generated industry plants digital twins individual sets data generated operation devices example pooled together result may almost seamless overview company internal operating procedures may absence appropriate protective mechanisms easily fall hands wrong parties outside company competitors negotiating partners authorities prospective buyers data ethics commission believes risk posed digital companies legal entities also digital sovereignty germany europe since data flows predominantly involve third countries concerning ethical viewpoint steps must taken mitigate key legislative starting point protecting enterprise data protection trade secrets particular german act protection trade secrets gesetz zum schutz von gesch√§ftsgeheimnissen geschgehg interpreting applying act efforts must made guarantee comprehensive protection sensitive business data given central importance latter building fair competitive economic system basis economic social many respects however directive provisions transposed act protection trade secrets adequately tailored reality iot industry data ethics commission therefore calls federal government step protection german european companies recommendations action relating personal data put forward data ethics commission remainder section example relation riskadequate interpretation applicable legal framework section design products services section also apply protection data relating companies legal entities modified attenuated form appropriate digital challenge tackled legal system whole cooperative relationship applicable legal regimes economy society heavily reliant use personal data huge variety different contexts yet always degree tension use personal data fundamental rights individuals constitutional right informational part general right personality essentially part protection human dignity data protection law particular gdpr clarifies benchmarks binding force public private bodies part ata gdpr one great achievements legislator currently functions source inspiration countries important temper expectations piece legislation however gdpr focused data protection rather comprehensive promotion individual welfare public good data economy taken isolation suitable tool averting harm individual may suffer result personal data processed therefore regarded protecting integrity respects different mechanisms provided legal system whole must used safeguard legally protected interests particularly specifically addressed provisions data protection law economic interests right life health physical integrity reputation applies even situations personal data play concept consent enshrined data protection law vitally important mechanism safeguarding informational digital analogue spheres yet concept right subject substantive limitations includes freedom inflict kind harm oneself third parties would alien element legal system ethically indefensible law limit even prohibit individual free informed consent expression general freedom action protected fundamental right narrowly defined exceptional circumstances however consent data protection law subject substantive limitations way analogy limitations freedom contract consent comes intrusions bodily integrity view data ethics commission become clear average individual systematically overwhelmed number complexity decisions required take connection consent data protection law also recital gdpr relates particular fairness test applied general terms conditions business sections seqq german civil code b√ºrgerliches gesetzbuch bgb principles public morals section civil code wilful immoral damage section civil code contractual protection fiduciary duties section paragraph civil code involved estimating potential impacts data processing data ethics commission believes inadequate use consent providers digital services one several reasons general loss trust digital society things stand individuals often longer rely fact state legal system put place framework conditions necessary navigate world safety relatively speaking free care without needing worry possibility suffering serious harm parties transactions contract law specifically unfair contract terms control provided basis rational indifference part consumers protection even cases result achieved way applying fairness test declarations consent applying fairness test general values principles underlying legal system whole must taken account interpretation applicable legal framework data ethics commission wishes stress existing legal framework must interpreted applied way mitigate maximum new hazards facing connection widespread collection use analysis personal data notwithstanding need comply requirements data protection law data processing operations also subject number absolute limits wherever possible uses data beyond limits prevented interpreting applying law manner consistent fundamental rights view data ethics commission relevant example standards use personal data personal privacy integrity incompatible fundamental rights result profiling scoring certain methods determining personality traits emotions expected behaviours surveillance incompatible human dignity inter alia comprehensive surveillance footprint super scoring exploitation situations urgent need medical conditions manipulation practices run counter principle democracy legislation currently force already categorises ethically reprehensible attempts mislead manipulate consumers commercial context include business practices aimed persuading party disclose personal data misleading aggressive commercial practices german unfair competition act gesetz gegen den unlauteren wettbewerb uwg regardless whether provisions data protection law infringed attempts therefore trigger appropriate legal consequences rescission grounds fraud threat injunctive relief compensation data ethics commission wishes cite following potential examples practices designs technologies exert undue influence user particular means mechanisms promote addictive behaviour therefore liable substantially adverse impact freedom decide whether use stop using patterns technologies mainly user interfaces designed way deceive user certain facts manipulate taking certain decision may financial implications instruments referred footnote limits must also imposed data processing order protect individuals placed undue financial disadvantage existing legislation contains various provisions used enforce view data ethics commission examples unfair contract terms violations contractual duties fiduciary nature include following access data generated device required normal use said device including performance repairs independent workshop making unreasonably difficult access data access granted accordance article gdpr within one month even three months access data needed operate networked device making unreasonably difficult access data individual bought house equipped smart home technology harder individuals switch provider means data refusing hand data analyses user already paid economic perspective protected trade secrets user generated data manufacturer another member supply chain purpose runs completely counter user economic interests price differentiation aim extracting maximum individual willing pay part ata need clarify tighten applicable legal framework things currently stand level protection legally protected interests line constitutional requirements achieved many questions arising digital society interpretation general legal concepts blanket clauses supervisory authorities courts data ethics commission believes situation untenable general legal concepts blanket clauses offer advantage flexible keeping future options open yet authorities courts often take years even decades develop established case law new phenomena digital phenomena particular meantime results structural enforcement gap regard law force lack legal social media monitoring social media monitoring systematic oversight social media content particular topic evolved data utilisation tool takes advantage fact social networks expand users communication options also allow digital behaviour constantly monitored companies frequently deploy data generated social network users purpose market research marketing although bodies far slower make use opportunities afforded social media monitoring means practice example tax authorities use web crawlers trawl content publicly available internet way pinpointing business sellers paying vat algorithmic systems used make information collated social media monitoring usable exploitable intrusive purposes particular creation personal profiles commercial purposes provided weighing interests pursuant article gdpr supports use exploitation another legal basis processing may entirely consistent law pursuant recital gdpr fact data subject disclosed data justify use exploitation data data ethics commission takes view monitoring activities rate deemed crossed boundary lawful unlawful publicly available information monitored scope monitoring could gauged data subject information disclosed example generally speaking statements made minors without due consideration alternatively information highly sensitive example suicidal ideation statements even applicants job willingly made data public data used recruitment process represent great intrusion personal integrity clearly related applicant job history statements sexual orientation applies systematic evaluation data originating individual private life tracking data particularly modes use exploitation intrusive weighing interests may result limits placed admissibility businesses target advertisements basis sexual orientation exploit individuals known emotionally vulnerable state certain providers particular providers social networking sites technically capable carrying evaluations communications exchanged via central platforms operate even general access content prevented using encryption metadata provide means obtain highly instructive analytical findings legislative ban evaluation communications individuals within closed groups also imposed private providers keeping principle telecommunications secrecy data ethics commission therefore recommends federal government delay efforts secure introduction ban forthcoming negotiations adoption eprivacy regulation standards use personal data need clarify tighten applicable legal framework things currently stand level protection legally protected interests line constitutional requirements achieved many questions arising digital society interpretation general legal concepts blanket clauses supervisory authorities courts data ethics commission believes situation untenable general legal concepts blanket clauses offer advantage flexible keeping future options open yet authorities courts often take years even decades develop established case law new phenomena digital phenomena particular meantime results structural enforcement gap regard law force lack legal certainty given extent issue affects fundamental rights uncertainty whether solutions emerge meet constitutional requirements data ethics commission believes prompt action establish clear binding regulatory framework falls squarely within remit democratically legitimised legislator view hazards posed individuals profiling sometimes resulting scoring data ethics commission believes urgent need take effective action tighten current legal framework particularly critical area order effectively counter risks individuals manipulated suffering discrimination social media monitoring social media monitoring systematic oversight social media content particular topic evolved data utilisation tool takes advantage fact social networks expand users communication options also allow digital behaviour constantly monitored companies frequently deploy data generated social network users purpose market research marketing although bodies far slower make use opportunities afforded social media monitoring means practice example tax authorities use web crawlers trawl content publicly available internet way pinpointing business sellers paying vat algorithmic systems used make information collated social media monitoring usable exploitable intrusive purposes particular creation personal profiles commercial purposes provided weighing interests pursuant article gdpr supports use exploitation another legal basis processing may entirely consistent law pursuant recital gdpr fact data subject disclosed data justify use exploitation data data ethics commission takes view monitoring activities rate deemed crossed boundary lawful unlawful publicly available information monitored scope monitoring could gauged data subject information disclosed example generally speaking statements made minors without due consideration alternatively information highly sensitive example suicidal ideation statements even applicants job willingly made data public data used recruitment process represent great intrusion personal integrity clearly related applicant job history statements sexual orientation applies systematic evaluation data originating individual private life tracking data particularly modes use exploitation intrusive weighing interests may result limits placed admissibility businesses target advertisements basis sexual orientation exploit individuals known emotionally vulnerable state certain providers particular providers social networking sites technically capable carrying evaluations communications exchanged via central platforms operate even general access content prevented using encryption metadata provide means obtain highly instructive analytical findings legislative ban evaluation communications individuals within closed groups also imposed private providers keeping principle telecommunications secrecy data ethics commission therefore recommends federal government delay efforts secure introduction ban forthcoming negotiations adoption eprivacy regulation profiling profiling defined article gdpr form automated processing personal data consisting use personal data evaluate certain personal aspects relating natural person particular analyse predict aspects concerning natural person performance work economic situation health personal preferences interests reliability behaviour location movements profiling ultimately involves making deductions drawing conclusions basis input data particular using certain statistical inference methods part section deductions may relate actual purported properties individual mental stability reliability social acceptability take form predictions relate individual future behaviour particular consumption pattern addition profiling attempts frequently made assign users predefined stereotype category basis observed behaviour interacting digital systems using matching algorithms example someone books holiday might classified sports fan culture enthusiast family man woman keen hiker sales representative gourmet stereotype instantiated individual user used store typical preferences goals personality traits used subsequent algorithmic processing operations sometimes profiles stored instead deductions particular behavioural predictions generated dynamically real time using raw data ready purchase shoes part ata given profiling makes possible personalise wide range digital products services degree many users perceive convenient helpful categorical ban would overshoot mark however data ethics commission recommends federal government speak forthcoming evaluation gdpr example favour expanding gdpr include specific rules profiling beyond existing provisions article gdpr permissibility automated alternatively federal government could lobby separate legislative act would effectively counter risks profiling poses fundamental rights individuals adequately european solution proves unworkable foreseeable future legislative rules put place national level within scope permitted law regulate profiling procedures pose potential risk fundamental rights data ethics commission believes particularly urgent need provisions horizontal sectoral profiling concerning following matters far solutions already follow correct interpretation gdpr imposition absolute limits prohibiting law certain critical applications selecting pool job applicants use profiles generated basis data originating private lives profiling procedures involve highly sensitive personal data example connection emotion detection software biometric data data processing operations entail unacceptable potential harm data subjects society expert group artificial intelligence policy investment recommendations trustworthy june available imposition admissibility requirements critical profiling procedures including quality requirements relation meaningfulness accuracy profiles generated see part section details system latter appropriate level risk low clarification principle proportionality inter alia regards requirements apply nature scope data used profiling permitted level detail conclusions drawn profiling purposes particular purposes profiling may admissibly used imposition specific labelling disclosure information obligations inter alia regards existence purpose algorithmic systems may used carry deductions critical deductions already carried instead providing information automated decisions taken later stage process provision feasible options data subjects exert influence profiles created including option verify also includes right digital new start involving erasure existing profiles upon reaching age majority recently suggested expert voice assistants voice assistants promise great deal terms convenience easier access digital technologies particularly people disabilities yet also harbour risks far data subjects concerned voice assistants record ambient noise often without user activated related function recordings include speech user third parties regarded biometric data purpose gdpr speech recordings analysed real time response given spoken commands automated processes often log certain data types log file unique timbre individual voice speech patterns analysed basis uniquely identifying individual deciphering speech emotions profiling kind represents particularly deep invasive intrusion core area personality rights entails risk exacerbating structural imbalances demand supply side market enormous potential misuse also present given possibility recombining digitally reconstructing spoken word deep fakes reality individual users often vague idea data processing carried indeed whether carried particularly user relatively inexperienced technical matters may easily persuaded disclose additional sensitive personal data upon hearing authentically voice many cases voice assistants limited simply recording going immediate vicinity instead networked virtual assistants smart home products act control centre technological heart modern data ethics commission believes creation comprehensive profiles based use voice assistants integration wide range software hardware components poses critical risk ease convenience apparent benefits connecting voice assistants devices may ultimately lead users trap view data ethics commission range measures taken mitigate risks associated voice assistants include bans particularly critical profiling procedures applications also following binding technical requirements implement principles data protection design default see also section especially processing speech files exclusively local basis well option erase files locally restrictions stating data may forwarded operators third parties form commands already translated machine language order placed binding technical requirements include option switch microphone internet connection way telling visual indication whether microphone see also section transparency obligations designed manner appropriate medium see part section ensure important information also provided acoustically either pertinent situation arises regular intervals standards use personal data imposition admissibility requirements critical profiling procedures including quality requirements relation meaningfulness accuracy profiles generated see part section details system latter appropriate level risk low clarification principle proportionality inter alia regards requirements apply nature scope data used profiling permitted level detail conclusions drawn profiling purposes particular purposes profiling may admissibly used imposition specific labelling disclosure information obligations inter alia regards existence purpose algorithmic systems may used carry deductions critical deductions already carried instead providing information automated decisions taken later stage process provision feasible options data subjects exert influence profiles created including option verify also includes right digital new start involving erasure existing profiles upon reaching age majority recently suggested expert voice assistants voice assistants promise great deal terms convenience easier access digital technologies particularly people disabilities yet also harbour risks far data subjects concerned voice assistants record ambient noise often without user activated related function recordings include speech user third parties regarded biometric data purpose gdpr speech recordings analysed real time response given spoken commands automated processes often log certain data types log file unique timbre individual voice speech patterns analysed basis uniquely identifying individual deciphering speech emotions profiling kind represents particularly deep invasive intrusion core area personality rights entails risk exacerbating structural imbalances demand supply side market enormous potential misuse also present given possibility recombining digitally reconstructing spoken word deep fakes reality individual users often vague idea data processing carried indeed whether carried particularly user relatively inexperienced technical matters may easily persuaded disclose additional sensitive personal data upon hearing authentically voice many cases voice assistants limited simply recording going immediate vicinity instead networked virtual assistants smart home products act control centre technological heart modern data ethics commission believes creation comprehensive profiles based use voice assistants integration wide range software hardware components poses critical risk ease convenience apparent benefits connecting voice assistants devices may ultimately lead users trap view data ethics commission range measures taken mitigate risks associated voice assistants include bans particularly critical profiling procedures applications also following binding technical requirements implement principles data protection design default see also section especially processing speech files exclusively local basis well option erase files locally restrictions stating data may forwarded operators third parties form commands already translated machine language order placed binding technical requirements include option switch microphone internet connection way telling visual indication whether microphone see also section transparency obligations designed manner appropriate medium see part section ensure important information also provided acoustically either pertinent situation arises regular intervals part ata addition special legislative measures kind aimed protecting users federal government examine extent would possible lobby new expanded legislative framework ensure appropriate data governance preferably european level otherwise national level framework entirely separate goals data protection law outside scope gdpr data ethics commission wishes issue following special recommendations connection see section examples case blacklisting unfair contract terms sections german civil code b√ºrgerliches gesetzbuch bgb contractual duties fiduciary nature section paragraph civil code specification torts umbrella existing tort intentional infliction harm contrary public policy new section civil code blacklisting misleading aggressive commercial practices addictive designs dark patterns expanding blacklist already exists german unfair competition act gesetz gegen den unlauteren wettbewerb uwg full harmonisation approach unfair commercial practices directive means change would need initiated level profiling carried government agencies potential cumulative infringements fundamental rights aggregated surveillance must taken account must potential side effects collateral damage data ethics commission believes particular potential abuse individual subsystems connected resulting pooling data analytical findings different areas sectors significantly steps intensity surveillance intelligent pattern recognition techniques particular facial recognition make easier link personal information across variety surveillance systems merge profiles view fact data ethics commission recommends firstly pattern recognition techniques kind come play use absolutely vital prerequisite fulfilment state obligations secondly clear legal limits beyond separation rule concerning intelligence activities must imposed exchange information patterns authorities may also encompass new legal provisions banning particular types use exploitation particularly regards sharing data government agencies engaged preventive repressive measures standards use personal data uniform supervisory activities task supervising compliance data protection law players german economy shared federal land authorities discrepancies observed terms interpretation data protection law approach enforcement raises certain challenges parties affected although european data protection board edpb introduced member states aim ensuring uniform application gdpr institution also power adopt binding decisions individual cases coexistence different data protection authorities various german l√§nder within framework federal system date prevented emergence binding uniform approach national level event proves impossible strengthen formalise cooperation german data protection authorities thereby safeguarding uniform consistent application data protection law consideration given establishment new data protection authority federal level data activities concentrating supervisory powers within single body would make possible build specialist expertise required enforce data protection law environment characterised highly dynamic technological developments single authority either acting alone close cooperation authorities would also need able safeguard enforcement areas law close functional ties data protection legislation general private law unfair commercial practices law establishment single body able wield market supervisory powers field data protection might also make germany voice louder within european data protection board since member states already represented edpb data protection authority national jurisdiction finally centralisation official competencies hand hand designation single court responsible judicial control supervisory authorities field data protection court also build relevant expertise set forth consistent body case models conceivable perspective organisational law based powers regulate economic law federal government could transfer supervisory competences data protection economy private sector federal commissioner data protection freedom information provide latter relevant resources setting number different satellite offices commissioner could ensure presence data protection bodies similar federal office migration refugees bundesbank alternatively l√§nder could establish joint facility basis interstate treaty way analogy similar projects broadcasting sector example central offices l√§nder safety engineering health protection joint facility responsible supervisory activities field data protection would need independent body principle enshrined interstate treaty irrespective decisions taken connection authorities provided better human material resources allow punch weight reasons constitutional law data protection authorities land level retain jurisdiction public sector part ata personal data asset commercialisation personal data economic significance personal data hard overestimate generally acknowledged protection personality rights fundamental rights also encompasses individual right decide whether certain aspects personality made available fee right one image words whether exploited economic way complete ban exploitation data individuals however rules categorically stating personal data may exploited economic purposes initiative third parties people compare situation trade human organs comparison flawed several respects unlike human organs data resource mere fact personal data processed someone else necessarily cause harm data subject harm caused processing data specific contexts specific purposes interpreting right informational natural corollary human dignity makes clear limits imposed economic exploitation personal data generally coincide general limits placed processing personal data see sections including substantive limitations consent backdrop economic exploitation personal data neither subject stringent rules general privileged way economic aspects frequently come play general data protection rules applied however example consent may longer freely given data subject exposed economic pressure see section german act protection copyright works art photographs gesetz betreffend das urheberrecht werken der bildenden k√ºnste und der photographie kunsturhg way examples european commission building european data economy january com final available arbeitsgruppe digitaler neustart der konferenz der justizministerinnen und justizminister der l√§nder working group digital new start conference ministers justice l√§nder report may seqq available data ownership issue financial compensation things stand data ethics commission believe adequate grounds introducing additional rights exploitation would allow data subjects request economic share profits derived help data often referred concepts data ownership data producer right data protection law general private law already provide individual range legal rights effective third parties basis rights individuals could theoretically make toleration data activities dependent payment appropriate fee individual fails negotiate fee kind attributed circumstances lack negotiating power poorly functioning competition nothing absence additional right exploitation theory imbalance negotiating power could introduction collective societies collectively exercise rights exploit data extending concept personal data include economic component would however potentially odds data protection particular regards voluntary nature consent ability withdraw consent time right request erasure would also create questionable financial incentives encouraging generation maximum personal data would put pressure individuals particular vulnerable groups minors low earners disclose much data possible industry passes costs remuneration customers privacyconscious individuals might also forced shoulder comparatively greater burden financial terms standards use personal data arguments hold water extent comes anonymised data however given huge number individuals contribute generation processing data level complexity fair remuneration system monitoring would required measure data flows would proportion potential gains terms justice data quality might also negatively affected since incentives would created generate data artificially creation fake profiles ultimately producing distorted picture reality data ethics commission therefore counsels introducing rights exploitation designed exclusive rights either anonymised data data types data large number digital content service types search engines social networks messenger services online games offered end users monetary consideration financed ways particular payments received third parties exchange personalised advertising personalised information services targeted users user profiles user scores personal data therefore often referred shorthand terms digital content services example original draft article digital content directive although term removed later point legislative procedure extent economic model described fact compatible prohibition article gdpr tying bundling consent provision must ultimately clarified european court justice european commission proposal directive european parliament council certain aspects concerning contracts supply digital content december com final available european data protection supervisor opinion proposal directive certain aspects concerning contracts supply digital content march available data ethics commission argues data referred provided exchange service even though term sums issue nutshell helped raise awareness among general public firstly personal data form integral part individual personality protected constitutional law secondly classification might unintended consequences example might abused argument favour largely excluding standard contract terms unfairness control justification triggering contractual sanctions consumers withdraw consent exercise right erasure etc connection german legislator implementing directive certain aspects concerning contracts supply digital content digital services use leeway available member states way might prevent individual seeking legal remedies data protection law particular individual withdraws consent processing data provider may right terminate provision service immediate effect however possible provider request payment services already provided retrospective automatic reversion pay option pay options increasingly discussed way avoiding tying bundling consent provision service yet even smallest financial burdens represents disadvantage particular vulnerable population groups may dissuade data subjects encourage disclose excessive amounts personal data also feared financial burden individuals would disproportionate commercial users previously able use certain digital content services free company page social networking site therefore preferred source funding part ata pay options may however increase consumer awareness financial value data also create transparency reasons data ethics commission believes offering pay options alternative may ethically acceptable way ensure consent given users genuinely free time however price must abusive exceed market prices consumer perspective must represent realistic alternative disclosure personal data ethical viewpoint safeguards must put place protect users users equally needs socially vulnerable groups must taken consideration example government transfers data basis personalised risk assessments predictions obtained using algorithmic systems purpose personalised risk assessment basis approving loan ongoing basis case black box schemes operated insurance companies characterised higher level granularity ultimately use case certain profiling technique associated scoring procedures see section part section details profiling general processing additional personal data purpose personalised risk assessments regularly requires consent data subjects individuals hope gain economic advantages result particularly likely grant consent yet granting consent one individual may significant impacts others give rise chain reactions problematic ethical viewpoint unravelling effects may put data subjects disproportionate pressure jeopardise voluntary nature insured parties healthy particularly likely consent processing data health insurance company result others come pressure also grant consent order avoid arousing suspicions regarding state health cases individual behaviour influence parameters models kind also significant influence people lead lives another ethical consideration particularly relevant insurance sector goal increasingly granular risk assessments runs counter basic principle collective risk sharing community insured persons taken extreme insurer access comprehensive information adjusts price individual risk whole concept insurance would reduced absurdity data ethics commission therefore believes personalised risk assessments must comply following ethical requirements particular data processing must intrude core individual private life must restricted areas individual already contact exterior world must therefore expect conclusions drawn basis behaviour principle dictates would ethically acceptable car insurance company example record miles driven traffic offences committed driver purely private behaviour inside vehicle even behaviour might relevant risk perspective often yawns whether chats passengers even driver state health heart problems lifestyle factors purchasing behaviour relation coffee alcohol clear causal relationship must exist data processed risk determined linking data must avoid discriminatory repercussions see part section details standards use personal data data must allow conclusions drawn directly implications relatives third parties full transparency required regards specific parameters weighting impacts pricing conditions individual must also provided clear comprehensible explanations improve conditions see part section order keep unwanted chain reactions check difference optimal conditions conditions apply consent refused must exceed certain ceiling maximum price difference data reputational capital coupled personalised economic conditions personalised prices personalised ranking personalised products services personal data profiles scores serve reputational capital personalised behavioural rewards aimed increasing customer loyalty granting discounts depending quantity purchased previous month incentivise consumers consent processing personal data may apt influence way lead lives evidence ethical limits outlined section currently disregarded german economy connection customer loyalty programmes come attention data ethics commission developments continue monitored article regulation data access many general provisions general terms conditions business view data ethics commission problems arising connection price differentiation narrow sense measures similar ilk relate regulation algorithmic systems see part details time however price differentiation morphs data use problem soon consumers led believe access prices lower overall disclosing much personal data possible exhibiting certain behaviours tailored relevant criteria making online purchases using computer manufactured certain company conversely suggested consumers refuse consent processing data purpose personalised pricing always pay higher prices average data ethics commission believes latter would also pose ethically questionable risk voluntary nature consent true reputational data also visible external third parties stars indicating someone profile online platform good person business gaining ever economic nonmaterial significance certain extent reputational data kind covered new regulation promoting fairness transparency business users online intermediation regulatory approach chosen lawmakers drafted regulation based part transparency requirements cautious data ethics commission welcomes approach principle however worth noting certain sectors heavily dependent true reputational data factor particular might lead significant effects may jeopardise competition cause problems individuals unable take data switching different online intermediary platform part ata example micro entrepreneur offers taxi services via online platform ranked highly many former passengers wishes switch platform take rankings data ethics commission aware problems would arise general obligation recognise ranking profiles built different platform enshrined law however recommends federal government examine conditions commercial users profiles kind might nevertheless granted right portability view lobbying broader regulation european way contrast rise significance social reputation data number likes followers friends part wider trend society limited exception influencers longer viewed predominantly lens personal data economic asset must instead discussed relation systemic societal implications data tradeable items significant number companies already deriving financial gain cases earning great deal money compiling personal data profiles scores personalised statistical evaluations carried using aggregated raw data reselling third parties enriching existing profiles estimated data placing market following section business models kind referred data trading example articles draft model rules online intermediary platforms european law institute made available data ethics gdpr currently contain provisions relating specifically data trading instead business models kind categorised merely normal data processing operations subject general provisions gdpr many cases closer examination applicable provisions leads inescapable conclusion certain types data trading infringe provisions gdpr therefore contrary law generally speaking however field data trading characterised significant enforcement gap data ethics commission therefore believes urgent action taken data protection authorities relation sector european data protection board edpb alternatively conference independent data protection authorities federal government l√§nder konferenz der unabh√§ngigen datenschutzaufsichtsbeh√∂rden des bundes und der l√§nder develop keeping gdpr approach clearly delimitable categories different types lawful data trading greater clarity needed regarding instances data trading data subject must grant consent forwarding data instances data subject right object processing data instances compelling reasons rule even right object regard general principles governing data processing article gdpr forwarding data third parties permitted within closely prescribed limits situations covered existing provisions data protection law data ethics commission therefore recommends federal government speak european level connection forthcoming evaluation gdpr example favour expanding scope gdpr include specific provisions data trading following ethical considerations already enshrined gdpr taken account drafting future legal provisions kind standards use personal data individual right informational selfdetermination starting point balancing exercise meaning data trading principle requires prior consent data subject due regard substantive limitations consent sections data processed legal basis consent likely occur isolated cases individual must straightforward opportunity exercise right object advance unchecking checkbox immediately data collected must forced communicate objection via separate communication channels data trading models deprive data subjects choices whatsoever rarely considered extent data need forwarded order public interests manifestly outweigh countervailing interests comprehensive legislative clarification category required gdpr contains detailed provisions transfer data processors forwarding data third countries given content rationale gdpr would illogical assume requirements apply transfers data third parties within less stringent apply transfers outside certain points also inferred general provisions requirements regarded appropriate safeguards nevertheless data ethics commission recommends urgent action taken clarify explicitly law obligations apply transferring data third parties control obligations well circumstances parties may held controllers obliged document disclose specific source data collected generated use algorithmic systems well identity individual recipients data information must provided standardised format allows automated data management using privacy management personal information management system see section details would take due account fact data subjects largely left dark regards existence data traders means simple list different categories sources recipients would little use given large number data traders market data subjects able exercise rights effectively central mechanisms established facilitate process assume responsibility data protection authorities see section privacy management information management systems see section details given dispersion effects give rise higher risks potential loss control data traders subject certification obligation data protection law includes regular audits certification bodies data ethics commission recommends specific certification criteria adopted appropriate independent data protection authorities federal government l√§nder criteria take due account risks recommendations outlined part ata data digital inheritance modern communication technologies data processing capacities make possible record every last detail individual private activities decades end evaluate recordings using automated systems handing data collected deceased individual heirs another third party adds whole new dimension privacy risk deceased person particular individuals communicated lifetime data often compared diaries personal correspondence comparison flawed many channels digital communication messenger services chats etc serve functional replacement ephemeral spoken word rather letters precedence living wills data ethics commission believes bestcase scenario data subject make intentional informed dispositions lifetime many cases however people neglect make dispositions sole reason unaware legal practical options put level uncertainty backdrop data ethics commission believes justified grounds obliging service providers alert users option making dispositions provide ongoing incapacity provide consent due dementia death provide technical means making said dispositions minimum barriers fewest possible changes medium corresponding provisions could added german telemedia act telemediengesetz tmg previous discussion topic see mario martini juristenzeitung view data ethics commission situation following data subject death merely extreme example serve prompt reflection general design digital modes communication data ethics commission therefore recommends federal government examine possibility making obligatory messenger services offer default option erasing messages certain period time user chose option message would automatically erased expiry relevant period unless manually archived recipient sender role intermediaries growing awareness topic digital inheritance allowed new business models flourish large number companies offering services field ranging central storage account data passwords comprehensive digital inheritance management services may provide useful guidance also associated certain hazards including inadequate provision cases company goes bankrupt otherwise liquidated shortcomings information security including genuine fraud data ethics commission believes quality assurance new regulations characterised cautious approach public potential advantages risks required order protect citizens standards use personal data addition recommends federal government part remit provide services general interest public set body least subject state supervision provides affordable basic digital inheritance protection planning services citizens services must reflect latest developments field information security technology german citizen writes choose store privately notary district court similar options private privatesector solutions service also available individual digital inheritance data protection data ethics commission recommend wholesale rejection principles set forth german federal court regarding transfer estates heirs since potential advantages would far outweighed effects either undesirable excessive different default solution trust model imposed law distinction user account content regarded asset content user account regarded highly personal conversely inheritance law apply nature user account online account alcoholics anonymous group renders data within financially worthless highly sensitive cases principle telecommunications confidentiality applies inter alia protect deceased communication partners legislator case still reconcile right inheritance enshrined fundamental right example corresponding reference part civil code devoted inheritance law judgment german federal court justice july ref iii principle set forth federal court justice estate transferred deceased heirs linked existence contractual relationship contractual relationship transfer heirs take place owing highly sensitive nature data heirs right legal recourse since data protection provided gdpr also means legal recourse relatives current state data protection law ethical concerns raised fact controllers almost unlimited power dispose deceased personal data result data ethics commission therefore recommends federal government follow footsteps several member states make use option provided recital gdpr enacting provisions data protection even death data subject latter relatives able exercise fundamental rights right erasure right rectification incorrect data time suitable measures taken ensure compliance dispositions made deceased lifetime even dispositions implied deliberate choice publish life story part ata special groups data subjects employees fact employers collect employees location data performance data widespread phenomenon certain modern workplaces poses significant risk employees right informational general rights personality true creation biometric profiles necessary precursor certain forms collaboration questions considered include legal basis data processing granting rights employee representation bodies also obligations provide employees information hazards posed fusion depending context opportunities object issues regarding data retention procedures terms data retention extent employees data may disclosed third parties right rectification incorrect obsolete data personal profiles example appropriate erasure procedures points consideration include framework conditions limited control surveillance employees restrictions tracking employees locations ban comprehensive location profiles restrictions obligation share social media accounts allow employer access data context bring device models framework conditions use biometric systems restrictions psychological investigation data ethics commission recommends federal government invite social partners work towards common position legislative provisions adopted view stepping protection employee data based examples best practices existing collective agreements concerns individuals forms employment also taken account process collective agreements works council agreements continue play significant part employee data protection yet foundational principles employee data protection regulated solely collective agreements works council agreements firstly employees covered latter secondly importance principles fundamental rights perspective also worth noting legal uncertainty currently reigning scope gdpr provisions negative impact investment security reference wider field legal bases processing employee data data ethics commission believes traditional construct consent data protection law suitable contexts since difficult put place framework conditions necessary consent given voluntarily employment situations impossible find appropriate balance cases employer needs option employees revoke consent request erasure data time employee data protection measures therefore focus legal grounds justification specifically tailored employment context guarantee high level protection appropriate weighing interests fundamental rights outcomes may look similar consent certain respects taking account power structures typically exist employment context standards use personal data deciding whether interest groups granted relation processing data within companies due regard must given asymmetry knowledge exists employers employees regards operating principles details data processing operations need models existing mechanisms allowing interest groups access external expertise time ensuring appropriate involvement company data protection officer also protection trade secrets given constant advancement systems within companies software updates elements etc shift away consent single event towards ongoing oversight processes interest groups progress field employee data protection neglect stages applying job entering employment relationship example care must taken ensure provisions applicable law prohibit employers asking certain questions application procedure recruiting individual asking whether woman pregnant circumvented use human resources algorithms request grant employer access social media accounts examples current legislative provisions see section german works constitution act betriebsverfassungsgesetz betrvg relation works councils section german federal staff representation act bundespersonalvertretungsgesetz bpersvg relation staff councils german ethics council deutscher ethikrat big data health opinion november available must also taken ensure persons nonstandard forms employment excluded progress field employee data protection upsurge forms employment platform economy means many people longer access traditional employee rights rights imbalance power arises client platform operator one hand contractors platform workers often significant may implications terms data protection informational selfdetermination appropriate legislative provisions adopted ideally level institutional framework developed interest group mitigate risk patients view benefits could gained digitalising healthcare basic principle data ethics commission recommends swift expansion digital infrastructures sector introduction procedures reviewing assessing digital healthcare services range quality digitalised healthcare services improved allow patients exercise rights informational become health even things stand today provision healthcare services involves processing huge volumes personal data data involved typically health data genetic data words special categories personal data within meaning article gdpr designing future health landscape primarily digital nature comprehensive account must taken need provide special protection data time boosting right patients health insurance policies inter alia field research see section part ata connection data ethics commission emphasises urgent need introduce roll electronic health record view improving quality transparency medical given vital role electronic health record would play digitalising healthcare sector data ethics commission wishes make clear greater attention paid information security patient autonomy implementing system existing cryptosecurity concept based decentralised management keys pins insured parties continue apply example also possible use electronic health record even patient incapable granting consent based provisions concerning legal representation otherwise apply regardless type health insurance policy held patient digital health services products collectively financed health market becoming ever important least digital healthcare services offered statutory health insurance funds far date important underestimate relevance services include fitness health wellness apps particular digital apps associated wearables context digitalised healthcare sector yet apps often questionable poorly verified quality meaning data collect limited usefulness carries risk health affected patients users cases significant furthermore assumed patients able assess quality products services independently particular compliance principles data protection information security equally access digital healthcare services dependent individual financial wherewithal mind data ethics commission welcomes plans federal institute drugs medical devices bundesinstitut f√ºr arzneimittel und medizinprodukte introduce procedure examining assessing apps kind see respect data ethics commission previous recommendation participatory development electronic health record dated november available minors data ethics commission welcomes efforts undertaken include adoption legislation voluntary develop special protective mechanisms allowing minors exercise right digital primary goal mechanisms step level data protection degree protection profiling manipulation dark patterns addictive designs etc secondary goal provide greater protection content glorifies violence example time however data ethics commission wishes make clear protective mechanisms prove futile unless reliable identity management system place ensuring age minors detected treated appropriately relying users honest age without question wrong approach viewed lens ethics however would also problematic ask providers ascertain user age collecting personal data may highly sensitive facial recognition data transferred provider cloud time placing entire burden whoever holds parental authority may easily result situation latter feels much asked data ethics commission therefore recommends federal government promote emergence technologies allow minors exercise right development time reliably guaranteeing protection standards use personal data data ethics commission recommends federal government lobby european level measures enforce compliance principles data protection design default enshrined gdpr particularly case mobile end devices order protect right informational minors protect privacy german european data protection authorities competition authorities media regulators technical regulatory authorities take action within relevant remits spheres responsibility force manufacturers operating systems mobile end devices providers digital services adhere legislative requirements apply age groups question block services parties responsible procuring relevant systems view use schools kindergartens also incorporate requirements tendering procedures detailed discussion need force manufacturers comply principle data protection design default found section far action area concerned consideration also given introduction obligation forces manufacturers mobile end devices program outset devices specifically intended children ensure jail breaking rooting impossible possible key devices programmed way enforce compliance legislative provisions aimed protecting children block services relevant settings enabled operating system upon activation minors able change settings without parents consent solution kind would also offer clear advantages parental control apps firstly apps often pose data protection information security problems right secondly raise ethical questions terms opportunities afford total surveillance private vulnerable persons many cases data belonging vulnerable individuals processed benefit individuals care sector digital technologies make much safer older people remain environment accustomed example may also help alleviate negative impacts skills shortage care sector ensure better healthcare provision particular digital assistance systems used correctly serve bridging technology adjust adaptively varying needs different people right life right bodily integrity also right informational fundamental rights must reconciled accordance principle practical concordance particular consideration must given two questions particular whether risks posed life health extent right informational encroached upon part ata data ethics commission believes standards guidelines surveillance professionals care sector developed conference independent data protection authorities federal government l√§nder particular standards guidelines specify legal provisions upon professionals base action particular situations cases especially consent granted data subject caregiver surveillance either prohibited possible basis article gdpr also outline arrangements provision information whereby data ethics commission takes position differentiated information digital surveillance options provided prior use institutional setting care home kindergarten school consent must also obtained differentiated basis cases legal basis data processing standards guidelines kind would also appropriate way provide legal certainty care home operators care staff reduce liability risks section civil code amended accordingly clarify fact living wills also include dispositions relevant data subject grants prior consent processing data basic principle particularly high level protection also accorded people homes since likely regard space within four walls safe privacy new technologies opened new expanding options surveillance private individuals private individuals surveillance romantic partners children persons disabilities range way ethically alarming prospect total private surveillance given awareness topic lacking many quarters data ethics commission recommends awarenessraising campaigns area initiated federal government governments l√§nder since latter often hold jurisdiction field although recommends federal government continue monitoring developments believe legislative measures new criminal offences required data protection technical design citizens companies government agencies parties entitled assert ethically justified data rights obliged comply corresponding data obligations must position first place necessary technical framework must put place enabling technologies must play prominent role respect yet enabling technologies kind must lead situation responsibility protection fundamental rights freedoms offloaded onto individual users instead state must matter principle adopt regulations required provide reliable protection fundamental rights freedoms without need action part individuals design products services heading suggests article gdpr makes mandatory controllers comply principles data protection design default designers new technologies must therefore take due account concerns relating data protection based interpretation term applied article gdpr following approach technical organisational measures must implemented end may required prior processing controller determines means data processed well processing operation standards use personal data design specifications data protection law high level practical relevance relation end devices end devices designed worn body wearables smartwatch smart textiles least carried close body smartphone others designed mobile means networked car immobile smart home facilities designing software systems end devices kind amount time spent reflecting ethical questions raise depends likelihood used close proximity body private intimate spheres bathrooms bedrooms probability use affect particularly vulnerable persons data protection design default technology working group conference independent data protection authorities federal government l√§nder das eine methode zur datenschutzberatung und auf der basis einheitlicher gew√§hrleistungsziele erprobungsfassung standard data protection model method data protection consulting assessment basis uniform warranty objectives test version available protection design imposes conditions selection technical organisational measures relating state art implementation costs processing risk posed rights freedoms natural persons example data protection default imposes conditions since principle must adhered without exceptions practice however often case excessive amounts personal data identifiers processed inadequate restrictions placed processing retention periods long inappropriately high number people able access data field privacy engineering therefore emerged banner additional protectionrelated goals transparency intervenability standard data protection model sdm used german data protection authorities incorporates goals warranty objectives like baseline protection catalogues published federal office information security bundesamt f√ºr sicherheit der informationstechnik bsi sdm defines modules used controllers designers new technologies basis choosing technical organisational measures appropriate protection needs although first modules currently available others planned fact many developers use baseline protection catalogues iso series standards reference works means developers familiar fundamental concept able take better account legal requirements designing implementing technical systems choice centralisation decentralisation another question must clarified basis designing technical systems general rule centralised systems allow operators exercise higher level control influence might good thing example underlying aim incorporate features contribute data protection information security yet also bad thing since potential misuse either malicious third parties wanting steal data sabotage data processing operators exploiting large volumes data amassed purposes notified data subjects greater data stored centrally processing data also controlled centrally designed appropriately however decentralised systems help decrease prevent data linkability reduce disruptions overall system availability part ata children young people persons persons disabilities extent encroach upon individual personality high level responsibility autonomy granted demanded users assemble configure operate devices represents particular challenge attempting design technologies foster selfdetermination data ethics commission recommends federal government step support efforts technical standards end devices also urges federal government lobby european level introduction technical requirements aimed safeguarding product safety private sphere particular reference end devices consumers data ethics commission takes view following principles minimum enshrined end device requirements adopted must protected cyber attacks improper use data measures taken must commensurate need protection comply state art suitable guarantees must provided particular sensitive data health data high level cyber resilience must achieved joint task incumbent upon state industry individual must able times identify functions currently enabled particular must able see whether camera microphone gps sensors switched whether device connected internet whether data transferred outside closed local area must easy turn data transfers including transfers outside local area data stored locally function switched must transferred without user consent next switched must also true individual applications smartphones smart tvs basic device functions technically possible without data transfers kind functions must remain available data transfers turned smart fridge must continue keep contents cool supplied user onboarding software onboarding take place automatically devices first put operation possible repeat onboarding process often necessary even second users information provided users cover mode operation also collection processing user data end devices direct connection internet routers secured using password possible put operation without changing factory password beforehand system side passwords allowed comply state art standards use personal data way products services applications designed huge influence extent controllers processors able comply data protection obligations incumbent upon yet manufacturers directly responsible processing personal data fall outside scope gdpr controllers want use solutions developed must therefore insist bakedin data mind data ethics commission recommends federal government either take steps support action parties aim forcing manufacturers shoulder greater share responsibility suitable measures might include following recital gdpr christiane wendehorst verbraucherrelevante problemstellungen und eigentumsverh√§ltnissen beim internet der dinge teil wissenschaftliches rechtsgutachten problems relating possession ownership structures internet things part scientific legal opinion studien und gutachten auftrag des sachverst√§ndigenrats f√ºr verbraucherfragen studies opinions behalf advisory council consumer affairs december available imposition legislator product design product safety requirements effective legal remedies along distribution chain used shift burden responsibility inadequate data protection design default onto whereby certain amount progress made new directive certain aspects concerning contracts sale goods terms shifting burden responsibility consumers onto retailers along distribution chain comprehensibility transparency data protection design also encompasses comprehensibility transparency systems including applications scripts sources elements point time development procedure process data ethics commission welcomes ongoing efforts develop models good terms conditions business onepagers consumers part approach consumers initially provided simple information important data processing operations necessary informed detail general terms conditions business data protection measures however approach solve underlying problem information provided often fails job either inadequate exceeds consumer capabilities consumers make informed purchase decisions standardised readily understandable graphical symbols icons introduced european level following broad consultations industry civil society icons convey key digital characteristics products including digital products apps services basic functions available internet connection internet connection required enhanced functions user data transfers user tracking examples possible characteristics icons could also colour coded would particularly useful case product characteristics apply greater lesser degree data ethics commission recommends federal government lobby european commission develop standardised icons kind keeping article gdpr increased transparency consumers could also achieved supporting development certified electronic shopping assistants would identify product online shop serve product information consumer format likely understand part ata tenders guidelines public procurement measures designed way require evidence compliance gdpr including principles data protection design default encourage compliance particularly high standards data protection design default example requirements effect government funding programmes product development importance data protection technical design must also taken account product development enhancement stages applies particular development algorithmic systems since latter typically require data bulk example use training data see part section details training algorithmic systems datatilsynet artificial intelligence privacy report january seq available options available complying principles data protection enshrined article gdpr training algorithmic systems january example datatilsynet norwegian data protection authority proposed means methods training algorithmic use data minimisation procedures relation training data use synthetic data using generative adversarial networks example federated learning use variants proposed neural networks use encryption procedures differential privacy homomorphic encryption procedures allow retrieval information without granting full access database use procedures promote transparency achieve higher level comprehensibility traceability data ethics commission believes research still needed areas also applies options testing algorithmic systems data ethics commission recommends measures taken ethically indefensible uses data examples uses include total surveillance profiling poses threat personal integrity targeted exploitation vulnerabilities addictive designs dark patterns methods influencing political elections incompatible principle democracy vendor systematic consumer detriment many practices involve trading personal data data protection law well branches legal system including general private law unfair commercial practices law already provide range instruments used prevent ethically indefensible uses data however spite widespread impact enormous potential harm little done date terms harnessing power instruments particularly market giants various factors contributing enforcement gap must tackled systematically well steps make players super visory authorities aware existing options urgent need legislative framework force fleshed clearly strengthened certain areas examples recommended measures include blacklisting unfair contract terms fleshing contractual duties fiduciary nature new torts blacklisting certain unfair commercial practices introduction much detailed legislative framework profiling scoring data trading order allow supervisory authorities take action effectively authorities need significantly better human material resources attempts made strengthen formalise cooperation different data protection authorities germany thereby ensuring uniform coherent application data protection law attempts fail consideration given centralisation supervisory activities within authority granted broad mandate cooperates closely specialist supervisory authorities authorities land level remain responsible supervisory activities relating public sector important recommendations action standards use personal data part ata data ethics commission believes data ownership exclusive rights data modelled ownership tangible assets intellectual property would solve problems currently facing would create new problems instead recommends refraining recognition also advises granting data subjects copyrightlike rights economic exploitation respect personal data might managed collective societies data ethics commission also argues data referred provided exchange service even though term sums issue nutshell helped raise awareness among general public regardless position data protection authorities european court justice ultimately take regard prohibition gdpr tying bundling consent provision service data ethics commission believes consumers must offered reasonable alternatives releasing data commercial use appropriately designed pay options stringent requirements limitations imposed use data personalised risk assessment black box premiums certain insurance schemes particular processing data may intrude intimate areas private life must clear causal relationship data risk difference individual prices charged basis personalised nonpersonalised risk assessments exceed certain percentages determined also stringent requirements respect transparency nondiscrimination protection third parties data ethics commission advises federal government consider issues falling heading digital inheritance settled federal court justice ruling ephemeral spoken word replaced many situations digital communications recorded less entirety possibility records handed deceased heirs adds whole new dimension privacy risk range mitigating measures taken including imposition new obligations service providers quality assurance standards digital estate planning services national regulations data protection data ethics commission recommends federal government invite social partners work towards common position legislative provisions adopted view stepping protection employee data based examples best practices existing collective agreements concerns individuals forms employment also taken account process view benefits could gained digitalising healthcare data ethics commission recommends swift expansion digital infrastructures sector expansion range quality digitalised healthcare services include measures better allow patients exercise rights informational measures could taken respect include introduction electronic health record building participatory process involves relevant stakeholders development procedures reviewing assessing digital medical apps health markets standards use personal data data ethics commission calls action significant enforcement gap exists regard statutory protection children young people digital sphere particular attention paid development mandatory provision technologies including effective identity management default settings guarantee reliable protection children young people also familyfriendly neither demand much parents guardians allow even encourage excessive surveillance home environment standards guidelines handling personal data vulnerable persons introduced provide greater legal certainty professionals care sector time consideration given clarifying relevant legal provisions living wills may also include dispositions regard future processing personal data far processing require person consent dementia patients position provide legally valid consent data ethics commission believes number binding requirements introduced ensure design products services principles privacy design privacy default gdpr imposes controllers already put practice upstream manufacturers service providers requirements would particularly important regard consumer equipment context standardised icons also introduced consumers able take informed purchase decisions action must also taken number different levels provide manufacturers adequate incentives implement features design includes effective legal remedies pursued parties along entire distribution chain ensure also manufacturers held accountable inadequate application principles privacy design privacy default consideration also given particular requirements built tender specifications procurement guidelines public bodies conditions funding programmes applies product development including training algorithmic systems debates data protection tend quite rightly centre around natural persons important ignore fact companies legal persons must also granted protection almost limitless ability pool together individual pieces data used means obtaining comprehensive picture company internal operating procedures information passed competitors negotiating partners parties interested takeover bid poses variety threats inter alia digital sovereignty germany europe view significant volumes data flow third countries many data ethics commission recommendations action therefore also apply mutatis mutandis basis data legal persons data ethics commission believes action must taken federal government step level protection afforded companies part ata improving controlled access personal data types data personal represent key resource within data economy serve vital ingredient many applications foster public good breakneck speed development digital technologies benefit every one enormously attributed part ability evaluate data generated billions users although data protection must always remain central priority applications involving personal data people asking whether general improvements area controlled access personal data might ethically tenable even desirable keeping principle data use data sharing public good section within framework prescribed data protection law enabling research uses personal data preliminary considerations research serves basis almost technical achievements current onslaught digitalisation means research becoming increasingly important significance already recognised gdpr backed certain cases national law german federal data protection act bundesdatenschutzgesetz bdsg data protection acts l√§nder data ethics commission wishes emphasise fact data processing operations involving genetic biometric health data enormous value terms furthering research goals promoting preventive methods developing new diagnostic therapeutic approaches use artificial intelligence holds promise significant progress certain areas depending problem tackled may rely large pools data issue releasing health data research purposes referred data donation recurrent topic debate term data donation misleading however data donated unlike organs money reused often necessary parallel even data donor conference independent data protection authorities federal government l√§nder orientierungshilfe der aufsichtsbeh√∂rden f√ºr anbieter von telemedien guidance supervisory authorities telemedia providers march available research part described activity terms way uses data providing healthcare services developing sustainable mobility concepts improving living conditions broader sense data ethics commission recommends full use made existing privileges data protection law research viewed particularly valuable good weighing competing additionally recommends l√§nder exercise regulatory powers already hold example area higher education law within framework data protection law way foster innovation keeping aforementioned notion special privileges research broad interpretation placed term scientific research context inter alia reference consistent past decisions federal constitutional court irrelevant whether research question carried private institutions data ethics commission wishes point challenging though task may appropriate balance must sought researchers fundamental rights data subjects right informational carrying weighing interests required law special priority accorded protection sensitive data associated rights data subjects patients insured parties example duty confidentiality imposed certain individuals doctors subject code professional secrecy section german criminal code strafgesetzbuch stgb may also apply work research institutions latter use data collected stored individuals question procedural precautions imposed law view protecting right informational would need observed improving controlled access personal data legal clarity certainty although law currently stands permits promotes research questions interpretation arise relation certain details questions require clarification supervisory authorities courts example yet definitively clarified whether processing data already lawfully collected one purpose healthcare provision basis article gdpr light recital appropriate safeguards within meaning article gdpr automatically deemed lawful processed research purposes whether requirement separate legal basis pursuant article article gdpr applies data first collected example section federal data protection act states healthrelated data processed express consent provided research interests substantially outweigh data subject interests also suggested certain quarters right process data invoked party collected data first place similar uncertainty reigns scope term research regards product development enhancement even though legal framework exists research germany inter alia relation healthrelated data special categories data finer details regulatory framework lack uniformity country federal structure means federal government l√§nder hold constitutionally enshrined legislative powers research perspective resulting legal uncertainty exacerbated yet ongoing lack reliable guidance particular regards criteria must met order consent deemed valid order data subject interests substantially outweighed research interests within meaning section federal data protection act legal uncertainty could prove stumbling block research germany data ethics commission believes recommendations action interpretative criteria therefore developed perhaps conference independent data protection authorities federal government l√§nder involvement relevant stakeholders politics healthcare industry civil society relevant rules applied feasible legally compliant way information pseudonymisation anonymisation standards see section view harmonisation aimed overcoming regulatory discrepancies field research different regulatory approaches member states division regulatory scope federal data protection act data protection acts l√§nder special regulations specific subjects data ethics commission recommends federal government push synchronisation legal bases federal data protection act data protection acts l√§nder subjectspecific acts drive forward projects european level aimed greater harmonisation regulatory frameworks put place member states respect research data protection lobby duty notification incumbent upon member states adopting national laws area establishment european clearing house research projects part ata consent processes sensitive data voluntary informed explicit consent data subject critically important means protecting individuals test subjects participating research projects particularly case clinical research research involving health data particularly sensitive categories data provides test subject opportunity exercise right informational since necessitates provision information research project also ensures test subject discover later date values preferences prevent participating study protective instrument enshrined law improves transparency research therefore increases people level confidence least among benefits fact also promotes integrity research researchers yet researchers act controllers face considerable challenges comes obtaining informed consent particularly project involves sensitive data example researchers want embark new project using health data already available database data subjects must contacted consent obtained unless data subjects originally consented reuse data future provided use term preferred within ethics discourse broad consent researchers wishing use health data collected course routine medical care research purposes must first contact patients ask grant informed consent task fraught huge practical obstacles mind data ethics commission recommends appropriate model procedures obtaining consent designed developed view making easier process data research explicit reference link exists consent data subject fundamental rights data ethics commission also calls development innovative consent models research sector dynamic consent models involve tailoring declarations consent individual context already trialled example connection must ensured consenting party remains able control data even granting consent order ensure case data ethics commission recommends emphasis placed development design privacy management tools pmt personal information management systems pims see section research sector digital consent assistants data agents consent assistants kind may make significantly easier data subjects keep track data processing operations granted consent even operations commenced equally may make possible back ask data subjects consent circumstances change provide data subjects straightforward way revoking consent calls heard increasingly often particularly connection research using health data blanket consent models involve data subject granting consent wide range data uses field research without reference specific course treatment event although research sector advance compelling reasons models kind number concerns obstacles must overcome adopted particular need consent informed linked specific purpose would make impossible take consenting party preferences values account differentiated basis even legal safeguards provided misuse data encroachments upon privacy improving controlled access personal data backdrop data ethics commission recommends discussion innovative model known meta consent appropriately informed without situation consent specifically required data subject decides type research projects research contexts wishes grant consent type consent involved specific broad consent may limited basis considerations following context private public research commercial research national european international research sources electronic health record human tissue health data lifestyle data wearables research preventive research research cancers neurodegenerative disorders kind health research researchers later wish use data specific research project data subject informed advance given opportunity object use data thomas ploug s√∏ren holm bioethics implementation model oversight data trust scheme ethics commission another responsible body tasked ensuring consenting party preferences fact taken account also possible data subject amend terms meta consent time technical regulatory framework required must place example example data subject specifies data electronic health record may used public commercial research also specifies blood tissue samples may used public commercial research degenerative diseases consents processing data electronic health record provided data transferred europe company spain would like use data electronic health record well data tissue samples dementia research data subject informed intention told four weeks object data used way part ata deliberating designing model kind care must taken ensure constraints placed freedom research research privilege secondary use data equivalent scope restrictions imposed current legal system preference given meta consent models emphasise ability data subjects express values preferences regarding use health data research purposes would also increase public confidence health data governance another ethical question must considered accountability relation use data also relation since may block potential progress vital areas result discrimination certain groups result exclusion progress example methodological reasons mean clinical studies involving older people suffering several different chronic diseases taking several different kinds medication time must necessarily limited scope highquality procedures used evaluate health data however key findings might obtained interactions different medications actions everyday conditions findings could used productive basis extensive research treatment patients going forwards mind given significance european healthcare sector medical economic perspective data ethics commission recommends proactive support learning healthcare system healthcare provision continuously improved making systematic qualityoriented use health data generated basis keeping principles evidencebased medicine learning healthcare system imposes high requirements terms governance requires approach healthcare provision puts insured party patient front legal protection discrimination time however data ethics commission wishes emphasise parties involved developing designing new research projects must take due account significant potential discrimination opened availability sensitive data data subject looks job takes insurance policy technical progress made possible sequence decode human genome data scientists able analyse biometric behavioural data collected course daily life means also possible profile individual risk falling ill future typically based likelihood suffer disease genetic data come play relatives may also affected mind federal government examine possibility including new grounds action german general act equal treatment allgemeine gleichbehandlungsgesetz agg well specific bans using information person health way analogy corresponding provisions genetic data german genetic diagnostics act gendiagnostikgesetz gendg improving controlled access personal data anonymisation pseudonymisation synthetic data operations involve accessing personal data must always comply applicable provisions data protection law abide rules data processing laid provisions purpose limitation principle right appropriate protective measures certain circumstances therefore may vitally important businesses users know certain operations either fall outside scope data protection law compliant data protection law data ethics commission believes lack legal certainty number different areas example concerning anonymisation pseudonymisation data identification consideration link individuals allegedly anonymised data sets synthetic data anonymised pseudonymised data anonymisation involves processing set personal data way link data subject broken irrevocably distinction made randomisation generalisation different ways approaching task anonymisation used individually combination randomisation involves modifying data way anonymised data longer matched data subject achieved falsifying individual data sets example appropriately designed randomisation methods ensure statistical properties original data set retained example swapping values rather changing generalisation involves aggregating pieces less detailed information age categories instead dates birth names regions instead postcodes periods time instead time stamps accurate nearest second three main strategies used identify natural persons data set singling method pinpointing data sets relating specific individuals larger pool data example using unique characteristics make possible identify individuals linkability method involves linking least two data sets relate individual group individuals basis matching values appear data sets identifiers spatial coordinates times even small amount data available individual augmented using linking strategy allowing identified inference method involves deriving highly probable value characteristic values number characteristics allowing data relating individual augmented increasing likelihood identified part ata anonymised data sets make impossible recreate links existed data individuals data relate create links first time given technological means reasonably likely used available developed time processing recital gdpr attacker wishing identify one data subjects deanonymisation would find task impossible modifications set data particular artificial addition fuzziness also referred noise blurring depending context ensure impossible pull data belong specific individual linkable data used inferences drawn modifications typically also place constraints utility data user aware evaluations later carried using data set anonymisation procedures optimised mind example retaining necessary level detail relevant characteristics wherever possible applies comparisons different data sets interoperability user knows comparisons carried appropriate anonymisation methods designed categorising data identical groups required taking account increase risk may occur result incorporating information data sets pseudonymisation involves processing data way longer assigned specific data subject without additional information may take form mapping tables cryptographic hash methods example pseudonymisation differs anonymisation reference person legal sense term retained controller must prevent unauthorised access additional information whenever pseudonymised data processed future since otherwise would possible map data data subjects gdpr refers pseudonymisation several times technical organisational measure reducing risk rights freedoms natural anonymisation pseudonymisation involve processing set data already available must distinguished pseudonyms deployed user side users may choose pseudonymised identifiers user names online services addresses use identifiers provided automatically technological system example online function electronic card authorisation certificates designed data protection concerns mind vast majority cases use pseudonyms provides little way protection identification data subject particularly used across contexts communication partners allows data profile linked data augmented conversely constantly changing transaction pseudonyms restricted specific context making much harder identify individual question procedures aimed concealing link data subject data relating data subject generally regarded anonymisation strict sense term may nevertheless provide level protection identification observation simple web proxies make possible surf internet using identifier address intermediary server multiple users whose identifiers known proxy server may therefore identifier far destination web servers concerned provided avoid identifying use cookies etc steps prevent identification taken arranging multiple intermediary servers one behind another example mix networks tor mix cascades jondo noise added sending artificially created dummy traffic additional obstacle path anyone attempting observe human users improving controlled access personal data procedures standards presumption rules often possible anonymise data completely break link data data subject belong way recreated without losing data utility time however perfect anonymisation often required firstly many goals upon closer examination achieved using data somewhat lower level utility secondly gdpr already contains exemptions data processing operations serve public good research sector meaning even personal data processed without obtaining consent data subjects nevertheless efforts aimed developing effective anonymisation technologies procedures stepped view allowing data processed wholly outside scope gdpr ultimately legal certainty achieved developing standardised technologies procedures must always take due account whirlwind pace technological development data ethics commission therefore recommends federal government lobby particular level anonymisation standards would benefit data subjects users pseudonymisation measures commensurate level risk faced data subjects private lives featured agenda federal government digital summit federal office information security technical guidelines bsi cryptographic mechanisms recommendations key lengths last updated february available particular anonymisation standards combined clear rules imposing rebuttable legal presumption would provide legal certainty users could rely data processing operations falling outside scope gdpr standard met context important remember restrictions may need imposed presumption rules example period validity way analogy cryptographic procedures authorised methods processing example stating data may published made accessible unspecified number people long legal basis rebuttable presumption rules federal government support development technical best practices codes conduct view building experience fields certain fields standardisation anonymisation pseudonymisation procedures may also impose rules way link data subject data relating broken making possible compare different data sets improving interoperability least areas improved interoperability outcome data ethics commission recommends rules developed preferred groupings value ranges age categories postcodes addresses similar approach already followed germany statistical offices handling data example part ata anonymisation pseudonymisation procedures carried repositories data known least suspected contain personal data differ repositories data thought contain personal data could used means least starting point either combination creating link purportedly anonymous data data subject data belong data ethics commission recommends development binding implementation standardised methods checking whether data subjects identified set data methods must allow user conclude reasonable degree certitude data either personal ban presumption rules also accompanied appropriate bans infringement bans cases proves possible identify data subject using formerly anonymous data example result technological developments subject penalty bans would need designed way avoid placing roadblocks way research detection removal links data data subjects repositories data since options available must investigated view developing appropriate anonymisation standards verifying effectiveness addition introduction bans penalties infringement must misused pretext downgrading standards apply anonymisation diluting meaning term personal data used gdpr since companies involved vitally important efforts drive forward technology anonymisation using technical means would otherwise placed competitive disadvantage applies reversal pseudonymisation absence justified reasons list drawn j√∂rg drechsler nicola jentzsch synthetische daten innovationspotenzial und gesellschaftliche herausforderungen synthetic data potential innovation societal challenges stiftung neue verantwortung may available synthetic data distinction made genuine data synthetic data data generated artificially rather collected directly real world synthetic data boast several advantages data firstly produced quantity particularly important dealing simulations data generated secondly steps taken synthetic data created ensure entire range values mapped comprehensively possible order test technical system would behave confronted unusual data combinations thirdly quality synthetic data measured necessary guaranteed individual cases properties set reference data retained alternatively distortions occurring sets data pinpointed removed order avoid discrimination set synthetic data contains references persons anonymous fall within scope gdpr data ethics commission recommends federal government support research field synthetic data number different issues including question whether extent contexts synthetic data might replace realworld data processing operations closely synthetic data resemble data terms properties data ethics commission recommends investigations creation use synthetic data particular emphasis topics including data quality avoidance bias discrimination improving controlled access personal data controlled data access data management data trust schemes privacy management tools pmt personal information management systems pims ever complex environment one major challenges faced individuals exercising data rights lack oversight personal data data subjects typically records documenting times granted consent example sharing data original data controller also result scattering data significant decrease transparency corresponding increase data protection risks data subjects see section regarding problem data trading currently enough standards software tools data subjects use track control ongoing basis granted access data transferred would necessary exercise data rights effectively increasing number technical institutional measures proposed response problem privacy management tools pmt range applications make consent management easier users dashboards etc tools automatically implement individual user preferences data agents focus much provision technical applications rather service end common use term personal information management systems pims services range single services local data safes online storage systems offers comprehensive less management user data data trust models designed data trust models pims may support digital selfdetermination shouldering responsibility exercising data subject rights data protection law granting withdrawing consent exercising right information right rectify data right erase data right data portability right object data ethics commission recommends federal government promote innovation standardisation relation software tools services kind need regulation notwithstanding privacy management personal information management systems may pose risks fail comply certain requirements beyond scope gdpr tools systems fail properly designed example risk data subjects empowered exercise true instead unwittingly find path external determination particular privacy management personal information management systems designed way data subjects write blank cheque handing majority decisions operators result data subjects taking decisions contrary interests influence would ultimately inconsistent ethical value privacy management information management systems must available aids data subjects must usurp power latter take decisions must certainly manipulate using dark patterns see section part ata given significant risks systems tools may pose fundamental rights lack options data subjects carry quality assurance measures data ethics commission recommends federal government develop quality standards privacy management information management systems introduce certification monitoring system latter apply particular systems act behalf place data subject result technical design play major role steering channelling data subject decisions cases data stored directly operators stored decentralised basis simply managed also possible provision must also made company insolvency liquidation privacy management information management systems operate reliably cooperation part relevant controllers guaranteed possibility achieve wideranging coverage required imposing legal obligation applies appropriate conditions controllers within meaning gdpr view ensuring access personal data monitored information relevant terms data protection reaches effectively protect data subject interests relation personal data approach social networks example might realistic option start view data ethics commission systems kind could either operated basis without involvement commercially motivated actors charitable foundations similar independent bodies organised enterprises provided operator derives profits managing rather using data either case fiduciary duties owed data subject must precisely defined legislation involvement parties conflicting interests must ruled appropriate opportunities oversight must built system whole minimise bias discrimination privatesector option chosen also necessary ensure operator commercial motivations undermine role plays custodian data subject interests operators access personal data based european union data ethics commission recommends federal government lobby appropriate amendments gdpr form clearer legally secure framework privacy management information management systems steps also taken addition action legal matters relating mandates etc prevent excessive centralised storage personal data since arrangements kind increase level risk data subjects event cyber attacks similar incidents machineinterpretable formats communication protocols must standardised automated execution services improving controlled access personal data potential interface data economy provided appropriate regulations adopted privacy management information management systems could also serve dual function one hand might help individuals exercise right informational effectively verify compliance limitations use imposed hand however could also used release data confines data silos allow used within european data economy particular exercising right data portability granted article gdpr main idea underlying privacy management personal information management systems improve individual control personal data promote data access indirect data access function might however compatible principle underpinning data trust schemes third parties allowed access data pursue certain purposes approved data subject connection research example see section economic exploitation data served data subject interests took place express consent see section discussion problems raised treating personal data economic asset data ethics commission believes decided privacy management information management systems play dual role also serve platform legally secure data access companies must ensured qualified ultimately subvert goal protecting data subjects rights strict compliance principles privacy ethics design must enforced particular objective pursued must broadest possible exploitation scattering data data ethics commission wishes emphasise fact privacy management information management systems must continue serve dedicated custodians data subjects interests conflicts interest must ruled part ata data access data portability promotion data portability right data portability granted article gdpr tool data subject use determine whether companies gain access personal data another company already collected companies includes right receive data provided structured commonly used machinereadable format transmitted directly another controller right data portability two main implications prevents unwanted effects data subjects switch providers thereby protecting individual data subjects right economic selfdetermination free competition even data subjects switch providers allows ask controller make data available either companies provides companies option gaining access data might otherwise available bearing mind need separate legal basis data processing data protection law consent contract example debates requirement separate legal basis kind data protection law see article data protection working party guidelines right data portability rev last revised adopted april available fact providing data structured commonly used format basic prerequisite must met order data subjects exercise right data portability effectively date requirement subject enormous range varying interpretations practice data ethics commission therefore recommends federal government data protection authorities implementation recital gdpr support development industryspecific codes conduct standards european level right data portability realised uniformly effectively practice benefit parties involved absence new intermediaries see section stimulus exercise right data portability often stems company gained new customer companies offer convenient automated process data subjects exercise right data portability likely particularly successful provider map service allows data ported mobility service provider click button also grounds assuming view potential network effects effects scale companies likely benefit right data portability least medium term already hold dominant position market accumulated huge amounts data data ethics commission therefore recommends federal government observe developments closely far judges necessary lobby european level measures specifically encourage facilitate porting data companies market participants including improving controlled access personal data scope right data portability extended debates ongoing whether scope right data portability extended various ways particular expanding cover data raw data provided controller certain forms processed derived data widening include right dynamic portability streaming data flows things currently stand recommendation data ethics commission proposes federal government lobby amendments gdpr aimed extending scope current right portability given gdpr force short period time wait see approach instead adopted clarity gained practical application supervisory practice data protection authorities interpretation courts portability interoperability interconnectivity network effects case messenger services mean data portability alone sufficient mitigate risks posed existing future data service oligopolies lower barriers market entry new competitors extent represent serious challenge providers data ethics commission therefore recommends federal government push introduction interoperability obligations sort previously imposed postal services mobile telephony example time measures must taken ensure interoperability features comply data protection principles default settings examples include option use different changing identifiers instead single universal identifier reduction use central components collect large volumes data suitable examples interoperable technical interaction different interoperability obligations could imposed powerful companies new market entrants respectively example provider messenger services might obliged allow customers smaller providers send messages directly customers allow customers send messages directly customers smaller providers time however must ensured interoperability requirements abused purpose increasing yet flow personal data towards powerful companies risk reliably averted would useful impose certain interconnectivity obligations short messaging services social networks view counteracting concentration effects networks promoting aims data portability effectively healthier competition easier access new market entrants economy model kind also prerequisite building strengthening certain basic services information society europe thereby promoting digital sovereignty germany europe part ata crowdsensing public good crowdsensing also hailed way opening new data resources data society data economy order deploys users technical devices form sensors collect data certain locality example forward instance analyses collected data data ethics commission acknowledges potential inherent technology especially put use public good example crowdsensing used smart city analysis traffic conditions state repair infrastructure air quality time however data ethics commission believes achieving ethically appropriate design significant challenge analysis carried using crowdsensing techniques typically extremely high level granularity meaning data involved may fall category sensitive perspective individuals generated certain circumstances also perspective anyone vicinity efforts must therefore stepped introduce standards anonymisation pseudonymisation see section view preventing situations data traced back users potentially persons affected also forms misuse data transfers may also overstrain resources users devices raise security must given points even users participate voluntarily intentionally crowdsensing programmes participatory sensing thought must therefore given substantive limitations consent exist connection see section even data used purposes serve public good must always ensured requirements outlined legislation particular data protection law consumer protection law complied full case also remembered decisions measures taken government agencies must based solely customarily data collected using participatory sensing techniques since data necessarily incomplete owing voluntary nature participation likely also exhibit bias data ethics commission believes discussion whether crowdsensed personal data collected forwarded compiled without user knowledge opportunistic sensing ignores potential measures violate fundamental principles data protection believes decisions must taken basis whether legal obligation justifiably imposed force data subjects make available technical devices data devices collected forwarded automatically extent analysis data promotes vital public interests summary important recommendations action improving controlled access personal data data ethics commission identifies enormous potential use data research purposes serve public interest improve healthcare provision data protection law currently stands acknowledges potential principle granting privileges processing personal data research purposes uncertainty persists however particular regards scope research privilege secondary use data scope counts research context product development data ethics commission believes appropriate clarifications law necessary rectify situation fragmentation data protection law within germany among member states represents potential obstacle datadriven research data ethics commission therefore recommends regulations harmonised federal land level different legal systems within introducing notification requirement specific national law could also bring improvement could establishment european clearing house research projects case research involving particularly sensitive categories personal data health data guidelines produced information researchers obtain consent legally compliant manner innovative consent models promoted explicitly recognised law potential options include development digital consent assistants recognition meta consent alongside endeavours clarify scope research privilege secondary use data data ethics commission supports principle move towards learning healthcare system healthcare provision continuously improved making systematic use health data generated basis keeping principles medicine progress made direction however greater efforts must made time protect data subjects significant potential discrimination exists sensitive categories data used might involve prohibiting exploitation data beyond defined range purposes part ata development procedures standards data anonymisation pseudonymisation central efforts improve controlled access formerly personal data legal presumption compliance standard achieved data longer qualify personal appropriate safeguards provided respect data subject rights would improve legal certainty long way measures accompanied rules pain criminal penalty prohibit anonymised data new technology becomes available would allow data subjects reversal pseudonymisation absence narrowly defined grounds also research field synthetic data shows enormous promise funding funnelled area fundamentally speaking data ethics commission believes innovative data management data trust schemes hold great potential provided systems designed robust suited applications compliant data protection law broad spectrum models falls heading ranging dashboards perform purely technical function privacy management tools pmt right comprehensive data consent management services personal information management services pims underlying aim empower individuals take control personal data overburdening decisions beyond capabilities data ethics commission recommends research development field data management data trust schemes identified funding priority also wishes make clear adequate protection rights legitimate interests parties involved require additional regulatory measures level regulatory measures would need secure central functions without operators active since scope action would otherwise limited hand also necessary protect individuals parties assume acting interests reality prioritising financial aims interests others event feasible method protection found data trust schemes could serve vitally important mediators data protection interests data economy interests far right data portability enshrined article gdpr concerned data ethics commission recommends codes conduct standards data formats adopted given underlying purpose article gdpr make straightforward change provider also allow providers access data easily important evaluate carefully market impact existing right portability analyse potential mechanisms prevented small number providers increase yet market power findings evaluation available expansion scope right example cover data data provided data subject porting data would seem premature advisable certain sectors example messenger services social networks interoperability interconnectivity obligations might help reduce market entry barriers new providers obligations designed asymmetric basis stringency regulation increase step company market share interoperability interconnectivity obligations would also prerequisite building strengthening within europe certain basic services information society debates around access non data debates around access data data economy play key role future competitiveness german european companies growing penetration internet things iot internet services ios means data collected automatically sensors potentially serve basis developing new business models innovations acquiring evergreater industrial significance germany cutting edge developments far many technologies concerned sensor technology mechanical engineering embedded systems also plays leading role broader field industrial production digital services cater sector given increasingly nature international competition must build head start order safeguard country future prosperity differentiated robust research landscape diversified economic structure reputation global leader key technological segments industry put germany perfect position leverage potential associated data economy basis creating future value appropriate data access macroeconomic asset data ethics commission believes providing appropriate access data german european companies decreasing current level dependency small number data oligarchs would long way towards building data economy serves public good towards strengthening digital sovereignty germany europe connection data access narrower sense firstly relates extent data required particular business model project used jure facto basis order benefit access data narrower sense however stakeholders must sufficient degree dataawareness data skills necessary make use data also access data proves disproportionately advantageous stakeholders already built largest reserves data best data infrastructures hand data ethics commission therefore wishes stress factors referred always receive due attention discussing whether improve access keeping asisa principle awareness skills infrastructures stocks access discussions section focus data genuinely data hold enormous potential science economy society yet potential often underestimated scientific data categorised include data originating technical sciences engineering materials science data fields physics data particle accelerators biology data plant animal kingdoms geology chemistry environmental data weather data ocean data right economic data data financial markets analysed using big data methods example used develop applications example data hold enormous value science economy society focused support must therefore provided researchers using data systematic efforts must undertaken make data access easier task broad nature gdpr definition personal data means safely assumed substantial proportion data repositories mixed nature contain data data could become personal time processing personal data vital prerequisite certain activities fall heading data economy provide benefits individuals general public discussion data access concentrates solely data would therefore appear appropriate approach would work towards general data access arrangements superseded data protection law cases personal data processed meaning activities falling heading data economy would need comply provisions gdpr equally forgotten gdpr already allows economic exploitation personal data many circumstances addition consent example article gdpr five additional justifying grounds article explicitly tailored economic interests needs part ata creation necessary framework conditions awareness raising data skills use data create value presupposes operators whether belong private sector serve public interest adequately relevant options risks also data skills required may involve drawing technical economic ethical legal knowledge see part section certain areas german economy companies still tapped potential exists make productive use data flows repositories cases benefit public data ethics commission welcomes steps taken raise awareness build digital skills various stakeholders chambers industry commerce associations vocational institutions approach improving data skills across board however required example form initial continuing training courses objective courses must always raise awareness risks posed individuals society viewpoint data protection law ethics government bodies slow recognise import implications huge volumes data already generated statistical purposes example advantages risks entailed models share data businesses data sharing businesses share operating data data sharing current reticence part public authorities utilise opportunities means shift mindset required modelled forerunners field scandinavian countries estonia data ethics commission also recommends federal government support work area relevant research building infrastructures needed databased economy although germany continues occupy leading position field science technology research tech companies providing vital data analysis infrastructures new digital economy primarily hail usa increasingly china means great deal european data consumer data enterprise data research data stored outside europe analysed third countries using software belonging companies makes crucially important germany develop economy using infrastructures data ethics commission recommends federal government support following measures european level initiated european commission establishment expansion support centre data sharing development model contracts data economy support forums consortiums tasked developing open standards legally compliant data exchanges particular formats programming interfaces apis tailored data exchanges increase traceability data flows promotion european platforms legally compliant data exchanges establishment european open science cloud eosc key precursors achievement digital sovereignty germany include access control sensitive data option carry appropriate audits critical data analysis software would require manufacturers disclose source code design criteria example given ethically problematic nature analyses wherever possible carried within geographical purview german legal system debates around access non data data ethics commission expressly welcomes number initiatives federal government stakeholders aimed creating secure international data spaces spearheaded germany different application domains allowing companies organisations sizes sectors industry retain sovereignty data exchange data securely data ethics commission also recommends setting ombudsman office federal level provide assistance support relation negotiation problematic data access agreements dispute settlement competent data protection authorities consulted cases involving personal data power must ultimately rest aforementioned authorities order avoid conflicting decisions establishment data infrastructures federal government initiatives aimed establishing data infrastructures include following efforts german research foundation deutsche forschungsgemeinschaft establish national research data infrastructure aim implement process systematically opens data repositories provides data storage backup accessibility across boundaries different disciplines l√§nder open international data spaces consortium ids formerly industrial data space promoted federal ministry education research aim provide companies organisations taking part standardised interface platform exchanging data based federal architecture concept initiative develop comprehensive network big data centres nodes distributed throughout germany part national generally accessible ecosystem aim network provide access large amount variety data basis time offer tools along entire data value creation chain preparation analysis visualisation exploitation develop basis user addition technical platforms interesting developments include platforms developed federal government collaboration associations view promoting coordinated research development standardisation practical implementation applications form socially economically innovative future projects industry smart service world learning systems european level european commission implementing similar projects futureoriented fiware project currently developing freely available toolbox software components used configure innovative internet services short space time big data value partnership organised european commission big data value association bdva developed interoperable ecosystem european level launchpad new business models using big data already delivered impressive number flagship projects lastly european institute innovation technology eit digital fostered emergence technical economic ecosystem involving companies research institutions part ata sustainable strategic economic policy far data economy concerned biggest challenges facing europe include lack sustainable funding often problem research projects paucity venture capital latter required make ideas already developed marketready inject capital appropriate points reach competitive size one reasons usa successful field digital products services country many angels willing invest billions projects many cases forfeit investments another trend worth noting innovative companies often bought foreign companies forced international investors move headquarters countries outside europe thinking outside box european path explicitly endorsed data ethics commission see part german must given access larger pool funding better tax incentives germany continue attract brightest best remain cutting edge sectors education public administration medicine characterised high level public interest existence mandatory values expressed legal system professional ethics time enormous potential achieve efficiency gains digitalisation sectors global platforms yet gained stranglehold market extent areas data ethics commission therefore recommends public funding channelled three areas particular used incentivise development platforms germany reflect values also internationally scalable solution endorsed preliminary drafts february october principles data economy see footnote improved industrial property protection also perspective data economy data ethics commission see benefit introducing new exclusive rights data often discussed using terms data ownership data producer right see section rights kind would need incorporated aligned existing provisions data protection law intellectual property law rules right personality trade secrets ownership rights storage media would nothing increase already significant level complexity legal uncertainty without clear indication rights kind would necessary even particularly helpful making data marketable data ethics commission nevertheless believe calls made industry government bodies afford limited effects contractual agreements restrictions data utilisation onward transfer data recipient justified legal situation currently stands thirdparty effects kind afforded extreme situations unless protection intellectual property rights law applies including sui generis protection databases consideration given extending scope recognition effects along lines model provided article trade secrets directive directive according approach acquisition use disclosure data would also considered unlawful whenever person time acquisition use disclosure knew ought circumstances known data obtained directly indirectly another person using disclosing data unlawfully approach would interests data economy also fit seamlessly existing primarily model debates around access non data data partnerships data ethics commission believes cautious development current legal framework would also appropriate field law breakneck pace developments data economy poses fresh challenges field law return provisions law pose fresh challenges digital companies data ethics commission recommends federal government pay particularly close attention opportunities risks entailed data partnerships consideration given introduction mandatory confidential procedure notifying data partnerships authorities supervisory authorities data protection law case personal data mention also made proposals presented commission experts competition law headings data exchange data pooling data access existing value creation systems context fair efficient data access plays significant role modern value creation systems area law suitable regulating fairly efficiently ability various stakeholders access data commercial context contract law since branch legal system autonomy private entities private autonomy expressed explicitly time general presumption freely negotiated agreements except cases market failure achieve efficient allocation resources thus increase general level prosperity unfair inefficient contractual arrangements may arise however result imbalances power information asymmetry example certain issues relating data access typically underestimated negotiation process result skimmed omitted entirely given dynamic nature interests correspondingly dynamic assessment data rights data obligations see section often difficult parties determine exactly data access regime look like order remain fair efficient entire term contract insignificant number cases accordingly found later date contract put test real world balance interests shifted unpredictable ways benefit one party major impact equilibrium rights obligations originally agreed since one parties typically stands benefit new state affairs contracts often renegotiated opportunity regulate data access properly efficiently part ata particularly complex value creation systems frequently direct contractual relationship party requesting access party effectively controls data interposing link distribution chain example interests fairness efficiency however data access arrangements would desirable sector incursions freedom contract form obligation contract currently result almost exclusively provisions law well small number general provisions law case essential commodities monopoly positions generally speaking however restricted small number extreme situations presence contractual relationship estimation data ethics commission steps initially taken view ensuring fair efficient data access arrangements include raising awareness promoting digital skills see section practical support form model contracts provide fair distribution data access infrastructures intermediaries facilitate shared data use ensuring protection trade secrets example see section european commission towards common european data space com final april available cases contractual relationship already exists principles fair data access enforced primarily contract interpretation including way courts example assuming existence appropriate contractual ancillary obligations standard contract terms control pursuant section civil code fairness test however one problems inherent substantive fairness tests virtual absence default provisions used benchmark tests specific abusive contractual practices could therefore spelt explicitly blacklisted contract terms see section corresponding recommendations contracts significant changes occur since conclusion contract may possible party invoke provisions frustration contract section civil code connection data ethics commission wishes reiterate general basic principles governing data sharing formulated european commission communication april entitled towards common european data space basic principles provide following transparency regarding access rights purposes using data recognition several parties contributed shared value creation respect commercial interests undistorted competition minimised data particularly regard repositories potentially include personal data well data consideration could also given expanding principles include right informational selfdetermination data subjects principle harm debates around access non data absence contractual relationship contractual relationship participants value creation system despite support provided neither rules interpretation contracts substantive fairness tests standard contract terms apply also impossible rely frustration view data ethics commission however simple fact party requesting access contributed generation data means special legal relationship exists party party effectively controls data see section true relationship exists within value creation system primarily shaped contracts special legal relationship may give rise certain duties fiduciary nature including duty enter negotiations fair efficient data access arrangements future legal framework make explicit reference fact data ethics commission therefore recommends amending section civil code include new subparagraph mentioning special relationship exists participants value creation system suppliers manufacturers brokers end users would entail certain relevant duties including regard data enormous significance data general legal economic relations means justified grounds inserting subparagraph law rather subsuming relations general heading similar business contacts would neither constitute separate legal basis processing personal data would restrict data protection law way discussion personal data see louisa specht datenrechte eine und sozialwissenschaftliche analyse vergleich deutschland usa teil rechtsvergleichende analyse des zivilrechtlichen umgangs mit daten den rechtsordnungen deutschlands und der usa abidagutachten data rights analysis perspective legal social sciences based comparison germany usa part comparative law analysis data governance civil law within framework german legal systems seqq available discussion data see principles data economy footnote consideration could given introducing rules law obligations based principles referred section aimed judicial use benchmark carrying substantive fairness tests standard contract particular provisions data contracts kind might define conditions parties entitled access data request desistance data access data use request rectification data however data ethics commission also concerned rules specifically spelt law albeit default rules might give rise additional disputes data access rights need identified extensive data access rights within existing value creation systems priority given solutions data ethics commission therefore recommends federal government pay greater attention data access issues adopting revising regulations part ata open data public sector preliminary considerations recently revised directive open data public sector information psi directive national level german information reuse act informationsweiterverwendungsgesetz iwg german act egovg additional special acts provide sound legislative basis disclosure data basis ogd concepts premise underlying concept open government data citizens companies already subsidised generation data taxes pay therefore allowed share associated benefits rather incurring double financial burden making data available reuse private sector also benefits european data economy since open government data often hold enormous potential value creation companies use develop new innovative products services helping increase general level prosperity process looking beyond economy access government data also vitally important democracy open debate involving society since increases administrative transparency facilitates participation allows oversight discussions open government data also used many different shapes forms social initiatives innovations social ecological purposes example basic principle therefore data ethics commission supports open data charter adopted summit defines following central principles governance administrative data open default expectation administrative data made public without compromising right privacy quality quantity timely fully described open data usable anyone much data possible many open formats possible improved governance open data transparency sharing expertise regarding data collection standards publication procedures innovation user consultations support future generations creative minds ethically speaking government body decided provide commercial operators access data instead selling profit otherwise exploiting economic purposes decision would need justified approximated basis corresponding increases prosperity macrosocial level data ethics commission also wishes draw attention degree tension calls privacy default one hand open default broader sense debate data protection debate open government data personal data made public legally compliant manner basis concepts guarantee security mechanisms put place protect right informational form explicit implicit restrictions reuse form technical organisational protection measures continue applied general provisions data protection law concerning reuse also issue furthermore since article gdpr requires categories recipients documented government bodies almost never position monitor compliance appropriate safeguards required pursuant article gdpr disclosure data might point become personal data regarded potentially measure data subjects debates around access non data applying ogd concepts area right informational protected fundamental right must always weighed carefully interests pursued ogd banner right freedom information also protected fundamental right freedom ogd recipients exercise trade profession data ethics commission submits cases doubt priority given state duty protection compliance duty important individuals may able decide freely data entrust government bodies may particularly apt believe government bodies refrain forwarding personal data third parties legal framework infrastructures data ethics commission welcomes federal government national action plan implement open data charter efforts part federal government governments l√§nder include ogd concepts digitalising administrations recommends federal government take action ensure implementation obligation publish structured unprocessed data open default allow data used without limitations principle free charge already applies direct federal administration section act given aforementioned tension open government data data protection obligations imposed section act apply relation certain types data particular undergone effective anonymisation procedures data ethics commission welcomes legislator attempts change data governance culture within administration acknowledges task made significantly challenging highly fragmented nature current legal situation often difficult authorities potential ogd users forge path tangled regulatory thicket made different legal regimes set general specialised rules access data reuse data federal government land level complicating factor interplay regulations data protection law intellectual property rights particular copyright law often fiendishly complex practice connection data ethics commission recommends merging synchronising various legal bases exist germany well clarifying demarcation lines various legal arrangements another obstacle stands way culture change needs take place fact currently impossible verify reliably whether authorities fact complying data provision obligations already force example section act imposes obligation direct federal administrative authorities provide public access data explicitly states parties requesting access enforceable right data made publicly available companies wish access data therefore deprived effective avenues forcing authorities comply statutory obligation making data open default view data ethics commission introduction right request publication data might encourage proactive approach provision open data part administrative authorities within limits placed obligation act information reuse act quality standards must achieved respect data provided government bodies another question left open current legal situation particular act states obligation provide access data met handing unprocessed data data reused easily manner complies ogd objectives high level data quality guaranteed part ata aside legal framework establishment expansion infrastructure framework open government data portals govdata also essential particularly local level form municipal platforms applies investments appropriate quality assurance tools state duty protection keeping mind state duty protect data entrusted appropriate precautions must taken ensure central interests private individuals relating personal data operating trade secrets sensitive data confidential information relating public procurement procedures given comprehensive level protection key public interests security interests interests relating national sovereignty ethical premise underpinning ogd concept citizens companies already paid data tax contributions places certain constraints reuse particular care must taken ensure data used private sector develop services products may ultimately restrict freedom citizens businesses available unfair data ethics commission therefore recommends federal government make use opportunity afforded article recast psi directive developing model conditions standard licences including agreements conditions transfer data third parties alternatively lobby conditions introduced european level may even advisable make model conditions mandatory least basis based number key considerations including following pursuant article psi directive conditions must objective proportionate nondiscriminatory justified grounds public interest objective shall unnecessarily restrict possibilities shall used restrict competition rules imposed companies contain clearly defined safeguards rights affected mechanisms allow compliance rules verified intellectual property developed using data must used disallow activities carried government bodies fulfilment public remit make activities subject payment licence fee product service developed using data offered government bodies preferential conditions companies large market share subject reciprocal obligation make data generated operations available identical conditions data used business activities take place minimum product service development processes take place debates around access non data basic principle compliance agreed safeguards restrictions use longer reliably verified data transferred copies data sent recipient stored infrastructure controlled latter given duty incumbent upon government bodies protect data may used harm third parties public even harm would possible data linking data data sets special consideration must given model government bodies allow supervised data access supervised processing data infrastructures control costs incurred connection passed companies seeking access open data private sector platforms data use operating data generated companies levels german economy course everyday business data enormously valuable innovation particularly combined data generated participants value creation chain german economy already established platforms express purpose linking different types data examples different platform models include merger several different companies gmbh limited liability company operation single company involvement partners proprietary platform operated service third parties various sectors economy increasingly coming around idea shared platforms also common regulatory approaches data data ethics commission believes reasonable assume data use within value creation systems continue organised industrial players basis new market entrants continue find opportunities innovate within landscape since market participants stand benefit working together trailblazing develop disruptive digital innovations sharing data end trend companies club together establish platforms modelled along various lines welcomed allows build industrial already exists europe fosters data use including higher standards data protection information security data ethics commission proposes federal government lend support emergence increasing number platforms view achieving necessary market size effects scale allowing german businesses harness shared strength compete international stage additional incentives voluntary data sharing already large number business models based private providers voluntarily allowing public access data example example one case point geoinformation industries take basic geodata cases official sources enrich information allowing users access specialist geodata wide range purposes examples include map services openstreetmap google maps feature purely topographical administrative information also wide range interesting details also tailored offerings weather forecasts traffic predictions part ata data ethics commission recommends voluntary data access arrangements kind supported addition practical support measures recommended section consideration therefore given additional incentives voluntary data sharing example data transfers releases open access strategies favourably viewed tax legislation procurement law making grant awards either inside outside research sector carrying authorisation procedures voluntary data sharing data transfers releases open access strategies however envisaged fields referred risk infringing confidentiality requirements procurement law operating trade secrets provisions data protection law result statutory data access rights way contrast debate voluntary data sharing main idea underpinning discussion statutory data access rights society get something back large repositories data many members society helped build case social networks example viewed conjunction fundamental value social solidarity interests may relevant specific cases concept could serve basis granting extensive rights respect data access disclosure obligation part private details see viktor thomas ramge das digital english title reinventing capitalism age big data seqq frand fair reasonable test features several international agreements basis assessing whether exemption limitation copyright represents acceptable encroachment copyright holder rights according test exemptions kind subject three conditions may apply certain special cases may conflict normal exploitation iii may unreasonably prejudice legitimate interests right holder calls increasingly made test include mandatory consideration interests general potential measure often discussed context improving general access privately held data repositories introduction general right portability data modelled along lines article gdpr would mean business supplied raw data controller would right request controller make data available business commonly used format ask controller forward directly third party reasons essentially similar cited arguments extension scope article gdpr section data ethics commission recommends federal government initially adopt approach developments relating use interpretation article gdpr complexity issue exacerbated yet fact issue proper allocation portability right equivalent data subject regard nonpersonal data would raise head range measures ultimately synonymous statutory data access rights also discussed view improving general access privately held data repositories potential options respect include statutory obligation publish reports containing internal data analytics access rights private individuals mandatory licensing complies principles incorporates test copyright disclosure data general public open access based either general model model data ethics commission believes least following factors taken account initial examination options debates around access non data need protect personal data operating trade secrets access may given may disclosed need ensure encroachment fundamental rights private entities affected data access disclosure obligation proportionate relates particular freedom exercise trade profession need avoid negative impacts competition resulting access data disclosure data example owing strategic use competitors may obliged disclose data return need ensure incentives still exist invest business models data economy need protect strategic interests german european companies face global competition particular consideration must given whether companies would still able compete effectively international stage forced provide access data repositories digital giants already stand head shoulders companies terms data proficiency data infrastructures particular volumes data hold exploit policy regard data ethics commission recommends preference given approach far spatial information concerned inspire directive provisions transposing national law already set sectorspecific data access rules rules apply government bodies however one first privateenterprise applications data access right found payment services industry data ethics commission proposes steps jacques cr√©mer montjoye heike schweitzer competition policy digital era special advisers report european commission seqq available new competition framework digital economy report commission competition law september available taken identify level demand implementation options number selected industries example media mobility energy sectors role competition law although framework competition law currently place contains almost provisions relating data general thrust also applies data economy example essential facilities doctrine efd used slightly modified form necessary company holds exclusive control resource crucially important competition neighbouring market aftermarket doctrine relates cases effects mean consumers primary product unable exercise full freedom choose secondary market market parts provider secondary market kind faces yet uncertain legal situation stringent requirements apply amount time money involved relevant procedures means supervisory efforts prevent abuse currently regarded solution data access problems applicable provisions competition law either individually entirety could however act central building block new framework digital economic law one crucial components range solutions data access problems findings commission experts competition law taken account part ata data access purposes thought given whether controllers subject obligation grant access specific subsets data order allow use either bodies certain publicgood purposes scope obligation rights access data belonging private entities obligations disclose data might particularly relevant research sector easier access data might lead general advances science provided access arrangements designed appropriately take due account data subjects rights corresponding access rights data might also make easier ngos media similar institutions deliver social remit thereby helping protect democratic polity particularly priority must also given times averting risks issuing storm warnings view data ethics commission preference given approach tailors design data access disclosure obligations specific requirements constitutional law come play one hand practical circumstances characterise relevant sphere activity health sector mobility sector energy sector regarded particular priorities action respect data ethics commission also calls societywide debate precursor decisions general obligations provide access data connection research projects serve public good data ethics commission wishes reiterate basic principles governing data sharing set european commission communication april entitled towards common european data space european commission towards common european data space com final april seq available proportionality justified clear demonstrable public interest proportionate terms details relevance data protection purpose limitation clearly limited one several purposes assurances data obtained used unrelated administrative judicial procedures harm respect legitimate interests data subjects right informational selfdetermination trade secrets commercially sensitive information exploitation interests acknowledgement public interest goal agreeing conditions data reuse preferential treatment government bodies conditions government bodies reduction overall burden citizens companies data quality management obligation offer reasonable proportionate support help assess quality data stated purposes general obligation improve quality data transparency societal participation respect parties agreement objectives insights best practices basic principles may serve good starting point drafting provisions freely negotiated contracts data exchanges also designing extensive statutory measures improve data access summary important recommendations action debates around access data access european companies appropriate personal data appropriate quality key factor growth european data economy order benefit enhanced access data however stakeholders must sufficient degree data skills necessary make use data also access data proves disproportionately advantageous stakeholders already built largest reserves data best data infrastructures hand data ethics commission therefore wishes stress factors referred always receive due attention discussing whether improve data access keeping asisa principle awareness skills infrastructures stocks access data ethics commission therefore supports efforts already initiated european level promote improve data infrastructures broadest sense term platforms standards application programming interfaces elements model contracts support centre recommends federal government efforts continue matched corresponding efforts national level would also advisable set ombudsman office federal level provide assistance support relation negotiation data access agreements dispute settlement data ethics commission ascribes enormous importance holistically conceived sustainable strategic economic policy outlines effective methods preventing exodus innovative european companies acquisition thirdcountry companies also excessive dependence infrastructures server capacities balance must struck context muchneeded international cooperation networking one hand resolute assumption responsibility sustainable security prosperity europe backdrop global power dynamic also perspective boosting european data economy data ethics commission see benefit introducing new exclusive rights data ownership data producer right instead recommends affording limited effects contractual agreements restrictions data utilisation onward transfer data recipient effects could modelled new european regime protection trade secrets data ethics commission also recommends adoption legislative solutions enabling european companies cooperate use data example using data trust schemes without running afoul law data partnerships part ata data accumulated existing value creation systems production distribution chains often enormous commercial significance inside outside value creation system many cases however provisions data access appear contractual agreements concluded within value creation system unfair inefficient lacking entirely certain cases contractual agreement efforts must therefore made raise awareness among businesses sectors far outside commonly perceived data economy provide practical guidance support model contracts data ethics commission furthermore recommends cautious adaptations current legislative framework first stage process make explicit reference section german civil code b√ºrgerliches gesetzbuch bgb special relationship exists party contributed generation data value creation system controller data clarifying parties may certain duties fiduciary nature duties normally include duty enter negotiations fair efficient data access arrangements consideration also given whether additional steps taken could range blacklisting particular contract terms also transactions formulating default provisions data contracts introducing specific data access rights data ethics commission believes open government data ogd concepts hold enormous potential recommends concepts built promoted also recommends series measures promote shift mindset among public authorities something yet fully taken place make easier practice share data basis ogd concepts measures include establishment relevant infrastructures platforms also harmonisation improvement existing legal framework currently fragmented sometimes inconsistent nevertheless data ethics commission identifies degree tension efforts promote ogd relying principles open default open purposes efforts enhance data protection protection trade secrets legally enshrined concepts privacy default data ethics commission submits cases doubt priority given duty protecting individuals companies entrusted data state often without given choice matter tax information state must deliver duty implementing range different measures may include technical well legal safeguards misuse data debates around access non data particular would beneficial develop standard licences model terms conditions sector data sharing arrangements make use mandatory least basis standard licenses model terms conditions include clearly defined safeguards rights third parties affected data access arrangement provision also made data used way ultimately harms public interests also still greater accumulation data market power part big players would likely undermine competition taxpayer pay twice regards concepts private sector priority given promoting supporting voluntary arrangements consideration must given improvement infrastructures data platforms also broad range potential incentives might include certain privileges context tax breaks public procurement funding programmes licensing procedures statutory data access rights corresponding obligations grant access considered options measures fail deliver desired outcomes generally speaking data ethics commission believes cautious approach taken introduction statutory data access rights ideally rights developed basis sectors level demand analysed include media mobility energy sectors case statutory data access right even disclosure obligation introduced full impact assessment needs carried examining weighing possible implications include implications data protection protection trade secrets investment decisions distribution market power well strategic interests german european companies compared companies third countries data ethics commission recommends considering enhanced obligations private enterprises grant access data public interest purposes cautious approach however recommended respect well part algorithmic systems part lgorithmic systems characteristics algorithmic systems numerous products applications days voice assistants automated lending right autonomous driverless cars based less smart algorithms due many different forms types technical systems take seemed advisable data ethics commission base considerations general concept algorithmic systems see part section key questions presented federal government regarding topics algorithmic prognosis processes well artificial intelligence therefore discussed together questions concerning use algorithmic systems however following distinctions particular must taken account part ethical legal assessment individual algorithmic systems technical perspective different algorithmic systems different characteristics spectrum ranges systems operate completely deterministic basis right systems use machine learning develop action plans independently order achieve goal specified operator algorithmic system algorithmic systems used social informatics systems ethically legally relevant processes established different system levels level pool data used algorithm technical sense right level human individuals involved development implementation assessment correction system purpose consequences using algorithmic systems vary considerably algorithmic systems support replace human prognoses often direct impact individuals rights interests examples include automated lending automated administrative acts however algorithmic systems also used link human indirectly established case example various processes constitute autonomous driving predictive maintenance mechanical engineering systems affect different ethical legal principles depending context used externally visible discernible action autonomous systems example typically raises questions key aspect example debate surrounding use robotics healthcare principles design essential assessment systems algorithmic systems physically embodied similar way conversely often system externally invisible method making decision focus attention discussions may example centre system transparency principle final decision made human accordance article gdpr example automated credit checks however distinction action decision perspectives becomes relative upon closer inspection every visible action system point preceded human decision example construction system every decision impact another system component including human base action characteristics algorithmic systems data ethics commission believes distinctions made particular algorithmic systems closely involved human processes algorithm make decision ethically substantial sense since preferences accord three different levels involvement algorithmic systems human distinguished based specific distribution tasks humans machine based decisions human decisions based either whole part information obtained using algorithmic calculations examples include clinical decision support systems provide doctor treatment recommendations using patient data electronic medical records based assessment scientific literature taking recommendation consideration doctor makes decision together patient treatment option ultimately selected decisions nevertheless subtly yet significantly influence human decisions example algorithmic system collates information contain value judgment user may necessarily aware driven decisions human decisions shaped outputs algorithmic systems way human abilities capacity effectively restricted particular decision made within algorithmically determined prescribed paths one example industry application whereby part interaction robotic system provides human involved production process limited room manoeuvre determined hence fully automated decisions prima facie made independently human fact outputs algorithmic system trigger consequences automatically provision made explicit human decision examples applications range price differentiations fully automated administrative acts known autonomous weapons systems human decisions nevertheless involved sense human must decided use algorithmic system purpose way example differences illustrated algorithmic system used process selecting candidates job algorithmic system simply collates information individual candidates employer question basis employer make decisions constitutes process system lead decisions information provided employer contains evaluation individual candidates example ranking could significantly influence likelihood individual candidates selected actual restriction employer ability make decisions becomes even apparent system already screens candidates advance meaning employer longer even sees applications case selection process notification regarding acceptance rejection application would automatically provided algorithmic system without human ever checking selection part algorithmic systems classifying algorithmic system one three types often difficult hybrids possible within complex software architecture level determination humans point also different depending way system works example process algorithmic system filters individual candidates advance rejects point view candidates filtered remaining overlaps practical operation systems account known automation bias default effects even case decisions humans full authority may tend simply algorithmic system recommendation without carrying sufficiently critical check otherwise would feel uncomfortable need justify decision would get impression risk blamed wrong decision would increase nevertheless fundamental distinction relevant assigning responsibility risk assessment therefore also characteristics algorithmic systems design implementation decision general standards algorithmic systems general standards algorithmic systems general ethical legal principles primarily human dignity see part section constitute benchmark design use algorithmic systems terms principle prospective responsibility intentional unintentional effects users individuals affected use algorithmic system must taken consideration part assessment specific algorithmic systems also necessary think plan social consequences depending intended purpose context use especially regard network effects effects scale effects scope consequences range positive effects social innovations right sometimes subtle negative effects example diversity culture social debate essential condition functioning democracy basis data ethics commission believes following key requirements design use algorithmic systems set terms governance perspective taken must met interplay especially developers companies users state bodies design centre requirement strive algorithmic systems design takes fundamental rights freedoms consideration data ethics commission believes approach must permeate entire design process must ensured means wide range different measures may also particular involve nclusion participation development algorithmic design requires particular taking account changes resulting individual confrontation algorithmic systems gains losses expertise using systems effects people lifestyles formation opinions well physical must taken consideration early system development stage attention also paid emotional state affected individuals may differ directions depending whether humans conventional technology algorithmic systems used significant individual affected decision also user consideration given example fact direct interpersonal interaction fulfils variety functions far beyond good example medical diagnoses supported algorithmic systems accuracy diagnosis identified first foremost intended purpose however need human care contact consultations concerning treatment corresponding significance success treatment strong must disregarded need doctors able contribute medical experience conversely certain situations example case embarrassing symptoms may find comfortable confide primarily another human person part lgorithmic systems functions include example satisfaction basic human need communication feeling principle able assess person line thinking reactions understood person opportunity convince person one point view well certain control effect arising fact human directly confronted reaction individual affected decision example emotional aspects also play major role algorithmic systems used interaction example use system intrinsically intended support employees may perceived employees invasive patronising since system analyses employees behaviour takes certain tasks hands actually come enjoy makes think performance inferior robotic colleague individuals affected technology including example use robotics nursing central guiding value absolutely must taken consideration part ethical approach technology design important note extremely subjective static change depending context time therefore needs constantly reassessed compatibility core societal values depending area application impacts algorithmic systems may relevant society whole example may affect democratic process state action competition future work also digital sovereignty germany development smart systems providers able build business model large amounts data privileged starting position since many applications algorithmic systems depend amounts data data analysed likely correlations findings generated taken together network effects effects scale effects scope typical platform markets market power companies begins strengthen monopolies formed certain threshold reached ultimately enables companies prevent new players entering market interfere forces competition depending area application companies control social opinionforming processes market behaviour order counteract create framework conditions fair competition competition law control mechanisms must readjusted necessary subsequently tightened data ethics commission view individual consequences often handled state bodies legislative measures alone instead need taken consideration phases design use algorithmic systems extent developers companies users shared social responsibility particular corresponding consequences seem likely example case algorithmic systems affect communication people relevant democracy necessary already design process thoroughly assess purposes unintended indirect consequences system question examine extent system affect democracy fundamental rights secondary law basic principles rule law far possible culture incorporating basic principles democracy rule law fundamental rights system architecture established process designing technology general standards algorithmic systems many aspects interplay technology society admittedly still unclear data ethics commission believes research therefore necessary shed light social impacts algorithmic systems develop corresponding strategies limit negative effects sustainability design use algorithmic systems assessment personal social effects algorithmic systems must also global nature limited regard time reason deciding use design algorithmic systems sustainability human skills retention particular must also taken consideration important remaining human control functions principle failure algorithmic systems exceptional circumstances event disaster cyber attacks ensuring innovative prowess future generations development new digital technologies first foremost question basic advanced training well education sense lifelong learning ensuring future generations also necessary general skills limiting training user perspective teaching developing digital skills also promotes social sustainability social framework conditions example institutions procedures must organised way ensure promotion participatory inclusive design algorithmic systems use serve public interest sustainable development also includes ecological dimension irrespective positive contribution algorithmic systems make environmental protection key ethical requirement reducing need electricity certain resources rare earths using sustainability requires perspective looks beyond exclusively economic profits also takes effects consideration commercial success disastrous consequences demonstrated global financial crisis several years ago limit freedom economic activity focus attention responsibility associated economic activity within context social market economy principle prospective responsibility well considerations fairness solidarity must regard sustainability specifically taken consideration design use algorithmic systems case handling data risk assessment crucial importance ecological economic social sustainability design use algorithmic systems high level quality performance algorithmic systems must work well reliably order achieve goals pursued help systems also used promote ethical aims technical legal specifications designed improve develop safeguard state art take ethical quality systems support replace human activities deemed irrespective intrinsic value human activity implementing ethical principles better previously example ethically sound use algorithmic systems healthcare sector firstly requires technology necessary medical quality accuracy assessment findings accuracy diagnosis probability recommended treatment successful success rate medical intervention etc must system used least good view sensitive usage context ideally better conventional technology humans used part lgorithmic systems quality performance improved wide range different measures include example appropriate risk models inclusive participatory possible development standards systemic management control approaches process design aimed continuous improvement entire system role humans part algorithmic system understood ensemble see section must always taken consideration context number algorithmic systems still rely input critical experts perform optimally system design therefore also includes mechanisms help enhance human capabilities prevent counteract reduction skills critical ability readiness reflect example connection automation bias examples productive interaction humans machines also designed ensure skill retention found diagnostic imaging healthcare guarantee robustness security algorithmic systems must robust secure otherwise legitimate goals used pursue achieved achieved expense potential harm ethically legally protected rights interests ethical perspective said robust secure system design appropriate system usage therefore affect respective purposes system need protect data used system result robustness security requirements identical systems specific requirements differ based specific need protection usage context example systems robust secure used control systems pose immediate threat people environment example control emission pollutants industrial plants control robots steer autonomous driverless cars traffic failure could even cause harm important legally protected rights life limb order prevent processes put place define current state art legal rules regulations enacted make mandatory follow state art measures implemented guarantee effective enforcement standards general standards algorithmic systems robust secure system design involves securing system external threats means encryption anonymisation etc also protecting humans environment negative influences system particular systematic risk management approach basis risk assessment must also incorporate phases data processing technical organisational components risks arise technical design also result errors caused human decisions taken using algorithmic systems algorithmic systems way incorporated organisation information technology static management system also required checks ensures effectiveness measures view changing conditions example newly discovered risks minimising bias discrimination prerequisite fair decisions key aim regulating algorithmic systems ensure patterns upon algorithmic systems based systematic distortions bias leading discriminatory unfair decisions first noted biased discriminatory unfair decisions also found conventional technology humans used conversely prejudiced decisions individual humans algorithmic systems however bear danger using system large scale broad impact individual human could never cause mind discussion surrounding bias discrimination algorithmic systems view data ethics commission also seen opportunity detect existing problems existing contexts general achieve better algorithmic system used detect skin cancer trained predominantly patients white skin probability correctly detecting skin cancer therefore significantly higher case patients white skin case patients different coloured skin medical device system would permitted use patients white skin effect would admittedly also noted dermatologist training practised clinical professional exclusively specific cultural environment ultimately cases steps would need taken ensure patients irrespective skin colour receive proper medical care even cases direct intention discriminate developing algorithmic systems discriminatory decisions may still made decisions systematically put certain groups unfair disadvantage particular case machine learning problem rather systems learn models using available data resulting predictions recommendations extrapolate past future whereby existing social injustices obscured incorporation seemingly neutral technology potentially amplified example algorithmic system used assess applications managerial position trained data managers proven relevant company past decades since predominantly male managers employed past decades system trained data set consistently assesses male candidates better equally qualified female candidates part lgorithmic systems keyword bias covers range different types systematic distortions range different causes case human cognitive bias social preconceptions prejudices stereotypes negatively affect process case algorithmic systems bias refer technical reproduction social preconceptions prejudices stereotypes reproduction take place various points primarily within context machine learning often insufficient level representation low number cases social group training data leads distortions whereby specific characteristics group sufficiently recognised development process therefore taken account addition training data used technical methodological decisions regarding target variables labels also lead discriminatory models therefore unfair decisions lastly problems may arise systems actively used practice example algorithmic systems used changing social framework conditions unforeseen usage contexts algorithmic systems directly use categories data legally explicitly recognized highly sensitive gender origin particularly critical point view discrimination direct use sensitive information may depending area application important correct data processing also often permissible within legal limits example many systems diagnosing diseases know patient gender age take account sensitive characteristics may also used within context business decision implementing business strategies example business expanding specific age group occupational group region characteristics define customer segment example simplified acceptance criteria use information indirectly codes sensitive categories however also problematic example household income used information creditworthiness assessments germany average income varies genders result algorithmic system uses household income may incorrectly assess creditworthiness men women involved terms distribution fully preventing discrimination even terms legally recognised categories gender origin difficult within context algorithmic systems furthermore use algorithmic systems lead totally new groups thrown together based coindicing characteristics excluded socially protected rights due certain classification system without cause confronted negative consequences light involved development use system must made aware complex conditional discriminatory effects prevent counteract far possible see section however technical measures designed minimise discrimination limitations even continuous improvement processes used partly different technical fairness targets achieved simultaneously criteria nondiscrimination fairness appropriate context technical social political question accordingly decisions must entrusted technology developers alone instead part future regulation algorithmic systems included operational obligations data controllers prerequisite criteria must decided specifically based context well democratically general standards algorithmic systems algorithmic systems difficult analyse precisely order able detect prevent discrimination data controllers oversight bodies must opportunity gain idea undesirable discrimination effects occur within algorithmic system within context development productive deployment effects identified processes risk assessments output analyses tension specifications limit collection storage discriminatory characteristics concern retain possibility detect discriminatory effects able prove nondiscrimination different requirements must balanced basis may influence tests different phases system development lifecycle standard collation potentially discriminatory therefore sensitive information sole purpose proving result discrimination taking place would justified greater efforts needed produce practical concordance law data protection law transparent explainable comprehensible systems order able carry reliable ethical legal assessment algorithmic system essential enough information available scope functionality pool data data analysis truly transparent system examined determine whether pursuing legitimate purpose transparency principle key functions depending type addressee possible transparency obligations regard public sufficient transparency must created sufficient information available discourse algorithmic systems supervisory authorities oversight bodies must able decide whether legal technical specifications met algorithmic systems used individual citizens must able take informed confident decisions regarding use algorithmic systems event negative effects freedoms rights able assess whether extent wish exercise rights consequence ethical principle digital view increasing complexity systems demand transparency practice confronted fact even experts hardly able individual components system fully look interact comprehend everything within reasonable amount time particular case individual machine learning methods difficult today science technology state input led specific output system also fact even technically simple algorithmic systems often incorporated complex social informatics ecosystems information worksharing processes numerous manufacturers operators involved part lgorithmic systems example visual display personalised online advert result complex processes advert delivered paid basis analysis segmentation particular analytics services used deployed site owners across websites incorporating corresponding program code javascript code tracking components systems also fixed change example manufacturers provide new versions adaptive selflearning systems legal aspects also limit certain forms information disclosure via algorithmic systems source codes hardware designs often protected trade secrets operators also often legitimate interest preventing systems manipulated algorithmic systems process personal data data protection law also limit interest public affected citizens information however transparency requirement regarding system concerns disclosure source code contain personal data data protection law stand way disclosure however complexity refute goal designing algorithmic systems transparent justify lack transparency like aforementioned legal grounds aspects must nevertheless taken account drafting information rights transparency obligations must based legally actually possible principle transparency also requires continuously developing technology make disclosure information easier example use opensource software open hardware developing approaches reduce complexity research also required banner explainable researchers working increasing success producing meaningful findings internal processes algorithmic demand transparency must always take different levels expertise parties potentially interested transparency account example disclosure computer code supervisory authorities carrying necessary checks may make much easier understand system conversely laypersons often need clearly comprehensibly prepared information system basic characteristics enables carry risk assessment suitable everyday purposes time interest seldom limited system order prevent negative decisions future explanation rather also required decision specifically concerning came factors weighting specific drafting specifications transparency explainability based affected individuals level understanding always comprehensible sense rules transparency explainability safeguard citizens capacity act general standards algorithmic systems clear accountability structures control data implies obligation accountable power opportunity control algorithmic systems must also accompanied willingness answer one actions liable necessary complexity algorithmic systems practice make difficult assign responsibility hardware software manufacturers data providers algorithm developers operators individual components clients users either organisation individual employees contribute system components often used change without knowledge control user example result important updates required information security purposes involved often also located different parts world efforts required levels order prevent diffusion responsibility establish accountability structures starting technical design systems right legal specifications example form concept data protection law joint control article gdpr result consideration assessing ethical aspects algorithmic systems practice extremely complex due large number factors need taken account well fact specific area application different individuals may put better worse position said social consequences sustainability aspects rarely unequivocally classified either positive negative however mean humans surrender judgment cases difficult weigh everything everyone required take particular care assessments decisions algorithmic applications may potentially develop phenomenally impressive performance scope questions raised concerning future mankind weighted assessments opportunities risks increasingly reach limits fundamental anthropological ethical discussions required precisely principle prospective responsibility fundamental importance regard democratic process provides ways means balancing conflicting convictions ideally supported special deliberative processes institutions society ensure inclusive participatory way possible challenges presented algorithmic systems addressed part lgorithmic systems rarely case human activity use algorithmic system need weighed latter ethically relevant respects achieves better result humans using conventional technology case however data ethics commission believes use algorithmic systems ethically commanded general ethical preference human activity use machines expense protection important legally protected rights justified view data ethics commission however regard question whether human machine activity preferable see part section factors routinely need taken consideration emotional people human skills retention sustainable development ultimately requires weighing options may favour algorithmic system example use diagnostic algorithmic system specific clinical area leads patients dying whereas patients would die result human misdiagnoses use system would depending circumstances specific case ethically advisable even result minor tolerable reductions patients emotional occurred additional measures would taken ensure human skills taking circumstances account use algorithmic system expense important legally protected rights leads inferior result use conventional technology humans example wrong decisions made increase efficiency convenience use algorithmic systems must principle rejected ethical reasons however ethically defensible exceptions could made case based economic considerations would minimal impairment exceptionally high potential saving would benefit public good recommendation risk regulator approach recommendation regulatory approach regulatory point view fact algorithmic systems need assessed differently ethical perspective depending intended purpose performance robustness security well terms impacts suggests regulatory required follows principle greater potential algorithmic systems cause harm stringent requirements intervention means regulatory instruments risk spectrum algorithmic systems therefore ranges systems application involves low risk right systems could lead irreversible harm individuals society causes risks example inadequate models unsuitable pool data particular case selflearning systems inappropriate basic assumptions weighting see sections potential harm caused algorithmic systems vary nature include financial loss nonmaterial damage physical harm example individual applications cause potentially serious financial loss example lending insurance terms affect opportunities participation example discrimination hiring involve violations fundamental rights risks life health consumers example case robotic nurses mobility applications compare particular tobias krafft katharina zweig transparenz und nachvollziehbarkeit algorithmenbasierter entscheidungsprozesse transparency traceability decision processes studie auftrag des verbraucherzentrale bundesverband vzbv study commissioned federation german consumer organisations vzbv january seqq available sarah fischer thomas petersen deutschland √ºber algorithmen wei√ü und denkt ergebnisse einer repr√§sentativen bev√∂lkerungsumfrage germany knows thinks algorithms results representative population survey bertelsmann stiftung available overarching objective regulating use algorithmic systems prevent detrimental effects individual level particular algorithmic systems affect matters sensitive terms fundamental rights legal provisions concerning design systems also needed regulation strive intervene much necessary little possible order hamper innovation creativity time ensuring protection fundamental rights freedoms values efficient proper regulation help increase public trust use algorithmic systems public perception systems particular controllable adds corresponding scepticism towards data ethics commission takes view primary addressees regulation manufacturers operators algorithmic systems due state direct obligation uphold fundamental rights necessary differentiate however private state use algorithmic systems see section particular regulation drawn detail given model role model character state action federal government advised exercise particular care using algorithmic systems state purposes system criticality system requirements regulatory approach made concrete orienting towards criticality model algorithmic system system criticality based system potential cause harm determined based likelihood harm occur severity harm part lgorithmic systems severity harm could potentially result example faulty decision depends among things significance legally protected rights interests affected particular example right determine use one personal data freedom expression fundamental right life physical integrity well equal treatment extent potential harm resulting infringement furthermore assessment severity potential harm must take account specific sensitivity data used level potential harm individuals groups including harm loss utility hard calculate monetary terms number individuals affected total figure potential damage harm society whole may well beyond straightforward summation harm suffered individuals consequences using algorithmic system based area application considered terms ecological social psychological cultural economic legal dimensions general ethical values principles see part set standard regard assigned value likelihood harm occur also influenced following system properties factors role algorithmic calculations making process mere inspiration humans without claim accuracy algorithmdetermined decisions see section complexity decision made simple deterministic depiction reality probabilistic appraisal reality multifactorial prediction future reality effects decision purely abstractly conceivable context action specific context action direct implementation reversibility effects full reversibility irreversibility likelihood potential harm severity harm may also depend whether state private party taking action particularly economic contexts market power party using algorithmic system due fact state private nature action market power relevant terms obligation uphold fundamental rights potential harm society whole also determine possible alternative options affected affected persons depend algorithmic system example terms access markets goods services criticality increases limitation options due various different causes example network effects effects scale effects scope turn reflected market power lack equivalent alternatives greater system criticality stricter requirements imposed system regulatory perspective requirements formed particular corrective oversight mechanisms specifications regarding transparency algorithmic systems explainability comprehensibility results rules assignment responsibility liability within context development use algorithmic systems see sections recommendation risk regulator approach variety complexity dynamics algorithmic systems pose major challenges regulation based limited toolbox must depending system criticality implement different corrective control instruments different regulatory levels order achieve objectives regulation ensure risks involved systems manageable spectrum possible instruments ranges forgoing special legal provisions soft incentives giving authorities right monitor requiring final decision taken human banning certain intended purposes contexts using algorithmic systems provisions regarding transparency systems explainability comprehensibility results see section key components corrective control regime algorithmic systems also extent criticality system determines scope rights information obligations provide information information requested comprehensibly communicated varies depending addressees system hence also intended purpose usage context ethical legal perspective crucial dealings algorithmic systems responsibility impacts clearly assigned human decisionmakers times rules liability particular also key importance question proper organisation liability regime certain digital products content services must also addressed view criticality system see section terms governance perspective adopted data ethics commission relevant stakeholders state companies developers public must participate specifying drawing differentiated regulatory requirements data ethics commission points even without special regulation use algorithmic systems must measured general legal norms include particular civil liability law fundamentally states compensation mandatory event action infringes legally protected interests provisions existing regulation unfair competition also apply example event consumers misled well criminal law crimes committed help algorithmic systems examining conditions norms criticality systems resulting system requirements also legal significance accordance general standards algorithmic systems used order fulfil specific functions order assess system criticality ethical assessment intended purpose therefore also crucial importance intended purpose ethically indefensible example infringes fundamental rights freedoms breaches free democratic basic order red lines absolute limits algorithmic systems humans example algorithmic system used political manipulation fraud collusive must seen per ethically objectionable part lgorithmic systems intended purposes often multifaceted individual facets particular regarding secondary purposes may need assessed differently ethical perspective identifying intended purpose decisive assessment often sense requires difficult value judgments assessing intended purpose algorithmic systems complicated case digital products development market launch phases increasingly overlap intended purpose product may also change launched market due updates deployment usage contexts complex intended purposes case media intermediaries number media intermediaries search engines essential internet age provide access information online channel flood information actually enable individuals use internet first place extent purposes desirable unproblematic ethical terms however media intermediaries ethically problematic terms specific design systems provide users personalised selection information leads selection displayed content however since result overwhelming majority content displayed displayed lower priority individual spectrum perception narrowed intermediary decides programming user head user sees far business models media intermediaries driven advertising case major social networks risk operators economic interest disseminating also ethically questionable even extremist content promises keep users platform longer thus increasing advertising revenue due interplay sorting narrowing seen additional danger influencing user interests possibility influence exerted example political decisionmaking process could even result political manipulation significant danger free formation opinions basic foundation democracy recommendation regulatory approach criticality pyramid data ethics commission recommends consistently determining degree criticality algorithmic systems using overarching model degree criticality guide legislators society seeking suitable regulatory thresholds instruments also provide developers operators guidance assessing products systems finally also used basic advanced training educate increase awareness amongst various stakeholders extent regard potential algorithmic systems cause harm data ethics commission differentiates private state operators five levels criticality figure criticality pyramid regulatory system use algorithmic systems level zero negligible potential harmno special measuresbeginning specific regulationlevel potential harmmeasures formal substantive requirements transparency obligations publication risk assessment monitoring procedures disclosure obligations towards supervisory bodies controls audit procedures level regular significant potential harmadditional measures approval procedureslevel serious potential harmadditional measures live interface always oversight supervisory institutionslevel untenable potential harmcomplete partial ban algorithmic system ban part lgorithmic systems unproblematic usage contexts normally necessary require developers clients operators specific ethical legal oversight procedures many applications zero negligible potential harm lowest level level criticality pyramid data ethics commission sees need special oversight would beyond general quality requirements apply even products without algorithmic elements example algorithms used drinks vending machine certain potential harm since user could example receive goods lose money however potential harm exceed threshold specific potential harm within algorithm context sufficient rely general mechanisms oblige contractual partners fulfil contractually undertaken performance obligations manufacturers produce devices function case applications potential harm level criticality pyramid regulation implemented however scope necessary measures limited view low level criticality excessive burden manufacturers operators specifically avoided order excessively hinder technological social innovations market development measures could offered level include example controls example form control reason suspect system malfunctioning furthermore obligation produce publish appropriate risk assessment see section addition basis obligations disclose information supervisory institutions including establishing interface supervisory institution carry controls increased transparency obligations well access rights individuals affected see section details may useful codes conduct also considered would developed specifically industry approved competent supervisory authorities compliance would need tested supervisory authorities using spot checks well basis see section criticality case smart mobility applications provider smart mobility applications access data pool generated using vehicle mobility data data used exclusively predicting traffic jams level criticality classified negligible however flow traffic also controlled using smart mobility algorithms example identify route optimum route travelling based overall usage mobility system consisting road rail water air transport determined real time using vehicle data corresponding route suggested user based user preference environmentally etc route however also question whether state stipulate certain routes user consideration criteria view changed potential harm level criticality would higher would therefore require stricter regulation appropriate recommendation risk regulator approach example dynamic pricing example based criteria supply demand however involve personalised pricing potential harm generally low still exceeding threshold relevance example concerning covert discrimination case applications regular tangible potential harm level criticality pyramid specific cases addition mechanisms already required level control form licensing procedure may justified see section account fact many algorithmic systems highly dynamic regular review required event licence price algorithms setting personalised prices setting price based criteria tailored individual customer usually estimate maximum personal willingness pay involve appreciable potential harm example concerning discrimination particularly vulnerable groups best possible use undergone licensing procedure must apply applications significant potential harm level applies levels however additional oversight transparency obligations may extend way publication information factors influence algorithmic calculations relative weighting pool data used algorithmic model comprehensible format required even oversight via live interface provided protective measures prevent harm also necessary differentiated criticality case media intermediaries help algorithmic filtering systems media intermediaries process communicate content relevant formation opinions relevant democratic process content used advertising purchase recommendations entertainment therefore represent perfect example situations use algorithmic system differing potential harm case user interaction consumer goods sector particular advertising purchase recommendations depending personalisation model used low high potential harm soon balanced variety must produced particular case topics relevant formation opinions account overarching interests maintaining free democratic basic order potential harm already higher right outset due content result regulatory requirements change simultaneously case consumption entertainment offerings depending personalisation criteria used usage contexts welfare effects expected less stringent regulation must ensue part lgorithmic systems example algorithmic systems example players huge market share used determine creditworthiness individual consumer company must classified level whether person receives loan decisive bearing person fate high level system criticality also justified market concentration providers tendency lender rely judgment particular player regard system criticality criteria may ultimately worth considering complete partial ban use algorithmic system applications untenable potential harm level ban may also used consequence breaches applicable law system requirements set specific system criticality example lethal autonomous weapons systems often seen red line machines allowed kill people however apply basis killings lethal autonomous weapons simply provide human soldiers support recognising objects merely used keep missile track face crosswinds ethical red line crossed classification algorithmic system criticality pyramid must necessary regularly reviewed light dynamic nature regulation algorithmic systems enshrining horizontal requirements formed sectoral instruments algorithmic systems infiltrating areas personal social lives purposes algorithmic systems areas could potentially used therefore set stone example facial recognition system developed use private photos could also used state investigative authorities law enforcement purposes prevent threats suggests addressing challenges posed algorithmic systems following example data protection law form horizontal regulation legal instrument material scope covers algorithmic systems general applies private public players alike addition considerable symbolic power another point favour horizontal regulation fact gaps protection would eliminated dangerous situations currently foreseen would covered one main arguments favour overarching regulation sets basic principles algorithmic systems also fact citizens would result clear idea expect areas european legislators could complete task within reasonable period time result data ethics commission recommends federal government work towards drawing horizontal basic regulation european level form regulation algorithmic systems addition key basic principles algorithmic systems developed requirements algorithmic systems horizontal legal instrument group together general substantive rules informed concept system criticality admissibility design algorithmic systems transparency rights individuals affected organisational technical safeguards supervisory institutions structures recommendation regulatory approach figure regulation algorithmic systems enshrining horizontal requirements specified sectoral instrumentssektor rules requirementssektor rules requirementssektor rules requirementssektor rules requirementsfederal government european union regulation algorithmic systems key basic principles algorithmic systems general substantive rules admissibility design algorithmic systems rules transparency organisational technical safeguards supervisory institutions union time data ethics commission recommends federal government also advocate sectoral rules european level outside competences within legislative administrative competences enact appropriate sectoral legal acts oriented towards system criticality fig overarching limited basic principles otherwise european legislatory powers would overburdened legislators would rules detailed particular face issue deal general legal instrument wide variety systems almost impossible keep track highly dynamic development technology perspective affected general legal instruments also carry risk administrative obligations also apply cases sufficient potential harm horizontal legal instrument distinguish risky less risky operational aims well potential exceptional configurations level detail reality regard points supplementary recourse legislation would limited terms scope would therefore easier form would relieve burden supplementary approach would also take consideration legislative administrative powers distributed accordance applicable law federal level states bundesl√§nder additional fact regard official oversight supervisory institutions structures various reasons could question consolidating assigning overall task one single authority see section therefore addition necessary enact several legal instruments specific provisions individual sectors potentially harmful situations view data ethics commission combining general basic regulation legal instruments major advantage enabling differentiation different needs protection involved individual systems usage contexts line basic concept behind regulation according regulatory requirements algorithmic systems determined based specific system criticality part lgorithmic systems even data protection law public sector numerous special laws supplement general provisions gdpr different sectors basic idea behind data protection law case automated data processing longer thing inconsequential data hardly possible differentiate meaningfully personal data basis worthiness protection criticality absence common basic rules nonetheless also true variety special provisions ensures increased level protection wide range areas state activity similarly according need supplementary sectoral provisions algorithmic systems application regulation also fall short result fact purpose usage context could change firstly change would especially complex systems inherently limited secondly issue could addressed regulatory perspective fact legal instruments would materially linked original purpose original usage context current functionality system new intended purpose system way changes purpose context would necessary result application differentiated regulatory framework however primarily pragmatic considerations way affect requirement standardsetting body bodies ensure greatest possible coherence legal instruments respective undertakings apply regulatory approaches developed particular notion system criticality rights data subjects regulatory infrastructures processes also designed uniformly possible data ethics commission recommends adopting regulatory approach algorithmic systems principle underlying approach follows greater potential harm stringent requirements intervention means regulatory instruments assessing potential harm sociotechnical system whole must considered words components algorithmic application including people involved development phase example training data used right implementation application environment evaluation adjustment measures data ethics commission recommends potential algorithmic systems harm individuals society determined uniformly basis universally applicable model purpose legislator develop assessment scheme tool determining criticality algorithmic systems scheme based general ethical legal principles presented data ethics commission among things regulatory instruments requirements apply algorithmic systems include corrective oversight mechanisms specifications transparency explainability comprehensibility systems results rules allocation responsibility liability using systems data ethics commission believes useful first stage determining potential harm algorithmic systems distinguish five levels criticality applications fall lowest levels level associated zero negligible potential harm unnecessary carry special oversight impose requirements general quality requirements apply products irrespective whether incorporate algorithmic systems applications fall level associated potential harm regulated basis regulatory instruments used connection may include controls obligation produce publish appropriate risk assessment obligation disclose information supervisory bodies also enhanced transparency obligations access rights individuals important recommendations action regulatory approach part lgorithmic systems addition introduction licensing procedures may justified applications fall level associated regular significant potential harm applications fall level associated serious potential harm data ethics commission believes applications subject enhanced oversight transparency obligations may extend way publication information factors influence algorithmic calculations relative weightings pool data used algorithmic model option regulatory oversight via live interface system may also required finally complete partial ban imposed applications untenable potential harm level data ethics commission believes measures proposed implemented new regulation algorithmic systems enshrining general horizontal requirements regulation algorithmic systems horizontal regulation incorporate fundamental requirements algorithmic sytems data ethics commission developed particular group together general substantive rules informed concept system criticality admissibility design algorithmic systems transparency rights individuals affected organisational technical safeguards supervisory institutions structures horizontal instrument fleshed sectoral instruments member state level concept system criticality serving guiding framework process drafting recommended incorporate debate best demarcate respective scopes regulation gdpr number factors taken account respect firstly algorithmic systems may pose specific risks individuals groups even involve processing personal data risks may relate assets ownership bodily integrity discrimination secondly regulatory framework introduced future horizontal regulation algorithmic systems may need flexible current data protection regime instruments obligations data controllers rights data subjects instruments obligations data controllers rights data subjects order provide individuals groups effective protection dangers algorithmic systems data ethics commission believes transparency requirements see section specifications algorithmic systems view effective protection substantively inappropriate decisions unfair decisions section advisable transparency requirements mandatory labelling key tool creating transparency mandatory labelling mandatory labelling scheme requires little detailed information infringements fundamental rights system operators particular regard business secrets also less serious case access rights data ethics commission believes justifies establishing labelling case critical systems level blanket obligation system operators requestbased right individuals affected due comparatively narrow scope article gdpr relating decision based solely automated processing duties provide information refer data ethics commission believes existing labelling obligations insufficient particular significant impacts affected individuals arise even threshold article gdpr applies decisions situations humans taking decisions run risk accepting algorithmic information proposed decisions without reflection default particular areas human assessment expected following algorithmically determined prescribed paths article article article conjunction article data ethics commission sees authenticity interpersonal communication fundamental condition trustworthy interaction within society mandatory labelling scheme always apply risk confusion human machine therefore apply irrespective system criticality applies example digital voice assistants chatbots days sometimes hard identify labelling may case voice assistants example carried means regular reminder assistant mechanical nature even ongoing communication also use voice conversely data ethics commission considers risk confusion therefore also need mandatory labelling scheme areas nature information irrelevant recipient expects mechanical voice anyway case loudspeaker announcements railway stations duties provide information duties provide explanation access information whilst mandatory labelling schemes require system operators ensure transparency regarding whether extent algorithmic systems used duties provide information rights access regularly focused detailed information regarding mechanism data used algorithmic system part lgorithmic systems duties provide information rights access regarding behaviour algorithmic systems way decisions made inside systems important perspective citizens able understand decisions review reviewed individually help data subjects exercise rights challenge decision informed basis following transparency requirements apply equally private state operators algorithmic systems special requirements regard transparency systems used state covered detail section duties provide information rights access articles gdpr already set duties provide information rights access personal data processed event automated decisionmaking within meaning article gdpr gdpr grants data subject right meaningful information logic involved well significance envisaged consequences data ethics commission takes view case mandatory labelling scheme see section legal concept behind norms also apply outside narrow scope article gdpr integral part suggested see section extent duty provide information depend criticality system case applications negligible potential harm brief statements logic behind decisions suffice example pool data used general weighting certain factors regard result risk system involves extensive duties disclose information essentially article article article sensitive decision terms personality detailed information relating individual case needed however also borne mind providing detailed information regarding factors weighting could also potentially ethically questionable influence private lifestyle data subject furthermore data subject could also use acquired information undermine algorithmic system performs important function technical organisational requirements must met order able fulfil extensive duties provide information must incorporated design algorithmic systems right outset possible ensure systems operated lawfully corresponding necessary meaningful information also provided system used defining duties provide information rights access order increase transparency algorithmic systems care taken ensure special technical skills knowledge required consumers whenever rights access expanded borne mind perspective data subjects increase transparency information prepared way suitable recipient instruments obligations data controllers rights data subjects duties provide explanation least certain areas complex algorithmic systems may appropriate addition general explanation regarding system logic significance require explanation specific reasons system made recommendation decision specific explanation required decision concerns areas sensitive terms personality otherwise particular significance terms fundamental rights socioeconomics important cases data subjects informed comprehensible relevant clear manner data ethics commission therefore welcomes technical efforts improve explainability algorithmic particular systems explainable explicable encourages federal government promote projects data ethics commission believes certain situations worth considering entitlement counterfactual explanations sometimes discussed cases data subjects informed factors process case negative decision would made positive difference would actually led desired outcome case application loan rejected based use algorithmic system data subject would example entitled learn system operator factors taken consideration system would different way application positive outcome however data ethics commission points approach quickly reaches limits case complex systems data subject would provided whole host different counterfactual scenarios order given reasonably complete picture otherwise would danger misinformation questionable steering even manipulation focusing certain aspects strategic educational reasons sandra wachter brent mittelstadt chris russel harvard journal law technology view data ethics commission given current state technical development concept counterfactual explanation therefore suitable use general component regulation algorithmic systems however could considered special processing situations access information directly affected persons addition data ethics commission considers certain sectors individual also social interests affected significant extent advisable even individuals directly affected granted right access information regarding algorithmic systems would apply particular use relevant public major welfare effects population rights would first foremost worth considering journalistic research purposes would also accompanied adequate protective measures affected interests system operators certain circumstances particular event state use systems significant potential harm unconditional rights access information publication requirements also conceivable view data ethics commission part lgorithmic systems requirements defining duties rights particular consideration system operators rights defining duties provide information explanations rights access must always borne mind may also affect legally protected interests operators algorithmic systems well use outputs includes notably protection business secrets interest preventing manipulation systems manipulative use systems private system operators principle invoke fact define decisions contractual decisions based outputs algorithmic system however release monitoring required check whether acting accordance law fundamental right freedom action restricted bans discrimination particular general act equal treatment fundamental rights data subjects third parties general provisions specific contractual provisions legal system furthermore transparency rights must always balanced provisions data protection law relating protection personal data third parties stored system data ethics commission therefore believes appropriate legislators accompany transparency obligations rules initiative system operators also possibly affected third parties enable conflicting rights interests weighed transparency interests data subjects private individuals entitled claim rights however view data ethics commission rigid rules priority example general preference protection business secrets transparency interests appropriate matter concerned despite increase legal certainty might bring system operators third parties invoke conflicting interests meticulous checks must carried see whether interests taken account specific protective measures transparency obligation completely rejected private individuals rights access information requirements regarding protective measures demonstration existence must devised act barrier preventing vulnerable consumers citizens acquiring information interests third parties must protected example means anonymisation risk impact assessment impact assessment within meaning article gdpr concerns information impacts protection personal data however include comprehensive risk analysis algorithmic system case algorithmic systems certain level potential harm however appropriate reasonable legally require produce publish appropriate risk impact assessment order assess risk involved system critical system comprehensive risk impact assessment must also cover assessment risks relating privacy bodily integrity personal integrity well assets property nondiscrimination also include methods gauging quality fairness data model accuracy example bias rates statistical error overall certain exhibited system formation instruments obligations data controllers rights data subjects use case personalised prices transparency requirements increasing use pricing algorithms presents challenges consumer protection law also competition law pricing algorithms review market order adjust prices line demand competitors offers real time providers therefore apply personalised prices individual users groups directly via individual discounts algorithmic systems example used specifically cash consumers maximum willingness pay encourage users abort purchase transaction personalisation based scoring processes example using analyses users surfing habits data collected another way underlying algorithmic systems usually black boxes meaning pool data used logic behind decisions pricing comprehensible outsiders therefore risk price discrimination example relating protected population groups within meaning general act equal treatment potential harm caused implementation higher personalised prices individual consumers vary greatly nevertheless even small price increases individual goods services added together lead significant welfare losses individuals population groups affected particular learning systems may example use signalling also lead high market prices competitors deviously collude prices conditions via algorithms negative effect competition innovative prowess economy ultimately consumers applies intentional use algorithms influence prices also parallel behaviour high prices tacit collusion occur means learning algorithms without specific intention direct undertaken humans would suffice overall high level criticality merely trigger transparency requirements labelling obligations pricing systems comprehensive impact assessment could also help identify discrimination risks algorithmic pricing system pool data used calculate personalised prices known independent experts able check whether correlate protected population groups known proxies whether example women certain religious groups pay higher prices consumers also made aware via labelling obligations prices discounts personalised affected parties could exercise rights access check data used price accuracy potential discriminatory factors transparency regarding factors also important order observe steering effects personalised pricing behaviour individual consumers may scale relevant freedom part lgorithmic systems duty draw documentation keep logs complex dynamic dispersed process individual systems convert input output important regulatory perspective make specific causes particular decision comprehensible errors detected infringements rights penalised effectively one approach better understand processes work record individual program steps digitally use test purposes may required personal data processing accordance data protection law order fulfil accountability requirement firstly requirement document log data sets models used level granularity retention periods intended purposes specified data protection law provide controllers processors greater legal clarity secondly systems significant potential harm level required document log program processes data sets models used described way comprehensible supervisory institutions carrying oversight measures regards origin data sets way prepared example optimisation goals pursued using models requirements algorithmic systems general quality requirements algorithmic systems system operators required standards guarantee minimum level quality technical perspective procedural criteria imposed must ensure algorithmically derived results obtained correct lawful manner purpose quality criteria imposed particular regards mathematical model specific processing methods corrective control mechanisms data quality system security strike balance conflicting fundamental rights software operator subjects decisions requirements validity mathematical models relevance underlying data become stricter potential algorithmic systems cause harm increases case decisions skill sensitivity also built design example deliberately mandating completion certain training modules situations decision assistants used example proven particularly helpful introduce systemimposed role changes certain intervals words assign user task making initial decision sees algorithmically derived proposal attention tests another option albeit one individual user may perceive onerous require detect incorrect decisions computer deliberately interspersed among correct ones therefore also require true nature proposals question identified good time anyone suffers harm instruments obligations data controllers rights data subjects steps also taken ensure improvement processes carried fairly regard interests everyone affected particular attention paid ensuring suitable feedback loops take interests data subjects system operators account regard data quality would also advisable specify extent use estimated proxy data see part section seq permitted forbidden certain areas application addition requirements placed algorithmic system actual processing purpose security requirements also fulfilled design stage individual requirements parties involved taken consideration order ensure appropriate decisions taken part conceptualisation implementation operation although system operator usually main responsibility risk assessment system operator fulfil responsibility access sufficient documentation manufacturer risk impact assessment also needs clarity responsible area areas identified critical data ethics commission recommends setting legal specifications relating standards required security measures taken details regarding conditions manufacturers system operators must design conduct test procedures example identify bias discriminatory distortion consequences case security gaps errors draw documentation functionality tests users receive order able assess risks article gdpr article gdpr article gdpr article gdpr carry system updates within specified time frame report special protective measures use algorithmic systems context human humans must become object technology key principle regulation algorithmic systems particularly pertinent algorithmic systems used order support human decisions automate processes replace human decisionmaking technical processes article gdpr codifies principle applicable existing law certain algorithmic systems fall within scope gdpr one subject decision based solely automated processing including profiling produces legal significant effects concerning unless necessary entering performance contract based data subject explicit consent authorised law fully automated decision permitted data controller must implement protective measures order safeguard data subject rights stricter duties provide information rights access also part lgorithmic systems data ethics commission believes various aspects rules currently require clarification duties provide information rights access connected article gdpr including profiling refer automated profiling individual credit reference agencies example consider subject rules claiming apparently simply conduct profiling decisions made companies example request credit score data ethics commission believes argument sufficiently take intention gdpr account effects data subjects profiling could firstly significant secondly gdpr particularly emphasises profiling data protection authorities courts able apply applicable law appropriate extent means interpretation based protective purpose gdpr welcomed however time given sensitive issue terms fundamental rights democratically legitimised legislator called upon specify legal framework conditions soon order create legal certainty quickly possible data ethics commission recommends federal government advocate part evaluation gdpr clarification specification also needed regarding question decision pursuant article gdpr based solely automated processing personal data scope term similar effect protection rights article gdpr data ethics commission recommends federal government advocate evaluation gdpr scope article gdpr fleshed potential harm caused algorithmdetermined systems original guiding principle article gdpr particular categorically differ many systems particular tendency humans involved simply accept recommendations algorithmic systems exercise discretion plays view fact potential harm systems varies heavily detail data ethics commission believe would appropriate generally broaden prohibitory principle article gdpr particular principle human final pursuant article gdpr suitable algorithmic systems equal measure algorithmic systems decision taken system within meaning current wording article gdpr right final decision made human would often practical also often desirable instead data ethics commission recommends regulatory regime provides individuals appropriate safeguards particular profiling opportunities defend mistakes made rights jeopardised legal notion humans must become mere object technical systems also form central legislative anchor point within horizontal legal instrument see section regulation algorithmic systems data ethics commission recommends within accompanying sectoral legal instruments legal instruments therefore include provisions also set specifications decisionmaking systems outside scope article gdpr far new layer regulation also covers algorithmic systems also fall within scope article gdpr may modified light recommendations made regulatory systems must precisely synchronised instruments obligations data controllers rights data subjects right appropriate algorithmic inferences data ethics commission believes processes involved generation algorithmic inferences supposed interests tendencies character traits individuals particular consumers deserve maximum social political attention digital economy awash inferences characteristic many digital business models geared towards detailed personalisation certain offers services many consumers appreciate convenience offers services however also lead risks inferences made based incorrect pool data results inappropriate contents obtained account inadequacy system components order prevent risks could posed certain algorithmic inferences many want grant data subjects legal right appropriate inferences proposal sets comprehensive package measures would give data subject effective tool monitoring inferences concerning generated operators algorithmic systems addition substantive right subject appropriate inferences sets obligation part system operator without requested information inform individual concerned inferences drawn appropriate reasons case data ethics commission welcomes debate proposal right appropriate inferences triggered however points right could affect constitutionally protected interests operators algorithmic systems view data ethics commission regulatory development proposal take protection aspects consideration example limiting scope systems high level criticality due relevance terms participation fundamental rights omer tene jules polonetsky northwestern journal technology intellectual property seq sandra wachter brent mittelstadt columbia business law review seqq proposal consists material component procedural legal protection discrimination one main aims regulation algorithmbased systems prevent discrimination individual based characteristic set article basic law federal republic germany article charter fundamental rights european union well objectively unjustified discrimination protect personal integrity individuals concerned whilst state bodies direct obligation uphold fundamental rights undertaking kind state activity therefore subject comprehensive prohibition discrimination basis required private actors technical legal starting point essentially german general act equal treatment also serving incorporate according directives german law alongside general clauses german private law example unconscionable contracts discrimination private individuals fall general act equal treatment firstly discrimination must grounds sensitive characteristic race ethnic origin gender religion disability age sexual orientation secondly situational scope must open employment context access goods services including housing available public part lgorithmic systems principle provisions general act equal treatment already cover discrimination algorithmic systems accordance applicable law however matters susceptible discrimination included scope general act equal treatment act cover sensitive situations algorithmically established results trigger facilitate discrimination case mortgage offer based individual risk assessment therefore worth considering example broaden situational scope general act equal treatment include automated processes additionally incorporating individual areas relating algorithmic inferences particularly sensitive terms primarily concerns areas could negative effect person way life consumer contracts drawn based scoring procedures facial recognition methods price discrimination certain areas life healthcare contractual partner general freedom action equally constitutionally protected must also properly taken consideration mario martini juristenzeitung also necessary discuss whether context algorithmic systems legislators remove restrictive reference specific grounds discrimination discriminatory effects algorithmic systems sometimes reflect bias exists within society regard classic grounds discrimination example far bias training data model used would example case system used select candidates trained using data successful managers past overwhelmingly male however potential algorithmic systems discriminate extends far beyond example disadvantage systematically associated group attributes discrimination prohibited law home address specific district correlations determined means pattern recognition really random extent situations already managed form indirect discrimination respect suitable relaxation rules relating burden proof may also possibly required extent however entirely new issues fairness also arise concern distribution opportunities detriment traditionally marginalised communities also exclusion groups thrown together based less coincidental attributes specific characteristics machine learning creating new grounds discrimination however could enormous widespread impacts account fact trained algorithms also used areas application instruments obligations data controllers rights data subjects therefore appropriate consider broadening protection include every systematic objectively unjustified type discrimination based group attribute data ethics commission recommends federal government also examine appropriately adjusting general act equal treatment alternatively anchoring protection future specific algorithm legislation particular regulatory problem fundamentally evergrowing plethora group attributes could lead algorithmic discrimination hence systematic nature would sole criterion differentiating prejudices relevant irrelevant terms discrimination law corresponding regulation substantive protection discrimination would therefore case accompanied one hand corresponding duties disclosure duties state reasons various internal external oversight mechanisms new regulation would provide substantive examination criteria consequences regulation parties involved would case meticulously assessed weighed irrespective issue broadening definition offence thought given whether rules burden proof already sufficiently reflect characteristics algorithmic systems ascertaining indirect discrimination requires neither proof intent discriminate unambiguous proof causality fact injured party prove correlation decisions sensitive criteria algorithmic systems used however proof generally difficult affected parties data ethics commission therefore recommends legislators enact legislation clarifying requirements providing proof discrimination operators algorithmic systems lower requirements affected parties needed reason general act equal treatment always considered together rights access duties state reasons see section without injured party would often unable exercise rights protection interests third parties system users affected result must given sufficient consideration preventive official licensing procedures algorithmic systems case algorithmic systems regular appreciable level even significant potential harm level addition existing regulations would make sense establish licensing procedures preliminary checks carried supervisory institutions order prevent harm data subjects certain sections population society whole teil algorithmische ysteme summary important recommendations action instruments data ethics commission recommends introduction mandatory labelling scheme algorithmic systems enhanced criticality level upwards mandatory scheme kind would oblige operators make clear whether extent algorithmic systems used regardless system criticality operators always obliged comply mandatory labelling scheme risk confusion human machine might prove problematic ethical point view individual affected decision able exercise right meaningful information logic involved well scope intended consequences algorithmic system gdpr respect fully automated systems also situations involve kind profiling regardless whether decision taken basis later line right also expanded future apply decisions differing levels access decisions according system criticality measures may require clarification certain legislative provisions widening regulatory scope european level certain cases may appropriate ask operator algorithmic system provide individual explanation decision taken addition general explanation logic procedure scope system main objective provide individuals affected decision comprehensible relevant concrete information data ethics commission therefore welcomes work carried banner explainable efforts improve explainability algorithmic systems particular systems recommends federal government fund research development area view fact certain sectors society whole may affected well individual members also particular parties individually affected algorithmic system entitled access certain types information likely rights kind would granted primarily journalistic research purposes order take due account operator interests would need accompanied adequate protective measures data ethics commission believes consideration also given granting unconditional rights access information certain circumstances particular algorithmic systems serious potential harm level used state summar important recommendations action appropriate reasonable impose legal requirement operators algorithmic systems least potential harm level upwards produce publish proper risk assessment assessment kind also cover processing data well risks fall heading data protection particular appraise risks posed respect determination privacy bodily integrity personal integrity assets ownership discrimination encompass underlying data logic model also methods gauging quality fairness data model accuracy example bias rates statistical error overall certain exhibited system formation provide controllers processors greater legal clarity work must done terms fleshing requirements document log data sets models used level granularity retention periods intended purposes addition operators sensitive applications obliged future document log program runs software may cause lasting harm data sets models used described way comprehensible employees supervisory institutions carrying oversight measures regards origin data sets way example optimisation goals pursued using models system operators required setting body guarantee minimum level quality technical perspective procedural criteria imposed must ensure algorithmically derived results obtained correct lawful manner purpose quality criteria could imposed particular regards corrective control mechanisms data quality system security example would appropriate impose quality criteria relationship algorithmic data processing outcomes data used obtain outcomes data ethics commission believes necessary first step clarify flesh greater detail scope legal consequences article gdpr relation use algorithmic systems context human second step data ethics commission recommends introduction additional protective mechanisms systems since influence systems settings may almost significant applications prohibitory principle followed date article gdpr replaced flexible regulatory framework provides adequate guarantees regards protection individuals particular profiling concerned options individuals take action mistakes made rights jeopardised consideration given expanding scope legislation cover specific situations individual discriminated basis automated data analysis automated procedure addition legislator take effective steps prevent discrimination basis group characteristics qualify protected characteristics law discrimination often currently qualify indirect discrimination basis protected characteristic case algorithmic systems regular significant level even serious potential harm level would useful supplement existing regulations systems covered licensing procedures preliminary checks carried supervisory institutions interests preventing harm individuals affected certain sections population society whole part lgorithmic systems institutions data ethics commission takes view burden responsibility ethically justified lawful use algorithmic systems must shared rest several sets shoulders institutions supervisory structures currently exist sufficiently prepared effectively oversee monitoring algorithmic systems various levels data ethics commission therefore urges federal government expand reorient competences existing supervisory institutions structures set new institutions structures necessary regulatory powers specialist expertise distribution supervisory tasks within sectoral network oversight authorities data ethics commission recommends federal government principle entrust regulatory supervisory tasks oversight powers case authorities already expertise view data ethics commission apply matters fall within administrative competence states bundesl√§nder specifically data ethics commission believes would make sense entrust oversight use algorithmic systems private parties sectors digital economy authorities sectorspecific responsibility already exist existing authorities examples authorities federal financial supervisory authority bundesanstalt f√ºr finanzdienstleistungsaufsicht bafin federal network agency bundesnetzagentur bnetza federal office information security bundesamt f√ºr sicherheit der informationstechnik bsi federal motor transport authority kraftfahrtbundesamt kba come mind furthermore federal cartel office bundeskartellamt bkarta data protection supervisory authorities would special status horizontal responsibilities responsibilities span various different sectors data ethics commission believes national oversight network critical algorithmic systems set order coordinate activities authorities entrusted algorithm supervisory tasks particular rules distribution responsibilities within network exchange information organisation administrative procedures carried network legal protection would appropriate purposes order prevent gaps supervision data ethics commission urges federation l√§nder identify areas currently authority sufficient expertise oversight tasks could assigned monitoring critical algorithmic systems view data ethics commission cases often appropriate event corresponding need oversight entrust matters one existing authorities horizontal responsibility case algorithmic systems process sensitive personal data data protection authorities example may adequate expertise however data ethics commission believes particular cases may necessary create completely new regulatory control structures light technical developments federation l√§nder regularly review situation authorities faced structural challenge effectively executing algorithmic system oversight tasks object focus oversight work technically highly complex subject dynamic change data ethics commission therefore believes providing authorities practical skills particularly important firmly recommends federal government provide federal authorities financial human technical resources required draft salary structure modernisation act besoldungsstrukturenmodernisierungsgesetz expected increase salaries bonuses publicsector professionals establish new regulations without doubt welcome first step however light difficult attract welltrained professionals public sector measures soon required institutions data ethics commission also recommends federal government set official unit form competence centre algorithmic systems provide sectoral authorities support monitoring algorithmic systems responsibility body acquire analyse develop impart technical methodological knowledge required supervising critical algorithmic systems coordination request authorities also primarily support supervisory authorities building expertise needed carry tasks assess criticality algorithmic systems extend particular centre task developing criteria processes tools oversight algorithmic systems also include standards assessing criticality checking compliance critical algorithmic systems centre competence also important intermediary advisory role far possible advise bodies federation l√§nder municipalities also manufacturers system operators system users data subjects regard use development algorithmic systems also involved international european initiatives designed build sufficient oversight expertise including standardisation procedures however competence centre supervisory powers remain sectoral supervisory authorities service unit either created new autonomous federal authority attached existing authority federal office information security data ethics commission considers would also make sense establish corresponding body european union level future example form agency federal government work towards achieving example article gdpr governs investigative powers relating data protection supervision section german act restraints competition gesetz gegen wettbewerbsbeschr√§nkungen gwb governs sector inquiries federal cartel office oversight trade financial supervisory authorities based section german securities trading act gesetz √ºber den wertpapi erhandel wphg section german stock exchange act b√∂rsengesetz b√∂rsg amended version conjunction section stock exchange principle data ethics commission sees reason state bodies able make use expertise private individuals entities carrying tasks building expertise involve private individuals entities execution tasks long cooperation complies general constitutional administrative specifications applicable cooperation conversely corresponding cooperation example also entrustment may used order deal current lack qualified specialists expertise public sector definition oversight powers according tasks involved regulating body law clearly assign relevant competent authorities powers intervention including rights information rights inspection access required supervision algorithmic systems blueprints regulatory powers content control found various areas competent supervisory authorities must times able examine algorithmic systems sensitive areas application high potential harm audit test procedures used must particular cover systems interaction user may example take place via standardised interfaces access used carry known tests check example whether algorithmic system systematically discriminates groups particularly useful case learning systems adapt internal rules time steps must taken ensure testing learning systems lead change system rules whereby system learns test data test part lgorithmic systems assigning legal authority steps must taken ensure supervisory authorities power event proven breach law force operators algorithmic systems configure systems compliance law example adapting pool data used necessary apply penalties provided commensurate case question supervisory authorities also able impose official bans use unlawful algorithmic systems components extent oversight elements algorithmic system must taken account order behaviour effectively audited audit conducted authorities may potentially must extend training data learning processes used final model well input output data underlying decisions quality indicators regarding pool data used model accuracy training model final decision model also taken consideration order identify system bias rates statistical error overall certain methodological perspective test may carried analysing large amounts data reviewing weighting factors complex multidimensional systems analysing due complex nature subject matter amounts data involved use control algorithms significantly increase efficiency effectiveness audit systematically look conspicuous patterns pool data used results algorithmic system example shed light case extent oversight required specific case determined based area application system criticality case systems potential harm level may suffice legislators limit regulatory oversight inspection results event system documented failure however areas high potential harm may necessary stipulate system operators must use standardised interface view data ethics commission question whether regulatory oversight affects system operators trade business secrets third parties privacy rights issue level criticality pyramid supervisory authorities obliged treat information obtained part oversight work confidential due professional secrecy aspects represent legal obstacle powers full detailed audits proper interpretation test results technical perspective anything trivial particular always clear whether really unearth error algorithmic system restricts ability provide evidence quality informative value different test procedures audits therefore also need agreed particular regard probative value court proceedings order enforce rights parties affected data ethics commission therefore recommends federal government support initiatives develop statistical technical standards test procedures audits necessary differentiated areas application competence centre algorithmic systems see section take leading role endeavours institutions use case personalised prices controls supervisory institutions gesellschaft f√ºr informatik technische und rechtliche betrachtungen algorithmischer entscheidungsverfahren gutachten der fach gruppe rechtsinformatik der gesellschaft f√ºr informatik auftrag des sachverst√§ndigenrats f√ºr verbraucherfragen gesellschaft f√ºr informatik technical legal considerations regarding algorithmic processes report legal informatics expert group gesellschaft f√ºr informatik request advisory council consumer affairs berlin seqq available institutions could check whether algorithmic pricing systems used comply law discriminate example protected population groups within meaning general act equal treatment supervisory authorities could look conspicuous patterns pool data used issued prices may shed light possible case discrimination carrying supervision comprehend potentially highly complex rules underlying algorithm analysing code effective oversight carried help statistical tests analyse things equal issued prices change depending input data associated certain population groups example system issues higher prices consumers gender changed male female input data issued prices correlate attributes protected equality legislation individual population groups example via proxies mathematically statistically corporate neither possible necessary legislator implement blanket regulations covering algorithmic systems instead various models could also essentially provide sufficient responses certain situations involves regulatory approaches navigate state regulation private characterised combination component data ethics commission recommends selfregulation form internal audit conducted manufacturer operator algorithmic system lowest level criticality pyramid could supported manufacturers operators basis specific standards algorithmic systems particular advantage system would bodies would necessary account close connection specific topics result experts even companies question could take legal standards monitoring compliance therewith consideration including development stage necessary also incorporate corporate expertise regulatory mechanisms institutionally admittedly purely internal voluntary would constitute independent monitoring event breaches would ensure effective implementation penalties part lgorithmic systems architecture could supplemented model involving regulated would set external standards quality risk management could also externally monitored similar system set gdpr article establishes option specify general clauses gdpr make applicable specific circumstances significant parties subject codes conduct well set minimum standards specific sector question order able guarantee regulation would effective intended effective monitoring must ensure actual compliance approved codes conduct pursuant article gdpr would codes conduct drawn procedural rules relating monitoring control implementation penalties cases would also set provider signs voluntary verifiably demonstrates compliance agreed procedures body may grant privileges terms supervisory measures approach would based condition exercising corporate responsibility cooperation private body providers would develop procedural standards would recognised supervisory authority involvement civil society organisations preparatory work would essential order able properly represent interests citizens consumers take consideration mario martini juristenzeitung creation code conduct concept regulated would worth considering including algorithmic accountability code adopting comply explain approach parts legal system could oblige parties subject regulation state whether extent following recommendations false statements would subject sanctions code drawn could binding nature holding companies authorities responsible consequences use algorithmic systems could example developed based corporate digital responsibility guidelines see part section conversely also help shape guidelines level granular detail codes guidelines practical ethical challenges specific code would useful become clear quality defined requirements framework conditions opportunities independent external parties carry checks ability impose penalties event breaches would essential ensuring code control function responsibility developing code assigned independent commission equal representation manufacturers operators scientific community civil society remains seen whether government commission german corporate governance code regierungskommission deutscher corporate governance kodex could model addition alternatively binding statements manufacturers operators algorithmic systems could considered institutions quality seals algorithmic systems establishing quality seals algorithmic systems sensible order support effective algorithm regulation could take form voluntary mandatory evidence protective measures would make extent algorithmic system meets certain requirements clear users would important clarify would define requirements quality seal would specifically responsible fulfilling requirements connected quality seal extent breaches would subject penalties case algorithmic accountability code responsibility defining requirements quality seal entrusted independent commission equal representation operators algorithmic systems scientific community civil society contact persons algorithmic systems companies authorities companies authorities work critical algorithmic systems level least starting certain size company authority appoint contact person responsible communications authorities cooperation cases must ensured contact person specific expertise monitor use algorithmic systems internally provide company authority management team advice functionally independent case data protection officers contact person could act link supervisory authority operators algorithmic systems affected groups people would also help ensure proper awareness problems within companies authorities increase oversight pressure involvement civil society stakeholders order ensure interests civil society affected companies properly taken account part audits algorithmic systems advisory boards set within competent authorities civil society stakeholders also example involved connection code advisory boards feature balance representatives civil society organisations individuals appointed companies order ensure interests affected individuals groups interests affected companies properly taken account part audits technical standardisation view data ethics commission standardisation organisations ieee ietf itu etsi cen din set technical standards information communications technologies could significantly help forming requirements algorithmic systems technical standards take ethical legal requirements consideration could provide legal certainty companies develop use algorithmic systems could also easily translate requirements legality algorithmic systems specific guidelines individual sectors data ethics commission believes technical standards would essentially useful tools bridge gap classic state regulation purely private therefore recommends federal government suitably work develop adopt technical standards designed prevent risks posed algorithmic systems part lgorithmic systems however view data ethics commission federal government also lose sight fact technical standards limitations see part section technical standards substitute defining clear legal requirements algorithmic systems regulatory supervision use systems constitutional reasons principle citizens fundamental rights affected detailed legal provisions must upheld practice means legislators must first define legal framework technical committees least ensure integrity protected active participation representatives sectors affected companies ensure addition impressive technical expertise interests companies sectors course also often taken consideration first hand technical standards drawn institutional legal protection particular rights associations file action system granting competitors competition associations consumer associations right file action important feature german legal landscape many years could play key role civil society oversight use algorithmic systems particular private rights kind allow civil society players legitimate mandate enforce compliance legislative provisions area contract law fair trading law without needing rely authorities take action without needing wait individuals authorise civil law approach particularly strong market focus characterised swift responses therefore international standards successful associations essentially politically administratively independent therefore advocate authority common interest consumers companies competition regulations consumer rights efficiently protected unfair business practices also damaging comply regulatory provisions potentially benefit unfair competitive advantage order prevent competitive edge gained breaking law competition associations consumer associations able stop legal infringements summary important recommendations action institutions data ethics commission recommends federal government expand realign competencies existing supervisory institutions structures necessary set new ones official supervisory tasks powers primarily entrusted sectoral supervisory authorities already built wealth expert knowledge relevant sector ensuring competent authorities financial human technical resources need particularly important factor respect data ethics commission also recommends federal government set national centre competence algorithmic systems centre act repository technical regulatory expertise assist sectoral supervisory authorities task monitoring algorithmic systems ensure compliance law data ethics commission believes initiatives involving development technical statistical quality standards test procedures audits differentiated according critical application areas necessary worthy support test procedures kind provided designed adequately meaningful reliable secure may make vital contribution future auditability algorithmic systems opinion data ethics commission particular attention paid innovative forms regulation alongside complement forms state regulation recommends federal government examine various models selfregulation potentially useful solution certain situations data ethics commission believes option worth considering might require operators law inspired comply explain regulatory model sign declaration confirming willingness comply algorithmic accountability code independent commission equal representation must free state influence could set develop code kind would apply binding basis operators algorithmic systems appropriate involvement civil society representatives drafting code must guaranteed part lgorithmic systems voluntary mandatory evidence protective measures form specific quality seal may also serve guarantee consumers algorithmic system question reliable time providing incentive developers operators develop use reliable systems data ethics commission takes view companies authorities operating critical algorithmic systems obliged future appoint contact person way companies specific size currently obliged appoint data protection officer communications authorities routed contact person also subject duty cooperation ensure official audits algorithmic systems take due account interests civil society companies affected suitable advisory boards set within sectoral supervisory authorities opinion data ethics commission technical standards adopted accredited standardisation organisations generally useful measure occupying intermediate position state regulation purely private therefore recommends federal government engage appropriate efforts towards development adoption standards system granting competitors competition associations consumer associations right file action important feature german legal landscape many years could play key role civil society oversight use algorithmic systems particular private rights kind could allow civil society players legitimate mandate enforce compliance legal provisions area contract law fair trading law law without needing rely authorities take action without needing wait individuals authorise special topic algorithmic systems used media intermediaries special topic algorithmic systems used media intermediaries relevance democratic process example social networks many people would impossible imagine life days without social networks search engines like enable users keep date latest news around world circle friends real time platforms people portray lifestyles communicate also used entertainment purposes business activity including advertising whole becoming increasingly important private public order manage wealth information available providers services use algorithmic systems designed amongst things identify interests tendencies convictions users identify posts potential relevance present similar posts order encourage interact network filter illegal offensive posts economic aim primarily generate high advertising revenue depending reach content media intermediaries profound impact democratic process people also using social networks keep abreast politics world affairs social networks therefore offer users new opportunities participate information society sense constitute media factors exchange information opinions time fact public debate concentrated private platforms also poses challenge democracy economic stakeholders private operators social networks vested interest directing traffic networks gearing activity primarily towards economic aspects rather focusing social interests process benefit public good use algorithmic systems predominantly oriented economic criteria negative consequences diversity opinions social networks use services also lead manipulation opinions one hand happen unintentionally due certain characteristics underlying software example recommender systems hand systems used intentionally various actors manipulative purposes operators social networks sufficiently guarded activities threaten foundations democracy regulatory framework social oversight needed particular view high level criticality part lgorithmic systems data ethics commission believes future media intermediaries gatekeeper role ultimately develop high potential harm democracy resulting need regulation data ethics commission believes essential legislators create appropriate regulatory framework use algorithmic systems media intermediaries data ethics commission opinion first operators platforms providers services define implement basic rules ensure fairness process however digital domiciliary right limitations particular integrity democratic process affected depending market share gatekeeper role platforms services operators obligations account indirect view data ethics commission obligations specified precisely subconstitutional law particular also regard use algorithmic systems platforms services significant market share gatekeeper role also relevant recommended data ethics commission see section regulation also needed ensure regulatory fairness comparison broadcasters data ethics commission recommends federal government examine risks posed providers particular power influence opinions countered whole range measures possible greater transparency right controls form licensing procedure algorithmic systems relevant terms democracy decisions federal constitutional court fraport margin seqq stadionverbot decisions federal constitutional court diversity media intermediaries example social networks wide variety roles played social networks predominantly high level criticality algorithmic systems use present particular challenges data ethics commission suggested approach regulation algorithmic systems data ethics commission believes positive legal provisions social networks example increase transparency range discussions held bolster rights users would particularly constructive case social networks dominant market share data ethics commission calls measures safeguard diversity defensive measures alone suffice algorithmic systems operate types networks impacts freedom diversity constitutive democracy extremely high level criticality account reach alone data ethics commission believes legislators therefore ethical constitutional obligation establish binding normative framework regulation media intermediaries order protect democracy may require transforming regulatory framework governing media legislators must take suitable measures ensure total range offer reflects variety opinions exist guarantees balance neutrality freedom bias information society applies particular media intermediaries gatekeeper role power influence opinions according federal constitutional court safeguard pluralistic diversity substantive organisational procedural regulations needed focused creating freedom communication therefore suitable producing desired effects article basic law federal republic germany special topic algorithmic systems used media intermediaries light legislators l√§nder responsible media law obliged implement aforementioned provisions applies legislators regulation algorithmic systems see section media intermediaries platforms vsps already subject audiovisual media services provide content general public draft interstate media services agreement also covers media intermediaries data ethics commission welcomes respect provisions transparency social networks set draft interstate media agreement medienstaatsvertrag initial step direction legislators l√§nder plenty scope freedom drawing provisions however must decide regulation model must leave private individuals agree data ethics commission view plurality obligations media intermediaries case include obligation use algorithmic systems least additional option also provide access unbiased balanced selection posts information reflect diverse range different based considerations data ethics commission also recommends federal government investigate whether areas irrespective situation relevant democracy discussed corresponding obligation establish requirements neutrality provisions diversity seems necessary protecting minors influenced social networks example one consideration directive march coordination certain provisions laid law regulation administrative action member states concerning provision audiovisual media services audiovisual media services directive rolf schwartmann maximilian hermann robin m√ºhlenbeck multimedia und recht mmr labelling obligation social bots democratic process essence based people freedom form opinions make decisions however bots software programs give impression human users used various platforms view data ethics commission highly problematic bots used manipulate individual users public debate guide result vote one way political decisions made firstly simulation human traits falsely suggests statements made result independent thought independent formation political opinions secondly automation massively increase number frequency expressions opinion making harder even impossible assess actual majorities opinions data ethics commission believes regulatory intervention required basis data ethics commission recommends implementing measure enhance transparency form labelling obligation social bots social networks based general considerations data ethics commission recommends labelling obligation implemented anywhere risk social bots could mistaken human interlocutors see section given particular potential jeopardise democratic process data ethics commission furthermore believes case labelling obligation social bots impact political processes essential even irrespective real risk confusion part lgorithmic systems measures combat fake news labelling obligation social bots could help combat automated spread fake news however data ethics commission also believes concept fake news suitable starting point regulation relating media legislation presentation legal definition fake news draws objective distinct line exaggerated satirical expression opinion intentional misrepresentation news impossible due complexity human communications disinformation manipulation public typically associated term fake news also result true facts presented selectively data ethics commission also particular recommends legislators operators social networks grant users right reply requiring network post correction statement proven false invented quote timeline newsfeed etc users network using available data trace back shown false statement data ethics commission emphasises state must create incentives collateral censorship social networks provide protection overblocking data ethics commission therefore believes necessary parallel obligations imposed operators grant affected individuals prompt efficient procedural protection mechanisms data ethics commission believes include particular right effective process reinstate deleted posts provided break laws invocation networks rules alone suffice grounds permanent view data ethics commission rights must apply users respect social transparency obligations news aggregators social networks use algorithmic systems also aggregate select present content third parties generally accessible way allow users interested third parties enough insight technical procedure use select prioritise news make clear recommendation arrived individual case democratic information interest would essentially take precedence business secrets media intermediaries interests fair process fair exchange opinions duties disclose information also stretch economic ties reason well data ethics commission welcomes current thoughts reforming interstate media agreement medienstaatsvertrag call corresponding transparency obligations media intermediaries soon certain reach summary important recommendations action special topic algorithmic systems used media intermediaries given specific risks posed media intermediaries act gatekeepers democracy data ethics commission recommends options examined countering risks also regard influencing legislation see recommendation whole gamut risk mitigation measures considered extending controls form licensing procedure national legislator constitutional obligation protect democratic system dangers free democratic pluralistic formation opinions may created providers act gatekeepers establishing binding normative framework media data ethics commission believes small number operators concerned obliged use algorithmic systems allow users least additional option access unbiased balanced selection posts information embodies pluralism opinion federal government consider measures take due account risks typically encountered media sector respect media intermediaries also respect providers act gatekeepers whose systems associated lower potential harm measures might include mechanisms enhancing transparency example ensuring information available technical procedures used select rank news stories introducing labelling obligations social bots establishing right post countering responses timelines part lgorithmic systems use algorithmic systems state bodies opportunities risks involved use algorithmic systems state bodies citizens rightly expect state use best technology available carry duties depending type duties also include algorithmic systems systems already exist relieve state bodies repetitive tasks thereby expediting processes freeing human resources complex cases certain improve consistency quality state activity form chatbots voice assistants example facilitate citizens access justice time using algorithmic systems state bodies must uphold particularly high standards firstly direct obligation uphold fundamental rights public authorities secondly state activity general expected set example whole society institutional capacity expertise state must build order ensure sufficient oversight algorithmic systems used private parties must therefore also used order guide oversee work carried state bodies particular competence centre algorithmic systems called data ethics commission likely play key role use algorithmic systems state bodies must treated principle particularly sensitive within meaning criticality pyramid least level therefore view data ethics commission comprehensive risk impact assessment must carried mandatory requirement ethically sound use algorithmic systems furthermore depending criticality systems used state necessary instruments discussed designed ensure citizens protected put place algorithmic systems used state legal data protection requirements remain unaffected constitutional administrative specifications design systems additionally view data ethics commission certain sectors use algorithmic systems conflicts constitutionally protected rights overriding importance use algorithmic systems irrespective protective measures taken case question permitted restrictive conditions prohibited particular concerns use algorithmic systems purposes jurisprudence algorithmic systems use algorithmic systems within government context subject restrictions data ethics commission sees democratic process sense people able form opinions make decisions freely possible essentially sacrosanct automated support therefore acceptable ancillary tasks detecting inconsistent use terms legal instruments far removed democratic process catalogues technical specifications subsequent regulations cases systems must meet extremely strict requirements quality security use algorithmic systems state bodies context data ethics commission also particular opposes demand newly enacted legal instruments already formulated view possible future automated application regard technology must follow law reverse accordance conventional criteria assessment legislation compliance fundamental rights law impact assessment etc two equivalent versions conceivable may argument one version easier algorithmise tip scales favour algorithmic systems dispensation justice data ethics commission view use algorithmic systems dispensation justice permissible peripheral tasks justice administered name people means least contentious proceedings well administrative court proceedings criminal proceedings always administered human judges pacification effect court proceedings achieved judgment fairness finding also hearing weighing conflicting interests humans particular structural processing facts legal consequences procedural fairness contrast opaque blackbox decision due often high level trust placed supposed infallibility technical systems automation bias well low level willingness make divergent decisions particular associated additional burden reasoning proof risk miscarriage justice default effects even legally proposals decisions judgments algorithmic systems generally highly problematic perspective parties concerned however algorithmic systems provided strict quality control high security standards place useful preparatory work directly affect judicial decision file management document control use systems retrospectively analyse judicial decisions available voluntary use judges protected access third parties security measures also conceivable systems could example work whether decisions influenced external factors ones order provide judges future ways prevent distortions thus contribute better consistent dispensation justice researchers may also legitimate interest access systems though sufficient safeguards would required individual cases use systems purpose monitoring path judicial checking dispensation work judges external targets average processing time case however view objective judicial independence permissible domain example exercising air passenger rights also dunning procedure similar view data ethics commission fully automated handling legal claims permissible provided procedural rights individual parties concerned safeguarded result however case algorithmic systems create correlations follow legal provisions procedural steps set current state art systems based classic deterministic algorithms therefore generally considered example make decisions meeting formal criteria open assessment systemic point view impending losses expertise compensated freeing human resources complex individual cases part lgorithmic systems algorithmic systems public administration potentially greater scope use algorithmic systems public administration increased automation authorities routine cases included subject precisely defined conditions regarding facts legal consequences may advisable interest efficiency section administrative procedures act order carry administrative procedures appropriately swiftly possible particular relieving administrative staff routine tasks frees human resources deployed handle procedures automated potential particular provision services benefits data ethics commission believes algorithmic systems used expand proactive procedure management whereby required data available authorities services benefits increasingly provided without need applications educationally disadvantaged individuals needy particular could benefit family allowance austria provided child born without need apply however case intervention authorities use algorithmic systems must dealt carefully fundamental rights particularly affected judicial use applies algorithmdetermined administrative decisions also use systems limits authorities scope general assessing whether permit use systems extent resulting intervention reversibility decisions need taken consideration essentially designing systems technology must used easily accessible oversight therefore sensitive areas public administration often allowed use systems based classic deterministic algorithms use proprietary software avoided case discretionary decisions executive decisions margin discretion external legal effect data ethics commission believes currently necessary humans make final decision decision mere beneficial impacts however forming groups cases specification conceivable discretion could reduced extent view algorithmic system one option terms decision data ethics commission view section german administrative procedures act sufficiently reproduce range different possible types cases schematic taking account safeguards required constitutional law based article gdpr legislators carefully expand scope section administrative procedures act set provisions differentiated terms specific legislation administrative acts supported partially fully automation regulations partial full automation administrative procedures developed part horizontal sectoral regulations algorithmic systems recommended data ethics commission see section algorithmic systems public security law public discussion especially critical use algorithmic systems security authorities administrative measures area particularly profound effect fundamental rights use algorithmic generally restricted use algorithmic systems state bodies algorithmic systems used predict crimes threat situations predictive policing consideration must given fact even systems use personal data directly effects relevant fundamental rights case particular reference person created means especially detailed location information addition risk prognoses lead excessive police checks certain neighbourhoods identified hotspots therefore ethnic social profiling population groups living measures also trigger crime relocation displacement effects data ethics commission therefore recommends making security authorities effects incorporating randomisations prediction systems order reduce corresponding effects distortions steps must also taken ensure security authorities still always carry human review cases risk cases selected system section fiscal code germany abgabenordnung security authorities allowed order discretionary intervention measures solely basis locationrelated forecasts risk forecasts relating individuals allowed law area security forecasts must created fully automatically could negative legal consequences parties concerned account risk automation bias even case decisions support human decisionmakers algorithmic systems profiling may permissible within strict limits position paper part conference freedom information officers germany transparenz der verwaltung beim einsatz von algorithmen f√ºr gelebten grundrechtsschutz unabdingbar transparency public administration use algorithms essential protection fundamental rights ulm october available transparency requirements use algorithmic systems state actors state decisions made using algorithmic systems must remain transparent justifiable generally speaking even important private sector due obligation uphold fundamental rights need democratic accountability authority power public sector therefore general transparency requirements see section apply state bodies state bodies must also strive particularly hard ensure openness data ethics commission points many cases algorithmic systems used state actors already fall within scope existing freedom information transparency laws data ethics commission also welcomes position paper transparency public administration use algorithms transparenz der verwaltung beim einsatz von algorithmen adopted conference freedom information officers konferenz der informationsfreiheitsbeauftragten germany according paper state bodies must meaningful comprehensive generally comprehensible information regarding data processing legally possible publish including information data categories procedure input output data logic involved particular calculation formulae used including weighting input data underlying expertise individual configuration deployed users iii scope resulting decisions possible consequences part lgorithmic systems regard specifying corresponding transparency obligations duties provide access information data ethics commission also points insufficient provisions transparency lead lack trust systems lead greater numbers appeals thereby counteracting efficiency gains intended use algorithmic systems reason data ethics commission ultimately believes justifiable cases rule access information regarding public algorithmic systems across board citing risk manipulation protection business secrets rule therefore particular interests must weighed disclosure information system general functionality sufficient every case algorithmic systems used public authorities often decisions made public authorities must also justified parties affected main factual legal reasons led decision particular case must provided section administrative procedures act individual explanation required constitutional subconstitutional law due technical complexity system possible possible way course official complaint procedure court enables effective review viability reasoning use algorithmic systems must prohibited apart data ethics commission believes state required build sufficient expertise within administration courts able ensure necessary oversight data ethics commission points transparency state activity also negatively affected state uses proprietary software closedsource software private providers carrying duties generally speaking proprietary software makes difficult users make changes adaptations results dependent relationship addition use proprietary software leads lack transparency therefore threaten public acceptance systems especially areas sensitive terms fundamental rights public security law use proprietary software therefore avoided possible instead state bodies rely opensource solutions develop systems ideally interdisciplinary teams developers practical data ethics commission recommends federal government consider amending public procurement law minimise aforementioned negative effects proprietary software need fear effectiveness system suffer result transparency exploitation effects ruled software developed open consultative process inclusion civil society stakeholders use algorithmic systems state bodies risk involved automated total enforcement data ethics commission refuses ethical point view acknowledge general right rules regulations however automated total enforcement law raises number ethical concerns example citizens might feel full enforcement practice places everyone suspicion turn reduces general willingness obey rules regulations furthermore automated enforcement danger complexity situations sufficiently portrayed particular unforeseen exceptional situations example speeding private vehicle taking seriously injured individual hospital sufficiently taken consideration finally many laws originally enacted total enforcement general rule therefore systems designed way human override technical enforcement specific case addition law enforcement measure constitutes state intervention must based principle proportionality part lgorithmic systems summary important recommendations action use algorithmic systems state bodies state must interests citizens make use best available technologies including algorithmic systems must also exercise particular prudence actions view obligation preserve fundamental rights act role model general rule therefore use algorithmic systems public authorities assessed basis criticality model particularly sensitive entailing least comprehensive risk assessment areas dispensation justice algorithmic systems may used peripheral tasks particular algorithmic systems must used undermine functional independence courts democratic process way contrast enormous potential exists use algorithmic systems connection administrative tasks particular relating provision services benefits legislator take due account fact giving green light greater number partially fully automated administrative procedures cautious consideration therefore given expanding scope section german administrative procedures act verwaltungsverfahrensgesetz vwvfg couched overly restrictive terms corresponding provisions statutory law measures must accompanied adequate steps protect citizens decisions taken state basis algorithmic systems must still transparent must still possible provide justifications may necessary clarify expand existing legislation freedom information transparency order achieve goals furthermore use algorithmic systems negate principle decisions made public authorities must generally justified individually contrary principle may impose limits use overly complex algorithmic systems finally greater priority accorded opensource solutions since latter may significantly enhance transparency government actions ethical point view general right rules regulations time however automated total enforcement law raises number different ethical concerns general rule therefore systems designed way human override technical enforcement specific case balance struck potential transgression automated perhaps preventive enforcement measure must times meet requirements proportionality principle liabilit algorithmic systems liability algorithmic systems significance criminal responsibility administrative sanctions liability damages vital components ethically sound regulatory framework especially algorithmic systems digital technologies ethical perspective data ethics commission also highlights particular role tort law serves compensation prevention damage therefore significantly contributes protection legally protected interests line fundamental rights ethical perspective following requirements inter alia must set liability system needs keep new digital technologies sufficient compensation victims particular case legally protected interests highly relevant terms fundamental rights compensation comparable situation involving humans conventional technology would owed provision right behavioural incentives whereby damage paid actors caused damage avoidable undesirable behaviour whose sphere risk question resulted fairness whereby actors liable pay damages example placed system market exercise control system benefit use efficiency whereby costs covered internalised actors avoid insure costs least amount harm caused use algorithmic systems liability electronic person data ethics commission expressly advises granting robots autonomous systems legal personality often discussed using keyword intention making systems liable car registered owner operates mobility service measure would achieve allocation responsibility liability harm responsible use system ultimately benefit economically use fact measure could conversely used evade responsibility legal personality machines new type legal entity would enable desirable outcome achieved could achieved freely easily another way example help company law treating autonomous machines even analogy natural persons would dangerous mistake vicarious liability autonomous systems data ethics commission believes however harm caused autonomous systems attributed operating systems according rules vicarious liability would apply case human auxiliaries particular section german civil code actor uses system order broaden range activities example hospital uses surgical robot event malfunction able release liability actor uses human vicarious agent example human surgeon liable culpable misconduct vicarious agent treated behaviour part actor becomes particularly important case liability algorithmic system otherwise liability loopholes easily occur breach duty care person behind proven use monitoring algorithmic system part lgorithmic systems example surgical robot hospital makes operational incision long causes complications algorithmic system incorrectly derives score creditworthiness bank customer customer take attractive offer relating property may occasionally difficult establish adequate equivalent standard care autonomous systems particular soon abilities machine exceed human majority cases however malfunctions distinguishable normal functions therefore general cited operator liability standard must defined based comparable systems available market whereby question use technology could expected operator must decided based general principles respect question quality surgical robot used differ question quality device used strict liability essentially fact rules relating classic liability always sufficient resolving legal issues arise case dangerous products legal system far come range different answers challenge particular include liability example adaptations standard care various ways easing burden proof right reversal burden proof bases strict liability facilities activities typically cause harm account benefit society whole prohibited liability accordance german act liability defective products gesetz √ºber die haftung f√ºr fehlerhafte produkte prodhaftg acts special form liability regardless fault differs strict liability account fact requires inter alia product defect therefore comes fairly close liability steps must taken ensure answers lead legally watertight solutions terms compensation harm caused dangerous digital applications operation digital applications currently involves legal uncertainties liability loopholes primarily result unpredictability harmful events including applications placed market hence possibly failure classic liability also result fact various different actors applications interact generally speaking almost impossible prove error occurred cause error open dynamic nature digital ecosystems close functional interplay products digital contents digital services also present challenge legal uncertainties perspective companies consumers obstacles innovation acceptance new technologies harmful events routinely assigned terms liability compensated impact market intended achieved liability provisions achieved order create appropriate balance interests legislator must provide transparency responsibility responsibilities clarified possible insure harm damage practice liabilit algorithmic systems data ethics commission solve point complex technical legal questions arise pin right solutions terms liability law especially instances chances finding solution european level explored first ethical perspective crucial legal clarity legal certainty particular regard liability principles described created however debate currently stands appears highly likely addition appropriate amendments product liability directive see section certain changes may need made rules relating liability new bases strict liability may need introduced legislative process firstly necessary determine liability regime appropriate particular types products digital content digital services exact shape regime take depending criticality see section relevant system also criteria specifically relevant within context liability strict liability example based model involving car owner liability could appropriate cases regarding devices operational risk similarly uncontrollable could end leading harm life limb part question insurability possible compulsory insurance must always play role decision must also always taken type harm subject liability personal injury damage property data loss pure financial losses damage ultimately case decision need taken taking consideration liability principles described right party liability assigned particular three possible parties liability could assigned two could possibly also jointly severally liable liability concept differentiated liability operator digital ecosystems see report entitled liability artificial intelligence emerging digital technologies european commission expert group liability new technologies new technologies formation september seqq individual registered owner system owner person similar position uses system purposes manufacturer system operator system whoever exercises greater control system operation individual registered owner operator operator may also manufacturer determination party type liability always depend specific type networked autonomous system identification specific spheres liability product security product liability overall currently important highlight paradigm shift situation whereby products simply placed market situation whereby products placed market additional services continue provided products thereafter ongoing product monitoring product maintenance becoming important security data protection standards fulfilled product leaves production plant also must continue met part subsequent software updates conversely event security gaps subsequently appear manufacturer accordance provisions directives digital content digital services trade goods subject duty provide security updates line consumers reasonable expectations regarding service life part lgorithmic systems example security updates provided smart home system result following house broken product liability directive longer able cover features networked hybrid autonomous products data ethics commission recommends part evaluation revision product liability directive european level federal government push watertight clear legal provisions particular following aspects inclusion digital content digital services including algorithmic systems term product liability product defects appear product placed market result software provision updates failure provide productspecific data feeds liability breaches product monitoring obligation inclusion legally protected interests typically affected digital product safety particular right informational compensation regimes adaptation development risk need reassessment liability law digital ecosystems throw variety issues connection liability responsibility example extent liability loophole current tort law cases damage data digital products provided neither recognised absolute right infringed ownership storage medium statute intended protect another person breached provisions criminal law conditions intentional damage contrary public policy met new digital technologies often also involve opportunistic use people infrastructures systematic collation use third parties sensor data generated private iot devices direct use computing capacity transmission functions create complicated liability issues contexts stronger focus contract law major harm damage particular expense consumers caused account fact usability goods real property machines cars etc becoming increasingly dependent provision digital services software updates user accounts etc provision services guaranteed even specifically suspended order put individuals pressure electronic repossession liabilit algorithmic systems digital ecosystems also extent characterised interaction numerous components operators whereby often disproportionately difficult injured party prove several potential tortfeasors hardware supplier suppliers various software components data feed provider network operator caused harm hand digital technologies create new lack transparency regard cause harm damage conversely also help documenting course causal events unprecedented way question therefore arises actor obliged contribute providing clarification cause harm already logging data data actually recorded via logging disclosed event harm data ethics commission therefore recommends overall federal government investigate extent current liability law kept challenges digital ecosystems needs reworked priority must given striving achieve solution european level data ethics commission advises context tendency towards focus specific technological features particular feature machine learning whilst machine learning creates certain additional dangers involves certain additional issues regarding assignment liability challenges liability law attributable factors intangibility interaction numerous components networking decentralisation part lgorithmic systems summary important recommendations action liability algorithmic systems liability damages alongside criminal responsibility administrative sanctions vital component ethically sound regulatory framework algorithmic systems already apparent today algorithmic systems pose challenges liability law currently stands inter alia complexity dynamism systems growing autonomy data ethics commission therefore recommends current provisions liability law undergo checks necessary revisions scope checks revisions restricted basis narrowly defined technological features machine learning artificial intelligence proposal future system legal personality would granted algorithmic systems systems would liable damages electronic person pursued far concept protagonists based purported equivalence human machine ethically indefensible far boils introducing new type company company law fact solve pertinent problems way contrast harm caused autonomous technology used way functionally equivalent employment human auxiliaries operator liability making use technology correspond otherwise existing vicarious liability regime principal auxiliaries particular section german civil code example bank uses autonomous system check creditworthiness customers liable towards least extent would used human employee perform task debate currently stands appears highly likely appropriate amendments need made product liability directive dates back connection established new product safety standards addition certain changes may need made rules relating liability new bases strict liability may need introduced case necessary determine liability regime appropriate particular types products digital content digital services exact shape regime take depending criticality relevant algorithmic system consideration also given innovative liability concepts currently developed european level european pathpart part uropean path data ethics commission examined great many different questions discussions questions raised new ones turn alone indicate opinion serve one many building blocks larger edifice debate future ethics law technology must return debate must interdisciplinary outset encompass broad range sciences diverse mix representatives worlds economy civil society politics view immense economic pressure nature technological change findings emerge debate must integrated ongoing basis activities parties involved levels shape technological future founded values data transfers use algorithmic systems transcend national boundaries means discussion ethical legal issues arising connection data algorithmic systems must restricted national level need view problems global perspective accordingly strive present findings perspectives debate well lessons learned implementing gdpr shown economic clout european economic area significance market operators providers algorithmic systems may ultimately mean latter prompted economic interests comply basic requirements developing implementing products services european requirements also used ever governments reference point drafting regulatory debate needs take place therefore priority topic agendas international forums oecd council europe united nations mind data ethics commission recommends federal government make voice heard within international bodies particular german presidency council second half utilised opportunity promote measures deal data governance algorithmic systems proposed opinion european level data ethics commission also believes federal government actively involved early stages process ongoing basis establishment international panel artificial intelligence ipai initiated level global contest future technologies germany europe confronted value systems models society cultures differ widely prompted debate whether germany europe adapt one models order remain competitive data ethics commission supports european path followed date often referred debates third way strikes balance chinese positions asserts defining feature european technologies consistent alignment european values fundamental rights particular enshrined european union charter fundamental rights council europe convention protection human rights fundamental freedoms order remain actively involved future debate interplay ethics law technology digital sovereignty germany europe must preserved greatest extent possible used reference nation states organisations term digital sovereignty encompasses every aspect data processing control storage transfer use sensitive data held bodies autonomous decisions access part uropean path globalised world people states companies side side requires flows data internet serves conduit flows global network networks distributed global structure embraces different legal societal systems renders complete sovereignty impossible task debate digital sovereignty must therefore tackle vital questions relating technical infrastructure including hardware networks control components routers address servers data centres view preserving digital sovereignty germany europe given huge extent reliant foreign products data ethics commission believes urgent need take action german european level investments developing safeguarding appropriate technologies infrastructures virtually important basic internet infrastructure components used germany indeed europe whole procured continents present efforts preserve sovereignty must restricted two main avenues open first critical analysis assessment basic components used second application highest possible security standards operating order minimise risk misuse foreign states organisations looking future however data ethics commission believes important germany europe whole develop higher level digital sovereignty right level technical infrastructure support available work systems comply highest possible standards security work kind would include design new components replace previous systems attempts engineer integrated solutions use existing components achieve required level protection spite known suspected inadequacies security digital sovereignty nation state viewed relation nation states also relation actors wield significant amounts power data economy grows trend economic power concentrated hands emergence new power imbalances apparent ever greater extent work algorithmic systems digital technologies carried within framework established small group digital giants companies often act important source public research funding therefore say research past decades intermediaries played increasingly important role forming opinions therefore influencing sociopolitical discourse means associated risk abuse also increased given importance ethical legal fundamental values freedoms preserve digital sovereignty germany europe data ethics commission believes urgent need closely monitor shifts power structures vital functioning democratic state social market economy efficiently regulate according areas wherever needed excessive dependence others turns nation rule taker rather rule maker resulting citizens nation subject requirements imposed players elsewhere world embarking efforts safeguard digital sovereignty long term therefore politically necessity also expression ethical responsibility appendix appendi federal government key questions data ethics commission coalition agreement set data ethics commission within next year provide government parliament proposals develop data policy deal algorithms artificial intelligence digital innovation clarification data ethics questions add impetus process digital development help define approach towards resolving social conflicts within area data key questions data ethics commission digitisation fundamentally changing society new technologies beneficial people everyday lives well industry environment science society whole potential enor mous time digitisation also clearly brings certain risks numerous ethical legal questions raised particularly concerning effects develop ments desired role new technologies digital change benefit whole society need examine possible consequences new technologies establish ethical safeguards one challenge develop law way protects human dignity human must become mere object guarantees fundamental human rights general right personality right privacy right informational nation freedom discrimination freedom science freedom conduct business freedom expres sion information bringing rights equilibrium one another complex tensions principles common good progress innovation solidarity task commission identified current state discussion legislation euro pean international level ascertained possibilities positive action national level given special consideration sensitive areas develop ethical standards guidelines protection individuals preservation social cohesion safeguarding promotion prosperity information age commission also tasked providing federal government recommendations regulatory proposals ethical guidelines developed respected implemented monitored propos als also include description underlying concepts used well assessments possible consequences side effects public appropriately involved work commission order help data ethics commission carry work federal government provided following key questions three areas federal government key questions data ethics commission algorithmic adm advanced automation systems increasingly shaping economic social realities people everyday lives data collection analysis enable develop ment innovative interpretation models also used make prepare decisions algorithms make possible example recognise patterns differences behaviour different groups whether matter setting individual prices assessing creditworthiness selecting candidates recruitment procedures people evaluated technical processes areas life data evaluation predictions individual behaviour offer opportunities aiding research strengthening innovation within industry increasing efficiency data processing processes also harbour risks individual freedom participation equal opportunities among certain individuals social groups social inequality discrimination individuals groups individuals perpetuated biases incorporated programming algorithm training data risks particularly acute adm processes background following questions arise especially regard consumer protection ethical limits using adm processes ethical limits ethically necessary use adm processes characteristics criteria certain kinds data incorporated adm pro cesses due age origin example determine prejudices distor tions areas ethically undesirable effects use adm processes social groups regulatory approaches could used prevent manipulation unequal treatment discrimination advisable graduated regulatory frame work based risk social participation potential discrimination reliability reproducibility scrutiny adm guaranteed limits use adm use crite ria explained people affected test methods make adm open scrutiny artificial intelligence development industrial administra tive environments deploying highly automated systems use methods ability learn use training data addition work done simulating cognitive functions human brain developments field artificial intelligence raise question dignity autonomy individual safeguarded fostered leads questions following fundamental ethical principles must observed developing programming using ethical boundaries lie using robots especially special areas life assistance dealing particularly vulnerable groups children elderly people disabilities ethically necessary use ethics design possible could implemented monitored ensured machines working basis controlled appendi generated ascribed bear responsibility malfunctioning systems responsibility actors involved development use systems programmers data scientists clients etc made transparent else necessary future sustainably guarantee freedoms fundamental rights upon society based iii data digitisation characterised increase volume data big data vast accumulation data individual actors high speed data processing real time connectivity internet complex networks actors internet things increasing ubiquity permanence data development various methods data analysis amount available data increases ability dertake granular analyses data used develop new business models change chains work processes data regarded commodi enables value creation data economy national european level current laws general data protection regulation open data legislation numerous legislative initiatives concern handling data eprivacy regula tion legislative proposals regarding free flow data one hand intended safeguard funda mental rights right informational termination hand intended enable useful innovative data processing proposals discussed whether access data use data trade data rights data could regulated first time better process following questions may arise regard ing handling data general data access use data ethical limits economization data permitted derive economic benefit data obligation offer payment models advisable uniform rules apply equally data preference given rules apply specific areas brain data connecting factor rules apply specific areas consequences existing access exclusivity rights data competition innovation consequences would additional access exclusivity rights data need state offer support part provision general public services citizens navigate internet social networks responsible competent confident manner learn handle data provision data particular open data become part provision public services state much transparency necessary appropriate safeguard right informational tion enable citizens participate economic life manner particular life circumstances require special protec tion concepts specific user groups existing institutions sensitive areas sufficient ensure data used ethically adequate stakeholder representation ensured long term federal government key questions data ethics commission effects extensive data collections functioning market economy compet itiveness information asymmetry suppliers consumers possibility developing inno vative products democracy recording analysing behaviour social networks necessary action taken data silos especially intermediaries data access data declared public good certain cases cases ethical criteria use data collective effects example individuals certain population groups may placed disadvantage data analysis shows payment habits worse par ticular neighbourhood regulatory instruments would needed sectors statutory regulations improving access data possible necessary advisable data processing prohibited certain cases ethical reasons example cases involving certain types data political views brain data certain areas use profiling political purposes use elections circumstances ethical obligation use data legal system sufficiently recognise possible benefits data processing common good achieved possible advisable create experimentation clauses testing new applications new regulatory instruments make sense invest data infrastructures ones constitutionally protected interests individuals enterprises science art reconciled public interest use data last revised june appendi members data ethics commission christiane wendehorst civil law university vienna department innovation digitalisation law university vienna european law institute eli christiane woopen ethics theory medicine head research unit ethics university clinic cologne director cologne center ethics rights economics social sciences health ceres university cologne european group ethics science new technologies ege members johanna haberer christian media studies friedrich alexander university erlangen nuremberg fau institute practical theology friedrich alexander university erlangen nuremberg fau marit hansen protection commissioner land unabh√§ngiges landeszentrum f√ºr datenschutz independent centre privacy protection dirk heckmann professor law security digitization technical university munich tum bavarian research institute digital transformation bavarian constitutional court ulrich kelber commissioner data protection freedom information professor university applied sciences members data ethics commission dieter kempf federation german industries bdi professor friedrich alexander university erlangen nuremberg fau mario martini public administration public law administrative law european law german university administrative sciences speyer duv speyer programme area transfor mation state digital age deputy director german research institute public administration f√∂v klaus m√ºller director federation german consumer organisations vzbv heinrich heine university d√ºsseldorf hhu paul nemitz advisor european commis sion justice consumers sabine sachweh applied software engineering dortmund university applied sciences arts dortmund board member institute digital transformation application living domains idial dortmund university applied sciences arts dortmund digitalisation education elderly advisory council federal ministry family affairs senior citizens women youthchristin sch√§fer managing director company acs plus data science boutique big data analytics research group german economic institute cologne k√∂ln rolf schwartmann civil law economic law cologne university applied sciences k√∂ln research centre media law cologne university applied sciences k√∂ln german association data protection data security gdd judith simon ethics information technol ogy university hamburg uhh wolfgang wahlster computer science chair artificial intelligence saarland university german research center artificial intelligence dfki steering committee standardisation roadmap german institute standardization din thomas wischmeyer professor tenure track public law information law university bielefeld current october imprint berlin december opinion data ethics commissionpublisher data ethics commission federal governmentfederal ministry interior building berlinfederal ministry justice consumer protectionmohrenstra√üe berlin website design atelier hauer d√∂rfler gmbh berlin photo credits bmi group photo studio wilke christiane wendehorst reiner zensen christiane woopen ulrich kelber christian kruppa dieter kempf baumbach klaus m√ºller markus mielek sabine sachweh rolf schwartmann judith simon jim rakete wolfgang wahlster printingbrandenburgische universit√§tsdruckerei und verlags gesellschaft potsdam mbh bud dek
