independent expert group artificial intelligence set european commission ethics guidelines trustworthy ethics guidelines trustworthy high expert group artificial intelligence document written high expert group hleg members hleg named document support overall framework trustworthy put forward guidelines although necessarily agree every single statement document trustworthy assessment list presented chapter iii document undergo piloting phase stakeholders gather practical feedback revised version assessment list taking account feedback gathered piloting phase presented ropean commission early hleg independent expert group set european commission june contact nathalie smuha hleg coordinator cnect european commission brussels document made public april first draft document released december subject open consultation generated feedback contributors wish explicitly warmly tha contributed feedback document first draft considered preparation revised version neither european commission person acting behalf commission responsible use might made following information contents working document sole responsibility high level expert group artificial intelligence hleg although commission staff facilitated preparation guidelines views expressed document reflect opinion hleg may circumstances regarded reflecting official position european commission information high exp ert group artificial intelligence available online single reuse policy european commission documents regulated decision use reproduction photos material copyright permission must sought directly copyright holders table contents executive summary introduction framework trustworthy chapter foundations trustworthy chapter realising trustworthy requirements trustworthy technical non methods realise trustworthy iii chapter iii assessing trustworthy examples opportun ities critical oncerns raised conclusion glossary executive summary aim guideline promot trustworthy trustworthy three components met throughout system entire life cycle lawful complying applicable laws regulation ethical ensuring adherence ethical principles values robust technical social perspective since even good intentions systems cause unintentional harm component necessary sufficient achievement trustworthy ideally three components work harmony overlap operation practic tensions arise components society endeavour align guidelines set framework achieving trustworthy framework explicitly deal trustworthy first component lawful instead aims offer guidance second third components fostering securing ethical robust addressed stakeholders guidelines seek beyond list ethical principles providing guidance principles operationalis socio technical systems guidance provided three layers abstraction abstract chapter concrete chapter iii closing examples opportunities critical concerns raised systems based approach founded fundamental rights chapter identifies ethical principles correlated values must respected development deployment use systems key guidance derived chapter develop deploy use systems way adhere ethical principles respect uman autonomy prevention arm fairness explicability acknowledge address potential tensions ese principles pay particular attention situations involving vulnerable groups children persons disabilities others historically disadvantaged risk exclusion situations characterised asymmetries power information employers workers businesses acknowledge bringing substantial benefits individuals society systems also pose certain risks may negative impact including impacts may difficult anticipate identify measure democracy rule law distributive justice human mind adopt adequate measures mitigate risks appropriate proportionately magnitude risk drawing upon chapter chapter provides guidance trustworthy realised listing seven requirements systems meet technical non methods used implementation key guidance derived chapter ensure development deployment use systems meets seven key requirements trustworthy human agency versight technical robustness afety privacy data governance transparency diversity airness nvironmental societal well accountability consider technical non methods ensure implementation requirements normative statements document aim reflect guidance towards achieving second third component trustworthy ethical robust statements hence meant provide legal advice offer guidance compliance applicable laws though acknowledged many statements extent already reflected existing laws regard see following see articles charter fundamental rights charter dealing rights child elderly integration persons disabilities workers rights see also article dealing consumer protecti foster research innovation help assess systems achievement requirement disseminate results open questions wider public systematically train new generation experts ethics communicate clear proactive manner information stakeholders system capabilities limitations enab ling realistic expe ctation setting manner requirements implemented transparent fact dealing system facilitate traceability auditability systems particularly critical contexts situations involve stakeholders throughout system life cycle foster training education stakeholders aware trained trustworthy mindful might fundamental tensio different principles requirements continuously dentify evaluate document communicate trade solutions iii chapter iii provid concrete trustworthy assessment list aimed operationalis ing key requirements set chapter assessment list need tailored specific use case system key guidance derived chapter adopt trustworthy assessment list developing deploying using systems adapt specific use case system applied keep mind ssessment list never exhaustive ensuring trustworthy ticking boxes continuously identifying implementing requirements evaluating solutions ensuring improved outcomes throughout system lifecycle involving stakeholders final section document aims concretise issues touched upon throughout framework offering examples beneficial opportunities pursued critical concerns raised systems carefully considered guidelines aim offer guidance applications general building horizontal founda tion achieve trustworthy different situations raise different challenges therefore explored whether addition horizontal framework sectorial approach needed given context systems guidelines intend substitute form current future policymak ing regulation aim deter introduction thereof seen living document reviewed updated time ensure continuous relevance technology social environments knowledge evolve document starting point discussion trustworthy europe beyond europe guidelines also aim foster research reflection discussion ethical framework systems global level line scope framework assessment list provide advice ensuring legal compliance lawfu limits offering guidance meeting second third components rustworthy ethical robust ideal intended apply systems developed deployed used member states european union well systems developed produced elsewhere deployed used referring europe document mean encompass member states however guidelines also asp ire relevant outside regard also noted norway switzerland part coordinated plan agreed published december commission member states introduction communication april december european commission set vision artificial ntelligence supports ethic secure cutting made europe three pillars underpin commission vision increasing public private investments boost uptake preparing socio changes iii ensuring appropriate ethical legal framework strengthen european values support implementation vision commission established high expert gro artificial intelligence hleg independent group mandated drafting two deliverables ethics guidelines policy investment recommendations document contains ethics guidelines revised following deliberation group light feedback received public consultation draft published december builds work european group eth ics science new takes inspiration similar past months met discussed interacted committed european motto united diversity believe potential significantly transform society end rather promising means increase human flourishing thereby enhancing individual societal well common good well bringing progress innovation particular systems help facilitate achievement sustainable development goals promoting gender balance tackling climate change rationalising use natural resources enhancing health mobility production processes supporting monitor progress sustainability social cohesion indicators need human resting commitment use service humanity common good goal improving human welfare freedom offering great opportunities systems also give rise certain risks must handled appropriately proportionately important window opportunity shape deve lopment want ensure trust socio technical environm ents embedded also want producers systems get competitive advantage embedding trustworthy products services entails seeking maximise benefits systems time preventing minimising risks context rapid technological change believe essential trust remains bedrock societies communities economies sustainable development therefore identify trustworthy foundational ambition since human beings communities able confidence technology development application clear comprehensive framework achieving trustworthiness place path believe europe follow become home leader cutting ethical technology trustworthy european citizens seek reap benefits way aligned foundational values respect human rights democracy rule law trustworthy trustworthiness prerequisite people societies develop deploy use systems without systems human beings behind demonstrably worthy trust unwanted consequences may ensue uptake might hindered preventing realisation potentially vast social economic com com ote term made europe used throughout commission communication scope guidelines however aims encompass systems made europe also developed elsewhere deployed used europe throu ghout document hence aim promote trustworthy europe european group ethics science new technologies ege advisory group commission see section com glossary end document provides definition systems purpose document definition elaborated edicated document prepared hleg accompanies guidelines titled definition main capabilities scientific disciplines benefits bring help europe realise benefits vision ensure scale trustworthy trust development deployment use systems concern technology inherent properties also qualities socio systems involving application analogous questions loss ust aviation nuclear power food safety simp components system system overall context may may engender trust striving towards trustworthy hence concerns trustworthiness system requires holistic systemic approach encompassing trustworthiness actors processes part system socio context throughout entire life cycle trustworthy three components met throughout system entire life cycle lawful complying applicable laws regulations ethical ensuring adherence ethical principles values robust technical social perspective since even good intentions systems cause unintentional harm three component necessary sufficient achieve trustworthy ideally three work harmony overlap operation practice however may tension betwe elements times scope content existing law might step ethical norms individual collective responsibility society work towards ensuring three components help secure trustworthy trust worthy approach key enabling responsible competitivenes providing foundation upon affected systems trust design development use lawful ethical robust guidelines int ended foster responsible sustainable innovation europe seek make ethics core pillar developing unique approach one aims benefit empower protect individual human flourishing common good society believe enable europe position global leader cutting worthy individual collective trust ensuring trustworthiness european individuals fully reap systems benefits secure knowledge measures place safeguard potential risks use systems stop national border neither impact global solutions therefore required global opportunities challenges systems bring forth therefore encourage stakeholders work towards global framework trustworthy building international consensus promoting upholding fundamental rights approach audience scope guidelines addressed stakeholders designing developing deploying implementing using affected including limited companies organisations researchers public services government agencies institutions civil society organisations individuals workers consumers stakeholders committed towards achieving trustworthy voluntarily opt use guidelines method operationalise commitment particular using practical assessment list chapter iii develop ing deploy ing using systems assessment list also complement hence incorporated existing assessment processes guidelines aim provide guidance applications general building horizontal foundation achieve trustworthy however different situations raise different challenges music recommendation systems systems comprise humans state actors corporations infrastructure software protocols standards governance existi laws oversight mechanisms incentive structures auditing procedures best practices reporting others exclude fact additional conditions may come necessary also means legislature policy may need review adequacy existing law might step ethical principles raise ethical concerns systems proposing critical medical treatments likewise different opportunities challenges arise systems used context business business employer public relationships generally different sectors use cases given context systems implementation guidelines needs adapted particular moreover necessity additional sector ial approach complement general horizontal framework proposed document explored gain better understanding guidance implemented horizontal level matters require sectorial approach invite stakeholders pilot trustworthy assessment list chapter iii operationalises framework provide feedback based feedback gathered piloting phase revise assessment list guidelines early piloting phase launched summer last end year interested stakeholders able participate indicating interest european alliance framework trustworthy guidelines articulate framework achiev ing trustworthy based fundamental rights enshrined charter fundamental rights european union charter relevant international human rights law briefly touch upon trustworthy three components lawful systems operate lawless world number legally binding rules european national international level already apply relevant development deployment use systems today legal sources include limit rimary law treaties european union charter fundamental rights econdary law general data protection regulation product liability directive regulati free flow non ata anti directives consumer safety health ork directives human rights treaties council europe conventions european convention human rights numerous member state aws besides horizontally applicable rules various domain rules exist apply particular applications instance medical device regulation healthcare sector law provides positive negative obligations whi means interpreted reference done also reference done may done law prohibits certain actions also enables others regard noted charter contains articles freedom conduct business freedom arts sciences alongside articles addressing areas familiar looking ensure trustworthiness instance data protection guidelines explicitly deal first component trustworthy lawful instead aim offer guidance fostering securing second third components ethical robust two atter certain xtent often already reflected existing laws full realisation may beyond existing legal obligations nothing document shall construed interpreted providing legal advice guidance concerning compliance applicable existing legal norms requirements achieved nothing document shall create legal rights impose legal obligations towards third parties however recall duty natural legal person comply laws whether applicable today adopted future according development guidelines proceed assumption legal rights obligations apply processes activities involved developing deploying using systems remain mandatory must duly observed ethical achieving trustworthy requires compliance law one three components laws always speed technological developments times step ethical norms may simply well suited addressing certain issues system trustworthy hence also ethical ensur ing alignment ethical norms robust even ethical purpose ensured individuals society must also confident systems cause unintentional harm systems perform safe secure reliable manner safeguards foreseen prevent unintended adverse impacts therefore important ensure systems robust needed technical perspective ensuring system technical robustness appropriate given context application domain life cycle phase social perspective due consideration context environment system operates ethical robust hence closely intertwined complement principles put forward chapter requirements derived principles chapter address components framework guidance document provided three chapters abstract chapter concrete chapter iii chapter foundations trustworthy sets foundations trustworthy laying fundamental based approach identifies describes ethical principles must adhered order ensure ethical robust chapter realis ing trustworthy translates thical principles seven key requirements systems implement meet throughout entire life cycle addition offers technical non methods used implementation chapter iii assessing trustworthy sets concrete trustworthy assessment list operationalise requirements chapter offering practitioners practical guidance assessment tailored particular system application document final section lists examples beneficial opportunities critical concerns raised systems serve stimulate debate guidelines structure illustrated figure fundamental rights lie foundation international human rights law underpin legally enforceable rights guaranteed treaties charter legally binding compliance fundamental rights hence fall trustworthy first component lawful ndamental rights however also understood reflecting special moral entitlements individuals arising virtue humanity regardless legally binding status tha sense hence also form part second component trustworthy ethical figure guidelines framework trustworthy chapter foundations trustworthy chapter sets foundations trustworthy grounded fundamental rights reflected four ethical principles adhered order ensure ethical robust draws heavily field ethics ethics sub applied ethics focusing ethical issues raised development deployment use central concern identify advance raise concerns good life individuals whether terms quality life human autonomy freedom necessary democratic society ethical reflection technology serve multiple purposes first stimulate reflection need protect individuals groups basic level second stimulate new kinds innovations seek foster ethical values helping achieve sustainable development firmly embedded forthcoming agenda document mostly concerns first purpose mentioned importance ethics could second underestimated trustworthy improve individual flourishing collective wellbeing generating prosperity value creation wealth maximization contribute achieving fair society helping increase citizens health well ways foster equa lity distribution economic social political opportunity therefore imperative understand best upport development deployment use ensure everyone thrive world build better future time globally competitive powerful technology use systems society raises several ethical challenges instance relating impact people society decision capabilities safety increasingly going use assistance delegate decisions systems need make sure systems fair impact people lives line values shou compromised able act accordingly suitable accountability processes ensure europe needs define normative vision future wants reali understand ich notion studied developed deployed used europe achieve vision document intend contribute effort introducing notion trustworthy believe right way build future future democracy rule law fundamental rights underpin systems systems continuously improv defend democratic culture also enable environment innovation responsible competitiveness thrive domain ethics code however consistent developed fine future versions may never function substitute ethical reasoning must always remain sensitive contextual details captured general guidelines beyond developing set rules ensuring trustworthy requires build maintain ethical culture mind public debate education practical learning fundamental rights moral legal entitlements believe approach ethics based fundamental rights enshrined treaties charter international human rights respect fundamental rights within framework democracy rule law provides promising foundations identifying abstract ethical principles values operationalised context treaties charter prescribe series fundamental rights member states institutions leg ally obliged respect implementing law rights described charter based constitutional commitment protect fundamental indivisible rights human beings ensure respect rule law foster democratic freedom promote commo good rights reflected articles treaty european union charter fundamental rights legal instruments reflect provide specification commitments instance council europe european social charter specific legislation general data protection regulation reference dignity freedoms equality solidarity citizens rights justice common foundation unites rights understood roo ted respect human dignity thereby reflecting describe human approach human enjoys unique inalienable moral status primacy civil political economic social rights charter legally binding important recognise fundamental rights provide comprehensive legal protection every case charter instance important underline field application limited areas law international human rights law particular european convention human rights legally binding member states cluding areas fall outside scope law time fundamental rights also bestowed individuals certain degree groups virtue moral status human beings independently legal force understood legally enforceable rights fundamental rights therefore fall first component trustworthy lawful safeguards compliance law understood rights everyone rooted inherent moral status man beings also underpin second component trustworthy ethical dealing ethical norms necessarily legally binding yet crucial ensure trustworthiness since document aim offer guidance former component purpose non guidelines references fundamental rights reflect latter component fundamental rights ethical principles fundamental rights basis trustworthy among comprehensive set indivisible rights set international human rights law treaties charter families fundamental rights particularly apt cover systems many rights specified circumstances legally enforceable compliance terms legally obligatory even compliance legally enforceable fundamental rights achieve ethical reflection help understand development deployment use systems may implicate fundamental rights underlying values help provide fine guidance seeking identify rather currently technology respect human dignity human dignity encompasses idea every human possesses intrinsic worth never diminished compromised repressed others new technologies like context respect human dignity entails people treated respect due moral subjects rather merely objects sifted sorted scored herded conditioned manipulated systems hence developed manner respects serves protects humans physical mental integrity personal cultural sense identity satisfaction essential freedom individual human beings remain free make life decisions entails freedom sovereign intrusion also requires intervention government non organisations ensure individuals people risk exclusion equal access benefits opportunities context freedom individual instance requires mitigation direct illegitimate coercion threats mental autonomy mental health unjustified surveillance deception unfair manipulation fact freedom individ ual means ommitment enabling individuals wield even higher control lives including among rights protection freedom conduct business freedom arts science freedom expression right private life priva freedom noted commitment human anchoring fundamental rights requires collective societal nstitutional foundations individual freedom respect human dignity practically possible meaningful rather implying unduly individualistic account human pursuant article charter applies institutions member states implementing law mccrudden human dignity judicial interpretation human rights ejil understanding human dignity along lines see hilgendorf problem areas dignity debate ensemble theory human dignity grimm kemmerer m√∂llers eds human dignity context explorations contested concept assembly association respect democracy justice rule law governmental power constitutional democracies must legally authorised limited law systems serve maintain foster democratic processes respect plurality values life choices individuals systems must undermine democratic processes human deliberation democratic voting systems systems must also embed commitment ensure operate ways undermine foundational commitments upon rule law founded mandatory laws regulation ensure due process equality law equality solidarity including rights persons risk exclusion equal respect moral worth dignity human beings must ensured goes beyond non tolerate drawing distinctions dissimilar situations based objective justifications context equality entails system operations generate unfairly biased outputs data used train systems inclusive possible representing different population groups also requires adequate respect potentially vulnerable persons groups workers women persons disabilities ethnic minorities children consumers others risk exclusion citizens rights citizens benefit wide array rights including right vote right good administration access public documents right petition administration systems offer substantial potential improve scale efficien government provision public goods service society time citizen rights could also negatively impacted systems safeguarded term citizens rights used deny neglect rights third nationals irregular illegal persons also rights international law therefore area systems ethical principles context many public private civil organizations drawn inspiration fundamental rights produce ethical frameworks systems european group ethics science new technologies ege proposed set basic principles based fundamental values laid treaties build work recognising principles hitherto propounded various groups clarifying ends principles seek nurture support ethical principles inspire new specific regulatory instruments help interpreting fundamental rights socio environment evolves time guide rationale systems development deployment use adapting dynamicall society evolves systems improve individual collective wellbeing section lists four ethical principles rooted fundamental rights must respected order ensure systems developed deployed used trustworthy manner specified ethical imperatives practitioners always strive adhere without imposing hierarchy list principles manner mirrors order appearance fundamental rights upon based description term used throughout document see glossary principles also apply development deployment use technologies hence specific systems follows aimed set relevance specifically context reliance fundamental rights also helps limit regulatory uncertainty build basis decades practice fundamental rights protection thereby offering clarity readability foreseeability recently taskforce surveyed aforementioned ege principles well ethical principles put forward date subsumed four overarching principles floridi cowls beltrametti chatila chazerand dignum luetg madelin pagallo rossi schafer valcke vayena ethical framework good society opportunities risks principles recommendations minds machines respect human auto nomy strongly associated right human dignity liberty reflected articles charter prevention harm strongly linked protection physical mental integrity reflected artic principles respect human utonomy prevention harm iii fairness explicability many large extent already reflected existing legal requirements mandatory compli ance required hence also fall within scope lawful trustworthy first yet set many legal obligations reflect ethical principles adherence ethical principles goes beyond formal compliance existing rinciple respect human autonomy fundamental rights upon founded directed towards ensuring respect freedom autonomy human beings humans interacting systems must able keep full effective self determination able partake emocratic process systems unjustifiably subordinate coerce deceive manipulate condition herd humans instead designed augment complement empower human cognitive social cultural skills allocation nctions humans systems follow human design principles leave meaningful opportunity human choice means securing human work processe systems systems may also fundamentally change work sphere support humans working environment aim creation meaningful work rinciple prevention arm systems neither cause exacerbate otherwise adversely affect human beings entails protection human dignity well mental physical integrity systems environments operate must safe secure must technically robust ensured open malicio use vulnerable persons receive greater attention included development deployment use systems particular attention must also paid situations systems cause exacerbate adverse impacts due asymmetri power information employers employees businesses consumers governments citizens preventing harm also entails consideration natural environment living beings rinciple fairness development deployment use systems must fair acknowledge many different interpretations fairness believe airness substantive procedural dimension substantive dimension implies comm itment ensuring equal distribution benefits costs ensuring individuals groups free unfair bias discrimination stigmatisation unfair biases avoided systems could even increase societal fair ness qual opportunity terms access education goods services technology also fostered moreover use systems never lead people deceived unjustifiably impaired freedom choice additionally fairness implies practitioners respect principle proportionality means ends consider carefully fairness closel linked rights non solidarity justice reflected articles following explicability responsibility closely linked rights relating justice reflected article think instance gdpr consumer protection regulations reading subject see instance floridi soft ethics governance digital philosophy technology march volume issue concept human oversight developed one key requirements set chapter harms individual collective include intangible harm social cultural political environments also encompasses way living individuals social groups avoiding instance cultural harm balance competing interests procedural dimension fairness entails ability contest seek effective redress decisions made systems humans operating order entity accountable decision must identifiable decision processes explicable rinciple explicability explicability crucial building maintaining users trust systems means processes need transparent capabilities purpose systems openly communicated decisions extent possible explainable directly indirectly affected without information decision duly contested explanation model generated particular output decision combination input factors contributed always possible cases referred black box algorithms require special attention circumstances explicability easures traceability auditability transparent communication system capabilities may required provided system whole respects fundamental rights degree explicability needed highly dependent context severity consequences output erroneous otherwise inaccurate tensions rinciples tensions may arise principles fixed solution line fundamental commitment democratic engagement due process open political participation methods accountable deliberation deal tensions established instance various application domains principle prevention harm principle human autonomy may conflict consider example use systems predictive policing may help reduce crime ways entail surveillance activities impinge individual liberty privacy furthermore system overall benefits substantially exceed foreseeable individual risks principles certainly offer guidance towards solutions remain abstract ethical prescriptions practitioners hence expected find right solution based principles yet approach ethical dilemmas trade via reasoned evidence reflection rather intuition random discretion may situations however ethically acceptable trade identified certain fundamental rights correlated principles absolute subject balancing exercise human dignity key gui dance derived chapter develop deploy use systems way adheres ethical principles respect human autonomy prevention harm fairness explicability acknowledge address potential tensions principles pay particular attention situations involving vulnerable groups children persons disabilities others historically disadvantaged risk exclusion situations characterised asymmetries power information employers workers businesses relates principle proportionality reflected maxim one use sledge hammer crack nut measures taken achieve end data extraction measures implemented realise optimisation function limited strictly necessary also entails several measures compete satisfaction end preference given one least adverse fundamental rights ethical norms developers always prefer public sector data personal data reference also made proportionality user deployer considering rights companies includ ing intellectual property confidentiality one hand rights user including using right association join trade union working environment provided article charter fundamental rights example little ethical concern may flow inaccurate shopping recommendations generated system contrast systems evaluate whether individual convicted criminal offence released par ole see articles charter dealing rights child elderly integration persons wit disabilities workers rights see also article dealing consumer protection acknowledge bringing substantial benefits individuals society systems also pose certain risks may negative impact including impacts may difficult anticipate identify measure democracy rule law distributive justice human mind adopt adequate measu res mitigate risks appropriate proportionately magnitude risk chapter realising trustworthy chapter offers guidance implementation realisation trustworthy via list seven requirements met building principles outlined chapter addition available technical non methods introduced implementation requirements throughout system life cycle requirements trustworthy principles outlined chapter must translated concrete requirements achieve trustworthy requirements applicable different stakeholders partaking systems life cycle developers deployers well broader society developers refer research design develop systems deployers refer public private organisations use systems within business processes ffer products services others end engaging system directly indirectly finally broader society encompasses others directly indirectly affected systems different groups stakeholders hav different roles play ensuring requirements met developers implement apply requirements design development processes deployers ensure systems use products services offer meet requirements broader society informed requirements able request upheld list requirements non includes systemic individual societal aspects human agency oversight including fundamental rights human agency human oversight technical obustness safety including resilience attack security fall back plan general safety accuracy reliability reproducibility privacy data governance including respect privacy quality integrity data access data transparency including traceability explainability communication diversity airness including avoidance unfair bias accessib ility universal design stakeholder participation societal nvironmental wellbeing including sustainability environmental friendliness social impact society democracy accountability including auditability minimisation reporting negative impact trade redress without imposing hierarchy list principles manner mirrors order appearance principles rights relate charter figure interr elationship seven requirement equal importance support implemented evaluated throughout system lifecycle requirements equal importance context potential tensions need taken account applying across different domains industries implementation requirements occur throughout stem entire life cycle depends specific application requirements apply systems special attention given directly indirectly affecting individuals therefore applications instance industria settings may lesser relevance requirements include elements cases already reflected existing laws reiterate line trustworthy first component responsibility practitioners ensure comply legal obligations regards horizontally applicable rules well domain regulation following paragraphs requirement explained detail human agency oversight systems support human autonomy decision prescribed principle respect human autonomy requires systems act enablers democratic flourishing equitable society supporting user agency foster fundamental rights allow human oversight fundamental rights like many technologies systems equall enable hamper fundamental rights benefit people instance helping track personal data increasing accessibility education hence supporting right education however given reach capacity systems also negatively affect fundamental rights situations risks exist fundamental rights impact assessment undertaken done prior system development include evaluation whether risks reduced justified necessary democratic society order respect rights freedoms others moreover mechanisms put place receive external feedback regarding sys tems potentially infringe fundamental rights human agency users able make informed autonomous decisions regarding systems given knowledge tools comprehend interact systems satisfactory egree possible enabled reasonably self challenge system systems support individuals making better informed choices accordance goals systems sometimes deployed shape influen human behaviour mechanisms may difficult detect since may harness processes including various forms unfair manipulation deception herding conditioning may threaten individual autonomy verall principle user autonomy must central system functionality key right subject decision based solely automated processing produces legal effects users similarly significantly affects human oversight human oversight helps ensur ing system undermine human autonomy causes adverse effects oversight may achieved governance mechanisms human hitl human hotl human hic approach hitl refers capability human intervention every decision cycle system many cases neither possible desirable hotl refers capability human intervention design cycle system monitoring system operation hic refers capability oversee overall activity system including broader economic societal legal ethical impact ability decide use system particular situation include decision use system particular situation establish levels human discretion use system ensure ability override decision made system moreover must ensured public enforcers ability exercise oversight line mandate oversight mechanisms required varying degrees support oth safety control measures depending system application area potential risk othe things equal less oversight human exercise system extensive testing stricter governance required technical robustness safety crucial component achieving trustworthy technical robustness closely linked principle prevention arm technical obustness requires systems developed preventative approach risks manner reliably behave intend minimis ing unintentional unexpected harm preventing unacceptable harm also appl potential changes operating environment presence agents human artificial may interact system adversarial manner addition physical mental integrity humans ensured resilience attack security systems like software systems protected vulnerabilities allow exploited adversaries hacking attacks may target data data poisoning model model leakage underlying infrastructure software hardware system attacked adversarial attacks data well system behaviour changed leading system make different decisions causing shut altogether systems data also become corrupted licious intention exposure unexpected situations insufficient security processes also result erroneous decisions even physical harm systems considered possible unintended applications system dual applications potential abuse system malicious actors taken account steps taken prevent mitigate fallback plan general afety systems hav safeguards enable fall back plan case problems reference made article gdpr right already enshrined see considerations european union coordinated plan artificial intelligence may strong imperative develop virtuous circle research development understanding attacks development adequate protection improvement evaluation methodologies achieve convergence community security community promoted addition responsibility relevant actors create common cross safety securit norms establish environment mutual trust fostering international collaboration possible measures see malicious use avin brundage mean systems switch statistical rule procedure ask human operator continuing action must ensured system supposed harming living beings environment includes minimi sation unintended consequences errors addition processes clarify assess potential risks associated use systems across various application areas established level safety measures required depend magnitude risk posed system turn depends system capabilities foreseen development process ystem pose part icularly high risks crucial safety measures developed tested proactively accuracy accuracy pertains system ability make correct judgements example correctly classify information proper categories ability make correct predictions recommendations decisions based data models explicit well development evaluation process support mitigate correct unintended risks inaccurate predictions occasional inaccurate predictions avoided important system indicate likely erro high level accuracy especially crucial situations system directly affects human lives reliability reproducibility critical results systems reproducible well reliable reliable syst one works properly range inputs range situations needed scrutinise system prevent unintended harms reproducibility describes whether experiment exhibits behaviour repeated conditions enables scientists policy makers accurately describe systems replication facilitate process testing reproducing behaviours privacy data overnance closely linked principle prevention arm privacy fundamental right particularly affected systems prevention harm privacy also necessitates adequate dat governance covers quality integrity data used relevance light domain systems deployed access protocols capability process data manner protects privacy privacy data rotection systems must guarantee privacy data protection throughout system entire lifecycle includes information initially provided user well information generated user course interaction system outputs system generated specific users users responded particular recommendations digital records human behaviour may allow systems infer individuals preferences lso sexual orientation age gender religious political views allow individuals trust data gathering process must ensured data collected used unlawfully unfairly discriminate quality integrity ata quality data sets used paramount performance systems data gathered may cont socially constructed biases inaccuracies errors mistakes needs addressed prior training given data set addition integrity data must ensur feeding malicious data system may change behaviour particularly self systems processes data sets used must tested documented step planning training testing deployment also apply systems developed acquired elsewhere acce ata given organisation handl individuals data whether someone user system ata protocols governing data access put place protocols outline access data circumstances nly duly qualified personnel competence need access individual data allowed scenarios human intervention would immediately possible shou also considered concerns files replicate step system development process research initial data coll ection results reference made existing privacy laws gdpr forthco ming eprivacy regulation transparency requirement closely linked principle xplicability encompasses transparency elements relevant system data system business models traceability data sets processes yield system decision cluding data gathering data labelling well algorithms used documented best possible standard allow traceability increase transparency also applies decisions made system enables identification reasons erroneous turn could help prevent future mistakes traceability facilitates auditability well explainability explainability explainability concerns ability explain technical processes system related human decisions application areas system technical explainability requires decisions made system understood traced human beings moreover trade might made enhancing system explainability may reduce accuracy increasing accuracy cost explainability whenever system significant impact people lives possible demand suitable explanation system decision process explanation timely adapted expertise stakeholder conce rned layperson regulator researcher addition explanations degree system influences shapes organisational decision process design choices system rationale deploying available hence ensuring business model transparency communication systems represent emselves humans users humans right informed interacting system entails systems must identifiable addition option decide interaction favour human interaction provided needed ensure compliance fundamental rights beyond stem capabilities limitations communicated practitioners end manner appropriate use case hand could encompass communication system level accuracy well limitations diversity non fairness order achieve trustworthy must enable clusion diversity throughout entire system life cycle besides consideration involvement affected stakeholders throughout process also entails ensuring equal access inclusive design processes well equal treatment requirement closely linked principle airness avoidance unfair ias data sets used systems training operation may suffer inclusion inadvertent historic bias incompl eteness bad governance models continuation biases could lead unintended direct prejudice certain groups people potentially exacerbating prejudice marginalisation harm also result intentional exploitation consumer biases engaging unfair competition homogenisation prices means collusion nontransparent identifiable discriminatory bias remov collection phase possible way systems developed algorithm programming may also suffer unfair bias uld counteracted putting place oversight processes analyse address system purpose constraints requirements decisions clear transparent manner moreover hiring diverse backgrounds cultures disciplines ensure diversity opinions encouraged accessibility universal esign particularly business domains systems user designed way allows people use products services regardless age gender abilities characteristics accessibility technology persons disabilities present societal definition direct indirect discrimination see instance article council directive nove mber establishing general framework equal treatment employment occupation see also article charter fundamental rights see agency fundamental rights paper bigdata discrimination data decision making groups particular importance systems one approach consider universal principles addressing widest possible range users follow ing relevant accessibility standards enable equitable access active participation people existing emerging computer human activities regard assistive stakeholder participation order develop systems trustworthy advisable consult stakeholders may directly indirectly affected system throughout life cycle beneficial solicit regular feedback even deployment set longer mechanisms stakeholder participation example ensuring workers information consultation participation throughout whole process implementi systems organisations societal environmental line principles fairness prevention arm broader society sentient beings environment also considered stakeholders throughout system life cycle sustainability ecological responsibility systems encouraged research fostered solutions addressing areas global concern instance sustainable development goals ideally systems used benefit human beings including future generations sustainable environmentally friendly systems promise help tackling pressing societal concerns yet must ensured occurs environmentally friendly way possible system development deployment use process well entire supply chain assessed regard via critical examination resource usage energy consumption training opting less harmful choice measures securing environmental frie ndliness system entire supply chain encouraged social impact ubiquitous exposure social areas lives education work care entertainment may alter conception social agency impact social relationships attachment systems used enhance social skills equally contribute deterioration could also affect people physic mental wellbeing effects systems must therefore carefully monitored considered society democracy beyond assessing impact system development deployment use individual impact also assessed societal perspective taking account effect institutions democracy society large use systems given careful consideration particularly situations relating democratic process including political decision also electoral contexts accountability requirement accountability complements requirements closely linked principle fairness necessitates mechanisms put place ensure responsibility accountability systems outcomes development deployment use auditability auditability entails enablement assessment algorithms data design processes necessarily imply information business odels intellectual roperty related article public procurement directive requires technical specifications consider accessibility design instance requirement links united nations convention rights persons disabilities denotes systems communicating interacting humans simulating sociality human robot interaction embodied avatars virtual reality ing systems potential change socio practices fabric social life see instance project developing software enables robots interact effectively autistic childre human therapy sessions helping improve social communication skills infocentre system must always openly available evaluation internal external auditors availability evaluation reports contribute trustworthiness technology applications affecting fundamental rights including safety applications systems able independently audited minimisation reporting negative impacts ability report actions decisions contribute certain system outcome respond consequences outcome must ensured identifying assessing documenting minimis ing potential negative impacts systems especially crucial directly affected due protection must available whistle ngos trade unions entities reporting legitimate concerns system use impact assessments red teaming forms algorithmic impact assessment prior development deployment use systems helpful minimise negative impact assessments must proportionat risk systems pose trade implement ing requirements tensions may arise may lead inevitable trade trade addressed rational methodological manner within state art entails relevant interests values implicated system identified conflict arises trade explicitly acknowledged evaluated terms risk ethical princi ples including fundamental rights situations ethically acceptable trade identified development deployment use system proceed form decision trade make reasoned properly documented decision must accountable manner appropriate trade made continually review appropriateness resultin decision ensure necessary changes made system redress unjust adverse impact occurs accessible mechanisms foreseen ensure adequate knowing redress possible things wrong key ensure trust particular attention paid vulnerable persons groups technical non ethods realise trustworthy implement requirements technical non methods employed encompass stages system life cycle evaluation met hods employed implement requirements well reporting changes implementation processes occur ongoing basis systems continuously evolving acting dynamic environment realisation trustworthy therefore continuous process depicted figure figure realising trustworthy throughout system entire life cycle different governance models help achieving presence internal external ethic sector specific expert board might useful highlight areas potential conflict suggest ways conflict might best resolved meaningful consultation discussion stakeholders including risk adverse affected system useful european universities take leading role training ethics experts needed see also european union agency fundamental rights opinion improving access remedy area business human rights level entails justification choices system design development deployment implement requirements following methods either complementary alternative since different requirements different sensitivities may raise need different methods implementation overview neither meant comprehensive exhaustive mandatory rather aim offer list suggested methods may help implement trustworthy technical methods section describ technical methods ensure trustworthy incorporated design development use phases system methods listed vary level maturity architectures trustworthy requirements trustworthy translated procedures constraints procedures anchored system architecture could accomplished set white list rules behaviours states system always follow black list restrictions behaviours states system never transgress mixtures complex provable guarantees regarding system behaviour monitoring system compliance restrictions operations may achieved separate process system learning capabilities dynamically adapt behaviour understood nondeterministic system possibly exhibiting unexpe cted behaviour often considered theoretical lens sense cycle adapting architecture ensure trustworthy requires requirements integration three steps cycle sense system developed recognises environment elements necessary ensure adherence requirements plan system consider plans adhere requirements iii act system actions restricted behaviours realise requirements architecture sketched generic provides imperfect description systems nevertheless gives anchor points constraints policies reflected specific modules result overall system trustworthy perceived ethics ule law design methods ensure values provide precise explicit links abstract principles system required respect specific implementation decisions idea ompliance norms implemented design system key method companies responsible identifying impact systems start well norms system ought comply avert negative impacts different concepts ready widely used privacy security indicated earn trust needs secure processes data outcomes designed robust adversarial data attacks implement echanism fail shutdown enable resumed operation forced shut attack explanation methods system trustworthy must able understand behaved certain way provided given interpretation whole field research explainable xai tries address issue better understand system underlying mechanisms find solutions today still open challenge systems based neural networks training processes neural nets result network parameters set numerical values difficult correlate results moreov sometimes small changes data values might result dramatic changes interpretation leading system confuse school bus ostrich vulnerability also exploited attacks system methods involving xai res earch vital explain system ome methods already available today others still require research areas research needed also inform hleg second deliverable policy investment recommendations behaviour users also deploy reliable technology testing validating due non context nature systems traditional testing enough failures concepts representations used system may manifest program applied sufficiently realistic data consequently verify validate processing data underlyi model must carefully monitored training deployment stability robustness operation within well understood predictable bounds must ensure outcome planning process consistent input decisions made way allowing validation underlying process testing validation system occur early possible ensuring system behaves intended throughout entire life cycle especially afte deployment include components system including data models environments behaviour system whole testing processe designed performed diverse group people possible multiple metrics developed cover categories tested different perspectives adversarial testing trusted diverse red teams deliberately attempting break system find vulnerabilities bug bounties incentivise outsiders detect responsibly report system errors weaknesses considered finally must ensured hat outputs actions consistent results preceding processes comparing previou sly defined policies ensure violated quality service indicators appropriate quality service indicators defined systems ensure baseline understanding whether tested developed security safety considerations mind indicators could include measures evaluate testing training algorithms well traditional software metrics functionality performance usability reliability security maintainability non methods section describes variety methods hat serve valuable role securing maintaining trustworthy evaluated ongoing basis regulation mentioned regulation support trustworthiness already exists today think product safety legislation liability frameworks extent consider regulation may need revised adapted introduced safeguard enabler raised second deliverable consisting policy investment recommendations codes conduct organisations stakeholders sign guidelines adapt charter corporate responsibility performance indicators kpis codes conduct internal policy documents add striving towards trustworthy organi sation working system generally document intentions well underwrite standards certain desirable values fundamental rights transparency avoidance harm standardisation standards exam ple design manufacturing business practices function quality management system users consumers organisations research institutions governments offering ability recognise encourage ethical conduct purchasing decisions beyond conventional standards regulatory approaches exist accreditation systems professional codes ethics standards fundamental rights compliant design current examples iso standards ieee standa rds series future possible trustworthy label might suitable confirming reference specific technical standa rds system instance adheres safety technical robustness transparency certification expected everyone able fully understand workings effects systems consideration given organisations attest broader public system transparent accountable certifications would apply standards developed different application domains techniques appropriately aligned industrial societal standards different context certification however never replace responsibility ould hence complemented accountability frameworks including disclaimers well review redress accountability via governance frameworks organisations set governance frameworks internal external ensuring accountability ethical dimensions decisions associated development depl oyment use systems instance include appointment person charge ethics issues relating systems ethics panel board amongst possible roles person panel board provide oversight advice set certification specifications bodies also play role end communication channels ensured industry public oversight groups sharing best practices discussing dilemmas reporting emerging issues ethical concerns mechanisms complement replace legal oversight form appointment data prote ction officer equivalent measures legally required data protection law education awareness foster ethical mind trustworthy encourages informed participation stakeholders communication education training play important role ensure knowledge potential impact systems widespread make people aware participate shaping societal development includes stakeholders involved makin products designers developers users companies individuals impacted groups may purchase use system decisions made system society large basic literacy fostered across society pre requisite educating public ensure proper skills training ethicists space stakeholder participation social dialogue benefits systems many europe needs ensure available requires open discussion involvement social partners stakeholders including general public many organisations alread rely stakeholder panels discuss use systems data analytics panels include various members legal experts technical experts ethicists consumer representatives workers actively seeking participation dialogue use impact systems supports evaluation results approaches particularly helpful complex cases diversity inclusive design teams diversity inclusion play essential role developing systems employed real world critical systems perform tasks teams design develop test maintain deploy procure systems reflect diversity users society general contributes objectivity consideration different perspectives needs objectives ideally eams diverse terms gender culture age also ter professional backgrounds skill sets advocated ieee ethically aligned design initiative connect limitations certification see key guidance derived chapter ensure system entire life cycle meets seven key requirements trustworthy human agency oversight technical robustness safety privacy data overnance transparency iversity fairness environmental ocietal well accountability consider technical non methods ensure implementation requirements foster research innovation help assessing systems achievement requirements disseminate results open questions wider public systematically train new generation experts ethics communicate clear proactive manner information stakeholders system capabilities limitations enabling realistic expectation setting manner requirements implemented transparent act dealing system facilitate traceability auditability systems particularly critical contexts situations involve stakeholders throughout system life cycle foster training education stakeholders aware trained trustworthy mindful might fundamental tensions different principles requirements continuously identify evaluate document communicate trade solutions iii chapter iii assessing trustworthy based key requirements chapter chapter sets non trustworthy assessment list pilot version operationalise trustworthy particularly applies systems directly interact users primarily addressed developers deployers systems whether acquired third parties assessment list address operationalisation first component trustworthy lawful compliance assessment list evidence legal compliance intended guidance ensure compliance applicable law given application systems assessment list need tailored specific use case context system operate addition chapter offers general recommendation implement assessment list trustworthy though governance structure embracing operational management level assessment list governance structure developed close collaboration stakeholder across public private sector process driven piloting process allowing extensive feedback two parallel processes qualitative process ensuring representability small selection companies organisations institutions different sectors different sizes sign pilot assessment list governance structure practice provide feedback quantitative process interested stakeholders sign pilot assessment list provide feedback open cons ultation piloting phase integrate results feedback process assessment list prepare revised version early aim achieve framework horizontally used across applicati ons hence offer foundation ensuring trustworthy domains foundation established sector ial application framework could developed governance stakeholders may wish consider trustworthy assessment list implemented organisation done incorporating assessment process existing governance mechanisms implementing new processes hoice depend internal structure organisation well size available resources research demonstrates management attention highest level essential achieve also demonstrates involving stak eholders company organisation institution fosters acceptance relevance introduction new process whether technological therefore recommend implementing process embraces involvement operational level well top management level level relevant oles depending organisation management board top management discusses evaluates systems development deployment procurement serves escalation board evaluating innovations uses critical concerns detected involves impacted possible introduction system workers representatives throughout process via inf ormation consultation participation procedures responsibility department responsibility department onitor use assessment list necessary evolution meet technological regulatory changes updates standards internal policies systems ensure use system complies current legal regulatory framework value organisation product service development equivalent product service development department uses assessment list evaluate product services log results results discussed management level ultimately approve new revised applications quality assurance quality assurance department equivalent ensure check results assessment list take action escalate issue higher result satisfactory unforeseen results detected department nsure right mix competences diversity profile developers systems ensure appropriate level training delivered trustworthy inside organisation procurement procurement department ensure process procure products services includes check trustworthy operations developers project managers include assessment list daily work document results outcomes assessment using trustworthy assessment list using assessment list practice recommend paying attention areas concern also questions easily answered one potential problem might lack diversity skills competences team developing testing system therefore might necessary involve stakeholders inside outside organisation strongly recommended log results technical terms management terms ensuring problem solving understood levels governance structure assessment list meant guide practitioners achieve trustworthy assessment tailored specific use case proportionat way piloting phase specific sensitive areas might revealed need specifications cases evaluated next step see instan bryson barth dale effects organisational change worker well moderating role trade unions ilrreview july jirjahn smith factors lead management support oppose employee participation without works councils hypotheses evidence germany industrial relations michie sheehan labour market deregu lation flexibility innovation cambridge journal econom ics assessment list provide concrete answers address raised questions encourages reflection trustworthy operationalised potential steps taken regard relation existing law processes also important practitioners recognise various existing laws mandating particular processes prohibiti particular outcomes may overlap coincide measures isted assessment list example data protection law sets series legal requirements must met engaged collection processing personal data yet trustworthy also requires ethical handling data internal procedures policies aimed securing compliance data protection laws might also help facili tate ethical data handling hence complement existing legal processes compliance assessment list however evidence legal compliance intended guidance ensure compliance applicable laws moreover many practitioners already existing assessment tools software development processes place ensure compliance als non standards assessment sho uld necessarily carried stand exercise incorporated existing practices trustworthy assessment list pilot version human agency oversight fundamental rights carry fundamental rights impact assessment could negative impact fundamental rights identify document potential trade made different principles rights system interact cisions human end users recommended actions decisions take presenting options could system affect human autonomy interfering end user decision process unintended way consider whether system communicate end users decision content advice outcome result algorithmic decision case chat bot conversational system human end users made aware interacting non agent human agency system implemented work labour process consider task allocation system humans meaningful interactions appropriate human oversight control system enhance augment human capabilities take safeguards prevent overconfidence overreliance system work processes human oversight consider appropriate level human control particular system use case describe level human control involvement human control moments tools human intervention put place mechanisms measures ensure human control oversight take measures enable audit remedy issues related governing autonomy self autonomous system use case put place specific mechanisms control oversight whic detection response mechanisms establish assess whether something could wrong ensure stop button procedure safely abort operation needed procedure abort process entirely part delegate cont rol human technical robustness safety resilience attack security assess potential forms attacks system could vulnerable consider different types natures vulnerabilities data pollution physical infrastructure cyber put measures systems place ensure integrity resilience system potential attacks verify system behaves unexpected situations environments consider degree system could dual take suitable preventative measures case including instance publishing research deploying system fallback plan general safety ensure system sufficient fallback plan encounters adversarial attacks unexpected situations example technical switching procedures asking human operator proceeding consider level risk raised system specific use case put process place measure assess risks safety provide necessary information case risk human physical integrity consider insurance policy deal potential damage system identify potential safety risks foreseeable uses technology including accidental malicious misuse plan mitigate manage risks assess whether ere probable chance system may cause damage harm users third parties assess likelihood potential damage impacted audience severity consider liability consumer protection rules take account consider potential impact safety risk environment animals risk analysis include whether security network problems cybersecurity hazards could pose safety risks damage due unintentional beh aviour system estimate likely impact failure system provides wrong results becomes unavailable provides societally unacceptable results example discrimination define thresholds put governance procedures place trigger plans define test fallback plans accuracy assess level definition accuracy would required context system use case assess accuracy measured assured put place measures ensure data used comprehensive date put place measures place assess whether need additional data example mprove accuracy eliminate bias verify harm would caused system makes inaccurate predictions put place ways measure whether system making unacceptable amount inaccurate predictions put place series steps increase system accuracy reliability reproducibility put place strategy monitor test system meeting goals purposes intended applications test whether specific contexts particular conditions need taken account ensure reproducibility put place verification methods measure ensure different aspects system reliability reproducibility put place processes describe system fails certain types settings clearly document operationalise processes testing verification reliability systems establish mechanisms communication assure end use system reliability privacy data governance respect privacy data protection depending use case establish mechanism allowing others flag issues related privacy data rotection system processes data collection training operation data processing assess type scope data data sets example whether contain personal data consider ways develop system train model without minimal use potentially sensitive personal data build mechanisms notice control personal data depending use case valid consent possibility revoke applicable take measures enha nce privacy via encryption anonymisation aggregation data privacy officer dpo exists involve person early stage process quality integrity data align system relevant standards example iso ieee widely adopted protocols daily data management governance establish oversight mechanisms data collection storage processing use assess ext ent control quality external data sources used put place processes ensure quality integrity data consider processes verifying data sets mpromised hacked access data protocols processes procedures follow manage ensure proper data governance assess access users data circumstances ensure persons qualifi required access data necessary competences understand details data protection policy ensure oversight mechanism log purpose data accessed transparency traceability establish measures ensure traceability could entail documenting following methods methods used designing developing algorithmic system rule systems method programming model built learning systems method training algorithm including input data gathered selected occurred methods used test validate algorithmic system rule systems scenarios cases used order test validate learning model information data used test validate outcomes algorithmic system outcomes decisions taken algorithm well potential decisions would result different cases example subgroups users explainability assess extent decisions hence outcome made system understood degree system decision influences organisation decision processes particular system deployed specific area system business model example create value orga nisation ensure explanation system took certain choice resulting certain outcome users understand design system interpretability mind start research try use simplest interpretable model possible application question assess whether analyse training testing data change update time assess whether examine interpretability model training development whether access internal workflow model communication communicate end users disclaimer means interacting system another human label system establish mechanisms inform end users reasons criteria behind system outcomes communicate clearly intelligibly intended audience establ ish processes consider users feedback use adapt system communicate around potential perceived risks bias depending use case consider communication transparency towards audiences third arties general public clarify purpose system may benefit specify usage scenarios product clearly communicate ensure understandable appropriate intended audience depending use case think human psychology potential limitations risk confusion confirmation bias cognitive fatigue clearly communicate characteristics limitations potential shortcomings system case system development whoever deploying product service case system deployment end user consumer diversity non fairness unfair bias avoidance establish strategy set procedures avoid creating reinforcing unfair bias system regarding use input data well algorithm design assess acknowledge possible limitations stemming composition used data sets consider diversity representativeness users data test specific populations problematic use cases search use available technical tools improve understanding data model performance put place processes test monitor potential biases development deployment use phase system depending use case ensure mechanism allows others flag issues related bias discrimination poor performance system establish clear steps ways communicating issues raised consider others potentially indirectly affected system addition end users assess whether possible decision variability occur conditions consider possible cause could case variability establish measurement assessment mechanism potential impact variability fundamental rights ensure adequate working definition fairness apply designing systems definition commonly used consider definitions choosing one ensure quantitative analysis metrics measure test applied definition fairness establish mechanisms ensure fai rness systems consider potential mechanisms accessibility universal design ensure system accommodates wide range individual preferences abilities assess whether system usable special needs disabilities risk exclusion designed system verified ensure information system accessible also users assistive technologies involv consult community development phase system take impact system potential user audience account assess whether team involved building system representative target user audience representative wider population considering also groups might tangentially impacted assess whether could persons groups might disproportionately affected negative implicatio get feedback teams groups represent different backgrounds experiences stakeholder participation consider mechanism include participation different stakeholders system development use pave way introduction system organisation informing involving impacted workers representatives advance societal environmental well sustainable environmentally friendly establish mechanisms measure environmental impact system development deployment use example type energy used data centres ensure measures reduce environmental impact system life cycle social impact case system interacts directly humans assess whether system encourages humans develop attachment empathy towards system ensure system clearly signals social interactio simulated capacities understanding feeling ensure social impacts system well understood example assess whether risk job loss workforce wha steps taken counteract risks society democracy assess broader societal impact system use beyond individual end user potentially indirectly affected stakeholders accountability auditability establish mechanisms facilitate system auditability ensuring traceability logging system processes outcomes ensure applications affecting fundamental rights including safety applications system audited independently minimising reporting negative impact carry risk impact assessment system takes account different stakeholders tha directly ffected provide training education help developing accountability practices workers branches team involved beyond developmen phase trainings also teach potential legal framework applicable system consider establishing ethical review board similar mechanism discuss overall accountability ethics practices including potentially unclear grey areas foresee kind external guidance put place auditing processes oversee ethics accountability addition internal initiatives establish processes third parties suppliers consumers workers report potential vulnerabilities risks bia ses system documenting trade establish mechanism identify relevant interests values implicated system potential trade decide trade ensure trade decision documented ability redress establish adequate set mechanisms allows redress case occurrence harm adverse impact put mechanisms place provide information end parties opportunities redress invite stakeholders pilot assessment list practice provide feedback implementability completeness relevance specific application domain well overlap complementarity existing compliance assessment processes based feedback revised version trustworthy assessment list proposed commission early key guidance derived chapter iii adopt trustworthy assessment list developing deploying using systems adapt specific use case system applied keep mind assessment list never exhaustive ensuring trustworthy ticking boxes continuously identifying requirements evaluating solutions ensuring improved outcomes throughout system lifecycle involving stakeholders therein examples opportunities critical concerns raised following section provide examples development use encouraged well examples development deployment use run counter values may raise spe cific concerns balance must struck done due care must given done examples trustworthy opportunities trustworthy represent great opportunity support mitigation pressing challenges facing society ageing population growing social inequality environmental pollution potential also reflected globally sustainable development following section looks encourage european strategy tackles challenges climate ction sustainable nfrastructure tackling climate change top priority policy across world digital transformation trustworthy great potential reduce humans impact environment enable efficient effective use energy natural resources trustworthy instance coupled big data order dete energy needs accurately resulting efficient energy infrastructure consumption looking sectors like public transportation systems intelligent transport used minimise queuing optim ise routing allow vision impaired people independent optimise energy efficient engines thereby enhance decarboni sation efforts reduce environmental footprint greener society currently worldwide one human dies every seconds car systems could help reduce number fatalities significantly instance better reaction times better adherence health well trustworthy technologies used already used render treatment smarter targeted help preventing doctors medical professionals potentially perform accurate detailed analysis patient complex health data even people get sick provide tailored preventive context europe ageing population technologies robotics valuabl tools assist caregivers support elderly care monitor patients conditions real time number projects aim development smart grids energy storage potential contribute successful digitally supported energy transition including digital solutions compleme work hose individual project commission launched bridge initiative allowing ongoing horizon smart grid energy storage rojects create common view cross cutting issues see instance encompass project new solutions help prepare cities future mobility see instance funded project called fabulos see instance project hich part european vision strategy combat preventable blindness especially due old age mobility orientation one project priority areas european project instance aims address outlined transport challenges providing contributions enabling gradual automation collaboration among vehicles facilitating safer inclusive affordable transportation system tps see instance revolver repeated evolution cancer project murab project conducts accurate biopsies aims diagnosing cancer illnesses faster see instance live incite project consortium healthcare procurers challenges industry develop smart ict solutions enable lifestyle interventions perioperative process rget concerns new inn ovative ehealth solutions influence patients personalised way take necessary actions prior surgery lifestyle optimise healthcare outcome project caresses deals robots elderly care focusing cultural sensitivity adapt way acting speaking match culture habits elderly person assisting see also application called alfred virtual assistant helping older people stay active basis thus saving lives trustworthy also assist broader scale example examine identify general trends healthcare treatment sector leading earlier detection diseases efficient development medicines targeted ultimately lives saved quality education igital transformation new technological economic environmental changes mean society needs become proactive governments industry leaders educational institutions unions face responsibility bring citizens new digital era ensuring right skills fill future jobs trustworthy technologies could assist accurately forecasting jobs professions disrupted technology new roles created skills needed could help governments unions industry plan ning skilling workers could also give citizens may fear redundancy path development new role add ition great tool fight educational inequalities cre ate personalised adaptable education program mes could help everyone acquire new qualifications skills competences according ability could increase learning speed quality education reaching primary school university examples critical oncerns raised critical concern arises one components trustworthy violated many concerns listed already fall within scope existing legal requirements mandatory must therefore complied yet even circumstances compliance legal requirements demonstrated may address full range ethical concerns may arise understanding adequacy rules ethical principles invariably evolves may change time following non list concerns may shortened expanded edit updated future identifying tracking individuals enables ever efficient identification individual persons public private entities noteworthy examples scalable identification technology face recognition involuntary methods identification using biometric data lie detection personality assessment micro expressions automatic voice detection identification individuals sometimes desirable outcome aligned ethical principles example detecting fraud money laundering terrorist financing however automatic identification raises strong concerns legal ethical nature may unexpected impact many psychological sociocultural levels proportionate use control techniques needed uphold autonomy european citizens clearly defining used automated identification individuals differentiating ide ntification individual tracing tracking individual moreover empattics project empowering patients better information improvement communication systems research define health care professi onals patients use ict technologies including systems plan interventions patients monitor progression physical mental state see instance myhealth avatar ers digital representation patient health status research project launched app online platform collects gives access digital long health status information takes form life health compan ion myhealthavatar also predi cts risk stroke diabetes cardiovascular disease hypertension see instance enrichme project tackles progressive decline cognitive capacity ageing pop ulation integrated platform ambient assisted living aal mobile service robot long monitoring interaction help elderly remain independent active longer see instance use sophia genetics leverages statistical inference ttern recognition machine learning maximize value genomics radiomics data see instance mathisis project aimed providing solution affect learning comfortable learning environment comprising high technological devices algorithms see also ibm watson classroom century tech platform targeted surveillance mass surveillance crucial achievement trustworthy application technologies must clearly warranted existing legal basis activity consent practical must developed allow meaningful verified consent given automatically identified equivalent technologies also applies usage anonymous persona data covert systems human beings always know directly interacting another human machine responsibility practitioners reliably achieved practitioners therefore ensure humans made aware able request validate fact interact system instance issuing clear transparent disclaimers note border line cases exist complicate matter voice spoken human born mind confusion humans machines could multiple consequences attachment influence reduction value development human therefore undergo careful ethical assessment enabled citizen coring violation fundamental ights societies strive protect freedom autonomy citizens form citizen scoring lead loss autonomy endanger principle non scoring used clear justification measures proportionate fair normative citizen scoring general assessment moral personality ethical integrity aspects large scale public authorities private actors endangers values especially used accordance fundamental rights used disproportionately without delineated communicated legitimate purpose today citizen scoring large smaller scale already often used purely descriptive domain scorings school systems driver licenc even narrow applications fully transparent procedure made vailable citizens including information process purpose methodology scoring note transparency prevent non ensure fairness panacea problem scoring ideally possibility opting scoring chanism possible without detriment provided otherwise mechanisms challenging rectifying scores must given particularly important situations asymmetry power exists parties opt option ensured technology design circumstances necessary ensure compliance fundamental rights necessary democratic society lethal autonomous weapon ystems laws currently unknown number countries industries researching developing lethal autonomous weapon systems ranging missiles capable selective targeting learning machines cognitive skills decide fight without human intervention raises fundamental ethical concerns fact could lead uncontrollable arms race historically unprecedented level create military contexts human control almost entirely relinquished risks malfuncti addressed european parliament called urgent development common legally binding position addressing ethical legal questions human control oversight accountability implementation international human rights international humanitarian law military recalling european union aim promote peace enshrined article treaty european union stand look support parliament resolution september related efforts laws regard article gdpr recalled provides among things processing data shall lawful valid legal basis current mechanisms giving informed consent internet show consumers typically give consent without meaningful consideration hence hardly classified practical madary metzinger real virtuality code ethical conduct recommendations good scientific practice consumers ology frontiers robotics also applies avatars european parliament resolution rsp potential longer concerns development still domain requires well human scientists engineers precisely specify targets however extrapolating future longer time horizon certain critical long concerns hypothesized risk approach suggests concerns kept consideration view possible unknown unknowns black swans high nature concerns combined current uncertainty corresponding developments calls regular assessments topics conclusion document constitutes ethics guidelines produced high expert group artificial intelligence hleg recognise positive impact systems already continue commercially societally however equally concerned ensure risks adverse impacts technologies associated properly proportionately handled technology transformative disruptive evolution last several years facilitated availability enormous amounts digital data major technologi cal advances computational power storage capacity well significant scientific engineering innovation methods tools systems continue impact society citizens ways yet imagine context important build systems worthy trust since human beings able confidently fully reap benefits technology including processes people behind technology trustworthy drafting uidelines trustworthy therefore foundational ambition trustworthy thre components awful ensuring compliance applicable laws regulations thical ensuring adherence ethical inciples values obust technical social perspective since ensure even good intentions systems cause unintentional harm component necessary sufficient achieve trustwo rthy ideally three components work harmony overlap operation tensions arise endeavour align chapter articulated fundamental rights corresponding set ethical principles cruci chapter listed seven key requirements systems meet order realise trustworthy proposed technical non methods help implementation finally chapter iii provided trustworthy assessment list help operationalising seven requirements final section provided exampl beneficial opportunities critica concerns raised systems hope stimulate discussion europe unique vantage point based focus placing citizen heart endeavours focus written nto dna european union treaties upon built current document forms part vision promotes trustworthy believe foundation upon europe build leadership innovative cut systems ambitious vision help securing human flourishing european citizens individually collectively goal create culture trustworthy europe whereby benefits reaped manner ensures respect foundational values fundamental rights democracy rule law consider artificial general intelligence artificial consciousness artificial moral agents super transformative examples long concerns currently non many others believe unrealistic black swan event rare yet high impact event rare might served hence probability occurrence typically estimated high uncertainty glossary glossary pertains guidelines meant help understanding terms used document artificial intelligence systems artificial intelligence systems software possibly also hardware systems designed given complex goal act physical digital dimension perceiving environment data acquisition interpreting collected structured unstructured data reasoning knowledge processing information derived data deciding best action take achieve given goal systems either use symbolic rules learn numeric model also adapt behaviour analysing environment affected previ ous actions scientific discipline includes several approaches techniques machine learning deep learning reinforcement learning specific examples machine reasoning includes planning scheduling knowledge representation reasoning search optimization robotics includes control perception sensors actuators well integration techniques cyber systems separate document prepared hleg elaborating definition used purpose document published parallel titled definition main capabilities scientific disciplines practitioners practitioners denote individuals organisations develop including research design provide data deploy including implement use systems excluding use systems capacity enduser consumer system life ycle system life cycle encompasses development including research design data provision limited trials deployment including implementation use phase auditability auditability refers ability syste undergo assessment system algorithms data design processes necessarily imply information business models intellectual property related system must always openly available ensuring traceabil ity logging mechanisms early design phase system help enabling system auditability bias bias inclination prejudice towards person object position bias arise many ways systems example data systems produced machine learning bias data collection training result system demonstrating bias logic rule systems bias arise due knowledge eng ineer might view rules apply particular setting bias also arise due online learning adaptation interaction also arise personalisation whereby users presented recommendations information feeds tailored user tastes necessarily relate human bias human data collection arise example limited contexts system used case opportunity generalise contexts bias good bad intentional unintentional certain cases bias result discri minatory unfair outcomes indicated document unfair bias humans design systems directly may also use techniques optimise design ethics ethics academic discipline subfield philosophy general terms deals questions like good action value human life justice good life academic ethics four major fields research meta mostly concerning meaning reference normative sentence question truth values determined normative ethics practical means determining moral course action examining standards right wrong action assigning value specific actions iii descriptive ethics aims empirical investigation people moral behaviour beliefs applied thics concerning obligated permitted specific often historically new situation particular domain often historically unprecedented possibilities action applied ethics deals real situations decisions made time pressure often limited rationality ethics generally viewed example applied ethics focuses normative issues raised design development implementation use within ethical discussions terms moral ethical often used term moral refers concrete factual patterns behaviour customs conventions found specifi cultures groups individuals certain time term ethical refers evaluative assessment concrete actions behavio urs systematic academic perspective ethical document ethical used indicate development deployment use ensures compliance ethical norms including fundamental rights special moral entitlements ethical principles related core values second three core elements ecessary achieving trustworthy human human approach strives ensure human values central way systems developed deployed used monitored ensuring respect fundamental rights including set treaties european union charter fundamental rights european union united reference common foundation rooted respect human dignity human enjoy unique inalienable moral status also entails consideration natural environment living beings part human ecosystem well sustainable approach enabling flourishing future generations come red teaming red teaming practice whereby red team independent group challenges organisation improve effectiveness assuming adversarial role point view particularly used help identifying addressing potential sec urity vulnerabilities reproducibility reproducibility describes whether experiment exhibits behaviour repeated conditions robust robustness system encompasses technical robustness appropriate given context application domain life cycle phase well robustness social perspective ensuring system duly takes account context environment system operates crucial ensure even good intentions unintentional harm occur robustness third three components necessary achieving trustworthy stakeholders stakeholders denote research develop design deploy use well directly indirectly affected including limited companies organisations researchers public services institutions civi society organisations governments regulators social partners individuals citizens workers consumers traceability traceability system refers capability keep track system data development deployment processes typically means documented recorded identification trust take following definition literature trust viewed set specific beliefs dealing benevolence competence integrity predictability trusting beliefs willingness one party depend another risky situation trusting intention combination trust usually property ascribed machines document aims stress importance bei able trust fact systems legally compliant ethically adherent robust also trust ascribed people processes involved system life cycle trustworthy trustworthy three components lawful ensuring compliance applicable laws regulations ethical demonstrating respect ensure adherence ethical principles values robust technical social perspective since even good intentions systems cause unintentional harm trustworthy concerns trustworthiness system also comprises trustworthiness processes actors part system life cycle vulnerable persons groups commonly accepted widely agreed legal definition vulnerable persons exists due heterogeneity constitutes vulnerable person roup often context temporary life events childhood illness market factors infor mation asymmetry market power economic factors poverty factors linked one identity gender religion culture fact ors play role charter fundamental rights encompasses article non following grounds reference point amongst others namely sex race colour ethnic social origin genetic features language religion belief political opinion membership national minority property birth disability age sexual orientation articles law address rights specific groups addition listed suc list exhaustive may change time vulnerable group group persons share one several characteristics vulnerability siau wang building trust artificial intelligence machine learning robotics cutter business technology journal document prepared members high expert group listed alphabetical order pekka ala chair hleg finland huhtamaki sanoma pierre lucas orgalim europe technology industries wilhelm bauer fraunhofer ieva martinkenaite telenor urs bergmann zalando thomas metzinger jgu mainz european university association m√°ria bielikov√° slovak university technology bratislava catelijne muller allai netherlands eesc cecilia bonefeld digitaleurope markus noga sap yann bonnet anssi barry sullivan vice hleg university college cork loubna bouarfa okra ursula pachl beuc st√©phan brunessaux airbus nicolas petit university li√®ge raja chatila ieee initiative ethics systems sorbonne university christoph peylo bosch mark coeckelbergh university vienna iris pl√∂ger bdi virginia dignum umea university stefano quintarelli garden ventures luciano floridi university oxford andrea renda college europe faculty ceps jean gagn√© element francesca rossi ibm chiara giovannini anec cristina san jos√© european banking federation joanna goodey fundamental rights agency george sharkov digital sme alliance sami haddadin munich school robotics philipp slusallek german research centre dfki gry hasselbalch thinkdotank dataethics copenhagen university fran√ßoise souli√© fogelman consultant fredrik heintz link√∂ping university saskia steinacker bayer fanny hidvegi access jaan tallinn ambient sound investment eric hilgendorf university w√ºrzburg thierry tingaud stmicroelectronics klaus h√∂ckner hilfsgemeinschaft der blinden und sehsch wachen jakob uszkoreit google mari j√©go orange aimee van wynsberghe delft leo k√§rkk√§inen nokia bell labs thi√©baut weber etuc sabine theresia k√∂szegi wien cecile wendling axa robert kroplewski solicitor advisor polish government karen yeung university birmingham elisabeth ling relx urs bergmann cilia bonefeld virginia dignum jean gagn√© thomas metzinger nicolas petit saskia steinacker aimee van wynsberghe karen yeung acted rapporteurs document pekka ala chairing hleg barry vice coordinating hleg second deliverable nozha boujemaa february coordinat ing first deliverable also contribut content document nathalie smuha provided editorial support
