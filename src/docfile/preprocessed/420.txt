model artificial intelligence governance framework artificial intelligence governance framework model second edition summary updates foreword preamble introduction objectives guiding principles model framework assumptions definitions model governance framework internal governance structures measures determining level human involvement operations management stakeholder interaction communication annex reference compilation existing ethical principles annex algorithm audits acknowledgements contents editiondate releasedsummary first january model governance framework first edition world economic forum annual meeting davos switzerland second january model governance framework second edition world economic forum annual meeting davos switzerland key changes include addition industry examples section illustrate organisations implemented governance practices section updating titles two sections accurately reflect content determining model determining level human involvement customer relationship management stakeholder interaction communication changes include following determining level human involvement aiaugmented clarified approach explaining human supervisory role aiaugmented clarified organisations consider factors nature reversibility harm operational feasibility determining level human involvement organisation process involving updates model artificial intelligence governance framework editiondate releasedsummary second january management provided guidance organisations adopt riskbased approach implementing measures identifying features functionalities greatest impact stakeholders considering measure would effective building trust stakeholders provided guidance necessity relevance various measures clarified datasets used building models may include personal nonpersonal data included new measures robustness reproducibility auditability provided examples helpful practices measures stakeholder interaction communication highlighted importance communication various internal external stakeholders highlighted need consider purpose context interacting various stakeholders provided suggestions level information provided interacting various stakeholders annex reference compilation existing ethical principles annex clarified list ethical principles provided compilation existing principles reference listed principles addressed model governance framework organisations could consider incorporating principles annex corporate principles editiondate releasedsummary second january algorithm audits clarified algorithm audit conducted necessary discover actual operations algorithms comprised models request regulator part forensic investigation annex use case annex removed instead separate compendium use cases published world saw significant advances sophistication pervasive use artificial intelligence instance witnessed emergence natural text generators like generate passages difficult distinguish human writing also saw development dactyl robotic hand uses reinforcement learning grasp manipulate common household objects dexterity examples attest speed advancement become ubiquitous daily lives discourse ethics governance also moved forward last two years governments international organisations begun issuing principles frameworks recommendations ethics governance january singapore launched model governance framework model framework world economic forum davos model framework unique contribution global discourse ethics lies translating ethical principles practical recommendations organisations could readily adopt deploy responsibly heartened diversity organisations adopted practices outlined model framework underscores relevance singapore proud launch second edition model framework edition incorporates experiences organisations adopted feedback participation leading international platforms european commission expert group oecd expert group input enabled provide clearer effective guidance organisations implement artificial intelligence governance framework singapore media development authority imda personal data protection commission pdpc also partnered world economic forum centre fourth industrial revolution develop implementation guide organisations isago isago complements model framework allowing organisations assess alignment governance practices model framework providing useful industry examples practices also publishing compendium use cases features realworld examples organisations implemented aligned governance practices model framework together initiatives enable organisation establish refine governance practices concrete practical ways initiatives play critical role singapore national strategy epitomise plans develop approach towards governance builds sustains public trust also reflect emphasis ecosystem collaborative inclusive manner model framework isago pave way future developments training professionals ethical deployment laying groundwork singapore world better address impact society steps take today leave indelible imprint collective future model framework recognised firm foundation responsible use future evolution build momentum advance approach one facilitates innovation safeguards public trust ensure positive impact world generations come iswaran minister communications information singapore january model artificial intelligence governance framework preamblemodel artificial intelligence governance framework model framework focuses primarily four broad areas internal governance structures measures human involvement operations management stakeholder interaction communication model framework certainly limited ambition ultimately limited form purpose practical considerations scope mind several caveats bear mentioning model framework focus specific data analytics methodology applies design application use general focus specific systems software technology apply regardless development language data storage method serves baseline set considerations measures organisations operating sector adopt specific sectors organisations may choose include additional considerations measures adapt baseline set meet needs pdpc encourages collaborate public agencies adapting model framework sectors focus organisations particular scale size also used organisations engaging activities operations business model model artificial intelligence governance framework recognised number issues closely interrelated ethical use deployment model framework focus specific issues often sufficient scope warrant separate study treatment examples issues include articulating new set ethical principles already number attempts globally establishing universal set principles consistent core set ethical principles emerging also penumbra variation across cultures jurisdictions industry sectors model framework uses existing common ethical principles compilation set annex converts implementable practices providing model frameworks addressing issues around data sharing whether public private sectors organisations within consortia number guides relevant imda trusted data sharing framework guide data valuation data sharing discussing issues relating legal liabilities associated intellectual property rights societal impacts employment competition unequal access products services different segments society technologies falling hands wrong people etc issues nevertheless pertinent explored separately platforms centre data governance established singapore management university school law model artificial intelligence governance framework objectives exponential growth data computing power fuelled advancement technologies used organisations provide new goods services boost productivity enhance competitiveness ultimately leading economic growth better quality life new technology however also introduces new ethical legal governance challenges include risks unintended discrimination potentially leading unfair outcomes well issues relating consumers knowledge involved making significant sensitive decisions advice advisory council proposes second edition living voluntary model framework general tool enable organisations deploying solutions scale responsible manner model framework intended organisations deploying updated commercial software packages happen incorporate feature set voluntary model framework provides guidance key issues considered measures implemented adopting model framework require tailoring measures address risks identified implementing organisation model framework intended assist organisations achieve following objectives build stakeholder confidence organisations responsible use manage different risks deployment demonstrate reasonable efforts align internal policies structures processes relevant practices data management protection personal data protection act pdpa oecd privacy principles section singapore personal data protection act imda designated pdpc assist organisations implementing model framework pdpc also prepared complementary isago isago helps organisations assess alignment governance practices processes model framework also provides additional useful industry references examples clarify recommendations set model framework extent organisations adopt recommendations model framework depends several factors including nature complexity used organisations extent employed organisations decisionmaking severity probability impact autonomous decision individuals elaborate technologies may used augment human autonomously make decision instance impact autonomous decision medical diagnosis arguably greater product recommendation commercial risks deployment therefore proportionate impact individuals generally cost implementing technologies ethical manner outweighs expected benefits organisations consider whether alternative solutions adopted considerations recommendations set framework intended guide organisations decided deploy technologies scale model artificial intelligence governance framework guiding principles model framework based two guiding principles promote trust understanding use technologies organisations using ensure process explainable transparent fair although perfect explainability transparency fairness impossible attain organisations strive ensure use application undertaken manner reflects objectives principles far possible helps build trust confidence solutions used amplify human capabilities protection interests human beings including safety primary considerations design development deployment organisations ensure processes explainable transparent fair solutions like technologies aims increase human productivity however unlike earlier technologies aspects autonomous predictions decisions made may fully explainable technologies make decisions affect individuals significant impact society markets economies organisations consider using model framework guide deployment organisations detail set ethical principles embark deployment scale within processes empower products services necessary organisations may wish refer compilation ethical principles annex far possible organisations also review existing corporate values incorporate ethical principles articulated ethical principles safety may articulated risks incorporated corporate risk management framework model framework designed assist organisations incorporating ethical principles familiar corporate governance structures thereby aid guiding adoption organisation model artificial intelligence governance framework assumptions model framework aims discuss good data management practices general model framework mainly applicable machine learning models compared pure decision models model framework address risk catastrophic failure due organisation heavily dependent organisations remain responsible ensuring availability reliability quality safety products services regardless whether technologies used adopting voluntary model framework absolve organisations compliance current laws regulations however framework adopting assist organisations demonstrating implemented practices data management protection pdpa oecd privacy principles noted certain industry sectors finance healthcare legal sectors may regulated existing laws regulations guidelines relevant sector example monetary authority singapore published principles promote fairness ethics accountability transparency use artificial intelligence data analytics singapore financial sector feat principles provide guidance firms use data analytics offer financial products organisations advised remain mindful laws regulations guidelines adopting model framework mean organisations compliance laws regulations guidelines monetary authority singapore principles promote fairness ethics accountability transparency feat use artificial intelligence data analytics singapore financial sector november definitions following simplified diagram depicts key stakeholders adoption process discussed model framework adoption process distinguish relationships terms used may different definitions depending context use definitions key terms used model framework follows solution providers organisations individuals refers set technologies seek simulate human traits knowledge reasoning problem solving perception learning planning depending model produce output decision prediction recommendation classificatio technologies rely algorithms generate models appropriate model selected deployed production develop solutions application systems make use technology include commercial products online services mobile applications software consumers use directly also applications fraud detection software sold financial institutions also include device equipment manufacturers integrate features products whose solutions standalone oducts meant integrated final product organisations develop solutions solution providers refers companies entities adopt deploy solutions operations backroom operations processing applications loans services portal app sale distribution devices provide features smart home appliances depending context refer persons organisations intend supply products services persons already purchased products services may referred consumers customers solution providers organisations individuals definition adapted various sources contextualised accordingly purposes model framework taken authoritative exhaustive model artificial intelligence governance framework model governance frameworkmodel artificial intelligence governance framework model governance framework model framework comprises guidance measures promoting responsible use organisations adopt following key areas internal governance structures measures adapting existing setting internal governance structure measures incorporate values risks responsibilities relating algorithmic determining level human involvement methodology aid organisations setting risk appetite use determining acceptable risks identifying appropriate level human involvement operations management issues considered developing selecting maintaining models including data management stakeholder interaction communication strategies communicating organisation stakeholders management relationships organisations adopting model framework may find elements relevant model framework meant flexible organisations adapt model framework suit needs adopting elements relevant help organisations better understand model framework included section illustrations demonstrating companies implemented certain practices described specific section addition pdpc also released compendium use cases illustrates various local international organisations put place governance practices aligned sections model framework model artificial intelligence governance framework internal governance structures measures section intended guide organisations developing appropriate internal governance structures allow org anisations appropriate oversight technologies brought operations products services internal governance structures measures help ensure robust oversight organisation use organisation existing internal governance structures adapted new structures implemented necessary example risks associated use managed within enterprise risk management structure ethical considerations introduced corporate values managed ethics review boards similar structures ethical considerations introduced corporate values managed ethics review boards similar structures organisations may also consider determining appropriate features internal governance structures example relying completely centralised governance mechanism optimal one could considered incorporate ethical considerations decisionmaking operational level necessary sponsorship support participation organisation top management board directors organisation governance crucial key roles responsibilities allocated include using existing risk management framework applying risk control measures see risk management internal controls assess manage risks deploying including potential adverse impact individuals vulnerable impacted assess scale impact get feedback impacted decide appropriate level human involvement manage model training selection process organisations may wish consider including features relevant development internal governance structure clear roles responsibilities ethical deployment responsibility oversight various stages activities involved deployment allocated appropriate personnel departments necessary possible consider establishing coordinating body relevant expertise proper representation across organisation personnel departments internal governance functions fully aware roles responsibilities properly trained provided resources guidance needed discharge duties model artificial intelligence governance framework maintenance monitoring documentation review models deployed view taking remediation measures needed iii reviewing communications channels interactions stakeholders provide disclosure effective feedback channels ensuring relevant staff dealing systems properly trained applicable necessary staff working interacting directly models may need trained interpret model output decisions detect manage bias data staff whose work deals system customer relationship officer answering customer queries system salesperson using product make recommendation trained least aware sensitive benefits risks limitations using know alert experts within organisations risk management internal controls organisations consider implementing sound system risk management internal controls specifically addresses risks involved deployment selected model measures include using reasonable efforts ensure datasets used model training adequate intended purpose assess manage risks inaccuracy bias well reviewing exceptions identified model training virtually dataset completely unbiased organisations strive understand ways datasets may biased address safety measures deployment strategies establishing monitoring reporting systems well processes ensure appropriate level management aware performance issues relating deployed appropriate monitoring include autonomous monitoring effectively scale human oversight systems designed report confidence level predictions explainability features could focus model certain level confidence iii ensuring proper knowledge transfer whenever changes key personnel involved activities reduce risk staff movement creating gap internal governance reviewing internal governance structure measures significant changes organisational structure key personnel involved periodically reviewing internal governance structure measures ensure continued relevance model artificial intelligence governance framework cujo network intelligence software company telecommunications operators market headquartered seeks develop deploy improve security control privacy connected devices homes businesses cujo implemented clear internal governance structures measures ensure robust oversight use governance structures facilitate decisions appropriate levels consisting chief technology officer head labs chief data scientist approves development deployment particular chief technology officer oversees four technical teams consists employees roles responsibilities clearly defined research team performs data analysis research develop machine learning models algorithms engineering team builds software cloud services applications operation team deploys model upgrade platform delivery team engages operators integrate services consisting chief technology officer chief architect officer lead engineers ensures robustness models deployment asg meetings research team shares findings models algorithms data approach assumptions oversee development deployment process strive implement academic review standards new feature development addition cujo developed general code ethics code employees new employees introduced cujo local country document process repository example cujo ffice finland provides employees electronic cujo employee handbook handbook describes detail code covering topics business ethics conduct employees carry tasks responsibilities basis following ethical principles illustration internal governance structures measurescujo research board architecture steering group asg employees conduct business honest ethical manner across various offices around world base decisions honesty fairness respect responsibility integrity trust sound business judgment illegal unethical conduct part officers directors employees affiliates company best interest compromise company principles advantage mastercard technology company global payments industry global payments processing network connects consumers financial institutions merchants governments businesses countries territories achieve vision mastercard leveraged many applications fraud prevention forecasting future spending trends improving user retail experience ensure robust oversight mastercard use mastercard established governance council review approve implementation applications determined high risk governance council chaired executive vice president artificial intelligence center excellence whose members include chief data officer chief privacy officer chief information security officer data scientists representatives business teams mastercard defined clear roles responsibilities governance council representative council brings expertise decisionmaking process illustration internal governance structures measuresmastercard model artificial intelligence governance framework review proposal implementation ensure ensure security design implemented build implement continued dialogue data office privacy office continued information sharing regarding required governance lifecycle particular implementation application mastercard also implemented risk management internal controls address risk involved deployment example mastercard conducts initial risk scoring determine risk proposed activity includes evaluation multiple factors including alignment corporate initiatives data types sources utilised impact individuals decisions addition mastercard identify potential mitigants part process reduce level risk posed data collected poten tial biases activity project identified high risk referred governance council review low risk projects subjected review proceed model development information security officerb chief data officer chief privacy officera data fit purpose used ethical purpose impact individual appropriate potential harms including risks privacy data protection sufficiently mitigated data science teams determining level human involvement aiaugmented section intended help organisations determine appropriate extent human oversight clarity objective using key first step determining extent human oversight organisations start deciding commercial objectives usi ensuring consistency improving operational efficiency reducing costs introducing new oduct features increase consumer choice commercial objectives weighed risks using organisation assessment guided organisations corporate values turn could reflect societal norms expectations territories organisations operate also desirable organisations operating multiple countries consider differences societal norms values expectations possible example gaming advertisements may acceptable one country another even within country risks may vary significantly depending deployed example risks individuals associated recommendation engines promote products online mall automating approval online applications travel insurance may lower risks associated algorithmic trading facilities offered sophisticated investors deploying solutions organisations decide commercial objectives using weigh risks using organisation model artificial intelligence governance framework risks individuals may manifest group level example widespread adoption stock recommendation algorithm might cause herding behaviour increasing overall market volatility sufficiently large numbers individuals make similar decisions time addition risks individuals types risks may also identified risk organisation commercial reputation organisations weighing commercial objectives risks using ideally guided corporate values organisations assess intended deployment selected model algorithmic consistent core values inconsistencies deviations conscious decisions made organisations clearly defined documented rationale identifying commercial objectives risks determining appropriate level human involvement iterative ongoing process desirable organisations continually identify review risks relevant technology solutions mitigate risks maintain response plan mitigation fail documenting process periodically reviewed risk impact assessment helps organisations develop clarity confidence using solutions also help organisations respond potential challenges individuals organisations businesses regulators suggests human oversight active involved human retaining full control providing recommendations input decisions exercised without affirmative actions human human command proceed given decision example doctor may use identify possible diagnoses treatments unfamiliar medical condition however doctor make final decision diagnosis corresponding treatment model requires provide enough information human make informed decision factors used decision value weighting correlations suggests human oversight execution decisions system full control without option human override example product recommendation solution may automatically suggest products services individuals based demographic behavioural profiles also dynamically create new profiles make product service suggestions rather relying predetermined categories machine learning model might also used airline forecast demand likely disruptions outputs model used solver module optimise airline scheduling without human loop suggests human oversight involved extent human monitoring supervisory role ability take control model encounters unexpected undesirable events model failure approach allows humans adjust parameters operation algorithm example gps navigation system plans route point point offering several possible routes driver pick driver alter parameters due unforeseen road congestions trip without based risk management approach described model framework identifies three broad approaches classify various degrees human oversight process three broad approaches human involvement model artificial intelligence governance framework matrix however taken imply probability harm severity harm factors considered determining level human oversight organisation process involving although generally two important factors systems would prudent organisations ensure person allowed assume control system providing sufficient information person make meaningful decisions safely shut system human control possible severity harm probability harmhigh severity low probabilityhigh severity high probability low severity low probabilitylow severity high model framework also proposes design framework structured matrix help organisations determine level human involvement required design framework structured along two axes probability severity harm individual organisation result decision made organisation individual organisation definition harm computation probability severity depend context vary sector sector example considerations hospital regarding harm associated wrong diagnosis patient medical condition differ considerations clothing store regarding harm associated wrong product recommendation apparels factors organisations various contexts may consid relevant could also include nature harm whether harm physical intangible nature reversibility harm corollary ability individuals obtain recourse whether operationally feasible meaningful human involved process would unfeasible highspeed financial trading impractical case driverless vehicles highly recommended online retail store wishes use fully automate recommendation food products individuals based browsing behaviours purchase histories automation meet organisation commercial objective operational efficiency assessment definition harm impact making product recommendations address perceived needs individuals severity harm making wrong product recommendations individuals may low since individuals ultimately decide whether make purchase probability harm may high low depending efficiency efficacy solution degree human intervention process given low severity harm assessment points approach requires human intervention regular review organisation regularly reviews approach severity probability harm societal norms values evolve note simple illustration using norms values organisations consider testing method determining model cases challenging complex ethical dilemmas severity harm probability harmhigh severity low probabilityhigh severity high probability low severity low probabilitylow severity high probability harm matrix model artificial intelligence governance framework suade labs suade regtech firm operates globally world economic forum technology pioneer suade provides solution allows financial institutions process large volumes granular data generate required regulatory data calculations reports necessary controls governance suade solution also allows users analyse impact existing stock regulation including impact individual pieces legislation determining level human involvement using suade considered following key factors degree domain knowledge legal knowledge required accurately interpret results algorithm cost regulation tool accurately analyse impact regulation provide correct suggestions regulatory compliance suade solution requires certain degree domain knowledge human experts given cost regulatory result incorrect recommendations made solution significant users suade thus adopted approach solution hand comes tuning model suade adopts approach general suade tunes model automatically favour identification false posi tives false negatives however suade conducted user research informed users prefer model favour false negatives false positives therefore suade adopts approach model tuned account differing preferences users respect whether algorithm produces results favours false positives false determining level human involvement labs grab company offers transport services food delivery solutions uses across platform ride allocation detecting safety incidents identifying fraudulent transactions particular grab uses improve overall quality trip allocations minimise trip cancellations allocate trips successfully grab model considers drivers preferences based following key factors driver preferences certain trip types preferred locations driver start end day selective driving behaviours determining level human involvement trip allocation grab considered following key factors scale required grab make trip allocations every minute would mean impa customers terms efficiency cost human review trip allocation severity probability users model work suboptimal manner among factors grab considered technically feasible human make high volume trip allocations short amount time often little harm life less optimal trip allocations hence grab decided adopt approach model deployed trip allocation continuously reviewing model ensure optimal determining level human involvement model artificial intelligence governance framework operations management section intended help organisations adopt responsible measures operations aspect adoption process reference adoption process set order provide context recommendations good governance respect organisation data algorithm model model framework uses following generalised model development deployment process describe phases implementing solution noted process always usually continuous process learning data preparation algorithms chosen model stage raw data formatted cleansed conclusions drawn accurately generally accuracy insights increase relevance amount models trained dataset algorithms may applied includes statistical machine learning models including decision trees neural networks results examined models iterated appropriate model chosen model used produce probability scores incorporated applications offer predictions make decisions solve problems trigger actions prepared dataapply algorithms train modelmachine learning algorithms candidate modelchosen model application iterate data ready iterate appropriate modeldata preprocessingraw data raw data adapted machine learning scale microsoft azure december scale accessed december data model development datasets used building models may come multiple sources could include personal data quality selection data sources critical success solution model built using biased inaccurate data risks unintended discriminatory decisions model increase persons involved training selecting models deployment may internal staff external service pro viders ideal models deployed intelligent system internal departmental owner one making decisions models deploy ensure effectiveness solution would helpful relevant departments within organisation responsibilities quality data model training model selection work together put place good data accountability practices include following ensure effectiveness solution relevant departments within organisation responsibilities quality data model training model selection must work together put place good data accountability deployment algorithms linear regression algorithms decision trees neural networks applied analysis training datasets resulting algorithmic models examined algorithms iterated model produces appropriate results use case emerges model results incorporated applications offer predictions make decisions solve problems trig ger actions intimate interaction data model focus part model framework model artificial intelligence governance framework understanding lineage data means knowing data originally came collected curated moved within organisation accuracy maintained time data lineage represented visually trace data moves source destination data gets transformed along way interacts data representations change three types data lineage backward data lineage looks data backdating source forward data lineage begins data source follows iii data lineage combines two looks entire solution data source source keeping data provenance record allows organisation ascertain quality data based origin subsequent transformation trace potential sources errors update data attribute data sources instances origin data could difficult establish one example could datasets obtained trusted may commingled data multiple sources would prudent organisations assess risks using data manage ensuring data quality organisations encouraged understand address factors may affect quality data accuracy dataset terms well values dataset match true characteristics entities described dataset completeness dataset terms attributes items iii veracity dataset refers credible data including whether data originated reliable source recently dataset compiled updated relevance dataset context data collection may affect interpretation reliance data intended purpose integrity dataset joined multiple datasets refers well extraction transformation performed vii usability dataset including well dataset structured machineunderstandable form viii human interventions human filtered applied labels edited data minimising inherent bias many types bias relevant model framework focuses inherent bias datasets may lead undesired outcomes unintended discriminatory decisions organisations aware data provide systems could contain inherent biases encouraged take steps mitigate bias two common types bias data include model artificial intelligence governance framework selection bias bias occurs data used produce model fully representative actual data environment model may receive function common examples selection bias datasets omission bias stereotype bias omission bias describes omission certain characteristics dataset example dataset consisting asian faces exhibit omission bias used facial recognition training population includes dataset vehicle types within central business district weekday may exhibit stereotype bias weighted favour cars buses motorcycles bicycles used model types transportation available singapore measurement bias bias occurs data collection device causes data systematically skewed particular direction example training data could obtained using camera colour filter turned thereby skewing machine learning result identifying addressing inherent bias datasets may easy organisations mitigate risk inherent bias heterogeneous dataset collecting data variety reliable sources another way ensure dataset complete possible perspective data attributes data items premature removal data attributes make difficult identify address inherent bias different datasets training testing validation different datasets required training testing validation model trained using training data model accuracy determined using test data applicable model could also checked systematic bias testing different demographic groups observe whether groups systematically advantaged disadvantaged finally trained model validated using validation dataset considered good practice split large dataset subsets purposes lead significant reduction quality data terms accuracy representation however possible organisation working large datasets using models case transfer learning organisations encouraged cognisant risks systematic bias put place appropriate safeguards periodic reviewing updating datasets would prudent datasets including training testing validation datasets reviewed periodically ensure accuracy quality currency relevance reliability necessary datasets updated new input data obtained actual use models deployed production new input data used organisations need aware potential bias using new input data already gone model could create reinforcement even data used training models including personal data anonymised good data accountability practices remain relevant model artificial intelligence governance framework data used suade model development directly affects quality performance suade adopted several good data accountability practices example ensure regulatory data comes credible reliable source suade obtains updates regulatory data relevant regulators addition suade tags datasets used additional metadata allows suade trace datasets back original source needed inconsistencies found order trace particular datasets used model suade also documents stores information pertaining model development database suade also minimises inherent risks models responsible data tagging using larger number taggers people tag data suade aims make output models neutral possible reduce risk taggers influenced context data often comprise text annotating words suade uses many individuals practicable tag data reduce risk tagger bias addition suade developed tagging system facilitate annotation data system used generate training data used algorithm suade develop tagging system enhance ability manage multiple annotators better select datasets used model training suade also periodically updates tagging system new data new training data subsequently fed repeatedly back model way model able continuously learn new sets data another data accountability practice suade adopts use validation schema checks various stages data transformation process suade verifies data schema accurately represents data source ensure errors factors data formatting managing data model developmentsuade labs suade introduced developed solution helps financial institutions generate required data reports comply regulatory requirements jurisdictions operate pymetrics technology provider uses neuroscience insights audited models help evaluate applicants predictive less biased manner develop model pymetrics gets clients employees pymetrics assessments builds trait profile employee best fit specific job role validates trait profile client team collects behavioural data applicants pymetrics gamified assessments assesses suitability applicants based trait profile deal socially sensitive features mitigate risk inherent unintentional bias datasets used model pymetrics uses objective data based established neuroscience research attention detail attention span ability recall generally stable across gender racial age groups proactively models ensure fully repre sentative environment may function models disadvantage people basis demographic features standards fairness informed legal requirements prehire assessment pymetrics models must pass test known fourfifths rule commonly cited employment law according equal employment opportunity commission eeoc selection rate legally protected group must least sel ection rate majority group example employer screens qualified applicants men women model selects men must also select least women pymetrics test model dataset users diverse demographics ensure random patterns data learned model address potential bias illustration managing biases datasets model developmentpymetrics model artificial intelligence governance framework pymetrics would conduct additional demographic based geographical relevance legal requirements pymetrics uses bias ratio compare proportional pass rates demographic group group demographic category gender ethnicity model would deployed meet eeoc standards deployment pymetrics test model decisions real applicants adverse impact revisits impact system predictions retention role bias found either deployment pymetrics adjust model optimise fairness towards applicants ensuring predictive performance model algorithm model systems may numerous features functionalities enabled algorithms models measures explainability repeatability robustness regular tuning reproducibility traceability auditability enhance transparency algorithms found models may feasible costeffective implement even essential measures algorithms organisations encouraged take approach making assessment first identify subset features functionalities greatest impact stakeholders measures relevant second identify measures effective building trust stakeholders measures like explainability repeatability using models easily explained robustness regular tuning sufficiently essential could varying extents incorporated part organisation deployment process measures reproducibility traceability auditability may relevant specific features specific scenarios explainability explainability achieved explaining deployed models algorithms function process incorporates model predictions purpose able explain predictions made build understanding trust algorithm deployed solution said explainable functions arrives particular prediction explained algorithm explained understanding trust still built explaining predictions play role process organisations deploying solutions recommended adopt following practices model training selection necessary developing intelligent system system contains technologies documenting model training selection processes conducted reasons decisions made measures taken address identified risks enable organisation provide account decisions subsequently regard field automated machine learning aims automate significant portion machine learning workflows including feature engineering feature selection model selection tuning organisations using types tools consider transparency explainability traceability automated machine learning approach well models selected incorporating descriptions solutions design expected behaviour product service descriptions system technical specifications documentation demonstrates accountability individuals regulators could also include design decisions relation certain features attributes models selected place others steps help provide greater clarity model giving understandable digestible insights model operates model artificial intelligence governance framework technical explainability may always enlightening especially man street implicit explanations models algorithms function may useful explicit descriptions models logic example providing individual counterfactuals would approved average debt lower comparisons users similar profiles received similar decision powerful type explanation organisations could consider nevertheless may scenarios might practical reasonable provide information relation algorithm example disclosing algorithms deployed antimoney laundering detection information security fraud prevention may allow bad actors avoid detection likewise providing detailed information proprietary algorithms decisions made algorithms may expose confidential business organisation system obtained procured solution provider organisation consider requesting assistance solution provider may better placed explain solution functions supplementary explanation tools helpful explaining especially models less interpretable also known black box systems tools help make underlying rationale system output interpretable intelligible use system possible use combination tools improve explainability model tools known supplementary present single comprehensive technical solution making models explainable tools thus play supplementary role providing level interpretability model operation examples tools include use surrogate models partial dependence plots global variable sensitivity analysis counterfactual explanations repeatability explainability practicably achieved given state technology organisations consider documenting repeatability results produced model repeatability refers ability consistently perform action make decision given scenario repeatability results equivalent explainability algorithm degree assurance consistency performance could provide users larger degree confidence helpful practices include conducting repeatability assessments commercial deployments live environments ensure deployments repeatable performing counterfactual fairness testing counterfactual fairness testing ensures model decisions real world counterfactual world attributes deemed sensitive race gender altered assessing exceptions identified handled decisions repeatable randomness introduced design ensuring exception handling line organisations policies regard may helpful use models able recognise given set facts contains new variables previously considered able highlight new variables human identifying accounting changes time ensure models trained data remain relevant james manyika jake sitberg brittany presten biases harvard business review october accessed october model artificial intelligence governance framework robustness robustness refers ability computer system cope errors execution erroneous input assessed degree system component function correctly presence invalid input stressful environmental conditions ensuring deployed models sufficiently robust contribute towards building trust system concept robustness arises possible models able enumerate set preconditions consequences action creates possibility models producing insensible unexpected results even minor modifications input data may even perceptible humans testing robustness achieved testing foreseeable erroneous ensure models robust organisations consider working developers conduct adversarial testing models ensure models able handle broader range unexpected input variables especially systems exercise organisations take approach towards identifying subset features products services requires adversarial testing model perfectly robust possible detect possible modifications set input data reason organisations intending use continual learning learned parameters machine learning model fixed model continues change learned parameters deployed production encouraged aware risks continual learning model behave unpredictable manner distinct user acceptance testing uat process actual software users test piece software ensure handle required tasks world scenarios based specifications uat often critical step taken software released regular tuning establishing internal policy process perform regular model tuning effective ensuring deployed models cater changes customer behaviour time allows organisations refresh models based updated training datasets incorporate new input data model tuning may also necessary commercial objectives risks corporate values change wherever possible testing reflect dynamism planned production environment ensure safety testing may need assess degree solution generalises well fails gracefully example warehouse robot tasked avoiding obstacles complete task picking packages could tested different types obstacles realistically varied internal environments workers wearing variety different coloured shirts otherwise models risk learning regularities environment reflect actual production environment conditions assuming humans must avoid wearing white lab coats models deployed environment active monitoring review tuning advised traceability model considered traceable decisions datasets processes yield model decision including data gathering data labelling algorithms used documented easily understandable way former refers traceability decisions latter refers traceability model training raceability facilitates transparency explainability also helpful reasons first information might also useful troubleshooting investigation model functioning particular prediction made second traceability record form audit log source input data used training dataset future model artificial intelligence governance framework practices organisations may consider promote traceability include building audit trail document model training decision implementing black box recorder captures input data streams example black box recorder selfdriving car tracks vehicle position records system takes control vehicle suffers technical problem requests driver take control ensuring data relevant traceability stored appropriately avoid degradation alteration retained durations relevant industry traceability measures may lead accumulation large volume activity data organisations consider product features require traceability traceability measures might sufficient needs bearing mind resources needed document model decisions datasets processes organisations could assess based several factors including assessment probability severity harm arising use system extent model previously trialled used regulatory needs industry noted black box recorder refer black box model sense process model inherently difficult interpret explain reproducibility repeatability refers internal repetition results within one organisation reproducibility refers ability independent verification team produce results using method based documentation made organisation reproducibility influence trustworthiness product organisation deploying model implementing reproducibility entails involvement external parties organisations take approach towards identifying subset features products services requires external reproducibility testing following practices contribute towards reproducibility testing whether specific contexts particular conditions would need taken account ensure reproducibility putting place verification methods ensure different aspects model reliability reproducibility making available replication files files replicate step model developmental process facilitate process testing reproducing behaviours companies procure commercial systems checking original solution provider whether model results reproducible adopting points paragraph repeatability namely assessing exceptions identified handled ensuring exceptionhandling line organisational policies identifying accounting changes time model artificial intelligence governance framework auditability auditability refers readiness system undergo assessment algorithms data design processes evaluation system internal external auditors availability evaluation reports contribute trustworthiness system demonstrates responsibility design practices justifiability outcomes however noted auditability necessarily entail making information business models intellectual property related system publicly available implementing auditability entails involvement external parties requires disclosure commercially sensitive information auditors may external organisations take approach towards identifying subset features products services implementing auditability necessary implementing auditability necessary organisation align regulatory requirements industry practice facilitate auditability organisations consider keeping comprehensive record data provenance procurement preprocessing lineage storage security record could also include qualitative input data representations data sufficiency source integrity data timelines data relevance unforeseen data issues encountered across workflow organisations may also wish centralise information digitally process log would enable organisation make available one place information may assist demonstrating concerned parties affected decision subjects responsibility design practices justifiability outcomes system processing behaviour log would also enable better organisation accessibility presentation information yielded assist curation protection data kept unavailable public view increase organisation capacity cater presentation results different tiers stakeholders different interests levels expertise solution ayasdi model accelerator ama first identifies relevant variables include model explains selected ama looking possible relationships encoded within enriched data finding hidden patterns hold predictive value ama uses variables selected build models presents candidate model several viable challenger models clients selection business units within clients organisations evaluate candidate challenger models select best represent business units entire model creation process documented automatically clients use ama institutionalise variable selection modelling methodology systematically deterministically produce repeatable process consistent supporting reports model lineage variable selection allows clients ensure initial selections features models recorded documented time entire modelling approval process tracked catalogued thus facilitating subsequent processes review model ability demonstrate detailed process model building rigour evaluating challenger models allows ayasdi clients explain federal reserve final models documenting model developmentsymphony ayasdiai symphony ayasdiai ayasdi offers solution helps clients mainly banking finance sector build models adequately forecast revenues capital reserve required absorb losses stressed economic conditions clients need prove federal reserve models accurate defensible model artificial intelligence governance framework stakeholder interaction communication section intended help organisations take appropriate steps build trust stakeholder relationship strategies deploying general disclosure organisations encouraged provide general information whether used products services appropriate could include information used relation consumers benefits organisation decided use organisation taken steps mitigate risks role extent plays process example online portal may inform users interacting chatbot human customer service agent organisations consider disclosing manner decision may affect individual consumer whether decision reversible example organisation may inform individuals credit ratings may lead loan refusal organisation also similar organisations also informing decision reversible individuals provide evidence credit worthiness policy explanation organisations encouraged develop policy explanations provide individuals provide policies help ensure consistency communication clearly sets roles responsibilities different members organisation include explanations works process specific decision made reasons behind decision impact consequence decision explanation provided part general communication also information respect specific decision upon request regard principle equivalence provide guidance standards disclosure humandriven decisions applied decisions made augmented system appropriate interaction communication inspire trust confidence build maintain open relationships betwe organisations individuals including employees stakeholder relationship strategies also remain static compan ies encouraged test evaluate review strategies effectiveness extent mode implementation factors could vary scenario scenario different stakeholders different information needs organisation start first identifying audience external internal stakeholders organisation external stakeholders may include consumers regulators organisations business society large internal stakeholders may include organisation board management employees organisation also consider purpose context interaction stakeholders purposes illustration model framework provides considerations interacting consumers organisations interacting consumers organisations encouraged consider information needs consumers journey interacting considering whether use solution understanding solution works use requesting reviews decisions made solution typical consumer journey may entail meeting following information needs consumers bringing explainability transparency together meaningful way different stakeholders different information needs organisation start first identifying audience considering purpose context interaction model artificial intelligence governance framework making sure consumers aware products services considering information could provided part general product description providing information consumers know features expected behave normal use information could provided detailed descriptions specifications product features however may necessary every feature organisations encouraged identify features providing additional information manner enhance consumer trust similarly used information may provided consumers understand decisions made assistance may affect likewise provided descriptions service provided features consumers interact regularly providing information understand feature behaving certain way providing preference settings allow consumers influence future behaviour possible requires engineering effort providing additional user interfaces user history level information provided may somewhat detailed personalised feature descriptions organisations decide product features benefit provision level detail decisions affect consumers consider providing additional information understand decisions made certain categories decisions providing appropriate channel contest decisions level information provided necessarily detailed may necessary except scenarios customer affected decision option organisations may wish consider carefully deciding whether provide individuals option opt use product service whether option offered default upon request relevant considerations include degree individuals reversibility decision made availability alternative mechanisms cost alternative mechanisms complexity inefficiency maintaining parallel systems technical feasibility organisation weighed factors decided provide option opt prudent organ isation consider providing modes recourse consumer providing channel reviewing decision appropriate organisations may also wish keep history chatbot conversations facing complaints seeking recourse consumers communication channels organisations encouraged put place following communications channels customers model artificial intelligence governance framework channel could used customers raise feedback raise queries could managed organisation data protection officer dpo appropriate customers find inaccuracies personal data used decisions affecting channel also allow correct data correction feedback turn maintain data veracity could also managed organisation quality service manager qsm stakeholders wish raise feedback queries material inferences made apart existing review obligations organisations consider providing avenue individuals aggrieved consumer request review material decisions affected effect decision consumer may material would reasonable provide opportunity decision reviewed human testing user interface organisations encouraged test user interfaces address usability problems deployment user interface serves intended purposes applicable organisations also encouraged inform individuals responses would used train system chatbot organisations aware risks using responses individuals may intentionally use bad language random replies would affect training system communications organisations encouraged communicate manner increase transparency existing tools measure readability fry readability graph gunning fog index readability tests etc would helpful decisions higher impact communicated manner need transparent technology used besides textual communications organisations also consider using visualisation tools graphical representations summary tables combination priority convey information explanation interpretation way understandable organisation consumers channels decision review channelsb acceptable user policies certain cases organisations may implementing solutions also trained input data active learning organisations may wish consider setting certain acceptable user policies aups ensure users maliciously introduce input data unacceptably manipulates performance results solution model pertinent given past examples chatbot systems unduly manipulated issue publiclyunacceptable responses regard aups serve set broad boundaries interactions individuals perform system restrictions regard intentional actions attempts reverse engineer disable interfere disrupt functionality integrity performance service interacting organisations approaches methodologies described preceding section also relevant organisations interact solution providers procuring solutions obtaining regulatory approval organisations facilitating industry collaboration enabling interoperability systems organisations would thus need obtain sufficient information solution providers help meet business objectives example could arrangement providing information described paragraph could straightforward obtaining solution providers support provide build necessary deploying organisation align model framework example information related lineage training dataset documenting key steps model training selection example interactions providing information expected behavior feature building function allow users manage preference settings influence feature perform model artificial intelligence governance framework organisations may consider level support detailed information may need obtain solution providers pertaining data types range data used training algorithm source quality external training data model training selection features variables used weights commercial models supplied documenting key decisions made respect model training selection human elements nature human involvement developing algorithm process inferences predictions made algorithm incorporated product features decisionmaking algorithmic presence solution algorithm used measures safeguards place mitigate biases data algorithms depending purpose context type level detail information required may different example regulator may require regulated entity demonstrate model development selection process sufficiently rigorous solution provider may required provide information involved clarification process regulator industry collaborator hand may concerned factors pertaining compatibility interoperability ethical evaluation finally ethical standards governing development use evolve organisations encouraged evaluate whether governance practices processes line evolving standards make available outcome evaluations relevant stakeholders particular facebook strives meaningfully transparent users providing general disclosure facebook collection use data manner achieved terms service data policy accompanied explanatory userfriendly videos giving users meaningful control information used shared publishing policy explanation series blogposts discuss complex subjects explain rationale facebook decisions invite experts share opinions example facebook published hard questions blogpost face recognition discussed facebook used face recognition help users tag photos controls implemented promoting series educational initiatives campaigns help users learn technology underlies various products eatures example facebook artificial intelligence research lab developed published series education videos explain machine learning algorithms used facebook currently provides users customised news feed shows posts relevant content news feed determined people pages user chooses friend follow part facebook consultation news feed feature facebook took consideration need transparent provide information algorithms behind feature illustration stakeholder interaction communicationfacebook social media technology company facebook committed transparent public users operations services includes use model artificial intelligence governance framework type information would valuable users example facebook included examples people interactions contributed posts news feed need users take control manage news feed facebook put place following build trust users implement seeing post feature explain users past interactions impacted ranking posts news feed specifically users able learn reason viewing certain post news feed example post could friend group page user followed information largest influence order posts including frequency user interacts posts people pages groups frequency user interacts specific type post videos photos links popularity posts shared people pages groups user follows iii shortcuts controls help users personalise news feed see first unfollow news feed preferences privacy shortcuts publish series news feed fyi blog posts highlighted explained rationale key updates news feed launch new inside feed website provided greater detail facebook systems worked way facebook evaluated changes prior deployment msd user experience team tested interface addressed usability problems ensure optimal user interaction jennie particular three tenets guided development deployment jennie understanding user mental model team conducted user research representative users understand users expectations interacting chatbot research covered scope questions expected answers kinds answers provided technical answers phrased building interface users would comfortable interact use chatbot taking approach understand patterns human behaviour team analysed employees reacted faced challenges interacting chatbot examples include users formulate questions types answers satisfy users many times chatbot allowed attempt answer understanding human interaction touchpoints team used insights create information flow architecture deliver better experience users managing handover could instances jennie might able provide satisfactory answer instances team determined chatbot would maximum three attempts provide satisfactory reply forwarding user request chat logs customer care executive employees engage jennie msd disclose landing page jennie beta version improve time see figure stakeholder interaction communicationmsd msd multinational pharmaceutical company deploys chatbot jennie answer queries matters model artificial intelligence governance framework conclusion model framework means complete exhaustive remains document open feedback technologies evolve would related ethical governance issues pdpc aim update model framework periodically feedback received ensure remains relevant useful organisations deploying solutions appropriate communication regarding use inspires trust builds maintains open relationships organisations individuals annex reference compilation existing ethical principles annex comprises collection foundational ethical principles distilled various included addressed model framework organisations may consider incorporating principles corporate principles relevant desired accountability ensure actors responsible accountable proper functioning systems respect ethics principles based roles context consistency state art accuracy identify log articulate sources error uncertainty throughout algorithm data sources expected implications understood inform mitigation procedures auditability enable interested third parties probe understand review behaviour algorithm disclosure information enables monitoring checking criticism explainability ensure automated algorithmic decisions associated data driving decisions explained stakeholders terms fairness ensure algorithmic decisions create discriminatory unjust impacts across different demographic lines race sex develop include monitoring accounting mechanisms avoid unintentional discrimination implementing systems consult diversity voices demographics developing systems applications algorithms include institute electrical electronics engineers ieee standards association ethically aligned design software information industry association ethical principles artificial intelligence data analytics principles pdf fairness accountability transparency machine learning principles accountable algorithms social impact statement algorithms also european commission communication commission european parliament council european economic social committee committee regions building trust artificial intelligence oecd recommendation council artifici intelligence also include principles raised consultation feedback model artificial intelligence governance framework human centricity aim equitable distribution benefits data practices avoid data practices disproportionately disadvantage vulnerable groups aim create greatest possible benefit use data advanced modelling techniques engage data practices encourage practice virtues contribute human flourishing human dignity human autonomy give weight considered judgements people communities affected data practices aligned values ethical principles people communities affected make decisions cause foreseeable harm individual least minimise harm necessary circumstances weighed greater good allow users maintain control data used context data used ability modify use context ensure overall user central system functionality human rights alignment ensure design development implementation technologies infringe internationally recognised human rights inclusivity ensure accessible progressiveness favour implementations value created materially better engaging project responsibility accountability transparency build trust ensuring designers operators responsible accountable systems applications algorithms ensure systems applications algorithms operate transparent fair manner make available externally visible impartial avenues redress adverse individual societal effects algorithmic decision system designate role person office responsible timely remedy sues incorporate downstream measures processes users stakeholders verify technology applied keep detailed records design processes robustness security systems safe secure vulnerable tampering compromising data trained sustainability favour implementations effectively predict future behaviour generate beneficial insights reasonable period time model artificial intelligence governance framework annex algorithm audits algorithm audits conducted necessary discover actual operations algorithms comprised models would carried request regulator part forensic investigation jurisdiction organisation technology provider assist customer organisation respond regulator request conducting algorithm audit requires technical expertise may require engaging external experts audit report may beyond understanding individuals organisations expense time required conduct algorithm audit weighed expected benefits obtained audit report ultimately algorithm audits normally used reasonably clear audit yield clear benefits investigation following factors may relevant considering algorithm audit purpose conducting algorithm audit model framework promotes provision information models function part explainable embarking algorithm audit advisable consider whether information already made available individuals organisations businesses regulators sufficient credible product service descriptions system technical specifications model training selection records data provenance record audit trail target audience audit results refers expertise required target audience effectively understand data algorithm models information required different audience vary audience consists individuals providing information process individuals data used processes achieve objective explainable efficaciously audience consists regulators information relating data accountability functioning algorithms ould examined first algorithm audit prove model operates reason doubt veracity completeness information operation general data accountability organisations provide information general data accountability achieved within organisations includes good data practices described model framework data model development section maintaining data lineage keeping data provenance record ensuring data accuracy minimising inherent bias data splitting data different purposes determining data veracity reviewing updating data regularly algorithms models commercially valuable information affect market competitiveness example algorithm may trade secret may embody business rules trade secrets technical audit contemplated corresponding mitigation measures also considered agreements acknowledgements pdpc expresses sincere appreciation following individuals organisations valuable feedback model framework alphabetical order star accenture aig asia pacific insurance pte apple asia cloud computing association asiadpo bsa software alliance cambrian data synergies dbs element emerging technologies policy forum facebook fountain court chambers google grab great eastern gskibm asia pacific mastercard microsoft asia msd international gmbh singapore branch working group ocbc bank pwc pymetrics salesforce singtel standard chartered bank suade labs symphony ayasdiai telenor group temasek international tookitaki untangle model artificial intelligence governance framework brought sgdigital singapore digital gives singapore digitalisation efforts face identifying digital programmes initiatives one set visuals speaking local international audiences language logo made rounded fonts evolve expressive dot red stands singapore refers digital economy smiley face icon also signifies optimism singaporeans moving digital economy progress digital economy people empathy assurance heart copyright media development authority imda personal data protection commission pdpc publication intended foster responsible development adoption artificial intelligence contents herein intended authoritative statement law substitute legal professional advice pdpc members officers employees shall responsible accuracy error omission publication liable damage loss kind result use reliance publication contents publication protected copyright trademark forms proprietary rights may reproduced republished transmitted form means whole part without written
