Ethics by Design:   An organizational   approach to responsible   use of technology WHITE PAPER DECEMBER 2020In collaboration with Deloitte and the Markkula Center  for Applied Ethics at Santa Clara University
Contents Foreword 1 Introduction 1.1 Three design principles for promoting ethical behaviour 2 Ethics by design principles 2.1 Attention Examples of tools and tactics to drive attention Consequences of failing to promote attention 2.2 Construal Examples of tools and tactics to drive construal Consequences of failing to promote construal 2.3 Motivation Examples of tools and tactics to drive motivation Consequences of failing to promote motivation 2.4 Summary 3 Findings 3.1 The importance of integrating attention, construal and motivation 3.2 Getting construal right is the most challenging 3.3 Instituting ethical reviews and assessments is becoming standard 3.4 Employees look to senior leadership to provide ethics frameworks 3.5 Ethics deepens relationships with customers 3.6 Diversity is fundamental 3.7 Ethics is a discrete business function 3.8 Ethical literacy develops as the company matures 3.9 Summary 4 Recommendations Conclusion Contributors Acknowledgements Endnotes3 4 6 8 8 9 11 11 12 13 13 14 15 16 17 18 19 19 20 22 22 23 24 25 26 27 28 29 31 Cover: Getty Images/Gremlin Inside: Getty Images/Mihailo Milovanovic; Getty Images/Gorodenkoff  © 2020 World Economic Forum. All rights  reserved. No part of this publication may  be reproduced or transmitted in any form  or by any means, including photocopying  and recording, or by any information  storage and retrieval system. Ethics by Design: An organizational approach to responsible use of technology  2
Foreword From AI to blockchain to quantum computing,  the explosive growth of new digital technology is  a defining feature of the current era. While new  technologies can serve as powerful tools to help  organizations become smarter and more agile,  their deployment must be carefully planned to  avoid adverse ramifications.  Most companies today understand the  importance of ensuring that the technology  they employ is trustworthy (i.e. that it addresses  foundational security, privacy and regulatory  concerns). Lately, however, many are beginning  to acknowledge a range of new ethical challenges  related to how such emerging and disruptive  technologies are designed, delivered and used in  ways that may erode fundamental human values  (e.g. equality and autonomy), and which require  careful judgement to identify and mitigate. While  critical ethical thinking about technology may  be a new skill set for some, almost everyone  agrees that issues such as data privacy and  algorithmic bias can pose significant reputational  and financial risks if unaddressed. This paper  seeks to offer clear principles and practices that  organizations can apply across their operations to  improve the ethical use of technology. We believe a comprehensive approach to  promoting the responsible, ethical use of  technology should consider three critical  components: education in how emerging  technologies work and what ethical challenges  they might pose; the product life cycle and  development of the tools needed to help  drive ethical outcomes; and the design of  organizations, to ensure that the people creating,  deploying and using these tools are motivated  and equipped to make ethical choices. This paper focuses on the last component, an  area in which research has to date been nascent  but which remains no less critical. While certain  foundational ethical risks can be mitigated  through the establishment of clear operational  rules, many others require the capacity for  ethical judgement and organizational factors that  support translating that judgement into action. As  technology is increasingly incorporated into the  daily operations of companies across sectors,  leaders must prepare their people to be aware of  the ethical risks posed by emerging tools, equip  them to make ethical choices even in situations  in which information is imperfect or ambiguous,  and motivate them to act upon that judgement in  ways that advance prosocial goals.  Given the immense impact that technology can  have on individuals, corporations and society  more broadly, institutions have begun to actively  identify best practices to ensure its ethical use  (e.g. Deloitte’s Trustworthy & Ethical Tech offering  and the Markkula Center’s Ethics in Technology  Practice). To that end, this paper reflects a  collaborative effort between the World Economic  Forum, Deloitte and the Markkula Center for  Applied Ethics at Santa Clara University, which  we hope will offer helpful guiding principles and  illustrative examples that can support your firm’s  journey in navigating the evolving landscape of  embedding ethics in technology.Beena Ammanath  Executive Director, Deloitte  AI Institute and Trustworthy  and Ethical Technology Kay Firth-Butterfield  Head of AI and Machine  Learning, Member of the  Executive Committee,   World Economic Forum Don Heider  Executive Director, Markkula  Center for Applied Ethics at  Santa Clara University Ethics by Design: An organizational approach to responsible use of technology  3
Introduction1 Ethics by Design: An organizational approach  to responsible use of technology  December 2020 I don’t think technology by itself improves people’s lives. Unless  there’s commensurate ethical and moral improvements to go  along with it, it’s for naught. Jaron Lanier1  Ethics by Design: An organizational approach to responsible use of technology  4
While stories of ethical failures and calls for ethical  leadership in business dominate today’s headlines,  particularly in relation to the tech sector, the topic  is hardly a new one. Ethical discussions pertinent  to business conduct date back centuries, and  business ethics emerged as an academic discipline  in the wake of environmental and anti-corporate  protests in the United States in the 1970s. Yet the  continued emergence of high-profile corporate  scandals throughout the decades attests to the fact  that ethical research, debate and instruction have  not consistently translated into ethical behaviour.  Furthermore, previous generations’ leaders have  sent mixed signals about the need for ethics in  business training and decision-making. In 1970,  Milton Friedman famously argued that, “There is one  and only one social responsibility of business – to  use its resources and engage in activities designed  to increase its profits so long as it stays within the  rules of the game, which is to say, engages in open  and free competition without deception or fraud.”2  One sociologist reported that getting Harvard  Business School to teach ethics in the late 1980s  (after receiving a $20 million grant to do so) was  nearly impossible. He commented, “They said, ‘We  teach people how to put small toys into large boxes  so they seem bigger. We put hot colors onto boxes  to produce impulsive buying. If you want us to teach  ethical behavior, we’re out of business.’”3 Today’s climate of opinion is considerably different.  In 2019, the Business Roundtable moved away  from Friedman’s doctrine of shareholder primacy,  declaring the need to make “a fundamental  commitment to all of our stakeholders”, to support  communities and uphold the environment.4 More  recently, to mark the 50th anniversary of the  publication of Friedman’s essay, a chorus of leading  economists and business leaders have articulated  the need to move beyond a single-minded focus on  short-term profits.5  This shift in sentiment occurs at the same historical  moment as a widespread acknowledgement of the  potentially deleterious effects of new technologies on  individuals and societies. As artificial intelligence (AI),  cloud computing, robotics, 3D printing, the internet  of things (IoT) and other advanced technologies  penetrate ever more aspects of society, there is a  growing consensus that they pose not only technical   challenges but societal ones as well. For example, if  left unchecked, AI and social media technologies can  promote the spread of disinformation, exacerbate  group polarization, become addictive, amplify  societal biases, exacerbate wealth inequalities and  pose the risk of automating decisions that require  human judgement.6  As a result, there are increasing calls for the  development of suitable ethical norms, governance  structures and institutional arrangements to help  ensure that the benefits of technology outweigh the  risks, that these benefits are distributed fairly and  that novel technologies do not undermine human  autonomy and self-determination. At the same time, it will be important to ensure that the evolving legal  and regulatory systems do not needlessly impede  technological innovation.  These calls have been met with a proliferation of  technology ethics statements of principles and  guidelines. For example, AlgorithmWatch’s AI  Ethics Guidelines Global Inventory has compiled  no fewer than 160 sets of AI principles and  guidelines promulgated by prominent companies  and organizations.7 Similarly, many companies have  adopted codes of business ethics. But issuing a  set of guidelines or a code of conduct does not  guarantee that more ethical behaviour will follow.  Another signature issue of our time – the  revolution in our understanding of human  psychology ushered in by Daniel Kahneman,  Amos Tversky and their collaborators and  followers – offers an underused toolkit to help  bridge the gap between ethical intentions and  ethical behaviour within organizations. In realms  such as law, economics and public policy,  the idealized view of perfectly rational, selfinterested economic actors has given way to  a more nuanced view of actors characterized  by bounded rationality, bounded self-control,  bounded self-interest and bounded ethicality.8  A major implication explored by the behavioural  economics pioneer and Nobel laureate Richard  Thaler and legal scholar Cass Sunstein in their  “choice architecture” manifesto Nudge suggests  that – contrary to the classical economics  postulates – providing information and offering  material incentives are not the only drivers  of human behaviour. The manner in which  information is provided (for example, the choice  of frames) or choices arranged (for instance,  the choice of defaults) can significantly and  systematically affect behaviour. Thaler stated, “A  good rule of thumb is to assume that everything  matters.”9 This carries a powerful practical  implication: We can harness insights from the  social and behavioural sciences to design our  operating environments in ways that promote  more beneficial and prosocial behaviour and  decisions. Consistent with this, in their book  Nudge, Thaler and Sunstein define a “nudge” to  be “any aspect of the choice architecture that  alters people’s behavior in a predictable way  without forbidding any options or significantly  changing their economic incentives”.10 For example, it is often observed that financial  literacy training alone does little to change  individuals’ savings behaviour – perhaps due  to bounded cognition and bounded selfcontrol. In contrast, it has been estimated that  changing defaults to automatically enroll people  in retirement schemes (while giving them the  freedom to opt out) results in substantially  increased savings.11 Analogously, behavioural  scientists who study gender biases in large  organizations emphasize that while diversity  training does little to move the equality needle,  Ethics by Design: An organizational approach to responsible use of technology  5
such design elements as blinded résumés or  salient reminders of notable female leaders can  yield measurable impacts.12 The behavioural  scientist Iris Bohnet states: “Instead of trying to debias mindsets, the  evidence suggests that we should focus on  debiasing systems.”13  The corresponding implication in the realm of ethics  is that the time-honoured traditions of business ethics  classes and corporate ethics training alone are unlikely  to move the ethical behaviour needle. Systematic  changes to decision-making environments are needed as well. That is: We would do well to treat ethics not  only as a training and education challenge, but as a  behavioural design challenge as well. The behavioural scientist Jonathan Haidt states: “I certainly think it’s good for business students  to take a course on business ethics, but I don’t  think that one course will improve ethical behavior  years later, when social forces in real work settings  overwhelm whatever lessons students learned in  class. If we really want to improve ethical behavior  in business, we must grab the bull by the horns  and change those social forces.”14 Three design principles for promoting ethical  behaviour1.1 A major theme emerging from decades of research  in social psychology is that situational factors drive  human behaviour to a considerably greater extent  than our intuitions might suggest. Behavioural  scientists use the term “fundamental attribution error”  to denote our systematic tendency to overestimate  the importance of individual personality traits while  underestimating the degree to which situational  factors affect human behaviour.15  In addition, a large body of research suggests that  individuals are boundedly ethical, meaning that  they are subject to systematic ethical “blind spots”,  leading them to neglect the ethical dimensions of  their decisions. This can lead ordinary individuals to  act in ways that diverge from even their own ethical  preferences.16 The practical takeaway is that leaders  should resist the natural tendency to focus excessively  on rooting out unethical individuals while neglecting  the need to address the contextual factors that can  lead ordinary individuals astray. In short, even the best  of ethical intentions can fail to result in ethical actions. A third major theme in social psychology is that  reasoning exerts more power over our actual  behaviour than is commonly thought. Rather,  reasoning – including ethical reasoning – often  follows from behaviour, serving to rationalize or  justify it. Jonathan Haidt comments that modern  psychology bears out David Hume’s maxim,  “Reason is a slave of the passions.”17  In their essay “Treating Ethics as a Design Problem”,  the behavioural scientists Nicholas Epley and David  Tannenbaum discuss three “myths” about morality  that are consistent with these themes: 1. Ethics are a property of people, rather than  the broader context in which the behaviour  takes place.2. People’s [good or bad] ethical intentions lead to  [good or bad] ethical actions.  3. Ethical reasoning drives ethical behaviour.  Debunking these myths leads to the realization that:  –Interventions that focus on rogue individuals in  the midst of environments in which unethical  behaviour is systematic are unlikely to succeed.   –Good ethical intentions can precede unethical  behaviour. It is wise to have ethical safeguards  in place, even when people with good intentions  are involved.  –Leaders should resist the temptation to  overestimate the effectiveness of ethics  educational and learning programmes and  underestimate the importance of contextual  changes for prompting ethical behaviour. This final point begs the question: How should  well-intended leaders and organizations design such  contextual changes? Epley and Tannenbaum suggest  that programmes, policies and decision environments  are more likely to be effective if they are designed to  “go with the grain” of human psychology. They call  this “ethical design for a human mind” and state:  “Policies that encourage ethical behavior should  … be designed around three basic psychological  processes that guide human behavior: attention,  construal, and motivation [emphasis added].”18 Consistent with the core message of Thaler and  Sunstein’s Nudge, Epley and Tannenbaum suggest  that key findings from psychology and behavioural  science can be harnessed to serve as design  principles to shape decision environments in ways that  prompt better and more routine ethical behaviour. Ethics by Design: An organizational approach to responsible use of technology  6
In more detail:  1. Attention: Timely reminders, checklists,  frequent ethics refresher trainings and other  interventions can be developed to help ensure  that ethical considerations are top-of-mind at  crucial decision points.  2. Construal: Mission statements, deliberate  choices of ethically freighted language, new  employee onboarding sessions and periodic  training sessions involving ethical deliberation,  and other interventions can be used to promote  ethical considerations. For example, encouraging employees to ask not only “is it legal?” but also  “is it right?” promotes the use of an ethical view  at critical junctures such as when making a key  business decision. 3. Motivation: People are often intrinsically  motivated to act in ethical ways, particularly  when doing so is the cultural norm. At the same  time, reward systems that focus on material  incentives can “crowd out” such intrinsic  motivations. Encouraging prosocial actions,  employing social “norm nudge” interventions  and other culture-change activities can be used  to motivate ethical behaviour.19  The following sections will discuss these design  principles in more detail and provide examples  that illustrate their effectiveness. Subsequently, we  review examples of the principles in action – both  within and outside of technology settings – to suggest approaches for applying them. Throughout,  a collection of case studies drawn from interviews  conducted in the second half of 2020 illuminates  applications of the principles in greater detail. Three design principles FIGURE 1 Source: World Economic Forum, based on Epley, Nicholas, and David Tannenbaum. “Treating Ethics as a Design Problem”; Skeet, Ann Gregg. “Defining Healthy Organizational Culture” Note: The guidance in this paper is generally directed towards professionals in operating roles within companies, namely, executives  responsible for framing and implementing their company’s approach to technology ethics. It should be acknowledged that such work  inevitably takes place in the context of factors within and outside companies that might constrain or otherwise shape an approach to  promoting ethical behaviour. For instance, the degree of regulation in a company’s industry may shape the relevant scope for ethical  deliberation. Similarly, the financial obligations inherent in a company’s capital structure may limit what an individual actor can do to  influence business operations – even as those financial obligations and operations may themselves be relevant topics for ethically oriented  discussion. We note these factors simply to acknowledge the complexity of working on ethics in any existing organizational structure or  multistakeholder environment. That said, we hope these principles and applications can be helpful to professionals in these roles.Contemporary psychology highlights the power of designing systems that go with the grain of human psychology. Attention, construal and motivation are three core psychological processes that can be harnessed to serve as behavioural design principles. Attention Construal Motivation Ethical people can behave unethically because  their attention is focused elsewhere    Effective system design prompts people to  think about ethics routinely  –Trainings  –Conversation  starters  –Blogs  –Pre-mortems –Timely   reminders  –Checklists  –Algorithms   that identify  ethical risks –Mantras  –Mission  statements  –Acronyms  –SlogansBuilding  awarenessUsing  organizational  nudgesCreating shared  languageIndividuals’ behaviour is influenced by how they  interpret their environment  Effective system design helps people recognize  ethical conduct and adjust behaviour accordingly  –Functionally and  socially diverse  teams to identify  different issues  and consider  downstream  effects –Modes of moral  reasoning or  ethical lens  –Principles for  responsible use  of technology –Receiving input  from users,  customers and  others affected  by the action or  technologyDrawing  on diverse  perspectivesUsing  frameworks for  ethical decisionmakingEngaging  stakeholdersPeople are motivated by more then material  incentives – they also have intrinsic prosocial  motivations    Effective system design establishes ethical  norms of behaviour  –Rotating  assignments   –Conscious  community  creation   –Narrative  integration –Rubrics  encouraging  ethical reflexivity,  cross-divisional  teams, using  mission –Historical  reviews, selfassessments,  acknowledging  uncertaintyFostering  empathetic  relationshipsIntegrating  organizational  functionsDeveloping  organizational  introspection Ethics by Design: An organizational approach to responsible use of technology  7
Ethics by design  principles2 We turn to a deeper discussion, with illustrations, of  the psychological processes of attention, construal  and motivation that are regarded as behavioural  design principles. While our primary focus is on  the ethical design, development and deployment of technology, these principles – particularly when  used in combination – are broadly relevant to the  challenge of prompting ethical behaviour in a variety  of contexts. We provide examples from disparate  contexts to illustrate the possibilities.Improving ethics often requires altering the type of  situation a person is in, not simply altering the type  of people in a given situation. Nicholas Epley and David Tannenbaum20 Attention operates like a spotlight rather than a  floodlight, focusing on a small slice of all possible  relevant information … An otherwise ethical person  might behave unethically simply by failing to consider  the ethical implications of his or her actions. Nicholas EpleyAttention 2.1 Social psychology teaches that attention functions  more like a “spotlight” than a “floodlight”. The  implied behavioural design challenge involves  keeping ethics top-of-mind, particularly with critical  employees at important decision junctures. Refocusing the attention in a timely manner on the  ethical implications of the technology helps cut  through competing factors that may cause this to  be neglected. The need to do so is memorably  suggested by the well-known “invisible gorilla”  experiment conducted by Christopher Chabris and  Daniel Simons.21 Participants watched a video of students playing basketball and were instructed  to count the number of times players passed the  ball. With the “spotlight” of their attention focused  on the act of counting, half of the participants  failed to notice a person in a gorilla suit crossing  the court. By analogy, the absence of timely  reminders might result in well-intended individuals  and organizations losing sight of important ethical  considerations – the metaphorical “person in the  gorilla suit” hidden in plain sight.  Insights from the social and behavioural sciences  can serve as a wellspring of ideas for the focusing  Ethics by Design: An organizational approach to responsible use of technology  8
of attention. For example, the state of New Mexico  found that a timely pop-up message reminding  most unemployment insurance claimants to report  their past week’s earnings accurately resulted in a  35% reduction in overpayments.22 (Note that the  timing of the digital pop-up messages illustrates  the tactic of focusing attention on ethical behaviour.  The content of the messages – highlighting a social  norm – illustrates the principle of social motivation,  to be discussed shortly.) Another behavioural tool  is checklists, long used in the aviation profession and more recently advocated in the medical domain  by Atul Gawande. Well-designed checklists that  are tailored to specific use cases can help ease  cognitive load, focus attention on crucial tasks or  issues at appropriate times, and amplify the “voices”  of lower-status individuals raising uncomfortable  issues.23 However, checklists, as with any tool,  can be misused. Without complementary tactics  described later in this paper, checklists can devolve  from useful guidance into compliance “tick boxes”. Design principle #1 FIGURE 2 Examples of tools and tactics to drive attention It is not uncommon for firms to establish formal or  informal guidelines (e.g. codes of behaviour) and  articulate mission statements, and reinforce these  using physical or electronically delivered cues and  reminders. But given the “spotlight” nature of human  attention, such interventions might not go far enough  to keep ethics at the forefront of people’s minds  and embedded into daily operational processes and  decision-making.  A number of companies therefore work with an  expanded set of tools to focus attention on ethical  issues. These include more innovative approaches  to training, promoting active discourse on ethical  issues and providing tools to better embed ethics in  daily workflows. Building awareness  By imparting familiarity with ethics concepts, formal  training can be an essential first step in helping  employees recognize, and later reflect on, ethical  issues that might arise in their work. By making such training mandatory and delivering it at scale  (with periodic refreshes), firms can ensure that all  employees receive exposure to critical concepts  and form a better appreciation of their importance. Note that in-depth training highlighting the  application of ethical principles in real-world  business decisions can also promote ethical  construals – to be discussed shortly. We also  note that while leaders should not overestimate  the effectiveness of training in isolation from other  systematic interventions, it is nonetheless natural  to consider both in-depth training (to promote  ethical construals) and more frequent reminders and  refreshers (to help keep ethics top-of-mind) as part  of a comprehensive ethical design strategy.  To enable retention and keep ethics prominent at  crucial moments, firms should consider the format,  framing and frequency with which educational  content is imparted. For example, relying  excessively on video chat to deliver lengthy training Source: World Economic Forum, based on Epley, Nicholas, and David Tannenbaum. “Treating Ethics as a Design Problem”; Skeet, Ann Gregg. “Defining Healthy Organizational Culture”By imparting familiarity with ethics  concepts, employees can more easily  recognize ethical issues through:    –Training to familiarize them with ethics   –Internal communications channels  such as blogposts and contests  –Pre-mortems and post-mortems   to avoid systemic ethical failures in   a projectHow organizations orient people  towards ethics…Building awarenessAttention Effective system design prompts people to think about ethics routinely Timely flagging of issues for review  by using:    –Reminders built into existing processes  such as sales due diligence, customer  presentations and hiring interviews  –Technical tools that review algorithms  to identify potential ethical issues  –Checklists and dashboardsHow organizations remind people  about ethics…Using organizational nudges Weaving values and ethics into  declarative cultural elements such as:  –Mantras and acronyms and other  mnemonic devices  –Mission statements  –Codes of conduct  –Intentional names for business  functions and teamsHow organizations talk about  ethics…Creating shared language Ethics by Design: An organizational approach to responsible use of technology  9
can compromise engagement due to phenomena  such as “Zoom fatigue”.24 However, infusing training  content with storytelling and innovative multimedia  tools (even entertainment) can improve engagement  and overall effectiveness. Illustrative examples of innovative ethics trainings  and related tools include:  –Dell deploying a training game that was shown to  notably increase awareness of the firm’s values25   –Cisco debuting an “Ethics Idol” contest,26 using  video content and music to support employee  familiarity with firm principles  –Circulating postcards with real-life dilemmas  so that people can see “ethics in action”  across the company Continually encouraging conversations involving  ethical considerations can also build familiarity  with and focus attention on how ethical concepts  apply in real-life scenarios. A number of avenues  exist, including periodic blogs (which can address  multiple topics while supporting updates and broad  community engagement, and more generally help  keep the issue top-of-mind) and panel discussions  (helpful for increasing awareness through  showcasing diverse participant perspectives).  One notable example of promoting dialogue is a blog  run by Allianz Life’s chief ethics and compliance officer,  which has become one of the most-read pages on  the company’s internal site.27 The blog shares the  challenges faced by the firm’s leadership, while raising  awareness of the role of the ethics office and inviting  employee engagement in related discussions. Another example of encouraging dialogue comes  from the non-profit sector. NetHope, a nonprofit consortium of nearly 60 global non-profit  organizations that emphasizes collective action and  harnesses the power of technology for the social  impact sector, convened an AI Working Group of  more than 30 global NGOs.28 This group identified  a need for more capacity-building in understanding  the challenges and risks that AI poses. The group  also realized the need for training in how to make  ethical decisions in real-world scenarios. NetHope,  in collaboration with USAID and MIT D-Lab, hosted  a series of workshops and webinars for non-profits  and private-sector partners in 2020 to explore the  ethical considerations related to the principle of  fairness in AI use cases for humanitarian response,  education, health, workforce and agriculture. A  toolkit is expected to be published from this effort. Finally, pre-mortems and post-mortems are tools  used to avoid systemic ethical failures in a project.29  Identifying ethical risks – those that can harm other  people – before a project begins makes it less likely to experience the kinds of cascade effects that lead to  ethical disasters. These tools help to mitigate against  multiple team failures that in isolation would have been  minor, but in concert produce an ethical disaster.30 Using organizational nudges While training and guidance are commonly used  to focus attention on ethics generally, new means  are emerging that promote attention by flagging,  in a timely way, specific issues for human review.  By analysing data and systems far faster than  humans can, these tools may uncover risks (such  as promoting biases or compromising privacy) that  could otherwise go undetected or unaddressed.  Technology-enabled tools for focusing attention  become more practical as many jobs become  increasingly digitally mediated. Analytics Ventures31  uses algorithmic assessment tools to efficiently  review the decision-making processes of algorithms  in order to help developers better anticipate  potential ethical challenges.  A key attribute of effective nudges is their  timeliness. One company built its human rights  assessment directly into its due diligence practice  for sales, recognizing that the issue needed to be  raised at the point of closing the deal and getting it  approved in order to be effective.32 Creating shared language Businesses have learned to develop new, shared  language as a technique for bringing attention  to ethical concerns. In one company, the first  document a new employee receives is the  corporate code of conduct. And some companies  decide to start at the beginning, by revisiting and  updating their mission statements. NovaCare  invited employee input to help define its company  values; the resulting shared mission statement  and accompanying organizational changes helped  to reduce turnover and drive stronger ethical  awareness and alignment.33 One organization arranged its values into an  acronym that formed an actual word, to encourage  its use as a mantra in the company and so draw  attention to ethics. Others give careful consideration  to the names they use for newly created teams,  aware that such functional titles and groups serve  as new declarative cultural elements that can have  a lasting effect in drawing attention to ethics.  In industries worldwide, a focus has been placed on  ethical issues by introducing the ESG framework.  The letters stand for environment, social and  governance concerns and most companies now  report on these to stakeholders. New business  publication lists, metrics34 and disclosure  mechanisms35 have emerged, and the acronym  has been powerful in keeping ethical issues at the  forefront of executives’ minds.36 Ethics by Design: An organizational approach to responsible use of technology  10
Consequences of failing to promote attention Failing to pay adequate attention to ethical  considerations can have material adverse  consequences. Apple offers one example:37 The social  networking app Path was uploading user addressbook lists onto its own servers, which seems to  have violated Apple’s policy.38 While Apple provided  clear guidelines to app developers on how best to  maintain the privacy of user data, it apparently failed  to sufficiently emphasize and enforce these guidelines.  Fallout from the incident included significant public  and regulatory backlash for the company. While focusing attention on ethics is a necessary  consideration, it is not sufficient to drive more  consistent ethical behaviour. The manner in which  ethics programmes are crafted – for example,  whether legality is emphasized over morality – can  shape ethical construals, to be discussed in the  next subsection. Furthermore, ethical motivations  should be fostered, to be discussed subsequently. Construal 2.2 To predict the behaviour of a given person successfully,  we must be able to appreciate the actor’s construal of  the situation – that is, the manner in which the person  understands the situation as a whole. Richard Nisbett and Lee Ross39 To act in accordance with ethical principles,  individuals need to interpret their work in ethical  terms. That is, they must construe their work and  environment in terms of ethical (as opposed to  economic, pragmatic, legalistic or other) principles. A simple illustration of the power of cuing ethical  construals can be found in a study in which college students were asked to play a resourceallocation game. Framing the exercise as a “Wall  Street Game” rather than a “Community Game”  resulted in a material reduction in cooperative  behaviour.40 Similarly, when the window for military  service member re-enrollment in a thrift savings  plans was promoted as an opportunity for a “fresh  start”, re-enrollment increased by 22%.41  Design principle #2 FIGURE 3 Source: World Economic Forum, based on Epley, Nicholas, and David Tannenbaum. “Treating Ethics as a Design Problem”; Skeet, Ann Gregg. “Defining Healthy Organizational Culture”Stakeholders from different  backgrounds will often interpret the  same circumstances in different ways.  Gather perspectives by:   –Standing up teams with different  functional expertise  –Ensuring teams have both social and  deep-level diversity  –Providing guides and other tools to  solicit internal and external perspectivesHow organizations employ   diversity for ethics…Considering diverse  perspectivesConstrual Effective system design helps people to recognize ethical conduct Weaving values and ethics into  declarative cultural elements such as:  –Gathering input from those using the  products and services  –Identification of the downstream  effects of decisions and products  –Opportunities to identify blind spots  and biases missed by product and  service developersHow an organization’s decisions  and products affect people…Engaging key  stakeholders Frameworks encourage the application  of different ethical lenses by:   –Posing questions using classic ethical  paradigms vs. legal or policy frames  –Exploring consistency with the  organization’s mission and values  –Aligning with specific principles the  organization commits to followHow organizations reason   morally…Using frameworks for  ethical decision-making Ethics by Design: An organizational approach to responsible use of technology  11
Examples of tools and tactics to drive construal Changing how people construe a situation can  affect the behaviour they deem appropriate. In  particular, imparting knowledge of ethical concepts  and promulgating guiding principles in clear terms  (avoiding, for example, highly legalistic language)  can promote ethical construals.  Technical tools can make complex datasets  and algorithms more intelligible and clarify the  implications of their design and deployment.  By highlighting potential risks and unintended  consequences, such tools can prompt individuals  to consider data and algorithms in ethical terms.  Examples of technical tools that aid with construal:  –Database marketing provider Acxiom has  a data ethics programme that ensures the  data it provides to marketers complies with  the ethical data use methodologies and data  governance across each participating country.  Acxiom also maintains a privacy team in  every region so that its tools adhere to data  protection rules, cross-border requirements  and appropriate use of data42  –Accenture developed chatbots as a resource  for employees to anonymously access ethicsrelated guidance and resources43 Considering diverse perspectives  Considering technology’s effects on potentially  affected populations – in particular, through a  focus on the impacts on vulnerable communities  – is an important step in ethical deliberations.  Including people with diverse perspectives  in discussions of ethically fraught issues can  promote ethical construals: Stakeholders from  different backgrounds will often interpret the  same circumstances in different ways. Promoting  dialogue to elicit varying perspectives makes it  more likely that organizations confront potential  ethical challenges head-on.  There are compelling, research-based reasons to  have diverse groups. Research by Kathy Phillips44  at Columbia University explored diversity on the  surface, which she terms social-level diversity,  and differences you can’t see, such as opinions  and the way people think, which she identifies as  deep-level diversity.45 She built on research done  by Sam Sommers which found that everyone,  both those in the majority and those in the  minority, changes their behaviour in groups with  social category differences.46 47 They actually  prepare more thoroughly,48 work harder49 and  think about issues more deeply.50 Further, Phillips identified a “delusion of  homogeneity”.51 Homogenous groups are overly  confident of their ability to arrive at a correct  answer and less likely to do so. Diverse groups  were more accurate in their understanding of their ability, and thus more likely to feel confident they  had an accurate answer when they did and less  certain when they did not. In other words, diverse  groups are more in touch with reality.  Some firms have sought to elicit diversity of  perspectives through organizational structures and  team compositions. Others have opted to appoint  designated experts to challenge the thinking of the  rest of the organization or lead formal consequencescanning or ethical risk assessments. Furthermore,  organizations have incorporated consultations and  engagements with representatives from affected  communities into their technology design process.  These approaches, not mutually exclusive, can help  frame an organization’s operational choices in terms of  potential risks to stakeholders or the broader society.  Several firms have successfully harnessed diverse  perspectives within their organizations to better  confront ethical challenges:   –Lockheed Martin52 and Microsoft53 created  networks of embedded ethics experts charged  with ensuring that every operational dimension,  from strategy-setting to market delivery, is  conducted with the input of an ethical advocate,  and that ethical priorities are not overlooked in  favour of other factors (such as profit)  –Salesforce periodically convenes an advisory  council to solicit internal and external advice on  policies and practices on ethical issues related to  its business and products54  –Appen promotes diversity and inclusion in the  workplace by hiring more than 100 persons with  disabilities (PWDs). By championing diversity,  Appen has seen continued success with projects  that include PWDs in their recruiting efforts Using ethical decision-making frameworks Frameworks that encourage people to consider  different modes of moral reasoning are becoming  more commonplace in business settings. Most  of the organizations we spoke to had developed  internal sets of principles to guide their decisions,  particularly with regard to the responsible use of  technology. Use of technology is a typical entry  point used by companies to develop customized  principles and decision-making frameworks  for the organization, which can have spillover  effects in bringing ethics into other workstreams.  There are also broad frameworks that embody a  philosophical ethical view, such as the Markkula  Center’s Framework for Ethical Decision Making,55  and more specific ones such as frameworks that  consider the impact on employees in workplaces  where AI is introduced.56 The United Nations  Guiding Principles on Business and Human  Rights also offer a foundational framework for  ethical decision-making, particularly useful for  companies starting out on their “ethics journey”.57 Ethics by Design: An organizational approach to responsible use of technology  12
Engaging key stakeholders Increasingly, companies recognize the benefits of  engaging key stakeholders – those directly affected  by technology and those impacted by its downstream  effects. Many have created formal mechanisms for  gathering input from these stakeholders.  –Workday convenes customer advisory councils  during product development to elicit feedback  and address customer concerns before a  product is released58  –BSR provides human rights impact  assessments of business practices to  help companies improve the ethics of their  operations from a human rights standpoint59  –PocketConfidant AI relies on third-party experts  to examine the potential ethical implications of  its products60  –Salesforce provides users of its AI platform with inapp notifications to raise awareness that the use  of certain sensitive fields (e.g. age, race, gender)  are at risk of contributing to biased outcomes61 As discussed above, programmes must focus the  attention of critical personnel at critical moments  to keep ethical considerations top-of-mind; and  they must be crafted in terms that promote ethical  (and not merely legalistic, economic or complianceoriented) construals. But this is not sufficient. To  bridge the gap between ethical intentions and ethical  actions, firms must motivate ethical behaviour, both  in the pursuit of prosocial goals or opportunities and  in avoiding, preventing and mitigating harms. As noted above, the power of material incentives  to influence behaviour is fundamental to classical  economics. However, material incentives are not  the only driver of human behaviour, and indeed a  key finding of modern psychology is that material  incentives can sometimes “crowd out” the intrinsic  motivations that lead to both superior performance  and ethical behaviour in the workplace.66 For example, several studies have revealed that  financial “carrot and stick” incentive structures  are often less effective at motivating employee  performance than prosocial or charitable  incentives.67 Communicating explicit imperatives  can also be less powerful than lighter-touch  techniques that gently “nudge” human behaviour.  For example, an experiment by the British tax  agency found that payment compliance rose by  6.8% when taxpayers were informed that they  were one of few delinquents in their home towns,68  compared with 3.9% when delinquent notices did  not mention the community. This is consistent with  the unemployment insurance example discussed in  the section on Attention, above.Money … is very often the most expensive way to  motivate people. Social norms are not only cheaper,  but often more effective as well. Dan Ariely65Motivation 2.3Consequences of failing to promote construal  Encouraging ethical construals helps organizations  avoid “ethical blind spots”,62 which – left unaddressed  – can lead to adverse outcomes downstream.  In one high-profile example, Google developed  an AI application called Duplex that was able to  credibly approximate human speech patterns when  helping people schedule appointments over the  phone. This technical accomplishment was met with  cheers when unveiled at a developers’ conference.  But many commentators expressed concern over  possible scenarios in which humans are fooled into  believing they are interacting with other humans. The  social media theorist Zeynep Tufekci commented:Google Assistant making calls pretending to be  human not only without disclosing that it’s a bot,  but adding “ummm” and “aaah” to deceive the  human on the other end with the room cheering  it ... horrifying. Silicon Valley is ethically lost,  rudderless and has not learned a thing.63 After a widespread outcry, Google clarified that  the system would have “disclosure built in”. The  outcry might have been avoided, or muted, if ethical  construals – such as the scenario highlighted  by Tufekci – were promoted alongside the  development of the technology.64  Ethics by Design: An organizational approach to responsible use of technology  13
Examples of tools and tactics to drive motivation  Motivation is highly influenced by the culture of  organizations and can be best sustained through  the creation of robust, self-reinforcing incentives  and operational structures. The Markkula Center  for Applied Ethics has advanced a framework for  how “healthy” organizations can act to sustainably  motivate ethical behaviour.69  First, Markkula posits that organizations should  foster relationships that develop individuals’ ability to  interact well with others. Next, they should support  cross-functional collaboration and the integration of  strategic and tactical functions. Finally, organizations  should develop the capability for introspection and  identification of the mental processes that influence  the behaviour of people within them. This framework  can be used to identify the range of tools and tactics  employed in the market today. Fostering empathetic relationships Organizations can encourage ethical action  through the cultivation of empathetic relationships  between different stakeholder groups, both  within and outside of the firm. Cultivating  such relationships creates empathy within the  organization and is important at Chatterbox Labs,  which has seen great success by deliberately  bringing engineers and data scientists together  in meetings to better understand each other’s  perspectives.70 In the case of cultivating  empathetic relationships outside of the firm,  Wetherill Associates trains employees to bear in  mind the customers, suppliers and communities  in which they operate when making business decisions.71 Other companies rely on rotating  employees through positions in different parts of  the company.72 Empathetic relationship development can also be  encouraged by developing conscious in-person or  virtual communities that offer exposure to the good  behaviour of peers. By creating opportunities for  people to do good and then actively promoting such  behaviour, organizations can create a shared sense  of community and help establish prosocial cultural  norms (e.g. HP’s “Champions Recognition Program”  showcases employees demonstrating admirable  leadership qualities).73 Similarly, NetHope members  join a non-profit consortium to benefit from the same  resources that individual organizations would not be  able to invest in on their own. Furthermore, NetHope  members benefit from having access to a community  of organizations that are willing to collaborate to solve  shared challenges. This network includes more than  60 partners and supporters that contribute resources  and expertise.74 BT addresses human rights issues  by convening a human rights working group – a  virtual team of 10–15 people across BT’s jurisdictions  to share understanding and awareness of human  rights impacts. Members of this working group are  brought into the development of risk assessments  led by the core team. BT found that developing  personal relationships helps uncover that moment at  which people say, “I’m not really sure about this.”75 Finally, another way to develop and strengthen  supported relationships is through narrative. Personal  stories can be a compelling tool in creating cultures Design principle #3 FIGURE 4 Source: World Economic Forum, based on Epley, Nicholas, and David Tannenbaum. “Treating Ethics as a Design Problem”; Skeet, Ann Gregg. “Defining Healthy Organizational Culture”Motivation Incentives and culture-change activities to encourage ethical and prosocial behaviour Organizations should remain aware  of their role in society and promote  supportive relationships internally via:  –Cross-silo relationship development to  nurture empathy, job rotations  –Conscious community-building   –Narrative organizational integration  to use personal stories to motivate  ethical behaviourHow organizations interact…Fostering empathetic  relationships Organizations should coordinate up,  down and across different structures  and stakeholder groups through:   –Ethical organizational reflexivity to  create organization-wide frameworks  for ethical decision-making  –Horizontal connectivity that integrates  different departments  –Organizational coherence to tether to a  defined mission and visionHow organizations function… Integrating organizational  functions Organizations should remain flexible,  adaptable, coherent, energized and  stable by employing:   –Historical organizational integration  to celebrate a shared history and  desired legacy  –Ethical organizational reflection to  promote regular self-assessment  –Temporal organizational integration to  acknowledge uncertainty and changeHow organizations think about   themselves… Developing organizational  introspection Ethics by Design: An organizational approach to responsible use of technology  14
that motivate ethical behaviour, as demonstrated  by Adobe’s highly trafficked internal blog on which  employees share stories and experiences relating  to ethical practices with their peers and seek  related guidance from them.76 Storytelling is a lowinvestment, high-impact77 method used by leaders  to establish connections with their team – a pathway  for those executives to make a more personal  connection with employees.78 Integrating organizational functions Integration and coordination of strategy and tactics  can help organizations function better. One way  to promote integration is through the cultivation of  ethical organizational reflexivity,79 or the setting of  shared expectations, which can help make ethical  outcomes easier, or even automatic. For example,  a transparently messaged and swiftly executed  recall during a 1982 Tylenol poisoning scare sent a  clear message from the Johnson & Johnson Chief  Executive Officer to employees that public safety  should supersede profits.80 Another example of  integrating organizational functions is the journey  of IBM’s AI ethics board, which includes executives  representing all IBM divisions. The initial version  of the AI ethics board was useful for awareness,  creating links between divisions of the company,  but it did not have enough decision-making power  or senior executive participation. Since the board  was restructured, it has had more decision-making  authority on workforce education, developers’  pipeline processes and prospective offerings from  the business units. The board’s deliberations are  more easily and promptly implemented across the  company.81 This is an example of extrinsic means  of encouraging ethical behaviour being designed  into the organization, without relying on the kinds  of material incentives that crowd out intrinsic  motivations, mentioned above. A commitment  to considering systemic changes to drive ethical  behaviour is a core tenet of the Markkula Center’s  ethical leadership practice.82 Convening teams that are representative of diverse  communities (e.g. Aerojet Rocketdyne’s “Ethics  Champion” initiative, which convenes employees  across the firm to collaborate on ethics issues)83 can  help support relationships by promoting a shared  understanding of organizational ethical issues  through different points of views and driving stronger   buy-in for shared values. Establishing clear roles and decision-making rights also enables ethical  advocates to affect operational decision-making. Finally, organizational coherence, or the alignment  of operational priorities with a firm’s mission  or values, can promote integration, as Delta  demonstrated when discontinuing NRA member  discounts that were at odds with its stated values  in the wake of the Parkland school shooting.84 The  Markkula Center offers one simple approach to help  companies develop this practice.85 Developing organizational introspection Firms should cultivate the ability to reflect upon  the factors motivating organizational behaviour  and to assess whether those factors and the  resulting behaviour are sufficiently ethical. The  emphasis of a shared history and desired legacy  can be a powerful force to prompt such reflection.  For example, Canon encourages employees to  consider how their daily actions align with the firm’s  history and founding philosophy of “all people,  regardless of race, religion, or culture, harmoniously  living and working together into the future”.86  Another organization with a long history and legacy  is the Coca-Cola Company. As part of its digital  transformation, Coca-Cola is starting to embed  ethical beliefs and principles into its business and  technology solution practices.87 Systematic assessments of organizational  responses to ethical issues (such as the quarterly  affirmation required of Allstate senior vice-presidents  that their teams have upheld company values)88  can also help prompt such reflection by identifying  tangible, actionable opportunities for improvement,  as well as areas of strength, in a way that  empowers and motivates leadership and individuals  to develop their behaviour positively.  Finally, leadership should help organizations  manage for an uncertain future by anticipating and  reflecting upon potential future risks that may be  ethically unacceptable, as Twitter and Square did  when announcing that all employees would be  permitted to work from home “forever” to remain  safe during the COVID-19 pandemic and should  feel empowered to “work where they feel most  creative and productive”, despite uncertainty  about the operational challenges a fully distributed  workforce might cause.  Consequences of failing to promote motivation Motivation is imperative in translating awareness and  understanding into action. Organizations that fail to  bridge this gap through the right balance of intrinsic  and extrinsic incentives can experience ethical  outcomes that are at odds with stated values.  In one notable case, well-reputed Danske  Bank acquired AS Sampo Bank and failed to  adequately assimilate that target into its highly ethics-oriented culture and infrastructure. This  led to a permissive environment, which the latter  exploited to launder substantial funds for Russian  and ex-Soviet customers. Danske Bank, motivated  by the profits the acquired entity was generating,  did not adequately investigate and was ultimately  implicated in the wrongdoing.89  Ethics by Design: An organizational approach to responsible use of technology  15
Efforts to sustainably drive ethical behaviour in  technology-producing and technology-enabled  firms benefit from an integrated approach that:   –Raises awareness of important principles and  keeps them top-of-mind  –Cultivates “cognitive toolkits” involving training,  ethical frameworks and judiciously chosen  language to help employees consider their work  in ethical terms.   –Harnesses the power of both intrinsic and  extrinsic motivations to drive actions that are  aligned with core principles.  Leaders should also be aware that people in the  organization may be at different levels in terms of  their own moral reasoning maturity or feel they  don’t have the influence to address an ethical issue.  Alternatively, people might mislabel the challenge they are experiencing as it relates to using ethics  – saying, for example, that they didn’t realize there  was an ethical issue present when in reality they  identified the issue but struggled to figure out  what to do about it. The organization-wide rubric  recommended in our discussion of the motivation  pillar is one way to account for the variances in how  Epley’s model is used, as are some of the tools,  such as consequence-scanning, that we found  companies using. The foregoing examples, while illustrative, are not  applicable to every company. A range of specific  firmographic factors (e.g. maturity, size, sector and  reliance on technology) collectively determine how  a specific organization can best craft an ethics  programme that harnesses the psychological  processes of attention, construal and motivation. In  the next section, we will explore the overall findings  of our research and offer a set of recommendations  for the path forward. Summary 2.4 Ethics by Design: An organizational approach to responsible use of technology  16
Findings3 Our team, with representatives from the World  Economic Forum, Deloitte and the Markkula Center,  spoke with 13 companies in the late summer of  2020. Seven were Fortune 500 companies, and  the interviews were conducted with executives in  seven different countries. These conversations,  and the history of available examples, revealed  how business leaders in 2020 are influencing the  business environment to encourage responsible  use of technology and build organizational capacity  to act with ethics. The success certain companies  are experiencing in managing their cultures and  the organizational environment to promote ethics  is encouraging; it validates the utility of Epley’s  framework and reveals new understanding at  the firm and sector levels about how executives  can create these conditions. It also supports  statements made by business leaders about the  necessity for businesses to reflect the needs of a set of stakeholders broader than just shareholders,  and commitments not only to financial targets but  also to societal goals.90 Corporations are, indeed,  building their capacity for “ethical organizational  reflexivity”,91 the tendency to engage in ethical  behaviour and deliberations more routinely. Our research found fewer current market players  focusing on construal (as compared to attention  or motivation); however, of those firms who have  targeted this space, most have concentrated on  developing tools to better analyse their processes  and solutions for ethical risks. More can be done  to empower practitioners with frameworks and  guidance and to institutionalize the practice of  including diverse perspectives (e.g. technical,  cultural or socioeconomic) in decision-making that  sufficiently consider ethical consequences. Ethics by Design: An organizational approach to responsible use of technology  17
The importance of integrating attention, construal  and motivation3.1 Because the pillars of Epley’s framework target  different aspects of the intention-action gap (from  building awareness, to construing relevance,  to motivating action), it stands to reason that  they should build on and reinforce each other.  Our hypothesis that organizations will probably  experience more sustainable ethical outcomes from  integrating and co-promoting the pillars of Epley’s  framework was confirmed.  First, it is evident from several high-profile examples  that failing to integrate the pillars may contribute to  ethical performance failures. Boeing has been a leader in the airline industry for  decades, and currently splits the large passenger  aircraft manufacturing market with France’s  Airbus.92 Two deadly crashes of its recently  introduced 737 MAX airliners, however, have  revealed significant process flaws and cultural  conditions that allowed cost and speed-to-market  to supplant quality and safety as priorities in the  manufacturing process. In the words of a Boeing  engineer who filed a formal complaint, “I was willing  to stand up for safety and quality, but was unable  to actually have an effect in those areas … Boeing  management was more concerned with cost and  schedule than safety or quality.”93 Amazon’s adverse experience with its Rekognition  facial software94 reflects a failure to promote both  construal and motivation. Fixated on the functionality  of its solution rather than the potential consequences  of its deployment (construal) and driven by the desire  to capitalize on such a differentiated, profitable  offering (motivation), Amazon began selling this  software to US government agencies, despite having  access to research that indicated the potential for  the software to reflect racial and gender biases.  Ultimately, a public outcry resulted in Amazon  banning the use of the app by law enforcement until  appropriate regulations were put in place.95 Second, we found evidence in the examples  provided by today’s business executives across  industries and in companies of varying size and  maturity, that organizations acting in ways that  draw on each of Epley’s pillars can, indeed,  create situations that make ethical behaviour and  deliberations more routine.  At Microsoft, the decision to create a work group  within the engineering function and call it Ethics  and Society96 activates each of Epley’s pillars, as did many other examples at Microsoft, which is  not surprising to find in a large, well-established  company. The name of the group – as well as  the presence of readily accessible ethics experts  – prompts employees to construe their work in  ethical terms. The very existence of such a group  draws attention to ethics and makes the connection  between Microsoft and broader society hard to  miss. A specialized team dedicated to helping  fellow employees sort through ethical dilemmas is  a commitment to supporting construal. And there  is a not-so-gentle nudge to work with the group as  employees do not want to be identified as resisting  working with the ethics team. At a smaller and  newer company, DataRobot, there is a practice of  tracking mentions of the company and its products  in the context of ethics in the media.97 This is one  practice that, again, activates all of the pillars – by  measuring ethics mentions, employee attention is  drawn to it, and it helps employees see how their  work contributes to ethics. Over time, metrics will  motivate employees to continue with this attention. To activate each of Epley’s pillars does not imply  that a single action must activate all three. As the  examples shared in the section above illustrate,  discrete activities using a single pillar are also  effective. There was a systematic approach to  embedding ethics in organizations with a variety  of ethics procedures, designed to tap all of the  pillars. In some companies, ethics criteria were  placed in the context of the country in which  business was being conducted. One company  described delivering “small ethics pills” through  presentations, questionnaires and design thinking.  Several described piloting ethics practices in one  part of the company and then scaling them across  the organization, recognizing that this developed  both learning capacity and ethics practices.  Suade Labs’ choice to add a new horizontal role  to ensure communications across departments  is one example of the ways in which a company’s  structure can support this effort.98 Similarly,  Workday launched a cross-functional task force  as part of its AI Ethics Initiative, which included  representatives from Product and Engineering,  Legal, Public Policy and Privacy, and Ethics and  Compliance.99 The group worked together to  develop the company’s machine learning ethics  principles, as well as operational controls to support  the principles. Finally, the Markkula Center’s Ethics  in Technology Practice provides approaches that  address each of Epley’s three pillars.100 Ethics by Design: An organizational approach to responsible use of technology  18
As they work to cultivate ethical cultures, a growing  number of companies are adding steps to their  product and service development processes  that serve as “gates” for ethics. These steps  are intentional assessments that apply specific  principles and the process of responding to  question sets aimed at uncovering the ethical  implications of technology. This practice also  activates each of Epley’s principles. Developers’  attention is drawn to ethics and construed  against ethical principles. By making it part of an  established process, companies remove barriers –  and even motivate employees – to behave ethically. In many organizations, this takes the form of  some type of self-assessment, such as that  developed by the Markkula Center for Applied  Ethics.103 Many assessments are designed to  focus on a specific business need or product  development, where an assessment for ethics  might be one part of the process. At DataRobot, an impact assessment for ethics is now  performed for each project, requiring AI product and  capability developers to ask themselves, essentially,  “What are the positive outcomes of this work and  how could it go wrong?” and honing in specifically on the aim, or goals, of developing that capability.104  Microsoft’s list of harms serves a similar function. In  addition, the company instituted impact assessments  used in product development. A senior leader at  Microsoft explained that assessments and other tools  are mechanisms for reinforcing the company culture  in language, which he identified as an opportunity  for leadership. Tools such as assessments solidify  the emerging language. Of their impact assessment,  he told us, “It asks engineers questions like ‘Is this a  sensitive use?’ We ask very deep questions about what  harms could be created by this tech we’re creating.  These could be subtle harms. We are not always  creating a model that has very overt bias and is going  to exclude a bunch of the population or misidentify  people. One example is neural text-to-speech. It can  sound like any human on earth. Can you imagine the  ways this could be used very badly? We went through  fairly deep assessments – e.g. interviewed voice actors  – put gates around how the tech gets to be used and  limited its customizability and production.”105 By refocusing attention, promoting ethical construal  and lowering motivational barriers, such procedural  interventions enable an organization-level embrace  of what Daniel Kahneman calls “slow thinking” about  ethical issues.106 This can be a tangible progress Operationalizing ethics is hard work. While  companies found a number of creative ways to  draw attention to ethics and nudge people with  reminders throughout work processes, construal  emerged as the most challenging task. A first step  is framing issues in ethical rather than, for example,  purely legal or regulatory compliance terms. But  even once this framing is done arriving at a decision  that reflects the organization’s ethical commitments  remains a challenge. For many companies, the tools  they are using are nascent and underdeveloped, or  not yet linked to values in a coherent manner. Some companies invested heavily in developing the  rubric, or framework, to be used to make decisions,  but struggled with how to make this useful.  Others were moving to implement solutions, while  acknowledging that they did not fully understand  the problems they were trying to solve. “Harms Modeling – Azure Application Architecture  Guide”101 captures Microsoft’s construal model,  while doing an admirable job of drawing attention to  the harms and providing motivation to employees  as well. The language of harms suggests a utilitarian  overlay, but within Microsoft’s principles, other modes of moral reasoning are present. They speak  explicitly to fairness, as well as some individual  protections that indicate a commitment to human  rights, such as privacy and transparency. Their  principle of accountability is defined in terms of  responsibility to society, evoking a commongood view. Microsoft’s commitment to inclusion  of all people, regardless of ability, adds an oftenoverlooked set of stakeholders and has contributed  to a relatively recent commitment to accessibility in  technology design.102 Within the guide, Microsoft notes types of harms to  be identified in a “harms modelling” activity, similar  to that of security threat modelling. This activity  helps employees map the types of exercises that  need to be completed at the beginning of the  product development process. By listing the harms,  attention about ethics and human biases are raised.  Within the definitions of each, employees are guided  back to the principles Microsoft has identified, to be  used in determining if a product, feature or policy is  ethical.  Some less obvious ethical considerations,  such as skill degradation, are thus raised in a way  that reinforces learning about them while using  them to make decisions. Instituting ethical reviews and assessments is  becoming standard3.3Getting construal right is the most challenging 3.2 Ethics by Design: An organizational approach to responsible use of technology  19
even if it falls short of a fully fledged adoption of new  metrics to quantify adherence to ethical principles in  replacement of previous metrics such as speed-tomarket or growth goals. We can term this responsible  growth, to accompany responsible use of technology,  or even more broadly, responsible metrics. This gives  organizations the freedom to define success in their  own terms and signal to investors and markets about  the goals they are setting, the time horizon they are  setting them for and the stakeholders they serve.  Some emerging business reporting mechanisms are supporting this shift.107 Given that market forces  have been driving towards measuring ethics for some  time, as captured by ESG measures and the UN’s  Sustainable Development Goals, we support the  adoption of new metrics and accounting practices to  institutionalize this change. Perhaps most significantly,  companies have stories about projects they have  decided not to pursue because of ethics. IBM,  Amazon and Microsoft’s decisions not to sell facial  recognition to police departments are examples.108  Employees look to senior leadership to provide  ethics frameworks 3.4 Given employees’ desire to be trusted to behave  ethically, the role for senior leadership has never  been clearer. Leaders bear unique responsibilities  to promote ethical construal in their organizations. First, they have the opportunity to ground the  vision, purpose and values of the corporation,  its foundational declarations, in ethical contexts.  Importantly, they must also connect the loftier, In August 2020, James Guszcza, US Chief Data  Scientist at Deloitte Consulting, spoke with Paula  Goldman, the Chief Ethical and Humane Use  Officer at Salesforce. Below are some highlights of  their conversation, lightly edited for clarity. The full  conversation can be found here. When asked to describe the Office of Ethical and  Humane Use at Salesforce, Paula Goldman said,  “This is something of a new function for tech,  and it promotes two things. The first is integrating  ethical considerations as top-of-mind as we create   our technology products. The second is creating  policy for how customers use our products.  But laddering up, it’s about culture: It’s about  integrating these considerations into the day-today way in which we do business and creating a  culture of ownership in which all of our employees,  and hopefully our community, owns these issues  and has a way to participate, and where we’re  driving these issues in a very conscious way.” Goldman says that Salesforce created the  organization because the tech industry has been  at an inflection point. “I think there is a recognition  by Salesforce leadership that it is a responsibility for  us to really think about the social concerns around  technology, and to include these considerations  as part of our processes and operations. Those  concerns keep getting louder from all elements of  society. From civil society, to our employees who  really care about it, to our community. And a lot of  my work is about creating channels for listening and  for that input to be fed into our decision-making.” James Guszcza asked Goldman if the organization  has been good for business. She agreed. “Absolutely … I could cite study after study that talks about  how consumers really care about the ethics of the  companies that they’re purchasing from. I know our  customers really care about it. I think that Salesforce  has a brand reputation of taking a stand on issues  and really caring about the community and caring  about stakeholder capitalism. It actually matters for  our business. It’s very positive for us.” Guszcza noted that, in ethical deliberations, there  will often be specific outcomes with which specific  people disagree and wondered if forums should be  created for those debates. Goldman agreed, saying,  “Ethics involves looking at all the different angles on  a potential problem or issue. And then it really comes  down to values and which values you prioritize in  making decisions. One of our four core values at the  corporate level is Equality. And we weigh that really,  really heavily when we make decisions.” Guzcza asked to what extent diversity is an important  input in these deliberations. Goldman replied, “The  Office of Ethical Use is part of the Office of Equality at  Salesforce. This is because diversity and inclusion are  crucially important. Thinking about who products are  being built for, who they might unintentionally exclude,  how product use and product design can protect  vulnerable populations, especially now that we’re in  the middle of a racial justice crisis and a pandemic,  which are disproportionately affecting people of  colour and people of lower incomes. These are the  most important questions, from my perspective. In  my mind, there is no tech ethics without thinking  about the who and bringing in the perspectives of  folks that are most impacted by these problems.” Salesforce SIDEBAR 1 Ethics by Design: An organizational approach to responsible use of technology  20
strategic view of the company to the work being  done within it in a way that continues to encourage  company employees to approach decisions using  ethics. Both steps are crucial. If the foundational documents of the organization  are not yet crafted with ethics in mind, the first  step is to revisit them. A shared language is being  created, and it is when speaking this language that  conversations leading to decisions will happen. In  the words of one executive we talked with, “You  need a language as a force multiplier. That’s the  culture being manifested, that’s language. How  do you create that language? That’s a leadership  problem … language changes how you think.”109  Furthermore, even mature organizations can revisit  their core missions in ways that promote ethical  behaviour. Satya Nadella’s 2015 articulation of  Microsoft’s fresh company mission, “To empower  every person and every organization on the planet  to achieve more”, is a prominent example.110 In the materials shared with us, companies have  shifted from zero-sum and competitive phrases of  vision and purpose, such as “winning” or “being  best” in a category, attribute or skill, to more  holistic and generative language, that is, language  that supports a growth mindset,111 the belief that capacities and talents can be improved over time,  and motivate more deliberate, thoughtful action.  More enterprises are referring to responsible  technology or AI development and documenting  their organization’s use of value-sensitive design112  or developed principles on use of data such as  IBM’s Principles for Trust and Transparency.113 Linking the high-level language enterprises use about  themselves to business practices is a task for the  senior leadership team. Values and principles must  be carefully and specifically defined. For example,  IBM first defined its key principles broadly and then  went on to spell out what they meant in terms of  responsible use of specific technology; what does  it mean, for example, to trust the decision (or the  recommendation) of an AI system? The company  focuses on four pillars of trust in AI: fairness,  robustness, explainability and transparency.114  Leadership teams do not need to do this in a  vacuum. Indeed, examples were shared in which  business leaders partnered to co-create guidelines  with developers. Several of the companies  participating in this research elected to have their  chief executive officer or founder participate, another  signal that ethics has the attention of leaders. In March 2016, Microsoft released the Tay  chatbot to the general public as an experiment in  “conversational understanding”. The hope was that  the more Tay engaged in natural conversations  with people on the internet, the “smarter” it would  get. Unfortunately, a group of American pranksters  quickly trained Tay to utter misogynistic, racist  and authoritarian remarks. As a result, Microsoft  withdrew Tay from the market within 24 hours.  This episode was pivotal in Microsoft’s efforts  to articulate and operationalize its principles of  responsible AI. Prompted by the Tay episode,  Microsoft formed its AI, Ethics and Effects in  Engineering and Research (AETHER) committee,  as well as its Office of Responsible AI (ORA).  Microsoft’s Responsible AI Champs programme  exemplifies the organization’s multifaceted efforts  to bridge the gap between AI ethics theory and  practice. “Champs” from multiple geographies and  work groups serve as resources and conduits for  awareness, advice, assistance and escalation. This  organizational construct makes it more likely that  employees will keep ethical issues top-of-mind,  view their work through an ethical lens and avoid  succumbing to groupthink or organizational pressures  to suppress potential ethical issues. In short, the programme helps the organization move from talking  the ethics talk to walking the ethics walk. Leaders such as Steve Sweetman, John  Montgomery and Mira Lane credit Satya Nadella’s  efforts to create a growth mindset culture with  creating the environment in which such programmes  could take root and flourish. In 2015 – less than 12  months before the Tay episode – Nadella articulated  a fresh company mission, one designed to change  the culture from the Steve Ballmer era of stack  rankings and zero-sum leadership styles. Nadella  declared that Microsoft’s mission was “To empower  every person and every organization on the planet  to achieve more”. Drawing on the “growth mindset”  work of the influential Stanford psychologist Carol  Dweck, Nadella stated that Microsoft’s culture  would reflect “the belief that everyone can grow and  develop; potential is nurtured, not predetermined,  and anyone can change their mindset”. Microsoft  employees would be encouraged to be “learn-italls”, not “know-it-alls”.  Consistent with the growth mindset culture,  Nadella sent an email to the Tay development  team shortly after the debacle. In it, he said, “Keep  pushing, and know that I am with you … (The) key  is to keep learning and improving.”Microsoft SIDEBAR 2 Ethics by Design: An organizational approach to responsible use of technology  21
Our research was conducted in the third quarter  of 2020, so it is not surprising that diversity, equity  and inclusion were part of many conversations.  “Diversity” is a business term with wider application  in 2020 – with a meaning that goes beyond gender,  race and sexual orientation and now includes  perspectives, geographies, levels of organizations  and the variety of societal stakeholders. The ESG  (environment, social and governance) metrics, as  defined by the World Economic Forum community,  reinforced this evolution.117 What is clear now is that these diverse voices  are invited into the process of determining what  constitutes responsible use of technology and ethics  more broadly. A number of organizations identified  their commitment to groups affected by their  enterprise at “every step of the process, from problem  definition to feature development and iteration,  programming and reviewing trade-offs”. A significant majority of the companies interviewed mentioned a  special commitment to vulnerable populations. Driven by a commitment to stakeholder capitalism,  Salesforce regularly takes stands on issues for its  communities.118 As part of this, Salesforce placed the  Office of Ethical and Humane Use within the Office  of Equality. This signals its belief, according to Paula  Goldman, Chief Ethical and Humane Use Officer, that  who the technology is being designed for is a key  ethical consideration.119  Companies have also moved to consolidate their  hiring, orientation and other human resource  practices to institutionalize ethics.120 It is clear that  this needs to be done. In spite of concerted efforts to  speak to a diverse representation of executives in the  interview pool, we could not achieve diversity on a  number of dimensions.Diversity is fundamental 3.6Ethics deepens relationships with customers The executives we spoke to were well aware  of the critical role that ethics plays in building  and sustaining customer relationships; this is  illustrated by the example of companies deciding  not to sell facial recognition technology to police  departments. Companies across the board  identified the expectation of customers for them  to behave ethically as something they understood  and accepted. A range of tools were used to gather  customer input that affected ethical product design  and responsibility – from customer inclusion panels  to customer community dialogues and stakeholder  gatherings. Alternatively, some corporations identified  the choices their clients were considering, such as  significant layoffs, and grappled with contributing to a  choice they perceived to be unethical. What emerged was a tiering of relationships with  customers based on the degree of trust between  the enterprise and the client. Some companies  explicitly rank customers based on the degree of  trustworthiness they experience in the relationship,  affording those more trusted customers access to  early versions of products, inviting their feedback as  part of the design process. As one executive noted,  “We want to find bugs [by working] with people  who won’t nail us to a wall.” The reciprocity in the  relationship appears here as well. This same company  was reluctant to take on customers operating without  forethought, such as those who feel they have “got  to sprinkle some AI on it” when building capabilities,  rather than proceeding with care.    There was enough clarity on this point to signal  implications for enterprises that develop customer  relationship management tools. Future refinements  will need to account for the complex range of  relationship types and reflect the ethics “gates” that  are becoming part of building those relationships.  They will also need to account for the fact that  companies understand they are responsible for  how customers are using their products. To know  this requires capturing new information about the  competency and ethical orientation of the client. Larger companies are doing this for themselves. One  uses a trust score to measure the success of an AI  feature from an enterprise user’s perspective. This  score is a multidimensional metric that consists of  statements to which users respond and that reflect  their level of trust, including, for example, whether an  AI feature helps with job efficiency and effectiveness;  and understanding how and when the feature should  be used in the customer’s job role.  This finding suggests that customers now join  employees, who have been vocal proponents of  ethics in the technology industry in particular,115 in  seeking communities of trust, marketplaces with  identifiable, repeatable standards. New entrants  to the market glean that there is an expectation  for ethics. IBM AI Ethics Global Leader Francesca  Rossi told us, “We’re not starting a new company.  We have to work with the attitudes of the people  who work in the company. But even clients are  asking more about what we are doing about bias,  ethics. Clients are requesting this.”1163.5 Ethics by Design: An organizational approach to responsible use of technology  22
Ethics is a discrete business function  The titles of the executives we spoke to reflect the  emergence of business units dedicated to ethics.  We spoke to leaders with titles incorporating words  such as: “ethics” itself; ethical concepts, such  as “human rights”; virtues, such as “trusted”; or  principles, such as “privacy”. Where permanent  units may not yet exist, bodies such as AI ethics  review boards are becoming more commonplace. Most companies we spoke to use some type of  centralized ethics decision-making body in the  organization, and some have multiple entities.  These boards or committees are typically nested  within parts of the organization, but some are  more comprehensive. We also received data on  an increasing number of chief AI officers, some of  whom are focused on matters of ethics.121 Where ethics departments are placed points  to strategic and cultural realities, as noted with  the Salesforce example just mentioned. Some  organizations view ethics as sufficiently integral to their  brand reputation that they place ethical leadership in  organizational positions where it signals its influence  and its integration with other strategic goals.  Prior research122 points to conditions that support  the application of ethics in business, such as an  acknowledgement of the interaction corporations  have with society, a climate of trust built on a belief  that individuals can use their moral autonomy  to make decisions ethically, and specific ethical  deliberation practices. When combined with the  mix of cultural elements identified in the first finding,  and also with opportunities to introduce, use and  institutionalize ethics, patterns emerge123 that reveal  a practice of managing culture for ethics. 3.7DataRobot provides an AI platform that automates  and accelerates the steps from data to value for  machine-learning pipelines. The organization,  which was founded in 2012, aspires to be an  iconic company by democratizing data science  and machine learning for the right reasons. Its Chief  Executive Officer and co-founder, Jeremy Achin,  understood early on that ethical and responsible AI  was essential to the company’s success. In 2019, the  company formed a Trusted AI function, led by Ted  Kwartler, who reports directly to the chief executive  officer. This team aims to inform stakeholders, from  data science practitioners to those affected by AI,  and to create and use technology that is unbiased,  fair and benefits society. The team operationalizes  trust by providing industry thought leadership,  improving governance and creating trust signals that  are used by AI systems. DataRobot views trust from two angles: technology  and people. From a technical perspective,  the company looks at 11 fairness and bias  measures that assist data scientists in evaluating  their algorithms and models. From a human  perspective, DataRobot views contractual trust  as the foundational and lowest form of trust and  long-term relationships as the highest form of trust. It assigns an AI success manager and a customerfacing data scientist to every customer. DataRobot  also conducts impact assessments for every  project with every customer. It asks questions such  as, “What is the full range of outcomes – both  good and bad?” It then helps customers apply  risk-management strategies that become ongoing  activities through the product life cycle.  From an internal perspective, DataRobot’s  Trusted AI function uses several techniques  to help its teams keep ethics top-of-mind. For  example, there is a trust slide in every customer  presentation. There are weekly internal meetings  in which DataRobot employees talk about ethics.  The Trusted AI team has an open-door policy  that makes it easier for employees to talk about  sensitive topics with ethical issues. As a datadriving company, DataRobot measures its share of  voice in the public ethics debate generated from  the thought leadership content that it publishes.  Lastly, the Trusted AI team is responsible for  important features and items in its product  backlog. This integration between its ethics and  product teams in order to jointly enhance its  products creates a unified goal of building more  impactful and ethical AI products. DataRobot SIDEBAR 3 Ethics by Design: An organizational approach to responsible use of technology  23
VMware software powers the world’s complex  digital infrastructure. The company’s cloud, app  modernization, networking, security and digital  workspace offerings help customers deliver any  application on any cloud across any device. The  company’s culture and values are expressed through  the acronym EPIC2: execution, passion, integrity,  customers and community. VMware celebrates  employees in its annual EPIC2 achievement awards.  This honour is given to employees who best  exemplify these values through their actions. Integrity and ethics are embedded in everything  they do, from the company culture to its product development processes. To help operationalize  ethics into the organization, VMware’s ethics  and compliance team is creating an ethical  decision-making framework called DECIDE to  help employees determine solutions when faced  with ethically ambiguous situations. The DECIDE  model is a systematic process to evaluate potential  solutions through multiple ethical lenses, driving  an appreciation of diverse perspectives, and  enhancing ethical problem-solving capabilities. As  with its AI code of ethics, which was created in a  grass-roots manner, VMware prioritizes ethics and  its EPIC2 values at every level from its leadership  to its 32,000-strong global workforce.VMware SIDEBAR 4Ethical literacy develops as the company matures Our research confirms the findings from earlier  work on understanding how ethical literacy and  orientation evolves in organizations. As companies  mature, they develop more sophisticated moral  reasoning capabilities. They also recognize that the  nature of this kind of critical thinking is ongoing;  companies are never done with their ethics work. Aspects of the growth mindset culture are implicit in  the cultures of many organizations, including those  where very public missteps have been made. The  key is if, and how, a company institutionalizes the  learning from these stumbles into new standards.  Several companies spoke about security along  similar lines – that it was initially seen as a hassle,  but now is an integral part of development – and  feel ethics is reaching the same point.124 Further,  they can see that integration contributes to the  development of new capacities in AI.  Organizations that advise businesses developing  these capacities, such as Chatterbox Labs, indicate  that the level of maturity of an organization’s ethics  work is an important area of study.125 As companies  mature, hiring practices and other ways in which  ethics is institutionalized, take hold. As companies become more adept at working with  ethics, they make additional organizational changes  beyond the initial new role or ethics function. In  addition to centralized committees, companies  intentionally distribute ethics responsibilities  throughout the organization, creating a climate of  trust.126 One executive leading data and analytics  at a Silicon Valley company told us, “Being able to  think for yourself rather than follow the guidelines.  I think that helps people understand and apply  the principles, more than being told.” Microsoft’s  Champs effort is one example.127 And Paula  Goldman, at Salesforce, discussed the need to  develop programmes and even unique taxonomies  for designers, researchers and engineers across  the company.128 The idea that ethics needed to be cultivated from the top down and the bottom up  in organizations was also regularly expressed, as  well as the need to educate not only the broader  employee population but also senior leadership.  We heard a number of ethics professionals speak  with pride about how capably their senior team  could express ethical intent and action, something  these professionals had dedicated time and  resources to accomplish. The means for gathering input and engaging  stakeholders external to the company also become  more robust as companies mature. Microsoft’s  use of a community jury129 is one such example,  where product teams work collaboratively with a  group of individuals affected by the technology  being created. To hold these juries, Microsoft brings  together product teams, a neutral researcher to  moderate and a set of stakeholders representative  of the diversity of the community in which the  technology will be deployed. The diversity sought is  specific to the technology. For example, Microsoft  has a privacy index used to screen stakeholders, to  ensure it has a group participating with a range of  privacy sensitivities.130  The jury format allows for an exchange of expertise  and perspectives, representing the attributes of  ethical deliberation – involving those affected,  considering downstream effects, using consensus  where possible and sharing the reasoning behind  decisions when appropriate. Participants hear  expert testimony from the product teams, use the  proximity of direct contact with users and identify  areas of agreement in building common ground to  address challenging problems.131 Regardless of where companies fall on the ethical  maturity spectrum, our research confirms that  ethics has broken out of its legal silo as a ride-along  to compliance, and is now a robust part of human  resources, product development, and customer  and investor relations.3.8 Ethics by Design: An organizational approach to responsible use of technology  24
Silicon Valley companies have attracted  considerable unwanted attention in the area of  ethics in recent years.132 Some Silicon Valley  technology companies identified how difficult culture  change can be in entrepreneurial environments.  But this challenge is not unique to Silicon Valley –  those hurdles were also identified by long-standing  consumer products companies. This reality is encouraging companies to begin  carefully sharing more information about techniques  and processes to embed ethics, creating  communities of trust. After several decades  in which Silicon Valley, in particular, became  more tight-lipped, the kind of “co-opetition” –  collaboration while competing – that was a hallmark  of the region’s early days133 is resurfacing.  More straightforward guidance on how to  integrate ethics into companies must be  provided, however, if companies are to feel  confident that ethics is fuelling innovation and adding long-term value – and not the opposite.  One executive told us, “When people can be  creative, they welcome the opportunity to make  sure the technology is beneficial and innovative.  When in a role where processes are well-defined  and you have used those processes for many  years, you may be a bit more resistant to a  revision of those processes. If it’s not easy to  integrate, they will resist.” Her company blunts  this concern by using an internal microsite for AI  ethics so that anyone in the company can see  what is being done on AI ethics. As an executive  in another company assured us, “No engineer  (at our company) wants to be in a place where  they have missed the mark in terms of doing  well.” This is consistent with Epley’s discussion  of the power of behavioural design interventions  that cultivate, rather than crowd out, employees’  intrinsic prosocial motivations. It also supports  the emerging sense one gets listening to these  companies that ethics is a force for good.Summary 3.9 Ethics by Design: An organizational approach to responsible use of technology  25
Our conversations with World Economic Forum  partner organizations crystallized some existing  trends in managing cultures for ethics and  provided a richer understanding of the myriad  ways in which corporations are weaving ethics  into everyday workflows.  1. Invest in each of the dimensions of Epley’s  framework – attention, construal and motivation  – and consider how those investments work  together. Companies should activate a mix  of cultural elements to increase the likelihood  that they will get employees’ attention, help  them use ethics and provide incentives to do  so. Executives can activate aspects of culture  that range from structure provided by the  organizational chart, to what is said, what is  done and the beliefs that are shared within the  company supporting these choices.134 The  matter of which dimension to address first is  less important because most tools and tactics  will likely touch on aspects of each dimension. 2. Use assessments to gain an understanding  of how mature the motivation level in the  organization is presently. These should be used  as a benchmark to track the progression of  people acting in ways that are simplistic – to  get what they want or avoid getting in trouble,  as opposed to being more consistent with the  organization’s values and purpose. Ultimately,  employees should move from following rules to  having a level of comfort in creating them. 3. Implement some form of regular organizational  introspection. Companies are using mixes of  surveys, focus groups and assessments that  examine ethical cultures both broadly and with a  specific focus on the use of certain technologies.  4. Check for the conditions that encourage ethical  behaviour to take root: an organizational sense  of responsibility to society as an actor that both influences and is influenced by it; the  distribution of moral autonomy throughout the  company to create a climate of trust; and the  use of ethical deliberation practices.135 5. Use ethical deliberation practices wherever  possible by using data and information,  involving those affected by decisions,  considering the downstream effects and  publicly sharing motivations behind decisions.136  Engage a diverse set of stakeholders, both  internal to and external to the company.  6. Develop a rubric for ethical decision-making.  Whether this is a set of principles or guidelines  unique to a specific technology, such as AI, or  used more comprehensively when the company  makes decisions, its existence activates each  aspect of Epley’s recommended approach.  Make sure the rubric is consistent with the  organization’s mission and values. 7. Teach these practices to members of any  centralized ethical deliberation bodies, and train  them on the organization’s rubric as well.  8. Look for new opportunities to introduce ethics  and do not shy away from opportunities to use  challenging moments to do so. Organizations  are primed for ethics in such moments. 9. As the challenges pass, capture them in the  organization’s memory, and return to them to  reinforce the learning and create conditions  that promote innovation. This can foster more  routine ethical construal. 10. Institutionalize your commitment to ethics in hiring,  orientation, training and evaluation protocols.Recommendations4 Ethics by Design: An organizational approach to responsible use of technology  26
Conclusion We live in an era marked by the rapid penetration of Fourth Industrial Revolution technologies in ever  more aspects of business and society. This makes it imperative that the organizations developing these  technologies not only contemplate the ethical implications but also actively encourage routine ethical  behaviour as these technologies are designed, developed, distributed and deployed.  Contemporaneous with these technological and societal developments is a revolution in our understanding  of human psychology and the drivers of human behaviour ushered in by such psychologists and  behavioural economists as Daniel Kahneman, Amos Tversky and Richard Thaler. Thanks to this, it is now  possible for organizations to scientifically approach the challenge of promoting ethical behaviour, going  beyond traditional approaches that rely largely on ethics education.  Intuition and traditional “best practices” might suggest the need to root out ethical “bad apples”,  encourage good ethical intentions and provide intellectual tools for sophisticated ethical reasoning.  A more psychologically informed approach focuses less on individual “bad apples” and more on the  “barrel” – the environments that can lead ordinary people to engage in behaviour contrary to their own  ethical commitments. Effective programmes focus on the creation of ethical systems that prompt more  routine ethical deliberations and behaviour by adopting design elements that “go with the grain of human  psychology”. Specifically, the fundamental psychological processes of attention, construal and motivation  can be harnessed as design principles in the creation of ethical systems. Richard Thaler commented that a “mantra” is at the heart of his book Nudge: “If you want to get people to  do something, make it easy. Remove the obstacles.”137 This approach supports the formation of policies  that highlight what is meant by good behaviour and that provide people with opportunities to do good  things for other people, consistent with the idea of ethical contagion.138 Organizations seeking to promote  ethical behaviour should teach people to recognize and reason about ethical issues, and also make  systematic changes that make ethical behaviour easier. Ethics by Design: An organizational approach to responsible use of technology  27
Contributors Lead Contributors Nicholas Bullard  Senior Manager, Deloitte James Guszcza  Fellow, Center for Advanced Study in the Behavioral Sciences, Stanford University, on leave from Deloitte Daniel Lim  Artificial Intelligence and Machine Learning Fellow, World Economic Forum, seconded from Salesforce Emily Ratté  Artificial Intelligence and Machine Learning Project Coordinator, World Economic Forum Ann Gregg Skeet  Senior Director of Leadership Ethics, Markkula Center for Applied Ethics, Santa Clara University Inna Sverdlova  Managing Director, Deloitte Lorraine White  Manager, Deloitte   Ethics by Design: An organizational approach to responsible use of technology  28
Acknowledgements Nicola Aliperti  European DPO Coordinator, Coca-Cola Italia Dunstan Allison-Hope  Vice-President, BSR (Business for Social Responsibility) Stuart Battersby  Chief Technology Officer, Chatterbox Labs Danielle Cass  Activation Lead, Ethics and Society, Microsoft  Danny Coleman  Chief Executive Officer, Chatterbox Labs Barbara Cosgrove  Chief Privacy Officer, Workday Hannah Darnton  Associate Director of Ethics, Technology and Human Rights, BSR (Business for Social Responsibility)   Sarah Drinkwater  Director, Responsible Technology, Omidyar Network  Paula Goldman  Chief Ethical and Humane Use Officer, Salesforce Brian Green  Director, Technology Ethics, Markkula Center for Applied Ethics at Santa Clara University Patrick Hynes  Partner Engagement Lead, World Economic Forum Paige Johnson  Chief Executive Officer, EDCatalyst Group Meltem Kilicoglu  Head of Data and Analytics, Corporate Services, VMware  Ted Kwartler  Vice-President, Trusted AI, DataRobot  Mira Lane  Partner Director, Ethics and Society, Microsoft  Mingkuan Liu  Head of Data Science, Appen  Steven Mills  Partner & Chief AI Ethics Officer, Boston Consulting Group John Montgomery  Corporate Vice-President, Program Management, AI Platform, Microsoft  Kimberly Moorehead  Senior Manager, Deloitte Lisa Mueller  Principal Studio Manager, Business Applications Group, Microsoft  Ethics by Design: An organizational approach to responsible use of technology  29
Sarah Murphy  Legal Team, Suade Labs Tim O’Brien  General Manager, AI Programs, Microsoft Corporation Ben Olsen  Responsible Innovation Lead, Education & Activation, Facebook Kay Pang  Senior Director and Associate General Counsel, Global Markets Compliance Officer, VMware Diana Paredes  Chief Executive Officer and Co-founder, Suade Labs Betsy Popken  Special Counsel, Orrick Francesca Rossi  AI Ethics Global Leader, IBM  Steve Sweetman  Principal Program Manager, Ethics and Society, Microsoft  Moira Thompson Oliver  Head of Human and Digital Rights, BT Group Leila Toplic  Lead for Emerging Technologies Initiative, NetHope Giorgia Vulcano  EU Privacy Counsel for the EU DPO office, The Coca-Cola Company Ethics by Design: An organizational approach to responsible use of technology  30
Endnotes 1. Brustein, Joshua. “One on One: Jaron Lanier”, The New York Times, 23 May 2011, https://bits.blogs.nytimes. com/2011/05/23/one-on-one-jaron-lanier/ (link as of 26/11/20). 2. Friedman, Milton. “A Friedman Doctrine – The Social Responsibility of Business Is to Increase Its Profits“, The New York  Times, 13 September 1970, www.nytimes.com/1970/09/13/archives/a-friedman-doctrine-the-social-responsibility-ofbusiness-is-to.html (link as of 26/11/20). 3. Paulas, Rick. “Do Ethics Have a Place in Business Schools?” Pacific Standard, 6 June 2017, https://psmag.com/ economics/millennials-youre-our-only-hope (link as of 26/11/20). 4. Updated Statement Moves Away from Shareholder Primacy, Includes Commitment to All Stakeholders. Business  Roundtable. “Business Roundtable Redefines the Purpose of a Corporation to Promote ‘An Economy That Serves All  Americans’”, Business Roundtable, www.businessroundtable.org/business-roundtable-redefines-the-purpose-of-acorporation-to-promote-an-economy-that-serves-all-americans (link as of 26/11/20). 5. Sorkin, Andrew Ross. “A Free Market Manifesto that Changed the World, Reconsidered”, The New York Times, 11  September 2020, www.nytimes.com/2020/09/11/business/dealbook/milton-friedman-doctrine-social-responsibility-ofbusiness.html (link as of 26/11/20). 6. See, for example, Lanier, Jaron. Who Owns the Future? Penguin Books, 2014; Zuboff, Shoshana. The Age of  Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power, PublicAffairs, 2020; Aral, Sinan. The  Hype Machine: How Social Media Disrupts Our Elections, Our Economy and Our Health – and How We Must Adapt,  HarperCollinsPublishers, 2020; Orlowski, Jeff. The Social Dilemma, 2020. 7. Thümmler, Marc. “In the Realm of Paper Tigers – Exploring the Failings of AI Ethics Guidelines”, AlgorithmWatch, 29 April  2020, https://algorithmwatch.org/en/ai-ethics-guidelines-inventory-upgrade-2020/  (link as of 26/11/20). 8. For the first three bounds, see Thaler, Richard H. Misbehaving: The Making of Behavioural Economics, Penguin Books,  2016. For bounded ethicality, see Bazerman, Max H., and Ann E. Tenbrunsel. Blind Spots: Why We Fail to Do What’s  Right and What to Do About It, Princeton University Press, 2013. 9. Thaler, Richard H., Cass R. Sunstein and John P . Balz. “Choice Architecture”, SSRN Electronic Journal, 2014, http:// dx.doi.org/10.2139/ssrn.2536504 (link as of 26/11/20).  10. Note that we are not suggesting that it is unimportant for leaders to consider the effect of economic incentives in driving  unethical behaviour. Rather, we are exploring the idea that leaders contextualize the importance of material incentives  within a broader framework that also encompasses the behavioural design concepts. For further discussion, see  Lowenstein, George and Nick Chater, “Putting Nudges in Perspective”, Behavioural Public Policy, vol. 1, no. 1, 2017, pp.  26–53, doi:10.1017/bpp.2016.7 (link as of 26/11/20). 11. Malito, Alessandra. “Nobel Prize Winner Richard Thaler May Have Added $29.6 Billion to Retirement Accounts”,  MarketWatch, 6 January 2018, www.marketwatch.com/story/nobel-prize-winner-richard-thaler-may-have-added-296billion-to-retirement-accounts-2017-10-09 (link as of 26/11/20). 12. See, for example, Bohnet, Iris. What Works: Gender Equality by Design, The Belknap Press of Harvard University Press, 2018. 13. Harvard Kennedy School. “‘A Special Moment in Time’: Q&A with Harvard Kennedy School Gender and Leadership  Experts Iris Bohnet and Hannah Riley Bowles”, Harvard Kennedy School, 5 October, 2018, www.hks.harvard.edu/ research-insights/policy-topics/gender-race-identity/special-moment-time (link as of 26/11/20). 14. Haidt, Jonathan. “Business Ethics”, https://jonathanhaidt.com/business-ethics/ (link as of 26/11/20). 15. The Person and the Situation by Lee Ross and Richard Nisbett is a classic discussion of this theme. Stanley Milgram’s  obedience to authority experiments illustrate the error in the realm of ethical behaviour. Participants in the experiments  were instructed to administer what they believed to be severe, possibly lethal, electric shocks to “victims” who in fact did  not actually receive shocks and only acted out severe pain. Prior to the experiments, none of the participants predicted  that they would deliver the severest possible electric shock to another person. But in fact, 65% of the participants did  so. This highlights the mistaken nature of the common intuition that only abidingly unethical personalities are capable of  such misdeeds. Rather, such behaviour can be common when ordinary people are placed in contexts in which unethical  behaviour is the norm. The philosopher Hannah Arendt termed such phenomena “the banality of evil”. 16. For a brief summary, see Sezer, Ovul, Francesca Gino and Max H Bazerman, “Ethical Blind Spots: Explaining  Unintentional Unethical Behavior”, Current Opinion in Psychology, vol. 6, 2015, pp. 77–81, https://www.hbs.edu/faculty/ Publication%20Files/Ethical+Blind+Spots_4db0de5b-5177-457d-be51-7f0d5d9f3f12.pdf (link as of 26/11/20). 17.  Tetlock, Philip. “‘The Righteous Mind’: Why Liberals and Conservatives Can’t Get Along”, Knowledge@Wharton, 1 July  2013, https://knowledge.wharton.upenn.edu/article/the-righteous-mind-why-liberals-and-conservatives-cant-get-along/   (link as of 26/11/20).  18. Epley, Nicholas, and David Tannenbaum. “Treating Ethics as a Design Problem”, Behavioral Science & Policy, vol. 3, no.  2, 2017, pp. 72–84, https://behavioralpolicy.org/articles/treating-ethics-as-a-design-problem/ (link as of 26/11/20).  19. Martínez, Cecilia, Ann Gregg Skeet and Pedro M. Sasia. “Managing Organizational Ethics: How Ethics Becomes Pervasive  within Organizations”, Business Horizons, 2020, https://europepmc.org/article/med/33106706 (link as of 26/11/20).  Ethics by Design: An organizational approach to responsible use of technology  31
20. Epley, Nicholas, and David Tannenbaum. “Treating Ethics as a Design Problem”, Behavioral Science & Policy, vol. 3, no.  2, 2017, pp. 72–84, https://behavioralpolicy.org/articles/treating-ethics-as-a-design-problem/ (link as of 26/11/20). 21. Bloom, Paul. “What We Miss”, The New York Times, 4 June 2010, www.nytimes.com/2010/06/06/books/review/ Bloom-t.html (link as of 26/11/20). 22. Pew, “Behavioral Analytics Help Save Unemployment Insurance Funds”, The Pew Charitable Trusts, 26 October  2016, https://www.pewtrusts.org/en/research-and-analysis/issue-briefs/2016/10/behavioral-analytics-help-saveunemployment-insurance-funds (link as of 26/11/20). 23. Gawande, Atul. The Checklist Manifesto: How to Get Things Right. Profile Books, 2011. 24. Sander, Libby, and Oliver Bauman. “Zoom Fatigue Is Real – Here’s Why Video Calls Are So Draining”, Ideas.ted.com, 25  June 2020, https://ideas.ted.com/zoom-fatigue-is-real-heres-why-video-calls-are-so-draining/ (link as of 26/11/20). 25. Dell Case Study. “LRN Corporation”, https://pages.lrn.com/hubfs/2020%20Migration/lrn-case-study-dell.pdf?hsLang=en  (link as of 26/11/20). 26. Gerard, Joe, et al. “Best Practices in Ethics Training by Cisco Systems”, i-sight.com, https://i-sight.com/resources/bestpractices-cisco-ethics-training/ (link as of 26/11/20). 27. Koslow, Steve. “Allianz Life: Reaching Our Audience with an Ethics Blog”, Ethisphere Magazine, 30 Dec. 2019, https:// magazine.ethisphere.com/allianz_s2019/ (link as of 26/11/20). 28. NetHope, 15 July 2020, interview with World Economic Forum, virtual. 29. Vallor, Shannon. “An Ethical Toolkit for Engineering/Design Practice”, Markkula Center for Applied Ethics, Santa Clara  University, www.scu.edu/ethics-in-technology-practice/ethical-toolkit/ (link as of 26/11/20). 30. Ibid. 31. Council, Jared. “Investors Urge AI Startups to Inject Early Dose of Ethics”, The Wall Street Journal, Dow Jones &  Company, 16 June 2019, www.wsj.com/articles/investors-urge-ai-startups-to-inject-early-dose-of-ethics-11560682800   (link as of 26/11/20).  32. BT Plc, 7 August 2020, interview with World Economic Forum, virtual. 33. Paine, Lynn S. “Managing for Organizational Integrity”, Harvard Business Review, 1 August 2014, https://hbr. org/1994/03/managing-for-organizational-integrity (link as of 26/11/20).  34. World Economic Forum, “Measuring Stakeholder Capitalism: Towards Common Metrics and Consistent Reporting of  Sustainable Value Creation”, World Economic Forum, www.weforum.org/reports/measuring-stakeholder-capitalismtowards-common-metrics-and-consistent-reporting-of-sustainable-value-creation (link as of 26/11/20). 35. Eccles, Robert G., and Timothy Youmans. “Materiality in Corporate Governance: The Statement of Significant Audiences  and Materiality”, SSRN Electronic Journal, 2015, https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2654199 (link as  of 26/11/20).  36. Skeet, Ann. “Market Forces Make a Case for Ethics in Governance”, xCEO Ink, vol. 12, issue 1, 9 March 2016. 37. Raicu, Irina. “Apps and Privacy”, Markkula Center for Applied Ethics, www.scu.edu/ethics/focus-areas/internet-ethics/ resources/apps-and-privacy/ (link as of 26/11/20). 38. Torres, Cesar. “Path Addresses Privacy Controversy, but Social Apps Remain a Risk to Users”, Ars Technica, 12 February  2012, https://arstechnica.com/gadgets/2012/02/path-addresses-privacy-controversy-but-social-apps-remain-a-risk-tousers/ (link as of 26/11/20). 39. Nisbett, Richard, and Lee Ross, The Person and the Situation: Perspectives of Social Psychology, McGraw Hill, 1991. 40. Liberman, Varda, et al. “The Name of the Game: Predictive Power of Reputations versus Situational Labels in Determining  Prisoner’s Dilemma Game Moves”, Personality and Social Psychology Bulletin, vol. 30, no. 9, 2004, pp. 1175–1185.,  https://journals.sagepub.com/doi/10.1177/0146167204264004 (link as of 26/11/20). 41. Congdon, William J., and Maya Shankar. “The White House Social & Behavioral Sciences Team: Lessons Learned  from Year One”, Behavioral Science & Policy, vol. 1, no. 2, 2015, pp. 77–86, https://behavioralpolicy.org/wp-content/ uploads/2017/05/BSP_vol1is2_Congdon.pdf (link as of 26/11/20). 42. PRNewswire. “Acxiom Continues to Expand Global Data Offerings and Digital Capabilities”, MarTech Series, 12 June  2019, https://martechseries.com/technology/acxiom-continues-expand-global-data-offerings-digital-capabilities/ (link as  of 26/11/20). 43. Accenture. “Accenture Reimagines Its Code of Business Ethics Through Intelligent Technology”, Newsroom, Accenture,  21 September 1970, https://newsroom.accenture.com/news/accenture-reimagines-its-code-of-business-ethics-throughintelligent-technology.htm (link as of 26/11/20). 44. Thomas-Hunt, Melissa C. and Katherine W. Phillips. “When What You Know Is Not Enough: Expertise and Gender  Dynamics in Task Groups”, Personality and Social Psychology Bulletin, vol. 12, 30 December 2004, pp. 1585–1598,  https://pubmed.ncbi.nlm.nih.gov/15536241/ (link as of 26/11/20). 45. Phillips, Katherine W., and Denise Lewin Loyd. “When Surface and Deep-Level Diversity Collide: The Effects on  Dissenting Group Members”, Organizational Behavior and Human Decision Processes, vol. 99, issue 2, March 2006, pp.  143–160, https://www.sciencedirect.com/science/article/abs/pii/S0749597805001524 (link as of 26/11/20). Ethics by Design: An organizational approach to responsible use of technology  32
46.  Sommers, Samuel R. “On Racial Diversity and Group Decision-Making: Identifying Multiple Effects of Racial Composition  on Jury Deliberations”, Journal of Personality and Social Psychology, vol. 90, no. 4. 2006, https://www.apa.org/pubs/ journals/releases/psp-904597.pdf (link as of 26/11/20). 47. Phillips, Katherine W. “The Effects of Categorically Based Expectations on Minority Influence: The Importance of  Congruence”, Personality and Social Psychology Bulletin. vol. 29, no. 1, 2003, pp. 3–13, https://journals.sagepub.com/ doi/abs/10.1177/0146167202238367 (link as of 26/11/20).  48. Loyd, Denise Lewin, Cynthia S. Wang, Katherine W. Phillips and Robert B. Lount, Jr. “Social Category Diversity Promotes  Pre-meeting Elaboration: The Role of Relationship Focus”, Organization Science, vol. 24, no. 3., May–June 2013, pp.  757–772, https://www0.gsb.columbia.edu/mygsb/faculty/research/pubfiles/6392/phillips_social_category.pdf (link as of  26/11/20). 49. Lount, Jr., Robert B. and Phillips, Katherine W. “Working Harder with the Out-Group: The Impact of Social Category  Diversity on Motivation Gains”, Organizational Behavior and Human Decision Processes, vol. 103, issue 2, July 2007, pp.  214–224, https://ideas.repec.org/a/eee/jobhdp/v103y2007i2p214-224.html (link as of 26/11/20). 50. Phillips, Katherine W. “How Diversity Makes Us Smarter”, Scientific American, vol. 311, no. 4, 2014, pp. 43–47. 51. Phillips, Katherine W. “Understanding and Capturing the Value of Diversity”, YouTube, 9 July 2019, https://www.youtube. com/watch?v=g5B516TPrKE (link as of 26/11/20). 52. Jaeger, Jaclyn. “Building a Compliance Ambassador Network”, Compliance Week, 14 April 2015, www.complianceweek. com/building-a-compliance-ambassador-network/3345.article (link as of 26/11/20). 53. O’Brien, Tim, Steve Sweetman, Natasha Crampton and Venky Veeraraghavan. “A Model for Ethical Artificial Intelligence”,  World Economic Forum, www.weforum.org/agenda/2020/01/tech-companies-ethics-responsible-ai-microsoft/ (link as of  26/11/20). 54. Salesforce, “How Salesforce Is Building a Culture of Responsible Technology – and Why It Matters”, Salesforce News, 18  Sept. 2020, www.salesforce.com/news/stories/how-salesforce-is-building-a-culture-of-responsible-technology-and-whyit-matters/ (link as of 26/11/20). 55. Velasquez, Manuel, et al. “A Framework for Ethical Decision Making”, Markkula Center for Applied Ethics, Santa Clara  University, 1 August 2015, https://www.scu.edu/ethics/ethics-resources/ethical-decision-making/a-framework-forethical-decision-making/ (link as of 26/11/20). 56. Partnership on AI, “Framework for Promoting Workforce Well-Being in the AI-Integrated Workplace”, 27 August 2020,  https://www.partnershiponai.org/workforce-wellbeing/ (link as of 26/11/20). 57. United Nations. Guiding Principles on Business and Human Rights: Implementing the United Nations “Protect, Respect  and Remedy” Framework, 2011, https://www.ohchr.org/documents/publications/guidingprinciplesbusinesshr_en.pdf  (link  as of 26/11/20). 58. Workday, 23 October 2020, interview with World Economic Forum, virtual. 59. BSR staff. “Conducting an Effective Human Rights Impact Assessment: Reports”, https://www.bsr.org/en/our-insights/ report-view/conducting-an-effective-human-rights-impact-assessment (link as of 26/11/20). 60. Malafronte, Olivier. “Ethics & AI: How a Startup Builds Ethics into Its Development”, PocketConfidant AI, 1 February 2018,  https://pocketconfidant.com/ethics-ai-startup-builds-ethics-development/  (link as of 26/11/20). 61. Finkle, Lauren. “NVIDIA Blogs: How to Guide Employees in Creating Responsible Technology”, the official NVIDIA Blog,  30 April 2020, https://blogs.nvidia.com/blog/2020/03/25/salesforce-ethical-ai/ (link as of 26/11/20). 62. See Bazerman, Max H., and Ann E. Tenbrunsel. Blind Spots: Why We Fail to Do What’s Right and What to Do About It.  Princeton University Press, 2013. 63. Statt, Nick. “Google Now Says Controversial AI Voice Calling System Will Identify Itself to Humans”, The Verge, 10 May  2018, https://www.theverge.com/2018/5/10/17342414/google-duplex-ai-assistant-voice-calling-identify-itself-update  (link as of 26/11/20). 64. Leviathan, Yaniv, and Matias, Yossi. “Google Duplex: An AI System for Accomplishing Real-World Tasks Over the Phone”,  Google AI Blog, 8 May 2018, https://ai.googleblog.com/2018/05/duplex-ai-system-for-natural-conversation.html; Statt,  Nick. “Google Now Says Controversial AI Voice Calling System Will Identify Itself to Humans”, The Verge, 10 May 2018,  https://www.theverge.com/2018/5/10/17342414/google-duplex-ai-assistant-voice-calling-identify-itself-update; Hern,  Alex. “Google’s ‘Deceitful’ AI Assistant to Identify Itself as a Robot during Calls”, The Guardian, 11 May 2018, www. theguardian.com/technology/2018/may/11/google-duplex-ai-identify-itself-as-robot-during-calls (links as of 26/11/20).  65. Ariely, Dan, Predictably Irrational, HarperCollins, 2008. 66. For a discussion of crowding out, see Bowles, Samuel. The Moral Economy: Why Incentives Are No Substitute for Good  Citizens, Yale University Press, 2016. For a brief survey of workplace-focused literature involving intrinsic motivations,  see Guszcza, James, Josh Bersin and Jeff Schwartz. “HR for Humans: How Behavioral Economics Can Reinvent  HR”, Deloitte Review, January 2017. https://www2.deloitte.com/us/en/insights/deloitte-review/issue-18/behavioraleconomics-evidence-based-hr-management.html (link as of 26/11/20).  67. Anik, Lalin, et al. “Prosocial Bonuses Increase Employee Satisfaction and Team Performance”, PLoS ONE, vol. 8, no. 9,  2013, https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0075509 (link as of 26/11/20).  68. Byrnes, Nanette. “Behavioral Economics Taps Power of Persuasion for Tax Compliance”, Reuters, 29 October 2012,  www.reuters.com/article/us-usa-tax-behavior/behavioral-economics-taps-power-of-persuasion-for-tax-complianceidUSBRE89S0DD20121029 (link as of 26/11/20). Ethics by Design: An organizational approach to responsible use of technology  33
69. Skeet, Ann. “Defining Healthy Organizational Culture”, Markkula Center for Applied Ethics, Santa Clara University, 25  October 2019, https://www.scu.edu/ethics/culture-assessment-practice/defining-healthy-organizational-culture/ (link as  of 26/11/20). 70. Chatterbox Labs, 14 September 2020, interview with World Economic Forum, virtual. 71. Paine, Lynn S. “Managing for Organizational Integrity”, Harvard Business Review, 1 August 2014, https://hbr. org/1994/03/managing-for-organizational-integrity (link as of 26/11/20). 72. Martínez, Cecilia, Ann Gregg Skeet and Pedro M. Sasia. “Managing Organizational Ethics: How Ethics Becomes  Pervasive within Organizations”, Business Horizons, 2020, https://europepmc.org/article/med/33106706 (link as of  26/11/20).  73. Jaeger, Jaclyn. “Building a Compliance Ambassador Network”, Compliance Week, 14 April 2015, www.complianceweek. com/building-a-compliance-ambassador-network/3345.article (link as of 26/11/20). 74. NetHope, 15 July 2020, interview with World Economic Forum, virtual. 75. BT Plc, 7 August 2020, interview with World Economic Forum, virtual. 76. The Manifest. “How Can Companies Encourage Ethics in the Workplace?” Medium, 12 Dec. 2018, medium.com/@ the_manifest/how-can-companies-encourage-ethics-in-the-workplace-5c36318e98a4 (link as of 26/11/20). 77. Choy, Esther. “What Is Leadership Storytelling, Anyway?” Forbes, 24 January 2020, www.forbes.com/sites/ estherchoy/2020/01/26/what-is-leadership-storytelling/?sh=7139e66b7b17 (link as of 26/11/20). 78. Key Step Media. “Daniel Goleman: What I Learned About Storytelling for Effective Leadership from Howard Gardner”,  YouTube, 13 June 2013, https://www.youtube.com/watch?v=vi6jDajB3Bc&feature=youtu.be (link as of 26/11/20). 79. Skeet, Ann. “Defining Healthy Organizational Culture”, Markkula Center for Applied Ethics, Santa Clara University, 25  October 2019, www.scu.edu/ethics/culture-assessment-practice/defining-healthy-organizational-culture/ (link as of  26/11/20). 80. Caesar-Gordon, Andrew. “The Perfect Crisis Response?”, PR Week, 29 October 2015, www.prweek.com/ article/1357203/perfect-crisis-response (link as of 26/11/20). 81. IBM, 11 September 2020, interview with World Economic Forum, virtual. 82. Skeet, Ann. “The Practice of Ethical Leadership”, Markkula Center for Applied Ethics, Santa Clara University,  2016,  https://www.scu.edu/media/ethics-center/ethical-decision-making/MARK_0418_EthicalLeadershipInfographic-3.pdf  (link  as of 26/11/20). 83. Jaeger, Jaclyn. “Building a Compliance Ambassador Network”, Compliance Week, 14 April 2015, https://www. complianceweek.com/building-a-compliance-ambassador-network/3345.article (link as of 26/11/20). 84. Bastian, Ed. “Ed Bastian Memo: Delta and the School Safety Debate”, Delta News Hub, https://news.delta.com/edbastian-memo-delta-and-school-safety-debate (link as of 26/11/20). 85. Skeet, Ann. “Create an Ethical Decision Making Framework for Your Organization”, Markkula Center for Applied Ethics,  Santa Clara University, 1, Jun. 2017, www.scu.edu/ethics/leadership-ethics-blog/create-an-ethical-decision-makingframework-for-your-organization/ (link as of 26/11/20). 86. Kaku, Ryuzaburo. “The Path of Kyosei”, Harvard Business Review, July–August 1997, https://hbr.org/1997/07/the-pathof-kyosei (link as of 26/11/20). 87. The Coca-Cola Company, 20 August 2020, interview with World Economic Forum, virtual. 88. Jaeger, Jaclyn. “Q&A: Allstate’s Approach to Fostering an Ethical Culture”, Compliance Week, 28 February 2017, www. complianceweek.com/qanda-allstates-approach-to-fostering-an-ethical-culture/2755.article (link as of 26/11/20). 89. Logan, Blyth. “The Case of Danske Bank and Money Laundering”, Sevenpillarsinstitute.org, 12 November 2019, https:// sevenpillarsinstitute.org/the-case-of-danske-bank-and-money-laundering/  (link as of 26/11/20). 90. Business Roundtable. “Business Roundtable Redefines the Purpose of a Corporation to Promote ‘An Economy that  Serves All Americans’: Updated Statement Moves Away from Shareholder Primacy, Includes Commitment to All  Stakeholders”, www.businessroundtable.org/business-roundtable-redefines-the-purpose-of-a-corporation-to-promotean-economy-that-serves-all-americans (link as of 26/11/20). 91. Skeet, Ann. “Defining Healthy Organizational Culture”, Markkula Center for Applied Ethics, Santa Clara University, 25  October 2019, www.scu.edu/ethics/culture-assessment-practice/defining-healthy-organizational-culture/ (link as of  26/11/20). 92. Beers, Brian. “Who Are the Major Airplane Manufacturing Companies?” Investopedia, 2 September 2020, www. investopedia.com/ask/answers/050415/what-companies-are-major-players-airline-supply-business.asp. (link as of  26/11/20). 93. Kitroeff, Natalie, et al. “Boeing 737 Max Safety System Was Vetoed, Engineer Says”, The New York Times, 2 October  2019, www.nytimes.com/2019/10/02/business/boeing-737-max-crashes.html (link as of 26/11/20). 94. Hao, Karen. “The Two-Year Fight to Stop Amazon from Selling Face Recognition to the Police”, MIT Technology Review,  15 June 2020, www.technologyreview.com/2020/06/12/1003482/amazon-stopped-selling-police-face-recognition-fight/  (link as of 26/11/20). 95. Ibid. 96. Microsoft, 14 September 2020, interview with World Economic Forum, virtual. Ethics by Design: An organizational approach to responsible use of technology  34
97. DataRobot, 25 September 2020, interview with World Economic Forum, virtual. 98. Suade Labs, 22 July 2020, interview with World Economic Forum, virtual. 99. Workday, 23 October 2020, interview with World Economic Forum, virtual. 100. Vallor, Shannon. “An Ethical Toolkit for Engineering/Design Practice”, Markkula Center for Applied Ethics, Santa Clara  University, www.scu.edu/ethics-in-technology-practice/ethical-toolkit/ (link as of 26/11/20). 101. “Harms Modeling – Azure Application Architecture Guide”, Microsoft docs, https://docs.microsoft.com/en-us/azure/ architecture/guide/responsible-innovation/harms-modeling/ (link as of 26/11/20). 102. Microsoft Accessibility – Trust Center, www.microsoft.com/en-us/trust-center/compliance/accessibility (link as of  26/11/20).  103. Skeet, Ann, and Markkula Center Staff. “Culture Self-Assessment Practice”, Culture Self-Assessment Practice - Markkula  Center for Applied Ethics, Santa Clara University, www.scu.edu/ethics/culture-assessment-practice/ (link as of 26/11/20). 104. DataRobot, 25 September 2020, interview with World Economic Forum, virtual. 105. Microsoft, 14 September 2020, interview with World Economic Forum, virtual. 106. Kahneman, Daniel. Thinking, Fast and Slow. Farrar, Straus and Giroux. 2011. 107. Eccles, Robert G., and Timothy Youmans. “Materiality in Corporate Governance: The Statement of Significant Audiences  and Materiality”, SSRN Electronic Journal, 2015, https://www.researchgate.net/publication/315490678_Materiality_in_ Corporate_Governance_The_Statement_of_Significant_Audiences_and_Materiality; World Economic Forum, “Measuring  Stakeholder Capitalism: Towards Common Metrics and Consistent Reporting of Sustainable Value Creation”, World  Economic Forum, www.weforum.org/reports/measuring-stakeholder-capitalism-towards-common-metrics-andconsistent-reporting-of-sustainable-value-creation (links as of 26/11/20). 108. xCEO Ink, vol. 12, no. 1, 9 March 2016, https://www.scu.edu/ethics/leadership-ethics-blog/market-forces-make-a-casefor-ethics/ (link as of 7/12/20). 109. Magid, Larry. “IBM, Microsoft and Amazon Not Letting Police Use Their Facial Recognition Technology” Forbes, 13 June  2020, www.forbes.com/sites/larrymagid/2020/06/12/ibm-microsoft-and-amazon-not-letting-police-use-their-facialrecognition-technology/#31768caf1887 (link as of 26/11/20). 110. Microsoft Corporation, 14 September 2020, interview with World Economic Forum, virtual. 111. Ibaria, Herminia, and Aneeta Rattan. “Microsoft: Instilling a Growth Mindset” Herminia Ibarra.com, 9 July 2019, https:// herminiaibarra.com/microsoft-instilling-a-growth-mindset/ (link as of 26/11/20). 112. Dweck, C. S. Mindset: The New Psychology of Success, Random House, 2006. 113. Friedman, Batya, et al. “A Survey of Value Sensitive Design Methods”, 2017, https://www.nowpublishers.com/article/ Details/HCI-015; “Harms Modeling – Azure Application Architecture Guide”, Microsoft docs, https://docs.microsoft.com/ en-us/azure/architecture/guide/responsible-innovation/harms-modeling/ (links as of 26/11/20). 114. IBM, “IBM’S Principles for Data Trust and Transparency”, THINKPolicy Blog, 11 December 2019, www.ibm.com/blogs/ policy/trust-principles/ (link as of 26/11/20). 115. IBM, 11 September 2020, interview with World Economic Forum, virtual. 116. Nedzhvetskaya, Nataliya, and J. S. Tan. “What We Learned from Over a Decade of Tech Activism”, The Guardian, 23  December 2019, www.theguardian.com/commentisfree/2019/dec/22/tech-worker-activism-2019-what-we-learned (link  as of 26/11/20). 117. IBM, 11 September 2020, interview with World Economic Forum, virtual. 118. World Economic Forum, “Measuring Stakeholder Capitalism: Towards Common Metrics and Consistent Reporting of  Sustainable Value Creation”, World Economic Forum, www.weforum.org/reports/measuring-stakeholder-capitalismtowards-common-metrics-and-consistent-reporting-of-sustainable-value-creation (link as of 26/11/20). 119. Deloitte, “Ethics and the Future of Work – Podcast”, Deloitte United States, 2 September 2020, https://www2.deloitte. com/us/en/pages/human-capital/articles/ethics-and-the-future-of-work.html (link as of 26/11/20). 120. Ibid; Deloitte US. “‎Capital H: Putting Humans at the Center of Work: Ethics and the Future of Work: From ‘Could We’  to ‘How Should We’ on Apple Podcasts”, Apple Podcasts, 21 August 2020, https://podcasts.apple.com/dk/podcast/ capital-h-putting-humans-at-the-center-of-work/id1441969641 (link as of 26/11/20). 121. Martínez, Cecilia, Ann Gregg Skeet and Pedro M. Sasia. “Managing Organizational Ethics: How Ethics Becomes  Pervasive within Organizations”, Business Horizons, 2020, https://europepmc.org/article/med/33106706 (link as of  26/11/20).  122. Chatterbox Labs, 14 September 2020, interview with World Economic Forum, virtual. 123. Skeet, Ann, and James Guszcza. “How Businesses Can Create an Ethical Culture in the Age of Tech”, World Economic  Forum, 7 January 2020, www.weforum.org/agenda/2020/01/how-businesses-can-create-an-ethical-culture-in-the-ageof-tech/; Martínez, Cecilia, Ann Gregg Skeet and Pedro M. Sasia. “Managing Organizational Ethics: How Ethics Becomes  Pervasive within Organizations”, Business Horizons, 2020, https://europepmc.org/article/med/33106706 (links as of  26/11/20).  124. Martínez, Cecilia, Ann Gregg Skeet and Pedro M. Sasia. “Managing Organizational Ethics: How Ethics Becomes  Pervasive within Organizations”, Business Horizons, 2020, https://europepmc.org/article/med/33106706 (link as of  26/11/20).  Ethics by Design: An organizational approach to responsible use of technology  35
125. Deloitte, “Ethics and the Future of Work – Podcast”, Deloitte United States, 2 September 2020, https://www2.deloitte. com/us/en/pages/human-capital/articles/ethics-and-the-future-of-work.html (link as of 26/11/20).  126. Chatterbox Labs, 14 September 2020, interview with World Economic Forum, virtual. 127. Martínez, Cecilia, Ann Gregg Skeet and Pedro M. Sasia. “Managing Organizational Ethics: How Ethics Becomes  Pervasive within Organizations”, Business Horizons, 2020, https://europepmc.org/article/med/33106706 (link as of  26/11/20).  128. O’Brien, Tim, Steve Sweetman, Natasha Crampton and Venky Veeraraghavan. “A Model for Ethical Artificial Intelligence”,  World Economic Forum, www.weforum.org/agenda/2020/01/tech-companies-ethics-responsible-ai-microsoft/ (link as of  26/11/20). 129. Deloitte, “Ethics and the Future of Work – Podcast”, Deloitte United States, 2 September 2020, https://www2.deloitte. com/us/en/pages/human-capital/articles/ethics-and-the-future-of-work.html (link as of 26/11/20).  130. Azure Application Architecture Guide. “Community Jury – Azure Application Architecture Guide”, Microsoft docs, https:// docs.microsoft.com/en-us/azure/architecture/guide/responsible-innovation/community-jury/ (link as of 26/11/20). 131. Ibid. 132. Ibid. 133. Tam, Pui-wing. “How Silicon Valley Came to Be a Land of ‘Bros’”, The New York Times, 5 February 2018, www.nytimes. com/2018/02/05/technology/silicon-valley-brotopia-emily-chang.html (link as of 26/11/20). 134. Encyclopedia Britannica. “Apple Inc”, Encyclopædia Britannica, www.britannica.com/technology/computer/Apple-Inc  (link as of 26/11/20). 135. Martínez, Cecilia, Ann Gregg Skeet and Pedro M. Sasia. “Managing Organizational Ethics: How Ethics Becomes  Pervasive within Organizations”, Business Horizons, 2020, https://europepmc.org/article/med/33106706 (link as of  26/11/20).  136. Ibid. 137. List, Christian, and Philip Pettit. Group Agency: The Possibility, Design, and Status of Corporate Agents, Oxford  University Press, 2013; Stansbury, J. “Reasoned Moral Agreement: Applying Discourse Ethics within Organizations”,  Business Ethics Quarterly, vol. 19, no. 1, pp. 33–36, doi: 10.5840/beq20091912 (link as of 26/11/20). 138. University of Chicago. “Richard Thaler Wins Nobel Prize for ‘His Contributions to Behavioral Economics’”, 9 October  2017, Uchicago News, https://news.uchicago.edu/story/richard-thaler-wins-nobel-prize-his-contributions-behaviouraleconomics (link as of 26/11/20). 139. Applebaum, Steven H., Giulio David Iaconi and Albert Matousek. “Positive and Negative Deviant Workplace Behaviors:  Causes, Impacts, and Solutions”, Corporate Governance, vol. 7, no. 5, 2007, pp. 586–598, https://citeseerx.ist.psu.edu/ viewdoc/download?doi=10.1.1.538.8130&rep=rep1&type=pdf (link as of 26/11/20). Ethics by Design: An organizational approach to responsible use of technology  36
World Economic Forum 91–93 route de la Capite CH-1223 Cologny/Geneva Switzerland   Tel.:  +41 (0) 22 869 1212 Fax: +41 (0) 22 786 2744 contact@weforum.org www.weforum.orgThe World Economic Forum,  committed to improving   the state of the world, is the  International Organization for  Public-Private Cooperation.   The Forum engages the  foremost political, business   and other leaders of society   to shape global, regional  and industry agendas.
