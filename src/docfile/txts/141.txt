ARTIFICIAL INTELLIGENCEAND EDUC ATIONA cr itical view through the lens of human r ights, democracy and the r ule of law
Wayne Holmes,  Jen P ersson,  I rene-Angelica Chounta,  Bar bara Wasson and  Vania DimitrovaARTIFICIAL INTELLIGENCE AND  EDUCATIONA critic al view through the lens of human righ ts, democracy and the r ule of law   C ouncil of Europe
The opinions expressed in this work are the r esponsibility of the author(s) and do not nec essarily reflect the official p olicy of the Council of Europe.T he reproduction of extracts (up to 500 w ords) is authorised, except for c ommercial purposes, as long as the in tegrity of the text is preserved, the e xcerpt is not used out of context, does not pr ovide incomplete information or does not other wise mislead the reader as t o the nature, scope or content of the t ext. The source text must always be ack nowledged as follows: “© Council of E urope, year of the publication” . All other r equests concerning the reproduction/tr anslation of all or part of the document should be addr essed to the Directorate of C ommunications, Council of Europe (F-67075 S trasbourg Cedex or publishing@c oe.int).A ll other correspondence concerning this documen t should be addressed to the E ducation Department Council of Europe A gora Building 1, Quai Jacoutot 67075 S trasbourg Cedex France  educa tion@coe.int C over design: Documents and Publications P roduction Department (SPDP),  C ouncil of EuropeLa yout: Jouve, ParisC over photo: Shutterstock C ouncil of Europe Publishing  F-67075 S trasbourg Cedex  h ttp://book.coe.intISBN 978-92-871- 9236-3   © C ouncil of Europe, November 2022  P rinted at the Council of EuropeThis report was prepared within the scope of  the Council of Europe’s intergovernmental pr oject on Artificial Intelligence and E ducation.A cknowledgements  T he authors would like to thank the C ouncil of Europe Education D epartment for their support and guidanc e throughout the drafting of this r eport, more specificallyf Villano Qiriazi, Head of the Education D epartmentf Mich ael Remmert, Head of the Education P olicy Divisionf Ahmet-Murat Kiliç, Programme managerf Gülden Serbest, Project assistantf Benedita Santos Silva, TraineeT he authors would also like to thank Nezir A kyeşİlmen, Brian O’Neill, Pascale Raulin-S errier and Janice Richardson (members of the C ouncil of Europe Digital Citizenship E ducation Expert Group), Yannick M eneceur, Head of the Central Division, DG I – C ouncil of Europe for their insightful c omments on earlier drafts of the report, and Judy K ay, Vincent Aleven and Ben du B oulay, for kindly identifying key reviews of AIED r esearch (Appendix IV).
 Page 3ContentsDEFINITIONS 5 EXECUTIVE  SUMMARY9 INTR ODUCTION11 P ART I – THE CONNECTIONS BETWEEN AI AND EDUCATION15 1.1. D efining AI16 1.2.  The connections between AI and education18 1.3. L earning with AI19 1.4. U sing AI to learn about learning24 1.5. L earning about AI (AI literacy)26 P ART II – SOME CHALLENGES FOR AI AND EDUCATION33 2.1. AI and lear ners34 2.2.  The ethics of AI and education40 2.3. AI and the educa tional ecosystem43 P ART III – AI, EDUCATION, HUMAN RIGHTS, DEMOCRACY AND THE RULE OF LAW47 3.1. AI, educa tion and human rights48 3.2. AI, educa tion and democracy59 3.3. AI, educa tion and the rule of law63 P ART IV – CONCLUSION AND A NEEDS ANALYSIS73 4.1. C onclusion74 4.2. A needs analy sis74 REFERENCES 77 APPENDIX  I – DEFINITIONS OF AI95 APPENDIX  II – RECENT RELATED COUNCIL OF EUROPE REPORTS97 APPENDIX  III – RECENT RELATED REPORTS FROM OTHER INSTITUTIONS99 APPENDIX  IV – REVIEWS OF AIED RESEARCH101 APPENDIX  V – SOME EXAMPLES OF STUDENT-SUPPORTING AIED TOOLS105 ABOUT  THE AUTHORS107 

 Page 5DefinitionsA daptive tutoring systems, intelligent tutoring systems (ITS), intelligent i nteractive learning environments or personalised learning systems i nteractive learning environments or personalised learning systems (NB (NB s ome of these terms are contested): AI-driven tools that might provide s ome of these terms are contested): AI-driven tools that might provide s tep-by-step tutorials, practice exercises, scaffolding mechanisms (e.g. recommen-s tep-by-step tutorials, practice exercises, scaffolding mechanisms (e.g. recommen-d ations, feedback, suggestions and prompts) and assessments, individualised for d ations, feedback, suggestions and prompts) and assessments, individualised for e ach learner, usually through topics in well-defined structured subjects such as e ach learner, usually through topics in well-defined structured subjects such as m athematics or physics.m athematics or physics.A I literacy: Having competencies in both the human and technological dimensions A I literacy: Having competencies in both the human and technological dimensions o f artificial intelligence, at a level appropriate for the individual (i.e. according to o f artificial intelligence, at a level appropriate for the individual (i.e. according to t heir age and interests).t heir age and interests).A I systems: Shorthand term encompassing AI-driven tools, applications, software, A I systems: Shorthand term encompassing AI-driven tools, applications, software, n etworks, etc.n etworks, etc.A rtificial intelligence (AI): Artificial intelligence is notoriously challenging to define A rtificial intelligence (AI): Artificial intelligence is notoriously challenging to define a nd understand. Accordingly, we offer two complementary definitions:a nd understand. Accordingly, we offer two complementary definitions:A  set of sciences, theories and techniques whose purpose is to reproduce by a machine A  set of sciences, theories and techniques whose purpose is to reproduce by a machine t he cognitive abilities of a human being. Current developments aim, for instance, to t he cognitive abilities of a human being. Current developments aim, for instance, to b e able to entrust a machine with complex tasks previously delegated to a human. b e able to entrust a machine with complex tasks previously delegated to a human. ( Council of Europe 2021)( Council of Europe 2021)1M achine-based systems that can, given a set of human-defined objectives, make p redictions, recommendations or decisions that influence real or virtual environments. p redictions, recommendations or decisions that influence real or virtual environments. A I systems interact with us and act on our environment, either directly or indirectly. A I systems interact with us and act on our environment, either directly or indirectly. O ften, they appear to operate autonomously, and can adapt their behaviour by learning O ften, they appear to operate autonomously, and can adapt their behaviour by learning a bout the context. (UNICEF 2021: 16)a bout the context. (UNICEF 2021: 16)2T o further illustrate the range of definitions of artificial intelligence, some alternatives a re given in Appendix I.a re given in Appendix I.A rtificial intelligence and education (AI&ED): The various connections between AI A rtificial intelligence and education (AI&ED): The various connections between AI a nd education that include what might be called “learning with AI”, “learning about a nd education that include what might be called “learning with AI”, “learning about A I” and “preparing for AI”. Learning with AI has also been called “artificial intelligence A I” and “preparing for AI”. Learning with AI has also been called “artificial intelligence f or education”.f or education”.3A rtificial intelligence in education (AIED): An academic field of enquiry, established in t he 1980s, that primarily researches AI tools to support learning (i.e. learning with AI).t he 1980s, that primarily researches AI tools to support learning (i.e. learning with AI).A utomatic writing evaluation: AI-driven tools that use natural language and seman-A utomatic writing evaluation: AI-driven tools that use natural language and seman-t ic processing to provide automated feedback on writing submitted to the system.t ic processing to provide automated feedback on writing submitted to the system.1 .w ww.coe.int/en/web/artificial-intelligence/glossary. 2 .2.w ww.unicef.org/globalinsight/reports/policy-guidance-ai-children. 3 .3.R ecommendation CM/Rec(2019)10 of the Committee of Ministers to member States on devel-R ecommendation CM/Rec(2019)10 of the Committee of Ministers to member States on devel-o ping and promoting digital citizenship education.o ping and promoting digital citizenship education.
Page 6  Artificial intelligence and educationBig data: Large heterogeneous and volatile data sets, generated rapidly from dif-f erent sources, that are cross-referenced, combined and mined to find patterns and f erent sources, that are cross-referenced, combined and mined to find patterns and c orrelations, and to make novel inferences.c orrelations, and to make novel inferences.4 The analysis of big data is too complex f or humans to undertake without machine algorithms.f or humans to undertake without machine algorithms.C hatbots: Systems designed to respond automatically to messages through the C hatbots: Systems designed to respond automatically to messages through the i nterpretation of natural language. Typically, these are used to provide support in i nterpretation of natural language. Typically, these are used to provide support in r esponse to queries (e.g. “Where is my next class?”, “Where can I find information r esponse to queries (e.g. “Where is my next class?”, “Where can I find information a bout my assessment?”).a bout my assessment?”).D ialogue-based tutoring systems: AI-driven tools that engage learners in a con-D ialogue-based tutoring systems: AI-driven tools that engage learners in a con-v ersation, typed or spoken, about the topic to be learned.v ersation, typed or spoken, about the topic to be learned.e -proctoring: The use of AI-driven systems to monitor learners taking examinations e -proctoring: The use of AI-driven systems to monitor learners taking examinations w ith the purpose of detecting fraud and cheating.w ith the purpose of detecting fraud and cheating.E ducational data mining: See Learning analytics.E ducational data mining: See Learning analytics.E ducators: Shorthand term encompassing teachers and other professionals in formal E ducators: Shorthand term encompassing teachers and other professionals in formal e ducation and early childhood care, including school psychologists, pedagogues, e ducation and early childhood care, including school psychologists, pedagogues, l ibrarians, teaching assistants and tutors.l ibrarians, teaching assistants and tutors.E mbodied AI and Robotics: Movable machines that perform tasks either automat-E mbodied AI and Robotics: Movable machines that perform tasks either automat-i cally or with a degree of autonomy.i cally or with a degree of autonomy.E xploratory learning environments: AI-supported tools in which learners are encour-E xploratory learning environments: AI-supported tools in which learners are encour-a ged to actively construct their own knowledge by exploring and manipulating a ged to actively construct their own knowledge by exploring and manipulating e lements of the learning environment. Typically, these systems use AI to provide e lements of the learning environment. Typically, these systems use AI to provide f eedback to support what otherwise can be a challenging approach to learning.f eedback to support what otherwise can be a challenging approach to learning.G OFAI: “Good old-fashioned artificial intelligence”, a type of AI more properly known G OFAI: “Good old-fashioned artificial intelligence”, a type of AI more properly known a s “symbolic AI” and sometimes “rule-based AI’, which was the dominant paradigm a s “symbolic AI” and sometimes “rule-based AI’, which was the dominant paradigm b efore machine learning (ML) came to prominence.b efore machine learning (ML) came to prominence.I ntelligent interactive learning environments: See Adaptive tutoring systems.I ntelligent interactive learning environments: See Adaptive tutoring systems.I ntelligent tutoring systems (ITS): See Adaptive tutoring systems.I ntelligent tutoring systems (ITS): See Adaptive tutoring systems.K 12K12: Children in primary and secondary education (i.e. from kindergarten to kinder-:  Children in primary and secondary education (i.e. from kindergarten to kinder-g arten to the end of secondary schooling.g arten to the end of secondary schooling.L earners: Shorthand term to encompass children and young people in formal edu-L earners: Shorthand term to encompass children and young people in formal edu-c ation (i.e. pupils and students) and people of all ages engaged in formal, informal c ation (i.e. pupils and students) and people of all ages engaged in formal, informal o r non-formal education (in accordance with the principle of lifelong learning).o r non-formal education (in accordance with the principle of lifelong learning).L earning analytics and Educational data mining: Gathering, analysing and visual-L earning analytics and Educational data mining: Gathering, analysing and visual-i sing big data, especially as generated by digital devices, about learners and learning i sing big data, especially as generated by digital devices, about learners and learning p rocesses, with the aim of supporting or enhancing teaching and learning.p rocesses, with the aim of supporting or enhancing teaching and learning.L earning network orchestrators: AI-driven tools that enable and support networks L earning network orchestrators: AI-driven tools that enable and support networks o f people (e.g. learners and their peers, or learners and teachers, or learners and o f people (e.g. learners and their peers, or learners and teachers, or learners and p eople from industry) engaged in learning.p eople from industry) engaged in learning.4 .w ww.coe.int/en/web/artificial-intelligence/glossary. 
Definitions  P age 7Machine learning (ML): A type of AI, the type that is currently dominant, which uses a lgorithms and statistical models to analyse big data, identify data patterns, draw a lgorithms and statistical models to analyse big data, identify data patterns, draw i nferences and adapt, without specific step-by-step instructions.i nferences and adapt, without specific step-by-step instructions.N atural language processing (NLP) or Speech to text and Natural language gen-N atural language processing (NLP) or Speech to text and Natural language gen-e ration: Systems that use AI to transcribe, interpret, translate and create text and e ration: Systems that use AI to transcribe, interpret, translate and create text and s poken language.s poken language.P ersonalised learning systems: See Adaptive tutoring systemsP ersonalised learning systems: See Adaptive tutoring systemsP lagiarism checking: AI-driven content scanning tool that helps identify the level P lagiarism checking: AI-driven content scanning tool that helps identify the level o f plagiarism in documents such as assignments, reports and articles by comparing o f plagiarism in documents such as assignments, reports and articles by comparing a  submitted text with existing texts.a  submitted text with existing texts.P rofiling: The automated processing of personal data to analyse or predict aspects of P rofiling: The automated processing of personal data to analyse or predict aspects of a  person’s performance, economic situation, health, personal preferences, interests, a  person’s performance, economic situation, health, personal preferences, interests, r eliability, behaviour, location or movements.r eliability, behaviour, location or movements.R obotics: See Embodied AI.R obotics: See Embodied AI.S mart curation of learning materials: The use of AI techniques to automatically S mart curation of learning materials: The use of AI techniques to automatically i dentify learning materials (such as open educational resources) and sections of i dentify learning materials (such as open educational resources) and sections of t hose materials that might be useful for a teacher or learner.t hose materials that might be useful for a teacher or learner.S peech to text: See Natural language processing.S peech to text: See Natural language processing.

 Page 9Executive summaryA s noted by the Council of Europe’s Committee of Ministers in 2019, artificial in telligence (AI) is increasingly having an impact on education, bringing oppor tunities as well as numerous threats. It was these observations that led t o the commissioning of this report, which sets out to examine the connections bet ween AI and education.I n fact, AI in education (AIED) has already been the subject of numerous international r eports (see Appendix III) – so what differentiates this one? There are three unique char acteristics. First, in this report, we explore both the application and the teaching of  AI in education, which we refer to collectively as “AI and education” (AI&ED). Second, w e approach AI&ED through the lens of the Council of Europe’s core values: human r ights, democracy and the rule of law. And third, rather than assuming the benefits of AI  for education, we take a deliberately critical approach to AI&ED, considering both the  opportunities and the challenges. Throughout, the aim is to provide a holistic view  to help ensure that AI empowers and not overpowers educators and learners, and tha t future developments and practices are genuinely for the common good.T he report begins with an introduction to AI (what it is and how it works) and to the  connections between AI and education: “learning with AI” (learner-supporting, t eacher-supporting and system-supporting AI), using AI to “learn about learning” (sometimes  known as learning analytics) and “learning about AI” (repositioned as  the human and technological dimensions of AI literacy). In Part II, we examine some  key challenges for AI&ED. These include the choice of pedagogy adopted by t ypical AIED applications, the impact of AIED applications on the developing brain and  learner agency, the use of emotion detection and other techniques that might c onstitute surveillance, digital safeguarding, the ethics of AI&ED, the political and ec onomic drivers of the uptake of AI in educational contexts and AIED colonialism.W e continue, in Part III, by exploring AI&ED through the lens of the Council of Europe’s c ore values – human rights, democracy and the rule of law – noting that currently ther e is little substantive relevant literature. Accordingly, we start with the Turing I nstitute’s report, commissioned by the Council of Europe, “Artificial intelligence, human  rights, democracy, and the rule of law: a primer” (Leslie et al. 2021), identifying and cr oss-checking the pertinent issues for education.W ith regard to human rights, we examine the impact of AI&ED on a child’s rights t o education, to human dignity, to autonomy, to be heard, to not suffer from dis-cr imination, to privacy and data protection, to transparency and explainability, to be  protected from economic exploitation and to withhold or withdraw consent f or their involvement with any technology. With regard to democracy, we consider ho w AI&ED might both support and undermine democratic values, how democratic educa tion, which depends on open access and equity, may be compromised by the dominanc e of commercial AIED applications, how certain tools promote individual-ism  at the expense of the collaborative and social aspects of teaching and learning 
Page 10  A rtificial intelligence and educationand the impact of AI models representing the world as a function of the past. With r egard to the rule of law, we identify and examine several cases in which the use of AI algor ithms in education have been subject to legal challenge – the use of historical school-lev el data to grade individual learners, learning data traces and biometric da ta. We then ask three key questions: Can children be required to use any particular AI  system? Can AI ever meet the test of necessity and proportionality and be lawful a t all? Must schools respect parents’ or children’s wishes or can they make the use of c ertain AI systems compulsory?W e end the report, in Part IV, with a conclusion and provisional needs analysis of open  challenges, opportunities and implications of AI&ED, designed to stimulate and  inform further critical discussion. Anticipated needs include: the need to iden-tify  and act upon linkages across the Council of Europe’s work; the need for more evidenc e of the impact of AI on education, learners and teachers; the need to avoid per petuating poor pedagogic practices; the need for robust regulation, addressing human  rights, before AI tools are used in education; the need for parents to be able t o exercise their democratic rights; the need for curricula that address both the human  and technological dimensions of AI literacy; the need for ethics by design in  the development and deployment of AI tools in educational contexts; the need t o ensure that data rights and intellectual property rights remain explicitly with the lear ners; and the need for the application and teaching of AI in education to prioritise and facilita te human rights, democracy and the rule of law.
 Page 11IntroductionI n 2019, the Council of Europe’s Committee of Ministers  adopted a recommen-da tion on digital citizenship education in which a key focus was the application of ar tificial intelligence (AI) in educational contexts:AI,  like any other tool, offers many opportunities but also carries with it many threats, which  make it necessary to take human rights principles into account in the early desig n of its application. Educators must be aware of the strengths and weaknesses of  AI in learning, so as to be empowered – not overpowered – by technology in their dig ital citizenship education practices. AI, via machine learning and deep learning, can enr ich education … By the same token, developments in the AI field can deeply impact in teractions between educators and learners and among citizens at large, which may under mine the very core of education, that is, the fostering of free will and independent and  critical thinking via learning opportunities … Although it seems premature to make  wider use of AI in learning environments, professionals in education and school staff  should be made aware of AI and the ethical challenges it poses in the context of schools . (Council of Europe 2019)5T his report builds on these prescient observations and concerns to explore in detail the  connections between AI and education through the lens of the Council of E urope’s mandate to protect human rights, to support democracy and to promote the  rule of law.6 Accordingly, this is not a review of the more than 40 years of aca-demic  research into the application of AI in education (see Appendix IV for reviews of  academic research of AI in education). Instead, it is a critical analysis of what is happening  now, with AI tools developed by multi-million-dollar-funded commercial pla yers increasingly being implemented in classrooms, in parallel with a growing demand  from policy makers for AI curricula designed for school students. Globally, AI in  education is often welcomed with enthusiasm – with many international reports and  recommendations painting unquestioned glowing pictures (see Appendices II  and III for lists of related reports). Here, to help rebalance the discussion, we take a  more realistic perspective, specifically focusing on the many complex challenges r aised by the connections between AI and education (AI&ED), to provide a holistic view  in order to ensure that future developments and practices are genuinely for the c ommon good.T he work was carried out in the context of the Digital Citizenship Education Project (DCE),  which aims to empower children through education and active participation in  the increasingly digital society.7 AI is fast becoming a cross-cutting issue that dr aws on, and relates to, other work undertaken by the Council of Europe’s Education 5. R ecommendation CM/Rec(2019)10 of the Committee of Ministers to member States on develop-ing  and promoting digital citizenship education, h ttps://search.coe.int/cm/Pages/result_details.asp x?ObjectID=090000168098de08. 6. T he Council of Europe, Values, w ww.coe.int/en/web/about-us/values. 7. C ouncil of Europe, “Digital Citizenship and education” , w ww.coe.int/en/web/digital-citizenship- educa tion. 
Page 12  A rtificial intelligence and educationDepartment, especially with respect to literacy and life skills. In addition, AI cuts across the  Council of Europe’s directorates’ focus on data protection, children’s rights and c ompetences for democratic culture.8T he Council of Europe’s Ad hoc Committee on Artificial Intelligence (CAHAI)9 was tasked  with examining the feasibility and potential elements on the basis of broad multi-stakeholder  consultations, of a legal framework for the development, design and  application of artificial intelligence, based on the Council of Europe’s standards on  human rights, democracy and the rule of law. To this end, CAHAI focused its work on  mapping relevant international and national legal frameworks and ethical guide-lines , while analysing the risks and opportunities arising from AI. However, although other wise comprehensive, the current work by CAHAI has not included education as  one of its AI domains. CAHAI has now been superseded by the Committee on A rtificial Intelligence (CAI).10A ccordingly, our motivation was to address this core gap, with a report that focuses on  education as a key AI domain, and that is written for the Council of Europe’s core audienc e. The aim was to develop a high-level mapping of key topics and issues iden-tified  in the field, in order to complement CAHAI’s work, to enhance what is known mor e widely about the connections between AI and education and their impact on human v alues, and to provide a foundation for future related work.T he scope of the material reviewed for this report includes:f academic and peer-reviewed publications;f open access policy guidelines and frameworks including those developed by in ternational, national and intergovernmental agencies; andf other relevant literature produced by civil society, regulators and protection agencies , and third sector organisations.T he report was guided by the following questions (all through the lens of the Council of E urope’s core values):f What is meant by AI and education, what does it involve, and what are its pot ential benefits?f What key issues and potential risks may arise in this context, and what are the possible mitiga tions?f What are the gaps in what is known, documented and reported, and what questions still need t o be asked?T he review is organised into four main parts. In Part I, we map the connections between AI  and education. In Part II, we identify and explore some potential challenges of AI  and education. In Part III, we explore AI and education through the lens of the C ouncil of Europe’s core values (human rights, democracy and the rule of law) and cr itically reflect on our findings. In Part IV, we conclude with a discussion and needs 8. C ouncil of Europe, Reference Framework of Competences for Democratic Culture (RFCDC), www .c oe.int/en/web/reference-framework-of-competences-for-democratic-culture. 9. A d hoc Committee on Artificial Intelligence, w ww.coe.int/en/web/artificial-intelligence/cahai. 10. w ww.coe.int/en/web/artificial-intelligence/cai. 
Introduction  P age 13analysis of open challenges, opportunities and implications of AI and education. O ur analysis includes the need to identify and act upon linkages across the Council of  Europe’s work, to increase understanding in and between policy makers, of the challenges  that AI poses across the directorates and member states, where children’s liv es are affected, in and beyond the context of education.I n addition, this report also includes a list of alternative definitions of AI (see Appendix I),  a list of related reports in this area (see Appendices II and III), a list of articles that r eview academic research in AI in education (see Appendix IV) and a list of examples of c ommercial learning with AI tools (see Appendix V).F inally, in parallel with this report, the Council of Europe’s Digital Citizenship Education Unit  is carrying out a survey of member states to better understand national initiatives linked  to AI and education, and is holding a multi-stakeholder conference (September 2022).  The survey and conference, together with this report, are all designed to help establish a f oundation for the Council of Europe’s future work in AI&ED.

 Page 15PART IT he connections b etween AI and educationF ollowing the societal changes brought about by the Covid-19 pandemic and its  impact on the educational landscape and the use of digital technologies ( Council of Europe 2021),11 exploring the link between the technologies of AI and educa tion is timely:T echnology and innovation matter … but the picture is much more complex, much mor e non-linear, much more dynamic than simple plug-and-play metaphors. There can  be dangerous unintended consequences from any single seemingly promising solution.  We must reorient our approach from solving discrete siloed problems to na vigating multidimensional, interconnected and increasingly universal predicaments. (UNDP 2020: 5) I t is precisely this complexity that we aim to address in this exploration of the con-nec tions between AI and education.11. Higher education’s response to the Covid-19 pandemic: building a more sustainable and democratic futur e, https://rm.coe.int/prems-006821-eng-2508-higher-education-series-no-25/1680a19fe2. 
Page 16  A rtificial intelligence and education1.1. Defining AII n order to explore the multiple connections between AI and education, we first have t o define AI. This is, however, immediately challenging. In fact, the description and boundar ies of AI are contested, without a universally accepted single definition (see A ppendix I for some examples of the different ways in which AI has been defined), and ar e constantly shifting:[ A] lot of cutting-edge AI has filtered into general applications, often without being called  AI because once something becomes useful enough and common enough it is not labelled AI an ymore. (Bostrom n. d.)12A rtificial intelligence, human rights, democracy, and the rule of law: a primer,  prepared b y the UK’s Alan Turing Institute (Leslie et al. 2021), draws on the Council of Europe’s A d hoc Committee on Artificial Intelligence (CAHAI) Feasibility Study, and defines AI sy stems as follows:AI  systems are algorithmic models that carry out cognitive or perceptual functions in the  world that were previously reserved for thinking, judging, and reasoning human beings . (Leslie et al. 2021: 8)13Giv en that this definition itself contains words and concepts that are not immediately tr ansparent for a general audience (e.g. algorithmic), we prefer a complementary definition  that is provided by UNICEF (which, in turn, is derived from a definition ag reed by the Organisation for Economic Co-operation and Development (OECD) member sta tes):AI  refers to machine-based systems that can, given a set of human-defined objectives, make  predictions, recommendations, or decisions that influence real or virtual en vironments. AI systems interact with us and act on our environment, either directly or  indirectly. Often, they appear to operate autonomously, and can adapt their behaviour b y learning about the context. (UNICEF 2021: 16)W e prefer this definition for several reasons. First, it does not depend on data, although it  does accommodate data-driven AI techniques such as artificial neural networks and  deep learning; second, it therefore also includes rule-based or symbolic AI and an y new paradigm of AI that might emerge in future years; and third, it highlights tha t AI systems necessarily depend on human objectives and sometimes “appear to oper ate autonomously” , rather than assuming that they do operate autonomously, which  is key given the critical role of humans at all stages of the AI development pipeline  (Holmes and Porayska-Pomsta 2022). None of the multiple other defin- itions  given in Appendix I has all these features. However, inevitably, the UNICEF definition  is not perfect. An element that we find less helpful is the notion of an AI sy stem “learning” – something that, it might be argued, requires the consciousness or  agency that, now and for the foreseeable future, machine-based systems entirely lack  (Rehak 2021). However, the use of anthropomorphic terms to describe these 12. T he Oxford philosopher Nick Bostrom cited in h ttp://edition.cnn.com/2006/TECH/science/07/24/ai.bostr om. 13.    http://rm.coe.int/cahai-2020-23-final-eng-feasibility-study-/1680a0c6da. 
The connections between AI and education  P age 17machine-based systems (including “intelligence” , “learning” and “recognition” , as in “facial  recognition”) are so part of the AI narrative that, although distracting and unhelpful , they are unlikely to change anytime soon.T he term artificial intelligence itself was coined at a workshop at Dartmouth College in  1956. From that time, AI experienced periods of huge interest and grand pre-dic tions, punctuated by periods known as AI winters, when the grand predictions failed  to materialise and so the funding all but dried up. From its earliest days, AI r esearchers have been interested in two parallel approaches. First, there is the “ symbolic” AI approach, which focused on encoding principles of human reasoning and  on knowledge engineering (encoding the knowledge of experts), and which led  to “expert systems” . This approach is often referred to as “rule-based” or “good old-fashioned  AI” (GOFAI). Second, although beginning at around the same time, ther e was AI inspired by how the human brain is structured (its neurons) and which dr aws inferences from usually large amounts of data. This artificial neural network ( ANN) approach is one of several data-based approaches (which also include support v ector machines (SVM), Bayesian networks and decision trees), which are collectively k nown as machine learning (ML).I n the late 20th century, most of the progress made in AI involved symbolic AI, but  progress was stalled by multiple roadblocks, leading to the AI winters. In the ear ly 21st century, thanks to much faster processors and the availability of huge amoun ts of data (mainly derived from the internet), ML became dominant – and it  is ML that has led to most of the dramatic achievements of AI in recent years (such  as automatic translation between languages14 and figuring out what shapes pr oteins fold into15). Interestingly, some researchers now argue that ML is soon to hit  its own development ceiling, such that significant further progress will only happen  if there is a new paradigm (which might involve bringing together GOFAI and ML) (M arcus 2020).D espite some impressive achievements and its broad presence in everyday life, AI of ten suffers from overselling and hyperbole,16 which raises multiple issues:T he hype around AI can result in unrealistic expectations, unnecessary barriers and a  focus on AI as a panacea rather than as a tool that can support positive impacts. (B erryhill et al. 2019: 27)F or example, AI systems can be brittle: a small change to a road sign can prevent an  AI image-recognition system recognising it (Heaven 2019). They can also be biased , because the data on which they are trained is biased (Access Now 2018; L edford 2019). AI language models such as GPT-3 (Romero 2021), again while 14. F or example, the OBTranslate foundation (w ww.obtranslate.org) is a deep learning, online CAT (c omputer-assisted translation) tool, neural machine translation (NMT) and AI platform for languages . Its parent company is OpenBinacle.15. G oogle DeepMind (2021), AlphaFold which addresses a 50-year-old grand challenge in biology, h ttps://deepmind .com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology. 16. T o give one example, it is often said that in some circumstances AL is “better than humans” , www .theguar dian.com/global/2015/may/13/baidu-minwa-supercomputer-better-than-humans-r ecognising-images. Ho wever, there is little evidence that this is accurate.
Page 18  A rtificial intelligence and educationimpressive, often write nonsense (Hutson 2021; Marcus and Davis 2020), while AI appr oaches made little impact on addressing Covid-19 when the pandemic was a t its height (Benaich 2020; Heaven 2021; Roberts et al. 2021; Walleser 2021). That said , the concerns that often feature in science fiction, such as the Singularity (K urzweil 2006) or superhuman AI machines that cannot be controlled by human-i ty,17 remain mythical.M uch of the problem begins, as noted earlier, with the language used to name these t echnologies (Rehak 2021). The early decision to call the field artificial “intelligence” eff ectively presupposes that the creation of a non-human intelligence is possible. T his anthropomorphism of AI also inevitably suggests agency (for example, “learning” r equires someone or something that “learns”). In any case, it is important to note tha t AI should not be thought of in purely technical terms; instead, AI is a complex sociot echnical artefact that needs to be understood as something that is constructed thr ough complex social processes (Eynon and Young 2021). In other words, when w e consider AI, we must consider both the human dimensions and technological dimensions in tandem. One  example is the potential impact of AI on jobs. Many claims have been made about  how AI will change the nature of employment (e.g. Arntz et al. 2016; Bughin et  al. 2017; Susskind and Susskind 2015). In an influential paper, Frey and Osborne estima ted the impact on more than 700 occupations and identified a trend towards labour  market polarisation, “with growing employment in high-income cognitive jobs  and low-income manual occupations, accompanied by a hollowing-out of middle -income routine jobs” (2013: 14). One example of the low-income jobs that AI  is currently creating are the so-called “hidden ghost work” of AI: the data cleaning, image  labelling and content moderation being undertaken by usually poorly-paid w orkers in developing economies (Gent 2019; Raval 2019). Furthermore, while the t otal number of jobs might grow, many individuals might still become terminally unemplo yed, and it is not likely that those middle-income employees will be able t o transfer easily to the high-income cognitive jobs. Either way, the impact of AI on emplo yment is complex, and is yet to be fully revealed.O ther examples of issues relating to both the human aspects and the technical aspec ts of AI include gender equity, surveillance and the impact of AI on sustainable dev elopment – each of which we consider in more detail below.1.2.  The connections between AI and educationF requently (e.g. Davies et al. 2020; OECD 2021; Seldon and Abidoye 2018), although r arely with strong evidence (Miao and Holmes 2021a), AI is hailed as a solution to man y of education’s core problems (e.g. the lack of qualified teachers, student under-achiev ement and the growing achievement gap between rich and poor learners). Nonetheless , this raises the need to consider multiple issues: the aims of using AI in educa tion, where it is used, by whom (by individuals, institutions or industry), how 17. h ttps://en.wikipedia.org/wiki/Skynet_(Terminator). 
The connections between AI and education  P age 19it is operationalised, at what levels (from the single learner to whole classrooms, c ollaborative networks and national and transnational levels), how it works and so on.A lthough the boundaries are not rigid, the connections between AI and educa-tion  (AI&ED) have elsewhere been grouped under four headings: “Learning with AI ” , “Using AI to learn about learning” , “Learning about AI” and “Preparing for AI” (Holmes et al . 2019).L earning with AI involves the use of AI-driven tools in teaching and learning, and includes: f the use of AI to support learners directly, involving tools such as those known as  intelligent tutoring systems, dialogue-based tutoring systems, exploratory lear ning environments, automatic writing evaluation, learning network or chestrators, chatbots and AI to support learners with disabilities;f the use of AI to support administrative systems (such as recruitment, timetabling and lear ning management);f the use of AI to support teachers directly (although, with the exception of smar t curation of learning materials, there are few examples).U sing AI to learn about learning  is not strictly AI, which almost always means some k ind of automation, but does involve the analysis of the same or similar data to that used  by “learning with AI” tools, and uses similar analytical techniques. Here, the data ar e used to learn about how learners learn, learning progression, or which learning desig ns are effective – the aim being to inform learners’ , teachers’ or other stakeholder pr actices, or to support admissions, retention of students and programme planning. T his overlapping but nonetheless distinct field is usually known as learning analytics or educa tional data mining.L earning about AI involves increasing the AI knowledge and skills of learners of all  ages (that is, from primary education, through secondary, to tertiary) and their t eachers, covering the techniques of AI (e.g. ML) and technologies of AI (e.g. natural language  processing), together with the statistics and coding on which it all depends (M iao and Holmes 2021a). Henceforward, in this publication, we refer to learning about AI as  AI literacy: the technological dimension .P reparing for AI involves ensuring that all citizens are prepared for the possible impac ts of AI on their lives – helping them to go beyond the hype in order to under-stand  issues such as AI ethics, data biases, surveillance and the potential impact on jobs . In fact, preparing for AI should always be integrated within learning about AI; it  is separated out only to ensure that it receives the attention it deserves and does not  become a tick box exercise. Henceforward, we refer to preparing for AI as AI lit eracy: the human dimension. 1.3. L earning with AIL earning with AI has been the focus of the AI in education (AIED) academic research field  since at least the 1980s. The International Journal of Artificial Intelligence in E ducation was first published in 1989, while the International AI in Education Society (IAIED ) was established in 1993. However, the origins of AIED are in the 1930s, which 
Page 20  A rtificial intelligence and educationsaw the development of “teaching machines” and their twin promises of personalised lear ning and saving teacher time (Watters 2021).A s noted, “Learning with AI” might be further divided into learner-supporting AI, t eacher-supporting AI and institution-supporting AI.1.3.1. L earner-supporting AIO ver the past three decades, most of the AIED research focus has been on learner-suppor ting AI, which by definition aims to automate teacher functions, so that lear ners can learn independently of teachers – or that they have their own artificial personal  tutor and can leverage the Bloom 2-Sigma effect.18 However, much of this adopts  a rather primitive approach to pedagogy, and all too often focuses on auto-ma ting poor pedagogic practices rather than innovation (for example facilitating e xaminations rather than devising innovative ways to assess and accredit learning).Nonetheless , the use of learner-supporting AI is fast becoming popular in main-str eam education (Becker 2017; Holmes et al. 2019; Miao and Holmes 2021a) and in r elated areas (e.g. legal education, Carrel 2018; science inquiry, Gobert et al. 2013; den tistry education, Majumdar et al. 2018; medical education, Sapci and Sapci 2020; and  engineering education, Silapachote and Srisuphab 2016). The AIED research c ommunity has demonstrated the efficacy of various learner-supporting AI tools, although  usually in short studies researched in limited contexts in universities and  high schools19 (e.g. Beal et al. 2007; Gobert et al. 2018; Mendicino et al. 2009; V anLehn et al. 2005)20 which have been summarised in meta-analyses (e.g. Ma et al. 2014).  However, robust, independent evidence remains scarce. Accordingly, many claims  (such as the use of AI in education will dramatically improve the way learners lear n, Davies et al. 2020; OECD 2021; Seldon and Abidoye 2018) remain aspirational (Holmes et al . 2019).O ver the many years, learner-supporting AI has developed to include, for example: adaptiv e learning tools “for complex domains such as programming languages, ma thematics, medicine, physics, avionics troubleshooting, pulp and paper mill fac tories, and electronics” (Wasson 1997: 572); the capture and analysis of a broad r ange of classroom signals (e.g. measuring attention, empathy and emotion), the use  of an increasing range of hardware (from mobile phones to EEG headsets), the dev elopment of chatbots designed to give learners 24/7 support, learning network or chestrators designed to build communities of learners, automatic writing evaluation, 18. T he US researcher Benjamin Bloom determined that learners receiving one-to-one tuition achieved t wo standard deviations more progress than learners participating in classroom learning. This obser vation has been the basis for much work in the AIED research community, which has aimed t o create machine-driven or automated one-to-one tuition (partly because one-to-one tuition pr ovided by humans is expensive and out of the reach of most children). See Bloom (1984).19. “ There have been relatively few studies of ITS software designed for use by younger learners in classr oom settings” (Beal et al. 2010: 66).20. G obert et al. (2018) demonstrated the efficacy of INQ-ITS intelligent scaffolding of the development of  science inquiry skills when 40 days after the scaffolding is removed learners demonstrated c ontinued growth of inquiry performance.
The connections between AI and education  P age 21the inclusion of open learner models (that the learners can inspect themselves to bett er understand their own learning) and the provision of teachers’ oversight func tionality by means of the ever-present data dashboards (cf. Holmes et al. 2018; T uomi 2018; Woolf 2010).W hile the use of learner-supporting AI appears to be growing in classrooms across the  world, as evidenced by the many multi-million-dollar-funded AIED companies globally ,21 there is actually surprisingly little to justify its wide use in well-resourced classr ooms, other than the marketing materials and mostly unsubstantiated hopes e xpressed by many policy makers (Miao and Holmes 2022).A rtificial Intelligence in Education (AIED) is one of the currently emerging fields in educa tional technology. Whilst it has been around for about 30y ears, it is still unclear for educa tors how to make pedagogical advantage of it on a broader scale, and how it can ac tually impact meaningfully on teaching and learning. (Zawacki-Richter et al. 2019: 1)I n fact, recent work (e.g. Centre for Data Ethics and Innovation 2020; Tuomi 2018) highligh t the technical, social, scientific and conceptual limits of AI in education sy stems and flag the lack of robust independent evidence for their efficacy or success in  delivering the intended outcomes. However, notable exceptions are the home-w ork-oriented ITS ASSISTments22 (Roschelle et al. 2017), the geometry Cognitive Tutor23(P ane et al. 2010), and Multi Smart Øving24 (Egelandsdal et al. 2019; Kynigos 2019).T he argument for using AI to support learners in contexts where there are few e xperienced or qualified teachers, such as in rural areas in developing countries, migh t be stronger. However, using technology to substitute for teachers addresses the  symptom of this key problem (children not receiving the education to which they ha ve a human right) rather than the cause (the global shortage of teachers). While some  children might benefit, the long-term effects of using this techno-solutionist appr oach to solve what is essentially a social problem remains unknown (Morozov 2014).  I n addition, AIED developers tend to be based in high-income WEIRD countries (w estern, educated, industrialised, rich and democratic, Pinkwart 2016), and are ther efore less familiar with the needs of young people in developing countries (Schiff 2021).  At the same time, although no specific evidence is available, it is likely AIED suff ers from the same lack of diversity for which AI in general is well-known (West et al . 2019). All of this potentially results in skewed or biased AIED data and algorithms. I n any case, while the issue of bias in data and algorithms has been the subject of much  research (e.g. Baker and Hawn 2021; Suresh and Guttag 2019), bias is actually a social pr oblem that might never have a technical fix (Powles 2018).21. I n 2015, Susskind and Susskind identified at least 70 companies that were providing adaptive lear ning systems. For some current examples, please see Appendix V.22. ASSIST ments was developed at Worcester Polytechnic Institute, https://new.assistments.org/r esearch. 23. Emer ging from research at CMU and published by w ww.carnegielearning.com. 24. A digital learning tool for practice and mass training in mathematics in primary school years 1-7, w ww.gyldendal.no/grunnskole/matematikk/multi-smart-oving. 
Page 22  A rtificial intelligence and educationA final issue to be mentioned here, in the context of learner-supporting AI, is that of trust . If AI tools are to become even more widely used in classrooms, it is essential that t eachers, learners, parents and other stakeholders can trust that they will be benefi-cial  – that they will enhance learning and not cause any harm. In fact, conversations about  stakeholder trust in AI tools designed for classrooms are only just beginning. Ho wever, all too often the onus is placed on the classroom stakeholders (to trust the  learner-supporting AI tools) rather than on the providers (to provide learner-suppor ting AI tools that are trustworthy). For example, a recent paper proposed eight fac tors that influence teachers’ trust in adopting AI-based educational tools, all of which  focus on the teachers, and none of which require the AI developers to make their  tools trustworthy (Nazaretsky et al. 2021); in short, the European Commission’s E thics guidelines for trustworthy AI25 should be applied to AIED systems too.1.3.2.  Teacher-supporting AIW hile many writers and government ministries have expressed their hope that AI will sa ve teacher time (Bryant et al. 2020; Miao and Holmes 2021b), others have suggested tha t AI will at some point make teachers de facto redundant – or at least their role will  be reconfigured as classroom orchestrators/technology facilitators, tasked with manag ing learner behaviour and ensuring that the technology is switched on (e.g. S eldon and Abidoye 2018). The reality is that, throughout its 30 plus years, most AIED r esearch and development has focused on using AI to support learners directly, with the  aim of enhancing learning, usually by taking over (namely, replacing) teacher func tionalities, such as by means of AI-powered adaptive tutoring (du Boulay 2016).D uring that time, there has been very little focus on AI designed specifically to support t eachers (aside from the dashboards that are common in educational technologies, Holst ein et al. 2018; Jivet et al. 2017). More recently, however, there has been some r esearch, such as AI to scrape the internet in order to curate resources (e.g. X5Learn, P erez-Ortiz et al. 2020), and tools designed to analyse and support teacher practices, time -management and course planning (e.g. Chounta et al. 2021; Holstein et al. 2017; M artinez-Maldonado et al. 2021). However, very little of this has been taken up by the c ommercial players or is widely available.T here has been a focus over many years on AI tools that aim to automatically assess lear ner assignments, again mostly with the intention of saving teacher time (which nea tly illustrates how the teacher-supporting/learner-supporting categories, although helpful , are not rigid). However, AI is not capable of the depth of interpretation or ac curacy of analysis that a human teacher can give (Byrne et al. 2010; Holmes et al. 2019),  a concern that led Australia to abandon plans to use automated marking for sta te-wide exams in 2018 (Hendry 2018). Even if AI was capable of fair and accurate mar king of free text, implementing such a system would also ignore how much a t eacher learns about their learners when they read what the learner has written – insigh ts that no dashboard will ever give. This is understood by a novel approach 25. E uropean Commission (2019), Directorate-General for Communications Networks, Content and T echnology, Ethics guidelines for trustworthy AI , Publications Office, https://op.europa.eu/en/publica tion-detail/-/publication/d3988569-0434-11ea-8c1f-01aa75ed71a1.
The connections between AI and education  P age 23which might be worth exploring that uses AI to support teachers while they grade their  learners’ work, by automatically offering prompts and shortcuts (that is, the t eacher does the grading, the AI only supports that process).26 There is also the use of  AI to formatively assess assignments, guiding learners how to improve their first dr aft assignments before submitting them for summative assessment, which is fast  becoming an area of interest.27 In summary, while AI might save teacher time, although  there’s little evidence for that, it remains unclear what the impact might be on the qualit y of teaching and learning.1.3.3. I nstitution-supporting AIW hile there is little evidence of AI being used to support directly primary or second-ar y education institutions, a recent systematic literature review of AI applications in higher  education (Zawacki-Richter et al. 2019) noted that almost half (48%) of the included  studies explored AI-support for administrative and institutional services. T hree main types of institution-supporting AI are automating processes related t o learners’ admissions, facilitating communication with learners and planning r esources allocation.M any higher education institutions, mainly in the USA, use AI-supported software (pr imarily offered by private companies) for supporting their admission proc esses.28,29F or example, the University of Texas at Austin launched an AI system named GRADE t o recommend whether an applicant should be admitted, based on their test scores, pr ior academic background and textual input, such as recommendation letters (Waters and  Miikkulainen 2014). However, by 2020, GRADE had been dropped because of its v arious biases.30 Nonetheless, AI is increasingly being used to support admissions, with  a focus on fairness and the institutions’ reputations (Dennis 2018; Marcinkowski et al . 2020; Zeide 2019).A nother focus of institution-supporting AI is the use of chatbots to facilitate com-munica tion with learners and to provide self-services operating 24/7. For example, G eorgia State University launched a chatbot, Pounce, in an attempt to support lear ners who were seeking support and counselling, especially those who were tr ansitioning from high school to college and were not familiar with academic life (P age and Gehlbach 2017). This approach was closely followed by other institutions. 26. w ww.graide.co.uk. 27. B olton College, UK, AI Cloud FirstPass tool, h ttps://ufi.co.uk/voctech-directory/formative-as-sessmen t-bolton-college; and Assessment Standards Knowledge exchange, Oxford Brookes Univ ersity (2021), Guide to Turnitin, h ttps://radar.brookes.ac.uk/radar/file/8ff7698b-72a1-9750-b982-1c c9080b421a/2/Turnitin.pdf. 28. USA Today (2021), “Artificial intelligence grading your “neuroticism”? Welcome to colleges’ new  frontier” , h ttps://eu.usatoday.com/story/news/education/2021/04/26/ai-infiltrating-c ollege-admissions-teaching-grading/7348128002. 29. P angburn D. (2019), “Schools are using software to help pick who gets in. What could go wrong?”  w ww.fastcompany.com/90342596/schools-are-quietly-turning-to-ai-to-help-pick-who-gets-in-wha t-could-go-wrong. 30. T weet from the Computer Science Dept UT Austin (2020), h ttps://twitter.com/UTCompSci/sta tus/1333890167782957060. 
Page 24  A rtificial intelligence and educationNonetheless, a recent literature review on the use of chatbots in education showed tha t although there is evidently research interest on the use of chatbots as assistants, ther e remain challenges and limitations regarding the evaluation, the potential and the  capabilities of this AI-enhanced technology that need to be addressed before mo ving towards its widespread adoption (Wollny et al. 2021).I n order for institutions to plan and allocate resources, it is important for them to k now the numbers and distribution of the learner population. Therefore, institutions ar e also investing in analytical tools for predicting learner dropouts. A well-known e xample is the Course Signals system at Purdue University, which initially appeared t o have a positive impact on learner retention (Arnold and Pistilli 2012), but this w as followed by controversial discussions regarding the findings (Sclater 2016). U sing AI to predict dropouts is also a popular area of research, especially in MOOCs (massiv e open online courses) where dropout rates can reach up to more than 90%. T he aim is to understand factors that can impact dropouts, to predict them and to r educe them (Dalipi et al. 2018; Feng et al. 2019; Goel and Goyal 2020) – although ther e remains little evidence for the effectiveness of such systems, or whether the c onnections are predictive or causal.1.4. U sing AI to learn about learning1.4.1. D igital tracesA s we noted earlier, AI’s recent massive growth was partly made possible by the a vailability of huge amounts of data (often known as big data). Now, the AI systems ar e themselves collecting similarly large amounts of data. In AIED, this includes data r epresenting the learner responses to questions, what they say, their affective state (e .g. interested or distracted), what they click and how they move their mouse across the  screen, to name just a few (Chassignol et al. 2018). A single session, with a child in teracting with an AI or other electronic education system (such as a MOOC or a ser ious game, Hwang et al. 2020), can generate “around 5-10 million actionable data poin ts per student each day” .31 These data points are collectively known as a learner’s dig ital traces (Pardo et al. 2019),32 and are of interest to three complementary and of ten overlapping academic fields: learning analytics and educational data mining, both  of which are “concerned with gathering, analysing and visualising data about lear ners and learning processes, so as to increase stakeholders’ understanding of these and henc e to improve learning and the environments in which it occurs” (du B oulay et al. 2018: 270),  and AIED, which uses similar data but to automate something (e .g. an adaptive learning platform).A lthough these fields (AIED, learning analytics and educational data mining) have dev eloped over many years, the capture and processing of data to represent learn-ers  and learning raises multiple issues that are yet to be fully considered. Predictive 31. Jose Ferreira, CEO of Knewton, an ITS company, talking at the Office of Ed Tech at the White House E ducation Datapalooza event, 2012, w ww.youtube.com/watch?v=GeajedxpWJA. 32. F or an example of how digital traces are used, see Predicting PISA scores from students’ digital tr aces, https://ojs.aaai.org/index.php/ICWSM/article/view/14996. 
The connections between AI and education  P age 25analytics and AI may be used to look for and act on patterns in learner participation in  class, approve or deny learner places at institutions, and to identify patterns of par ticipation at national levels. Questions raised include: who is permitted to collect those  digital traces, how are they transformed into useful knowledge, how may and ho w is that knowledge used, who has access to it and who uses that knowledge and  who benefits from it? Ostensibly, although there is still little evidence that data analytics  and the resultant visualisations are actionable and improve teaching and lear ning (Ferguson et al. 2016), it is the learner who supposedly benefits. However, pr esumably so do the AIED providers, which raises further questions: how do the AIED  providers benefit, how do they use the data for business intelligence purposes and  how, if at all, does this trickle down to the learners, teachers, school, or the educa tion system more broadly?1.4.2.  What commercial organisations are learningA s noted earlier, learner-supporting AI has been the subject of research for 30 plus y ears. However, for almost a decade AIED tools have “escaped” from the laboratory to be  developed into commercial products by a growing number of multi-million- dollar-funded  AIED companies around the worldand it is these products that are being implemen ted in schools. So, while the original research was undertaken in academia with  the explicit aim of enhancing teaching and learning, can we be so certain of t oday’s many commercial products? Instead, have these good intentions been o vertaken by commercial imperatives? Given that the children’s interactions with these  AI systems generate both technical knowledge about how the product works and  market knowledge about how the product is used, are children in classrooms ar ound the world being recruited by stealth to create and supply business intelligence desig ned to support the corporations’ bottom lines – and is this being prioritised o ver the child’s learning and cognitive development? If the children were to create an  image or a piece of writing, they would own the intellectual property rights (IPR). W hy then can commercial operators assume the IPR of data that has also been created b y the children? Educators and other stakeholders also have to negotiate the many h yperbolic claims of the corporations. For example, IBM writes that their Watson’s E ducation Classroom helps teachers realise “impressive outcomes” in the classroom, without pr oviding any robust independent evidence to support those claims.33I n addition, the nature of private companies means that they do not routinely share r esearch about the workings of their systems with others. This limits interoperability as  well as auditability of effectiveness. In particular, there is limited transparency of the  efficacy or error rates of the many AIED products that are being adopted with limit ed supporting evidence or oversight in public sector education. There are also man y educational products claiming to use AI but not actually doing so (defend dig ital me 2020). This informational asymmetry disadvantages the state and civil societ y in procurement, scrutiny and accountability for the public purse.33. w ww.ibm.com/common/ssi/cgi-bin/ssialias?htmlfid=897/ENUS218-010&infotype=AN&subtype=CA. 
Page 26  A rtificial intelligence and educationThis transfer of knowledge and power from the public to the private sector may also  have consequences for how future educational systems shape markets, society and  nation states – and the lives of individual learners. Meanwhile, multinational c ompanies and their products are not only shaping individual learners and teachers but  are also agenda-setting issues related to governance and national policies: “they will  impose their standards on what counts as knowledge at all. Knowledge is, or will be , what is or can be formalised in a computational way” (Baker 2000: 127). While ther e is some literature that addresses what these AIED companies are learning fr om the learners’ use of their systems, where that information flows and what can be  extracted from it (e.g. Komljenovic 2021), it still is not clear how this influences or  shapes our understanding of how learning happens, how teaching should be changed  and how learning should be measured. In any case, the AIED companies keep their inf ormation to themselves.Similar ly, while the literature sometimes does address the reduction of agency and aut onomy of learners as a result of introducing AI into education (Williamson 2019), ther e is little that analyses the reduced agency and autonomy of nation states to decide  policy, what they procure, and the outcomes of their school systems as a r esult. Finally, whether AIED governance models should accommodate proprietary and  closed systems which, rightly or wrongly, the Chinese Government has put a st op to (McMorrow et al. 2021), or whether governance should instead encourage open sour ce and interoperable systems, are key questions.1.5. L earning about AI (AI literacy)1.5.1.  Two dimensions of AI literacyI n this literature review, we build on Miao and Holmes (2021a) to include both the t echnical and human dimensions of AI literacy. We continue to separate these two dimensions , formerly learning about AI and preparing for AI, using different terms, in  order to ensure that the human dimension is not forgotten but instead is given equal billing t o the technological dimension.M ember states should invest in the level of literacy on AI with the general public through r obust awareness raising, training, and education efforts, including (in particular) in  schools. This should not be limited to education on the workings of AI, but also its  potential impact – positive and negative – on human rights. (Council of Europe C ommissioner for Human Rights 2019: 14)I t has also been suggested (Holmes et al. 2019) that in classrooms these two dimen-sions  of AI literacy should be interwoven throughout: that the human dimension should  not be left as some sort of nice-to-have but inessential add-on. In fact, the t echnological and human dimensions have both been important throughout the dev elopment of ICT, but the human dimension has rarely been addressed thoroughly. No w, given that AI techniques in many cases aim to emulate and even surpass human  cognitive processes, giving the human dimension of AI equal billing to the t echnological dimension is crucial.
The connections between AI and education  P age 27To enable this discussion in detail, and to be clear about what needs to be taught about  AI, we first need to establish how AI fits within education. This in turn begs the questions of wha t education is for and what should be taught more generally.1.5.2.  The purpose of educationT o begin with, some believe that the primary reason for education is the provision of  human capital for the economy.34 Others suggest that education is mostly about k nowledge transmission: ensuring that school students learn the content that has been  mandated by policy makers, selected by curriculum developers, packaged by t extbook publishers, taught by teachers and assessed by exams, and which appears t o be the aim of most AI tools that have been designed to support learners (Miao and Holmes 2021a). Ho wever, others take a broader view.F or example, the United Nations Convention on the Rights of the Child (UNCRC)35sta tes that “education should be directed to: (a) The development of the child’s personalit y, talents and mental and physical abilities to their fullest potential” . Subsequen tly, the World Economic Forum (2015) proposed that education should f ocus on the so-called 21st-century skills, comprising foundational literacies, com-pet encies and character qualities:f foundational literacies (how learners apply core skills to everyday tasks): lit eracy, numeracy, scientific literacy, ICT literacy, financial literacy and cultural and civic lit eracy;f competencies (how learners approach complex challenges): critical thinking/pr oblem solving, creativity, communication and collaboration;f character qualities (how learners approach their changing environment): cur iosity, initiative, persistence/grit, adaptability, leadership and social and cultur al awareness.M eanwhile, the Council of Europe’s Reference Framework of Competences for D emocratic Culture36 provides an alternative model of the competences that need t o be acquired by learners, from pre-school to higher education, so that they might par ticipate effectively in culturally diverse democratic societies. The framework 34. F or example, while the EU’s European Pillar of Social Rights (2021) begins by recognising: “E veryone has the right to quality and inclusive education” , its framing is economic: “in order t o maintain and acquire skills that enable them to participate fully in society and manage suc cessfully transitions in the labour market” . That is distinct from the aims of the funda-men tal human right to education, h ttps://ec.europa.eu/info/strategy/priorities-2019-2024/ec onomy-works-people/jobs-growth-and-investment/european-pillar-social-rights/eur opean-pillar-social-rights-20-principles_en. 3 5.w ww.unicef.org.uk/wp-content/uploads/2016/08/unicef-convention-rights-child-uncrc.pdf . “The Committee takes note of General Comment No. 13 (1999) of the Committee on E conomic, Social and Cultural Rights on the right to education, which deals, inter alia, with the aims  of education under article 13 (1) of the International Covenant on Economic, Social and C ultural Rights” , w ww.ohchr.org/en/resources/educators/human-rights-education-training/gener al-comment-no-1-aims-education-article-29-2001. 36. h ttps://rm.coe.int/prems-004721-the-reference-framework-of-competences-for-democratic-cul/1680a27f24. 
Page 28  A rtificial intelligence and educationincludes 20 competences, grouped into values, attitudes, skills and knowledge and cr itical understanding:f values: valuing human dignity and human rights, cultural diversity, democracy, justic e, fairness, equality and the rule of law;f attitudes: openness to cultural otherness and to other beliefs, world views and pr actices, respect, civic-mindedness, responsibility, self-efficacy, tolerance of ambiguit y;f skills: autonomous learning skills, analytical and critical thinking skills, skills of  listening and observing, empathy, flexibility and adaptability, linguistic, c ommunicative and plurilingual skills, co-operation skills, conflict-resolution sk ills;f knowledge and critical understanding: knowledge and critical understanding of the  self, of language and communication and of the world: politics, law, human r ights, culture, cultures, religions, history, media, economies, environment, sustainabilit y.F inally here, the 2020 United Nations Development Programme report37 reiterated tha t education has more than an instrumental role – its purpose is transformative thr ough exposure to broad human values and the promotion of critical thinking, to f oster politically aware and active people. In short, until policy makers are clear about the  purpose of education (for example, is it to transfer knowledge, increase exam suc-c ess, help young people to develop their individual potential and self-actualise, or to pr omote understanding, tolerance and friendship among all peoples?),38 and until they ha ve implemented appropriate policies, what should be taught about AI remains moot.1.5.3.  What should be learned about AIW hile the need for all citizens to be literate (able to read and write) and numerate (able  to understand and work with numbers) has long been recognised, more r ecently, as we have seen, multiple other literacies have been proposed. These include:  scientific literacy (the ability to engage with science-related issues, such as the  scientific method), ICT or digital literacy (the ability to use digital technologies in  order to function effectively in a knowledge society), financial literacy (the ability t o understand and use effectively skills such as personal financial management, budgeting  and investing) and cultural and civic literacy (the ability to understand, appr eciate, analyse and apply knowledge of the humanities).W hile only a small number of a total population of learners may want or need to lear n about AI in order to become AI designers or developers, the suggestion is tha t all citizens should also now be encouraged and supported to achieve a certain 37. h ttps://hdr.undp.org/en/content/human-development-report-2020, p. 134.38. T he Universal Declaration of Human Rights (UDHR) Article 26:2 states that “Education shall be dir ected to the full development of the human personality and to the strengthening of respect for human  rights and fundamental freedoms. It shall promote understanding, tolerance and friendship among  all nations, racial or religious groups, and shall further the activities of the United Nations f or the maintenance of peace. ”  
The connections between AI and education  P age 29level of AI literacy. They should have the knowledge, skills and values centred on the dev elopment, implementation and use of AI technologies:T he world’s citizens need to understand what the impact of AI might be, what AI can do and  what it cannot do, when AI is useful and when its use should be questioned, and ho w AI might be steered for the public good. (Miao and Holmes 2021a: 6)F or various reasons, AI literacy might be considered an extension or specialisation of  ICT/digital literacy – and, indeed, that is how it is almost always addressed by the f ew examples of government-sanctioned AI curricula that UNESCO has identified in  its recent mapping exercise (Miao and Shiohira 2022). Indeed, these AI curricula adopt  an almost exclusively technological perspective, with AI literacy being con-c eived as comprising “both Data Literacy, or the ability to understand how AI collects, cleans , manipulates and analyses data, as well as Algorithm Literacy, or the ability t o understand how the AI algorithms find patterns and connections in the data” (ibid .: 11). However, if we accept that AI is qualitatively different from most digital t echnologies, since “often they appear to operate autonomously, and can adapt their  behaviour by learning about the context” (UNICEF 2021), AI literacy cannot be limit ed only to its technological components. Instead, AI literacy should comprise both  the technological and the human dimensions of AI, both how it works (the t echniques and the technologies) and what its impact is on people (on human c ognition, privacy, agency and so on) (Holmes et al. 2019). In short, teaching about AI  using simplified technical language is important but teaching about what AI does is  incomplete without explanations of the people, power and political motivations behind the adoption of aut omated decision making.1.5.4.  Where is AI being taught, to whom and by whom?A s we have noted, AI can be, and indeed is being, taught at all stages of education, fr om primary, through secondary to tertiary (although almost exclusively in countries tha t have robust electricity and internet infrastructure). Having said that, it remains the  case that AI is mainly covered in tertiary education, either as a core discipline (e .g. in computer science or data science) or as a tool to advance specific application ar eas (e.g. in “fintech” ,39 the creative industries, or in medicine). Indeed, for some time ther e appears to have been a conveyor belt of AI PhD graduates directly from uni-v ersities into BigTech (Amazon, Apple, Facebook, Google) and the other technology c ompanies – but, unfortunately, fewer into health or education.M eanwhile, as noted by UNESCO (Miao and Shiohira 2022), some aspects of AI t echnologies are increasingly being included in secondary education, usually as part of  overall digital literacy and mostly in computing classes, and very occasionally as par t of an AI curriculum. In fact, there are many available resources for teaching the 39. “F intech” refers to computer programs and other technology used to support or enable banking and financial ser vices.
Page 30  A rtificial intelligence and educationtechniques and technologies of AI that teachers might use,40 with Scratch41 from MIT being  especially popular. In addition, many leading technology companies (such as  Microsoft, IBM and Adobe) have also developed AI curricula and tools for use in sec ondary education.42 In addition, there are various non-governmental organisa-tions  (NGOs) who offer some form of AI curriculum or training (e.g. Teens in AI43 and AI4K12 44), in Ukraine, for example, the STEM IS FEM initiative taught coding and AI to g irls aged 12-17 years, while in Egypt AI is being used to match young people’s skills with  available jobs (ITU 2020). Finally, the teaching of AI is also increasingly being in troduced in primary education, for example in Canada by Kids Code Jeunesse, which  aims to put “coding, Artificial Intelligence, ethics, and the UN’s Global Goals f or Sustainable Development at the forefront of kids’ education, ”45 and for all citizens, f or example with Finland’s Elements of AI which aims “to encourage as broad a group of  people as possible to learn what AI is, what can (and can’t) be done with AI, and ho w to start creating AI methods” .46W hile all such resources are to be welcomed, and corporations and NGOs are simply filling  the void left by the lack of government AI curricula and training for young citiz ens, the easy availability of well-funded commercial AI curricula and AI curricula dev eloped by AI experts rather than by educators again raises the frequently asked, v exing questions of what involvement the private sector should have in education, and wha t is the impact on school students of their commercial imperatives.1.5.5. AI lit eracy: the technological dimensionI nevitably, each of these many initiatives adopts a slightly different perspective. Ho wever, as we have noted, all of them tend to focus on the technological dimension of  AI to the exclusion of the human dimension, save for a brief foray into AI ethics, usually  tagged onto the end of the course. Nonetheless, here we should summarise the  technical aspects covered by most curricula/courses, which may be divided into the t echniques, technologies and applications (Miao and Holmes 2021a).AI  techniques include the classical AI or GOFAI approach, ML (including supervised, unsuper vised and reinforcement learning), artificial neural networks and deep lear ning, to name a few core ones. Inevitably, this is a fast-moving space, with new t echniques constantly in development, and the cutting-edge approaches frequently being  disputed by leading AI researchers (for example, as we have mentioned, while some  claim that ML will lead to human level artificial general intelligence, others ar gue that this will only be possible with a new AI paradigm which might combine 40. F or examples, see h ttp://teachingaifork12.org. 41. S cratch is the world’s largest coding community for children and a coding language with a simple visual  interface from the Scratch Foundation, a non-profit organisation, h ttps://scratch.mit.edu. 42. M icrosoft Computer Science Curriculum Toolkit, White Paper, h ttps://edudownloads.azureedge.net/msdo wnloads/Microsoft_CSCT_WhitePaper.pdf. 43. w ww.teensinai.com. 44. h ttps://ai4k12.org. 45. h ttps://kidscodejeunesse.org/partners. 46. w ww.elementsofai.com. 
The connections between AI and education  P age 31ML and GOFAI). Nonetheless, these techniques form the basis of the multiple AI t echnologies with which we are becoming increasingly familiar, including natural language  processing (NLP) and generation, speech, image and facial recognition, aff ect detection, recommenders and artificial creativity, again to name just a few. F inally, these techniques and technologies are combined to create a range of applica tions, including but not limited to autonomous agents and service chatbots, aut o-journalism, AI-driven shopping and entertainment platforms, AI legal services, AI  weather forecasting, AI fraud detection, AI-driven business processes, smart cities, AI  robots and deep-fakes. Together, these techniques, technologies and applications c onstitute the major part of the teaching of AI today. However, while the teaching of  this technological dimension is necessary, it is not sufficient (Holmes et al. 2021). I ndeed, any teaching of AI, it has been argued (Holmes et al. 2019), should also c onsider the human dimension – to which we turn next.1.5.6. AI lit eracy: the human dimensionW ith AI becoming ubiquitous in everyday life, preparing for the impact of AI is incr easingly important for everyone (Markauskaite et al. 2022). The aim of addressing the  human dimension of AI literacy is to enable everyone to learn what it means t o live with AI and how to take best advantage of what AI offers, while being pro-t ected from any undue influences on their agency or human dignity. To begin with, y oung people should be helped to understand how AI, automation and especially aut omated decision making, may affect their treatment in society. In other words, if they  are to be literate in AI as they are literate in mathematics, all young people need t o understand whether the AI with which they knowingly or unknowingly engage has  treated them fairly. This is not to relieve AI providers of their responsibilities, but the  onus should always be on the provider not the user to prevent harm. Instead it r ecognises that knowing about AI, going beyond the hype and misinformation, is in the best in terests of all.T o date, teaching about AI has largely been the preserve of computer scientists. The r esultant inevitable focus on the technological dimension of AI has tended to mis-dir ect policy making away from the social and cultural implications. Instead, there needs  to be a holistic understanding of the environment into which AI is introduced, both  outside and within education. Outside education, this raises issues such as the ac cumulation of data and AI expertise by BigTech, while inside education it includes ho w AIED is used to manage the educational infrastructure and deliver the teaching and lear ning.One  way in which these issues might begin to be addressed is by encouraging all t eachers of subjects ranging from the sciences to the humanities and arts, and not just  the ICT or computer science teachers, to explore with their students the potential uses , benefits, impacts, challenges and risks of AI in their subject areas. For example, g iven that AI might be used to automatically generate novel digital images47 and 47. h ttps://hotpot.ai/art-maker. 
Page 32  A rtificial intelligence and education“write” poems,48 art teachers and literature teachers might ask their students: if a machine migh t be capable of creative acts, what does it mean to be a human?O ther issues that should be considered, as identified in the Montréal Declaration f or Responsible Development of Artificial Intelligence (2018),49 include well-being, r espect for autonomy, protection of privacy, solidarity, democratic participation, equity, div ersity, prudence, responsibility and sustainable development. Other important issues  include the use of AI for surveillance, what it means for AI to be thought of as  intelligent, empowering AI tools (giving AI autonomy), the potential impact on jobs , inclusion and gender equity (Samuel 2018) and trust. Many of these issues are addr essed by the updated European Digital Competence Framework for Citizens50(DigC omp 2.2), which has a new focus on citizens’ AI competencies (Vuorikari and Holmes 2022). I n addition, all citizens should be enabled to understand the role of humans in AI, in  its development and control – with some calling for a human in the loop (e.g. Zanz otto 2019),51 ensuring that humans have control of the output of the AI system, and  others suggesting that should be reversed: humans should be in control, while AI should be in the loop (Holmes et al . 2021).48. h ttps://sites.research.google/versebyverse. 49. w ww.montrealdeclaration-responsibleai.com. 50. T he European Commission Digital Competence Framework 2.0, h ttps://ec.europa.eu/jrc/en/digc omp/digital-competence-framework. 51. “Human- out-of-the loop” systems are those that function without any human oversight or control.
 Page 33PART IIS ome challenges f or AI and educationI n Part II we move on to consider a range of issues or challenges centred on the c onnections between AI and education: AI and learners (pedagogy, equity and inclusion,  learner agency, privacy and cognitive development), the ethics of AIED, AI and the educa tional ecosystem and transnational issues.
Page 34  A rtificial intelligence and education2.1. AI and learners2.1.1. AI applic ations and pedagogyD espite using state-of-the-art technologies and often being grounded in the cognitive scienc es (Anderson et al. 1995), almost every existing commercial AI tool designed t o support learners effectively embodies a naïve approach to teaching and learning. T he dominant approach involves spoon-feeding pre-specified content, adapted to the  individual’s achievements, while aiming to avoid failure. In other words, despite suggestions  to the contrary, the approach is effectively behaviourist or instruction-ist , and ignores more than 60 years of pedagogical research and development (in, f or example, deep learning, Entwistle 2000; guided discovery learning, Gagné and Br own 1963; productive failure, Kapur 2008; project-based learning, Kokotsaki et al. 2016;  and active learning, Matsushita 2018). This behaviourist approach, especially the  spoon-feeding, prioritises remembering over thinking, and knowing facts over cr itical engagement, thus undermining learner agency and robust learning.T o give a parallel example, considerable effort has been expended by the research c ommunity and commercial organisations to develop AI-driven e-proctoring. During the  pandemic, as a great deal of education moved online, so did many assessments – leading  the company businesses of automated exam monitoring, e-proctoring, to g row massively. But the use of e-proctoring is controversial, and has been accused of  intrusion, racial discrimination, failing to work properly, preventing learners taking their  exams and exacerbating mental health problems, while having little impact on chea ting or attainment (Brown 2020; Conijn et al. 2022). This constitutes an example of  automating and scaling up poor pedagogic practices, rather than using AI to dev elop innovative approaches.A  second example is “personalisation” , which is often mentioned by the media, EdTech c ompanies and many policy makers, and is an ambition that has been around for almost  100 years (Watters 2021). If we can have personalised recommendations on  Netflix, why can’t we do that in education? Indeed Pearson, one of the biggest educa tion companies in the world, may be seen as trying to rebrand itself as the Netflix  of education: “Much as you would consume movies through Netflix, or buy ser vices through Amazon, we want education to be delivered through this single, qualit y user experience, but available to all ages and stages of learners. ”52 However, Holmes  and colleagues argued that this misses the point (2018). Some “learning with  AI” tools might provide each learner with their own individual pathway through the  materials, but they still take them to the same fixed learning outcomes as every-one  else. The pathway may be personalised but not the destination. This is a weak understanding of personalisa tion.One  could argue that personalisation of learning is not primarily about pathways (the  micro level of learning) but about helping each individual learner to achieve their  own potential, to self-actualise, and to enhance their agency (the macro level 52. Undelet e news (2018), “Pearson aims to become the ‘Netflix of education’” , h ttps://uk.undelete.new s/post/pearson-aims-to-become-the-netflix-of-education/68102. 
Some challenges for AI and education  P age 35of learning). This is something that no existing commercial AI tool does (Thompson and  Cook 2017), although there is some related academic research (e.g. Järvelä et al . 2021; Molenaar et al. 2021). Education is also about collaboration and the other social  interaction aspects of teaching and learning, and although AI-supported c ollaborative learning has been the subject of academic research (e.g. McLaren and  Scheuer 2010), again – to the best of our knowledge – no current commercially a vailable AIED tools appear to address this.2.1.2. AI applic ations and identifying learners at riskAI  applications are also used beyond the classroom to inform how education is managed  by institutions. For example, the USA has seen a proliferation of consulting fir ms offering predictive analytics to educational institutions for staff and student r ecruitment and retention (O’Neil 2017). AI is being used at the state level, for ex - ample  in India,53 to address the perennial problem of retention rates beyond primary school , especially for girls. However, such uses of technology can be misleading –  as measures of participation are not measures of quality or equity (Aikman and Un terhalter 2005).W hile using AI to profile learners may have some benefits, for example to identify studen ts at risk of dropping out (Barrett et al. 2019; Hager et al. 2019), it can also be  overly intrusive, undermining a learner’s rightful expectation of privacy. It may also  have punitive effects on the family where attendance is tied to state welfare pa yments, such as in the Bolsa Familia programme in Brazil (Canto 2019).W hen personal data are being joined up for the purposes of retention, approaches such  as using social network posts alongside school records are unlikely to meet th e data minimisation requirements of countries where the Convention for the P rotection of Individuals with regard to Automatic Processing of Personal Data (E TS No. 108)54 applies. Nor do such approaches address the argument that chil-dr en should not be routinely profiled, to avoid ranking or categorising them with a  detrimental effect on their development and future selves. In fact, using AI in this  way raises many problems that are probably not solvable, especially by the use of mor e technology.2.1.3. AI applic ations and the developing brainI n data protection law, definitions of biometric data tend to focus on the use of data f or purposes of identification. Accordingly, data protection laws do not address data pr ocessing in which the aim is to influence an individual’s behaviour. This lack of adequa te protection is particularly concerning when the biometric data is used to 53. T he government of Andhra Pradesh, a southern state in India in partnership with Microsoft.54. C onvention for the Protection of Individuals with regard to Automatic Processing of Personal Data (E TS No. 108), w ww.coe.int/en/web/conventions/full-list?module=treaty-detail&treatynum=108and  the Protocol amending Convention 108 (CETS No. 223), w ww.coe.int/en/web/conventions/full-list?module=tr eaty-detail&treatynum=223. 
Page 36  A rtificial intelligence and educationinfluence the behaviour of children, whose mental processes, values and attitudes ar e not yet fully formed. In short, we need to carefully consider the impact of AI applica tions on the development of human cognition and the developing brain, sinc e such technologies may have fundamental consequences especially during cr itical periods of brain development (Tuomi 2018).2.1.4. AI applic ations and learner agencySinc e Dewey,55 a learner-centric approach to teaching and learning has been a r ecurring theme in education research and practice. This approach gives children sig nificant control over the learning processes, thereby maximising learner agency. Ho wever, a learner-centric approach must also account for the fact that children do not  have the same capacity as adults. In the context of AI in education, this translates as  children not having the same capacity as adults to understand issues such as bias and  fairness, to give genuinely informed consent, or to understand or contest the eff ects of AI-based recommendations and predictions on their lives.I n any case, there is little evidence of the widespread adoption of learner-centric appr oaches in AI in education, despite claims to the contrary by some commercial pla yers. In fact, when using AIED tools, learners may have less actual control over their  learning, the data that their interactions with the system produce, or owner-ship  of any outcome (Lupton and Williamson 2017). In addition, the narrative of childcentred learning in the guise of personalised learning is, like that of children’s r ights discourses more broadly, challenged by the collection of intimate data that claim t o “speak on behalf of children” , thus further undermining children’s agency.F inally, the constantly changing boundaries of the education environment, which incr easingly includes digital devices that interact with and aim to influence children’s beha viour, can also be hard for children to comprehend. This also impacts on their families  as it is rarely how parents learned – it is outside their immediate experience of  the classroom. In addition, due to the complexity of the implications of the use of  AI tools, it is beyond what can be expected of parents. In any case, there is no tr ansparent way that children, staff or parents can independently validate claims about  how AI may influence a child’s cognitive, social or emotional development. A ll of this, and more, must be addressed before it is clear what the human rights or legal  basis are for the use of AI with children in settings in which they have limited choic e or control.2.1.5. AI applic ations for children with disabilitiesT he Council of Europe’s study “Two clicks forward and one click back”  (Lundy et al . 2019) notes that children with disabilities, irrespective of the nature of their impair ment, are disproportionately disadvantaged when using digital technologies. Nonetheless , AI approaches are increasingly being used to support children with 55. S tanford Encyclopaedia of Philosophy (2018) on John Dewey, h ttps://plato.stanford.edu/entries/dew ey/. 
Some challenges for AI and education  P age 37disabilities (Drigas and Ioannidou 2013); for example, to diagnose dyslexia (Kohli and  Prasad 2010), attention deficit hyperactivity disorder (ADHD) (Anuradha et al . 2010) and autism spectrum disorder (Stevens et al. 2019), and to support the inclusion  of children with neuro-diversity (Porayska-Pomsta et al. 2018). Common applica tions being used to support children with disabilities were not originally desig ned for education, but have been repurposed from elsewhere. These include some  assistive technologies, such as text to speech, speech to text, predictive text, spell  checkers and search engines (Popenici and Kerr 2017). However, unfortu -na tely, this repurposing is not always successful; for example, the ambient noise in  classrooms often means that speech recognition does not work well (Olney et al . 2017). Even when applications have research evidence, market failures often pr event them being rolled out more widely. In addition, to date there has been little  work on algorithmic or data biases specific to education and learner disability (Baker and Ha wn 2021).2.1.6. AI applic ations and parentsT he role of parents can be challenged by decisions made in educational settings. T he nature of childhood and the evolving capacities of a child mean they are still dev eloping, and parents expect to be involved in a process that is shared between the  educational setting and the home. Outcomes of AI applications may not only shape  an individual child’s experience of education in the moment, but might aff ect their neurological, cognitive and emotional development, for life – currently, w e just do not know (Gottschalk 2019). Nonetheless, the design of how AI tools w ork in the classroom can influence – and indeed aims to influence – how children think  and learn, and how they access and evaluate knowledge. What information is c onsidered valuable or valid by school children is shaped by what shows up at the t op of a search engine list, the accuracy of voice-assistants, or the processes priori- tised  by “intelligent tutoring systems” (Lovato et al. 2019). An intervention of any k ind in a child’s life within an educational setting has particular complexity due to the  non-consensual nature of participation in a relationship in which children and families  are disempowered. The rights bearers, often supported in law, are not only childr en, but also the parents or legal guardians.Lit erature that includes the views of parents on AIED is limited. However, the pot ential and risks of AI and education were mentioned by parents of school-aged  children in a survey commissioned by NESTA (Baker et al. 2019). Many of the  parents responded that they were concerned about the consequences of AI’s det erminism (77%), accountability (77%) and privacy and security (73%) in educa-tion.  Increasingly, parents are realising that, in the age of surveillance capitalism (Rust  2021), data can harm and discriminate, and that individually centred routes f or complaint or redress are inappropriate for the systemic inequity of AI and da ta-driven systems (Barassi 2020). Accordingly, it is essential for governments, businesses  and organisations, who act in loco parentis in educational settings, to r ecognise that algorithms cannot profile humans in just and fair ways, and we must challenge  the belief that algorithms are objective and can safely predict human beha viour, especially children’s behaviour.
Page 38  A rtificial intelligence and education2.1.7.AI applic ations as “high-risk”T he European Commission has identified “AI systems intended to be used for the pur pose of assessing students” and “AI systems intended to be used by children in  ways that have a significant impact on their personal development, including thr ough personalised education or their cognitive or emotional development” as  “high-risk” and “subject to compliance with certain mandatory requirements”56“ in relation to data and data governance, documentation and recording keeping, tr ansparency and provision of information to users, human oversight, robustness, ac curacy and security. ”57Ho wever, this underestimates how conventional uses of AIED for teaching and lear ning, which involves profiling patterns of behaviour or attainment scoring to make  predictions, can have a significant effect on the mental or emotional state of the  developing child, and can do so at scale. The computational learner modelling emplo yed by many AIED tools often uses profiles or stereotypes to predict academic per formance and identify learners for early interventions (Chrysafiadi and Virvou 2013).  However, this approach can lead to discrimination in underrepresented popu- la tions (Sapiezynski et al. 2017). Inferring learner states from indicators or features such  as gender, ethnic or cultural background and, even, socio-economic status, also in troduces bias and further widens existing gaps.Ho wever, even these obviously intrusive uses of sensitive data may not represent the  most important risks of AIED. Instead of looking only at overt or covert discrim-ina tion in data, it is important to consider whether and how using the technology is shaping  children in ways that schools and parents cannot see. The issues go beyond limiting  the child’s agency and autonomy to asking how external agents (typically, c ommercial players) are engineering the child’s development in closed and often impenetr able systems. In other words, the questions are less about data protection and  more about child protection from an unknown number of external stakeholders in terfering negatively with the child’s personal development.F inally, all too often, and almost always with the best of intentions, learners’ learning and  attendance data are being repurposed in ways for which the data was never desig ned – and usually without consent (defend digital me 2020). For example, in 2017,  the UK’s University of Buckingham began monitoring learners’ social media posts  as proxies for mental health risks: “An algorithm will scour their social media look ing for key positive and negative words, which will then be used to determine their  levels of happiness, engagement and fulfilment” (Gray 2017). The complex ethical issues tha t such a practice raises will be self-evident to most observers.56. P roposal for a Regulation of the European Parliament and of the Council laying down harmonised rules  on artificial intelligence (Artificial Intelligence Act) and amending certain legislative acts, 2021, Chapt er 5.2.3, Amendments, w ww.europarl.europa.eu/doceo/document/CJ40-PR-731563_EN.pdf. 57. R egulation of the European Parliament and of the Council laying down harmonised rules on ar tificial intelligence (Artificial Intelligence Act) and amending certain Union legislative acts, 2021.  Explanatory memorandum, Section 5.2.3. h ttps://eur-lex.europa.eu/legal-content/EN/T XT/HTML/?uri=CELEX:52021PC0206&from=EN.
Some challenges for AI and education  P age 392.1.8.AI applic ations and emotionT he impact of emotions on learning has been well-known for decades (for a summary, see  Pekrun 2014). Accordingly, there has recently been much research investigating ho w AI-driven educational technologies might identify a learner’s emotional (affect- iv e) state, in order to help move them from a negative to a positive affective state, which  is thought to enhance learning (e.g. Blanchard et al. 2009). However, these c omplicated constructs (positive and negative affective states) are often measured simplistically , by means of, for example, quiz scores, checkbox ticks and reaction times  (Jarrell et al. 2015), or by intrusive and unproven technologies such as the F ocus1 EEG headsets, which the developers claim can detect a learner’s attention b y monitoring electrical activity in their brain (Kosmyna and Maes 2019).58E ven if detecting, responding to and altering learner affect does improve their learning gains  (no evidence from independent large-scale studies was found to support these claims),  there are critical concerns regarding exactly how the affect is detected, what the  impact is on future learning, educational decisions and even mental health, and whether  such practice is ethical or constitutes “machinery for emotional management” ( Williamson 2020). In short, affective capture informing behavioural strategies aimed a t nudging learners is a form of psychological behavioural control which threatens lear ner privacy and autonomy (Nemorin 2017), and further, “tools using biometrics such  as facial detection in e-proctoring or emotions detection can infringe upon human r ights and human dignity” (King and Persson 2022: 32).I n a joint opinion published in response to the EU’s “proposal for a Regulation of the  European Parliament and of the Council laying down harmonised rules on ar tificial intelligence” , the European Data Protection Board and the European Data P rotection Supervisor comment that “the use of AI to infer emotions of a natural person  is highly undesirable, and they recommend it should be prohibited” .59 They also  call for a general ban on any use of AI for automated recognition of human f eatures in publicly accessible spaces (faces, fingerprints, DNA, voice, keystrokes and  other biometric or behavioural signals) in any context  – which presumably includes educa tional settings.2.1.9. AI and digital saf eguardingW ith web filtering software becoming routine in many UK and US schools, there has been  a marked increase in the use of AI-based tools that scan and capture a child’s dig ital activity. Monitoring and filtering combined products are used to keep under sur veillance all on-screen content, communications, children’s web searches and to filt er and block URLs and incoming online content matched against known website addr esses. This also creates a record of searches and attempted searches.58. Br ainCo grew out of the Harvard Innovation Lab, h ttps://brainco.tech/technology. 5 9.EDPB -EDPS Joint Opinion 5/2021 on the proposal for a Regulation of the European Parliament and of the C ouncil laying down harmonised rules on artificial intelligence (Artificial Intelligence Act), June 2021, h ttps://edpb.europa.eu/system/files/2021-06/edpb-edps_joint_opinion_ai_regulation_en.pdf. 
Page 40  A rtificial intelligence and educationMany vendors claim to use AI and automated systems to monitor everything children t ype on-screen in real time, compare and match this against thousands of words in English  and foreign languages libraries,60 and identify patterns in a learner’s search hist ory and activity. Matches trigger the system to create flags indicating risk of r adicalisation, extremism, risk to and from others, or self-harm. Consequently, these flags  can be used to create covert profiles, opaque for children and their families, for tar geting a range of interventions often without informed consent. The UN Special R apporteur’s 2014 report on children’s rights and freedom of expression commented tha t these AI tools can interfere with children’s right to access information and make inf ormed choices, around for example issues such as sex education and drug use.61M eanwhile, related work suggests that, as school security measures proliferate, learn-ers  actually feel less safe.62 In any case, when subjected to continuous monitoring, which  is by definition invasive, school children tend to alter their behaviour in order t o work around the policies and protect their privacy, freedom of expression and fr eedom of association (Leaton Gray and Kucirkova 2018). In addition, any harms fr om such prediction-based AI may affect entire communities as well as individuals ( Crawford 2021).F urthermore, “school safeguarding” companies often now present their AI-based sur veillance tools, which monitor everything that children do on a device, as solu-tions  for the seamless transition between the use of their tools in education, into wha t employers want “to improve employee productivity” .632.2.  The ethics of AI and education2.2.1.  The ethics of AIA  key set of issues in which all citizens should be encouraged to engage is the ethics of  AI. However, the ethics are complex, and so this is not so easy to achieve; in fact, the  ethics of AI in general has received a great deal of attention, by researchers (e.g. B oddington 2017; Whittaker et al. 2018; Winfield and Jirotka 2018) and more widely (e .g. the House of Lords,64 UNESCO,65 World Economic Forum66), with numerous 60. F or example, see NetSupport DNA, w ww.netsupportsoftware.com/20160719all-about-the-new -safeguarding-features-in-dna-v4-3-part-2. 61. LaRue F. (2014), Special Rapporteur on the Promotion and Protection of the Right to Freedom of  Opinion and Expression, “Promotion and protection of the right to freedom of opinion and e xpression: note / by the Secretary-General” , h ttps://digitallibrary.un.org/record/780499?ln=en. 62. w ww.brennancenter.org/our-work/research-reports/school-surveillance-zone. 63. w ww.netsweeper.co.uk. 64. House of Lords (2019), Select Committee on Artificial Intelligence, Report of Session 2017-19, AI  in the UK: ready, willing and able?  https://publications.parliament.uk/pa/ld201719/ldselect/ldai/100/100.pdf . 65. UNESC O (2021), Draft text of the Recommendation on the Ethics of Artificial Intelligence, h ttps://unesdoc .unesco.org/ark:/48223/pf0000376713. 66. B ossman J. (2016), “Top 9 ethical issues in artificial intelligence” , w ww.weforum.org/agenda/2016/10/t op-10-ethical-issues-in-artificial-intelligence. 
Some challenges for AI and education  P age 41institutes for AI ethics being set up (e.g. the Ada Lovelace Institute,67 the AI Ethics I nitiative,68 the AI Ethics Lab,69 AI Now,70 and DeepMind Ethics and Society,71 to name just  a few). In 2019, Jobin and colleagues (2019) identified 84 published sets of ethical pr inciples for AI, which they concluded converged on five areas: transparency, justice and  fairness, non-maleficence, responsibility and privacy. However, what each of these  means and includes, and how they may be applied both to the development or  use of AI, remains subject to ongoing debates. In any case, the hidden harms of e xclusion by automated decisions when a computer says no, are already very real. F or example, a university recruitment algorithm makes decisions with lifelong con-sequenc es and thus threatens how some in society are treated.Nonetheless , although these ethical questions are clearly important, we still have t o accept that the “social ills of computing will not go away simply by integrating ethics  instruction or codes of conduct into computing curricula” (Connolly 2020: 54). I n fact, although universities do typically have robust research ethics procedures, the major ity of university-based or commercial AI research has no oversight of AI ethics ( Crawford 2021). This might partly be because, in the early days of AI, research using human  data was perceived to pose minimal risks. Worryingly, some leading compan- ies  have been accused of undermining their commitment to ethics by removing leading ethics r esearchers from their teams.72F or AI in education, because children are being used by commercial developers to test their  AI technologies, it is important to design and implement ethical robust guidelines ( OECD 2021) and to avoid any “ethics washing” . Ethics “has been used by companies as  an acceptable facade that justifies deregulation, self-regulation or market driven go vernance, and is increasingly identified with technology companies’ self-interested adoption  of appearance of ethical behaviour. We call such growing instrumentalization of ethical language b y tech companies ‘ethics washing’” (Bietti 2020).2.2.2.  The ethics of AI is necessary but not sufficient for AI in educ ationA s discussed elsewhere:the  ethics of AI raises a variety of complex issues centred on data (e.g. consent and da ta privacy) and how that data is analysed (e.g. transparency and trust). However, it  is also clear that the ethics of AIED cannot be reduced to questions about data and c omputational approaches alone. In other words, investigating the ethics of AIED data 67. T he Ada Lovelace Institute, founded in 2018, is part of the Nuffield Foundation, w ww.adalove-lac einstitute.org. 68. T he Initiative is a joint project of the MIT Media Lab and the Harvard Berkman-Klein Center for I nternet and Society founded in 2017, h ttps://aiethicsinitiative.org. 69. T he AI Ethics Lab is based in Boston (USA) and Istanbul (Turkey), h ttp://aiethicslab.com. 70. T he AI Now Institute, founded in 2017, h ttps://ainowinstitute.org. 71. G oogle DeepMind, h ttps://www.deepmind.com/about/ethics-and-society. 72. MIT Technology Review (2014), “We read the paper that forced Timnit Gebru out of Google. Her e’s what it says” , w ww.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research- paper -forced-out-timnit-gebru. 
Page 42  A rtificial intelligence and educationand computations is necessary but not sufficient. Given that, by definition, AIED is the applica tion of AI techniques and processes in education, the ethics of AIED … also needs  to account for the ethics of education. Yet, while the ethics of education has been  the focus of debate and research for more than 2000 years (e.g. Aristotle, 2009; M acfarlane, 2003; Peters, 1970), it is mostly unacknowledged and unaccounted for by the wider AIED c ommunity. (Holmes et al. 2021: 520)P ertinent issues that the ethics of AI in education must address include:the  ethics of teacher expectations, of resource allocations (including teacher expertise), of  gender and ethnic biases, of behaviour and discipline, of the accuracy and validity of assessmen ts, of what constitutes useful knowledge, of teacher roles, of power relations bet ween teachers and their students, and of particular approaches to pedagogy (teaching and lear ning, such as instructionism and constructivism). (ibid.: 521)I n contrast with health, where there are long-established ethical principles and codes of  practice with regard to the treatment of human subjects, education (outside of  university research) does not have the same universal approach or commonly ac cepted model of ethics oversight committees. When it comes to AI, much of the discussion  on ethics frames learners as data subjects, not as people. Accordingly, although  a data protection impact assessment is required across Europe, commercial pla yers and schools are able to engage children with AI-driven systems without any ethical or other r isk assessment.F urther ethical challenges for AI and education include accountability and the per-sonal  data market. For institutions, it is not only a question of if and how children can  be “treated” using AI in education, but how accountability and liability should be  assigned when educators choose to apply or to override any system recommen-da tion. At industry-wide level, the common practice of purchasing children’s data, such  as voice or facial imaging data, from deprived populations including some c ountries in Africa, for use in creating data sets for biometric-based commercial pr oduct development in the global north, raises significant ethical issues that need t o be properly addressed.I n summary, the ethics of AI and education is complex but under-researched and without  oversight or regulation  – despite its potential impact on pedagogy, quality educa tion, agency and children’s developing minds. Accordingly, “multi-stakeholder c o-operation, with Council of Europe oversight, remains key to ensuring that ethical guidelines  are applied to AI in education, especially as it affects the well-being of y oung people and other vulnerable groups. ”732.2.3. AI lo yaltyLar gely missing from the literature and global conversations about AI and education is  the concept of conflicts of interest or “AI loyalty” (Aguirre et al. 2021) in educational 73. R ecommendation CM/Rec(2019)10 of the Committee of Ministers to member States on develop-ing  and promoting digital citizenship education, h ttps://search.coe.int/cm/Pages/result_details.asp x?ObjectID=090000168098de08. 
Some challenges for AI and education  P age 43settings. For whom does an AI system work? The learners, the schools, the educa-tion  system, the commercial players, or politicians and other decision makers? The question  therefore is less about the ethics of the technology itself and rather about the  ethics of the people in the companies behind their design, implementation and use , and the decision makers. Is the implementation of AI into educational contexts a  techno-solutionist approach that distracts from potentially more successful and long-t erm social approaches (Morozov 2014)? In fact, usually, “AI enters education thr ough mundane back-end AI-as-a-service plug-ins, rather than in the more spec-tacular  guise of automated pedagogic agents or tutoring systems” (Williamson and E ynon 2020). Understanding AI loyalty is therefore about making its ownership and an y conflicts of interest explicit.T o increase transparency and the trustworthiness of the effects of AI, system devel-opers  and controllers should be obliged to explicitly align the loyalty of their AI sy stems and governance structures with the best interests of the learner and others aff ected by the system. This should include measures to involve stakeholders (such as  those who represent children and teachers, parents, policy makers, industry and civil societ y) in the AI tool’s design, procurement and deployment.2.3. AI and the educ ational ecosystem2.3.1. P olitical and economic driversW hen considering the impact of a technology such as AI and its use in education, it  is also important to take a macro-perspective: “it is thus not possible to assess or manage  societal impacts by examining a technology divorced from its economic, political , and social context” (Parson et al. 2019: 2). This is all the more important because  education is prone to being highly politicised (Hickey and Hossain 2019): cr eating a curriculum or determining how learning should happen are political acts.F or example, it has been suggested that a competency-based approach to learning, as  adopted by much AI designed for education, is inevitably utilitarian and geared t owards meeting social and economic rather than learner needs (Ashrafi and Javadi 2020).  Accordingly, if AI becomes more widespread in education, it could lead to the  downgrading of what is valued, with knowledge transfer and easily measured c ompetencies being preferenced over the more humanistic and variable values tha t are hard to compare: learning that affirms human worth and dignity, reason, c ompassion, morality, ethics, democracy and inquiry.T he wide use of AI tools in education might also be characterised as privatisation b y stealth, given that most AI tools currently in use in educational contexts have been  provided by commercial players. The further problem is that these tools are r arely based on proven pedagogical need: “It is this pursuit of marketable products tha t appears to define the general approach of the private sector, rather than any under lying educational rationale for the design and development of AI applications” (K nox 2020: 16).F inally, most AI tools for use in education require a certain level of technical com-pet ence and language skills. Accordingly, AI may exacerbate rather than mitigate 
Page 44  A rtificial intelligence and educationinequities in education for marginalised communities, between the rich and poor, bet ween the able and learners with disabilities, and between those who have access t o reliable broadband infrastructure and those who do not (Biggs et al. 2018). For the  same reasons, there is also a critical need for appropriate professional devel-opmen t for teachers (as well as for administrators and policy makers), so that they ar e able to make informed decisions about which AI tools might be appropriate for their  classroom, how those tools broadly work, what they might achieve, how they migh t best be used, their challenges and risks, and what unintended consequences ther e might be.2.3.2. E valuating AI in educationD espite the wide advocacy for AI in education, there remains a paucity of evidence f or its efficacy, or its safety, inclusiveness or ethics. As noted earlier, the research c ommunity has conducted a wide range of evaluations over decades; however, this  is usually in small-scale settings over short periods of time, and focused on nar row scientific issues. With few exceptions, there is a lack of robust independent ev aluations of AI tools being used in educational contexts upon which policy might be  developed. Those independent evaluations that do exist typically compare an AI t ool with “business as usual” (that is, where no tool is in use), such that any success migh t be attributed to the use of a technology in general rather than to the particu-lar  technology in question. In addition, these “evaluations” only ever consider the lear ners’ academic progress (such as whether they have achieved a higher grade in a standar dised test or examination) rather than the tool’s impact on learner cognition or men tal health, classroom practices, or the teacher’s role.A ccordingly, it is unclear why so many governments around the world have bought in to and widely rolled out proprietary and commercial AI systems in the absence of sufficien t understanding of what the systems do, what they achieve, how they affect lear ners and teachers, and so on. All too often, failure is identified only in hindsight, af ter real-world detrimental effects on learners and teachers become obvious, and af ter long-term contracts have already been signed.M eanwhile, developers of AI tools being used in state education systems, the vast major ity of which are private commercial actors,74 can continue to sell or offer their pr oduct to schools with no accreditation and with no direct accountability towards the  learners. Furthermore, even more concerning than monetary costs, are the “data r ents” being paid in the form of learner and teacher data (Komljenovic 2021).I n addition, few teachers have the training or skills to assess properly the big claims made  by the AI developers, or have the digital literacy skills needed to understand wha t its data suggests. This shifts decision making from professional teachers to aut omated systems and commercial players, thus undermining professional authority, while  raising issues of corporate accountability that are rarely acknowledged. Further, g iven that private sector actors dominate the provision of AI in education, and state 7 4.h ttps://rm.coe.int/t-pd-2019-6bisrev5-eng-guidelines-education-setting-plenary-clean-2790/1680a07f2b . 
Some challenges for AI and education  P age 45education systems increasingly rely on outside partnerships for delivery of core edu-ca tional services, what happens if that commercial player fails or if that commercial pla yer simply decides that their provision is no longer sufficiently profitable? What c ontingencies have states put in place to mitigate or address such possibilities?M ost importantly, as these systems have an unknown impact on children’s developing minds , and are being used at scale, should they not be assessed to similar standards as  we assess medical interventions?75 Medical interventions must demonstrate their efficac y and safety, including foreseeable misuse, for the product’s life cycle and the out comes of its use. In any case, exactly how these systems are best evaluated, what c ounts as evidence, and where that evidence is applicable remain unclear.2.3.3. AIED c olonialismI n 2020, despite the coronavirus pandemic, venture capital (VC) investments in AI star t-ups reached a total of US$75 billion for the year, of which around US$2 billion w as invested in AI in education companies, mostly in the US. It is these companies tha t are selling their approaches globally, creating what has been called an AIED c olonialism: companies making claims to territory in the educational landscape ar ound the world, creating asymmetries in power across and between markets and sta tes. In fact, addressing cultural diversity is possibly one of the most complicated AIED  topics to consider, especially given the overwhelming balance of research car-r ied out in the global north and challenges in transfer of appropriate and effective polic y and practice (Blanchard 2015).AIED  colonialism might constitute the physical adoption by the decision makers of  AIED tools created in one context in other places. Territorial gains can be made acr oss schools as institutions, or as segments of entire state education systems, wher e a country or region adopts a single product across all its schools.76 A perhaps mor e subtle example is Google’s platform colonialism, which combines structures and  practices of data colonialism, surveillance capitalism and platformisation (S ujon 2019).77 The Google for Education product line78 is designed to achieve mar ket dominance in and through the classroom, with so-called Google Schools oper ating as ambassadors, teaching others in their local area about how Google pr oducts work – in other words, they act as marketers of the Google products. T his spreads territorial gains in both the physical space and the marketplace at the same  time. By embedding Google tools into teachers’ everyday practices enables G oogle to influence educational futures. Accordingly, we should be asking: what ar e the real implications of Google’s reach into young people’s lives and into public infr astructures and social institutions?75. S ee ISO 14971: w ww.iso.org/standard/72704.html. 76. h ttps://marketbrief.edweek.org/marketplace-k-12/coming-soon-huge-test-coming-artificial-in-t elligences-role-classrooms. 77. “P latformisation” is the increasing domination of the internet by a number of large companies whose pr oducts work as markets between users and other sellers.78. h ttps://edu.google.com. 
Page 46  A rtificial intelligence and educationA second tool of AIED colonisation is language. Classroom AIED tools tend to be tr ained and developed in English, and for the most part in standard American English  (Cotterell et al. 2020). This raises multiple questions centred on the impact of  the English-trained models used by AIED tools in non-English contexts, and on the  children who use them (Naismith and Juffs 2021). In sub-Saharan Africa, educa-tion  conducted through a European language continues to be associated with low school  achievement (Clegg and Afitska 2011). This is a situation identified within open  educational resources (OER), a field that has noted that linguistic and cultural div ersity continue to be a challenge, as the available OER are predominantly in English (M iao et al. 2019). In any case, do the relatively highly funded US-centred AIED tools cr owd out less well-funded but locally trained and potentially more locally sensitive AIED  tools? In short, the question of language used in AIED tools must be addressed if  states are to fulfil their obligations “to protect the existence and the national or ethnic , cultural, religious and linguistic identity of minorities within their respective t erritories and shall encourage conditions for the promotion of that identity” (United Na tions 1992, Article 1).I n conclusion, the notion that existing national policies and frameworks on AI for in ternational co-operation are sufficient for the use of AIED has been challenged ( Chander and Jakubowska 2020; Yeung 2020). In any case, AIED has for too long been a  domain dominated by computer-centric views without adequate attention paid t o pedagogy or the special nature of education and the developing child: “We can either  leave it to others (the computer scientists, AI engineers and big tech compan- ies)  to decide how Artificial Intelligence in education unfolds, or we can engage in pr oductive dialogue” (Holmes et al. 2019: 180).
 Page 47PART III AI, educ ation, human righ ts, democracy and the r ule of lawT he impact of AI on the Council of Europe’s core values – human rights, demo-cr acy and the rule of law – has been examined in detail by the UK’s Alan Turing I nstitute.G overnments should adopt a precautionary approach in the adoption and regulation of  AI that balances the realisation of the opportunities presented by AI while ensuring tha t risks to human beings and human interests are minimised to the extent possible. (L eslie et al. 2021: 16)Ho wever, that report, “Artificial intelligence, human rights, democracy and the rule of  law: a primer” (Leslie et al. 2021) does not specifically address challenges raised b y the connections between AI and education.P art III builds further on the Alan Turing Institute report, by discussing education as a specific  application domain for AI. We present work on AI systems for education that t ouch upon human rights, democracy and the rule of law, and we critically reflect on the challenges and implica tions for using these systems in education settings.
Page 48  A rtificial intelligence and education3.1. AI, education and human rights3.1.1.  What is meant by human rightsT o begin with and to provide a firm foundation for this discussion, given the many possible misin terpretations, what exactly are human rights?Human  rights are about respecting the human being, both as an individual and as a member  of the human species and ensuring the dignity of the human being. (Council of E urope n.d.)79Human  rights are the basic rights and freedoms that belong to every person in the w orld, from birth until death. They apply regardless of where you are from, what y ou believe or how you choose to live your life. They can never be taken away. These basic  rights are based on shared values like dignity, fairness, equality, respect and independenc e. These values are defined and protected by law. (Equality and Human R ights Commission n.d.)80A mnesty International81 provide the following additional details.f Human rights are the basic freedoms and protections that people are entitled t o simply because they are human beings. They are enshrined in the Universal D eclaration of Human Rights.f Human rights are universal: They belong to everyone, regardless of race, se xuality, citizenship, gender, nationality, ethnicity, or ability.f Human rights are inherent: We are all born with human rights. They belong t o people simply because they are human beings.f Human rights are inalienable: They cannot be taken away. No person, c orporation, organisation or government can deprive a person of his or her r ights.f Human rights can be violated: Although they are inalienable, they are not in vulnerable. Violations can prevent people from enjoying their rights, but they do not st op the rights existing.f Human rights are essential: They are essential for freedom, justice and peace.3.1.2. I nternational agreementsSinc e the Second World War, human rights have been encoded in multiple inter- na tional agreements, beginning with the UN’s Universal Declaration of Human R ights (UDHR),82 agreed in 1948, and the Council of Europe's European Convention 79. w ww.coe.int/en/web/portal/what-are-human-rights. 80. E quality and Human Rights Commission (UK), w ww.equalityhumanrights.com/en/human-rights/wha t-are-human-rights. 8 1.A mnesty International, What are human rights? http://www.amnesty.eu/about-amnesty- in ternational/. 82. w ww.un.org/en/about-us/universal-declaration-of-human-rights. 
AI, education, human rights, democracy and the rule of law  P age 49on Human Rights (the Convention),83 agreed in 1953. The Convention, for example, pr ohibits inhuman or degrading treatment or punishment (such as the death penalty, t orture, slavery and discrimination), and protects:f the right to life, freedom and security;f the right to respect for private and family life;f the right to freedom of expression;f the right to freedom of thought, conscience and religion;f the right to vote in and stand for election;f the right to a fair trial in civil and criminal matters;f the right to property and peaceful enjoyment of possessions.O f particular importance to this report, Article 2 of Protocol No. 1 in the Convention pr otects a child’s right to education and specifies that “the State shall respect the r ight of parents to ensure such education and teaching in conformity with their own r eligious and philosophical convictions” .84F inally, the International Covenant on Economic, Social and Cultural Rights (ICESCR) includes  two articles specifying a child’s right to education, and states that “education shall  be directed to the full development of the human personality and the sense of its dig nity” .85 Article 13 is both the longest provision in the ICESCR, and the most wide-ranging and  comprehensive article on the right to education in international human rights law.3.1.3. Human righ ts of childrenW ithout strong commitment to children, we undermine not only the destiny of many individuals  – but also our community’s strength. Protecting children’s rights and wellbeing should  be absolutely basic to who we are. All children possess inherent worth and should  have an equal chance to thrive, whatever their social origin, gender, place of bir th or family situation … Because if we do not take a stand for children’s rights, who ar e we and what has happened to our humanity and values? Because if we don’t act no w, when? (Michelle Bachelet, United Nations High Commissioner for Human Rights86)O f particular importance for education, UN member states in 1989 agreed the United Na tions Convention on the Rights of the Child (UNCRC).87 At the heart of the UNCRC is  respect for the evolving capacities of the child. It recognises that because children ar e still developing physically, cognitively and emotionally, they need specific and unique additional human r ights. These rights of the child include the following:f the right to life and development;f the right not to suffer from discrimination;83. w ww.echr.coe.int/documents/convention_eng.pdf. 84. Guide on Article 2 of Protocol No. 1 to the European Convention on Human Rights – Right to educa tion, w ww.echr.coe.int/documents/guide_art_2_protocol_1_eng.pdf. 85. w ww.ohchr.org/en/instruments-mechanisms/instruments/international-covenant-economic- social-andcultural-rights. 86. w ww.ohchr.org/en/statements/2019/05/stop-war-children-symposium. 87. w ww.unicef.org.uk/wp-content/uploads/2016/08/unicef-convention-rights-child-uncrc.pdf. 
Page 50  A rtificial intelligence and educationfthe right to a name and nationality;f the right to be cared for by parents or other responsible people;f the right to be protected from all forms of violence and abuse;f the right to health and healthcare;f the right to live in good conditions that help a child to develop;f the right to education;f the right to leisure, play and culture;f the right to express views and have them taken into consideration;f the right to have your own thoughts, beliefs and religion;f the right to meet and join groups and organisations with other children;f the right to privacy;f the right to access to information;f the right to be protected from economic exploitation;f the right to special protection for refugee children;f the right to special protection and support for children with disabilities;f the right of children of minorities to learn and use the language, religion and tr aditions of their families;f the right to special protection of children affected by wars.I t is important to recognise that education has relevance to all children’s human r ights. Education “is said to act as a multiplier of rights, meaning that all other human r ights can be enhanced when it is enjoyed fully and impacted negatively when it is not ” (Lundy 2021). It must also be recognised that children’s human rights are not without c omplications. For example:a  decontextualized discourse does not take into account the living conditions, the social , economical and historical contexts in which children grow up, which can be v ery diverse, and which are the environments in which children’s rights are to be r ealised. Neither does it take into account the enormous diversity among children, in  particular the differentiation between children of different ages. (Reynaert et al . 2009: 528)I n addition, researchers should focus on the child’s interests and entitlement, and should  be mindful of groups that may face discrimination or whose rights may be infr inged (Lundy et al. 2019).T he Convention on the Rights of Persons with Disabilities88 highlights the right to educa tion for children with disabilities, and obliges signatories to promote access f or children with disabilities, on an equal basis with others, to information and com-munica tion technologies and systems. Meanwhile, the Committee on the Rights of the  Child89 drew particular attention to indigenous children and their rights, and the 88 .T he Convention on the Rights of Persons with Disabilities and its Optional Protocol (A/RES/61/106) w as adopted in 2006. Article 24 is dedicated to education, w ww.un.org/development/desa/disabilities/c onvention-on-the-rights-of-persons-with-disabilities.html. 89. S ee: www2.ohchr.org/english/bodies/crc/docs/GC.11_indigenous_New.pdf. 
AI, education, human rights, democracy and the rule of law  P age 51need for states to ensure these are adequately reflected in the curricula, content of ma terials, teaching methods and policies. Inevitably, things are not so straightfor-w ard in practice: “problems raised include tokenism, unresolved power issues, being c onsulted about relatively trivial matters and the inclusion of some children leading t o the exclusion of others. Among the excluded groups are disabled children, ethnic minor ity groups and younger children” (Reynaert et al. 2009: 5).I t also needs to be recognised that the effectiveness of the UNCRC in upholding childr en’s rights is limited due to weak international enforcement mechanisms and  uneven domestic incorporation (Collinson and Persson 2021). Nonetheless, the  UNCRC remains the most widely ratified international human rights treaty, and  remains both a guide to good practices and an ethical or legal framework for assessing c orporations’ and states’ progress or regress.F inally, the connection between human rights and children goes beyond the fun-damen tal four Ps of rights – protection, prevention, provision and participation – to include  the need for young people to learn about and understand their human r ights. To this end, in 2010, Council of Europe member states agreed the Charter on E ducation for Democratic Citizenship and Human Rights Education.90 This defines human  rights education as the need to empower children and other learners “to c ontribute to the building and defence of a universal culture of human rights in soci-et y, with a view to the promotion and protection of human rights and fundamental fr eedoms” (Council of Europe 2010: 7).3.1.4. Human righ ts, AI and educationT here is little substantive literature that focuses specifically on, or even mentions in an y meaningful way, AI, education and human rights. Accordingly, in the remainder of  this section, we draw on the Turing Institute’s “Artificial intelligence, human rights, democr acy and the rule of law: a primer” (Leslie et al. 2021). We focus on a limited number  of specific human rights and rights of the child, and consider the reciprocal implica tions between these rights and AI and education.f Right to educationA I is often proposed as a way to ensure that all children have access to A I is often proposed as a way to ensure that all children have access to h igh-quality education,h igh-quality education,9191 although what constitutes quality education is  although what constitutes quality education is c omplex. In fact, today’s learners increasingly depend on digital technologies c omplex. In fact, today’s learners increasingly depend on digital technologies t o meet their right to be educated. This can place learners in a vulnerable t o meet their right to be educated. This can place learners in a vulnerable p osition with regard to their human, legal and social rights. At the same p osition with regard to their human, legal and social rights. At the same t ime, the human rights discourse has taken a rather narrow view, focusing t ime, the human rights discourse has taken a rather narrow view, focusing p rimarily on legal rights and not fully engaging with sociopolitical contexts p rimarily on legal rights and not fully engaging with sociopolitical contexts t hat impact human rights and education (Sayed and Ahmed 2011).t hat impact human rights and education (Sayed and Ahmed 2011).9 0.w ww.coe.int/en/web/edc/charter-on-education-for-democratic-citizenship-and-human-rights-educa tion. 91. XPRIZE F oundation, w ww.xprize.org/prizes/global-learning. 
Page 52  A rtificial intelligence and educationNonetheless, for children in remote areas, the right to education can often b e challenging to achieve, especially where too few experienced or qualified b e challenging to achieve, especially where too few experienced or qualified t eachers are available. The suggestion is that AI tools, such as the so-called t eachers are available. The suggestion is that AI tools, such as the so-called i ntelligent tutoring systems, might be used to alleviate the lack of quality i ntelligent tutoring systems, might be used to alleviate the lack of quality t eaching. However, while introducing AI tools might help some children t eaching. However, while introducing AI tools might help some children t oday, this techno-solutionism does little to solve the underlying and long-t oday, this techno-solutionism does little to solve the underlying and long-t erm human problem – that of too few experienced or qualified teachers. t erm human problem – that of too few experienced or qualified teachers. T his grand challenge is unlikely to be solved by more adaptive learning or T his grand challenge is unlikely to be solved by more adaptive learning or c lassroom robots. In fact, while AI tools might in some circumstances help c lassroom robots. In fact, while AI tools might in some circumstances help e nsure that some kind of education is available, there is little evidence that e nsure that some kind of education is available, there is little evidence that t hey provide the high-quality education or meet the wider aims of educa-t hey provide the high-quality education or meet the wider aims of educa-t ion, to which children have a right. Using AI tools to help enhance, rather t ion, to which children have a right. Using AI tools to help enhance, rather t han replace, the teaching capabilities of inexperienced teachers might t han replace, the teaching capabilities of inexperienced teachers might b e a better use of available resources. The reasons why there are too few b e a better use of available resources. The reasons why there are too few t eachers, and that they are hard to retain, will not be solved by more robots t eachers, and that they are hard to retain, will not be solved by more robots o r adaptive learning.o r adaptive learning.f Right to human dignityM ember States should ensure that, where tasks would risk violating human dignity M ember States should ensure that, where tasks would risk violating human dignity i f carried out by machines rather than human beings, these tasks are reserved i f carried out by machines rather than human beings, these tasks are reserved f or humans … The right to refuse interaction with an AI system whenever this f or humans … The right to refuse interaction with an AI system whenever this c ould adversely impact human dignity. (Leslie et al. 2021: 18)c ould adversely impact human dignity. (Leslie et al. 2021: 18)I n the context of AI and education, this human right implies that the teach-I n the context of AI and education, this human right implies that the teach-i ng, assessment and accreditation of learning, and all related pedagogical i ng, assessment and accreditation of learning, and all related pedagogical a nd other educational decisions, should not be delegated to an AI system, a nd other educational decisions, should not be delegated to an AI system, u nless it can be shown that doing so does not risk violating the dignity of u nless it can be shown that doing so does not risk violating the dignity of t he participating children. Instead, all such tasks should be carried out by t he participating children. Instead, all such tasks should be carried out by h uman teachers.h uman teachers.f Right to autonomyT he right not to be subject to a decision based solely on automated processing T he right not to be subject to a decision based solely on automated processing w hen this produces legal effects on or similarly significantly affects individuals. w hen this produces legal effects on or similarly significantly affects individuals. T he right to effectively contest and challenge decisions informed and/or made T he right to effectively contest and challenge decisions informed and/or made b y an AI system and to demand that such decision be reviewed by a person. b y an AI system and to demand that such decision be reviewed by a person. T he right to freely decide to be excluded from AI-enabled manipulation, indi-T he right to freely decide to be excluded from AI-enabled manipulation, indi-v idualised profiling, and predictions. (Leslie et al. 2021: 18)v idualised profiling, and predictions. (Leslie et al. 2021: 18)I n the context of AI and education, these human rights have multiple implica-I n the context of AI and education, these human rights have multiple implica-t ions. In particular, they add to children’s right to human dignity by underlining t ions. In particular, they add to children’s right to human dignity by underlining t hat children should not be subject to decisions made solely by AI systems – t hat children should not be subject to decisions made solely by AI systems – f or example, for the assessment of learning, for determining individualised f or example, for the assessment of learning, for determining individualised l earning pathways based on machine-made predictions, or for other decisions l earning pathways based on machine-made predictions, or for other decisions t hat might have significant effects.t hat might have significant effects.I n fact, the right to effectively contest and challenge decisions informed and/I n fact, the right to effectively contest and challenge decisions informed and/o r made by an AI system, and to demand that such decisions be reviewed by o r made by an AI system, and to demand that such decisions be reviewed by 
AI, education, human rights, democracy and the rule of law  P age 53a person, is set out in law. However the right to freely decide to be excluded f rom AI-enabled manipulation, individualised profiling and predictions is f rom AI-enabled manipulation, individualised profiling and predictions is s omething that parents and children do not yet have the ability to exercise s omething that parents and children do not yet have the ability to exercise i n consistent or universal ways in state-defined education.i n consistent or universal ways in state-defined education.I n addition, the use of AI in education to profile children ought to be carefully I n addition, the use of AI in education to profile children ought to be carefully c onsidered, to ensure that it does not compromise “the right to physical, c onsidered, to ensure that it does not compromise “the right to physical, p sychological, and moral integrity in light of AI-based profiling and emotion/p sychological, and moral integrity in light of AI-based profiling and emotion/p ersonality recognition” (Leslie et al. 2021: 18). If the data and the analysis p ersonality recognition” (Leslie et al. 2021: 18). If the data and the analysis t hat is used to determine what the child “should” learn next are inaccurate, t hat is used to determine what the child “should” learn next are inaccurate, c hildren’s development and future lives could be compromised.c hildren’s development and future lives could be compromised.I n fact, currently there appears to be little research into how historic educa-I n fact, currently there appears to be little research into how historic educa-t ion data, essentially generated by previous cohorts of children, may bias the t ion data, essentially generated by previous cohorts of children, may bias the s uggested pathways through the learning materials when used to train ML s uggested pathways through the learning materials when used to train ML m odels. The difficulties of using historical data were also highlighted when m odels. The difficulties of using historical data were also highlighted when v arious authorities (including the International Baccalaureate Organization v arious authorities (including the International Baccalaureate Organization a nd the UK Government) used data and algorithms to grade students who, a nd the UK Government) used data and algorithms to grade students who, b ecause of the school shutdowns during the Covid-19 lockdowns, had not b ecause of the school shutdowns during the Covid-19 lockdowns, had not b een able to sit their high-stakes examinations. The outcomes were contro-b een able to sit their high-stakes examinations. The outcomes were contro-v ersial (Everett 2020; Evgeniou et al. 2020) and later amended.v ersial (Everett 2020; Evgeniou et al. 2020) and later amended.f Right to be heardE very child who is capable of forming their own views should be given the E very child who is capable of forming their own views should be given the o pportunity to express those views freely, in all matters affecting them, and o pportunity to express those views freely, in all matters affecting them, and t hose views should be given due weight in accordance with the child’s age t hose views should be given due weight in accordance with the child’s age a nd maturity. Children also need to be afforded the inviolable right to make a nd maturity. Children also need to be afforded the inviolable right to make s ignificant decisions about their own education, rather than just “being s ignificant decisions about their own education, rather than just “being c onsulted only about relatively trivial matters” (Reynaert et al. 2009: 5).  c onsulted only about relatively trivial matters” (Reynaert et al. 2009: 5).  P ut another way, children should be considered “as active agents and autonomous, P ut another way, children should be considered “as active agents and autonomous, i ndependent human beings in constructing their lives in their own right” (ibid.: 4).i ndependent human beings in constructing their lives in their own right” (ibid.: 4).F or example, children or their parents should be afforded the right to refuse F or example, children or their parents should be afforded the right to refuse a ny involvement with AI classroom tools without such a refusal adversely a ny involvement with AI classroom tools without such a refusal adversely a ffecting their education. However, in practice children are rarely allowed that a ffecting their education. However, in practice children are rarely allowed that a gency: “the embodied and subjective voices of children are displaced by the a gency: “the embodied and subjective voices of children are displaced by the s upposed impartial objectivity provided by the technological mouthpieces of s upposed impartial objectivity provided by the technological mouthpieces of d ata ... data are positioned in ways that override the rights of children to speak d ata ... data are positioned in ways that override the rights of children to speak f or themselves” (Lupton and Williamson 2017). In other words, it is the tech-f or themselves” (Lupton and Williamson 2017). In other words, it is the tech-n ology that de facto exercises rights, on behalf of or rather instead of the child.n ology that de facto exercises rights, on behalf of or rather instead of the child.f Right not to suffer from discrimination (fairness and bias)I n addition to the UNCRC, the obligation of states to combat and eliminate I n addition to the UNCRC, the obligation of states to combat and eliminate d iscrimination is set out in other international agreements: the International d iscrimination is set out in other international agreements: the International C onvention on the Elimination of All Forms of Racial Discrimination, the C onvention on the Elimination of All Forms of Racial Discrimination, the C onvention on the Elimination of All Forms of Discrimination against Women, C onvention on the Elimination of All Forms of Discrimination against Women, 
Page 54  A rtificial intelligence and educationand the International Convention on the Protection of the Rights of All Migrant W orkers and Members of Their Families.W orkers and Members of Their Families.B uilding on these various conventions, it is clear that wherever AI is imple-B uilding on these various conventions, it is clear that wherever AI is imple-m ented, by design it must be non-discriminatory, fair and inclusive throughout m ented, by design it must be non-discriminatory, fair and inclusive throughout i ts entire lifecycle (from design to use) (Leslie et al. 2021: 18). In education, i ts entire lifecycle (from design to use) (Leslie et al. 2021: 18). In education, t his means ensuring that all children are able to benefit from the use of t his means ensuring that all children are able to benefit from the use of t echnology, not just those from the socio-economic groups who can afford t echnology, not just those from the socio-economic groups who can afford i t, thereby avoiding what is known as the Matthew Effect.i t, thereby avoiding what is known as the Matthew Effect.9292 In particular,  In particular, a s many AI education technologies are often only available online, this a s many AI education technologies are often only available online, this a lso means ensuring the wide availability of robust internet infrastructure, a lso means ensuring the wide availability of robust internet infrastructure, e specially in rural areas.e specially in rural areas.F airness is also determined by the biases known to compromise many AI F airness is also determined by the biases known to compromise many AI s ystems. Bias in AI systems can arise for various reasons; for example, stereos ystems. Bias in AI systems can arise for various reasons; for example, stereo--t yping biases, inheriting historic inequality and discrimination entrenched t yping biases, inheriting historic inequality and discrimination entrenched i n data sets, and discriminatory algorithmic decisions.i n data sets, and discriminatory algorithmic decisions.I t is well-known that current AI tools often exhibit gender and other biases I t is well-known that current AI tools often exhibit gender and other biases ( Borgesius 2018; Buolamwini and Gebru 2018). For example, Google Translate ( Borgesius 2018; Buolamwini and Gebru 2018). For example, Google Translate h as been shown to translate gender-neutral terms from gender-neutral lan-h as been shown to translate gender-neutral terms from gender-neutral lan-g uages into masculine terms providing results that reflect existing gender g uages into masculine terms providing results that reflect existing gender i nequality (Prates et al. 2019).i nequality (Prates et al. 2019).S imilarly, AI tools might exhibit biases against those who have a disability. S imilarly, AI tools might exhibit biases against those who have a disability. H owever, discrimination in the context of disability may be perceived as both H owever, discrimination in the context of disability may be perceived as both p ositive and negative: positive because AI tools might offer benefits to chil-p ositive and negative: positive because AI tools might offer benefits to chil-d ren who would otherwise not receive the same level of inclusion; negative d ren who would otherwise not receive the same level of inclusion; negative b ecause categorising a person can be the first step towards excluding that b ecause categorising a person can be the first step towards excluding that p erson and violating his or her inherent dignity (Karr 2009).p erson and violating his or her inherent dignity (Karr 2009).P rofiling behaviours could lead to companies inferring or claiming to identify P rofiling behaviours could lead to companies inferring or claiming to identify d isabilities without the qualified diagnosis one would expect from medical d isabilities without the qualified diagnosis one would expect from medical p rofessionals. This has the potential to have lasting effects for a child and p rofessionals. This has the potential to have lasting effects for a child and b rings with it fundamental ethical questions over what constitutes appropriate b rings with it fundamental ethical questions over what constitutes appropriate u se by a private company of learner interactions, and what information and u se by a private company of learner interactions, and what information and i nterventions they suggest or do not suggest to school staff. Whereas chil-i nterventions they suggest or do not suggest to school staff. Whereas chil-d ren involved in medical research trials will have ethical oversight and clear d ren involved in medical research trials will have ethical oversight and clear d iscussion of the expectations of what will be done with both the main and d iscussion of the expectations of what will be done with both the main and i ncidental findings, no parallel processes exist for the deployment of AIED.i ncidental findings, no parallel processes exist for the deployment of AIED.f Right to privacy and right to data protectionT he reality is that today’s data protection legislation does not sufficiently T he reality is that today’s data protection legislation does not sufficiently p rotect children from increasingly invasive uses of personal information, p rotect children from increasingly invasive uses of personal information, s uch as their eye gaze, speed of response, gait or emotions – despite these s uch as their eye gaze, speed of response, gait or emotions – despite these 92. T he Matthew Effect, sometimes paraphrased as “the rich get richer while the poor get poorer” , takes its name fr om the “Parable of the Talents” in the Christian Bible’s Gospel of Matthew.
AI, education, human rights, democracy and the rule of law  P age 55being protected as biometrics in data protection law such as Convention 1 081089393 and the EU General Data Protection Regulation (GDPR). In any case,  and the EU General Data Protection Regulation (GDPR). In any case, t he right to privacy should not be conflated with data protection rights. t he right to privacy should not be conflated with data protection rights. P rivacy is both a protective right, for example from harmful discrimination, P rivacy is both a protective right, for example from harmful discrimination, a nd an enabling right, to rights such as freedom of expression and the right a nd an enabling right, to rights such as freedom of expression and the right t o assembly. However, the right to privacy is often infringed by certain data t o assembly. However, the right to privacy is often infringed by certain data p ractices in the context of AI in education.p ractices in the context of AI in education.D ata is at the heart of ML, which is the type of AI that has made such dramatic D ata is at the heart of ML, which is the type of AI that has made such dramatic p rogress in recent years, with ML systems automatically and continuously p rogress in recent years, with ML systems automatically and continuously c ollecting, aggregating, analysing and acting upon innumerable data points c ollecting, aggregating, analysing and acting upon innumerable data points g enerated by the user’s interaction with the system. g enerated by the user’s interaction with the system. [ ML] can make predictions about a person’s behaviour, state of mind, and identity [ ML] can make predictions about a person’s behaviour, state of mind, and identity b y sensing information that is not necessarily considered personal or private, b y sensing information that is not necessarily considered personal or private, s uch as facial expressions, heart rate, physical location, and other seemingly s uch as facial expressions, heart rate, physical location, and other seemingly m undane or publicly accessible data. This can have the effect of being invasive m undane or publicly accessible data. This can have the effect of being invasive o f a person’s sense of privacy, and can also have so-called “panoptic effects” by o f a person’s sense of privacy, and can also have so-called “panoptic effects” by c ausing a person to alter their behaviour upon suspicion it is being observed c ausing a person to alter their behaviour upon suspicion it is being observed o r analysed. (Leslie et al. 2021: 15)o r analysed. (Leslie et al. 2021: 15)T his classroom surveillance by means of AI tools is often compared with T his classroom surveillance by means of AI tools is often compared with t he gaze of a teacher; in short, if it is acceptable for a teacher to closely t he gaze of a teacher; in short, if it is acceptable for a teacher to closely m onitor their students, why might it not be acceptable for an AI tool to do m onitor their students, why might it not be acceptable for an AI tool to do t he same? However, there are fundamental differences. The AI approach is t he same? However, there are fundamental differences. The AI approach is m ore long-lasting: the data is retained by the commercial developer, stored m ore long-lasting: the data is retained by the commercial developer, stored o ff-site, analysed automatically, shared with others, used to benchmark and o ff-site, analysed automatically, shared with others, used to benchmark and c ompare hundreds of thousands of children, and forms a key part of their c ompare hundreds of thousands of children, and forms a key part of their b usiness model (the use of data to generate income). The human approach, b usiness model (the use of data to generate income). The human approach, o n the other hand, is personal, human and ephemeral. Ultimately, “children o n the other hand, is personal, human and ephemeral. Ultimately, “children s hould be ensured a free unmonitored space of development and upon s hould be ensured a free unmonitored space of development and upon m oving into adulthood should be provided with a ‘clean slate’ of any public m oving into adulthood should be provided with a ‘clean slate’ of any public o r private storage of data”.o r private storage of data”.9494A I-driven tools are increasingly being used, for example, to determine a A I-driven tools are increasingly being used, for example, to determine a l earner’s emotional state. The aim might be laudable: to move a learner from l earner’s emotional state. The aim might be laudable: to move a learner from a  negative emotional state to a positive emotional state which is generally a  negative emotional state to a positive emotional state which is generally a ssumed to be more conducive for learning, or to tailor the feedback or the a ssumed to be more conducive for learning, or to tailor the feedback or the c omplexity of the problems. However, while a human teacher is constantly c omplexity of the problems. However, while a human teacher is constantly a ssessing and acting upon the emotional state of their learners, automating a ssessing and acting upon the emotional state of their learners, automating t his process crosses a privacy Rubicon, especially when the analysis takes t his process crosses a privacy Rubicon, especially when the analysis takes p lace in proprietary systems.p lace in proprietary systems.N onetheless, while commercial AI in education organisations might claim to N onetheless, while commercial AI in education organisations might claim to e nsure that they collect minimal data and that the data that they do collect e nsure that they collect minimal data and that the data that they do collect a re protected, the use of personal data raises a number of complex problems a re protected, the use of personal data raises a number of complex problems 93. w ww.coe.int/en/web/data-protection/convention108-and-protocol. 94. EU Commission High Level Expert Group on AI (AI HLEG) (2019), “Policy and investment recommen-da tions for trustworthy Artificial Intelligence” , paragraph 28.3, h ttps://digital-strategy.ec.europa.eu/en/libr ary/policy-and-investment-recommendations-trustworthy-artificial-intelligence. 
Page 56  A rtificial intelligence and education(Elliot et al. 2018). The problems include how the data is stored and used ( Binns 2021). This means that the data is open to hacking and leaks, while ( Binns 2021). This means that the data is open to hacking and leaks, while e ven apparently anonymous data can increasingly be de-anonymised. In e ven apparently anonymous data can increasingly be de-anonymised. In o ther words, removing identifiers, such as a child’s name, from the data is o ther words, removing identifiers, such as a child’s name, from the data is n ow rarely sufficient.n ow rarely sufficient.f Right to transparency and explainabilityW hile not human rights, these data rights are important parts of data protec-W hile not human rights, these data rights are important parts of data protec-t ion laws around the world. It is increasingly well-known that ML systems are t ion laws around the world. It is increasingly well-known that ML systems are o ften opaque, either because they are proprietary or because their methods o ften opaque, either because they are proprietary or because their methods a re impenetrable. While there are many examples of AIED systems that stem a re impenetrable. While there are many examples of AIED systems that stem f rom academic research, the majority of AI in education systems have been f rom academic research, the majority of AI in education systems have been d eveloped by commercial organisations, whose business plans depend on d eveloped by commercial organisations, whose business plans depend on k eeping secret details about how they make their recommendations and k eeping secret details about how they make their recommendations and d ecisions. In any case, how ML, which is used in increasing numbers of AI in d ecisions. In any case, how ML, which is used in increasing numbers of AI in e ducation tools, generates its outputs is often unknown even to the developers e ducation tools, generates its outputs is often unknown even to the developers ( Rudin 2019). In other words, ML systems are often “black boxes” that are neither ( Rudin 2019). In other words, ML systems are often “black boxes” that are neither t ransparent nor explainable, because they are both technically complex and t ransparent nor explainable, because they are both technically complex and f requently proprietary. Further, any “explanation must be tailored to the context f requently proprietary. Further, any “explanation must be tailored to the context a nd provided in a manner that is useful and comprehensible for an individual, a nd provided in a manner that is useful and comprehensible for an individual, a llowing individuals to effectively protect their rights”. (Leslie et al. 2021: 15).a llowing individuals to effectively protect their rights”. (Leslie et al. 2021: 15).I n education, when a ML-based AI in education tool decides a child’s learning I n education, when a ML-based AI in education tool decides a child’s learning p athway or makes recommendations, while some do provide feedback and p athway or makes recommendations, while some do provide feedback and e xplanations, it should be possible for the teacher or parent to identify and e xplanations, it should be possible for the teacher or parent to identify and u nderstand why that decision has been made and on what parameters it u nderstand why that decision has been made and on what parameters it h as been based, and to override it if they so choose. However, while there h as been based, and to override it if they so choose. However, while there h as been extensive academic research in this area (e.g. Conati et al. 2018), h as been extensive academic research in this area (e.g. Conati et al. 2018), w e have been unable to find any easily available commercial AI in education w e have been unable to find any easily available commercial AI in education t ools that genuinely and effectively address this right to transparency and t ools that genuinely and effectively address this right to transparency and e xplainability.e xplainability.f Right to withhold or withdraw consentT he question of consent, whether it is genuine and how it might be revoked T he question of consent, whether it is genuine and how it might be revoked o nce personal data has been retained or modified in training data sets, also o nce personal data has been retained or modified in training data sets, also r aises important questions for AI product development. How do we ensure r aises important questions for AI product development. How do we ensure t hat children have genuinely assented to their data being collected and t hat children have genuinely assented to their data being collected and m onetised in AI systems, and how do we ensure that parental consent is given m onetised in AI systems, and how do we ensure that parental consent is given w ith sufficient understanding? When a school requires the use of AI tools, w ith sufficient understanding? When a school requires the use of AI tools, a  consent basis for processing personal data either by the school or by the a  consent basis for processing personal data either by the school or by the d ata processor will not be valid, because consent must be unambiguously d ata processor will not be valid, because consent must be unambiguously f reely given and able to be refused without detriment.f reely given and able to be refused without detriment.9595 Again, the argument  Again, the argument 95. Guidelines on Children’s Data Protection in an Education Setting (2020), Council of Europe C ommittee on Convention 108, T-PD(2019)06BISrev5.
AI, education, human rights, democracy and the rule of law  P age 57sometimes made is that teachers have been using educational technology in c lassrooms for decades without raising complex issues of consent. However, c lassrooms for decades without raising complex issues of consent. However, a gain, there is a qualitative difference between non-AI educational technoloa gain, there is a qualitative difference between non-AI educational technolo--g ies and AI-driven tools – tools that collect huge amounts of data, for many g ies and AI-driven tools – tools that collect huge amounts of data, for many t housands of interaction points, for many thousands of children, which are t housands of interaction points, for many thousands of children, which are t hen stored outside the classroom, aggregated, analysed and monetised. t hen stored outside the classroom, aggregated, analysed and monetised. A  final question is whether a child or their parent should have the right to A  final question is whether a child or their parent should have the right to w ithdraw their assent/consent to the use and reuse of the child’s data, after w ithdraw their assent/consent to the use and reuse of the child’s data, after t hat data has been collected, and possibly once it has already been absorbed t hat data has been collected, and possibly once it has already been absorbed w ithin the company’s data sets?w ithin the company’s data sets?f Right to be protected from economic exploitationD ata rights in different parts of the world may or may not address the D ata rights in different parts of the world may or may not address the q uestions of ownership and economic exploitation of the data created q uestions of ownership and economic exploitation of the data created b y and about children, by means of their interactions with commercial b y and about children, by means of their interactions with commercial A I tools while they are in mandatory education. If a child (or any adult for A I tools while they are in mandatory education. If a child (or any adult for t hat matter) creates a poem, a song, or a story, they own that creation. The t hat matter) creates a poem, a song, or a story, they own that creation. The s ituation with respect to the data that they create through their interaction s ituation with respect to the data that they create through their interaction w ith the AI system is not so clear. This is especially important given that w ith the AI system is not so clear. This is especially important given that t he protection of personal data goes beyond privacy to ensuring that the t he protection of personal data goes beyond privacy to ensuring that the c hild retains all rights to their own personal data: “child rights need to be c hild retains all rights to their own personal data: “child rights need to be fi rmly integrated onto the agendas of global debates about ethics and data fi rmly integrated onto the agendas of global debates about ethics and data s cience” (Berman and Albright 2017: 4).s cience” (Berman and Albright 2017: 4).N onetheless, the idea of personal data ownership, seeing data as an intel-N onetheless, the idea of personal data ownership, seeing data as an intel-l ectual property, is a US-centric approach, which may be contested from a l ectual property, is a US-centric approach, which may be contested from a E uropean human rights perspective: “the protection of personal data is a E uropean human rights perspective: “the protection of personal data is a f undamental right and that therefore personal data cannot be considered f undamental right and that therefore personal data cannot be considered a s a commodity”.a s a commodity”.9696 The further problem is that educational data is often  The further problem is that educational data is often n ot only about the child but about the parent and also about the teacher, n ot only about the child but about the parent and also about the teacher, f or whom it might be used to inform performance metrics. In other words, f or whom it might be used to inform performance metrics. In other words, i t would be impossible to separate out in practice what data the child  i t would be impossible to separate out in practice what data the child  o wns.o wns.H owever, when that data is being collected by a third party, such as a H owever, when that data is being collected by a third party, such as a c ommercial AI developer, whose exploitation of that data is a fundamental c ommercial AI developer, whose exploitation of that data is a fundamental c omponent of their AI products and business model, how data rights or c omponent of their AI products and business model, how data rights or c ontrol can be managed by children and their parents remains unclear. c ontrol can be managed by children and their parents remains unclear. D ata protection laws do protect children from commercial exploitation, D ata protection laws do protect children from commercial exploitation, a nd there is almost never a lawful basis for it in an educational and not a nd there is almost never a lawful basis for it in an educational and not c onsensual context – although this is not currently being sufficiently c onsensual context – although this is not currently being sufficiently e nforced by data protection supervisory authorities. Accordingly, it has e nforced by data protection supervisory authorities. Accordingly, it has 96. Dir ective (EU) 2019/770 of the European Parliament and of the Council of 20 May 2019 on certain aspec ts concerning contracts for the supply of digital content and digital services (2019), OJ L 136/1, R ecital 24.
Page 58  A rtificial intelligence and educationbeen argued that states should acknowledge that the digital environment e nables commercial exploitation of children in a variety of ways, and should e nables commercial exploitation of children in a variety of ways, and should e xtend the protection of Article 32 of the UNCRC in order to protect children e xtend the protection of Article 32 of the UNCRC in order to protect children f rom such practices (Van Der Hof et al. 2020). The United Nations Guiding f rom such practices (Van Der Hof et al. 2020). The United Nations Guiding P rinciples on Business and Human Rights (United Nations 2011) sets out P rinciples on Business and Human Rights (United Nations 2011) sets out s tandards and the scope of social responsibilities for businesses that are s tandards and the scope of social responsibilities for businesses that are o f relevance here.o f relevance here.A  final and perhaps less obvious relevant issue is the accumulation of A  final and perhaps less obvious relevant issue is the accumulation of d ata, and thus the power that comes with that data, by a small number d ata, and thus the power that comes with that data, by a small number o f big companies (in particular BigTech): “Overlapping with these human o f big companies (in particular BigTech): “Overlapping with these human r ights concerns is the concentration of power that AI affords to its most r ights concerns is the concentration of power that AI affords to its most i nfluential private and public sector developers and implementers” (Leslie i nfluential private and public sector developers and implementers” (Leslie e t al. 2021: 15). At present, this is less of an issue for AI in education, as e t al. 2021: 15). At present, this is less of an issue for AI in education, as m ost of the relevant companies are as yet too small to have achieved any m ost of the relevant companies are as yet too small to have achieved any d ominance. However, there are pockets of crowding out and monopold ominance. However, there are pockets of crowding out and monopol-i sation where a single company has been adopted at national or regional l evel. For example, where AI-assisted child safeguarding platforms have l evel. For example, where AI-assisted child safeguarding platforms have b een used in refugee camps run by global NGOs, observational data from b een used in refugee camps run by global NGOs, observational data from m edia reports and company marketing suggest those authorities tend to m edia reports and company marketing suggest those authorities tend to b uy a single solution.b uy a single solution.H owever, BigTech and the big education publishers (e.g. Pearson) are them-H owever, BigTech and the big education publishers (e.g. Pearson) are them-s elves investing millions of dollars into AI in education tools, such as Google s elves investing millions of dollars into AI in education tools, such as Google C loud’s AI-powered learning platform and Pearson’s IBM Watson Tutor.C loud’s AI-powered learning platform and Pearson’s IBM Watson Tutor.9797M eanwhile, the currently independent AIED companies are growing fast. M eanwhile, the currently independent AIED companies are growing fast. A ll of this suggests that concentration of power by commercial companies A ll of this suggests that concentration of power by commercial companies m ay soon become an issue that will need to be addressed.m ay soon become an issue that will need to be addressed.f Rights of parentsT he role of parents in realising a child’s right to education is enshrined in T he role of parents in realising a child’s right to education is enshrined in A rticle 26 (3) of the UDHR:A rticle 26 (3) of the UDHR:P arents have a prior right to choose the kind of education that shall be given P arents have a prior right to choose the kind of education that shall be given t o their children.t o their children.T he UNCRC is also clear that the best interests of the child shall be a pri-T he UNCRC is also clear that the best interests of the child shall be a pri-m ary consideration, placing a duty of care on all those who have a legal m ary consideration, placing a duty of care on all those who have a legal r esponsibility for the child (parents, legal guardians, schools and the r esponsibility for the child (parents, legal guardians, schools and the s tate), which should be exercised in a manner consistent with the evolving s tate), which should be exercised in a manner consistent with the evolving c apacities of the child. However, parental rights are complicated by the fact c apacities of the child. However, parental rights are complicated by the fact t hat a parent’s decisions may not always align with their child’s own views t hat a parent’s decisions may not always align with their child’s own views o r best interests, making it challenging for schools to address properly. o r best interests, making it challenging for schools to address properly. F or example, if a parent allows their child to use an AI-powered tool that F or example, if a parent allows their child to use an AI-powered tool that 97. P earson Education (2018), AI-based tutoring: a new kind of personalized learning , www.pearson.c om/ped-blogs/blogs/2018/11/ai-based-tutoring-new-kind-personalized-learning.html. 
AI, education, human rights, democracy and the rule of law  P age 59collects and shares large amounts of personal data, they might in effect b e waiving the child’s rights to privacy (UC Berkeley Human Rights Center b e waiving the child’s rights to privacy (UC Berkeley Human Rights Center R esearch Team, 2019).R esearch Team, 2019).9898I n any case, the question of whether the state and schools should respect I n any case, the question of whether the state and schools should respect a ny child’s or parents’ refusal for the child to be involved with educational a ny child’s or parents’ refusal for the child to be involved with educational t echnologies such as AI-based tools, without such a refusal adversely affect-t echnologies such as AI-based tools, without such a refusal adversely affect-i ng the child’s education, is yet to be tested in law. In particular, if data are i ng the child’s education, is yet to be tested in law. In particular, if data are b eing captured and processed on the basis of consent, such consent must b eing captured and processed on the basis of consent, such consent must b e freely given by parents/legal guardians and the child, and cannot be b e freely given by parents/legal guardians and the child, and cannot be a ssumed by the school.a ssumed by the school.3.1.5. Remedies and r edressT he introduction of any technology in education, such as AI, brings with it new actors with a r ange of aims and interests. As a result:Childr en are often politically voiceless and lack access to relevant information. They ar e reliant on governance systems, over which they have little influence, to have their r ights realised. This makes it hard for them to have a say in decisions regarding laws and policies tha t impact their rights. (The Committee on the Rights of the Child 2013: 3)99Similar ly:A s bearers of rights, children should have recourse to remedies to effectively exercise their  rights or to be able to act upon violations of their rights. Children should have the  right to access appropriate independent and effective complaints mechanisms. ( Council of Europe 2010: 19)100D espite the right to effective remedy enshrined in Article 13 of the Convention, when it  comes to the use of technology in education, these mechanisms are largely absent.3.2 AI, educ ation and democracy3.2.1.  What is meant by democracyD emocracy can be literally interpreted as “power of (or, to) the people” and it points t owards a model of government where the members of the community have the po wer to choose representatives through established procedures (for example, 98. UC Berkeley Human Rights Center Research Team (2019), “Memorandum on artificial intelligence and  child rights” , w ww.unicef.org/innovation/media/10501/file/Memorandum%20on%20A rtificial%20Intelligence%20and%20Child%20Rights.pdf99. C ommittee on the Rights of the Child, General comment No. 16 (2013) on State obligations r egarding the impact of the business sector on children’s rights, h ttps://www2.ohchr.org/english/bodies/cr c/docs/CRC.C.GC.16.pdf. 100. Guidelines of the Committee of Ministers of the Council of Europe on child-friendly justice  (2010), h ttps://rm.coe.int/16804b2cf3. 
Page 60  A rtificial intelligence and educationelections).101 Democracy embodies the ideals of individual autonomy, inclusiveness and  equality. At the same time, democracy presupposes that community members ar e able to make free and informed decisions (Ben-Israel et al. 2020; UNICEF and UNESC O 2007),102 thus pinpointing the interconnection with human rights and the rule of la w.3.2.2. Demo cracy and AIR egarding the role of digital technologies in modern society and their potential nega tive impact on democracy, Diamond noted that “once hailed as a great force f or human empowerment and liberation, social media – and the various related dig ital tools that enable people to search for, access, accumulate, and process infor-ma tion – have rapidly come to be regarded as a major threat to democratic stability and human fr eedom” (2019: 20).Similar  concerns extend beyond social media and other internet-based platforms, t owards the integration of AI technologies in various aspects of everyday life. Ongoing  discussions focus on their potentially negative impact on democracy in t erms of cyber-attacks, manipulation of information, propaganda or co-ordinated inauthen tic behaviour (Barrett et al. 2021; Hilton 2019; Nemitz 2018). Similarly, Leslie and  colleagues (2021) point out that AI can pose a threat to human values such as fr eedom of expression, association and assembly. To demonstrate the potential danger , they discuss the example of facial recognition systems that may discour-age , or even prevent, people exercising their democratic rights. In addition, AI can be  used to manipulate the information that is communicated online, depending on  the target audience (for example, it can choose what information to highlight based  on demographic factors). Or it can fabricate information that is inaccurate (f or example, videos or articles that spread false news) with the aim and result of impeding inf ormed decision making.A t the same time, the positive contribution of AI technologies to the public and pr ivate sectors is clear (from AI models for cancer diagnosis103 to extreme weather phenomena  prediction104), such that AI will inevitably become an increasingly wide-spr ead and integral part of our lives. Accordingly, it will – to some extent – change our  society. However, how it does so is not inevitable or predefined, but will be det ermined by human choices. This suggests that there is an urgent need for the public  sector to take strategic decisions and to co-ordinate actions for safeguard-ing  democracy and democratic values while preparing and realising the transition t owards new social and technological spaces (Ahn and Chen 2020), thus preparing citiz ens to live productively with AI.101. T he Council of Europe, Democracy, www.coe.int/en/web/compass/democracy. 102. w ww.right-to-education.org/sites/right-to-education.org/files/resource-attachments/A%20Human%20R ights-based%20Approach%20to%20Education%20for%20All_0.pdf. 10 3.Gr eenfield (2019), Harvard University blog, Artificial intelligence in medicine: applications, implic ations, and limitations , https://sitn.hms.harvard.edu/flash/2019/artificial-intelligence- in-medicine -applications-implica tions-and-limitations/. 104. BBC (2021), AI can predict if it will rain in two hours’ time , www.bbc.com/news/technology-58748934. 
AI, education, human rights, democracy and the rule of law  P age 613.2.3. Democracy and AI in educationC oncerning education, AI is usually communicated as a potential solution for sup-por ting its democratisation through personalisation and adaptation (Corbett et al . 1997) – for example, by making possible one-to-one instruction, an approach tha t has been contested (e.g. Holmes et al. 2021), or through the delivery of quality c ontent regardless of geographical or language restrictions (Chounta et al. 2021). M ore than 20 years ago, Aiken and Epstein (2000) proposed a set of ethical guide-lines  for designing AIED in an attempt to start a conversation on ethics and AIED, a c onversation that stalled for the next two decades, pointing towards the need to “ respect differences in cultural values” and to “accommodate diversity” . Similarly, Blanchar d (2015) explored the impact of cultural variations on AIED research and poin ted out that international representation both in terms of authorship (that is , who conducts the research) and population sampling is necessary to ensure good  quality and generalisable outcomes, as well as to reinforce community in volvement. One may argue that these discussions point towards fundamental humanistic  values related to democratic ideals, but to date there has been little r esearch in these areas.Ho wever, the use of AI in education especially in relation to democracy and demo- cr atic education raises a number of questions regarding the organisation of our educa tion systems, pedagogy and societal aspects, among others. Issues include:f To promote democracy and democratic values, an AIED system should match the  description “from all and for all” supporting the three pedagogic rights der iving from mutuality in education: enhancement, inclusion and participation (B ernstein 2000), pinpointing the interconnection between democracy and human  rights. Similarly, how can we support the design and deployment of  AIED systems that are community-originated, community-oriented and c ommunity-driven (Heimans et al. 2021)? Do educational institutions (schools, univ ersities and so on) have the capacity to act as communities for driving the  widespread application of AIED – and should they do so? What are the implica tions for communities that, due to technological or financial disparities, ar e not able to follow up with the design and deployment of AIED systems, or  for marginalised communities that are typically underrepresented in the sta te-of-the-art research? Could these disparities lead to a greater divide rather than tr ansforming education for all?f Democratic education presupposes open access and equity, meaning that ev eryone has access to the same quality of learning materials, conditions and oppor tunities. The relationship between democracy and public education is  well documented and discussed over time, and one could argue that the clear est example of democratic education in practice is public sector schools (D ewey 1903; Heimans et al. 2021; Sehr 1997; Stitzlein 2017). Accordingly, when  we think of AI, how can we ensure that all learners, regardless of cultural backg round, personal characteristics or financial status will have access to AIED  systems and AI-enhanced learning environments, especially taking into ac count that prominent AI and, specifically, AIED initiatives are led by IT for-pr ofit corporations (Nemitz 2018)?
Page 62  A rtificial intelligence and educationfModern AIED systems are mainly based on cognitive and knowledge modelling with  the aim of providing personalised instruction and content while AI-enhanc ed learning targets individual learners rather than learner groups (Holmes  et al. 2021; Leaton Gray and Kucirkova 2018). AIED systems, mainly the so -called intelligent tutoring systems, have been criticised for not reinforcing a ttitudes of partnership, solidarity, respect and sensitivity for the needs of other members  of the community but instead promote individuals, potentially at the e xpense of the collective (Kucirkova and Littleton 2017). On the other hand, AIED  research extends to collaborative and group learning contexts, for example aiming  to facilitate group formation (Stewart and D’Mello 2018) or to promote c o-creative dialogues (Griffith et al. 2021). How can we broaden, expand and c ommunicate relevant research to promote the design and deployment of socially -aware over individually-focused AIED systems? How can we deliver sy stems that aim to support learners of different abilities and in various learning c ontexts without creating a divide between the learner population? How can w e balance the benefits for the individual learner and the learning group as a  whole, leading to classrooms that act as micro-communities of established democr atic practice?f A particular challenge for ML models is that they inevitably represent the world as  a function of the past. Accordingly, if the data used for training ML models in troduced bias, so will be the resultant models (for a review of algorithmic bias  in education, see Baker and Hawn 2021). Similarly, learner-supporting AI sy stems can only infer and respond to the patterns of engagement of past users  of the system. Here, the bias might not be so obvious, but it is still real and  has significant consequences (Tuomi 2018). For example, past users of the  AIED systems, the early adopters, tend to come from school systems in mor e privileged countries, as that is where the tools are mostly developed, and  schools in those countries are more likely to be able to afford the new t echnologies (Pinkwart 2016; Schiff 2021). Inevitably, therefore, the resultant ML  models may better represent those more privileged learners, with uncertain c onsequences for less privileged learners. How can we create data sets and models  that are balanced and representative for all learner populations and tha t do not reinforce bias? Alternatively, how can we design methodological appr oaches that allow us to correct for bias, if that is even possible, and develop sy stems that safeguard equity?3.2.4. C ritical reflectionsR elated work has focused and elaborated on the risks that AI poses to practising, establishing  and sustaining democracy and democratic procedures, especially in t erms of the manipulation and fabrication of information, practices that threaten democr atic rights (e.g. surveillance systems) and so on (Hilton 2019; Nemitz 2018). W hen it comes to the use of AI in education – as a specific application domain – additional  concerns come into play that do not necessarily apply or are not taken in to account for general-purpose AI systems.
AI, education, human rights, democracy and the rule of law  P age 63As noted earlier, the “personalisation” of learning has been the driving force of edu-ca tional technology for around 100 years (Watters 2021), and it is now probably the most  widely made argument for the integration of AI in education. This raises multiple c oncerns. For example, is personalisation possible or even desirable – given that ML w orks by grouping data? Is it actually more homogenisation than personalisation? Similar ly, what potential divides might follow personalisation, and could these have e xplicit or implicit negative impacts on democracy? For example, who can have or aff ord access to AIED systems and consequently their potential benefits, and might personalised  learning result in uneven learning gains, with some learners benefiting mor e than others? Similarly, there are implications for AIED on the social aspects of lear ning. Schools and classrooms do not only disseminate subject knowledge and c ontent, but they also aim to educate individuals regarding democratic values and humanistic  principles; in other words, a classroom may act as a preparation stage f or the individual becoming a citizen in a democratic society. At this point, it is not clear ho w AIED systems take up or impact on this role.I t is critical to establish and foster informed public discussions around the design, dev elopment and deployment of AI systems for education, regardless of the sys-t ems’ purpose (either systems that aim to act as learner-supporting or as teacher-suppor ting AI). These discussions, following the definition of democracy, should pr imarily be led by the public sector (while AIED is fast becoming the preserve of the  commercial sector). They should be open to all stakeholders – teachers, parents, lear ners, administration, researchers, technology providers – to ensure multivocality and  communication on common ground. Further discussions should not focus on t echnological aspects but explicitly address the potential impact of AI technologies on  democracy. Although democracy and democratic values are considered well-k nown and straightforward topics, related work has pointed out that – even among public  sector stakeholders – such terms are either non-uniformly understood, or it is  not clear why and how technology could have an impact on them (Barrett et al. 2021).  Existing work regarding the challenges around AI and democracy is valuable, but  at the same time there is the need for further elaboration on topics that closely r elate to AI in education and how to safeguard and promote democratic ideals in the dig ital era.3.3. AI, educ ation and the rule of law3.3.1.  What is meant by the rule of lawT he rule of law provides the institutional basis for safeguarding both democratic par ticipation and the protection of fundamental rights and freedoms. An independent and  impartial judiciary, which ensures citizens due judicial processes and fair and equal tr eatment under the law, acts as a guarantor of recourse whenever fundamental rights or fr eedoms could be breached. (Leslie et al. 2021: 13)I n a comprehensive review of the teaching of AI and the law in the USA, Johnson and Shen  write that “sectors as diverse as patent law, criminal law, torts, human rights, clima te change, healthcare, finance, and transportation all face imminent and abrupt 
Page 64  A rtificial intelligence and educationchanges in light of rapid advances in AI and ML technology” (2021: 25). Interestingly, the  education sector is not listed. However, it should be concluded that there is a pr essing need for ethical guidance for, and regulation of, AI.I n this section, the application of the rule of law with respect to AI in education is illustr ated by relevant legislation and legal frameworks, by work on regulation of AI sy stems, research on AI in education and law and through examples of interpreta-tions  and in reported cases of violations. The section ends with revealed gaps both in  research on AI, education and the rule of law, and in regulatory and legal aspects on the applica tion and impact of AI in the educational sector.3.3.2. I nternational legal frameworksL eslie et al. (2021) conclude that presently there are no international laws focused specifically  on AI. However, a number of existing legal instruments that set out people ’s fundamental rights (cf. section 3.1) are relevant, including:f The European Convention on Human Rights f The European Social Charter (ESC)f The International Bill of Human Rights (comprising the Universal Declaration of  Human Rights, the International Covenant on Economic, Social and Cultural R ights and the International Covenant on Civil and Political Rights and its two Optional P rotocols)f The Charter of Fundamental Rights of the European Union (CFR)f United Nations Convention on the Rights of the Child (UNCRC)f The Convention on the Rights of Persons with DisabilitiesI n particular, the right to non-discrimination and the right to privacy are applicable f or AI applications in general, and thus are also relevant for the use of AI in educa-tion.  Existing legal instruments that protect particular groups (e.g. minorities) are also of r elevance.L eslie et al. (2021) distinguish between soft law (non-binding, voluntary compliance) and  hard law (legally binding) and summarise that while current legal mechanisms t o some extent protect individual rights, the risks associated with AI are not yet suf-ficien tly addressed. This will require not only legal and regulatory efforts, but also public  oversight in the design, development and use of AI systems. This is challenging g iven the uncertainty and ambiguity of AI systems and a need to balance the benefits of  AI innovation and protection of human rights. These issues are certainly relevant f or the use of AI in education and are particularly crucial when children and youth ar e involved. Furthermore, it is recognised that AI systems (and their data flow) often cr oss multiple jurisdictions, making it more complicated. This arises in the use of AI in  education, often raising questions of data rights, learner profiling and cultural impac t on educational systems.I n their historical review of the origins and meaning of data protection, Korff and G eorges (2020) describe how the EU’s GDPR was adopted to meet the challenges posed  by new technologies and services such as profiling, algorithmic decision mak ing and AI, where the EU Commission saw “strong, high-level data protection 
AI, education, human rights, democracy and the rule of law  P age 65as an essential condition for gaining trust in the online environment” . Used together with  national education laws and data regulations, it provides some of the strongest da ta protection for learners in the world. For those developing AI applications for schools  in member states, it is necessary to comply with the requirement of data pr otection by design and by default as stipulated in Article 10 of Convention 108 or, in  addition, the GDPR Article 25. Similarly, in a review of Hildebrandt’s (2015)  Smart t echnologies and the end(s) of law , Kerr writes that “Hildebrandt instead forewarns tha t the only thing able to save the Rule of Law as we know it is ‘legal protection by desig n’”105 (2017: 92) for technology that impacts human behaviour. Legal protection b y design “aims to ensure that legal protection is not ruled out by the affordances of the  technological environment that determines whether or not we enjoy the sub-stanc e of fundamental rights” (Hildebrandt 2019: 16). In the GDPR this is addressed b y the legal obligation to conduct a Data Protection Impact Assessment (DPIA).106S chool owners (e.g. municipalities) are required to carry out a DPIA that identifies and  evaluates the risks associated with the use of digital tools in schools when the t ools engage certain processing operations. Thus, a DPIA is included for all “learning with  AI” learner- and teacher-supporting AI systems. This is challenging because it is a c omplex and time-consuming task, and requires high competence. To aid this process, f or example, the Norwegian Data Protection Agency provides a list of operations107tha t always requires a DPIA, including processes meeting two or more criteria (in some  cases only one): evaluation or scoring, automated decision making with legal or  similar significant effect, systematic monitoring, sensitive data or data of a highly personal  nature, data processed on a large scale, matching or combining data sets, and  data concerning vulnerable data subjects. Specifically named processes that ar e relevant for education include: processing of personal data for the purpose of ev aluating learning, coping and well-being in schools or kindergartens (at all levels of  education), camera surveillance in schools or kindergartens, the processing of personal  sensitive or highly personal data on a large scale for the training of algo-r ithms, and the processing of personal data to systematically monitor proficiency, sk ills, scores, mental health and development.Regula tion of AII n December 2020, the CAHAI Secretariat published a report “Towards regulation of AI  systems”108 addressing the impact of AI on human rights, democracy and the rule of  law, providing guidelines on AI ethics, an analysis of international legally binding 105. H ildebrandt M. (2019), “10. ‘Legal by Design’ or ‘Legal Protection by Design’?” Law for Computer S cientists, (see section 10.3), h ttps://lawforcomputerscientists.pubpub.org/pub/gfzd6k0g/release/12. 10 6.W olford B. (GDPR EU), Data Protection Impact Assessment (DPIA) , https://gdpr.eu/da ta-protection-impact-assessment-template. 107. Da tatilsynet (The Data Protection Supervisory Authority Norway), Processing operations subject t o the requirement of a data protection impact assessment , www.datatilsynet.no/globalassets/global/dok umenter-pdfer-skjema-ol/regelverk/veiledere/dpia-veileder/dpialist280119.pdf. 108. C ouncil of Europe (2020), CAHAI, “Towards regulation of AI systems: global perspectives on the  development of a legal framework on artificial intelligence systems based on the Council of  Europe’s standards on human rights, democracy and the rule of law” , w ww.coe.int/en/web/ar tificial-intelligence/-/-toward-regulation-of-ai-systems-. 
Page 66  A rtificial intelligence and educationinstruments, and reviewing three national perspectives on AI systems regulation. W hen defining AI for regulatory purposes they write that “A complicating factor is  that legal definitions differ from pure scientific definitions whereas they should meet  a number of requirements (such as inclusiveness, preciseness, comprehen-siv eness, practicability, permanence), some of which are legally binding, and some ar e considered good regulatory practice” (Ben-Israel et al. 2020: 23). With respect t o AI and the rule of law, they make six statements (ibid.: 31-32) about how AI is a double -edged sword with both potentials and dangers related to efficiency, legit-imac y and trust, authority in and out of the courts, terms of service versus the rule of  law, enforcement of trustworthy AI and threats to the law versus strengthening the  law. While none of these are directed in particular at education, all are relevant t o the application of AI in many facets of education (e.g. governance, learning, monit oring, assessments), namely in learner-, teacher- and institutional-supporting AI  systems. In particular, their strategies for “awareness” , “measure for compliance, ac countability and redress” , “protecting democracy, democratic structures and the rule of la w” should be conceptualised within education.T he European Commission, as part of their work on a digital strategy, is concerned with  fostering a European approach to AI109 which includes AI excellence and trust-w orthiness. This includes a communication that states that “Europe must act as one t o harness the many opportunities and address challenges of AI in a future-proof manner , ”110 and a regulatory framework. In April 2021, the European Union proposed the  Regulation on Artificial Intelligence, or the Artificial Intelligence Act,111 (AI Act) which  will be the first law on AI by a major regulator anywhere. The AI Act “seeks to la y down harmonised rules for the development, placement on the market and use of  AI systems which vary by characteristic and risk [high, limited, minimal]” (Veale and B orgesius 2021: 97). It is a legal framework that promotes the use of AI and addresses the  associated potential risks (Schwemer et al. 2021). The draft act112 recognises that, “ The use of AI with its specific characteristics (e.g. opacity, complexity, dependency on  data, autonomous behaviour) can adversely affect a number of fundamental r ights enshrined in the EU Charter of Fundamental Rights (‘the Charter’). ” Education and  training, identified as a critical area, is mentioned with respect to minimising the  risk of erroneous or biased AI-assisted decisions, especially related to assessing individuals  in, or trying to gain admission to, educational and vocational training institutions , cases which are identified as high risk, and to protecting the vulnera-bilities  of children. With respect to the values of the Council of Europe, Schwemer,  109. E uropean Commission (2021), Communication on Fostering a European approach to Artificial I ntelligence, h ttps://digital-strategy.ec.europa.eu/en/library/communication-fostering-european-appr oach-artificial-intelligence. 110. E uropean Commission (2021), Coordinated Plan on Artificial Intelligence 2021 Review, h ttps://dig ital-strategy.ec.europa.eu/en/library/coordinated-plan-artificial-intelligence-2021-review. 111. Sioli L. (2021), A summary presentation on the act by the European Commission, w ww.ceps.eu/wp -content/uploads/2021/04/AI-Presentation-CEPS-Webinar-L.-Sioli-23.4.21.pdf. 112. R egulation of the European Parliament and of the Council, Laying down harmonised rules on ar tificial intelligence (Artificial Intelligence Act) and amending certain Union legislative acts, C OM(2021) 206 final, (2021 draft), (para 3.5), h ttps://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?ur i=CELEX:52021PC0206&from=EN. 
AI, education, human rights, democracy and the rule of law  P age 67Tomada and Pasini write that:it  is noteworthy that the proposal does not follow a rights-based approach, which w ould, for example, introduce new rights for individuals that are subject to decisions made  by AI systems. Instead, it focuses on regulating providers and users of AI systems in a pr oduct regulation-akin manner. (2021: 6).3.3.3. Resear ch on AI in education and the rule of lawAI  and the rule of law has already been a field for research for some time, with its dev elopment following the general trends in AI research over the last decades (Leslie et  al. 2021; Surden 2019). Surden (2019) summarises its history113 as a move from ear ly academic endeavours centred on knowledge and rule-based legal systems in the  1970s, through the development of formal models of legal argument and com-puta tional models of legislation and legal rules in the 1980s and 1990s, to a focus fr om 2000 on machine-learning approaches, with an emergence of legal technology SMEs tha t aim to make law more efficient or effective.Sur den (2019) also distinguishes between AI in the practice of law (e.g. discovery for litiga tion or predictive coding and technology-assisted law), AI in the administration of  law (e.g. legal decision making or in policing) and AI and “users” of law (e.g. people using  legal self-help systems or legal expert chatbots). Furthermore, he identifies c ontemporary issues including bias in algorithmic decision making, interpretability of  AI systems, transparency around how AI systems are making their decisions and def erence to automated decision making, in line with recognised challenges for the AI  and its application. While describing AI in law in general, each of these contem-por ary issues are extremely relevant to understanding and evaluating the use of AI in educa tion, in particular in light of the GDPR.T hree examples of research that could be said to have a relation to AI in education and the  law are: work on algorithmic decision making for admission to higher education, r esearch on data and algorithmic literacy and research to support law education. With an  increasing use of algorithmic decision-making systems in general, “fairness concerns ar e gaining momentum in academic and public discourses” (Marcinkowski et al. 2020: 122)  due to biases in the training data. Interested in perceptions of (un)fairness of the  application of algorithmic decision making for admissions in higher education, M arcinkowski and colleagues (2020) carried out a survey of 304 students at a German univ ersity to assess their attitudes and perceptions of algorithmic versus human decision  making. They found that students rate algorithmic decision making higher than  human decision making with respect to procedural and distributive fairness; they  are perceived as more objective and fairer. This is interesting when compared t o medicine where human decision making is seen as superior to AI.114W ork on competence frameworks for data and AI literacies, for citizens in general and  for particular professions, often include both the technological dimension and 113. S ee Bench-Capon et al. (2012), a review of 55 papers presented during the first 25 years of the I nternational Conference on AI and Law.114. S ee: w ww.nature.com/articles/s41562-021-01146-0. 
Page 68  A rtificial intelligence and educationhuman dimensions of AI literacy such as aspects of data privacy, data protection and  personal rights. These literacies have a legal dimension and also are aimed at social  responsibility and democracy in the use of data and algorithms (Ben-Israel et al . 2020). One example is from Atenas and colleagues, who include data governance as a key lit eracy:Da ta governance can be understood as the policies and regulations in place for deploying and  presenting data in regards with its accessibility, usability, integrity and security-based da ta standards, norms and laws. (2020: 8)A nother example is the updated European Digital Competence Framework for C itizens – DigComp 2.2 (Vuorikari et al. 2022), which recognises that every citizen needs  to be cognisant in the use of their own, and other data, in the use of algorithms tha t manipulate this data, being aware of their right to privacy and that laws and r egulations are followed.A nother line of research is related to the use of AI in legal education. Practising ar gumentation (Lynch et al. 2007) or writing analytics in a civil law degree (Knight et al . 2018) are both examples of learning with AI.3.3.4. A pplying the rule of law to AI in educational practiceM ost of these examples involve institution-supporting AI (for administration of marks, admission,  attendance, fees), while two are focused on learner-supporting AI and the  use of adaptive algorithms in school, and the last on input to a new education la w that takes into account AI in education.AI and gr ade predictionI n 2020, two cases challenging the use of algorithms related to high school stu-den t exams were raised. The first, in the UK, was the use of algorithms to estimate A -level results, and the second, in Norway, was a challenge to the International Bac calaureate Organization’s use of an awarding algorithm in the calculation of final g rades.Dig ital rights’ organisation Foxglove threatened to take legal action against Ofqual,115the  government body that regulates qualifications, exams and tests in England, on  the grounds that the algorithm being used to determine students’ estimated A -level results potentially violated the UK Data Protection Act. The claim argues that (i)  the algorithm is not grading students, rather the school, resulting in significant disadv antages for students in poor schools and advantages for small, rich schools, and  (ii) this automation of such decision making in a situation with major impact f or the individual student potentially violates the GDPR Article 22, and the UK Data P rotection Act.115. Dar k (2020), UK: Legal action threatened over algorithm used to grade teenagers’ exams , www.sta tewatch.org/news/2020/august/uk-legal-action-threatened-over-algorithm-used-to-grade-t eenagers-exams/; and BBC (2020), A-levels and GCSEs: How did the exam algorithm work?  www.bbc .com/news/explainers-53807730. 
AI, education, human rights, democracy and the rule of law  P age 69In May 2020, Datatilsynet, the Norwegian DPA, requested116 that the International Bac calaureate Organization (IBO) explain their awarding algorithms that calculated final  grades for individual students based on student coursework, teacher-delivered pr edicted grades, as well as historical prediction data for an individual school.117T his method was taken into use as the final exams could not be written due to the C ovid-19 pandemic. The fear was that the calculation of the individual grades of IB  students was based on an automated decision-making process118 without room f or meaningful human assessment. This raised several questions with regard to the  processing of personal data pursuant to Article 58(1)(a) of the GDPR and in par ticular Article 5(1)(a), (c) and (d) and Article 22(2) and (3). The intention was tha t Datatilsynet would order the rectification of the final IB grades.119 While the ac tion resulted in changes, and some students received higher grades, it meant tha t (i) Datatilsynet did not have the competence to challenge them further, and (ii)  the IBO main office is in the UK, and at that time, as the UK was still part of the EEA,  Datatilsynet could not make a decision against IBO. Thus, the case was closed (see also C yndecka 2020).I n both cases, the final exam results were estimated based on historical data – not the  individual student’s previous grades, but previous years’ grades at the school. T his unfairly benefited students in previously successful schools, typically those in higher  socio-economic districts, and penalised students in lower-achieving schools, t ypically those in more challenged districts. This approach, which is far from the dominan t rhetoric of “algorithmic personalisation” , had serious consequences for individual  learners, impacting negatively on their access to higher education or en try to the world of work.Biometric da ta use in schoolsDa tainspektionen, the Swedish Authority for Privacy Protection (DPA), fined a Swedish school  €20 000 for running, albeit with the consent of the students, a facial recog-nition  pilot that kept track of student attendance.120 The school was found to have unla wfully used sensitive biometric data, failed to carry out an adequate impact assessmen t, and had not consulted the DPA. Given the clear imbalance between the da ta subject (the student) and the controller (the school), Datainspektionen ruled tha t consent was not a valid legal justification.116. Da tatilsynet (Data Protection Supervisory Authority Norway), “Order to provide information –  International Baccalaureate Organization – Awarding model and grading system” , www .da tatilsynet.no/contentassets/ea9284bbfcb64f819b2171228bc912a4/ibo---order-to-provide-inf ormation-by-24-july-2020.pdf. 117. I nternational Baccalaureate Organization (2020), Awarding May 2020 results further information , w ww.ibo.org/news/news-about-the-ib/awarding-may-2020-results-further-information. 118. w ww.efta-studies.org/post/a-dystopian-story-about-covid-19-artificial-intelligence-setting-g rades-and-the-gdpr. 119. Da tatilsynet (2020) The Norwegian DPA intends to order rectification of IB grades , www.datatilsynet.no/en/new s/2020/the-norwegian-dpa-intends-to-order-rectification-of-ib-grades. 120.    European Data Protection Board (2019), Facial recognition in school renders Sweden’s first GDPR fine , https://edpb.europa.eu/news/national-news/2019/facial-recognition-school-renders- sw edens-first-gdpr-fine_sv. 
Page 70  A rtificial intelligence and educationSimilarly, the Polish DPA fined a Polish primary school €5 000 for the illegal use of childr en’s biometric data without a legal basis, even though the school obtained the da ta and processed them on the basis of the written consent of the parents or legal guar dians.121 The school was using a biometric reader at the entrance to the school can teen to identify the children and verify the payment of the meal fee. The Polish DP A concluded that the processing of biometric data was both disproportionate and  unnecessary for achieving the goal of identifying a child’s entitlement to receive lunch.  They also highlighted that other forms of identification could be used.B oth cases highlight the imbalance between the use of an individual’s sensitive personal da ta and the goal of the school (see also King and Persson 2022).U se of AI systems’ data in schoolsA s part of Datatilsynet, the Norwegian Data Protection Agency, a sandbox for AI has  been created.122 One project examined the use of learning analytics and AI in an  adaptive application to be used in schools in Norway. This raised a number of questions  concerning the privacy and data protection of learners whose personal da ta are being processed by algorithms (Sluttrapport – AVT-Project). These were addr essed by applying the General Data Protection Regulation and the national la w on education. The final report123 presents a discussion of the legal basis for pr ocessing the personal data of learners with the purpose of providing adapted educa tion, which is guaranteed by law, and the development of the said algorithms. T he findings of this work will be valuable input in an update of the Norwegian educa tion law.3.3.5. C ritical reflectionsS everal gaps related to AI, education and law have been identified. First, in their chapt er “Landscape of legal instruments” (2021), Leslie and colleagues name several domain-specific  legal instruments for cybercrime, biomedicine and aviation – but they  do not identify any specific legal instrument for the education sector. This is a w eakness and a danger which urgently needs to be addressed.S econd, research on AI and the law in education is scarce, although with the promo-tion  of AI as a game changer for education, there is a need for research (from a legal perspec tive) on (i) data protection and rights, (ii) legal implications of algorithms and  bias, (iii) rights related to transparency and explainability of algorithms and (iv) lit eracy of stakeholders (from those creating laws and regulations to school owners, t eachers, learners, parents and providers of the technologies) with regard to their r ights.121. Ur ząd Ochrony Danych Osobowych (Data Protection Supervisory Authority Poland) (2020), Fine for pr ocessing students’ fingerprints imposed on a school , https://uodo.gov.pl/en/553/1102. 122. w ww.datatilsynet.no/en/regulations-and-tools/sandbox-for-artificial-intelligence. 12 3.w ww.datatilsynet.no/regelverk-og-verktoy/sandkasse-for-kunstig-intelligens/f erdige-prosjekter-og-rapporter/avt-sluttrapport. 
AI, education, human rights, democracy and the rule of law  P age 71Finally, given the growth of and complexity of AI in society, and the legal implications, ther e is also a pressing need for education lawyers on AI in general (Johnson and Shen  2021), and we would argue that this needs to include the legal issues related t o AI in education in particular. For example, Johnson and Shen (2021: 28) provide a  comprehensive overview of teaching AI and law in the USA124 and recommend tha t “law schools that do not offer a course in Law and AI should do so … and for those  schools that already have an introductory course, we suggest that AI issues be  more broadly engaged throughout the curriculum through dedicated courses and  by revising current course offerings” . Of the categories of courses offered in the  USA (e.g. AI and healthcare, AI and war/national security, AI and cybersecurity), ther e are currently no courses being offered about AI and education. The need for str engthening law education is supported by the Shanghai Initiative on Artificial I ntelligence and Future Rule of Law,125 which advocates “broadening the teaching c ontent of AI and other specialties on the basis of law discipline, paying attention t o the cross-integration of AI and law education, and cultivating a group of talents with legal lit eracy and knowledge of AI technology” (Cui 2020: 197).O pen questionsR ecommendation CM/Rec(2019)10 on developing and promoting digital citizenship educa tion,126 adopted by the Committee of Ministers on 21 November 2019, recom-mended  that governments of member states review their legislation, policies and pr actices, including learning frameworks, to ensure that they are aligned with the r ecommendations. This is especially urgent in relation to the use of AI in education.A s noted earlier, processing a child’s personal data in educational settings has par-ticular  complexity due to the non-consensual setting in which children and families ar e disempowered – which affects the freely given nature of consent. In particular, childr en cannot (or rarely in member state law) enter into contracts.T he rights bearers are not only children, but also the parents or legal guardians. T he purpose of going to school and the reasonable expectations of families of any associa ted data processing is to exercise and fulfil the child’s right to education. As discussed  earlier, this comes with associated obligations – to respect the rights and philosophical  beliefs of the parent and further legal obligations around the rights of the child with a disabilit y, or minority and indigenous children.A ccordingly, there are three key and challenging questions that need to be addressed.1. C an children be required to use an AI system that exploits their behaviours (thr ough the data processed from their interactions) in the interests of the institution,  any third party, or for commercial product development or 124. O f 197 law schools, only 26% offer at least one law and AI course, and only half of these offer multiple c ourses.125. A result from the high-level seminar on artificial intelligence and the rule of law, hosted by the Shanghai La w Society during the World AI Conference 2018. 126. R ecommendation CM/Rec (2019)10 of the Committee of Ministers to member States on develop-ing  and promoting digital citizenship education, h ttps://search.coe.int/cm/Pages/result_details.asp x?ObjectID=090000168098de08. 
Page 72  A rtificial intelligence and educationenhancement, in particular where the child’s personal data are retained as AI-model tr aining data?2. I f other less intrusive methods of performing the task are available and some schools  choose to teach children without sending their personal data to an AI  company, can AI ever meet the tests of necessity and proportionality and be la wful at all?3. M ust schools respect parents or children’s wishes, and where applicable in member  state data protection law, the right to object and the right to restrict pr ocessing, or can a school lawfully refuse, making the use of certain products c ompulsory for all learners in practice?
 Page 73PART IVC onclusion  and a needs analy sis
Page 74  A rtificial intelligence and education4.1. ConclusionT his report set out to explore the multiple connections between AI and edu-ca tion through the lens of the Council of Europe’s mandate to protect human r ights, to support democracy and to promote the rule of law. As we did so, while  we acknowledged the potential of AI for education, we encountered and dis-cussed  much hyperbole, identified many important challenges and raised multiple questions . Most importantly, how do we ensure that AI&ED protects and does not under mine human rights, democracy and the rule of law? To begin with, what is the “ right kind” of AI in education?A re the AI technologies being introduced in schools and other educational settings addr essing the right educational tasks? Are they enhancing learning as an essentially human  and social activity, or aiming to make learning “more efficient”? Are they desig ned to support, or to replace, teachers? Are they personalising learning pathways t o prespecified learning content, mainly preparing students for exams, or supporting personalised  learning outcomes, enabling students to achieve their individual aims and pot ential? (Holmes 2020)127I n parallel, on the other side of the AI&ED coin, what should be taught about AI, to our childr en and our citizens, in our schools and universities and in vocational education and  lifelong learning? How do we ensure that we move beyond focusing exclusively on  the technological dimension of AI to instead give equal attention to the human dimension  of AI – issues such as the impact of AI on human rights, autonomy and agenc y, alongside questions of transparency, fairness, trustworthiness and ethics.Giv en the novelty of our perspective on such a fast-growing domain of AI, we do not claim  that this report provides definitive answers. Instead, we hope our sometimes deliber ately provocative writing prompts more questions than answers, in order to pr ovide a stake in the sand for future related work being undertaken by the Council of  Europe and its member states. We conclude the report in the same light, with a pr ovisional and sometimes provocative needs analysis – identifying a diversity of needs  that we hope will stimulate further critical discussion about AI&ED through the lens of human r ights, democracy and the rule of law.4.2. A needs analy sisA s noted, the key purpose of the following provisional needs analysis is to stimulate and  inform further critical debate – between learners, educators, AI researchers, com-mer cial developers, policy makers and all other stakeholders. The identified needs are based  on the premise that AI in and of itself is not problematic and recognises that wha t is instead potentially problematic is how AI is developed, trained and applied in educa tional contexts, who the AI targets and who are the real beneficiaries.f We need to identify and act upon linkages across the Council of Europe’s work, t o increase understanding in and between policy makers of the challenges tha t AI poses across the directorates and member states.127. w ww.nesta.org.uk/blog/right-kind-ai-education
Conclusion and a needs analysis   P age 75fWe need a better understanding of the diversity of connections between AI  and education, and not be limited by current approaches (that tend to under emphasise the human dimension of AI).f We need more evidence (i.e. large-scale independent research, including from nonWEIRD – western, educated, industrialised, rich and democratic – countries) and  less hyperbole about the connections between AI and education, which in tur n will require more funding.f We need a better understanding of what counts as evidence. Research must go  beyond simple metrics like academic progress to consider the broader impac t of an AI tool on learners’ cognition, mental health and human rights.f We need to avoid automating poor pedagogic practices (e.g. instructionism and  exam proctoring) and instead focus on using the power of AI to address genuine  education “wicked problems”128 (e.g. inclusion, engagement and assessmen t).f We need appropriate, robust regulation, addressing human and child rights, bef ore AI tools are introduced into classrooms (in a process similar to medicine’s st epped safety trials), which addresses the technology’s full life cycle.f We need to recognise that there is a qualitative difference between teachers and  AI-driven tools that are notionally doing the same thing (the AI tools are outside  the system, commercially owned, proprietary and rarely transparent).f We need to ensure that parents are able to exercise their democratic rights in pr ocurement decisions (e.g. of AI-driven tools) that might affect their child’s dev elopment and right to education.f We need school and lifelong-learning curricula that address both the human and  technological dimensions of AI, to ensure that everyone better understands both ho w AI works and its potential impact on all our lives.f We need to ensure ethics by design (covering issues such as bias, transparency, choic e of pedagogy) for all AI-driven tools proposed for use in educational c ontexts, to facilitate rather than undermine innovation.f We need to ensure that children are not forced to accept being compulsory r esearch subjects or being compulsorily involved in product development simply b y exercising their right to education.f We need to ensure that data rights and intellectual property rights remain e xplicitly with the learners (for example, if state-funded schools are being used t o develop AI models, the models should at least be open access).f We need appropriate professional development for teachers (as well as for administr ators and policy makers), so that they are able to make informed decisions about which AI t ools might be appropriate for their classroom.128. F or a helpful explanation of “wicked problems” , see www.stonybrook.edu/commcms/wick-ed-pr oblem/about/What-is-a-wicked-problem. Wicked problem characteristics include: They do not  have a definitive formulation. Their solutions are not true or false, only good or bad. There is  no way to test the solution to a wicked problem. Their solutions are irreversible. There is no end  to the number of solutions or approaches to a wicked problem. All wicked problems are essen tially unique.
Page 76  A rtificial intelligence and educationfWe need multidisciplinary approaches, bringing together educators, learners and  parents, learning scientists and philosophers, computer scientists and AI eng ineers, commercial developers and governments.f In short, we need the application and teaching of AI in education to prioritise and facilita te human rights, democracy and the rule of law.
 Page 77ReferencesA ccess Now (2018), Human rights in the age of artificial intelligence , available at www .ac cessnow.org/cms/assets/uploads/2018/11/AI-and-Human-Rights.pdf, accessed 23 June 2022. A guirre A. et al. (2021), AI loyalty by design: a framework for governance of AI , Social S cience Research Network, SSRN Scholarly Paper ID 3930338, available at h ttps://papers .ssrn.com/abstract=3930338, ac cessed 23 June 2022.A hn M. J. and Chen Y.-C. (2020), Artificial intelligence in government: potentials, chal-lenges , and the future, The 21st Annual International Conference on Digital Government R esearch, pp. 243-52, available at h ttps://doi.org/10.1145/3396956.3398260, accessed 23 June 2022.  A iken R. M. and Epstein R. G. (2000), “Ethical guidelines for AI in education: starting a  conversation” , International Journal of Artificial Intelligence in Education  Vol. 11, pp. 163-76. A ikman S. and Unterhalter E. (2005), Beyond access: transforming policy and practice for gender  equality in education , Oxfam GB/Practical Action Publishing, available at h ttps://o xfamilibrary.openrepository.com/handle/10546/115410, ac cessed 23 June 2022.A nderson J. R. et al. (1995), “Cognitive tutors: lessons learned” , The Journal of the L earning Sciences Vol. 4, No. 2, pp. 167-207.A nuradha J. et al. (2010), “Diagnosis of ADHD using SVM algorithm” , Proceedings of the  Third Annual ACM Bangalore Conference , pp. 1-4, available at h ttps://dl.acm.org/doi/10.1145/1754288.1754317 , ac cessed 23 June 2022.A ristotle (2009), The Nicomachean ethics , Brown L. (ed.), Ross D. (tr.), (rev. edn), Oxford Univ ersity Press, Oxford.A rnold K. E. and Pistilli M. D. (2012), “Course signals at Purdue: using learning analytics  to increase student success” , LAK12: Proceedings of the 2nd International C onference on Learning Analytics and Knowledge , pp. 267-70, available at h ttps://doi.or g/10.1145/2330601.2330666, ac cessed 23 June 2022.A rntz M., Gregory T. and Zierahn U. (2016), The risk of automation for jobs in OECD c ountries: a comparative analysis , OECD, available at h ttps://doi.org/10.1787/5jlz9h-56dv q7-en, ac cessed 23 June 2022.A shrafi F. and Javadi A. (2020), “Correct characteristics of the newly involved arti-ficial  intelligence methods in science and technology using statistical data sets” , Int ernational Journal of Modern Engineering Technologies  Vol. 2, No. 2.A tenas J., Havemann L. and Timmermann C. (2020), “Critical literacies for a datafied societ y: academic development and curriculum design in higher education” , Research in  Learning Technology  Vol. 28, available at h ttps://doi.org/10.25304/rlt.v28.2468, ac cessed 23 June 2022.
Page 78  A rtificial intelligence and educationBaker M. J. (2000), “The roles of models in artificial intelligence and education research: a  prospective view, Journal of Artificial Intelligence and Education Vol. 11, pp. 122-43.Baker  R. S. and Hawn A. (2021), Algorithmic bias in education , EdArXiv Preprints, a vailable at h ttps://doi.org/10.35542/osf.io/pbmvz, ac cessed 23 June 2022.Baker  T., Smith L. and Anissa N. (2019), Educ-AI-tion rebooted? Exploring the future of ar tificial intelligence in schools and colleges , NESTA, available at w ww.nesta.org.uk/documen ts/1190/Future_of_AI_and_education_v5_WEB.pdf, accessed 23 June 2022.Bar assi V. (2020), Child data citizen: how tech companies are profiling us from before bir th, MIT Press, Cambridge, MA.Bar rett B., Dommett K. and Kreiss D. (2021), “The capricious relationship between t echnology and democracy: analyzing public policy discussions in the UK and US” , P olicy & Internet, available at h ttps://doi.org/10.1002/poi3.266, accessed 23 June 2022.Bar rett M. et al. (2019), “Using artificial intelligence to enhance educational oppor-tunities  and student services in higher education” , Inquiry: The Journal of the Virginia C ommunity Colleges Vol. 22, No. 11, pp. 1-10.B eal C. R. et al. (2007), “On-line tutoring for math achievement testing: a controlled ev aluation” , Journal of Interactive Online Learning  Vol. 6, No. 1, pp. 43-55.B eal C. R. et al. (2010), “Evaluation of AnimalWatch: an intelligent tutoring system for ar ithmetic and fractions” , Journal of Interactive Online Learning Vol. 9, No. 1, pp. 64-77.B ecker B. (2017), “Artificial intelligence in education: what is it, where is it now, where is  it going” , in Mooney B. (ed.), Ireland’s Yearbook of Education 2017-2018 , pp. 42-48, E ducation Matters, available at h ttps://irelandseducationyearbook.ie/irelands-y earbook-of-education-2017-2018/, ac cessed 23 June 2022.B enaich N. (2020), “AI has disappointed on Covid” , Financial Times, available at www .f t.com/content/0aafc2de-f46d-4646-acfd-4ed7a7f6feaa, ac cessed 23 June 2022.B ench-Capon T. et al. (2012), “A history of AI and law in 50 papers: 25 years of the in ternational conference on AI and law” , Artificial Intelligence and Law  Vol. 20, No. 3,  pp. 215-319, available at h ttps://doi.org/10.1007/s10506-012-9131-x, accessed 23 June 2022. B en-Israel I. et al. (2020), “Towards regulation of AI systems: global perspectives on the  development of a legal framework on artificial intelligence (AI) systems based on the  Council of Europe’s standards on human rights, democracy and the rule of law” , C ouncil of Europe, available at h ttps://rm.coe.int/prems-107320-gbr-2018-compli-cahaicouv-texte-a4-bat-web/1680a0c17a, ac cessed 23 June 2022.B erman G. and Albright K. (2017), Children and the data cycle: rights and ethics in a  big data world, Innocenti Working Papers No. 2017/05, available at h ttps://doi.or g/10.18356/7d33bc21-en, ac cessed 23 June 2022.B ernstein B. (2000), Pedagogy, symbolic control, and identity , Rowman & Littlefield P ublishers, Lanham, MD.B erryhill J. et al. (2019), Hello, World: artificial intelligence and its use in the public sector , OECD  Working Papers on Public Governance No. 36, OECD, available at h ttps://doi.or g/10.1787/726fd39d-en, ac cessed 23 June 2022.
References  P age 79Bietti E. (2020), “From ethics washing to ethics bashing: a view on tech ethics fr om within moral philosophy” , Proceedings of the 2020 Conference on Fairness, A ccountability, and Transparency , pp. 210-19, available at h ttps://dl.acm.org/doi/abs/10.1145/3351095.3372860 , ac cessed 23 June 2022.Biggs  P . et al. (2018), The state of broadband 2018: broadband catalyzing sustainable dev elopment, ITU, Geneva.Binns  R. (2021), Data minimisation and privacy-preserving techniques in AI systems , a vailable at h ttps://ico.org.uk/about-the-ico/news-and-events/ai-blog-data-mini-misa tion-and-privacy-preserving-techniques-in-ai-systems/, accessed 23 June 2022.Blanchar d E. G. (2015), “Socio-cultural imbalances in AIED research: investigations, implica tions and opportunities” , International Journal of Artificial Intelligence in E ducation Vol. 25, No. 2, pp. 204-28, available at h ttps://doi.org/10.1007/s40593-014-0027-7 , ac cessed 23 June 2022.Blanchar d E. G. et al. (2009), “Affective artificial intelligence in education: from detec-tion t o adaptation” , AIED Vol. 200, pp. 81-88.Bloom  B. S. (1984), “The 2 sigma problem: the search for methods of group instruction as eff ective as one-to-one tutoring” , Educational Researcher  Vol. 13, No. 6, pp. 4-16.B oddington P . (2017), Towards a code of ethics for artificial intelligence research , Spr inger, Berlin/Heidelberg.B orgesius F. Z. (2018), Discrimination, artificial intelligence and algorithmic decision-mak ing, Council of Europe, available at w ww.coe.int/en/web/europe-ancommission-against-racism-and-intolerance/newsroom/-/asset_publisher/U2IWx eHB054o/content/-discrimination-artificial-intelligence-and-algorithmic-de-cision-mak ing-, ac cessed 23 June 2022.B oulay B. (du) (2016), Artificial intelligence as an effective classroom assistant , IEEE Int elligent Systems Vol. 31, No. 6, pp. 76-81, available at h ttps://doi.org/10.1109/MIS.2016.93 , ac cessed 23 June 2022.B oulay B. (du) et al. (2018), “What does the research say about how artificial intelligence and  big data can close the achievement gap?” , in Luckin R. (ed.), Enhancing learning and  teaching with technology , pp. 256-85, UCL Institute of Education Press, London.Br own L. X. Z. (2020), How automated test proctoring software discriminates against disabled  students, Center for Democracy & Technology, available at h ttps://cdt.org/insigh ts/how-automated-test-proctoring-software-discriminates-against-disa-bled-studen ts/, ac cessed 23 June 2022.Br yant J. et al. (2020), How artificial intelligence will impact K-12 teachers , McKinsey, a vailable at w ww.mckinsey.com/industries/education/our-insights/how-artificial-in-t elligence-will-impact-k-12-teachers, ac cessed 23 June 2022.Bughin  J., Manyika J. and Woetzel J. (2017), Jobs lost, jobs gained: workforce transi-tions  in a time of automation , McKinsey Global Institute, available at h ttps://www.mck insey.com/~/media/mckinsey/industries/public%20and%20social%20sector/our%20insigh ts/what%20the%20future%20of%20work%20will%20mean%20for%20
Page 80  A rtificial intelligence and educationjobs%20skills%20and%20wages/mgi-jobs-lost-jobs-gained-executive-summary-dec ember-6-2017.pdf, ac cessed 23 June 2022.Buolam wini J. and Gebru T. (2018), “Gender shades: intersectional accuracy dispar-ities  in commercial gender classification” , Conference on Fairness, Accountability, a nd Transparency, pp. 77-91, available at h ttps://proceedings.mlr.press/v81/ b uolamwini18a/buolamwini18a.pdf, ac cessed 23 June 2022. B yrne R. et al. (2010), “eGrader, a software application that automatically scores studen t essays: with a postscript on ethical complexities” , Undefined, available at w ww.semanticscholar.org/paper/eGrader%2C-a-software-application-that-auto-ma tically-Byrne-Tang/6a800257bbb62df104e8595cea4dc73ccf4d2b54, accessed 23 June 2022. C anto M. (2019), Brazil – We don’t need no observation: the use and regulation of facial r ecognition in Brazilian public schools , Global Information Society Watch, available at h ttps://giswatch.org/node/6159, ac cessed 23 June 2022.C arrel A. (2018), “Legal intelligence through artificial intelligence requires emotional in telligence: a new competency model for the 21st century legal professional” , Georgia Stat e University Law Review Vol. 35, No. 4, p. 1153-83.C entre for Data Ethics and Innovation (2020), Review into bias in algorithmic  decision-mak ing, p. 151, available at h ttps://assets.publishing.service.gov.uk/govern-m ent/uploads/system/uploads/attachment_data/file/957259/Review_into_bias_in_algo-r ithmic_decision-making.pdf, ac cessed 23 June 2022.Chander  S. and Jakubowska E. (2020), Attention EU regulators: we need more than AI “ ethics” to keep us safe, Access Now, available at w ww.accessnow.org/eu-regulations-aiethics/, ac cessed 23 June 2022.Chassig nol M. et al. (2018), “Artificial intelligence trends in education: a narrative o verview” , Procedia Computer Science Vol.136, pp. 16-24.Choun ta I.-A. et al. (2021), “Exploring teachers’ perceptions of artificial intelligence as  a tool to support their practice in Estonian K-12 education” , International Journal of  Artificial Intelligence in Education , pp. 1-31, available at h ttps://doi.org/10.1007/s40593-021-00243-5 , ac cessed 23 June 2022.Chr ysafiadi K. and Virvou M. (2013), “Student modeling approaches: a literature r eview for the last decade” , Expert Systems with Applications  Vol. 40, No. 11, pp. 4715-29,  available at h ttps://doi.org/10.1016/j.eswa.2013.02.007, accessed 23 June 2022.Clegg  J. and Afitska O. (2011), “Teaching and learning in two languages in African classr ooms” , Comparative Education  Vol. 47, No. 1, pp. 61-77, available at h ttps://doi.or g/10.1080/03050068.2011.541677, ac cessed 23 June 2022.C ollinson J. and Persson J. (2021), A reflection on the UNCRC Best Interests of the Child principle  in the context of The Age Appropriate Design Code , defenddigitalme, available at  https://defenddigitalme.org/wp-content/uploads/2021/10/A-Reflection-on-the-B est-Interests-of-the-Child-in-the-context-of-the-Age-Appropriate-Design-Code-05102021v2.0.pdf, ac cessed 23 June 2022.
References  P age 81Conati C., Porayska-Pomsta K. and Mavrikis M. (2018), AI in education needs interpret-able  machine learning: lessons from open learner modelling , ArXiv:1807.00154 [Cs], a vailable at h ttp://arxiv.org/abs/1807.00154, ac cessed 23 June 2022.C onijn R. et al. (2022), “The fear of big brother: the potential negative side-effects of pr octored exams” , Journal of Computer Assisted Learning , pp. 1-14, available at h ttps://doi.or g/10.1111/jcal.12651, ac cessed 23 June 2022.C onnolly R. (2020), “Why computing belongs within the social sciences” , Communications of  the ACM Vol. 63, No. 8, pp. 54-59, available at h ttps://doi.org/10.1145/3383444, ac cessed 23 June 2022.C orbett A. T. et al. (1997), “Intelligent tutoring systems” , in Handbook of human-computer int eraction (2nd edn), pp. 849-74, Elsevier, Amsterdam.C otterell R. et al. (2020), Are all languages equally hard to language-model? , A rXiv:1806.03743 [Cs], available at h ttp://arxiv.org/abs/1806.03743, accessed 23 June 2022. C ouncil of Europe (2010), Charter on Education for Democratic Citizenship and Human R ights Education: Recommendation CM/Rec(2010)7 adopted by the Committee of M inisters of the Council of Europe on 11 May 2010 and explanatory memorandum, C ouncil of Europe, Strasbourg.C ouncil of Europe Commissioner for Human Rights (2019), Unboxing artificial intelli-genc e: 10 steps to protect human rights , available at h ttps://rm.coe.int/unboxing-ar-tificial-in telligence-10-steps-to-protect-human-rights-reco/1680946e64, accessed 23 June 2022. C rawford K. (2021), Atlas of AI: power, politics, and the planetary costs of artificial int elligence, Yale University Press, New Haven, CT.C ui Y. (2020), “The high-level seminar on AI and rule of law yields fruitful theoretical r esults, leading the direction of development” , in Artificial intelligence and judicial mod-ernization , pp. 193-99, Springer Singapore, available at h ttps://doi.org/10.1007/978-981-32-9880-4_15 , ac cessed 23 June 2022.C yndecka M. A. (2020), A dystopian story about Covid-19, artificial intelligence setting gr ades and the GDPR, EFTA-Studies, available at w ww.efta-studies.org/post/a-dys-t opian-story-about-covid-19-artificial-intelligence-setting-grades-and-the-gdpr, ac cessed 23 June 2022.Dalipi  F., Imran A. S. and Kastrati Z. (2018), MOOC dropout prediction using machine learning  techniques: review and research challenges , 2018 IEEE Global Engineering E ducation Conference  (EDUCON), pp. 1007-14, available at h ttps://doi.org/10.1109/EDUC ON.2018.8363340, ac cessed 23 June 2022.Da vies H. C., Eynon R. and Salveson C. (2020), “The mobilisation of AI in edu-ca tion: a Bourdieusean field analysis” , Sociology, available at h ttps://doi.or g/10.1177/0038038520967888, ac cessed 23 June 2022.def end digital me (2020), The state of data report 2020:  mapping a child’s digital foot-print  in the state education landscape in England , available at h ttps://defenddigitalme.or g/research/the-state-of-data-2020/report/, ac cessed 23 June 2022.
Page 82  A rtificial intelligence and educationDennis M. J. (2018), “Artificial intelligence and recruitment, admission, progression, and  retention” , Enrollment Management Report  Vol. 22, No. 9, pp. 1-3, available at h ttps://doi.org/10.1002/emt.30479, ac cessed 23 June 2022.D ewey J. (1903), “Democracy in education” , The Elementary School Teacher Vol. 4, No . 4, pp. 193-204.Diamond  L. (2019), “The road to digital unfreedom: the threat of postmodern total-itar ianism” , Journal of Democracy Vol. 30, No. 1, pp. 20-24.Dr igas A. S. and Ioannidou R.-E. (2013), “A review on artificial intelligence in special educa tion” , in Lytras D. M. et al. (eds), Information systems, e-learning, and knowledge management  research  Vol. 278, pp. 385-91, Springer, Berlin/Heidelberg, available at h ttps://doi.org/10.1007/978-3-642-35879-1_46, ac cessed 23 June 2022.E gelandsdal K. et al. (2019), Adaptiv læring i matematikk: empirisk rapport om Multi Smar t Øving i grunnskolen [Adaptive learning in mathematics: empirical report on the Multi  Smart intervention in primary schools ], Centre for the Science of Learning & T echnology (SLATE), University of Bergen, available at h ttps://bora.uib.no/bora-xmlui/handle/1956/21354 , ac cessed 23 June 2022.Elliot  M. et al. (2018), “Functional anonymisation: personal data and the data environ-men t” , Computer Law & Security Review Vol. 34, No. 2, pp. 204-21, available at h ttps://doi.or g/10.1016/j.clsr.2018.02.001, ac cessed 23 June 2022.En twistle N. (2000), Promoting deep learning through teaching and assessment – C onceptual frameworks and educational contexts , TLRP Conference, Leicester, available at  www.etl.tla.ed.ac.uk/docs/entwistle2000.pdf, ac cessed 23 June 2022.E verett C. (2020), UK A-level algorithm fiasco a global example of what not to do – What w ent wrong and why, Diginomica, available at h ttp://diginomica.com/uk-level-algo-r ithm-fiasco-global-example-what-not-do-what-went-wrong-and-why, accessed 23 June 2022. E vgeniou T., Hardoon D. R. and Ovchinnikov A. (2020), “What happens when AI is used  to set grades?” , Harvard Business Review , 13 August, available at h ttps://hbr.or g/2020/08/what-happens-when-ai-is-used-to-set-grades, accessed 23 June 2022.E ynon R. and Young E. (2021), “Methodology, legend, and rhetoric: the construc-tions  of AI by academia, industry, and policy groups for lifelong learning” , Science, T echnology, & Human Values Vol. 46, No. 1, pp. 166-91, available at h ttps://doi.or g/10.1177/0162243920906475, ac cessed 23 June 2022.F eng W., Tang J. and Liu T. X. (2019), “Understanding dropouts in MOOCs” , Proceedings of  the AAAI Conference on Artificial Intelligence Vol. 33, No. 01, pp. 517-24, available at h ttps://doi.org/10.1609/aaai.v33i01.3301517, ac cessed 23 June 2022.F erguson R. et al. (2016), Research evidence on the use of learning analytics: impli-c ations for education policy , JRC Science for Policy report, European Commission, L uxembourg.F rey C. B. and Osborne M. A. (2013), The future of employment: how susceptible are jobs  to computerisation?  Machines and employment workshop, Oxford University, O xford.
References  P age 83Gagné R. M. and Brown L. T. (1963), “Some factors in the programming of conceptual lear ning” , Journal of Experimental Psychology Vol. 62, No. 4, pp. 313-21, available at h ttps://doi.org/10.1037/h0049210, ac cessed 23 June 2022.G ent E. (2019), The “ghost work” powering tech magic , BBC – Worklife 101, available at  www.bbc.com/worklife/article/20190829-the-ghost-work-powering-tech-magic, ac cessed 23 June 2022.G obert J. D. et al. (2013), “From log files to assessment metrics: measuring students’ scienc e inquiry skills using educational data mining” , Journal of the Learning Sciences V ol. 22, No. 4, pp. 521-63.G obert J. D. et al. (2018), “Real-time scaffolding of students’ online data interpreta-tion  during inquiry with Inq-ITS using educational data mining” , in Auer M. E. et al. (eds),  Cyber-physical laboratories in engineering and science education  (pp. 191-217), Spr inger International.G oel Y. and Goyal R. (2020), “On the effectiveness of self-training in MOOC dropout pr ediction” , Open Computer Science Vol. 10, No. 1, pp. 246-58, available at h ttps://doi.or g/10.1515/comp-2020-0153, ac cessed 23 June 2022.G ottschalk F. (2019), Impacts of technology use on children – Exploring literature on the  brain, cognition and well-being , OECD Education Working Papers No. 195, OECD, a vailable at h ttps://doi.org/10.1787/8296464e-en, ac cessed 23 June 2022.Gr ay J. (2017), “University of Buckingham to monitor students’ social media accounts t o tackle depression and suicide” , HuffPost UK, available at w ww.huffingtonpost.c o.uk/entry/university-of-buckingham-students-social-media-accounts-depression-suicide_uk_588b5196e4b02f223a01a178 , ac cessed 23 June 2022.Gr iffith A. E. et al. (2021), “Discovering co-creative dialogue states during collabo-r ative learning” , International Conference on Artificial Intelligence in Education , pp. 165-177. Hager  G. D. et al. (2019), Artificial intelligence for social good , ArXiv:1901.05406 [Cs], a vailable at h ttps://doi.org/10.48550/arXiv.1901.05406, ac cessed 23 June 2022.Hea ven W. D. (2019), “Why deep-learning AIs are so easy to fool” , Nature Vol. 574, No . 7777, pp. 163-66, available at h ttps://doi.org/10.1038/d41586-019-03013-5, ac cessed 23 June 2022.Hea ven W. D. (2021), “Hundreds of AI tools have been built to catch covid. None of  them helped” , MIT Technology Review , available at w ww.technologyreview.c om/2021/07/30/1030329/machine-learning-ai-failed-covid-hospital-diagnosis-pandemic/ , ac cessed 23 June 2022.Heimans  S., Singh P . and Kwok H. (2021), “Pedagogic rights, public education and  democracy” , European Educational Research Journal , available at h ttps://doi.or g/10.1177/14749041211011920, ac cessed 23 June 2022.Hendr y J. (2018), “Govts dump NAPLAN robo marking plans” , ITnews, available at  www.itnews.com.au/news/govts-dump-naplan-robo-marking-plans-482044, ac cessed 23 June 2022.
Page 84  A rtificial intelligence and educationHickey S. and Hossain N. (2019), The politics of education in developing countries: fr om schooling to learning , OUP Oxford, available at h ttps://books.google.co.uk/books?id=gMKKD wAAQBAJ, ac cessed 23 June 2022.H ildebrandt M. (2015), Smart technologies and the end(s) of law: novel entanglements of  law and technology, available at h ttps://doi.org/10.4337/9781849808774, accessed 23 June 2022. H ildebrandt M. (2019), “10. ‘Legal by Design’ or ‘Legal Protection by Design’?” , Law for  Computer Scientists , available at h ttps://lawforcomputerscientists.pubpub.org/pub/g fzd6k0g/release/12, ac cessed 23 June 2022.H ilton A. D. (2019), “Artificial intelligence: the societal responsibility to inform, educa te, and regulate” , AI Matters Vol. 5, No. 3, pp. 70-76, available at h ttps://doi.or g/10.1145/3362077.3362088, ac cessed 23 June 2022.Holmes  W. (2020), The right kind of AI in education , Nesta, available at w ww.nesta.or g.uk/blog/right-kind-ai-education/, ac cessed 23 June 2022.Holmes  W. and Porayska-Pomsta K. (eds) (2022), The ethics of artificial intelligence in educ ation: practices, challenges, and debates , Routledge, New York.Holmes  W. et al. (2018), Technology-enhanced personalised learning: untangling the evidenc e, Robert Bosch Stiftung, available at w ww.bosch-stiftung.de/sites/default/files/publica tions/pdf/2018-08/Study_Technology-enhanced%20Personalised%20L earning.pdf, ac cessed 23 June 2022.Holmes  W., Bialik M. and Fadel C. (2019), Artificial intelligence in education: promises and  implications for teaching and learning , Center for Curriculum Redesign, available at  https://drive.google.com/file/d/1lmzlbhKvYyRB6J0USCndqXitmVgsfTbI/view, ac cessed 23 June 2022.Holmes  W. et al. (2021), “Ethics of AI in education: towards a community-wide frame-w ork” , International Journal of Artificial Intelligence in Education , available at h ttps://link .springer.com/article/10.1007/s40593-021-00239-1, ac cessed 23 June 2022.Holst ein K. et al. (2018), “The classroom as a dashboard: co-designing wearable cog-nitiv e augmentation for K-12 teachers” , Proceedings of the 8th International Conference on  Learning Analytics and Knowledge , pp. 79-88, available at h ttps://dl.acm.org/doi/10.1145/3170358.3170377 , ac cessed 23 June 2022.Holst ein K., McLaren B. M. and Aleven V. (2017), “Intelligent tutors as teachers’ aides: e xploring teacher needs for real-time analytics in blended classrooms” , Proceedings of  the 7th International Conference on Learning Analytics and Knowledge , pp. 257-66, a vailable at h ttps://doi.org/10.1145/3027385.3027451, ac cessed 23 June 2022.Hutson  M. (2021), “Robo-writers: the rise and risks of language-generating AI” , Nature V ol. 591, No. 7848, pp. 22-5, available at h ttps://doi.org/10.1038/d41586-021-00530-0 , accessed 23 June 2022.H wang G.-J. et al. (2020), Vision, challenges, roles and research issues of artificial intel-ligenc e in education, Elsevier, Amsterdam.ITU  (2020), United Nations activities on artificial intelligence (AI) 2020 , ITU Publications, G eneva.
References  P age 85Jarrell A. et al. (2015), “Examining the relationship between performance feedback and  emotions in diagnostic reasoning: toward a predictive framework for emotional suppor t” , in Conati C. et al. (eds), Artificial Intelligence in Education  Vol. 9112, pp. 650-53, Spr inger International Publishing, available at h ttps://doi.org/10.1007/978-3-319-19773-9_83 , ac cessed 23 June 2022.Jär velä S. et al. (2021), “What multimodal data can tell us about the students’ regu-la tion of their learning process?” , Learning and Instruction Vol. 72, 101203, available at  https://doi.org/10.1016/j.learninstruc.2019.04.004, ac cessed 23 June 2022.Jiv et I. et al. (2017), “Awareness is not enough: pitfalls of learning analytics dash-boar ds in the educational practice” , in Lavoué É. et al. (eds), Data driven approaches in  digital education, pp. 82-96, Springer International Publishing, available at h ttps://doi.or g/10.1007/978-3-319-66610-5_7, ac cessed 23 June 2022.Jobin  A., Ienca M. and Vayena E. (2019), “Artificial intelligence: the global landscape of  ethics guidelines” , Nature Machine Intelligence Vol. 1, No. 9, 389-99, available at h ttps://doi.org/10.1038/s42256-019-0088-2, ac cessed 23 June 2022.Johnson  B. and Shen F. X. (2021), “Teaching law and artificial intelligence” , Minnesota J ournal of Law, Science & Technology  Vol. 22, No. 2, pp. 23-42. K apur M. (2008), “Productive failure” , Cognition and Instruction Vol. 26, No. 3, pp. 379-424,  available at h ttps://doi.org/10.1080/07370000802212669, accessed 23 June 2022.K arr V. (2009), It’s about ability: learning guide on the Convention on the Rights of P ersons with Disabilities , UNICEF, available at w ww.unicef.org/media/85751/file/I ts_About_Ability_Learning_Guide_EN.pdf, ac cessed 23 June 2022. Ker r I. R. (2017), The devil is in the defaults , Social Science Research Network, SSRN S cholarly Paper ID 3395383, available at h ttps://papers.ssrn.com/abstract=3395383, ac cessed 23 June 2022.K ing P . and Persson J. (2022), The state of biometrics 2022: a review of policy and practice ar ound biometric data in UK education , defenddigitalme, available at h ttps://defend-dig italme.org/research/state-biometrics-2022, ac cessed 23 June 2022.K night S. et al. (2018), “Designing academic writing analytics for civil law student self-assessmen t” , International Journal of Artificial Intelligence in Education Vol. 28, No . 1, pp. 1-28, available at h ttps://doi.org/10.1007/s40593-016-0121-0, accessed 25 June 2022. K nox J. (2020), “Artificial intelligence and education in China” , Learning, Media and T echnology Vol. 45, No. 3, pp. 298-311.Kohli  M. and Prasad T. V. (2010), “Identifying dyslexic students by using artificial neu-r al networks” , Proceedings of the World Congress on Engineering Vol. 1, No. 1, pp. 1-4.Kokotsak i D., Menzies V. and Wiggins A. (2016), “Project-based learning: a review of the  literature” , Improving Schools Vol. 19, No. 3, pp. 267-77, available at h ttps://doi.or g/10.1177/1365480216659733, ac cessed 25 June 2022.Komljeno vic J. (2021), “The rise of education rentiers: digital platforms, digital data and  rents” , Learning, Media and Technology Vol. 46, No. 3, pp. 320-32, available at h ttps://doi.org/10.1080/17439884.2021.1891422, ac cessed 25 June 2022.
Page 86  A rtificial intelligence and educationKorff D. and Georges M. (2020), “The origins and meaning of data protection” , SSRN Elec tronic Journal, available at h ttps://doi.org/10.2139/ssrn.3518386, accessed 25 June 2022. Kosm yna N. and Maes P . (2019), “Attentivu: an EEG-based closed-loop biofeedback sy stem for real-time monitoring and improvement of engagement for personalized lear ning” , Sensors Vol. 19, No. 23, p. 5200.K ucirkova N. and Littleton K. (2017), “Developing personalised education for personal mobile  technologies with the pluralisation agenda” , Oxford Review of Education V ol. 43, No. 3, pp. 276-88.K urzweil R. (2006), The Singularity is near: when humans transcend biology , Duckworth, L ondon.K ynigos C. (2019), Adaptive learning in mathematics: situating Multi Smart Øving in the landsc ape of digital technologies for mathematics education , Centre for the Science of L earning & Technology (SLATE), University of Bergen, available at h ttps://bora.uib.no/bor a-xmlui/handle/1956/21352, ac cessed 25 June 2022.L eaton Gray S. H. and Kucirkova N. (2018), “A united and thriving Europe? A sociology of  the European Schools” and “If personalised education and artificial intelligence ar e a democratic problem, could pluralisation be the democratic solution?” British E ducational Research Association conference, Newcastle, 11-13 September.L edford H. (2019), “Millions of black people affected by racial bias in health-care algor ithms” , Nature Vol. 574, No. 7780, pp. 608-9, available at h ttps://doi.org/10.1038/d41586-019-03228-6 , ac cessed 25 June 2022.L eslie D. et al. (2021), Artificial intelligence, human rights, democracy, and the rule of  law: a primer, Council of Europe, available at w ww.ssrn.com/abstract=3817999, ac cessed 25 June 2022.L ovato S. B., Piper A. M. and Wartella E. A. (2019), “Hey Google, do unicorns exist?”: c onversational agents as a path to answers to children’s questions” , Proceedings of the 18th  ACM International Conference on Interaction Design and Children, IDC 2019 , pp. 301-13,  available at h ttps://doi.org/10.1145/3311927.3323150, accessed 25 June 2022.L undy L. (2021), Human rights law – The speckled bird of educational research?  E uropean Educational Research Association, available at h ttps://blog.eera-ecer.de/human-r ights-in-educational-research, ac cessed 25 June 2022. L undy L. et al. (2019), Two clicks forward and one click back: report on children with disabilities  in the digital environment, Council of Europe, available at h ttps://rm.coe.int/t wo-clicks-forward-and-one-click-back-report-on-children-with-disabili/168098bd0f, ac cessed 25 June 2022.L upton D. and Williamson B. (2017), “The datafied child: the dataveillance of children and  implications for their rights” , New Media & Society Vol. 19, No. 5, pp. 780-94, a vailable at h ttps://doi.org/10.1177/1461444816686328, ac cessed 25 June 2022.L ynch C. et al. (2007), “Argument diagramming as focusing device: does it scaffold r eading” , Proceedings of the AIED Workshop on Applications for Ill-Defined Domains , pp . 51-60.
References  P age 87Ma W. et al. (2014), “Intelligent tutoring systems and learning outcomes: a meta-analy sis” , Journal of Educational Psychology Vol. 106, No. 4, 901-18.M acfarlane B. (2003), Teaching with integrity: the ethics of higher education practice , R outledge, Abingdon, Oxon/New York, NY.M cLaren B. M. and Scheuer O. (2010), “Supporting collaborative learning and ediscussions using artificial intelligence techniques” , International Journal of Artificial Int elligence in Education Vol. 20, No. 1, pp. 1-46.M cMorrow R. et al. (2021), “China’s education sector crackdown hits foreign investors” , F inancial Times, 26 July, available at w ww.ft.com/content/dfae3282-e14e-4fea-aa5f-c2e914444fb8 , ac cessed 25 June 2022.M ajumdar B. et al. (2018), “Technology: artificial intelligence” , British Dental Journal, V ol. 224, No. 12, p. 916.M arcinkowski F. et al. (2020), “Implications of AI (un-)fairness in higher education admissions:  the effects of perceived AI (un-)fairness on exit, voice and organiza-tional  reputation” , Proceedings of the 2020 Conference on Fairness, Accountability, and T ransparency, pp. 122-30, available at h ttps://doi.org/10.1145/3351095.3372867, ac cessed 25 June 2022.M arcus G. (2020), The next decade in AI: four steps towards robust artificial intelligence , A rXiv:2002.06177 [Cs], available at h ttp://arxiv.org/abs/2002.06177, accessed 25 June 2022. M arcus G. and Davis E. (2020), “GPT-3, Bloviator: OpenAI’s language generator has  no idea what it’s talking about” , MIT Technology Review , available at www . t echnologyreview.com/2020/08/22/1007539/gpt3-openai-language-generator-ar tificial-in telligence-ai-opinion/, ac cessed 25 June 2022.M arkauskaite L. et al. (2022), “Rethinking the entwinement between artificial intelli-genc e and human learning: what capabilities do learners need for a world with AI?” , C omputers and Education: Artificial Intelligence  Vol. 3, 100056. h ttps://doi.org/10.1016/j.caeai.2022.100056 , ac cessed 25 June 2022.M artinez-Maldonado R. et al. (2021), “Moodoo the tracker: spatial classroom analytics f or characterising teachers’ pedagogical approaches” , International Journal of Artificial Int elligence in Education ” , available at h ttps://doi.org/10.1007/s40593-021-00276-w, ac cessed 25 June 2022.M atsushita K. (2018), “An invitation to deep active learning” , in Matsushita K. (ed.), D eep active learning: toward greater depth in university education , pp. 15-33, Springer, a vailable at h ttps://doi.org/10.1007/978-981-10-5660-4_2, ac cessed 25 June 2022.M endicino M., Razzaq L. M. and Heffernan N. (2009), “A comparison of traditional homew ork to computer-supported homework” , Journal of Research on Technology in  Education Vol. 41, No. 3, pp. 331-59, available at h ttps://doi.org/10.1080/15391523.2009.10782534 , ac cessed 25 June 2022.M iao F. and Holmes W. (2021a), AI and education: guidance for policy-makers , UNESCO, a vailable at h ttps://unesdoc.unesco.org/ark:/48223/pf0000376709, accessed 25 June 2022. 
Page 88  A rtificial intelligence and educationMiao F. and Holmes W. (2021b), Beyond disruption: technology enabled learning futures; 2020  edition of Mobile Learning Week , UNESCO, available at h ttps://unesdoc.unesco.or g/ark:/48223/pf0000377753, ac cessed 25 June 2022.M iao F. and Holmes W. (2022), International Forum on AI and Education – Ensuring AI  as a common good to transform education, 7-8 December 2021; synthesis report . UNESC O, available at h ttps://unesdoc.unesco.org/ark:/48223/pf0000381226, accessed 25 June 2022. M iao F. et al. (2019), Guidelines on the development of open educational resources p olicies, UNESCO and Commonwealth of Learning, available at h ttps://unesdoc.unesc o.org/ark:/48223/pf0000371129, ac cessed 25 June 2022.M iao F. and Shiohira K. (2022), K-12 AI curricula: a mapping of government-endorsed AI curricula , UNESCO.M olenaar I., Horvers A. and Baker R. S. (2021), “What can moment-by-moment learning cur ves tell about students’ self-regulated learning?” , Learning and Instruction Vol. 72, 101206,  h ttps://doi.org/10.1016/j.learninstruc.2019.05.003, accessed 25 June 2022.M orozov E. (2014), To save everything, click here: technology, solutionism, and the urge t o fix problems that don’t exist , Penguin, London.Naismith  B. and Juffs A. (2021), “Finding the sweet spot: learners’ productive knowledge of  mid-frequency lexical items” , Language Teaching Research , available at h ttps://doi.or g/10.1177/13621688211020412, ac cessed 25 June 2022.Nazar etsky T., Cukurova M. and Alexandron G. (2021), “An instrument for measuring t eachers’ trust in AI-based educational technology” , LAK22: 12th International Learning A nalytics and Knowledge Conference , pp. 56-66.Nemitz  P . (2018), “Constitutional democracy and technology in the age of artificial in telligence” , Philosophical Transactions of the Royal Society A: Mathematical, Physical and  Engineering Sciences Vol. 376, No. 2133, available at h ttps://doi.org/10.1098/rsta.2018.0089 , ac cessed 25 June 2022.Nemor in S. (2017), “Affective capture in digital school spaces and the modulation of studen t subjectivities” , Emotion, Space and Society  Vol. 24, pp. 11-18.OECD  (2021), OECD Digital Education Outlook 2021: pushing the frontiers with ar tificial intelligence, blockchain and robots , OECD, available at h ttps://doi.or g/10.1787/589b283f-en, ac cessed 25 June 2022.Olney  A. M. et al. (2017), “Assessing the dialogic properties of classroom discourse: pr oportion models for imbalanced classes” , in Hu X et al. (eds), Proceedings of the 10th Int ernational Conference on Educational Data Mining, pp . 162-67. O ’Neil C. (2017), Weapons of math destruction: how big data increases inequality and thr eatens democracy (01 edition), Penguin, London.P age L. C. and Gehlbach H. (2017), “How an artificially intelligent virtual assistant helps  students navigate the road to college” , AERA Open Vol. 3, No. 4, available at h ttps://doi.org/10.1177/2332858417749220, ac cessed 25 June 2022.P ane J. F. et al. (2010), “An experiment to evaluate the efficacy of cognitive tutor geometr y” , Journal of Research on Educational Effectiveness Vol. 3, No. 3, pp. 254-81.
References  P age 89Pardo A. et al. (2019), “Using learning analytics to scale the provision of personalised f eedback” , British Journal of Educational Technology Vol. 50, No. 1, pp. 128-38.P arson E. et al. (2019), Artificial intelligence in strategic context: an introduction , UCLA: T he Program on Understanding Law, Science, and Evidence (PULSE), available at h ttps://escholarship.org/uc/item/9c8651s6, ac cessed 25 June 2022.P ekrun R. (2014), “Emotions and learning” , Educational Practices Series Vol. 24, No. 1, pp . 1-31.P érez-Ortiz M. et al. (2020), An AI-based learning companion promoting lifelong learning opp ortunities for all (Opinion Series Report), International Research Centre on Artificial I ntelligence under the auspices of UNESCO, available at h ttps://ircai.org/project/ai-based-lear ning-companion-promoting-lifelong-learning/, accessed 25 June 2022.P eters R. S. (1970), Ethics and education, Allen & Unwin, London.P inkwart N. (2016), “Another 25 years of AIED? Challenges and opportunities for in telligent educational technologies of the future” , International Journal of Artificial Int elligence in Education  Vol. 26, No. 2, pp. 771-83.P openici S. A. D. and Kerr S. (2017), “Exploring the impact of artificial intelligence on  teaching and learning in higher education” , Research and Practice in Technology Enhanc ed Learning Vol. 12, No. 22, available at h ttps://doi.org/10.1186/s41039-017-0062-8 , ac cessed 25 June 2022.P orayska-Pomsta K. et al. (2018), “Blending human and artificial intelligence to support autistic  children’s social communication skills” , ACM Transactions on Computer-Human Int eraction (TOCHI) Vol. 25, No. 6, pp. 1-35.P owles J. (2018), “The seductive diversion of ‘solving’ bias in artificial intelligence” , O neZero, available at h ttps://onezero.medium.com/the-seductive-diversion-of-solv-ing-bias-in-ar tificial-intelligence-890df5e5ef53, ac cessed 25 June 2022.P rates M. O. R., Avelar P . H. C. and Lamb L. (2019), Assessing gender bias in machine tr anslation – A case study with Google Translate , ArXiv:1809.02208 [Cs], available at h ttp://arxiv.org/abs/1809.02208, ac cessed 25 June 2022.R aval N. (2019), Artificial intelligence: human rights, social justice and development , Global  Information Society Watch 2019, Association for Progressive Communications.R ehak R. (2021), “The language labyrinth: constructive critique on the terminology used in  the AI discourse” , in Verdegem P . (ed.), AI for everyone?, University of Westminster P ress, London, available at h ttps://doi.org/10.16997/book55.f, accessed 25 June 2022.R eynaert D., Bouverne-de-Bie M. and Vandevelde S. (2009), “A review of children’s r ights literature since the adoption of the United Nations Convention on the R ights of the Child” , Childhood Vol. 16, No. 4, pp. 518-34, available at h ttps://doi.or g/10.1177/0907568209344270, ac cessed 25 June 2022.R oberts M. et al. (2021), “Common pitfalls and recommendations for using machine lear ning to detect and prognosticate for Covid-19 using chest radiographs and CT scans ” , Nature Machine Intelligence  Vol. 3, No. 3, pp. 199-217, available at h ttps://doi.or g/10.1038/s42256-021-00307-0, ac cessed 25 June 2022.
Page 90  A rtificial intelligence and educationRomero A. (2021), “Understanding GPT-3 in 5 minutes” , Medium, available at h ttps://t owardsdatascience.com/understanding-gpt-3-in-5-minutes-7fe35c3a1e52, accessed 25 June 2022. R oschelle J. et al. (2017), How big is that? Reporting the effect, size and cost of ASSISTments in the Maine Homew ork Efficacy Study , SRI International, Menlo Park, CA.Rudin  C. (2019), “Stop explaining black box machine learning models for high stakes decisions  and use interpretable models instead” , Nature Machine Intelligence Vol. 1, No . 5, pp. 206-15, available at h ttps://doi.org/10.1038/s42256-019-0048-x, accessed 25 June 2022. Rust  R. (2021), “Code the code: surveillance capitalism, education, and the critical theor y of technology” , West Chester University doctoral dissertation, available at h ttps://digitalcommons.wcupa.edu/all_doctoral/99, ac cessed 25 June 2022.S amuel J. et al. (2018), Beyond STEM, how can women engage big data, analytics, r obotics and artificial intelligence? – An exploratory analysis of confidence and educa-tional  factors in the emerging technology waves influencing the role of and impact upon w omen, SSRN Electronic Journal, available at h ttps://papers.ssrn.com/sol3/papers.c fm?abstract_id=3735279, ac cessed 25 June 2022.S apci A. H. and Sapci H. A. (2020), “Artificial intelligence education and tools for med-ical  and health informatics students: systematic review” , JMIR Medical Education  Vol. 6,  No. 1, available at w ww.ncbi.nlm.nih.gov/pmc/articles/PMC7367541/, accessed 25 June 2022. S apiezynski P ., Kassarnig V. and Wilson C. (2017), Academic performance prediction in  a gender-imbalanced environment  (Data set), Boise State University, ID, available at  https://doi.org/10.18122/B20Q5R, ac cessed 25 June 2022.S ayed Y. and Ahmed R. (2011), “Education quality in post‐apartheid South African polic y: balancing equity, diversity, rights and participation” , Comparative Education V ol. 47, No. 1, pp. 103-18, available at h ttps://doi.org/10.1080/03050068.2011.541680 , accessed 25 June 2022.S chiff D. (2021), “Out of the laboratory and into the classroom: the future of artificial in telligence in education” , AI & Society Vol. 36, pp. 331-48, available at h ttps://doi.or g/10.1007/s00146-020-01033-8, ac cessed 25 June 2022.S chwemer S. F., Tomada L. and Pasini T. (2021), “Legal AI systems in the EU’s proposed A rtificial Intelligence Act” , Proceedings of the Second International Workshop on AI and Int elligent Assistance for Legal Professionals in the Digital Workplace (LegalAIIA 2021), held in c onjunction with ICAIL.S clater N. (2016), Learning analytics in higher education: a review of UK and interna-tional  practice – Data analytics , JISC, available at h ttps://analytics.jiscinvolve.org/wp/2016/04/19/lear ning-analytics-in-higher-education-a-review-of-uk-and-inter-na tional-practice/, ac cessed 25 June 2022.S ehr D. T. (1997), Education for public democracy , Suny Press, Albany, NY.S eldon A. and Abidoye O. (2018), The fourth education revolution: will artificial intelli-genc e liberate or infantilise humanity?  The University of Buckingham Press, London.
References  P age 91Silapachote P . and Srisuphab A. (2016), “Teaching and learning computational think-ing  through solving problems in artificial intelligence: on designing introductory eng ineering and computing courses” , 2016 IEEE International Conference on Teaching, A ssessment, and Learning for Engineering (TALE) , pp. 50-54.S tevens E. et al. (2019), “Identification and analysis of behavioral phenotypes in autism  spectrum disorder via unsupervised machine learning” , International Journal of  Medical Informatics Vol. 129, pp. 29-36, available at h ttps://doi.org/10.1016/j.ijmedinf .2019.05.006, ac cessed 25 June 2022.S tewart A. and D’Mello S. K. (2018), “Connecting the dots towards collaborative AIED: link ing group makeup to process to learning” , International Conference on Artificial Int elligence in Education , pp. 545-56.S titzlein S. M. (2017), American public education and the responsibility of its citizens: supp orting democracy in the age of accountability , Oxford University Press, Oxford.Sujon  Z. (2019), “Disruptive play or platform colonialism? The contradictory dynamics of  Google expeditions and educational virtual reality” , Digital Culture & Education  V ol. 11(1), available at h ttps://www.digitalcultureandeducation.com/volume-11-pa-pers/disruptiv e-play-or-platform-colonialism-the-contradictory-dynamics-of-google-e xpeditions-and-educational-virtual-reality, ac cessed 25 June 2022.Sur den H. (2019), “Artificial intelligence and law: an overview” , Georgia State University L aw Review Vol. 35, available at h ttps://papers.ssrn.com/sol3/papers.cfm?abstract_id=3411869# , ac cessed 25 June 2022.Sur esh H. and Guttag J. V. (2019), “A framework for understanding unintended con-sequenc es of machine learning” , ArXiv Preprint, ArXiv:1901.10002, available at h ttps://ar xiv.org/abs/1901.10002, ac cessed 25 June 2022.Sussk ind R. and Susskind D. (2015), The future of the professions: how technology will tr ansform the work of human experts  (1st edn), Oxford University Press, Oxford.T hompson G. and Cook I. (2017), “The logic of data-sense: thinking through learning personalisa tion” , Discourse: studies in the cultural politics of education  Vol. 38, No. 5, pp . 740-54, available at h ttps://doi.org/10.1080/01596306.2016.1148833, accessed 25 June 2022. T uomi I. (2018), The impact of artificial intelligence on learning, teaching, and educa-tion , Publications Office of the European Union, Luxembourg, available at h ttps://publica tions.jrc.ec.europa.eu/repository/bitstream/JRC113226/jrc113226_jrcb4_the_impac t_of_artificial_intelligence_on_learning_final_2.pdf, ac cessed 25 June 2022.UNDP  (2020), The next frontier: human development and the Anthropocene , United Na tions Development Programme.UNICEF  (2021), Policy guidance on AI for children , available at w ww.unicef.org/globalin-sigh t/media/2356/file/UNICEF-Global-Insight-policy-guidance-AI-children-2.0-2021.pdf .pdf, ac cessed 25 June 2022.UNICEF  and UNESCO (2007), A human rights-based approach to education for all , UNICEF.Unit ed Nations (1992), Declaration on the Rights of Persons Belonging to National or  Ethnic, Religious and Linguistic Minorities , available at w ww.ohchr.org/en/
Page 92  A rtificial intelligence and educationinstruments-mechanisms/instruments/declaration-rights-persons-belonging-na tional-or-ethnic, ac cessed 25 June 2022.Unit ed Nations (2011), Guiding Principles on Business and Human Rights – Implementing the  United Nations “Protect, Respect and Remedy” Framework , available at www .ohchr .org/documents/publications/guidingprinciplesbusinesshr_en.pdf, accessed 25 June 2022. V an Der Hof S. et al. (2020), “The child’s right to protection against economic exploita-tion  in the digital world” , International Journal of Children’s Rights  Vol. 28, No. 4, pp . 833-59.V anLehn K. et al. (2005), “The Andes physics tutoring system: lessons learned” , Int ernational Journal of Artificial Intelligence in Education  Vol. 15, No. 3, pp. 147-204.V eale M. and Borgesius F. Z. (2021), Demystifying the Draft EU Artificial Intelligence Ac t, ArXiv:2107.03721 [Cs], available at h ttps://doi.org/10.9785/cri-2021-220402, ac cessed 25 June 2022.V uorikari R. and Holmes W. (2022), “DigComp 2.2. Annex 2. Citizens Interacting with AI  systems” , in Vuorikari R., Kluzer S. and Punie Y. (eds), DigComp 2.2, The Digital C ompetence Framework for Citizens: with new examples of knowledge, skills and atti-tudes  (pp. 72-82), Publications Office of the European Union, available at h ttps://da ta.europa.eu/doi/10.2760/115376, ac cessed 25 June 2022.V uorikari R., Kluzer S. and Punie Y. (2022), DigComp 2.2: The Digital Competence F ramework for Citizens: with new examples of knowledge, skills and attitudes  (EUR 31006  EN), EU Joint Research Centre, available at h ttps://publications.jrc.ec.europa.eu/r epository/handle/JRC128415, ac cessed 25 June 2022.W alleser E. (2021), “When the world needed it most, artificial intelligence failed: how C ovid-19 poked holes in AI” , Towards Data Science, available at h ttps://towardsda-tascienc e.com/when-the-world-needed-it-most-artificial-intelligence-failed-how-c ovid-19-poked-holes-in-ai-38b742ddc222, ac cessed 25 June 2022.W asson B. (1997), “Advanced educational technologies: the learning environment” , C omputers in Human Behavior Vol. 13, No. 4, pp. 571-94, available at h ttps://doi.or g/10.1016/S0747-5632(97)00027-7, ac cessed 25 June 2022.W aters A. and Miikkulainen R. (2014), “GRADE: machine learning support for graduate admissions ” , AI Magazine Vol. 35, No. 1, p. 64, available at h ttps://doi.org/10.1609/aimag .v35i1.2504, ac cessed 25 June 2022.W atters A. (2021), Teaching machines, MIT Press, Cambridge, MA.W est S. M., Whittaker M. and Crawford K. (2019), Discriminating systems: gender, race and  power in AI, AI Now Institute, available at h ttps://ainowinstitute.org/discriminat-ingsy stems.pdf, ac cessed 25 June 2022.W hittaker M. et al. (2018), AI Now Report 2018, AI Now Institute, New York University, NY.W illiamson B. (2019), “Datafication of education: a critical approach to emerging analyt-ics  technologies and practices” , in Beetham H. and Sharpe R. (eds), Rethinking pedagogy for  a digital age, pp. 212-26, available at h ttps://doi.org/10.4324/9781351252805-14, ac cessed 25 June 2022.
References  P age 93Williamson B. (2020), “New digital laboratories of experimental knowledge produc-tion:  artificial intelligence and education research” , London Review of Education  Vol. 18, No . 2, pp. 209-20.W illiamson B. and Eynon R. (2020), “Historical threads, missing links, and future direc-tions  in AI in education” , Learning, Media and Technology Vol. 45, No. 3, pp. 223-35, a vailable at h ttps://www.tandfonline.com/doi/full/10.1080/17439884.2020.1798995 , accessed 25 June 2022.W infield A. F. T. and Jirotka M. (2018), “Ethical governance is essential to building trust  in robotics and artificial intelligence systems” , Philosophical Transactions of the Ro yal Society A Vol. 376, No. 2133, available at h ttps://doi.org/10.1098/rsta.2018.0085, ac cessed 25 June 2022.W ollny S. et al. (2021), “Are we there yet? A systematic literature review on chatbots in  education” , Frontiers in Artificial Intelligence Vol. 4, available at w ww.frontiersin.or g/article/10.3389/frai.2021.654924, ac cessed 25 June 2022.W oolf B. P . (2010), Building intelligent interactive tutors: student-centered strategies for r evolutionizing e-learning , Morgan Kaufmann, Burlington, MA.W orld Economic Forum (2015), New vision for education: unlocking the potential of t echnology, World Economic Forum, available at w ww3.weforum.org/docs/WEFUSA_NewV isionforEducation_Report2015.pdf, ac cessed 25 June 2022.Y eung K. (2020), “Recommendation of the council on artificial intelligence (OECD)” , Int ernational Legal Materials  Vol. 59, No. 1, pp. 27-34.Zanz otto F. M. (2019), “Human-in-the-loop artificial intelligence” , Journal of Artificial Int elligence Research Vol. 64, pp. 243-52.Za wacki-Richter O. et al. (2019), “Systematic review of research on artificial intelligence applica tions in higher education – Where are the educators?” , International Journal of  Educational Technology in Higher Education Vol. 16, No. 39, available at h ttps://doi.or g/10.1186/s41239-019-0171-0, ac cessed 25 June 2022.Z eide E. (2019), Artificial intelligence in higher education: applications, promise and perils, and  ethical questions, Educause, available at h ttps://er.educause.edu/articles/2019/8/ar tificial-intelligence-in-higher-education-applications-promise-and-perils-and-eth-icalquestions, ac cessed 25 June 2022.

 Page 95Appendix I Definitions of AI T he following examples are given here to illustrate the range of available defi-nitions of AI. John  McCarthy (who is credited with coining the term artificial intelligence), 1955129T he artificial intelligence problem is taken to be that of making a machine behave in w ays that would be called intelligent if a human were so behaving.O xford English Dictionary, 2006T he capacity of computers or other machines to exhibit or simulate intelligent behaviour.S tanford University, 2016130A  branch of computer science that studies the properties of intelligence by synthesizing in telligence.OECD , 2019131A n AI system is a machine-based system that can, for a given set of human-defined objec tives, make predictions, recommendations, or decisions influencing real or virtual en vironments. AI systems are designed to operate with varying levels of autonomy .C ouncil of Europe, 2021132A  set of sciences, theories and techniques whose purpose is to reproduce by a machine the  cognitive abilities of a human being. Current developments aim, for instance, to be able t o entrust a machine with complex tasks previously delegated to a human.E uropean Union, 2021133S oftware that is developed with one or more of the techniques and approaches listed in  Annex I and can, for a given set of human-defined objectives, generate outputs such as  content, predictions, recommendations, or decisions influencing the environments they in teract with.129. h ttp://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html. 130. h ttps://ai100.stanford.edu/2016-report. 131. h ttps://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449. 132. w ww.coe.int/en/web/artificial-intelligence/glossary. 133. h ttps://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206. 
Page 96  A rtificial intelligence and educationANNEX I(a )  Machine learning approaches, including supervised, unsupervised and reinforcement lear ning, using a wide variety of methods including deep learning;( b)  Logic- and knowledge-based approaches, including knowledge representation, induc tive (logic) programming, knowledge bases, inference and deductive engines, (symbolic) r easoning and expert systems;(c)   Statistical approaches, Bayesian estimation, search and optimization methods.P arliamentary Assembly of the Council of Europe, 2021134C omputer-based systems that can perceive and derive data from their environment, and  then use statistical algorithms to process that data in order to produce results in tended to achieve pre-determined goals. The algorithms consist of rules that may be established  by human input, or set by the computer itself, which “trains” the algorithm b y analysing massive data sets and continues to refine the rules as new data is received.UNICEF , 2021135M achine-based systems that can, given a set of human-defined objectives, make pr edictions, recommendations, or decisions that influence real or virtual environments. AI  systems interact with us and act on our environment, either directly or indirectly. O ften, they appear to operate autonomously, and can adapt their behaviour by learning about the c ontext.UNESC O, 2021136AI  systems are information-processing technologies that integrate models and algorithms tha t produce a capacity to learn and to perform cognitive tasks leading to outcomes such  as prediction and decision-making in material and virtual environments. AI systems ar e designed to operate with varying degrees of autonomy by means of knowledge modelling and r epresentation and by exploiting data and calculating correlations.134. h ttps://pace.coe.int/en/pages/artificial-intelligence. 135. w ww.unicef.org/globalinsight/reports/policy-guidance-ai-children. 136. h ttps://unesdoc.unesco.org/ark:/48223/pf0000381137. 
 Page 97Appendix II Rec ent related C ouncil of Europe reportsA rtificial intelligence, human rights, democracy, and the rule of law: a primerExplor es AI and the core Council of Europe values – human rights, democracy and the rule of la w. Education is not included.L eslie D., Burr C., Aitken M., Cowls J., Katell M. and Briggs M. (2021), “Artificial intelli-genc e, human rights, democracy, and the rule of law: a primer” , Council of Europe, w ww.turing.ac.uk/research/publications/ai-human-rights-democracy-and-rule-la w-primer-prepared-council-europeC onvention 108+ – Convention for the Protection of Individuals with regard to the P rocessing of Personal DataO utlines data protection guidelines, but does not directly refer to AI. Some of the issues r aised in this report relate to Convention 108.C ouncil of Europe (2018), Convention 108+ – Convention for the Protection of I ndividuals with regard to the Processing of Personal Data, h ttps://rm.coe.int/c onvention-108-convention-for-the-protection-of-individuals-with-regar/16808b36f1D igital Citizenship Guidelines for school-industry partnershipsO utlines guidelines for school-industry partnership. AI is briefly mentioned and the guidelines  can be further expanded to address broader aspects discussed in this report.C ouncil of Europe, DCE Expert Group (2019), “Digital Citizenship Guidelines for school-industr y partnerships” , www.ictcoalition.eu/medias/uploads/source/F orum%2002072019/CoE%20digital%20citizenship%20guidelines%20June%202019%20%20-%20%20R ead-Only.pdfHandbook on E uropean data protection lawDa ta protection law is referred to in this report.E uropean Union Agency for Fundamental Rights and Council of Europe (2018), Handb ook on European data protection law , www.echr.coe.int/Documents/Handbook_da ta_protection_ENG.pdf
Page 98  A rtificial intelligence and educationHigher education’s response to the Covid-19 pandemic – Building a more sustainable and democr atic futureI ndicates the importance of digital education, democracy and inclusion with a focus on higher educa tion.B ergan S., Gallagher T., Harkavy I., Munck R. and Hilligje van’t Land (eds) (2021), Higher educ ation’s response to the Covid-19 pandemic – Building a more sustainable and dem-o cratic future, Council of Europe Publishing, Higher Education Series No. 25, h ttps://r m.coe.int/prems-006821-eng-2508-higher-education-series-no-25/1680a19fe2H igher education for diversity, social inclusion and community – A democratic imper ativeD oes not explicitly refer to AI but some of the issues raised in this report refer to the democr atic imperative.B ergan S. and Harkavy I. (eds) (2018), Higher education for diversity, social inclusion and c ommunity – A democratic imperative , Council of Europe Publishing, Higher Education S eries No. 22, https://rm.coe.int/higher-education-for-diversity-16x24-web/16808e4a7aI nternet Governance – Council of Europe Strategy 2016-2019. Democracy, human righ ts and the rule of law in the digital worldT here is no reference to AI, but the internet governance is relevant to issues discussed in this r eport.C ouncil of Europe (2016), “Internet Governance – Council of Europe Strategy 2016-2019. D emocracy, human rights and the rule of law in the digital world” ,  https://rm.coe.int/in ternet-governance-strategy-2016-2019-updated-version-06-mar-2018/1680790ebeT he Reference Framework of Competences for Democratic Culture in briefAI is r eferenced in this report when referring to competences.C ouncil of Europe (2021), The Reference Framework of Competences for Democratic C ulture in brief, https://rm.coe.int/prems-004721-the-reference-framework-of-com-pet ences-for-democratic-cul/1680a27f24Unbo xing artificial intelligence: 10 steps to protect human rightsT his report makes several references to AI literacy, including both the technological and human dimensions , but does not address the application of AI in education.C ouncil of Europe Commissioner for Human Rights (2019), “Unboxing arti-ficial  intelligence: 10 steps to protect human rights” , https://rm.coe.int/unbo xing-artificial-intelligence-10-steps-to-protect-human-rights-reco/1680946e64
 Page 99Appendix III Rec ent related reports fr om other institutionsT he impact of artificial intelligence on learning, teaching, and education (European C ommission)O ffers a broad focus on what AI in education involves, rather than considering adoption or  offering a critical view from the lenses of human rights, democracy and rule of law.T uomi I., Punie Y., Vuorikari R. and Cabrera M. (eds) (2018), The impact of artificial intel-ligenc e on learning, teaching, and education , European Commission, Joint Research C entre, h ttps://op.europa.eu/en/publication-detail/-/publication/5cb8eee3-e888-11e8-b690-01aa75ed71a1 E thics guidelines for trustworthy AI  (European Commission)P rovides guidelines for trustworthy AI, some of which are elaborated in this report in the c ontext of AI and education.Dir ectorate-General for Communications Networks, Content and Technology (2019), E thics guidelines for trustworthy AI , European Commission, https://op.europa.eu/en/publica tion-detail/-/publication/d3988569-0434-11ea-8c1f-01aa75ed71a1OECD  Digital Education Outlook 2021: pushing the frontiers with artificial intel-ligenc e, blockchain and robots (OECD)Discusses  research perspectives, while this report focuses on adoption and a critical view thr ough the lens of human rights, democracy and the rule of law.OECD  (2021), OECD Digital Education Outlook 2021: pushing the frontiers with artificial int elligence, blockchain and robots , OECD Publishing, w ww.oecd.org/education/oec d-digital-education-outlook-7fbfff45-en.htmT rustworthy artificial intelligence (AI) in education: promises and challenges (OECD)T his paper was written to support the G20 artificial intelligence dialogue but there is  no explicit discussion with regard to human rights, democracy and the rule of la w. Also, this report offers a broader perspective of AI and education with a focus on adoption. V incent-Lancrin S. and van der Vlies R. (2020), Trustworthy artificial intelligence (AI) in educ ation: promises and challenges, OECD Education Working Paper No. 218 , www.oecd.or g/education/trustworthy-artificial-intelligence-ai-in-education-a6c90fa9-en.htm
Page 100  A rtificial intelligence and educationBeijing Consensus on Artificial Intelligence and Education (UNESCO)O utcome document of the International Conference on Artificial Intelligence and E ducation “Planning education in the AI era: Lead the leap” .UNESC O (2021), Beijing Consensus on Artificial Intelligence and Education, https://unesdoc .unesco.org/ark:/48223/pf0000368303AI and educa tion: guidance for policy-makers  (UNESCO)U ses similar historic references but does not offer a critical view, especially with r egard to human rights, democracy and rule of law.M iao F. and Holmes W. (2021), AI and education: guidance for policy-makers , UNESCO, h ttps://unesdoc.unesco.org/ark:/48223/pf0000376709I ntergovernmental Meeting of Experts (Category II) related to a Draft R ecommendation on the Ethics of Artificial Intelligence (UNESCO)Discusses  AI and ethics issues, some of which are elaborated in this report in the c ontext of AI and education.UNESC O (2021), Intergovernmental Meeting of Experts (Category II) related to a Draft Rec ommendation on the Ethics of Artificial Intelligence, h ttps://unesdoc.unesco.org/ar k:/48223/pf0000377897K -12 AI curricula: a mapping of government-endorsed AI curricula (UNESCO)T ouches on AI literacy, but this report offers a deeper discussion.M iao F. and Shiohira K. (2022), K-12 AI curricula: a mapping of government-endorsed AI  curricula, UNESCO’s Unit for Technology and Artificial Intelligence in Education, h ttps://unesdoc.unesco.org/ark:/48223/pf0000380602P olicy guidance on AI for children (UNICEF)C onsiders the range of ways in which AI systems impact children today, which are illustr ated by use cases or examples that highlight the key opportunities, risks and c oncerns.UNICEF  (2021), Policy guidance on AI for children,  www.unicef.org/globalinsight/media/2356/file/UNICEFGlobal-Insight-policy-guidance-AI-children-2.0-2021.pdf.pdfA rtificial intelligence for children – Toolkit  (World Economic Forum)D esigned to help companies, designers, parents, guardians, children and youth ensur e that AI respects the rights of children and has a positive impact in their lives.W orld Economic Forum (2022), Artificial intelligence for children – Toolkit,  https://w ww3.weforum.org/docs/WEF_Artificial_Intelligence_for_Children_2022.pdf
 Page 101Appendix IV Re views of AIED researchA leven V., McLaren B. M., Sewall J., van Velsen M., Popescu O., Demi S., Ringenberg M. and  Koedinger K. R. (2016), “Example-tracing tutors: intelligent tutor development for non-pr ogrammers” , International Journal of Artificial Intelligence in Education  Vol. 26, pp . 224-69, h ttps://link.springer.com/article/10.1007/s40593-015-0088-2. A leven V., McLaughlin E. A., Glenn R. A. and Koedinger K. R. (2017), “Instruction based on  adaptive learning technologies” , in Mayer R. E. and Alexander P . (eds), Handbook of  research on learning and instruction  (2nd edn), pp. 522-60, Routledge, New York, w ww.cs.cmu.edu/afs/.cs.cmu.edu/Web/People/aleven/Papers/2016/Aleven_etal_Handbook2016_A daptiveLearningTechnologies_Prepub.pdf. A leven V., Roll I., McLaren B. M. and Koedinger K. R. (2016), “Help helps, but only so much:  research on help seeking with intelligent tutoring systems” , International J ournal of Artificial Intelligence in Education  Vol. 26, pp. 205-23, h ttps://link.springer.c om/article/10.1007/s40593-015-0089-1. Baker  R. S. (2016), “Stupid tutoring systems, intelligent humans” , International Journal of  Artificial Intelligence in Education  Vol. 26, pp. 600-14, h ttps://link.springer.com/ar ticle/10.1007/s40593-016-0105-0. B oulay B. (du) (2016), “Artificial intelligence as an effective classroom assistant” , IEEE Int elligent Systems Vol. 31, No. 6, pp. 76-81, w ww.doi.org/10.1109/MIS.2016.93. B oulay B. (du), Mitrovic T. and Yacef K. (eds) (in preparation), Handbook of artificial int elligence in education , Edward Elgar Publishing, Cheltenham, Glos.Bull  S. and Kay J. (2016), “SMILI ☺: a framework for interfaces to learning data in open  learner models, learning analytics and related fields” , International Journal of  Artificial Intelligence in Education  Vol. 26, pp. 293-331, h ttps://link.springer.com/ar ticle/10.1007/s40593-015-0090-8. Char itopoulos A., Rangoussi M. and Koulouriotis D. (2020), “On the use of soft c omputing methods in educational data mining and learning analytics research: a r eview of years 2010-2018” , International Journal of Artificial Intelligence in Education  V ol. 30, pp. 371-430, h ttps://link.springer.com/article/10.1007/s40593-020-00200-8. C ukurova M., Luckin R. and Kent C. (2020), “Impact of an artificial intelligence research fr ame on the perceived credibility of educational research evidence” , International J ournal of Artificial Intelligence in Education  Vol. 30, pp. 205-35, h ttps://link.springer.c om/article/10.1007/s40593-019-00188-w. D ’Mello S. K. (2016), “Giving eyesight to the blind: towards attention-aware AIED” , Int ernational Journal of Artificial Intelligence in Education  Vol. 26, pp. 645-59, h ttps://link .springer.com/article/10.1007/s40593-016-0104-1. 
Page 102  A rtificial intelligence and educationDermeval D., Paiva R., Bittencourt I., Vassileva J. and Borges D. (2018), “Authoring t ools for designing intelligent tutoring systems: a systematic review of the literature” , Int ernational Journal of Artificial Intelligence in Education  Vol. 28, pp. 336-84, h ttps://link .springer.com/article/10.1007/s40593-017-0157-9. Dillenbour g P .(2016), “The evolution of research on digital education” , International J ournal of Artificial Intelligence in Education  Vol. 26, pp. 544-60, h ttps://link.springer.c om/article/10.1007/s40593-016-0106-z. Har ley J. M., Lajoie S. P ., Frasson C. and Hal N. C. (2017), “Developing emotion-aware, adv anced learning technologies: a taxonomy of approaches and features” , International J ournal of Artificial Intelligence in Education  Vol. 27, pp. 268-97, h ttps://link.springer.c om/article/10.1007/s40593-016-0126-8. Holmes  W. (2020), “Artificial intelligence in education” , in Tatnall A. (ed.), Encyclopedia of educ ation and information technologies , pp. 88-103, Springer International Publishing, h ttps://doi.org/10.1007/978-3-030-10576-1_107. Holmes  W., Bialik M. and Fadel C. (2019), Artificial intelligence in education: prom-ises  and implications for teaching and learning , Center for Curriculum Redesign, B oston, MA.Holmes  W., Porayska-Pomsta K., Holstein K., Sutherland E., Baker T., Shum S., Santos O ., Rodrigo M., Cukurova M., Bittencourt I. and Koedinger K. (2021), “Ethics of AI in educa tion: towards a community-wide framework” , International Journal of Artificial Int elligence in Education, https://link.springer.com/article/10.1007/s40593-021-00239-1. K im Y. and Baylor A. L. (2016), “Research-based design of pedagogical agent r oles: a review, progress, and recommendations” , International Journal of Artificial Int elligence in Education  Vol. 26, pp. 160-69, h ttps://link.springer.com/article/10.1007/s40593-015-0055y. K urdi G., Leo J., Parsia B., Sattler U. and Al-Emari S. (2020), “A systematic review of aut omatic question generation for educational purposes” , International Journal of A rtificial Intelligence in Education  Vol. 30, pp. 121-204, h ttps://link.springer.com/ar ticle/10.1007/s40593-019-00186-y. L uckin R., George K. and Cukurova M. (2022), AI for school teachers, CRC Press, Boca R aton, FL, h ttps://doi.org/10.1201/9781003193173. L uckin R. and Holmes W. (2016), Intelligence unleashed: an argument for AI in education , UCL K nowledge Lab, London.M arkauskaite L., Marrone R., Poquet O., Knight S., Martinez-Maldonado R., Howard S.,  Tondeur J., De Laat M., Buckingham Shum S., Gašević D. and Siemens G. (2022), “R ethinking the entwinement between artificial intelligence and human learning: what capabilities  do learners need for a world with AI?” , Computers and Education: Artificial Int elligence Vol. 3, w ww.sciencedirect.com/science/article/pii/S2666920X2200011X. P inkwart N. (2016), “Another 25 years of AIED? Challenges and opportunities for in telligent educational technologies of the future” , International Journal of Artificial Int elligence in Education  Vol. 26, pp. 771-83, h ttps://link.springer.com/article/10.1007/s40593-016-0099-7 . 
Appendix IV  P age 103Rummel N., Walker E. and Aleven V. (2016), “Different futures of adaptive collaborative lear ning support” , International Journal of Artificial Intelligence in Education  Vol. 26, pp . 784-95, h ttps://link.springer.com/article/10.1007/s40593-016-0102-3. S antos O. (2016), “Training the body: the potential of AIED to support personalized mot or skills learning” , International Journal of Artificial Intelligence in Education  Vol. 26, pp . 730-55, h ttps://link.springer.com/article/10.1007/s40593-016-0103-2. S ottilare R. A., Burke S., Salas E., Sinatra A. M., Johnston J. H. and Gilbert S. B. (2018), “D esigning adaptive instruction for teams: a meta-analysis” , International Journal of  Artificial Intelligence in Education  Vol. 28, pp. 225-64, h ttps://link.springer.com/ar ticle/10.1007/s40593-017-0146-z. 

 Page 105Appendix V S ome examples of studen t-supporting AIED t oolsT he following examples of student-supporting AIED tools is given here only t o illustrate just how many such tools already exist, many of which are  multi-milliondollar-funded, and many of which are being widely implemented b y national governments. P lease note that the inclusion of any particular tool in the following list does not c onstitute a recommendation of that tool by either the authors of this report or by the C ouncil of Europe. NB All links were accessible in July 2022.A lef (h ttps://www.alefeducation.com) ALEKS ( w ww.aleks.com) A lta (w ww.knewton.com) A mritaCREATE (w ww.amritacreate.org) A rea9 (h ttps://area9learning.com) ASSIST ments (h ttps://new.assistments.org) B etter Marks (h ttps://bettermarks.com) B yjus (h ttps://byjus.com) C ogBooks (w ww.cogbooks.com) C ognii (w ww.cognii.com) D omoscio (h ttps://domoscio.com/en/domoscio-spark-2) Dr eambox (w ww.dreambox.com) EnL earn (w ww.enlearn.org) I nq-ITS (w ww.inqits.com) iR eady (w ww.curriculumassociates.com/Products/i-Ready) Laix ( w ww.liulishuo.com) M athia (w ww.carnegielearning.com) Q ubena (h ttps://qubena.com) R ealizeIt (h ttp://realizeitlearning.com) 
Page 106  A rtificial intelligence and educationQuerium (h ttp://querium.com) Smar t Sparrow (w ww.smartsparrow.com) Snappet ( h ttps://nl.snappet.org) S offos (h ttps://soffos.ai) S quirrel AI (h ttp://squirrelai.com) Summit L earning (w ww.summitlearning.org) T hinkster Math (h ttps://hellothinkster.co.uk) T oppr (w ww.toppr.com) 
 Page 107About the authorsW ayne Holmes (PhD, University of Oxford) is an Associate Professor (learning sciences and  innovation) at University College London, and is a researcher on AI and education ( AI&ED) for IRCAI (the International Research Centre on artificial intelligence under the auspic es of UNESCO), UNESCO’s Technology and Artificial Intelligence in Education Unit  and the Council of Europe. Having been involved in education throughout his lif e, Wayne brings a critical studies perspective to the connections between AI and educa tion, and their social and ethical implications. His recent publications include A rtificial intelligence in education: promises and implications for teaching and learning  (2019),  Ethics of AI in education: towards a community-wide framework  (2021), The ethic s of AI in education: practices, challenges and debates  (2022) and, for UNESCO, AI  and education: guidance for policy-makers  (2021). Wayne also co-authored the EU ’s DigComp 2.2. Annex 2. Citizens interacting with AI systems  (2022) and has given in vited talks on AI&ED in Brazil, China, Croatia, Denmark, Germany, Greece, India, Japan,  Oman, Portugal, Slovenia, Spain and the USA (and online to audiences in man y other countries around the world). ORCID: 0000-0002-8352-1594.Jen  Persson is Director of defend digital me. This not-for-profit organisation is a call  to action to protect children’s rights in the digital environment in education. I t was founded in 2016 by teachers and parents who campaign for safe, fair and tr ansparent data processing in England and beyond. Jen supported the Council of E urope Consultative Committee of the Convention for the Protection of Individuals with  Regard to Processing of Personal Data (Convention 108) in the development of Guidelines on Childr en’s Data Protection in an Education setting adopted in 2020.I rene-Angelica Chounta  is a Junior Professor (tenure-track) in Computational Methods in  Modelling and Analysis of Learning Processes at the Department of Computer S cience and Applied Cognitive Science, University of Duisburg-Essen in Germany. Her r esearch focuses on computational learning analytics (LA) for technology-enhanced lear ning (TEL), AI in education (AIED) and educational technologies. Her main research in terest is to model learners’ behaviour in order to provide evidence-based, adaptive and  personalised feedback, in a variety of contexts: from intelligent tutoring systems and  computer-supported collaborative learning environments to hackathons and makerspac es. In 2019, she was awarded a four-year start-up grant from the Estonian R esearch Council for her research on “Combining machine learning and learning analytics  to provide personalised scaffolding for computer-supported learning ac tivities” . Irene was born and raised in Athens, Greece, and studied at the University of  Patras. She has lived and worked in Germany (University of Duisburg-Essen), USA ( Carnegie Mellon University) and Estonia (University of Tartu). Currently, she serves as  a Communications Co-Chair for the International Society of the Learning Sciences (ISLS),  and she is an active member of the International Artificial Intelligence in E ducation Society (IAIED) and the Society for Learning Analytics Research (SoLAR). OR CID: 0000-0001-9159-0664.
Page 108  A rtificial intelligence and educationBarbara Wasson is a full Professor of Information Science at the Department of I nformation Science and Media Studies, University of Bergen, Norway, and Director of  the Centre for the Science of Learning & Technology (SLATE), the national compe-t ence centre for learning analytics funded by the Norwegian Ministry of Education. Her  research work in the field of technology-enhanced learning (TEL) has ranged fr om AI in education, computer-supported collaborative learning, mobile learning, lear ning games, learning analytics and data literacy. Wasson was a co-founder of K aleidoscope, the European Network of Excellence, served on the executive board and  led the Computer-supported Collaborative Learning Special Interest Group (CSCL Sig)  with 400 members. She was programme co-chair of Quantitative Ethnography 2021  and is programme co-chair for the Society of Learning Analytics conference LAK24.  She is on the editorial board of Designs for Learning, the Italian Journal of E ducational Technology  and the Nordic Journal of Digital Literacy . Currently Wasson is  on the steering board of UiB AI (University of Bergen) and a member of the UiB r ector’s expert group EU Forum, in addition to her work for the Council of Europe, she  is a member of the Norwegian Government’s expert group on learning analyt-ics , which is looking at the technical, pedagogical, legal and ethical aspects of the implemen tation of learning analytics in the Norwegian educational sector. ORCID: 0000-0003-4897-1394. V ania Dimitrova is a full Professor (Chair) of Human-Centred Artificial Intelligence a t the School of Computing, University of Leeds, UK. Her research focuses on building  systems that help people make sense of data, take decisions in complex settings , expand their knowledge and learn from experience. She explores the use of  data and knowledge models to get insights into user-generated content, under-stand  users and influence behaviour, capture knowledge and support information e xploration. She is currently President of the International AI in Education Society and  Co-Director of the UKRI Centre for Doctoral Training in AI for Medical Diagnosis and  Care. She was Co-Director of the Leeds Research Centre in Digital Learning and w as Director of Technology Enhanced Learning Strategy at the Leeds Institute of M edical Education. She is associate editor of both the International Journal of AI in E ducation and Frontiers of AI: AI for Human Learning and Behavior Change . She was associa te editor of IEEE Transactions on Learning Technologies  (IEEE-TLT), a member of  the editorial boards for the personalisation journal UMUAI and chaired several in ternational conferences in intelligent learning environments (AIED, ECTEL, ICCE). She  co-ordinated the ImREAL EU project which developed AI technologies to aid cultur al awareness training. ORCID: 0000-0002-7001-0891.

Sales agents for publications of the Council of EuropeAgents de vente des publications du Conseil de l’Europe BELGIUM/BELGIQUE  La Librairie Européenne -  The European Bookshop  Rue de l’Orme, 1 BE-1040 BRUXELLES  Tel.: + 32 (0)2 231 04 35  Fax: + 32 (0)2 735 08 60  E-mail: info@libeurop.eu  http://www.libeurop.be Jean De Lannoy/DL Services  c/o Michot Warehouses  Bergense steenweg 77   Chaussée de Mons  BE-1600 SINT PIETERS LEEUW  Fax: + 32 (0)2 706 52 27  E-mail: jean.de.lannoy@dl-servi.com  http://www.jean-de-lannoy.be CANADA   Renouf Publishing Co. Ltd.  22-1010 Polytek Street   CDN-OTTAWA, ONT K1J 9J1   Tel.: + 1 613 745 2665  Fax: + 1 613 745 7660  Toll-Free Tel.: (866) 767-6766  E-mail: order.dept@renoufbooks.com  http://www.renoufbooks.com CROATIA/CROATIE  Robert’s Plus d.o.o.  Marasoviçeva 67 HR-21000  SPLIT  Tel.: + 385 21 315 800, 801, 802, 803  Fax: + 385 21 315 804 E-mail: robertsplus@robertsplus.hr CZECH REPUBLIC/  RÉPUBLIQUE TCHÈQUE  Suweco CZ, s.r.o. Klecakova 347  CZ-180 21 PRAHA 9  Tel.: + 420 2 424 59 204 Fax: + 420 2 848 21 646 E-mail: import@suweco.cz  http://www.suweco.cz DENMARK/DANEMARK GAD  Vimmelskaftet 32 DK-1161 KØBENHAVN K  Tel.: + 45 77 66 60 00  Fax: + 45 77 66 60 01  E-mail: reception@gad.dk  http://www.gad.dk FINLAND/FINLANDE Akateeminen Kirjakauppa  PO Box 128  Keskuskatu 1  FI-00100 HELSINKI  Tel.: + 358 (0)9 121 4430  Fax: + 358 (0)9 121 4242  E-mail: akatilaus@akateeminen.com  http://www.akateeminen.com FRANCE  Please contact directly /  Merci de contacter directement  Council of Europe Publishing Éditions du Conseil de l’Europe  F-67075 STRASBOURG Cedex  Tel.: + 33 (0)3 88 41 25 81 Fax: + 33 (0)3 88 41 39 10  E-mail: publishing@coe.int  http://book.coe.int Librairie Kléber  1, rue des Francs-Bourgeois  F-67000 STRASBOURG  Tel.: + 33 (0)3 88 15 78 88 Fax: + 33 (0)3 88 15 78 80  E-mail: librairie-kleber@coe.int  http://www.librairie-kleber.com NORWAY/NORVÈGE  Akademika  Postboks 84 Blindern NO-0314 OSLO  Tel.: + 47 2 218 8100  Fax: + 47 2 218 8103 E-mail: support@akademika.no http://www.akademika.no POLAND/POLOGNE  Ars Polona JSC  25 Obroncow Street  PL-03-933 WARSZAWA  Tel.: + 48 (0)22 509 86 00 Fax: + 48 (0)22 509 86 10 E-mail: arspolona@arspolona.com.pl  http://www.arspolona.com.pl PORTUGAL  Marka Lda  Rua dos Correeiros 61-3 PT-1100-162 LISBOA  Tel: 351 21 3224040 Fax: 351 21 3224044 E mail: apoio.clientes@marka.pt  www.marka.pt RUSSIAN FEDERATION/ FÉDÉRATION DE RUSSIE  Ves Mir  17b, Butlerova ul. - Office 338  RU-117342 MOSCOW  Tel.: + 7 495 739 0971  Fax: + 7 495 739 0971  E-mail: orders@vesmirbooks.ru  http://www.vesmirbooks.ru SWITZERLAND/SUISSE  Planetis Sàrl  16, chemin des Pins  CH-1273 ARZIER  Tel.: + 41 22 366 51 77  Fax: + 41 22 366 51 78  E-mail: info@planetis.ch TAIWAN  Tycoon Information Inc.   5th Floor, No. 500, Chang-Chun Road  Taipei, Taiwan  Tel.: 886-2-8712 8886  Fax: 886-2-8712 4747, 8712 4777 E-mail: info@tycoon-info.com.tw  orders@tycoon-info.com.tw UNITED KINGDOM/ROYAUME-UNI The Stationery Office Ltd PO Box 29  GB-NORWICH NR3 1GN  Tel.: + 44 (0)870 600 5522 Fax: + 44 (0)870 600 5533  E-mail: book.enquiries@tso.co.uk  http://www.tsoshop.co.uk UNITED STATES and CANADA/  ÉTATS-UNIS et CANADA  Manhattan Publishing Co 670 White Plains Road  USA-10583 SCARSDALE, NY  Tel: + 1 914 472 4650 Fax: + 1 914 472 4316 E-mail: coe@manhattanpublishing.com http://www.manhattanpublishing.com Council of Europe Publishing/Éditions du Conseil de l’Europe F-67075  STRASBOURG Cedex Tel.: + 33 (0)3 88 41 25 81 – Fax: + 33 (0)3 88 41 39 10  – E-mail: publishing@coe.int – Website: http://book.coe.int
ENGT he Council of Europe is the continent’s leading human r ights organisation. It comprises 46 member stat es, including all members of the European Union. All C ouncil of Europe member states have sig ned up to the European Convention on Human R ights, a treaty designed to protect human rights, democrac y and the rule of law. The European Court of Human R ights oversees the implementation of the C onvention in the member states.www.coe.intPREMS 092922 Artificial intelligence (Al) is increasingly having an impact on  education, bringing opportunities as well as numerous challenges . These observations were noted by the Council of  Europe’s Committee of Ministers in 2019 and led to the c ommissioning of this report, which sets out to examine the c onnections between Al and education (AI&ED). In particu-lar , the report presents an overview of AI&ED seen through the  lens of the Council of Europe values of human rights, democr acy and the rule of law; and it provides a critical analy sis of the academic evidence and the myths and hype.T he Covid-19 pandemic school shutdowns triggered a rushed  adoption of educational technology, which increas-ingly  includes AI-assisted classrooms tools (AIED). This AIED, which  by definition is designed to influence child develop-men t, also impacts on critical issues such as privacy, agency and  human dignity – all of which are yet to be fully explored and  addressed. But AI&ED is not only about teaching and lear ning with AI, but also teaching and learning about AI (AI lit eracy), addressing both the technological dimension and the of ten-forgotten human dimension of AI.T he report concludes with a provisional needs analysis – the aim  being to stimulate further critical debate by the Council of  Europe’s member states and other stakeholders and to ensur e that education systems respond both proactively and  effectively to the numerous opportunities and chal-lenges in troduced by AI&ED.h ttp://book.coe.intISBN 978-92-871-9236-3  €49/US$98 
