The Center for Democracy & Technology is convening industry representatives, researchers, government officials,  and civil rights advocates to develop principles to guide fair and responsible use of machine learning and algorithmic  decision-making. Sophisticated statistical analysis is a pillar of decision making in the 21st Century, including employment, lending, and  policing. Automated systems also mediate our access to information and community through search results and social  media. These technologies are pivotal to day-to-day life, but the processes that govern them are not transparent.  Civil rights and privacy advocates have expressed concern that this erodes accountability and fairness.   CDT is  working with stakeholders to develop guidance that ensures the rights of individuals, encourages innovation and  design incentives that promote responsible use. The question of how to ensure fairness in automated systems is complicated and will require thoughtful and candid  debate. CDT is providing a trusted space for individuals to share information and develop ideas within our Internet  Privacy Working Group.  CDT’s goal is to bring representatives from the technology industry and advocacy community  together to develop and codify realistic and forward-thinking protections that advance civil rights. + Technology Algorithms can take input data and categorize it according  to a set scheme to produce a prediction, a characterization,  or an inferred attribute. More sophisticated algorithms  can determine what is significant from historic data. This  process is called “machine learning,” which “automates  the process of discovering useful patterns, revealing  regularities upon which subsequent decision-making  can rely.”   Because of the power and relative costeffectiveness of this technique, companies are collecting  and buying large databases to feed into automated  decision-making systems. CONTACT For more information from CDT on this topic, contact Ali Lange  at (202) 407-8838 or alange @cdt.orgCENTER FOR DEMOCRACY & TECHNOLOGY + Civil Rights Computer scientists have argued that relying on  algorithms does not assure unbiased decisions,  despite the perception that mathematical systems  may be inherently fair. Big data analysis may never  be as accurate for minority populations where less  information is available as it is for majority populations.   When this technology is applied in a various contexts,  such as workplace or healthcare data, some groups  may be disproportionately over or under represented.  Additionally, the lack of transparency makes it harder for  individuals to understand what characteristics about them  were relevant to the decision. Without this information,  individuals (as well as advocates and regulators) cannot  be sure if they were evaluated fairly. + Vision for the Future Guidance for ethical use of automated decision-making  technology could help address deep-seated cultural bias  that has yet to be rooted out by civil rights laws. This is an  opportunity to demystify digital decision-making to create  principles for advocates and dynamic and responsive  criteria that can be implemented by industry. By looking  at positive examples of using big data as well as pitfalls,  we can analyze the incentive structure that achieves the  best results. + What’s at Stake? Automated decision-making plays a fundamental role in  society from allocating where police patrol to determining  what financial instruments and jobs are available to  individuals. Because of this, the question of how to  regulate algorithmic decision-making has implications for  individuals’ economic stability, individual well-being, and  future success. At the same time, automated processes  are crucial and invaluable parts of our digital ecosystem,  like credit card fraud detection and search engines.  Principled automated decision-making will encourage  innovation that maintains a positive social impact.DIGITAL DECISIONS: Building Trust in Algorithms
