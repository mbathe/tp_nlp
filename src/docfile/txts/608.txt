       GUIDANCE  ON  HUMAN  RIGHTS   IMPACT   ASSESSMENT  OF DIGITAL   ACTIVITIES   INTRODUCTION 
      INTRODUCTION     A cknowledgments: This 2020 version of the Guidance was written by Emil   Lindblad Kernell and Cathrine  Bloch  Veiberg,  with  research  assistance  from   Claire Jacquot. We would also like to thank Eva Grambye, Elin Wrzoncki, Tulika  Bansal and Ioana Tuta for their input and support. The Guidance has been  developed on the basis of the HRIA Guidance and Toolbox . We also received   invaluable  input from sever al individuals and organisations  who contributed  their expertise,  reflections and time on  a voluntary basis,  for which we are  deeply thankful. We wish to extend our sincere thanks to: Rikke Frank Jørgensen from the Danish Institute for Human Rights; Richard Wingfield from Global   Partners Digital; Jan Rydzak from Ranking Digital Rights; Jason Pielemeier and   David Sullivan from Global Networking Initiative (GNI); Molly Land from University of Connecticut School of Law; Alex Warofka from Facebook; Nicole   Karlebach from Verizon; Alexandria Walden from Google; Michael Karimian from Microsoft; Patrik Hiselius from Telia; Dunstan Allison -Hope from BSR; Margaret   Wachenfeld from Institute for Human Rights and Business (IHRB); Mark Hodge   and Lene Wendland from OHCHR and the B -Tech project; Isabel Ebert, University   of St. Gallen, on behalf of the German Institute for Human Rights; Ephraim Percy   Kenyanito from ARTICLE 19; Louise Kjær from Bluetown; and Elias Aboujaoude,   Professor of Clinical Psychiatry at the Stanford University School of Medicine. In   addition, the DIHR would like to recognise the collaboration with Lorna   McGregor and Sabrina Rau from the Human Rights and Big Data Project (HRBDT)   at Essex University, as DIHR’s academic partner in the project, with a particular focus on Data Privacy Impact Assessments.     The contribution of expert  reviewers  does not represent  their  endorsement of  the content.    ©  2020 The Danish Institute for Human Rights   Wilders  Plads  8K  DK-1403 Copenhagen K  Phone +45 3269 8888   www.humanrights.dk    Provided such reproduction is for non- commercial use, this publication, or parts   of it, may  be reproduced if author and source are  quoted.    At DIHR we aim to make our publications as accessible as possible. We use large   font size, short (hyphen- free) lines, left -aligned text and strong contrast for   maximum legibility. For further information about accessibility please click   www.humanrights.dk/accessibility  
3                   ABBREVIATIONS  5  1 IN TRODUCTION  6  1.1 WHAT  T HIS GUIDANCE  OFFERS  7  1.2 T ARGET  AUDIENCE  FOR  THE GUIDANCE  8  1. 2.1 COMPANIES  IN SCOPE  10  1.3 D IGITAL  ACTIVITIES  IN SCOPE  10  1.4 OVE RVIEW OF THE GUIDANCE  AND HRIA PHASES  13  2 HU MAN  RIGHTS  IMPACT  ASSESSME NT 15  2.1 IN TRODUCTION  TO HUMAN  RIGHTS  IMPACT  ASSESSMENTS 15  2.2 H OW DOES HRIA RELATE TO HUMAN RIGHTS DUE DILIGENCE   AN D THE  UN GUIDING PRINCIPLES?  17  2. 2.1 OPPORTUNITIES  AND RISKS OF HRIA  19  2.3 WHY  SH OULD  COMPANIES  CONSIDER  CONDUCTING  A HRIA?  20  2.4 WHE N SHOULD HRIAS BE UNDERTAKEN AND HOW LONG DOES   IT T AKE?  20  2. 4.1 REASSESSING  HRIA  FINDINGS  AND FOLLOW -UP ACTIONS  25   2.5 WHAT  AR E THE DIFFERENCES  AND  SIMILARITIES  BETWEEN   H RIA AND  OTHER  TYPES  OF IMPACT  AND  RISK ASSESSMENT? 27   2. 5.1 KEY CRITERIA  FOR HRIA  27  2. 5.2 OTHER FORMS OF IMPACT ASSESSMENTS RELATED TO   D IGITAL  ACTIVITIES COMPARED  TO HRIA  38  2. 5.3 SHOULD HRIA BE STAND -ALONE OR COMBINED WITH   O THER FORMS  OF IMPACT  ASSESSMENT?  45  2. 5.4 SECTOR- WIDE IMPACT ASSESSMENT: AN ALTERNATIVE TO   IN DIVIDUAL  ASSESSMENTS?  47  G LOSSARY  51  E ND NOTES  53  This document contains the Introduction sectio n of the Guidance on Human   Rights Impact Assessment of Digital  Activities (the  Guidance).  You can access the full version of the Guidance at:   https://www.humanrights.dk/publications/human- rights -impact -assessment -  digital- activities       CONTENT  
4              A N OTE ON THIS  VERSION   This first version of the Guidance on Human Rights Impact Assessment (HRIA) of  Digital Activities (the Guidance) is based on DIHR materials and experiences,  input from expert reviewers and practitioners, the UN Guiding Principles on Business and Human Rights and international human rights instruments, as well   as public domain  sources on  impact  assessment.   The preparation of this Guidance included a workshop in Denmark in November   2019, during which 20 expert reviewers participated in a discussion on human rights impact assessment of digital activities —i.e. activities related to digital  projects, products and services.   It is anticipated that in 2021, a Phase II of the project will focus on applying the   Guidance in practice, the gathering and sharing of learning, and subsequently   updating the Guidance.  As HRIA of digital activities is an emerging practice, this Guidance seeks to   provide support to those working with HRIA of digital projects, products and  services, but also to contribute to a platform for dialog ue about HRIA practice   and standards in the ‘digital’ business and human rights field. In this context, we   welcome comments from stakeholders on the Guidance and on experiences with using it.  Please  send  comments, questions and suggestions to:  Emil Lindblad Kernell emke@humanrights.dk  and Cathrine Bloch Veiberg   cph@humanrights.dk     Funding   Creation and publication of this guidance has been made possible by general   operating  funds received  from the Danish Ministry of Foreign  Affairs.  
5          ABBREVIATIONS          CHRB  Corporate  Human  Rights  Benchmark   CSO  Civil  Society  Organisation   DIHR  Danish  Institute  for Human  Rights   DPIA  Data  Protection  Impact  Assessment   EIA Environmental  Impact  Assessment   ESHIA  Environmental,  Social  and Health  Impact  Assessment   EtIA  Ethical  Impact  Assessment   HRDD  Human  Rights  Due  Diligence   HRIA  Human  Rights  Impact  Assessment   ICT Information  and Communications  Technology   ILO International  Labour  Organisation   IoT Internet -of-Things   NGO  Non -Governmental  Organisation   OHCHR  UN Office  of the High  Commissioner  for Human  Rights   SIA Social  Impact  Assessment   TIA Technology  Impact  Assessment   TOR  Terms  of Reference   SDGs  Sustainable  Development  Goals   SWIA  Sector -Wide  Impact  Assessment   UNGPs  UN Guiding  Principles  on Business  and  Human  Rights  
6              1 INTRODUCTION     There is a “critical need for clearer guidance  about what should be expected on human  rights from private companies as they develop and deploy digital technologies.” 1 UN High -Level  Panel  on Digital  Cooperation, 2019    More and more individuals have internet access, and the world is currently going   through an unprecedented digital transition. With that, the potential and actual   negative human rights impacts related to the design, development, application  and use of digital services and products by private as well as public actors are   increasing.  While digital  transformation  can lead  to increased  opportunities and  enjoyment of human rights it also comes with great risks.2 The Human Rights   C ouncil clarified  that “the  same  rights  that people  have  offline  must also be   protected online”3, meaning that human rights considerations must be central in  the  current and future digital transformation.   Considering the significant scope  of potential negative  impacts and the  constantly growing number of cases  of severe actual impacts  that digital  products and services cause, contribute to or otherwise are directly linked to, the   calls on businesses and other actors to assess and address their human rights   impacts, and to conduct human rights impact assessments (HRIAs), have   increased  in recent  years.4  The UN  High Commissioner for Human Rights restated the need to “ address the   human  rights  challenges  raised  by digital  technology ” and that the human  rights framework will be essential in ensuring adequate responses by technology   companies to their negative impacts.5  The UN Guiding Principles on Business and Human Rights (UNGPs) generally   outline the requirement on businesses to identify, assess and address their   negative human rights impacts through the conduct of human rights due   diligence. The B- Tech Project at the UN Office of the High Commissioner for   Human Rights , is working to provide general guidance on the implementation of  the UNGPs in the technology space, in relation to a number of strategic focus   areas.6      INTRODUCTION  
7        With increased  attention paid  to the accountability of businesses for their human  rights impacts related to digital projects, products and services, Human Rights   Impact Assessment (HRIA) is gaining traction as one useful tool in the human  rights due diligence toolbox that is available to the private sector.7 The Special  Ra pporteur on Fr eedom of Opinion and Expression has called on information and  communications technology (ICT) companies to conduct HRIAs for product and  policy development as well as conduct ongoing assessments during operations,  including ensuring meaningful public and c ivil society consultation.8  However, existing guidance and methodologies for conducting HRIA9, have been   la rgely focused on site -level projects and supply chains with clear ‘physical   footprints’, partly because the HRIA methodology has been modelled on   Environmental and Social Impact Assessments (ESIA) for such large -scale   projects. As such, there has been a lack of guidance for assessing and addressing   the particular kinds of impacts  that digital projects, products and services  can  caus e, contribute to or otherwise be linked to, whether by technology companies   themselves or other entities developing digital projects, or using or applying   digital products or services. HRIA of digital projects, products and services is   however an emerg ing practice. Efforts are being undertaken to share   experiences and lessons learnt of such HRIAs; however, this field would benefit from further dialogue amongst stakeholders and strengthening the HRIA   approach, in order  to ensure  that a human  rights- based  approach is applied.   In light of the above, the Danish Institute for Human Rights (DIHR) initiated dialogue and convened key stakeholders to develop guidance on how companies   and other stakeholders involved in the digital ecosystem can improve their effor ts to assess and address negative human rights impacts related to digital   projects, products and services. The purpose of the Guidance is to provide those   who are involved in conducting, commissioning, reviewing or monitoring HRIAs   of digital activities (i.e. projects, products or services of a digital nature) with guidance and practical examples, and to support in ensuring that HRIAs apply a   human rights -based approach and are consistent with  the UNGPs .    1.1 WHAT  THIS  GUIDANCE  OFFERS     This Guidance sets out to do the following:  • Offer  a methodology  that can be used by all kinds  of companies  that  design,   develop, sell, procure, deploy, apply or otherwise use digital projects, products and services, as well as state actors procuring such projects,   products  and services .  • Assist those individuals who are involved in HRIAs and enable the   consolidation of a robust body of HRIA practice . By providing guidance and  practical examples.  
8        • Provide tailored guidance for the realities of the digital ecosystem. It is, to   the greatest extent possible, tailored to the realities of the digital ecosystem,  in which a large variety of companies are involved from the design and   development phases all the way to end- use. The Guidance therefore focuses   strictly on impacts related to digital activities (see below) and leaves out   other impacts. While the Guidance has been tailored as much as possible to   the digital ecosystem, it also includes some general HRIA information that would apply  to companies  irrespective  of sector.   • Outline a process for stand- alone HRIA, i.e. an impact assessment that  focuses exclusively on human rights . However, stakeholders may also wish   to draw on specific components of this Guidance when combining human rights with other types of assessment—e.g. Ethical Impact Assessments   (EtIA), Data Protection Impact Assessments (DPIA), Technology Assessment   and Privacy Impact  Assessments.   The UNGPs recognise that the exact form of HRDD will vary depending on “the   size of the business enterprise, the risk of severe human rights impacts, and the   nature and context of its operations”. As such, it follows that HRIAs will need to   be adapted and scaled to suit the particular business and digital activities in   question. That  the focus of this Guidance is exclusively on digital activities  means   that other potentially (highly) relevant human rights impacts from certain parts   of the digital product and service value chain are not within the scope of the   Guidance.  This Guidance does  not:  • Provide in -depth guidance on broader human rights due diligenc e. See the  B-Tech Project for authoritative guidance on the general implementation of  the UN Guiding Principles  on Business and Human  Rights in the tech  sector.10  • Focus on impacts linked to labour rights in the hardware supply chain,   impacts related to physical infrastructure, or cumulative environmental or   labour rights related impacts . This includes, for example, impacts on the   climate related to data centres and impacts related to physical internet   infrastructure, job loss caused by  increased automation, human rights   impacts in the mineral and hardware supply chain, or labour rights impacts in   the gig economy.11      1.2 TARGET  AUDIENCE  FOR  THE  GUIDANCE     The primary target  audience for the Guidance is:  
9         • Human rights practitioners and consultants conducting impact assessments   of digital projects, products or services.   • Companies , in particular staff who are responsible for commissioning and   overseeing impact assessments, whether those businesses are developing   the digital projects,  products or services  themselves  or are buying them.  • Public entities that are procuring and using digital products and services —in  relation to e.g. e -governance initiatives, digital health services, automated   decision -making in court systems, and other forms of public service delivery.   While references throughout the Guidance will in most cases refer to what  businesses should consider in relation to HRIAs, the same r ecommendations  apply to public entities and actors that acts as project, product or service   owners.  The Guidance will be particularly relevant for companies that have already   conducted some form of company -wide human rights risk assessment and that  thereb y have been able to identify where a deeper dive into the potential and  actual human rights impacts  is needed.   The secondary  target audience  is:  • Other individuals  or organisations  who are interested in the topic of HRIA  of  digital projects, products or services, or who are involved in such   assessments.  For example:   a) Financial institutions, including development finance institutions,   institutional investors, private equity funds, providing financial support towards the develop ment  of digital projects,  products and services.   b) National human rights institutions exercising their mandate to promote   and protect human rights could use the Guidance when advising the   government and other stakeholders on impact assessment laws (e.g. in relation to mandated privacy impacts assessments, data protection   impact assessments, algorithmic impact assessments etc.), policies and   practice, to ensure that the adoption of a human r ights- based approach   and international  human rights standards are reflected.   c) Government departments and state institutions that are responsible for   providing guidance to businesses on respecting human rights, or setting   standards for due diligence and impa ct assessment in relation to digital  projects, products or services, could draw on the Guidance for   information on how human rights might be better reflected in such guidance and standards.  d) Non -governmental and civil society organisations that support and/ or  represent individuals and communities that are adversely impacted by   digital projects, products or services  could use the Guidance to advocate 
10        for a company to undertake a HRIA or for increased community   involvement in business -commissioned HRIAs, or to review and monitor  HRIAs  that have  been undertaken.     1.2.1 COMPANIES  IN SCOPE   The kinds  of businesses  that this Guidance is particularly  relevant  for, includes:  • Developers of digital projects, products and/or services (e.g. software or app  developers, who write, debug and execute the source code of the software   or application), who  want to:  a) Better understand how human rights are relevant to  the design,  development, sale and end- use of digital products and services.   b) Be better at anticipating potential human rights impacts and thereby   changing the design  of the digital product or service.   c) Better understand their involvement with negative human rights impacts   related  to the application  and end- use of digital products and services.   • Companies buying digital projects, products and/or services (whether off-  the-shelf or specifically tailored to the needs of the company in question),   who want to:   a) Better understand how human rights are relevant to the procurement,   deployment and use of digital  products and services.   b) Better anticipate and change the design or potential use -cases of the   product or service  to address  actual or potential human rights impacts.   c) Better evaluate,  monitor and communicate  how  human rights impacts  of  the digital service  or product are being managed.     1.3 DIGITAL  ACTIVITIES  IN SCOPE     The methodology outlined in the guidance focuses on digital projects, products   and services, which include:  • Digital platforms, search engines, social media platforms, geo -location   tools, voice recognition artificial intelligence (AI), cloud computing,   internet security services,  facial recognition  systems,  autonomous  vehicles, enterprise software solutions, ‘wearables’, Internet -of- Things  (IoT) devices, as well as digital telecommun ications and network  infrastructure.12  More specifically  the methodology is focused on the impacts  related  to the  ‘digital  activities’  of these  projects, products  and services . These  include: 
11        • Data collection, data processing, data use and data erasure; automated  decision -making, artificial intelligence, algorithms and machine learning;   management and moderation of user -generated content; content  hosting; and provision  of digital and Internet infrastructure.  While conducting human rights due diligence is a requirement according to the   UN Guiding Principles on Business and Human Rights (UNGPs), the same   framework does not include a requirement to conduct HRIAs as such. Such assessments may however  be an important tool when, for example, heightened  human rights risks have been identified (see chapter 2.3). In order to be efficient and practically possible to conduct, HRIAs also require a well delineated/defined   scope,  in terms  of geography, product or service,  and product life  cycle.     BOX 1: EXAMPLES OF SCENARIOS WHERE A HRIA MAY BE NECESSARY OR  RELEVANT   Below  is a non-exhaustive  list of types  of companies and scenarios  that this  Guidance is relevant  for:  • A social media platform that enters a new market or is operating in   country where human rights defenders and opposition leaders are   increasingly  persecuted.   • A telecommunication company that enters a newly liberalised market or   operates in a country where the  government in the past has shut down   the internet on many occasions, or where internet shutdowns are rapidly   increasing.   • A car manufacturer that decides to enter a new market with a carsharing  programme, which requires substantial data gathering and other  forms of   data processing linked to customer behaviour and geolocation  data.  • A developer of a commercial software suite for video editing that  develops a powerful algorithm that can assist in smoothing out cuts in  videos,  which will allow  edits in video  sequences  that most  viewers  will not  detect  (‘deepfakes’).  • A developer  of a digital service that  creates  synthetic  speech  based on   limited  amounts of recording  of real individuals’  speech.   • A supermarket chain that purchases and installs ‘smart cameras’ in its   stores that use facial recognition technology to assess user  engagement   with its  products, so that it can improve  product placement.  • A bank or insurance company that decides to use an algorithm to assess  credit risk , by combining its own customer data with data from   commercial  data  providers.  
12            •A digital communication or social media platform that is deploying an   algorithm to help with flagging ‘high risk’ content that should be taken off  the platform.  •A recruitment company that engages a data engineering company to  develop a vocal analytics algorithm that can assist companies in   recruitment processes by  analysing  potential recruits’ speech.  •A warehouse that is considering using biometric trackers and artificial  intelligence  to help improve  worker productivity  and efficiency.   •A smartphone  game  developer  that has developed  a highly popular game   for children and adolescents, that is potentially addictive.  •A state entity that decides to commission the development of an   algorithm  that will help assess who the vulnerable groups in society are in  order  to improve social security  programmes.   •A tech company that is offering a virtual classroom , which is used by   primary  school  children.   •A private hospital developing telemedicine initiatives and storing sensitive   health data in electronic medical recor ds, hosted by a third party.  •A cosmetic company using facial recognition to provide tailored skincare   routines and makeup suggestions.   •A legal tech or law firm relying on artificial intelligence (AI) -powered   chatbots  to provide initial legal advice  to prospective customers.   •An insurance company using in- vehicle sensors to monitor actual driving   habits  and using  data  to set up  personalized  premiums  based  on risk. 
13               1.4 OVERVIEW  OF THE  GUIDANCE  AND  HRIA  PHASES    The Guidance includes the following three principal sections:   • Introduction and HRIA: This section introduces the background, scope and  content of this Guidance. Further, it provides a brief explanation of the   relationship between the UN Guiding Principles on Business and Human rights, Human Rights Due Diligence and HRIA. It also provides m ore details   around what HRIA is, when it should be performed, and how it relates to   other forms of impact assessments and other forms of HRDD activities.   Finally, 10 key criteria for a human rights -based approach to HRIA are   outlined.  • Conducting a HRIA: Th is section of the guidance is divided into the five   phases of a HRIA and also includes a section on stakeholder engagement as   the key cross -cutting component throughout the phases of HRIA. The five   HRIA phases are: 1) planning and scoping; 2) data collection and context analysis;  3) analysing  impacts; 4) impact  prevention, mitigation,  remediation;  
14        and 5) reporting and evaluation. Explanatory guidance, practical examples   and case studies relevant to digital activities are provided throughout the five   phases. The cross- cutting section on stakeholder engagement includes an  introduction to consulting with rightsholders and other relevant parties, as   well as information on relevant stakeholders to engage with. The stakeholder   engagement  section  applies  to all stages of the assessment.  
15        2 HUMAN  RIGHTS  IMPACT   ASSESSMENT       2.1 INTRODUCTION  TO HUMAN  RIGHTS  IMPACT  ASSESSMENTS     In the business context, HRIA can be defined as a process for identifying,   understanding, assessing and addressing the adverse effects of a business   project or business activities on the human rights enjoyment of impacted   rightsholders.  HRIA involves several phases or steps, all of which need to be included to ensure   a comprehensive assessment. In this Guidance, the phases of have been divided   into:   1. Planning and scoping  2. Data collection  and context  analysis   3. Analysing  impacts   4. Impact  prevention, mitigation  and remediation,  and  5. Reporting and evaluation.   While HRIA  can be divided  into different phases,  it is important  to recognise  that  the assessment is an iterative process and should facilitate continuous learning   and analysis  throughout.  Engagement with rightsholders and other stakeholders is essential in HRIA . A  thorough assessment of human rights impacts is unlikely to be possible or   effective if conducted purely as a desktop research exercise. Instead, it is an  involved process, requiring background research and direct data collection —  through in- person or/and virtual engagement (further discussed in Stakeholder   Engagement section)—a nd that is heavily based on the participation of   rightsholders and other stakeholders. Local approaches must be used to take   local contexts and stakeholder perspectives fully into account and local   knowledge is a key feature of a good impact assessment. Stakeholder  engagement has therefore been situated as the core cross -cutting component in  the Guidance. 
16        To ensure that human rights are addressed  comprehensively,  it is important that  the content, process and outcomes of the assessment apply and are compatible   with international human rights standards and principles . Drawing on the UN   Guiding Principles on Business and Human Rights (UNGPs), as well as current   guidance and literature on HRIA, a number of aspects can be identified as   essential  key criteria for  HRIA  of all kinds of business projects and  activities:       •  International human rights as benchmarks: International human rights   standards and principles must constitute the basis and benchmarks for the   assessment. At minimum, HRIA should refer to the International Bill of   Human Rights and the ILO Core Labour Conventions , as well as other human   rights instruments (such as issue specific and regional human rights   instruments) as relevant  in the particular HRIA  context. It is important  that all  human rights are considered and that the scope is not limited to e.g. right to   privacy  or non- discrimination  from the  outset, since  there might  otherwise  be a  risk of blind spots.   • Human rights -based process: The assessment process itself needs to respect  human rights by paying particular attention to human rights principles such  as non -discrimination, privacy , participation, empowerment and  transparency.  • Focus on accountability: The assessment process and content need to be   structured in a way so that the company remains  accountable to the various   stakeholders. This includes recognising the rights that individuals potentially   impacted by the activities (‘rightsholders’) have, and the responsibility that   the company itself and other companies and states (‘duty -bearers’) have, to   respect  those same  rights.   These essential elements of HRIA, as well as guiding questions for implementing   them in practice, are elaborated further in 10 Key Criteria for HRIA (see Table B  in chapter 2.5.1).   
17        2.2 HOW DOES  HRIA  RELATE  TO HUMAN  RIGHTS  DUE  DILIGENCE   AND  THE  UN GUIDING PRINCIPLES?    The UNGPs articulate the expectation that businesses should respect human  rights by performing HRDD. HRDD is a process for identifying and assessing13,  preventing and mitigating14, tracking15, and accounting for (communicating and  reporting)16 the adverse potential or actual human rights impacts with which a   business is involved .17    BOX 2: THE UNITED  NATIONS  GUIDING PRINCIPLES  ON BUSINESS AND   HUMAN RIGHTS   The UN Guiding Principles (UNGPs) were developed under the auspices of  the former Special Representative of the UN Secretary -General on Business   and Human Rights, Professor John Ruggie, during his mandate term, 2005 -  2011.   They rest on three inter- related  pillars:   1. The State duty to protect against human rights abuses by third parties,   including businesses,  through appropriate  policies,  legislation,  regulation   and adjudication   2. The corporate responsibility to respect human rights, meaning that   businesses are expected to avoid infringing on the human rights of  others and to addre ss adverse  human rights impacts  with which they are  involved,  and  3. Access  to remedy , which requires both States and businesses to ensure  greater access by victims of business -related human rights abuses to   effective remedy,  both judicial and  non- judicial.   The UN Guiding Principles were unanimously endorsed by the Human Rights   Council in 2011. Since then, they have been integrated into numer ous key   business and human rights frameworks  and standards, for example, the  OECD  Guidelines for Multinational Enterprises,  the Performance  Standards of  the International Finance Corporation  and the European Union  Action  Plan   on Human  Rights and Democracy  2015- 2019.   It is important to note that the UN Office of the High Commissioner of  Human  Rights (OHCHR) launched the B-Tech  Project in 2019.  The project  will  “seek to provide authoritative guidance and resources to enhance the   quality  of implementation of  the UNGPs”  in relation  to technology .18  The UNGPs state that when a business is assessing its human rights impacts (or   o therwise conducts human rights  due diligence), it  should:19 
18        • Draw  on internal and/or independent human rights expertise  • Undertake meaningful consultation with potentially  affected rightsholders  and other relevant  parties  • Be gender-sensitive and pay particular attention to any human rights impacts   on individuals and groups that may be at heightened risk of vulnerability or   marginalisation   • Assess impacts from the perspective of risk to people rather than risk to   business, and  • Repeat its risk and impact identification and assessment at regular   interva ls—e.g. before entering into a new activity, prior to significant   decisions about  changes in activities,  and periodically  throughout the project   cycle.   The UNGPs apply to all companies, regardless of sector. As such, for companies   de veloping or using digital products or services, the UNGPs can be said to offer   “a roadmap  for operationalising  respect  for human  rights as part of how they do  business, no matter the focus, size or complexity” of the company.20 Conducting  H RDD includes that they “anticipate and address issues that might occur related  to the use”  of those products and services.21  HRIA is considered to be “one tool within a wider due diligence toolkit”22 that  c an be used to assess and address impacts at the project, product or service   level. As an example, a HRIA can be conducted in relation to e.g. a market entry   with a particular digital product in a specific country. The HRIA itself will touch   upon all steps of the HRDD process, but remains a discrete activity with a   clearly defined scope. HRDD, on the other hand, is constantly ongoing and  should concern all business  operations.  Digital projects, products and services can be fast- changing and often operate at   large scale.23 Considering specifically the potential scale of operations, HRIA can   be  a key HRDD tool in contexts where people, and therefore also businesses,  face severe risks and impacts in connection to businesses’ digital projects,  products or services. It is important that if a HRIA is conducted, it is seen as a   part of a company’s general responsibility to conduct HRDD, rather than as an isolated event. This  includes ensuring that HRIAs provide learnings for the   ongoing and company -wide  due diligence  processes.   When a HRIA  has been  conducted it will provide a snapshot of  impacts  as well  as specific recommendations for preventive and mitigation measures —it may  for  example suggest changes in the design of a product or service. The insights   gained from a HRIA should be used to increase awareness of potential human rights risks and inform decision -making and other aspects of ongoing Human  Rights Due Diligence  (HRDD) 24. 
19        2.2.1  OPPORTUNITIES  AND  RISKS  OF HRIA     There  are several ways in which HRIAs  can strengthen the wider  HRDD  process   in a co mpany25, including by:  • Serving as mechanisms to help focus business leaders on specific actual and  potential human rights impacts related to specific digital projects, products   and services,  and related  business decisions.   • Building  capacity  on human  rights for those involved  in the process  of  undertaking the HIRA.   • Generating granular and disaggregated  information  on impacts on  rightsholders.  • Leading to specific outputs in the form of public reports, which can assist staff with human rights responsibilities in their capacity -building efforts with  others in the business and provide  learnings  for other stakeholders.  • Guiding decision -making  around how to address human rights risks  identified  in HRIAs that are also relevant for other projects, products, services and   activities.   • Building  confidence and competence  within companies as they start   developing or continue  to develop their HRDD processes.   • Building  trusted relationships  with partners who  can continue to inform the  company’s  HRDD activities  generally.   There are, however, also some pitfalls that those looking to conduct HRIA   s hould be wary of, in order  to avoid them.26 These  include:  • C onsidering that the human rights work is ‘done’ once the HRIA report is   finished. Rather, the focus should be on integrating the findings and implementing the recommendations.  • Treating HRIA as the primary mechanism through which a company aims to   perform its HRDD, rather than as one tool that businesses have at their   disposal.   • HRIAs, if not adequately used to inform internal HRDD processes, such as   decision -making and capacity building, can lead to reduced ownership of  human rights risks  within companies. It is therefore important  that e.g. the  HRIA team works closely with company representatives and that action plans—with clear roles and responsibilities for implementing the act ions—  are developed by the company in question after a HRIA report has been  finalised.   • The push for HRIAs, without proper use of a human rights -based approach,  can send the message internally that respecting human rights is a ‘box ticking   exercise’ focused  only on identifying risks to the company and meeting   disclosure  requirements. To avoid  this,  it is essential  to include key internal 
20        stakeholders in the HRIA process to increase their understanding of human  rights and their capacity  to take action  to address identified impacts.   • Finally, treating HRIAs as something entirely different from ongoing HRDD   might lead to companies stopping at identifying and communicating the   results of the HRIA at the expense of investing resources to address specific   human rights risks and being transparent about the impact of those efforts.   Rather, as mentioned above,  companies should develop  action  plans on the  back of conducted HRIAs, and those action plans should include how the   company  will follow -up on its  preventive and mitigation  measures.     2.3 WHY  SHOULD  COMPANIES  CONSIDER CONDUCTING  A HRIA?     HRIA can be a key element of HRDD, and provide process for businesses to   understand and address their impacts in relation to specific digital projects,   products or services, and the contexts where they will be used or applied. HRIA   of digital projects, products and services  can provide a structured approach to:  • Identify adverse human rights impacts, including understanding these from   the perspectives of impacted rightsholders, in general, and vulnerable   rightsholder groups, in particular.   • Determine measures  to address any adverse human rights impacts   identified—through prevention, mitigation  and remediation.   • Facilitate dialogue between businesses, rightsholders and other relevant   parties, in particular human rights actors (for more information on the   different stakeholders to engage in HRIA see cross -cutting Stakeholder   Engagement  section).  • Facilitate capacity -building and learning for company stakeholders,  rightsholders and others  involved in the impact assessment, including   through raising  awareness  of respective rights and responsibilities.   • Enhance the accountability of businesses through documenting the impacts   that have been identified and the actions taken to address  them.  • Build partnerships between businesses and other stakeholders to address   human rights impacts, including through developing joint actions to address   cumulative impacts  and/or systemic  issues.   • Identify learnings that inform and improve HRDD practices with regards to   other digital  projects, products or services.     2.4 WHEN  SHOULD  HRIAS  BE UNDERTAKEN  AND  HOW LONG  DOES   IT TAKE?     Human rights due diligence is an iterative process meant to be implemented   throughout business activities. Identifying if, when and how a HRIA is warranted  is specific to the business, and companies’ HRDD  activities  should  inform  when 
21        and if a HRIA is the appropriate tool to use. Large multinational corporations are   often present across many countries and operating contexts. Therefore,  businesses should carefully  consider  which projects,  products or services  in  which countries should be subject to a HRIA,  as well as under  what  circumstances it  is relevant  to trigger  the HRIA  process.   Developing an internal typology of circumstances for when a HRIA should be   undertaken, could be undertaken or should be considered (e.g. in the form of  an internal ‘comply or explain’ structure), can be an effective method to enable   staff in companies to identify relevant digital projects, products or services for   HRIA.   Severity o f actual or potential human rights impacts should always guide   decision -making on which projects warrant a HRIA. Digital activities with the   highest severity of impacts (e.g. threats to health and lives) should receive the   highest priority. For more infor mation on severity, see Phase 3: Analysing   Impacts. How many assessments should take place within a given timeframe   cannot be quantified and will depend on the identified risks, their severity, the   company’s resources and involvement in the potential or ac tual impacts, and a  range  of other  factors.27  When the assessment of severity and other circumstances highlight a need for a   HRIA, the HRIA should be conducted early in the project cycle or development   phase of the product or service. The observations and assumptions from the   HRIA should be re -evaluated at regular intervals and critical moments, as well as   be consistently  monitored.     TABLE A: EXAMPLES OF WHEN HRIAS OF DIGITAL ACTIVITIES MAY BE   WARRANTED   Below is a non -exhaustive list of scenarios   where HRIAs should or could be   undertaken28, or where further human  rights due diligence may be necessary to   identify whether a  HRIA is  warranted.  Examples   When introducing a digital product or   service to a new market , particularly where   human rights, in general, and freedom of   expression and right to privacy, in  particular, are not well protected by the   authorities, including in conflict sensitive   contexts When introducing a digital   service  that requires  a lot of  data collection and processing in  a country with very limited data   protection legislation  
22          When a digital product or service will be   launched in a country where there are   legacy issu es with regard to human rights ,  systemic human rights abuses or significant   negative  human rights  developments . Where a government have   increasingly been pressuring   companies to share user data   linked to political opponents   ahead  of an election  cycle.   When withdrawing a digital product or   service from a market , particularly where   human rights, in general, and freedom of   expression and right to privacy, in  particular, are not well protected, including   in conflict sensitive  contexts.  When considering whether to   allow  a social  media platform to  be used  in a particular country.  When designing,  developing,  introducing,   deploying or using new and untested  digital projects, products and services.  When developing a facial   recognition  technology for  commercial purposes in   shopping malls, to assess   shopper behaviour.  When designing,  selling  and/or using digital  projects, products and services that HRDD   processes have identified may potentially   cause or contribute to severe negative  human right  impacts . Selling a text -to-speech service  that can be used  to spread  ‘deep fakes’, or making available   a targeted advertising model   that assists third- parties in   discriminating protected   groups29  When making a major  product shift . Introducing end-to-end  encryption on messaging   service.   When planning for or adopting a new   business  model , or when stakeholders have   raised concerns  about the business model . Moving to a targeted advertising   business model from a   subscription mo del30  When the political context changes   significantly  and human rights  protections   are decreased in a country where the   projects are taking place or where digital  products and services have been  introduced. If a new cyber terrorism law in a   country provides  law  enforcement with far -reaching   powers to request user data   from companies without the   need  of a warrant,  which migh t 
23           lead to revised procedures for   responding to government  demands.  When internal or external analysis or  reports finds that use -cases of a digital   product or service are different from what   was initially understood, and that it might  lead to severe adverse human rights   impacts.  It has been found that a   powerful video  editing software  aimed at the production of  commercials has been largely   used by political groups to   distort the messaging from   opposing political parties.  When business decisions of large scale   pertaining to the digital products or   services  are about to be  made  A company -wide decision about  where data should be stored.   When acquiring other companies or   forming operational partnerships with  companies or state actors that are involved   in any of the other scenarios mentioned in  this list. See above.     Sources: Global Network Initiative (2017), “ Global Network Initiative Implementation Guidelines” :  https://globalnetworkinitiative.org/implementation- guidelines/  [Accessed July 29, 2020]; Verizon   (2020), “Human Rights Impact Assessments”: https://www.verizonmedia.com/brand -trust/business -  and- human- rights/human -rights -impact -assessments [Accessed July 29, 2020]; Shift (2016), “Doing   business with respect for human rights: a guidance tool for companies” ; CDC (2016), “Practical   guidance and Terms of Reference (ToRs) templates for enhanced assessment of human rights risks and  impacts”:   https://view.officeapps.live.com/op/view.aspx?src=http%3A%2F%2Ftoolkit.cdcgroup.com%2Fwp-   content%2F uploads%2F2018%2F10%2FCDC_Guidance_and_ToRs_for_Human_Rights_Due_Diligence_   -_160623.docx [Accessed July 29, 2020] ; Ranking Digital Rights (2018), “RDR Corporate Accountability  Index: Draft indicators” ; McGregor (2018), “The Universal Declaration of Human Rights at 70: Putting  human rights at the heart of the design, development and deployment of artificial intelligence”,   Human Rights, Big Data and Technology Project (HRBDT): https://48ba3m4eh2bf2sksp43rq8kk-   wpengine.netdna- ssl.com/wp -content/uploads/2018/12/UDHR70_AI.pdf  [Accessed July 29, 2020];   Latonero (2018), “Governing Artificial Intelligence: Upholding human rights and dignity”, Data &  Society : https://datasociety.net/library/governing- artificial -intelligence/  [Accessed July 29, 2020];  Ranking  Digital  Rights  (2020), “2020 Ranking Digital  Rights Corporate  Accountability  Index  Research   Indicators”  : https://rankingdigitalrights.org/wp- content/uploads/2020/06/2020RDRIndicators.pdf   [Accessed July 29, 2020]     The decision on when to conduct a HRIA and the scope of the assessment will   require professional judgment and while formal structures and procedures can  help inform  such decisions  they should always  leave  room  for those with  human  rights expertise to make  their analysis.  
24        In planning and undertaking a HRIA, it is important to recognise that even when  a decision to conduct a HRIA has been taken, the complexity of the assessment   must be appropriately scaled to the particular context ( e.g. the local context,  whether it is an ex -ante or ex -post assessment, whether there are pre -existing  human rights issues etc.) and to the nature of the digital project, products or   services (e.g. the size of the operation, the stage of the project, product or   service, whether a similar project, activity or product has been on the market   before, what the intended use -cases are and who the intended users are, etc.).   The complexity and nature of the project, product of service will be essential to   considerations of how much time will be needed for the assessment. See Box 3,  below, for examples  of HRIA  reports of  digital activities  made  public.    BOX 3: EXAMPLES OF HRIAS  RELATED  TO DIGITAL  PRODUCTS AND  SERVICES  Facebook  Sri Lanka   A HRIA of Facebook’s activities in Sri Lanka was conducted in 2018 and the   executive summary was published in 2020. According to the summary the   assessment included six phases: initial in -country engagement; desk review;   stakeholder mapping; second in- coun try engagement; internal and   international expert engagement; analysis and report writing. According to   the report, the assessment included a focus on engagement with  rightsholders, or their legitimate representatives, and also direct engagement   with Sri Lankan civil society organizations (CSOs) and Facebook users. The   total amount of in- country engagement was approximately two weeks and  included interviews with around thirty CSOs and other experts. It also   included focus groups with Facebook users that were led by the company   while the HRIA  team accompanied the  process.   The assessment was commissioned to assess Facebook’s platform and its   involvement in adverse human rights impacts in Sri Lanka, a country   identified by the HRIA consultant as “one of the most critical countries when  it comes  to potential human rights infringements on the platform”.   Telia  Eurasia  Telia  commissioned  several HRIAs  between October 2015 and May 2016 in  relation  to its  subsidiaries  in Eurasia (namely  in Azerbaijan,  Georgia,   Kazakhstan, Moldova, Tajikistan  and Uzbekistan). The assessments were  made  after Telia’s  announcement in September 2015 that it intended to sell  its subsidiaries in the mentioned countries and generally divest from the   region.  The t hird-party HRIA  consultant identified human rights impacts  and  risks in relation to each subsidiary and made recommendations for impact   mitigation and  management.  The assessments were focused  on Telia’s   involvement  in human  rights  impacts  related  to its divestments  from  the 
25          Eurasia  region,  and each  HRIA  was reported  to having  taken  place  over  the  course of two months. Approximately 50 interviews were conducted with  rightsholders and other stakeholders, including civil society organi sations,   human rights  defenders, and others.  Google Celebrity  Recognition  API Human Rights   In 2019, Google published an executive summary of a human rights   assessment it had recently conducted. According to the executive summary,  Google had commissioned a HRIA of its facial recognition technology in the   Media and Entertainment (M&E) industry in order to “inform the   development of [its] celebrity recognition a pplication program interface   (API)”. The API would enable Google’s business customers in the M&E   industry to “identify celebrities in their content at a frame -by-frame or scene -  by-scene level using a database of celebrity images licensed by Google and   available for use as part of its Cloud AI product portfolio.” The assessment  reportedly included engagement with potentially affected stakeholders, as   well as consultation with independent expert  resources. It  is mentioned in  the executive summary that the assessment was structured to focus on those   “at heightened risk of vulnerability or marginalization.”       Note: By featuring these examples in the guidance, DIHR is not endorsing the   quality of the impact assessments conducted by these companies. The cases  are included only for illustrative purposes, providing examples of public   reports of assessments of human rights for other companies who have not yet   conducted or published their HRIAs.   Sources: Facebook (2020), “An Update on Facebook’s Human Rights Work in Asia and Around the   World” : https://about.fb.com/news/2020/05/human- rights -work -in-asia/ [Accessed July 29, 2020]; BSR   (2016), “Human Rights Impact Assessments and Responsible Divestment Plan for Business Region  Eurasia: Summary project report for Telia Company” :  https://www.teliacompany.com/globalassets/telia-company/documents/about -telia -company/bsr -  telia -company -hria-summary.pdf  [Accessed July 29, 2020]; Telia Company (July 11, 2017), “Human  Rights Impact Assessments”:  https://www.teliacompany.com/en/news/news -articles/2017/human-   rights -impact -assessments/; BSR (2019), “Google Celebrity Recognition API Human Rights Assessment” :  https://www.bsr.org/reports/BSR- Google -CR-API-HRIA -Executive -Summary.pdf  [Accessed July  29,2020].    2.4.1  REASSESSING HRIA  FINDINGS AND  FOLLOW -UP ACTIONS     Human rights risks and impacts should be reassessed whenever the scale,   scope, use or application of the digital project, product or service changes, such   as during introduction of the same product to a new (high- risk) market,   significant changes to terms of service, or a decision to withdraw the product  from a particular mark et.31 Another re ason  to reassess the findings  of an initial 
26        HRIA is when there are material changes to laws, regulations or markets .32 Re-  e valuation of HRIA findings may also be appropriate when there are significant   changes in the social and political context and when the company enters into   new business  relationships  that may  pose  risks  to human rights.   It i s important to stress that reassessment of the observations and conclusions   in a HRIA and the actions taken as a result should be part of ongoing HRDD   processes. Reassessment does not necessarily need to amount to a follow-up  HRIA  if the due diligence  process  suggests, for  example,  that the preventative   and mitigation measures worked well and there are no major changes to the   project, product or service, and the political environment is stable. It may also be   relevant to reassess the conclusions of various HRIAs in conjunction , in order t o  better track performance, to learn across assessments and to better allocate   resources.  
27          2.5 WHAT  ARE  THE  DIFFERENCES  AND  SIMILARITIES  BETWEEN  HRIA  AND  OTHER  TYPES  OF IMPACT  AND   RISK  ASSESSMENT?     2.5.1 KEY  CRITERIA  FOR  HRIA   In order to be able to compare HRIA with other forms of impact assessments we need to clarify what defines HRIA. Despite the   diversity  in current HRIA  approaches, there are a number of elements that recur  in HRIA  literature,  guidance and practice  as  critical aspects to consider. These ‘key criteria’ relate to both the process and content of HRIA, and reflect what is unique  about  HRIA. These criteria also emphasise aspects which may to a lesser or greater degree be reflected in other impact assessment   methodologies, but which arguably warrant heightened attention from a human rights perspective. These aspects can be   grouped into five key  criteria relating  to process  and five key criteria relating  to content.   The 10 key criteria listed below were initially developed for DIHR’s Human rights impact assessment guidance and toolbox ,  which is primarily focused on large -scale business projects conducted at the project or site level. While the key criteria remain   general, they have here been adapted to the realities of digital activities, as necessary. Table B, below, provides an overview of   these 10 key criteria, including  example guiding  questions for HRIA  practitioners.     TABLE B: 10 KEY CRITERIA  FOR  HUMAN  RIGHTS  IMPACT ASSESSMENT   Key criteria  for the process and content  of HRIA  Example  guiding  questions  for HRIA  practitioners   Process  1. Participation  Meaningful participation  of affected or potentially   affected rightsholders is   integrated during all  stages of the impact  assessment  process,  • Have  a broad  range  of rightsholders been  engaged  in the impact  assessment,   including vulnerable groups (in person o r virtually; directly, or through   representatives or proxies)?   • Have the rights and involvement of rightsholders throughout the digital ecosystem   been  considered (e.g.  individual end- users,  those potentially impacted  by the design   and other  individuals  that are not users  but that nonetheless  may  be negatively  
28          TABLE B: 10 KEY CRITERIA  FOR  HUMAN  RIGHTS  IMPACT ASSESSMENT   Key criteria  for the process and content  of HRIA  Example  guiding  questions  for HRIA  practitioners     including: planning and  scoping; data collection   and context analysis;   impact analysis; impact   prevention, mitigation   and remediation; and  reporting and  evaluation.  impacted, such  as those who may  be subject to offline violence  after their  personal  information is  shared  online)?  • Have rightsholders, or their proxies, been involved throughout the impact  assessment  process,  including during early  phases of the impact  assessment  such   as: design of the impact assessment process; development of terms of reference for   the assessment; imp act scoping; and prioritisation of critical issues to be considered  by the assessment?   • Have rightsholders, duty -bearers and other relevant parties been involved in   designing measures  to address impacts (e.g.  through prevention, mitigation  and  remediation)  and follow -up to evaluate  the effectiveness  of these measures?   • Have rightsholder representatives or representative organisations, or rightsholder   proxies,  been  included in consultation and engagement, including consideration of  the legitimacy  of their claim to represent  the relevant  individuals  and/or groups?   • Is engagement and participation in the impact assessment guided by the local   context, including through using the impacted  individuals’  preferred  mechanisms   (e.g.  modes  of communication)  where possible?   • Is the assessment process being undertaken at particular times to ensure   participation  (e.g.  when women are  not at work and young people are not at  school)?  
29          TABLE B: 10 KEY CRITERIA  FOR  HUMAN  RIGHTS  IMPACT ASSESSMENT   Key criteria  for the process and content  of HRIA  Example  guiding  questions  for HRIA  practitioners      • Does the impact assessment provide for ongoing dialogue between rightsholders,  duty- bearers  and other relevant  parties (e.g.  through collaborative  problem  analysis   and design  of mitigation  measures)?   • To the extent digital and virtual means of engagement are utilised (e.g. online   consultations and surveys) have accessibility issues been assessed, particularly with  regard  to the most  vulnerable  rightsholders? E.g. if the most  vulnerable  do not have   physi cal access to internet or if internet data is prohibitively expensive, they will not  be able  to participate.   2. Non -  discrimination  Engagement and  consultation processes   are inclusive, gender-  sensitive and take into   account the needs of  individuals  and groups at  risk of vulnerability or  marginalisation.  • Has impact assessment consultation and engagement involved both women and   men, including through gender -sensitive engagement methods as necessary (e.g.   through holding women-only meetings with female  HRIA team  members)?   • Have steps been taken to ensure that the modes of engagement and participation  address any barriers that may be faced by vulnerable and marginalised individuals   (e.g. by offering transport or holding meetings in culturally appropriate locations,   and considering ‘technology barriers’  for older persons  or persons with disabilities)?   • Have  the vulnerable or marginalis ed individuals  and groups in the given  context  been identified and considered, (e.g. by considering discrimination, resilience,  poverty factors etc.)? 
30          TABLE B: 10 KEY CRITERIA  FOR  HUMAN  RIGHTS  IMPACT ASSESSMENT   Key criteria  for the process and content  of HRIA  Example  guiding  questions  for HRIA  practitioners      • Have  the needs of vulnerable  and marginalised  individuals  been  identified in  stakeholder mapping and engagement planning?  3.  Empowerment  Capacity building of   individuals  and groups at  risk of vulnerability or  marginalisation is   undertaken to ensure   their meaningful   participation. • Does the assessment process include sufficient time for capacity building to allow  individuals and groups to be meaningfully involved (e.g. to first present the digital   products or services in a way that the audience understands, and to follow- up later   with the same  groups when they have  had time  to discuss and organise,  in order to  receive feedback  and potential concerns)?   • Do rightsholders have access to independent and competent legal, technical and  other advice as necessary? If not, does the impact assessment include provisions for   making  such  support available?   • Does the impact assessment provide for capacity building of rightsholders to know  their rights (e.g.  by thoroughly explaining the right  to privacy  before explaining how  the digital product or service will be developed to ensure respect for the same   right), as well as of duty- bearers  to meet  their human rights duties?  • Does the impact assessment provide particular attention to vulnerable or   marginalised individuals and grou ps in engagement and participation activities (e.g.   by allowing sufficient time and resources to facilitate the inclusion of these   individuals)?  
31          TABLE B: 10 KEY CRITERIA  FOR  HUMAN  RIGHTS  IMPACT ASSESSMENT   Key criteria  for the process and content  of HRIA  Example  guiding  questions  for HRIA  practitioners    4. Transparency  The impact assessment   process is as transparent   as possible in order to   adequately engage   affected or potentially   affected rightsholders,  without causing any risk  to security and well -  being of rightsholders or   other participants (such  as NGOs and human  rights defenders).  Impact   assessment findings are   appropriately publicly   communicated. • Does the impact  assessment  process  provide for inform ation  sharing  between  stakeholders at relevant  and regular intervals?   • Is the information about the digital project, product or service available to   participating stakeholders adequate for giving a comprehensive understanding of  potential implications and human rights impacts (e.g. information on intended use -  cases, potential mis -use and measures to address it, application and functioning of  a service)?   • Are HRIA findings and impact management plans (action plans) publicly   communicated  to the greatest  extent  possible  (e.g.  published, with any reservations  based on risk to rightsholders or other participants clearly justified)? Is there a firm   top-level  management  commitment  in place  with  regard  to transparency  before the  start  of the HRIA  process?  • Are the phases of the impact  assessment,  including timeframes,  communicated to  relevant stakeholders  in a clear and  timely  manner?   • Does communication and reporting take into account and respond to the local   context? For example, is information made available in relevant languages and   formats, in non -technical summaries and in physical and/or web -based formats that  are accessible  to stakeholders? 
32          TABLE B: 10 KEY CRITERIA  FOR  HUMAN  RIGHTS  IMPACT ASSESSMENT   Key criteria  for the process and content  of HRIA  Example  guiding  questions  for HRIA  practitioners    5. Accountability The impact assessment   team is supported by   human rights expertise,  and the roles  and  responsibilities for  impact assessment,   prevention, mitigation   and management are   assigned and adequately   resourced. The impact   assessment  identifies the  entitlements of  rightsholders and the   duties and  responsibilities of   relevant duty -bearers   (e.g. developers,   companies buying digital   products or services,  those using or applying   digital products and • Is responsibility for the implementation, monitoring and follow -up of mi tigation   measures assigned to particular individuals or functions within the company (e.g.   data engineers are tasked with changing the design  to limit  potential mis-use)?  • Are sufficient resources  dedicated  to undertaking the HRIA,  as well as implementing   the impact management plan (i.e. adequate time, as well as financial and human   resources)?   • Are relevant duty -bearers meaningfully and appropriately engaged in the impact   assessment process, including in impact prevention, mitigation and remediation  (e.g. data protection authorities are engaged since some systemic impacts can best   be dealt  with through data protection policies  and regulation)?   • Does the HRIA draw on the knowledge and expertise of other relevant parties, in  particular human rights actors (e.g. digital rights groups working on right to privacy,   fair machine  learning  etc.)?   • Does the HRIA team have the relevant inter -disciplinary skills and expertise   (including human rights, technical, legal, language and local knowledge) to   undertake the HRIA  in the given  context  and with regard  to the specific product or  service (e.g.  data engineers and software developers  might  need  to be involved)?   • Have  efforts been  made  to include local individuals,  including women, in the impact   assessment  team,  if appropriate?  
33          TABLE B: 10 KEY CRITERIA  FOR  HUMAN  RIGHTS  IMPACT ASSESSMENT   Key criteria  for the process and content  of HRIA  Example  guiding  questions  for HRIA  practitioners     services, and   government authorities).   Content 6. Benchmark  Human rights standards   constitute the   benchmark for the   impact assessment.   Impact analysis,   assessment of impact   severity and design of  mitigation measures are   guided by international   human rights standards   and principles.  • Are international human rights standards and principles used as the benchmark for   the assessment?   • Is the impact assessment addressing the full scope of relevant human rights? If  certain human rights are excluded from the assessment, is the basis for this   reasonable,  as well as explicitly  noted  and explained  in the impact  assessment?   • Is the scoping,  data collection,  analysis  of actual and potential impacts,  and design   of mitigation  measures  guided by the substantive content of human rights?   7. Scope of   impacts  The assessment   identifies actual and  potential impacts the   business caused or   contributed to. The   assessment  also  considers  impacts  • Does the assessment  include actual and potential impacts  related  to the digital  project, products or services? Are these impacts categorized by: caused,   contributed to, and directly  linked?  • Does the assessment assess human rights the business is directly linked to through   operations, products or services and/or business relationships (e.g. developers that   have  been  contracted  to develop the  product, business partners marketing  and 
34          TABLE B: 10 KEY CRITERIA  FOR  HUMAN  RIGHTS  IMPACT ASSESSMENT   Key criteria  for the process and content  of HRIA  Example  guiding  questions  for HRIA  practitioners     directly linked to the   business through  operations, products or   services and/or business  relationships  (contractual and non-  contractual). The   assessment analyses  cumulative impacts and   legacy  issues.  selling the product, business customers, and government agencies ordering and  using a  digital product)?  • Does the assessment  consider any cumulative  impacts,  i.e. impacts that arise  due to  the aggregative or cumulative effect of multiple business activities  (e.g. several   actors sharing limited amounts of data to one source leading to a negative impact   on the right to privacy at a later stage when more data points about the same   individual has been collected; or several actors taking down user -generated   content, which leads  to a significant  negative  impact  on freedom of  speech)?  • Does the assessment identify and address any legacy impacts associated with the   digital project, product or service (e.g. previous companies have been reckless with  the handling of data causing wide ranging impacts on the right to privacy and many   other rights; or where a previous digital health service discriminated a minority   group, which is now reluctant to access  any new  similar services)?   8. Assessing  impact  severity  Impacts are addressed   according to the severity   of their human rights   consequences. This   includes considering the   scope, scale and  irremediability  of • Is the assessment  of impact  severity  guided by relevant  considerations, including  the scope,  scale,  irremediability  and interrelatedness of  impacts?   • Is the assessment  of severity  determined with respect  to the consequences  for the  individuals  affected (as opposed to risk  to the business)?   • Are the relevant rightsholders and/or their legitimate representatives or proxies   involved  in the assessment  of impact  severity?  Does  the assessment  of severity  
35          TABLE B: 10 KEY CRITERIA  FOR  HUMAN  RIGHTS  IMPACT ASSESSMENT   Key criteria  for the process and content  of HRIA  Example  guiding  questions  for HRIA  practitioners     particular impacts,   taking into account the   views of rightsholders   and/or their legitimate   representatives. reflect  the views  of the relevant  rightsholders? If it does not, has that been   appropriately  explained?   • Has the analysis  of impacts taken into account the interrelatedness of human rights,   as well as the interrelatedness of social and human rights factors? (e.g. if a digital  product discriminates an individual applying for and being declined a loa n, this may   have a  corresponding impact  on the  rights of that individual’s  children  to care;  or if  a business has insufficient safeguards in place in relation to data privacy, this may   have an impact on the right to privacy but also on e.g. employees’ right to freedom   of association since they may not want their superiors know their political   affiliatio n.)  9. Impact   mitigation   measures  All human rights impacts   are addressed. Where it   is necessary to prioritise   actions to address   impacts, severity of   human rights impacts is   the core criterion.   Addressing identified  impacts follows the   mitigation  hierarchy  of • Are all human rights impacts that are identified addressed?  • If it is necessary to prioritise actions to address impacts, is such prioritisation guided   by the severity of  human rights consequences?   • In determining mitigation measures, are all efforts made to first avoid the impact   altogether,  and if this is not possible,  to reduce, mitigate  and remediate  the impact?   • Is care  taken to ensure that compensation  is not considered synonymous with  impact mit igation  and remediation?   • Does the impact  assessment  identify ways of exercising  leverage  to address any  impacts  the business  contributes  or is directly  linked  to (e.g.  through  business  
36          TABLE B: 10 KEY CRITERIA  FOR  HUMAN  RIGHTS  IMPACT ASSESSMENT   Key criteria  for the process and content  of HRIA  Example  guiding  questions  for HRIA  practitioners     ‘avoid -reduce -restore -  remediate’.  relationships)? Where leverage  does not exist,  does  impact  mitigation  include  building leverage  to address  such  impacts?   10. Access to   remedy  Impacted rightsholders   have avenues whereby   they can raise grievances   regarding the digital  project, products or   services, as well as the   impact assessment   process and outcomes.   Impact assessment and  management  ensure  that the business   provides for or   cooperates in access to   remedy for impacted   rightsholders. • Does the impact  assessment  identify actual impacts  for which a remedy  is needed?  Are such impacts referred to the appropriate channels for remediation, including   legal and non-legal,  as appropriate?   • Have any severe human rights impacts that may constitute a legal breach been   referred to the relevant legal channels (pending the consent of the rightsholders   involved)?  Does  the business co-operate in legal proceedings?  • Is there an operational -level grievance mechanism in place that contributes to   ongoing impact management, as well as the identification of unanticipated use -  cases and impac ts? If not, does the impact management plan include the   establishment of such a mechanism? Does the operational -level grievance   mechanism meet the eight effectiveness criteria for non- judicial grievance   mechanisms  that are  outlined in UN Guiding Principle  31?  • Is it ensured that the operational- level  grievance  mechanism does not deny  rightsholders access  to all  relevant  judicial processes?   • Are the access to remedy channels responsive to the context and preferences of the   rightsholders in question? 
37          TABLE B: 10 KEY CRITERIA  FOR  HUMAN  RIGHTS  IMPACT ASSESSMENT   Key criteria  for the process and content  of HRIA  Example  guiding  questions  for HRIA  practitioners     Sources: These criteria are based on a literature review including sources on human rights impact assessment, stakeholder engagement, social impact assessment and the human rights -based   approach. See Danish Institute for Human Rights, “Human rights impact assessment guidance and toolbox” : https://www.humanrights.dk/business/tools/human- rights -impact -assessment -  guidance -toolbox  
38          2.5.2 OTHER  FORMS  OF IMPACT  ASSESSMENTS RELATED  TO DIGITAL   ACTIVITIES  COMPARED  TO HRIA     When looking at digital projects, products and services, there are a few impact  assessment methodologies that can be considered in conjunction with HRIA.   These include Data Protection Impact Assessment (DPIA), Ethical Impact   Assessments (EtIA), Technology Impact Assessment (TIA) of particular health   related digital products and services as well as Algorithmic Impact Assessment   (AIA)33. Below you can find an outline of some of these assessments and how  the y compare  to HRIA.     BOX 4: DATA PROTECTION IMPACT ASS ESSMENT AND COMPARISON TO   HRIA   Many states require businesses to carry out privacy impact assessments and   DPIAs  by law. Under the EU General Data Protection Regulation (GDPR),  DPIAs   are required for all data controllers within the EU and those outside the EU   that offer products and services or monitor the behaviour of individuals in the   EU. Article  25 of GDPR states that,  Where a type of processing in particular using new  technologies , and taking into account the nature, scope,  context and purposes of the processing,  is likely  to result  in a  high risk to the rights and freedoms of natural persons, the   controller shall, prior to the processing, carry out an   assessment of the impact of the envisaged processing   operations  on the protection of personal data.34  DPIAs,  as envisioned  under the GDPR,  require  the data controller at a  minimum to:  1. describe the envisioned processing operations  2. assess the necessity and proportionality  of the processing operation  in  relations  to its intended purpose  3. assess the risks to the  rights and freedoms of data subjects  4. explain  the measures  envisioned to address the risks   While the GDPR and the Article 29 Working Party35 provide guidance on the   minimum requirements of a DPIA, sufficient flexibility is left to the data   controller to determine the methodology and where DPIA fit within  organisational structures. A DPIA is also  scalable ; meaning that a data   controller can design  and implement  a DPIA  that is suitable and proportionate 
39        for their processing operation. Failure  to comply  with the DPIA  requirements  of the GDPR  can lead  to fines .  There are many substantive and procedural similarities between DPIA and   HRIA. However, they do not completely converge. The incorporation of   elements of HRIA into DPIA and vice versa could strengthen the nature of   both impact assessments and their ability to effectively protect human rights.   However, there are also risks that elements of HRIA may be lost if businesses   attempt to merge them  or incorporate HRIA into  DPIA.  Some key features  of DPIAs  include:   Scope of human rights covered : DPIA focuses on ‘the rights and freedoms of  natural persons’ which refer to the rights contained within the Charter on  Fundamental Rights of the European Union  (EU Charter)  which does not cover   all of the rights  set out in international human rights  instruments.  Coverage  of business  (in)activity: DPIA  only covers  one dimension  of a  business’  activities:  data processing.   Threshold for requiring  a DPIA:  DPIAs  are only required for activities   ‘result[ing] in high risk’ determined by a range of criteria of activities that   c ould result in such a risk.36 DPIA must be of an iterative nature as part of a   c ontinuous cycle and require a new assessment of risk to the individual if a   change in nature, scope,  context, purpose, and sources  of the risk occurs.   Pla nning and scoping : The GDPR does not contain an explicit reference to a   planning and scoping phase as envisaged in HRIA and does not specify who   should be involved  in conducting the DPIA  beyond a data protection officer.   Data collection and baseline development : DPIA does not require a   consideration of context or stakeholder engagement, and does not require a   particular methodology.   Identifying and assessing risks: For a DPIA, the necessity and proportionality   of the data processing has to first be assessed.  This ensures that consideration  is given to compliance with key principles of data protection, such as data   minimisation. An ass essment of the specific risks to individuals must then be   conducted. The assessment of risk is independent of the preliminary   assessment of severity of risk required to trigger the carrying out of a DPIA in the first place but is rather a full risk assessm ent.  Impact prevention and mitigation: DPIA requires data controllers to set out   how they will mitigate the risks they identify. While flexibility is given to the   data controller to identify effective measures to reduce the risk to an acceptable level, if the data controller is not able to find such a measure, consultation with the supervisory  authority is required. The mitigation  
40          measures  in HRIA,  including  ‘prevention,  mitigation and  remediation’,  are not  found in DPIA.   Reporting : Under the GDPR, there is no obligation to publish a DPIA and its   findings. It is up to the data controller to publish it if they wish. Generally,  lack  of transparent reporting requirements has been identified as a major issue in   DPIA.37  Oversigh t: The GDPR  requires  states to establish  or designate a supervisory   authority as part of a system  of monitoring and oversight.  Continuous review : Data controllers are required to consider whether they   need to renew their DPIA if a change is likely to present a high risk to data   subjects. Changes  in the data processing operation or technology can trigger   the requirement to carry out a DPIA, as can changes in organisational or   societal context.   Consultati on: The consultation required for DPIAs is much narrower and   specific than in HRIA. Consultations in relation to DPIA are referred to in two   ways: consultation with supervisory authorities (as already discussed above)   and consultation with ‘interested parties’. Article 35(9) of the GDPR states   that, ‘[w]here  appropriate,  the controller shall seek  the views  of data subjects  or their representatives on the intended processing, without prejudice to the   protection of commercial  or public interests or the security  of processing  operations.’38  Sources: McGregor and Rau, “Identification of Synergies and Divergences between HRIA and DPIA:   Assessing Entry Points for Human Rights Integration”, Human Rights Big Data and Technology Project   (forthcoming)     There are numerous ways in which the methodologies used to conduct HRIA   could  strengthen DPIA  practices :  • Adopting a HRIA  approach to public reporting could  contribute to addressing  shortcomings of DPIA in relation to the lack of transparency and information  that exists on the experiences of data controllers in carrying out DPIAs and the challenges  they face in practice.   • Thro ugh adopting all internationally recognised human rights and principles   as a benchmark, companies conducting DPIAs may gain a further   understanding of the conception of risk and what may constitute a trigger to   a new or  renewed assessment.   • It can improve  the general  understanding of cumulative impacts and impacts   on specific groups.   • An explicit  planning and scoping phase could be introduced into DPIAs,   including consideration  of the human rights context  and a mapping of 
41        relevant stakeholders in order to take into account the full human rights   impact  of the  project  or activity.   • It could provide a means  for engaging  with and empowering stakeholders,  including impacted rightsholders, to provide input through transparent  engagement and reporting as well as gain more consolidated consultation   approaches as is established  by a human  rights- based  approach.  • Guidance to viable alternatives to consultation with affected rightsholders   would also be added to replace dismissing the need for consultation on the   basis  of not being feasible,  as is made  possible  under the GDPR.  • It would further entrench the need  for ongoing review  to ‘know  and show’  how a business operation  or relationship  may  affect rightsholders.  Incorporating a HRIA methodology to DPIA would however leave open several   questions  that require  further consideration, such as:   • Would the human rights expertise of the data protection officer ha ve to be   developed  or could a dedicated human rights officer be appointed as part of  the core  team?   • While the existence  of national supervisory  authorities under the GDPR  could   strengthen monitoring and compliance with the UNGPs as there is not an equivalent oversight body required by the UNGPs, would the human rights   expertise of data protection authorities need to be strengthened or should  the mandates of NHRIs be extended, with resource, to carry out such   oversight  or to provide expert  advice  to Data Protection Authorities?    BOX 5: ETHICAL  IMPACT  ASSESSMENT  AND  COMPARISON TO HRIA   A further methodology that has been  developed  to address negative impacts   related to certain new and emerging digital technologies is Ethical Impact   Assessment (EtIA). EtIA is a process during which “an organization, together   with stakeholders, considers the ethical issues or  impacts  posed  by a new  project, technology, service, program […], or other initiative, to identify risks   and solutions”39. During the assessment, dialogues with stakeholders such as   industry actors, policy -makers, regulators, civil society, academics and media   is considered esse ntial in order to achieve a  comprehensive study.  An EtIA strives to identify, understand, assess and address potential harms   caused by the difference between the intent of a project and its effective   contribution to a ‘common good’ in society. However, rig ht and wrong, good  and bad, and other similar concepts are not clearly defined, which can allow   different traditions and cultures to choose  different outcomes suited to their  own  needs  and sensitivities.  Unlike ethical  decision making  that involves  
42        identified phases, EtIA is characterized by its large set of different approaches   that can be used by businesses. Though EtIA methodologies differ and are  inherently  flexible , the process  generally  involves  the following  six steps :  1. Conducting  an ethical  impact  threshold analysis  2. Preparing  an EtIA plan   3. Identifying ethical impacts using foresight and ethical impact identification methods  4. Evaluating ethical impacts by identifying value conflicts, proposing   solutions, discussing impact analysis and conducting an evaluation   with stakeholders  5. Formulating  and implementing  remedial  actions   6. Reviewing  and auditing  the EtIA  outcomes   The model methodology outlined is comparable to other types of impact   assessments,  including HRIA,  but the absence of clear standards can lead  to a  business taking a less extensive approach or choosing the approach that is   most  beneficial for the project in  financial terms.   There  are, as such,  some important  differences between HRIA  and EtIA:   • Stakeholder engagement is a key feature of the EtIA framework, but the   degree of stakeholder engagement can vary and the minimalist version of   EtIA is characterized by the involvement of only project managers and   internal discussions around their actions. HRIA, on the other hand, requires engagement with rightsholders or their proxies, with a focus on   the experiences  of the most vulnerable  groups and individuals.   • Unlike HRIA, EtIAs are not based on clear references to international   standards but use various ethical standards and frameworks as benchmarks . Similar to HRIAs, however, EtIAs have contributed to the   implementation of the ‘do no harm’ doctrine in the ICT sector. The lack of  benchmarks means that there is a risk that EtIAs contribute to ‘ethics   washing’ instead of ensuring that negative impacts are effectively   prevented and/or  mitigated.  • The lack of clear international standards and benchmarks may also lead to   allocation of insufficient resources allocated to tackle identified negative  ethical impacts . As such, EtIAs could benefit from the integration of  human rights as a standard, and EtIA methodologies can adopt HRIA   methodologies in order to enhance the potential of EtIAs to identify and address negative human rights impacts. This may also help widen the   scope  of potential impacts  to be addressed  throughout the EtIA process.   • While a larg e variety of EtIA approaches can be identified, there is limited   insight into how  EtIAs  are conducted in practice  since  EtIAs  are generally  
43          not made public. This holds true even as many tech companies have   made public their own ethical principles and standards , which are the   standards that ought to be used  in EtIAs.  While there are also limited  HRIA   reports in the public domain, the benchmarks and standards make the   expectations on such  processes  clearer.   In sum, the EtIA approach is more flexible and less rigorous than the HRIA   methodology  and can therefore benefit from adopting internally  recognised   human rights as a reference when e.g. the ‘common good’  is concerned.   However, seeing as ethics -based approaches are common in relation to   assessment  of new and emerging  technologies, such  approaches can be useful  as entry points for discussions of wider human rights topics and, thus, ensure   that a given  company  in practice  lives  up to its responsibility  to respect  human   rights.   Source: Wright (2014), “Ethical Impact Assessment”; Markkula Center for Applied Ethics & Guerrero   (2018) “Areas of Ethical Impact” ; SATORI (2016) “ A Common Framework for Ethical Impact Assessment” :  https://satoriproject.eu/media/D4.1_Annex_1_EIA_Proposal.pdf  [Accessed July 29, 2020]; Vallor, Green   & Raicu (2018 ) “Ethics in Technology Practice” p.2 : https://www.scu.edu/ethics/ [Accessed July 29,   2020]; Hao (2019),  “In 2020, let’s stop  AI ethics -washing  and actually do  something”   :https://www.technologyreview.com/2019/12/27/57/ai- ethics -washing -time -to-act/ [Accessed July 29,   2020]; BSR and the World Economic Forum (2019), “White paper: Responsible Use of Technology”:  https://www.weforum.org/whitepapers/responsible- use-of-technology  [Accessed September  15, 2020].       BOX 6: TECHNOLOGY  ASSESSMENT  (TA) AND  COMPARISON TO HRIA   Technology  assessment  is a broad  field defined as “a scientific, interactive and  communicative process, which aims to contribute to the formation of public   and political opinion on societal aspects of science and technology."40  Technology Assessment (TA) is an operat ional -oriented and case -based tool   focusing on various  technologies  (e.g.  virtual reality,  facial recognition etc.)   The assessment focuses on a specific technology and not activities broadly   speaking, assessing one product at the time. Often incorporated in  development processes, TAs aim to explore all impacts and aspects of a  technology and are not limited to adverse impacts. Legal and ethical   considerations are important components of the assessments, but TAs are not  restricted to them. Three dimensions make up TA: the cognitive dimension,  which creates an overview on knowledge relevant to policy -making; the   normative dimension, which establishes dialogue in order to support opinion  making; and the pragmatic dimension, which establishes processes that help  decisions to be made.  
44          Some  differences  and commonalities  between  TA and HRIA  are as such:   • TA explores all impacts, positive and negative, of a given technology,   whereas HRIA focuses on identifying and addressing the negative human  rights impacts.   • TA places significant emphasis on ongoing process of assessment rather   than snapshot evaluati ons, in that sense it is more similar to general  HRDD. HRIA,  however, is one tool in the HRDD  toolbox which provides a  snapshot of context and impacts at  a certain  point  in time.   • TA is conducted by a variety of actors, businesses but also governments   and regional bodies, which differs slightly from the HRIA methodology   presented here  and which is generally  thought of as a process  related  to  business activities (compare, however, SWIA methodology discussed in  chapter 1.5.3).  • A notable difference between  HRIA  and TA lies in the standards applied  as  benchmark for the assessment. Except in the health sector, TA is not  regulated with reference to internationally recognized standards, which  allows a flexibility for businesses but also less accountability for  stakeholders.  • The core principles used by businesses resembles those from Ethical   Impact Assessment (see Box 5, above). Therefore, TAs may integrate   human rights—and activities  such  as training  developers  and managers  on  human rights —which may increase the respect for human rights with  increased  efficiency and at a limited  cost.  However,  such  integration  is not  necessarily  expected.   Source: European Parliamentary Technology Assessment, TAMI project, "Technology Assessment -  Methods and Impacts": https://eptanetwork.org/about/what -is-ta [Accessed July 29, 2020]; Benta   (2009) “ What is technology assessment ?”: https://www.cambridge.org/core/journals/international -  journal -of-technology -assessment -in-health -care/article/what -is-technology -  assessment/F2CE6903EE02296499AC0AC24192454E [Accessed July 29, 2020]     While the different kinds of assessments presented above  all have  their upsides,   it is important to point out that “part of the value of the human rights   framework stems  from  the fact that these  norms  already exist  under   international human rights law.”41 The standards in international human rights   ha ve been negotiated and agreed to internationally and are therefore highly   appropriate for a globalised context, such as the context of digital products and  services. As such, the human rights framework has much to offer also to other   forms  of impact  assessment.  
45        2.5.3 SHOULD HRIA  BE STAND -ALONE  OR COMBINED  WITH  OTHER   FORMS  OF IMPACT  ASSESSMENT?     One key question for HRIA practice is whether it is best to assess human rights by   using a ‘stand -alone’ approach (i.e. an assessment that focuses exclusively on  human rights) or a ‘combined approach (i.e. combining human rights impact   assessment methodology with other forms of impact assessment, such as those   presented above).  In short, the answer  should depend on the particular  context .  Based on the comparisons to DPIA, EtIA and TA, there are a number of potential   benefits  to combined  approaches  that can be identified, such  as:  • Building  on and utilising  existing impact  and risk management  structures  • Avoiding consultation fatigue of external stakeholders and assessment  fatigue of internal stakeholders  • Facilitating analysis of the interrelatedness of e.g. data protection, privacy,   ethical principles  and broader human rights impacts, and   • Building  on the respective strengths of the different disciplines  involved.  On the other hand, there are also a number of benefits to taking a stand- alone   approach. A stand- alone  HRIA can, for example:   • Avoid side -lining human rights issues amongst a range of topics being   considered   • Draw  more  extensively on human rights expertise, and   • Facilitate more in -depth space for learning and capacity building of the   different stakeholders  involved.    TABLE C: STRENG THS AND  WEAKNESSES OF DIFFERENT  APPROACHES  TO  ASSESSING HUMAN  RIGHTS IMPACTS    Combined approach (with  EtIA, DPIA  or TIA)  Dedicated (stand- alone)   approach  Strengths  • Benefits from established  internal and external  company structures that   assign  accountabilities.   • Avoids duplication of work  and stakeholder   consultation fatigue by   focusing on the synergies  between e.g. potential data   protection and  privacy  • Draws on human rights   expertise, enabling specific   focus and de ep analysis of   human rights.   • Specifically  prioritises  individuals   and communities who may   experience human rights   impacts,  in particular by  facilitating participation of   vulnerable  and marginalised  
46          TABLE C: STRENGTHS AND  WEAKNESSES OF DIFFERENT  APPROACHES  TO  ASSESSING HUMAN  RIGHTS IMPACTS    Combined approach (with  EtIA, DPIA  or TIA)  Dedicated (stand- alone)   approach   impacts, and human rights   impacts.   • Can ensure that companies’  ethical commitments or data   privacy impacts, as well as   human rights impacts are   assessed simultaneously and   thereby improve  efficiency.   • Can enable more efficient  use of project time and  resources.   • The term ‘human rights’   resonates differently   amongst people. This can  lead to confusion, concern  and sensitivities.  A  combined approach has the   benefit of addressing human  rights while using a   framework and language   with which project  teams   are familiar (e.g. ethics,   privacy, data protection,   diversity  etc.).   • Can allow companies to   assess human rights without  explicitly framing it as such,   which can be important in  certain  country contexts.  individuals or groups, or their  proxies.   • Provides th e freedom for   companies to identify and assess   human rights impacts,  irrespective of government  adherence to international   human rights  standards.  Weaknesses • The process, especially if it is   dictated by prescriptive   regulatory  requirements or  by standard  setting  bodies,  • Mitigation and management  plans drawn from a dedicated  assessment  may  not be easily   incorporated  into existing  
47          TABLE C: STRENGTHS AND  WEAKNESSES OF DIFFERENT  APPROACHES  TO  ASSESSING HUMAN  RIGHTS IMPACTS    Combined approach (with  EtIA, DPIA  or TIA)  Dedicated (stand- alone)   approach   may not allow for a specific   focus on human rights.   • Those conducting the   assessment  may  not have   sufficient human rights   expertise.   • Human rights considerations   may not be explicitly   referenced, and it may be   less clear how human rights   impacts  have  been  identified  and will be  addressed.  • Mandated assessments,  such  as DPIAs,  are often not  required to be made public   and there is a risk that  combining approaches   therefore leads to less   transparency. company management systems   and may  suffer from lack of both  ‘buy- in’ and accountability for   implementation.  • Adds additional cost and   resource man agement   requirements to the company   and/or project; cost sensitivities   may also arise with business   partners or governments.   • The impact assessment   practitioners may lack specific   human rights  expertise.   • May exacerbate or give rise to   potential political se nsitivities  from external stakeholders, or  may raise or create stakeholder  expectations in situations where  human rights are not promoted  and protected.    2.5.4 SECTOR -WIDE  IMPACT  ASSESSMENT: AN ALTERNATIVE  TO  INDIVIDUAL  ASSESSMENTS?     In some cases, HRDD processes and/or external stakeholders may identify or   point out that individual assessments and individual action  will not be either:   A) sufficient to address largely  systemic  issues which require  coordination,  or  B) the most efficient way of identifying and addressing human rights   impacts that will largely be similar for most actors in a given context (e.g.   when a country with human rights legacy issues opens up its markets to   foreign investment).  
48        In such circumstances, it can be more efficient to take a wider look at potential   and actual human rights impacts. One such approach and methodology is Sector   Wide Impact Assessment (SWIA). Box 7, below, provides an example of a SWIA  related  to the digita l activities.     BOX 7: SECTOR WIDE IMPACT  ASSESSMENT  OF ICT SECTOR  IN MYANMAR   Contribution by Margaret  Wachenfeld.  The Myanmar Centre for Responsible Business (MCRB) together with the Institute  for Human Rights and Business (IHRB) and DIHR conducted a “sector wide human  rights impact assessment” (SWIA) on the Information and Communications   Technology (ICT) sector in Myanmar in the period 2014 -2015. A SWIA uses an   impact assessment approach but looks across human rights impacts in the whole   sector, rather than impacts of only a particular product, project or company. As a  SWIA takes the UNGPs as a normative framework, it also looks across all three   pillars of the UNGPs —at the government’s role unde r Pillars I and III and the   corporate role  in human rights under Pillars II  and III.  The ICT SWIA was conducted at a point in time when Myanmar was undergoing a   profound transformation, emerging from authoritarian rule and economic   isolation. Mobile phone penetration was experiencing a dramatic rise at the time   of the SWIA (from 7% to 33% between 2012 and 2014), the first mobile licenses   were being issued to international operators and Myanmar residents had access to   the Internet for the first time. All of this development took place amid an absence   of adequate policy  and legal frameworks.   The SWIA  contained a detailed  analysis  of the ICT policies  and laws  in place  and the  gaps from a human rights perspective. The gaps in the policy and legal frameworks   were and still are compounded by people’s basic lack of experience of using ICTs,  resulting in the potential for misuse and negative impacts on a range of human  rights, particularly  the rights to privacy and  freedom  of expression.   The SWIA also included a mapping of the ICT business ecosystem in the early days   of Myanmar’s ICT transformation. Developing a mapping was useful to understand  where different businesses fit in the value chain, and it was also in itself helpful as   an engagement tactic with companies and others as no other actors had put that  information together. It thus became something useful that could be offered in  return for participating in consultations. As few companies had even heard of  human rights or other concepts such as responsible business conduct at the time,  questions had to be framed to ask about particular issues in plain language,   focusing on asking companies  about what they were  doing and why, and using that  as a basis to draw conclusions, rather than asking companies about human rights   directly.  
49        With regard to access to remedy (Pillar III), there was limited options for raising   grievances with state -based mechanisms and few companies had even thought  about user  or consumer grievances.   A SWIA puts stakeholder engagement at the core of the process of identifying and  assessing human rights impacts. As a SWIA is about a whole sector rather than a particular company, the process started with mapping out the sector —government  agencies, the ICT businesses ecosystem and the limited CSO actors in the space —  which had not been done  before.  Four groups of stakeholders were identified and interviewed (i) communities   potentially affected by ICT operations, covering issues including: ICT use;   consultation; children; gender; security; indigenous peoples/different ethnic   groups; (ii) managers of ICT companies, covering issues including: customer/user privacy and security (including lawful interception and surveillance); freedom of expression (including censorship and hate speech); community impacts; (iii)   employees  and workers of ICT companies  and (iv) external  stakeholders,  covering   issues including: the impacts of ICT operations for local or national authorities,   NGOs and CSOs, international organisations, journalists, political parties, schools   and monasteries.   As the project was looking at the whole sector across the country, the team   selected field research locations w here ICT operations were underway and that  were representative of a range of ICT contexts in Myanmar: urban and rural ICT   usage;  Internet cafes  and phone and SIM shops in urban and rural settings.   The field researchers conducted interviews one -to-one and i n small groups, as well  as focus group discussions. Open questions were used as much as possible, in order   to allow respondents to answer using their own thoughts and words, and raise the   issues they considered important. Because the sector was so new for many of the   stakeholders, approaching them to ask about either the technical dimension or the   human rights dimension often also required reframing to ask questions from which human rights concerns  or impacts  could  be inferred.  To many users, the Internet and Facebook were synonymous. The researchers   therefore provided some basic explanations and “translated” concepts like   freedom of expression into terms that stakeholders could understand. For   stakeholder groups such as the few specialized CSOs at the time or user groups,   with expert knowledge on the subject, it was possible to have more detailed  discussions,  such as  around gaps  in the  policy  and legal framework.   MCRB built on those early discussions to bring together a coalition of interested  organizations who host the Myanmar Digital Rights Forum every year to continue   discussions on topics raised in  the SWIA  and on digital rights more  generally.  
50          One dimension that was different from the typical digital HRI A is that the SWIA   covered both “online” and “offline” issues —such as labour rights impacts from   tower or fibre line construction. The consultation process therefore also included  discussions with day laborers  digging fibre cable  trenches  and constructing mobile   network towers.   Sources: MCRB, IHRB, DIHR (2015), “Sector- Wide Impact Assessment of Myanmar’s ICT Sector” :  https://www.myanmar -responsiblebusiness.org/sectors/ict.html  [Accessed July 29, 2020]; Wachenfeld,   Wrzoncki & de Angulo (2019), “Sector- wide impact assessment: A ‘big picture’ approach to addressing human  rights impacts”, in Gotzmann (2019), “Handbook on Human Rights Impact Assessment” ; MCRB (2019), “Third   Myanmar  Digital  Rights  Forum  Ends  With  Call for Better  Regulated,  Freer, Safer  Online  Space, Emphasises Need   for Consultation” : https://www.myanmar -responsiblebusiness.org/news/digital -rights -forum -2019-   report.html [Accessed July 29, 2020].  
51          GLOSSARY     Allow -list: practice  of allowing  some  identified entities (e.g.  customers)  access  to  a particular privilege  (e.g.  possibility  to purchase a specific product or service).   Sometimes  also called  ‘whitelist’. Opposite of block- list.  Block -list: practice of not allowing identified entities (e.g. customers) access to a   particular privilege  (e.g.  possibility  to purchase a specific product or service).   Sometimes  also called  ‘blacklist’.  Opposite of allow -list.  Borderline online  content:  content that comes  close  to—but  doesn’t quite cross   the line of—violating  e.g. company  guidelines or  human rights.   Chatbot: software that simulates human- like conversations with users via text  messages on chat.  Data lifecycle: phases that data goes through during its lifetime, including data  collection,  data processing,  data use, data cleaning, data erasure.   Deep  learning:  subset  of machine  learning,  a branch of artificial intelligence  that  configures computers  to perform tasks through experience.   Duty -bearer: those that have  duties and responsibilities  to uphold and respect   these human rights.  Includes both states  and businesses.   Ex-ante assessment: assessment that occurs before the business project or   activities  commence.   Ex-post assessment: assessment that occurs once the business project or   activities  are already  well underway.  First -order impacts: The most ‘immediate’ impacts of an activity, which may lead   to other impacts. E.g. a first -order impact on the right to a fair trial, can lead to   second - and third- order impacts on the right to family life, to education and to   health.  Freemium: business model that involves offering customers both  complementary  and extra -cost services.   Gating:  process  to limit  e.g. the sale,  use or application  of a particular product or  service.   Human in the loop: process when the machine or computer system is unable to   offer an answer to a problem, needing a human intervention. Human- in-the- loop   allows  the user to  change the outcome of an event  or process.  
52        Know Your Customer (KYC): process of identifying and verifying the identity of a   client or customer when engaging initially (e.g. when applying to enter an ‘allow   list’)  and periodically  over  time.   Off-the-shelf : product or service that is available immediately and does not need   to be specially  made  to suit a particular purpose, e.g. off-the- shelf  software.  Rightsholders:  individuals  that have  entitlements to have  their rights protected,  respected and  fulfilled.  Second - and third- order  impacts:  see ‘first -order  impacts’.   Sentiment analysis: uses natural language processing and machine learning to   interpret and classify  emotions in  subjective data.  Tech  giants:  refers  to technology companies  that have  a dominant position  in  markets  for internet- based  platforms and services.   Use-cases:  a specif ic situation  in which a product or service  could  potentially be  used.  Zero- rating: refers to the practice of not charging users for data used to access   certain  online  services  or platforms.  
53                     1 High -level Panel on Digital Cooperation (2019), “The age of digital interdependence”, p. 17,   https:/ /digitalcooperation.org/wp -content/uploads/2019/06/DigitalCooperation -report -for-  web.pdf  [Accessed July 29, 2020]   2 Ibid.   3 HRC (2012), “T he promotion, protection and enjoyment of human rights on the Internet”,  A/HRC/20/L.13: https ://documents -dds-  ny.un.org/doc/RESOLUTION/GEN/G12/153/25/PDF/G1215325.pdf?OpenElement  [Accessed July  29, 2020]   4 See e.g. C ouncil  of Europe  (2020), “Recommendation  CM/Rec(2020)1  of the Committee  of  Ministers  to member  States  on the  human rights  impacts  of algorithmic  systems” :  https ://search.coe.int/cm/pages/result_details.aspx?objectid=09000016809e1154#globalcontain   er [Accessed July 29, 2020]; Independent High- level Expert Group on Artificial intelligence (2019),   “Ethics Guidelines for Trustworthy AI”, European Commission: https://ec.europa.eu/digital -single -  market/en/news/ethics- guidelines-trustworthy-ai [Accessed July 29, 2020]; Australian Human   Rights Commission (2019), “Human Rights and Technology: Discussion Paper”:  https://tech.humanrights.gov.au/sites/default/files/2019-   12/TechRights_2019_DiscussionPaper.pdf  [Accessed  July 29, 2020];  and Latonero  (2018),   “Governing Artificial Intelligence: Upholding Human Rights & Dignity”, Data & Society:   https://datasociety.net/library/governing-artificial- intelligence/  [Accessed  July 29, 2020].   5 41st session  of the Human  Rights  Council,  “Opening  statement by the UN High  Commissioner for  Human Rights Michelle Bachelet”:   https://ohchr.org/EN/NewsEvents/Pages/DisplayNews.aspx?LangID=E&NewsID=24724   6 For more  information see Office  of the High  Comm issioner on  Human  Rights, “B-Tech  Project”:  htt ps://www.ohchr.org/EN/Issues/Business/Pages/B -TechProject.aspx   7 See e.g. Human Rights Council (2018), “Report of the Specia l R apporteur on the promotion and  the protection of the right to freedom of opinion and expression: Note by the Secretary -General”,   A/73/348,  para. 53: https ://undocs.org/A/73/348 [Accessed  July 29, 2020]; HRC  (2020),  “Question of the realization in all countries of economic, social and cultural rights - Report of the   Secretary -General” , A/HRC/43/29 para. 52: https://undocs.org/en/A/HRC/43/29  [Acces sed July   29, 2020]; Australian Human Rights Commission (2019), “Human Rights and Technology:  Discussion Paper”: https://humanrights.gov.au/our -work/rights- and-  freedoms/publications/human-rights -and-technology- issues- paper -2018  [Accessed July 29,   2020]; HRC (2019), “Surveillance and human rights - Report of the Special Rapporteur on the   promotion and protection of the right to freedom of opinion and expression”, A/HRC/41/35 para.   60: https://documents -dds-  ny.un.org/doc/UNDOC/GEN/G 19/148/76/PDF/G1914876.pdf?OpenElement  [Accessed  July 29,  2020];  Ranking Digital Rights  (2020), “Ranking Digital  Rights  Corporate  Accountability Index  Draft   Indicators” : https://rankingdigitalrights.org/wp- content/uploads/2020/04/2020-draft-       END  NOTES  
54                       methodology- redline -version.pdf  [Accessed July 29, 2020]; Investor Alliance for Human Rights   (2020), “Investor Toolkit on Human Rights”:  https://investorsforhumanrights.org/sites/default/files/attachments/2020-   05/Full%20Report%20- %20Investor%20Toolkit%20on%20Human%20Rights%20 -  %20May%202020b.pdf  [Accessed  July 29, 2020].   8 See e.g. Human  Rights  Council  (2018), “Report  of the Special  Rapporteur  on the promotion  and  protection of the right to freedom of opinion and expression”, A/HRC/38/35:  https:// undocs.org/A/HRC/38/35   9 Danish Institute for Human Rights, “Human rights impact assessment guidance and toolbox”,  https://www.humanrights.dk/business/tools/human -rights -impact -assessment -guidance -toolbox   [Accessed  Nov 17, 2020].   10 Office of the High  C ommissioner for Human  Rights,  “B-Tech  Project”:   https: //www.ohchr.org/EN/Issues/Business/Pages/B -TechProject.aspx [Accessed  Oct 22, 2020].   11 It is important  to n ote that it remains an expectation that companies  assess all of their  impacts,   and users of this guidance are still expected to assess these impacts. While we are not including   workers in the gig economy in the scope of this Guidance, they may be severely impacted by business models of digital platforms facilitating such work and sho uld thus also be considered by   companies  as they  assess their  human rights  impacts.  For more on the gig economy,  see e.g.  Busines s & Human Rights Resource Centre (March 2019), “The Future of Work: Litigating Labour   Relationships in the Gig Economy”, Corporate Legal Accountability Annual Briefing:   https://media.business-   humanrights.org/media/documents/files/documents/CLA_Annual_Briefing- FINA L.pdf  [Accessed   Nov 23, 2020]; International Labour Organisation, “Crowdwork and the gig economy”:  https://www.ilo.org/global/topics/non -standard- emp loyment/crowd-work/lang --en/index.htm   [Accessed Nov 23, 2020]; International Trade Union Confederation (Oct 2019), “ITUC Policy Brief   Organising and Collective Bargaining in Non- Standard Forms of Work”: https://www.ituc -  csi.org/Organising -CollectiveBargaining -in-NonStandard-Work  [Accessed  Nov 23, 2020].   12 For more  information B- T ech Foundational Paper (forthcoming), “ Key Characteristics  of  Busin ess Respect for Human Rights”, Office of the High Commissioner for Human Rights:   https://www.ohchr.org/EN/Issues/Business/Pages/B -TechProject.aspx [Accessed  July 29, 2020].   13 UN Guiding  Prin ciple  18.  14 UN Guiding Prin ciple  19.  15 UN Guiding Prin ciple  20.  16 UN Guiding Prin ciple  21.  17 B-Tech  Project (2020),  “A B-Tech  Foundational  Paper: The UN Guiding  Principles  in the Age of  Technology” , OHCHR: htt ps://www.ohchr.org/EN/Issues/Business/Pages/B -TechProject.aspx   [Accessed  July 29, 2020].  
55                       18 Office of the High  Co mmissioner for Human  Rights,  “B-Tech  Project”   https:/ /www.ohchr.org/EN/Issues/Business/Pages/B -TechProject.aspx [Accessed  Sept  14, 2020].   19 United Nations (2011), “ Guiding P rinciples on Business and Human Rights: Implementing the  United Nations ‘Protect, Respect and Remedy’ Framework”, A/HRC/17/31 [Hereinafter: UN  Guiding  Principles].   20 B-Tech Project (2020), “A B- Tec h Foundational Paper: The UN Guiding Principles i n the Age of   Technology” , OHCHR: https:// www.ohchr.org/Documents/Issues/Business/B-Tech/introduction-   ungp- age-technology.pdf   21 Ibid.   22 B-Tech Project (2020), ”A B- Tec h Foundational Paper: Key Characteristics of Business Respect   for Human Rights”: https:// www.ohchr.org/Documents/Issues/Business/B- Tech/key -  characteristics -business-respect.pdf   23 See e.g. Global Network Initiative (GNI) (2020), “The G NI Principles at Work: Public Report on   the Third Cycle of Independent Assessments of GNI Company Members 2018/2019”, p. 103:   https:// globalnetworkinitiative.org/wp-content/uploads/2020/04/2018- 2019- PAR.pdf   24 B-Tech Project (2020), ”A B- Tec h Foundational Paper: Key Characteristics of Business Respect  for Human Rights”: https:// www.ohchr.org/Documents/Issues/Business/B- Tech/key -  characteristics -business-respect.pdf   25 Ibid.   26 Ibid.   27 Ranking  Digital Rights  (2 020), “2020 Ranking  Digital  Rights  Corporate  Accountability  Index   Researc h Indicators”: https://rankingdigitalrights.org/2020- indicators/  [Accessed July 29, 2020].   Indicators related  to Section G4 suggest  that risks  ought  to be identified  and further  assessment   should  be conducted whenever  specific  concerns  have  been  identified.   28 There are times wh en a robust  HRIA  as outlined  in this Guidance  may  not be feasible.  This may   e.g. inc lude M&A processes or early -stage development with unclear use -cases, in relation to   which there are inherent obstacles to external stakeholder engagement. In such circumstances   HRDD processes of course remain essential. That a HRIA may not be feas ible at a certain point in   time  should  never  imply  that companies  do not assess and address  human rights  impacts.   29 See e.g. Ranking Digital Rights (2019), “Co nsultation Draft – Human Rights Risk Scenarios:  Targeted Advertising”: htt ps://rankingdigitalrights.org/wp -content/uploads/2019/02/Human-   Rights -Risk-Scenarios-targeted- advertising.pdf  [Accessed  July 29,  2020].   30 Ibid.   31 Global Network Initiative (2017), “ The GNI principles” : http s://globalnetworkinitiative.org/wp-   content/uploads/2018/04/GNI -Principles- on-Freedom -of-Expression -and-Privacy.pdf  [Accessed   July 29, 2020].  
56                       32 Ibid.   33 See e.g. Reisman et.al. (2018), “Algori thmic Impact Assessments: A Practical Framework for   Public Agency Accountability”: https:// ainowinstitute.org/aiareport2018.pdf; and, Ada Lovelace   Institute & DataKid UK (2020),  “Examining the Black  Box:  Tools  for Assessing Algorithmic   Systems”:  https://www.adalovelaceinstitute.org/examining -the-black -box-tools -for-assessing -  algorithmic -systems/   34 EU General Data Protection Regulation [herein after:  GDPR]  Art. 35(1).   35 Article  29 Working  par ty was replaced  by the European  Data Protection Board when  GDPR   came  into force  on 25 May 2018.   36 GDPR  Art. 35(1).   37 Wright & de Hert (2012), “Privacy Impact Assessment” , Law , Governance and Technology   Series,  Vol. 6., p. 27; “Comments  of the Electronic  Privacy  Information Center  on Consultation  on  Data Protection Impact Assessments (DPIAs) Guidance” , July 3, 2018:   https: //epic.org/algo rithmic -transparency/EPIC -Irish -DPC-Comment -DPIA.pdf , p. 10 [Accessed   July 30, 2020].   38 GDPR  Art. 35(9).   39 SATORI (2016) “A Common Framework for Ethical Impact Assessment” , p. 7:   htt ps://satoriproject.eu/media/D4.1_Annex_1_EIA_Proposal.pdf  [Accessed  July 29, 2020].   40 European Parliamentary Technology Assessment, “ Technology Assessment - Methods and  Impacts”, TAMI  project: http s://eptanetwork.org/about/what- is-ta [Accessed  July 29, 2020].   41 Donahoe (2018), open remarks to the conference “H uman Centered AI: Building Trust,  Democracy and Human Rights by Design“ : http s://medium.com/stanfords- gdpi/human- centered -  ai-building- trust -democracy-and- human -rights -by-design -2fc14a0b48af  [Accessed  June  26, 2020].  
   
