THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•1  Charlotte Siegmann* and Markus Anderljung* |August 2022TheBrusselsEffect andArtificialIntelligence: How EU regulation will impact the  global AI market
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•2  ABSTRACT The European Union is likely to introduce among the first, most stringent, and most comprehensive AI regulatory regimes of the world’s major jurisdictions. In this report, we ask whether the EU’s  upcoming regulation for AI will diffuse globally, producing a so-called “Brussels Effect”. Building  on and extending Anu Bradford’s work, we outline the mechanisms by which such regulatory  diffusion may occur. We consider both the possibility that the EU’s AI regulation will incentivise  changes in products offered in non-EU countries (a de facto Brussels Effect) and the possibility it  will influence regulation adopted by other jurisdictions (a de jure Brussels Effect). Focusing on the  proposed EU AI Act, we tentatively conclude that both de facto and de jure Brussels effects are  likely for parts of the EU regulatory regime. A de facto effect is particularly likely to arise in large  US tech companies with AI systems that the AI Act terms “high-risk”. We argue that the upcoming  regulation might be particularly important in offering the first and most influential operationalisation of what it means to develop and deploy trustworthy or human-centred AI. If the EU regime is  likely to see significant diffusion, ensuring it is well-designed becomes a matter of global importance. *ThisreportwasjointlyauthoredbyCharlotteSiegmannandMarkusAnderljungwithequalcontributions.Authororderrandomized.CharlotteSiegmannisaPredocFellowinEconomicsatthe  GlobalPrioritiesInstituteattheUniversityofOxford.MarkusAnderljungisHeadofPolicyatthe  CentrefortheGovernanceofAI.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•3  ExecutiveSummary In2019,twoofthemostpowerfulEuropeanpoliticians,UrsulavonderLeyenandAngelaMerkel,  calledfortheEuropeanUniontocreateaGDPRforAI. ³TheGeneralDataProtectionRegulation ⁴ (GDPR)isoneofthemostinfluentialpiecesofEuropeanUnion(EU)legislationinthelastdecade.  ItnotonlychangedbusinesspracticeswithintheEU,butalsocauseda“BrusselsEffect”abroad.  It incentivised changes in products offered in several non-EU countries (a de facto Brussels  Effect)andinfluencedregulationadoptedbyotherjurisdictions(a dejureBrusselsEffect). This report argues that upcoming EU regulation of AI is poised to have a similarly global  impact. Focusing on the proposed AI Act and  proposed updates to liability regimes, we argue that: • Both de facto and de jure Brussels Effects  are likely for parts of the EU’s AI regulation. • The Brussels Effect will likely be more  significant than the “Washington Effect”  or the “Beijing Effect”. If there is a significant AI Brussels Effect, this  could lead to stricter AI regulation globally.  The details of EU AI regulation could also influence how “trustworthy AI” is conceived  across the world, shaping research agendas  aimed at ensuring the safety and fairness of AI  systems. Ultimately, the likelihood of a Brussels Effect increases the importance of helping shape the EU AI regulatory regime: getting the regulation right would become a  matter of global importance.Findings ForpartsoftheEU’sAIregulation,adefacto  BrusselsEffectislikely We expect multinational companies to offer  some EU-compliant AI products outside the  EU. Once a company has decided to produce  an EU-compliant product for the EU market, it  will sometimes be more profitable to offer that  product in some other jurisdictions or even  globally rather than offering a separate noncompliant version outside the EU. Drawing and building on Anu Bradford’s work,  we highlight several factors that make this behaviour (“non-differentiation”) more likely.  • The EU has relatively favourable market  properties . In particular, the market for AIbased products is large and heavily serviced by multinational firms. The EU market  size incentivises firms to develop and offer  EU-compliant products, rather than simply  abandoning the EU market. The fact that  these firms also service non-EU markets  opens the door to a de facto effect. 3Directorate-General for Neighbourhood and Enlargement Negotiations, “SpeechbyPresident-ElectvonDerLeyenintheEuropeanParliamentPlenaryontheOccasionofthePresentationofHerCollegeofCommissionersandTheirProgramme,” European Neighbourhood Policy and Enlargement  Negotiations, November 27, 2019 4European Parliament, “Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the Protection of Natural Persons  with Regard to the Processing of Personal Data and on the Free Movement of Such Data, and Repealing Directive 95/46/EC (General Data Protection  Regulation) (Text with EEA Relevance).”
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•4 • The EU ’s AI regulation is likely to be especially  stringent . If it were not more stringent than other  jurisdictions’ regulations on at least some dimensions, then there would be no room for it to have  aneffectabroad. • The EU has high regulatorycapacity . The EU’s  ability to produce well-crafted regulation decreases the chance that its AI regulations will  be either difficult to enforce or overly cumbersome to comply with. Customers may also see  EU compliance as a sign of the trustworthiness  of the product, further incentivising firms to offerEU-complaintproductsinotherjurisdictions. • Demand for some affected AI products is  likely to be fairly inelastic . Compliance with  EU AI rules may raise the cost or decrease  the quality of AI products by reducing  product functionality. If demand were too  elastic in response to such changes in cost  and quality, then this could shrink the size of  the EU market and make multinational firms  more willing to abandon it. The incentive to  offer non-EU-compliant products outside  the EU would also increase.  • The costofdifferentiation for some, but not all,  AI products is likely to be high. Creating both  compliant and non-compliant versions of a  product may require developers to practise  “earlyforking”(i.e.changingafundamentalfeature early on in the development process) and  maintain two separate technology stacks in  parallel. If a company has already decided to  develop a compliant version of the product,  then simply offering this same version outside  the EU may allow them to cut development  costs without comparably large costsofnondifferentiation , e.g. the costs of offering EUcompliant products globally. The proposed AI Act would introduce new  standards and conformity assessment requirements for “high-risk” AI products sold in  the EU, estimated at 5–15% of the EU AI market. We anticipate a de facto effect for some  high-risk AI products and for some categories  of requirements, but not others, owing to variation in how strongly the above factors apply.  A de facto effect is particularly likely, for in-stance, for medical devices, some worker  management systems, certain legal technology, and a subset of biometric categorisation  systems. A de facto effect may be particularly  likely for requirement sconcerning risk management, record-keeping, transparency, accuracy, robustness, and cybersecurity. A de  facto effect is less likely for products whose  markets tend to be more regionalised, such as  creditworthiness assessment systems and  various government applications. Although so-called “foundation models”  are not classed as high-risk in the EU Commission’s AI Act proposal, they may also  experience a de facto effect. Foundation  models are general purpose, pre-trained AI  systems that can be used to create a wide  range of AI products. Developers of these  models may wish to ensure that AI  products derived from their models will satisfy certain EU requirements by default. In  addition, the AI Act proposal may also be  amended to introduce specific requirements on general purpose systems and  foundation models. The AI Act proposal also introduces prohibitions on certain uses of AI systems. There is  a small chance that prohibitions on the use of  “subliminal techniques” could have implications for the design of recommender systems. If so, companies may choose to offer  EU-compliant recommender systems in  other jurisdictions. Other prohibitions (such  as on the real-time use of facial recognition  for law enforcement) also have a small  chance of influencing non-EU products by  shaping norms. The proposal also requires people to be made  aware if they are engaging with certain AI systems, e.g. content-generating systems (such as  authentic-seeming images and chatbot conversations) or remote biometric surveillance.  There is a modest chance that these requirements will lead companies to also e.g. display  tags indica ting some piece of content is AIgenerated in other jurisdictions, since removing the tags could come to be seen as dishonest behaviour.EXECUTIVESUMMARY
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•5 EXECUTIVESUMMARY A de jure Brussels Effect is also likely for  partsoftheEU’sAIregulation We expect that other jurisdictions will adopt  some EU-inspired AI regulation. This could  happen for several different reasons:  • Foreign jurisdictions may expect EU-like  regulation to be high quality and consistent  with their own regulatory goals. • The EU may promote its blueprint  through participation in international institutions and negotiations. • A de facto Brussels Effect with regard to a  jurisdiction increases its incentive to adopt  EU-like regulations, for instance by reducing  the additional burden that would be placed  on companies that serve both markets. • The EU may actively incentivise the adoption of EU-like regulations, for instance  through trade rules. We think de jure diffusion is particularly likely  for jurisdictions with significant trade relations  with the EU, as introducing requirements incompatible with the AI Act’s requirements for  “high-risk” systems would impose frictions to  trade. We also think there is a significant  chance that these requirements will produce  a de jure effect by becoming the international  gold standard for the responsible development and deployment of AI. A de jure effect is more likely for China than  for the US, as China has chosen to adopt  many EU-inspired laws in the past. However,  China is unlikely to include individual protections from state uses of AI. Further, China has  already adopted some new AI regulation,  somewhat reducing the opportunity for a de  jure effect. We are more likely to see a Brussels Effect  thanaWashingtonorBeijingEffect The US is unlikely to implement more stringent legislation than the EU, making a Washington Effect unlikely. Beijing will struggle to create a de facto Beijing Effect as companies  often already offer products specifically for  the Chinese market, though there could be a  de facto Beijing Effect through Chinese firm  exports. There is some chance that we see a  de jure Beijing Effect with regard to countries  that share the Chinese Communist Party’s  regulatory goals. Implications EUpolicymakers and other actorswithaninterest in AI regulation should take especially  great care to ensure the EU’s regulatory regime addresses risks from AI, since the regime may diffuse across the world. It is especially important, for instance, to ensure that  EU AI regulation is future-proof and can be adapted to a world of increasingly transformative AI capabilities. Policymakers worldwide should expect their  jurisdictions to experience a partial de facto  Brussels Effect. As a result, they – and non-EU  AI companies – might want to increase participation in the EU regulatory process. They  may also face incentives to ensure that their  regulation is compatible with the EU’s regime. The globalAIfield should invest in certain research topics – including explainability, fairness, transparency, robustness, and human  oversight – to help guide the EU’s regulatory  efforts. The proposed regulation should be  seen as a rallying cry to engage with policymakers and produce the research needed to  support the development and enforcement of  useful standards. Finally, regulators and standard setters beyond the EU legislative process should take  note. Higher prospects of an AI Brussels  Effect might suggest that other rules and  standards for AI could diffuse globally. This includes Californian AI regulation affecting US  federal regulation – a “California Effect” –and  standards set by organisations such as the  ISO, NIST, and the IEEE having a global effect.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•6  STRUCTURE OF THE REPORT We have aimed to make the report modular. We encourage readers to skip to the sections they  expect to find most informative.  The introduction summarises the EU’s upcoming regulatory regime for AI, as well as the rest of  the report.  Section 2 concerns the de facto Brussels Effect: whether firms outside the EU will voluntarily  comply with EU AI regulation. It outlines the core mechanisms of de facto diffusion and assesses  its likelihood, for various kinds of AI systems and requirements in the proposed AI Act.  Section3 concerns the de jure Brussels Effect: whether other jurisdictions will adopt EU-like regulation. It outlines the core mechanisms of de jure diffusion and assesses its likelihood.  The appendix details three relevant case studies of the Brussels Effect: the EU’s regulatory regime for data privacy, its product liability regime, and its product safety scheme (including CE  marking).  Table1 summarises the EU Commission’s proposed AI Act. Table 2 summarises our conclusions on the likelihood that various parts of the proposed AI Act  will produce a Brussels Effect.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•7  ACKNOWLEDGEMENTS For valuable comments, input, and discussion, we thank Joslyn Barnhart, Haydn Belfield, Alexandra Belias, Mathias Bonde, Miles Brundage, Will Carter, Allan Dafoe, Tom Davidson, Jeff Ding,  Noemi Dreksler, Gillian Hadfield, Shin-Shin Hua, Henry Josephson, Jade Leung, Darius Meissner, Nicolas Moës, Ben Mueller, Zach Robinson, Daniel Schiff, Toby Shevlane, Charlotte Stix,  Emma Bluemke, and Robert Trager. We also thank audiences at the CHAI all-hands meeting and  the European Governance Research Network bookclub in September 2021, as well as attendees of various Centre for the Governance of AI work-in-progress sessions. We also thank  Wes Cowley for copy editing, Maria Valente De Almeida Sineiro Vau for fact-checking, José Luis  León Medina for referencing assistance, and Aleksandra Knežević for typesetting. Special  thanks to Stefan Torges and Ben Garfinkel.  The cover image was generated using Midjourney, a machine learning image generation tool,  covered by a Creative Commons License. Prompt engineered by Noemi Dreksler. 
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•8 AI artificial intelligence GDPR General Data Protection Regulation  GAN generative adversarial networkAIA EU AI Act GMO genetically modified organism  B2B business-to-businessHLEG High-level expert group B2C business-to-consumerICT information and communications technology CoE Council of EuropeOMB Office of Management and Budget (a US  government agency) DPC Data Protection CommissionPLD Product Liability Directive EC European CommissionQMS quality management system EU European Union RoHS Restriction of Hazardous Substances directiveDMA Digital Market ActPET privacy-enhancing technologies DSA Digital Services ActPSD Product Safety DirectiveDPD Data Protection DirectivePNR passenger name record EMAS Eco-Management and Auditing SchemeREACH Registration, Evaluation, Authorisation and  Restriction of Chemicals regulation GAFAM Google, Apple, Facebook, Amazon, and Microsoft SME small-to-medium enterpriseCE Conformité Européenne (the European conformity  marking for “safe” products)ISO International Organization for Standardization CEN European Committee for StandardizationMRA Mutual Recognition Agreement on Conformity  Marking CENELEC European Committee for Electrotechnical  StandardizationMSA market surveillance authorityAbbreviations
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•9  Contents 1. Introduction...................................................................................................................................11 1.1.TheEU’sUpcomingRegulatoryRegimeforAI..................................................................11 1.1.1.TheDigitalMarketActandtheDigitalServiceAct..............................................11 1.1.2.TheAIAct.....................................................................................................................12 1.1.3.UpdatedLiabilityRules..............................................................................................17 1.2.WillWeSeeaBrusselsEffectfortheEUAIRegulatoryRegime? .................................18 1.2.1.DeFactoBrusselsEffect ..........................................................................................18 1.2.2.DeJureBrusselsEffect...........................................................................................20 1.2.3.WillThereBeaBrusselsEffectfortheAIAct?.................................................22 1.3.WhatAboutChinaandtheUS?..........................................................................................24 1.4.AnaloguestoEUAIRegulation.........................................................................................25 2. Determinants of the De Facto Brussels Effect ....................................................................26 2.1.FavourableMarketProperties............................................................................................28 2.1.1.MarketSize..................................................................................................................29 2.1.2.OligopolisticCompetitionandMultinationalCompanies...............................30 2.1.3.TerritorialScope.........................................................................................................31 2.2.RegulatoryStringency.........................................................................................................32 2.3.RegulatoryCapacity.............................................................................................................34 2.3.1.RegulatoryExpertise................................................................................................35 2.3.2.RegulatoryCoherence...........................................................................................36 2.3.3.SanctioningAuthority.............................................................................................36 2.3.4.FirstMoverAdvantage...........................................................................................38 2.4.InelasticitywithinandoutsidetheEU..............................................................................39 2.4.1.PreferencesforCompliantProducts....................................................................40 2.4.2.AbilitytoLeavetheMarket....................................................................................41 2.4.3.Substitutability..........................................................................................................42 2.4.4.Supply-SideElasticity.............................................................................................43
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•10  2.5.CostsofDifferentiation.......................................................................................................44 2.5.1.VariableCostsofNon-Differentiation..................................................................44 2.5.2.DuplicationCostsandEarlyForking..................................................................45 2.5.3.Non-EUComplianceCostsofDifferentiation....................................................47 2.5.4.ExistingProductDifferentiation...........................................................................48 2.6.LikelihoodofaDeFactoBrusselsEffectforDifferentIndustriesandRegulatory Requirements.................................................................................................................................49 2.6.1.TransparencyObligationsforSomeLower-RiskAISystems ..............................49 2.6.2.ConformityAssessmentsforHigh-RiskAISystems.......................................50 2.6.2.1.WhatHigh-RiskUsesofAIAreMostLikelytoSeeaDe FactoEffect?.........................................................................................................................50 2.6.2.2.WhatRequirementsforHigh-RiskAISystemsAreMost LikelytoProduceaDeFactoEffect?.............................................................................54 2.6.3.ProhibitedAIPractices...........................................................................................56 2.6.4.LiabilityofAISystems.............................................................................................57 2.7.DeFactoBrusselsEffectConclusion...............................................................................59 3. Determinants of the De Jure Brussels Effect........................................................................61 3.1.BlueprintAdoptionChannel...............................................................................................62 3.2.MultilateralismChannel......................................................................................................66 3.3.DeFactoEffectChannel.....................................................................................................67 3.4ConditionalityChannel........................................................................................................69 4. Appendix: Case Studies...........................................................................................................70 4.1.DataProtection.......................................................................................................................70 4.1.1.TheAnalogybetweenDataProtectionandAIRegulation.............................70 4.1.2.RegulatoryDiffusion.................................................................................................72 4.1.3.Conclusion..................................................................................................................76 4.2.ProductLiabilityDirective...................................................................................................76 4.2.1.RegulatoryDiffusion..................................................................................................77 4.2.2.ImpactsofEU-styleLiabilityLaw..........................................................................77 4.2.3.Conclusion.................................................................................................................78 4.3.ProductSafetyandCEMarking........................................................................................78 4.3.1TheEUProductSafetyFramework.......................................................................78 4.3.2.RegulatoryDiffusion................................................................................................79 4.3.3.Conclusion.................................................................................................................80 References.......................................................................................................................................81
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•11 1.1. The EU’s Upcoming  Regulatory Regime for AI Over the past two years, the European Commission (“the Commission” below) has proposed a number of updates and additions to  EU regulation5that will likely have significant  impact on the AI industry.6These include the AI  Act7(the primary focus of this report), updates  to the EU liability regime, the Digital Market Act  (DMA), and the Digital Services Act (DSA). The  Commission has not yet proposed liability updates. It may take 1–2 years before the AI Act  has been finalised in negotiations between the  Parliament and Council. The Digital Markets  Act and the Digital Services Act are both expected to be formally adopted in the summer  of 2022.  1.1.1. The Digital Market Act and the Digital  ServiceAct In December 2020, the Commission presented their proposed Digital Market Act and Di-gital Services Act.8These acts jointly seek to  rein in the power of big tech companies and  make digital markets more competitive.9They  are expected to be formally adopted in the  summer of 2022, following adoption by the  Parliament in July 2022.10 The DMA would prohibit some practices of  “gatekeeper” companies, such as self-preferencing their products in search results, and  would restrict gatekeepers’ ability to reuse  personal data across platforms. Most big  tech companies are expected to be considered gatekeepers.11Without removing or  amending existing EU competition law, the  DMA adds new rules which consider certain  actions unfair ex ante, before the fact. This is  a break with the current competition law regime which requires investigations into  whether there has been a breach of competition law after some potential breach has  been committed. The DMA will also require  companies to report upcoming mergers and  acquisitions to the Commission, though it  1.Introduction 5We speak of regulation to mean all regulatory instruments. Regulation is also one legal instrument of the EU, which is directly translated into  national law. In contrast, directives are legislative acts that set out the goals that all member states must achieve, while preserving the freedom of  member states to decide how to achieve those goals best. The AI Act is a proposed piece of regulation; other future legislation could be in the  form of a directive, e.g. for AI liability rules. 6A more thorough overview and history can be found in Mark Dempsey et al., “TransnationalDigitalGovernanceandItsImpactonArtificialIntelligence,” in The Oxford Handbook of AI Governance, ed. Justin Bullock et al. (Oxford University Press, May 19, 2022) 7European Commission, “Proposal for a Regulation of the European Parliament and of the Council Laying Down Harmonised Rules on Artificial  Intelligence(ArtificialIntelligenceAct)andAmendingCertainUnionLegislativeActsCOM/2021/206Final,” CELEX number: 52021PC0206, April  21, 2020 8European Commission, “ProposalforaRegulationoftheEuropeanParliamentandoftheCouncilonContestableandFairMarketsintheDigital  Sector (Digital Markets Act) COM/2020/842 Final,” CELEX number: 52020PC0842, December 15, 2020; European Commission, “Proposal for a  Regulation of the European Parliament and of the Council on a Single Market for Digital Services (Digital Services Act) and Amending Directive  2000/31/ECCOM/2020/825Final,” CELEX number: 52020PC0825, Dec,15,2020. 9Aline Blankertz and Julian Jaursch, “WhattheEuropeanDSAandDMAProposalsMeanforOnlinePlatforms,” Brookings, January 14, 2021. 10Both proposals were adopted by the European Parliament in July 2022. They are expected to be formally adopted by Council and published in  the EU Official Journal. European Parliament, “Digital Services: Landmark Rules Adopted for a Safer, Open Online Environment,” May 7, 2022;  European Parliament, “Digital Markets Act: EP Committee Endorses Agreement with Council,” May 16, 2022; European Parliament, “Digital ServicesAct:AgreementforaTransparentandSafeOnlineEnvironment,” April 23, 2022. 11“‘Gatekeeper’ platforms with a turnover of at least €6.5bn; activities in at least 3 EU countries; at least 45 million monthly active end-users and  10,000 yearly active business users (both in the EU); having met these thresholds in the last three years. Alternatively, an investigation can determine applicability.” Blankertz and Jaursch, “WhattheEuropeanDSAandDMAProposalsMeanforOnlinePlatforms.”
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•12 does not give the Commission new powers  to block them.  The DSA focuses specifically on content moderation on large platforms, mainly those with  more than 45 million EU users.12It will continue to be the case that platforms are not  sanctioned for having illegal content on their  websites, but there are new obligations to try  to find such content and to remove it if found.  The DSA will also include provisions requiring  companies to disclose some details of how  their content moderation algorithms work,  how they decide what content to remove, and  how advertisers are targeting users.  Though we focus on the AI Act and changes to  liability in this report, as these are directly  aimed at regulating AI systems, the impacts of  the DMA and DSA on the global AI industry  may be significant. Those acts could more significantly impact how big technology companies deploy AI systems in Europe than the AI Act  will. We encourage others to explore whether  the DMA and DSA would lead to a de facto  and/or de jure Brussels Effect as some have  suggested.13 We hypothesise that much of the DMA and  DSA will not have a strong de facto Brussels  Effect, as the costs of differentiation, e.g. implementing different pricing strategies in  different jurisdictions, might be low and because the benefits of behaviour in breach of  the proposed legislation may be significant.  However, there may be a significant de facto  effect with regard to mergers and acquisitions,  as the Commission has powers to block global  mergers if the merging parties have sufficient  turnover in the EU.14The disclosure requirements introduced by the DSA15could exhibit a de facto effect, so long as it does not require  disclosure of information that could be particularly detrimental to the company. For example,  if Google were to release their model for  search in full, that could make it possible to exploit the algorithm using search engine optimization to place one’s website high in the  search results without that website being what  the user is looking for. In such a situation,  Google might be forced to keep separate algorithms for EU and non-EU markets. There  might also be a significant de jure effect considering increasing interest among US legislators in updating US antitrust laws, including  proposals with new ex ante regulatory requirements for big tech companies, similar to the  DMA.16Further, the UK is currently considering  adopting a Digital Markets Bill, which shares  many features of the DMA.17 1.1.2.TheAIAct In April 2021, the EU Commission published  its AI Act (AIA) proposal.18It may take 1–2  years before the bill has been finalised in negotiations between the Parliament and  Council. The AI Act takes a risk-based approach, classifying AI systems as creating  unacceptable, high, limited, or minimal risk.  The level of risk is judged by the likelihood  that the system may harm specific individuals,19potentially violating their fundamental  rights. The requirements imposed on systems are related to the level of risk, ranging  from prohibitions to the voluntary adoption  of codes of conduct. The AIA proposes prohibitions on AI applications that pose “unacceptable risks”, including “real-time” remote  biometric identification systems used by governments. It requires conformity assessments for “high-risk” AI systems, such a s 12European Commission, “ProposalforaRegulationoftheEuropeanParliamentandoftheCouncilonaSingleMarketforDigitalServices(DigitalServices  Act)andAmendingDirective2000/31/ECCOM/2020/825Final.” 13Anu Bradford, “TheBrusselsEffectComesforBigTech,” December 17, 2020; Alex Engler, “TheEUAIActWillHaveGlobalImpact,butaLimitedBrussels  Effect,” Brookings, June 8, 2022. 14Anu Bradford, TheBrusselsEffect:HowtheEuropeanUnionRulestheWorld (Oxford University Press, 2020). 15See European Commission, “ProposalforaRegulationoftheEuropeanParliamentandoftheCouncilonaSingleMarketforDigitalServices(Digital  ServicesAct)andAmendingDirective2000/31/ECCOM/2020/825Final” , articles 13, 23, 24. 16Senate Republican Policy Committee, “BigTechGetsBigger,CallsforAntitrustChangesGetLouder,” Senate RPC, November 18, 2021. 17DCMS and BEIS, “ANewpro-CompetitionRegimeforDigitalMarkets-GovernmentResponsetoConsultation,CommandPaper:CP657,” May 6, 2022. 18AI Act. 19That is, it does not seek to mitigate small harms that afflict a large number of people. INTRODUCTION
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•13 some AI systems deployed in worker management, critical infrastructure operation,  border control, remote biometric identification, medical devices, machinery, and other  areas.20Certain limited-risk AI systems need  to comply with transparency rules, requiring  that users are made aware e.g. if they are engaging with AI-generated content that may  appear authentic such as chatbots or deepfakes. All other AI systems, termed “minimal  risk”, face no additional obligations, though  providers are encouraged to follow voluntary  codes of conduct. We summarise the proposed AI Act in Table 1 . The draft legislation builds on years of policy  efforts in the EU, including the Commission’s  AI Whitepaper in February 2020 and the  High-level expert group’s AI Ethics  Guidelines in April 2019.21The proposed AI  Act is expected to enter into force in a few  years after being negotiated and amended  by the European Parliament and the Council  of the European Union. The proposed AIA prohibits the following  uses of AI: (i) systems that deploy “subliminal  techniques” or use vulnerabilities of a specific  group22to materially distort their behaviour  such that they cause harm or are likely to do  so to themselves or other persons, (ii) the use  of “social scores” by public authorities or on  their behalf, and (iii) the use of ‘real-time’ remote biometric identification systems in publicly accessible spaces for the purpose of law  enforcement” with a small number of exceptions.23There is significant uncertainty about  how to interpret the ban on subliminal techniques, e.g. when a group’s vulnerability has  been used, and what level of harm to an indi-vidual is required.24Thus, it is not clear  whether recommender systems and algorithms used in social media news feeds  could be prohibited under the regulation.25 Such systems could avoid the prohibition because companies are not held liable for harm  caused by content on their platforms that has  been posted by others, but this is not yet  clear. Further, ambiguity on whether e.g. the  Google search algorithm would be considered manipulative would likely impose  large costs to tech companies, as these companies have already pointed out.26 The Commission’s proposal classifies some  AI systems as high-risk.27Producers of such  systems are obligated to go through a conformity assessment to ensure they comply  with certain standards before they are put on  the EU market. Systems identified as highrisk are firstly those that are safety components in or constitute products in domains that  are already covered by 12 EU product safety  regulations and that require third party conformity assessments. The full list is available  in Annex II, Section A, and most notably includes medical devices (including those for  in vitro diagnostics), toys, and machinery. For  these products, the AI Act proposes that existing product safety regulation be updated  such that it ensures compliance also with the  AI Act, to reduce regulatory complexity.28 There is also a list of seven additional product  safety regulations listed in Annex II, Section B,  covering e.g. aviation and cars, where the AI  Act introduces no new requirements for producers.29However, in the recitals accompanying the AI Act, the Commis sion suggests that  “the ex-ante essential requirements for highrisk AI systems set out in this proposal will INTRODUCTION 20See AI Act, annex II. When we refer to “high-risk” AI systems throughout this report, we simply refer to the Commission’s definition.  21European Commission, EthicsGuidelinesforTrustworthyAI (Publications Office of the European Union, 2019). 22Due to “their age, physical or mental disability.” 23AI Act, title II, art. 5. 24Michael Veale and Frederik Zuiderveen Borgesius, “DemystifyingtheDraftEUArtificialIntelligenceAct—AnalysingtheGood,theBad,andtheUnclear  ElementsoftheProposedApproach,” Computer Law Review International 22, no. 4 (August 1, 2021): 97–112. It has also been criticised for excluding forms  of manipulation. Dan Taylor, “Op-Ed:TheEU’sArtificialIntelligenceActDoesLittletoProtectDemocracy,” Tech.eu, March 14, 2022. 25Facebook, “ResponsetotheEuropeanCommission’sProposedAIAct,” August 6, 2021; Will Douglas Heaven, “ThisHasJustBecomeaBigWeekforAI  Regulation,” MIT T echnology Review, April 21, 2021. 26Facebook, “ResponsetotheEuropeanCommission’sProposedAIAct” ; Google, “Consultation on the EU AI Act Proposal,” July 15, 2021. 27AI Act, annex III(1). 28In addition to this, the Commission started a process of renewing the EU’s General Product Safety Regulation in June 2021. European Parliament,  “GeneralProductSafetyRegulation,” Legislative Train Schedule European Parliament, June 23, 2022; European Parliament, “2021/0170(COD),” 2021.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•14 INTRODUCTION have to be taken into account when adopting  relevant implementing or delegated legislation under those acts.”30 The AI Act lists additional high-risk uses of AI  in Annex III. This list includes remote biometric identification and categorisation, admission or grading in education, management  and operation of critical infrastructure, law  enforcement, and certain aspects of employment and worker management. The category  of AI used for “employment, worker management, and access to self-employment opportunities,” appears particularly sizable and  fast-growing:31it likely includes nearly all gig  economy companies, ranging from new ridehailing companies (e.g. Uber and Bolt) to the  collection of errant e-scooters (e.g. Bolt, Bird,  and Lime), delivery companies (e.g. Deliveroo, Foodora, and Just Eat), and various  other freelancing platforms (e.g. Fiverr,  Amazon Mechanical Turk, and TaskRabbit).  Further, it will likely apply to the growing industry of software for staff scheduling and  hiring, often referred to as workforce management.  Further, there will be many systems in the financial sector that determine “[a]ccess to and  enjoyment of essential private services … services and benefits.” Critical infrastructure systems include road traffic, gas, water, heating,  and electricity. Remote biometric identification does not seem to cover facial recognition  systems used in place of signatures,32though  it will likely apply to automatic tagging of photos by e.g. Google or Facebook. High-risk systems also include a number of government  uses of AI, including certai n uses in law enforcement, border control and migration, the  courts, and social benefit allocation.33For  more details, see Table 1 . 29AI Act, art. 2 §2. Though Article 84 will still apply, which refers to the EU Commission’s responsibilities to review and evaluate the AI Act at certain  intervals, Article 84 §7 suggests that such a review could result in the Commission recommending legislation be introduced to have the rest of the AI  Act’s requirements apply to these Old Approach product safety regulations.  30AI Act, recitals, 1.2.  31For example, the ride-hailing and food-delivery markets both garnered 150 million users in Europe in 2021 and are expected to see significant  growth in the coming few years. The food-delivery app market is estimated to grow by 10% annually. David Curry, “TaxiAppRevenueandUsage  Statistics (2022),” Business of Apps, November 10, 2020; David Curry, “Food Delivery App Revenue and Usage Statistics (2022),” Business of  Apps, October 29, 2020; Deloitte LLP, “DeliveringGrowth,” Deloitte United Kingdom, November 26, 2019, 8.  32European Commission, “Speech by Executive Vice-President Vestager at the Press Conference on Fostering a European Approach to Artificial  Intelligence,” April 21, 2021. 33For more, see AI Act, annex III.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•15 CATEGORY SCOPE REQUIREMENTS SANCTIONS Unacceptable Risk:Prohibited  (TitleII)·Subliminal techniques or exploiting  vulnerabilities of specific populations  which cause harm ·“Social scores” used by public authorities  or on their behalf ·Real-time remote biometrics in public  spaces used by law enforcement (with  some exceptions)These uses are prohibited. Fines up to 6% of global  revenue or 30mn euros,  whichever is higher High-Risk Systems: Conformity Assessment (TitleIII)AnnexII: ·AI systems that are products or safety  components of products covered by 12  product safety regulation regimes and that  require third party conformity assessments,  including medical devices (including for in  vitro diagnostics), toys, and machinery. AnnexIII: ·Remote biometric identification and  categorisation of natural persons (e.g. a  system classifying the number of people of  different skin tones walking down a street) ·Management and operation of critical  infrastructure (road traffic and the supply of  water , gas, heating, and electricity) ·Education and vocational training, where  systems are used for e.g. admission and  grading ·Employment, worker management, and  access to self-employment opportunities,  including systems that make or inform  decisions about hiring, firing, and task  allocation ·Access to and enjoyment of essential  private services and public services and  benefits ·Specific uses of law enforcement ·Specific uses in migration, asylum, and  border control management ·Administration of justice and democratic  processes, in particular when used to  research and establish facts or applying the  law to some factsProviders of high-risk  systems must perform a  conformity assessment to  make sure that they are  compliant with requirements  including: ·Risk management system ·Data requirements ·T echnical documentation ·Record-keeping ·T ransparency on the  system’s functioning ·Human oversight ·Accuracy, robustness, and  cybersecurity ·Post-market monitoringFines up to 4% of  global revenue or  20mn euros,  whichever is higher,  for everything except  the data requirements,  where the same fines  apply as for the  prohibited systems LimitedRisk: Transparency Obligations (TitleIV)·AI systems interacting with natural persons ·Emotion recognition systems or biometric  categorisation systems ·AI system that generates or manipulates  image, audio, or video content that appears  realNotify the user that they  are engaging with an AI  systemFines up to 4% of global  revenue or 20mn euros,  whichever is higher MinimalRisk: Voluntary Codesof Conduct (TitleIX)All AI systems that are not either  prohibited or high- riskProviders can choose to  comply with voluntary  codes of conduct. The  Commission and Member  States will encourage the  creation and voluntary  compliance with these  codes.Not applicable as there  are no requirements. 34Inspired by the graphic in Eve Gaumond, “ArtificialIntelligenceAct:WhatIstheEuropeanApproachforAI?,” Lawfare, June 4, 2021.Table 1: A summary of the EU Commission’s proposed AI Act.34
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•16 INTRODUCTION 35AI Act, art. 73.  36Other notable clauses state “Human oversight shall aim at preventing or minimising the risks to health, safety or fundamental rights that may emerge  when a high-risk AI system is used in accordance with its intended purpose or under conditions of reasonably foreseeable misuse, in particular when  such risks persist notwithstanding the application of other requirements set out in this Chapter” as well as the individual overseeing the system’s  functioning being “able to intervene on the operation of the high-risk AI system or interrupt the system through a ‘stop’ button or a similar procedure.” 37AI Act, title III, chapter 2. 38However, Veale and Borgesius argue that the transparency obligation may be unenforceable. Market surveillance authorities will struggle to find the  undisclosed deepfakes, especially if there are limited routes for citizens to file complaints. Veale and Borgesius, “DemystifyingtheDraftEUArtificial  IntelligenceAct—AnalysingtheGood,theBad,andtheUnclearElementsoftheProposedApproach.” See also AI Act, title IV. 39AI Act, art. 71ing deployers to inform users if their system  (i) interacts with humans, (ii) is used to detect  emotions or determine association with (social) categories based on biometric data, or  (iii) generates or manipulates content, e.g.  deepfakes or chatbots.38 All other AI systems, termed “minimal risk”,  face no additional obligations, though providers are encouraged to follow voluntary  codes of conduct. The proposed AI Act tasks  the Commission and member states with encouraging and facilitating the drawing up of  voluntary codes of conduct. The AI Act includes clauses to promote compliance. Member states are, according to the  AI Act, obligated to designate or create market surveillance authorities (MSAs) to oversee  and ensure the implementation of the regulation, with significant powers to request information from providers of AI systems. Noncompliance with the AI Act would come with  significant fines. Breaching the prohibitions or  the data governance requirements for highrisk systems can produce fines of up to 30 million euros or 6% of global annual turnover,  whichever is higher. Non-compliance with all  other requirements in the AI Act may have the  actor incur up to 20 million euros or 4% of  global annual turnover, whichever is higher.39 RegulatoryCostsoftheAIAct Though it is exceedingly difficult to predict  the costs imposed by new regulation, there  have been attempts to estimate them.  These regulatory costs consist of compliance costs, which are those associated  with meeting the requirements, and verification costs, those associated with being  able to evidence compliance. The list of high-risk AI systems can be updated over time. The EU Commission can add  additional uses to the list in Annex II, so long  as they are under the eight categories outlined in the annex (e.g. education, law enforcement, and biometric identification) and  the use poses similar risks to the uses currently on the list.35 In the Commission’s proposed AI Act, producers of high-risk AI systems have to comply  with specific standards and procedures before putting the products on the EU market,  after which they must add the CE mark to  their product. Producers of high-risk systems  would be required to have a risk management system that includes identifying and  analysing risks, post-market monitoring, implementing suitable risk management  measures, and communicating residual  risks to users. Moreover, producers are required to eliminate or reduce risks through  adequate product design and development.  In addition, they need to conform to requirements for data governance, technical documentation, and record-keeping. Producers  should also integrate human oversight into  their products, such as with human-machine  interface tools, for example to ensure that  individuals overseeing the system “fully understand the capacities and limitations of  the high-risk AI system and be able to duly  monitor its operation”.36Finally, the AI Act  proposes requirements for accuracy, robustness, and cybersecurity of AI systems.  This includes both resilience to errors and  to attempts by unauthorised parties to alter  the system’s use or performance by exploiting vulnerabilitie s, including via data poisoning, adversarial examples, or model flaws.37 For “limited-risk” systems, the Commission’s  proposed AI Act includes provisions requir-
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•17 INTRODUCTION 40AI Act, art. 10 (3). Microsoft, Google, Facebook, and DeepMind (part of Google) maintained in their submissions to the EU AI Act consultation that in  certain cases this data requirement is unnecessary, and in others, impossible. 41AI Act, recitals, 44 42La Présidence Française du Conseil de l’Union européenne, “PropositiondeRèglementDuParlementEuropéenetDuConseilétablissantDesRègles  HarmoniséesConcernantL’intelligenceArtificielle(législationSurL’intelligenceArtificielle)etModifiantCertainsActesLégislatifsdel’Union-Textede  CompromisdeLaPrésidence-Articles16-29.” 43 European Commission, “Commission Staff Working Document Impact Assessment Accompanying the Proposal for a Regulation of the European  ParliamentandoftheCouncilLayingDownHarmonisedRulesonArtificialIntelligence(ArtificialIntelligenceAct)andAmendingCertainUnionLegislativeActsSWD/2021/84Final,” CELEX number: 52021SC0084, April 21, 2021, 67–70. 44European Commission, 66. 45 See European Commission, “CommissionStaffWorkingDocumentImpactAssessmentAccompanyingtheProposalforaRegulationoftheEuropean  ParliamentandoftheCouncilLayingDownHarmonisedRulesonArtificialIntelligence(ArtificialIntelligenceAct)andAmendingCertainUnionLegislativeActsSWD/2021/84Final.” 46 Andrea Renda et al., “StudytoSupportanImpactAssessmentofRegulatoryRequirementsforArtificialIntelligenceinEuropeFinalReport(D5)” (Luxembourg: European Commission, April 2021), Chapter 4. 47 See European Commission, “CommissionStaffWorkingDocumentImpactAssessmentAccompanyingtheProposalforaRegulationoftheEuropean  ParliamentandoftheCouncilLayingDownHarmonisedRulesonArtificialIntelligence(ArtificialIntelligenceAct)andAmendingCertainUnionLegislativeActsSWD/2021/84Final.” The Inception Impact Assessment from June 2021 also clearly communicates these aims.of the requirements are already being complied with.44Further, these costs could fall  over time because a significant proportion  of the compliance and verifications costs  will only be paid once.45They could also be  reduced further if the AI Act reduces the  net regulatory complexity of deploying AI  systems, which are already regulated by  existing rules that may be overlapping or  otherwise inappropriate for AI systems. The total cost could also be higher than the  Commission’s estimate. First, these estimates  only focus on the cost imposed on high-risk AI  systems, excluding regulatory costs as a result of voluntary codes of conduct and transparency requirements for e.g. chatbots. However, one might reason that the voluntary  codes will only be followed should it look like  a sound business decision and that the transparency requirements will impose small costs.  Second, the study commissioned by the Commission before the draft AI Act was released  finds higher regulatory costs of up to 17% of  high-risk systems’ development costs.46 1.1.3.UpdatedLiabilityRules In addition to the AI Act, the Commission  seeks to adopt liability rules for AI products.  In 2021, the Commission stated its intention  to propose regulation either via an update  of the Product Liability Directive (PLD) or by  separately harmonising aspects of the national civil liability framework regarding certain AI systems in the first quarter of 2022.47While the EU hopes to reduce the regulatory  costs of operating AI systems in the EU, the  AI Act, in the form suggested by the EU Commission, could be costly. For example, many  commentators have pointed to the impracticability of Article 10§3, which states that “training, validation and testing data sets shall be  relevant, representative, free of errors and  complete.”40Meeting such a requirement  could be incredibly costly as it is nearly impossible to ensure that a dataset is free of errors or complete. No dataset is perfect. However, there are indications that this  requirement will be different in the final bill.  The recitals that accompanied and contextualised the EU Commission’s draft AI Act include a weaker, more practicable version of  the statute: “Training, validation and testing  data sets shouldbesufficientlyrelevant, representative and free of errors and complete  in view of the intended purpose of the system” [our emphasis].41Further, the French  presidency of the EU Council proposed  changes to the AI Act in early 2022, wherein  datasets would need only be e.g. free of errors “to the best extent possible.”42 The Commission’s impact assessment estimates that the AI Act would impose additional regulatory costs of 6–10% to investments in developing high-risk AI systems  (including the cost of verifying compliance),43suggesting that prices for EU  products may rise by the same amount.  The Commission says this represents the  “theoretical maximum costs” imposed on  high-risk systems, as it assumes that none 
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•18 1.2. Will We See a Brussels  Effect for the EU AI Regulatory  Regime? Having described the contours of the upcoming EU regulation of AI above, we now  summarise the mechanisms that may lead to  de facto and de jure Brussels Effects, and  their plausibility for upcoming EU AI regulation.  Some clarifications could be helpful at this  point. Throughout the report, we use “Brussels Effect” to simply refer to regulatory diffusion from the European Union. We do not  limit our discussion to diffusion that occurs  solely due to market forces. We also do not  treat regulatory diffusion as an all-or-nothing  phenomenon – we allow for degrees of diffusion. Further, we focus primarily on the EU  Commission’s April 2021 proposed AI Act.  For the most part, we do not consider  whether proposed amendments from the EU  Parliament and Council to the Commission’s  draft may differ in their propensity for a Brussels Effect. Further, we do not look closely at  the chance of a Brussels Effect from the recently passed Digital Services Act and Digital  Markets Act. We encourage others to pursue  that work, in particular as these bills could  have a large impact on how some of the  world’s most widely interacted with AI systems are developed and deployed.48 We also contribute to the conceptual understanding of the drivers of regulatory diffusion. While similar factors of the Brussels  Effect have been introduced in Bradford  (2020), we either generalise or disentangle  each of Bradford’s factors into 2–4 components.491.2.1.DeFactoBrusselsEffect A de facto Brussels Effect occurs when companies voluntarily comply with EU regulation  in non-EU jurisdictions without those jurisdictions requiring it. As with all jurisdictions,  when the EU introduces new rules, multinational companies face two decisions. First,  they must decide whether to remain in the  EU market. New regulation could sufficiently  reduce the market size and profit margins to  make operating in the EU market unprofitable. Second, assuming firms stay in the EU  market, they must decide whether to comply  with the new regulation internationally or  offer two different products: one EU-compliant and one non-EU-compliant.50We use the  term “differentiation” to refer to offering  different products for different jurisdictions,  and “non-differentiation” for offering an EUcompliant product outside the EU. A de facto  Brussels Effect has occurred if firms stay in  the EU market and sell EU-compliant  products worldwide (see Figure 1 ).51Note  that throughout the report, we refer to  products and services simply as products. This section summarises section 2 of this report, describing the mechanisms by which a  de facto Brussels Effect can occur and our  high-level conclusions on its plausibility with  regard to the EU’s forthcoming regulatory regime. INTRODUCTION 48As discussed in Engler, “TheEUAIActWillHaveGlobalImpact,butaLimitedBrusselsEffect.” 49See also the introduction of section 2 for more detail. 50Though note that these two decisions will in reality be made at the same time. Firms need not prefer both differentiation and non-differentiation to  leaving in order to choose to stay in the market. 51Technically, multinational companies are also a requirement for a de facto Brussels Effect (§2.1.2). If all firms in the industry only sell nationally, which is,  for instance, the predominant case in the metal industry, a de facto Brussels Effect will never occur. For the particular example of the metal industry and  regulation – wherein the local industry did not exhibit a de facto Brussels Effect. David Hanson, CEMarking,ProductStandardsandWorldTrade (Edward  Elgar, 2005),
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•19 Figure 1: De facto Brussels Effect decision tree. A de facto Brussels Effect occurs when (i) the EU puts in place  legislation that is more stringent than other jurisdictions, (ii) the company decides to stay in the EU market, and (iii)  decides to adopt the regulation outside the EU.  Buildingon52Anu Bradford’s 2020 book The  Brussels Effect53and 2012 paper by the  same name,54we consider five determining  factors of the de facto Brussels Effect: (i) Favourablemarketproperties – The larger  the absolute EU market, the more likely  companies will stay in the market despite  the legislation. The larger the relative EU  market, the more likely companies will sell  EU-compliant rather than non-EU-compliant products outside the EU. The more the  market is oligopolistic and consists of multinational firms, the more likely is de facto  regulatory diffusion. (See section 2.1 .) (ii) Stringency – The EU regulation must be  more stringent than other jurisdictions’  regulations, at least on some dimensions,  for the de facto Brussel Effect to occur.  (See section 2.2. ) (iii) Regulatorycapacity – This concerns a jurisdiction’s expertise and capacity to produce well-crafted legislation, ideally earlier  than other jurisdictions, and to sanction  non-compliance. Well-crafted legislation  lowers the regulatory costs and increases  the likelihood that companies comply with  the regulation and that customers value  EU-compliant products, while ideally meeting the same regulatory goals. We refer to  the sum of compliance and verification  costs as regulatory costs, where compli-ance costs are those associated with meeting the requirements of the regulation and  verification costs are those associated with  showing and documenting that this is the  case. ( See section 2.3. ) (iv) InelasticitywithinandoutsidetheEU – Demand and supply, both within and outside  the EU, need to be relatively inelastic, such  that the market size does not shrink in response to the regulation, e.g. due to negative changes to price, cost, or quality resulting from the new regulation. Low elasticity  within the EU in response to the new rules  increases the chance of companies remaining in the EU, while low elasticity outside the EU in response to EU-compliant  products increases the chance of nondifferentiation. ( See section 2.4. ) (v) Costs of differentiation – The costs of  differentiation being higher than those of  non-differentiation increases the likelihood of a de facto effect. It can be more  costly to choose differentiation – maintaining both EU-compliant and non-EUcompliant products – as it might come  with higher fixed and variable regulatory  costs, and duplication costs associated  with maintaining two separate products  rather than one. ( See section 2.5. ) We argue in section 2.6 that a de facto Brussels Effect for at least some of the EU’s AI  52We summarise how our proposed framework differs from Bradford’s in section 2 . 53Bradford, TheBrusselsEffect:HowtheEuropeanUnionRulestheWorld. 54Anu Bradford, “TheBrusselsEffect,” Northwestern University Law Review 107 (Northwestern University School of Law, 2012).YESYES EUlegislationis  passedDoesthefirm stayintheEU market?Doesthefirm offerEUcompliant productsoutside theEU?DefactoBrussels Effect/Nondifferentiation Differentiation: Non-EU-compliant productsoffered abroadFirmleavesthe EUmarketNONO
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•20 INTRODUCTION regulation is likely. High-risk systems deployed  by multinational companies seem particularly  likely to see a de facto effect. These systems  include those used in products covered by existing EU product safety regulation such as machinery and medical technology.55They could  also include systems used for worker management and hiring, remote biometric identification systems, and legal tech, especially if compliance with EU requirements becomes seen  as a strong signal of product trustworthiness.  Foundation models could see a de facto effect  if it turns out to be difficult to comply with the  regulation without making fundamental  changes to those systems and if the market for  high-risk systems grows significantly. A de  facto effect is more likely for some requirements of high-risk systems, such as those regarding setting up risk management systems,  record-keeping, and making the system’s functioning sufficiently transparent, as well as accuracy, robustness, and cybersecurity requirements.  Transparency requirements, such as for e.g.  AI systems producing content that may appear authentic, could see a de facto effect, as  extending compliance beyond the EU would  likely be cheap and because customers might  appreciate the transparency. On the other  hand, the cost of differentiation is likely to be  low. The AI Act’s prohibitions are unlikely to  see a de facto effect, though they could have  a weak effect by changing norms in other jurisdictions about the acceptability of such systems. 1.2.2. De Jure Brussels Effect There is a de jure Brussels Effect if foreign  jurisdictions adopt rules influenced by EU  regulation. We analyse four channels for the  diffusion of EU AI regulation.1.BlueprintAdoptionChannel – Foreign jurisdictions adopt the EU regulation voluntarily as they  believe the legislation will meet their regulatory  goals. This may be because of imitation before  the results of the regulation are known, e.g. because EU regulations are usually well-crafted  due to the EU’s regulatory expertise and capacity, or it could be a result of learning, with nonEU jurisdictions adopting the regulation once  positive results are seen. ( See section 3.1. ) 2. Multilateralism Channel – The EU promotes its regulation in multilateral and bilateral negotiations and institutions. For instance, EU product safety standards are  regularly promoted in and influence work at  the International Organization for Standardization (ISO).56 (See section 3.2. ) 3. DeFactoChannel – Subjected to a de facto  Brussels Effect, multinational companies may  be put at a disadvantage in non-EU markets  compared to national companies operating  only in the non-EU market. Therefore, multinational companies are incentivised to lobby legislators in non-EU jurisdictions to adopt EUequivalent standards. For such jurisdictions,  the cost of adopting such standards is also  lower, as some companies are already complying with them. ( See section 3.3. ) 4. ConditionalityChannel – EU trade requirements, extraterritoriality (that is, when the  legal power of a jurisdiction is extended beyond its territorial boundaries), and economic  pressure encourage other countries to adopt  EU-equivalent regulation. ( See section 3.4. ) The BlueprintAdoptionChannel is plausible for  AI because of the EU’s first mover advantage,  the Commission’s active promotion of their AI  regulation,57and the diffusion o f the EU’s AI  policy narrative over the last three years.58This  channel seems most likely to impact jurisdic55Listed in AI Act, annex II. 56Reasons cited are the first mover advantage. Moreover, the outsized influence in health and safety standards might also come from the more hierarchical  regulatory structure of the EU compared to the US. Abraham L. Newman and Elliot Posner, “PuttingtheEUinItsPlace:PolicyStrategiesandtheGlobal  RegulatoryContext,” Journal of European Public Policy 22, no. 9 (October 21, 2015): 1316–1335. See for instance: Deborah Hairston, “Hunting for Harmony in Pharmaceutical Standards,” Chemical Engineering 104, no. 20 (1997); Annika Björkdahl et al., eds., ImportingEUNormsConceptualFramework  andEmpiricalFindings,vol.8, United Nations University Series on Regionalism 8 (Springer International Publishing, 2015), 122. 57This includes the “International Alliance on Trustworthy AI”. However, it might be too early to evaluate the extent of the Commission’s promotion. 58See AccessNow report: Daniel Leufer and Laureline Lemoine, “Europe’s Approach to Artificial Intelligence: How AI Strategy Is Evolving” (accessnow,  December 2020). Note however that it is difficult to distinguish between the EU regulation causing other jurisdictions to adopt EU-esque regulation from  the EU and the other jurisdictions simply responding to the same regulatory need. 
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•21 INTRODUCTION on the Chinese state’s uses of AI e.g. for surveillance of its citizens.  Perhaps the most important de jure effect via  the Blueprint Channel would be if the AI Act  sets the global gold standard for what requirements a responsible developer and deployer  of risky AI systems ought to fulfil. These requirements seem likely to inspire other jurisdictions, even if they choose to define the riskiness of systems differently.  Upcoming EU AI regulation also comprises updates to the liability regime. A de jure Brussels  Effect of the Product Liability Directive (PLD)  (1985) reached more than a dozen countries  through the Blueprint Adoption Channel ( appendix 4.2 ). At the same time, the PLD did not  lead to significant litigation cases in the EU.  Hence, the de jure Brussels Effect of product  liability could see limited real-world effects. The MultilateralismChannel is plausible since  the EU has historically influenced standard  setting bodies, such as the ISO. The ISO sets  and seeks to set AI product safety standards.63Moreover, bilateral coordination on  technology policy, such as via the US-EU  Trade and Technology Council,64make such  de jure regulatory diffusion more likely. Taken  together, the US and the EU constitute more  than 50% of the AI market’s spending.65 Hence, they could more effectively push for  their respective AI regulatory agendas if they  cooperate effectively. On the other hand,  there has bee n an increase in engagement  with international standard s etting efforts for  AI from China and the US.66tions smaller than the US and China for which  compatibility with EU regulation is particularly  important and where there are no large domestic AI companies to oppose the measures. A  de jure Brussels Effect reaching the US federal  level seems much less likely. Historically, there  have been few instances of a de jure Brussels  Effect reaching the US via this channel.59However, it does seem plausible that we will see  some regulatory diffusion to US states – notably  California, which has adopted data protection  laws similar to the GDPR – which could affect future regulation at the federal level.  A de jure Brussels Effect reaching China via this  channel is plausible due to the country’s extensive history of adapting regulatory blueprints from the EU and United States, though  it might be less likely because the Chinese  government is starting to adopt regulation for  certain AI applications. Chinese legal documents often reference EU regulation. For instance, data protection legislation; the RoHS  directive, which manages hazardous substances; the labelling schemes for genetically  modified foods; energy regulation; and the  chemical regulation REACH have been used  as blueprints for Chinese law.60In 2021, China  adopted the Personal Information P rotection  Law, which provides GDPR-like protections for  citizens against private corporations.61However, Chinese regulators have recently  charged ahead in some domains, regulating AI  sooner and more stringently than the EU is  likely to with regard to recommender systems  and potentially systems that generate content.62Further, de jure regulatory diffusion to  China is likely to be lim ited to regulation of  private companies, and is unlikely to infringe  59Bradford, The Brussels Effect: How the European Union Rules the World; Joanne Scott, “ExtraterritorialityandTerritorialExtensioninEULaw,” The  American Journal of Comparative Law 62, no. 1 (January 1, 2014): 87–126; David Vogel, ThePoliticsofPrecaution:RegulatingHealth,Safety,and  EnvironmentalRisksinEuropeandtheUnitedStates,FocusonClimate (Princeton University Press, 2012). 60See Bradford chapter 5 page 153 for the GDPR; chapter 7 page 225 for the RoHS directive; page 180 for the GMO labelling; page 201, 203 for the  chemical regulation REACH; some toy safety standards page 204; China’s 2008 Anti-Monopoly Law (page 117 and 118); merger rules page 118.  Bradford, TheBrusselsEffect: How the European Union Rules the World. For more, see also sections 3.1.and 4.2. 61Though note that it does not afford any protection against state uses of personal data. Lomas, “ChinaPassesDataProtectionLaw.” 62Jeffrey Ding, “ChinAI#168:AroundtheHorn(edition6),” ChinAI Newsletter, January 9, 2022; Jeffrey Ding, “ChinAI #182: China’sRegulationson  RecommendationAlgorithms,” ChinAI Newsletter, May 9, 2022; Helen Toner, Rogier Creemers, and Graham Webster, “Translation:InternetInformationServiceAlgorithmicRecommendationManagementProvisions(DraftforComment)–Aug.2021,” DigiChina, August 27, 2021. 63ISO, “ISO/IECJTC1/SC42” ; ISO, “StandardsbyISO/IECJTC1/SC42:ArtificialIntelligence.” 64European Commission, “EU-USLaunchTradeandTechnologyCounciltoLeadValues-BasedGlobalDigitalTransformation,” European Commission  - Press release, June 15, 2022. 65Christie Lawrence and Sean Cordey, “ TheCaseforIncreasedTransatlanticCooperationonArtificialIntelligence,” ed. Lauren Zabierek and Julia Voo  (The Cyber Project, Belfer Center for Science and International Affairs Harvard Kennedy School, August 2020),  66For the US, see for instance: “U.S. Executive Order on Maintaining American Leadership in Artificial Intelligence” which defines international standards  as one of the priorities.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•22 INTRODUCTION 67See section 3.3 of this report. Birdsall and Wheeler discuss the de facto to de jure regulatory diffusion leading to de jure diffusion of US pollution standards to South American and other developing countries. Nancy Birdsall and David Wheeler, “Trade Policy and Industrial Pollution in Latin America:  WhereArethePollutionHavens?,”JournalofEnvironment&Development2,no.1 (January 1993): 137–49. Perkins and Neumayer find evidence for the  hypothesis that the countries that have more transnational corporations and more imports are more likely to have stricter automobile emission standards.  Richard Perkins and Eric Neumayer, “Doesthe‘CaliforniaEffect’OperateacrossBorders?Trading-andInvesting-upinAutomobileEmissionStandards,”  JournalofEuropeanPublicPolicy19,no.2 (March 1, 2012): 217–37. For other US environmental standards influencing non-US countries see: Elizabeth R.  DeSombre, “TheExperienceoftheMontrealProtocol:ParticularlyRemarkable,andRemarkablyParticular,”UCLAJournalofEnvironmentalLawand  Policy19,no.1 (2000). For Mexico and Brazil in particular see: Ronie Garcia-Johnson, ExportingEnvironmentalism:U.S.MultinationalChemicalCorporationsinBrazilandMexico,GlobalEnvironmentalAccord:StrategiesforSustainabilityandInstitutionalInnovation (MIT Press, 2000). 68European Commission, “EMAS – Environment,” June 14, 2016; Walter Mattli and Ngaire Woods, “In Whose Benefit? Explaining Regulatory Change in  GlobalPolitics,” in The Politics of Global Regulation (Princeton University Press, 2009), 1–43. Also see the discussion in Bradford, “TheBrusselsEffect.” 69David Vogel, Trading Up: Consumer and Environmental Regulation in a Global Economy (Harvard University Press, 1995); David Vogel, California  Greenin’: HowtheGoldenStateBecameanEnvironmentalLeader, Princeton Studies in American Politics: Historical, International, and Comparative  Perspectives (Princeton University Press, 2018). 70Note that the AI Act exhibits some extraterritoriality. A producer would fall under the scope of the regulation if they were producing an AI system  whose output is used in the EU, as would a user of an AI system whose output is used in the EU. Graham Greenleaf, “The‘BrusselsEffect’ of the EU’s  ‘AI Act’ on Data Privacy Outside Europe,” 171PrivacyLaws&BusinessInternationalReport1 , June 7, 2021.The De Facto Channe l of the de jure Brussels Effect is contingent on a de facto Brussels Effect. If this condition is fulfilled, one  would expect multinational AI companies to  lobby other jurisdictions to pass EU-like AI  regulation, as the AI industry is relatively  large and has an oligopolistic structure. For  example, since the GDPR’s passage, we  have seen some big tech companies arguing  that the US needs a federal equivalent. However, it is unclear how successful such lobbying efforts would be. While the De Facto  Channel is common for US and Californian  regulation,67it has only been demonstrated  for a single EU regulation: the Eco-Management and Auditing Scheme (EMAS).68 Perhaps the most likely route by which this  channel could lead to an effect on US federal AI regulation is if US states start adopting EU-like regulation, which in turn incentivises US companies to lobby the  government to adopt similar regulation, as  has been seen with a lot of environmental  regulation in the US.69 The Conditionality Channel is currently implausible because EU AI legislation would  likely not comprise a high degree of extraterritoriality, e.g. through equivalency clauses.70 1.2.3.WillThereBeaBrusselsEffectforthe  AIAct? In this report, we suggest that there is likely  to be a de facto Brussels Effect for parts of  the AI Act. Prohibitions are generally unlikely  to create a de facto Brussels Effect, as they  aim to remove certain products from the EU  market. However, there is some chance that the prohibitions on manipulation, e.g. subliminal techniques, could produce a Brussels  Effect if recommendation algorithms used by  social media companies risk being classified  as manipulative or if such bans increase the  reputational costs to offer EU-prohibited  products abroad. Transparency obligations  will likely only produce a very weak de facto  effect as compliance might only require surface-level changes to the product for EU customers, such as adding a disclaimer at the  start of a conversation with a chatbot. However, a de facto effect might occur if such disclaimers become seen as a signal of a highquality, trustworthy product. For high-risk  systems, the requirements that have low  variable costs, that increase perceived  product quality, and that may require early  forking of systems are more likely to see a de  facto Brussels Effect. Specifically, we are  most likely to see a de facto effect with regard to products under certain existing  product safety regulation, worker management systems (e.g. those used by the gig  economy and logistics companies), potentially for general or foundational AI systems,  and in remote biometric identification and  categorisation systems and legal technology. It is even more difficult to assess the likelihood of a de jure effect. We are unclear  about the international impacts of the prohibitions and transparency obligations. However, we do think that perhaps the most important impact of the AI Act will be in the  design of the conformity assessments, which  may set the gold standard for regulation and  standards in the EU and beyond. Our conclusions are summarised in Table 2 and explained in greater detail in sections 3and 4.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•23 REQUIREMENT DE FACTO DE JURE Manipulation Perhaps, if e.g. recommendation  algorithms are considered plausibly  manipulative and if foundational  adjustments to such are needed to  avoid manipulative behaviour.Unclear; depends on to what  extent the EU exports its narrative. Socialcreditscores Likely not, as the requirements apply  primarily to governments. However , it could  increase the reputational cost of offering  such products in other jurisdictions.Unclear; depends on to what  extent the EU exports its narrative. Real-timebiometrics Likely not, as the requirements apply  primarily to governments. However , it could  increase the reputational cost of offering  such products in other jurisdictions.Unclear; depends on to what  extent the EU exports its narrative. Productsalreadycoveredby someproductsafetyrules, includingmedicaldevices, toys,andmachineryLikely to see a de facto effect as long as  the requirements are new. The requirements laid out in the  regulation might have a de jure  Brussels Effect. This could plausibly  be the most important impact of  the regulation.Largelyregionalor governmentusesofAI, includingincritical infrastructure,education,the financialsector,andlaw enforcementLikely not, as these uses are  regionalised. Could change if the  provision of these systems becomes  globalised or if the EU requirements  become seen as the gold standard. Workermanagement, includinghiring,firing,and taskallocationPlausibly, though it largely depends on  the extent to which the EU requirements  are perceived as a net quality benefit  and how regionalised the industry is. Remotebiometric identification/categorisation systemsand“legaltech”Perhaps, if the EU’s requirements become  seen as the gold standard in these more  contentious applications of AI. GeneralAIsystemsand foundationmodels,which couldbeusedinhigh-risk applicationsLikely for some, though it depends on  e.g. how large the market for high-risk AI  uses becomes, whether general  purpose AI systems will be covered by  the AI Act, and whether compliance  requires early forking, e.g. differences in  the systems’ pre-training. Transparencyobligations Likely for some, though strength will  depend on the extent to which  disclosures are seen as quality signals.Unclear; depends on to what  extent the EU exports its narrative  and the extent to which California’s  Bot Disclosure Act is more causally  responsible for the diffusion. Table 2: A summary of our conclusions on the likelihood of a Brussels Effect from various parts of the proposed AI Act. Deeper  blues indicate that we think a Brussels Effect is likely.  PROHIBITIONS CONFORMITY 
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•24 INTRODUCTION 71Interestingly, from the 1960s to the 1990s, the US adopted more stringent regulation than the EU. Vogel, ThePoliticsofPrecaution:RegulatingHealth,  Safety,andEnvironmentalRisksinEuropeandtheUnitedStates pp. 4-6. 72Mario Damen, “TheEuropeanUnionandItsTradePartners,” Fact Sheets on the European Union (European Parliament, September 2021). However,  in the case of digital technology trade, the US and the EU are aiming to foster their bilateral trade. See the Tech Alliance. Global Times, “ChinaReplacesUStoBecomeLargestTradePartnerofEU,” December 4, 2020; European Commission, “EU-US Launch Trade and Technology Council to Lead  Values-Based Global Digital Transformation.” 73“In 2019, U.S. exports of information and communications technology (ICT) services to the EU was $31 billion, with potentially ICT-enabled services  adding another $196 billion.” Rachel F. Fefer, “EU Digital Policy and International Trade,” R46732 (Congressional Research Service, March 25, 2021). 74For more, see Bradford, TheBrusselsEffect:HowtheEuropeanUnionRulestheWorld. 75Engler also discusses the effect of the AI Act on the US. Engler, “TheEUAIActWillHaveGlobalImpact,butaLimitedBrusselsEffect.” 76Chinese exports to the EU consist more of physical products than software. 77Huawei and Lenovo operate outside China, and there are Western companies (like Apple) that operate in the Chinese market. Chinese ByteDance  offers TikTok outside of China, with supposedly separated businesses and technology.1.3. What About China and the  US? The EU has successfully exported different  regulatory standards to less geopolitically  powerful jurisdictions in the past, including  states in Africa, Oceania, Latin America, and  Asia. These countries have less regulatory  capacity and international bargaining power  relative to the EU. However, to evaluate the  impact of EU regulation on the global AI industry, it is essential to know whether EU  regulation diffuses to the advanced and  prosperous nations that dominate the AI industry and AI sales market, especially China  and the United States.  The United States will most likely not adopt  more stringent AI regulations than the EU (for  more information, see section 2.2. ). Since  about the 1990s, US regulation on harms  from business to citizens has become less  stringent than EU regulation.71However,  there could be a de jure effect spreading to  US states such as California, which has  already adopted GDPR-like regulation.  Should a sufficient number of US states adopt EU-esque regulation, it could diffuse to  the federal level via a de facto channel.  China may adopt AI regulation that is more  stringent than that of the EU. Indeed, in early  2022 it adopted regulation with regard to recommender systems and proposed regulation for AI systems that generate content in  early 2022. This regulation shares many features with the EU’s Digital Services Act, Digital Markets Act, and the forthcoming AI Act  but goes beyond the EU in some respects.  Overall, we expect the Chinese Communist  Party to regulate its technology sector more severely than the EU, but it will be unwilling  to rein in government use of AI. We may still  see a de jure Brussels Effect with regard to  domains where the EU is regulating first or  by Chinese regulators using the EU requirements for high-risk systems as a blueprint. Until 2020, the US was the EU’s biggest trading partner before being overtaken by  China.72This means that many firms are operating in both the EU market and the US or  Chinese market, making a de facto Brussels  Effect possible.  Because of the significant EU-US trade in digital technology, with many multinationals  serving both markets,73the probability of a de  facto Brussels Effect for the United States increases. Historically, various EU legislative  efforts have exhibited some measure of a de  facto Brussels Effect on the US, including the  Data Protection Directive (DPD), the GDPR,  the chemical regulation REACH, toy safety  standards, and the EU Code of Conduct regarding online hate speech.74However, the  US has demonstrated that it can selectively  resist or avoid EU regulation. For instance, the  Safe Harbor Agreement helped the US avoid  some GDPR requirements (for more information, see the appendix section 4.1 ).75 A de facto AI Brussels Effect reaching China  is less likely since the dominant Chinese  technology companies mostly do not operate outside China76and the ones that do  tend to already have differentiated  products.77
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•25 INTRODUCTION 78For a more detailed discussion see section 3.1. As one reference, see: Graham Greenleaf, “TheInfluenceofEuropeanDataPrivacyStandardsOutside  Europe:ImplicationsforGlobalizationofConvention108,”InternationalDataPrivacyLaw2,no.2 (April 4, 2012): 68–92. 79Jeremy Colvin, “UncheckedAmbiguityandtheGlobalizationofUserPrivacyControlsUndertheGDPR,” ed. Jonathan Mayer (Senior Theses, Princeton  University, 2019). 80Greenleaf, “The‘BrusselsEffect’oftheEU’s‘AIAct’onDataPrivacyOutsideEurope.”1.4. Analogues to EU AI  Regulation To assess a future AI Brussels Effect, it is useful to consider not only its determinants and  dynamics but also relevant case studies. We  do so in the appendix. In addition to the AI Act, the upcoming EU AI  regulation will comprise changes to the liability regime and the product safety regime.  Many of the 29 pieces of EU sectoral product  safety legislation have exhibited substantial  de jure Brussels Effects, reaching Oceania,  Africa, South America, and Asia, including  China. A de facto Brussels Effect also  reached the United States among many  other countries. AI product safety standards  and the general product safety regime share  many characteristics. For instance, it is plausible that future EU AI regulation will impact  the relevant ISO standards, as other EU  product safety standards have in the past.  The regulatory diffusion of EU data protection legislation may also help understand the  prospects of an AI Brussels Effect because  data protection legislation regulates parts of  AI development and deployment. The 1995  Data Protection Directive (DPD) experienced  a significant de jure Brussels Effect,78though  some authors attribute this diffusion of  norms similar to those in the DPD to the  Council of Europe’s Convention 108, which  preceded and influenced the DPD. The 2018  General Data Protection Regulation (GDPR)  has shown a robust de facto Brussels Effect.  For instance, 58% of popular websites offer  US subjects both the right to erasure (GDPR  Article 17) and the right to portability (GDPR  Article 20).79In addition and despite its recentness, six countries, including Japan, Argentina, and New Zealand, have already adopted similar rules – a de jure Brussels  Effect.80Regulatory diffusion of the DPD and GDPR may have benefited from extraterritorial demands and high costs for differentiation. For more details, see the appendix .
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•26 When new more stringent legislation is introduced in a jurisdiction, multinational actors  are faced with two choices. First, they need  to decide whether it is worth remaining in the  market. Second, if they choose to stay in the  market, they must decide whether to comply  with the new regulation globally or offer two  or more products, one compliant with the jurisdiction’s requirements and at least one  non-compliant version. With regard to EU  regulation, if companies choose to stay in the  market and sell EU-compliant products outside the EU, we have a de facto Brussels  Effect, as illustrated in Figure 1 . Whether firms stay in the EU depends to a large  degree on the market size after the relevant regulation taking effect, which depends on the EU  market size before the regulation ( §2.1), how  compliance is likely to affect product quality and  costs, and how much buyers and sellers are ex-pected to react to accompanying price and  product changes ( §2.4 ). If a company chooses to remain in the EU  market, their next choice is whether to offer  their EU-compliant product outside the EU or  not. We consider the factors which make it  likely profitable for companies to offer one  EU-compliant product globally (“non-differentiation”) rather than to differentiate their  products into one EU-compliant product and  at least one non-EU-compliant product  (“differentiation”). In short, we assume nondifferentiation will be chosen when it is  deemed more profitable to sell EU-compliant  products, rather than non-EU-compliant  products, outside the EU.  More specifically, the following inequality must  hold if a company is to choose non-differentiation, creating a de facto Brussels Effect:  2.Determinantsofthe DeFactoBrusselsEffect Figure 2: The conditions under which non-differentiation is more profitable and a de facto Brussels Effect would be produced. REVENUES ≥ - -Revenue from selling EU compliant  products outside the EURevenue from selling non-EUcompliant products outside the EUNon-differentiationprofits outsidetheEUDifferentiationprofits outsidetheEU COSTSVariable compliance cost of producing an EU-compliant product for non-EU marketsAdditional regulatory costs of non-EUcompliant products (fixed + variable costs) + Duplication costs associated with
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•27 DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 81Unless the jurisdiction put in place e.g. unilateral recognition of CE marked products. 82The EU’s Code of Conduct on countering illegal hate speech online could illustrate such oligopolistic coordination. The big tech companies, including Google  and Facebook, implemented the new Code of Conduct worldwide. European Commission, “TheEUCodeofConductonCounteringIllegalHateSpeech  Online:TheRobustResponseProvidedbytheEuropeanUnion,” accessed July 11, 2022; Bradford, TheBrusselsEffect:HowtheEuropeanUnionRulesthe  World, chap. 6. 83Compliance cost is the cost of meeting the requirements, and verification cost refers to the cost of being able to verify and evidence that this is the  case. We refer to the sum of these two costs as regulatory costs.In choosing non-differentiation, the company  would not have to pay additional fixed compliance costs, as that cost has already been  borne in choosing to stay in the EU market.  On the other hand, it might see smaller revenues if the EU-compliant product is less desirable to non-EU customers ( §2.4 ), and it will  have to pay the variable compliance costs associated with offering an EU-compliant  product outside the EU ( §2.5.1 ). In choosing differentiation, the company’s  profit outside the EU is equal to its revenue  from selling the non-EU-compliant product  minus the variable compliance cost in producing the non-EU-compliant product (§2.5.3 ) and the fixed compliance costs from complying  with regulation in other jurisdictions. In addition, it may have to bear duplication costs associated with needing to maintain two separate production processes (§2.5.2 ).The  company choosing differentiation may also  need to pay additional verification costs in  non-EU jurisdictions. Even though such costs  would be borne in choosing non-differentiation,81they would if anything be lower in the  non-differentiation case, as verification efforts  (e.g. documentation) for the EU market could  be more easily reused in other jurisdictions if  the system remains the same. As a simplification, we assume that if a  product is EU-compliant, it is automatically  compliant with all non-EU regulation. This  would not be the case if other jurisdictions introduced regulation incompatible with EU  rules, undermining de facto diffusion. Another  simplification is that we do not consider in detail differences in verification costs outside the  EU between non-differentiation and differentiation.  In this section, we discuss five factors which  make a de facto Brussels Effect more likely.  Roughly speaking, we discuss the role of three actors: regulators ( §§2.2 and 2.3), the market  and consumer behaviour ( §§2.1 and 2.4), and  the firms’ production processes ( §2.5 ). Firstly, market properties (§2.1)such as market  size, mar ket concentration, and globalisation  influence the chance of a de facto Brussels  Effect. Some properties, such as the EU’s relative market size, make it more likely that firms  stay in the EU. The bigger the EU’s relative and  absolute market size, the more likely companies are to stay in the market. The more globalised the market structure, the more likely it is  that firms offer products outside and wi thin the  EU, creating the preconditions for a de facto  Brussels Effect. Further, the more oligopolistic  the market structure (see §2.1.2 ), the more  likely it is that companies choose non-differentiation, as they can coordinate their compliance strategies, e.g. by choosing to all  offer non-differentiated products, thereby  not being put at a disadvantage compared to  their competitors.82 Secondly, a requirement for the de facto Brussels Effect is that EU regulation must be more  stringent than that of other jurisdictions ( §2.2 ).  Higher stringency with regard to all regulatory  dimensions across all other jurisdictions is not  necessary, but without any higher stringency  there cannot be de facto diffusion.  Thirdly, the more regulatory capacity ( §2.3 ), such as regulatory expertise (see §2.3.1 ), is  brought to bear on the design of the EU regulation, the more likely companies are to stay in the  EU and the smaller the costs of non-differentiation.83This is because better-crafted regulation  might decrease the cost of complying with EU  regulation (particularly if it decreases variable  compl iance costs) while ensuring minimal (or  positive) impacts o n revenue within and outside  the EU. Well-cra fted regulation may also be required to ensure that EU -compliant products will  be compatible with the la ws o fotherjurisdic tions. 
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•28 DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT Otherwise, a Brussels Effect with regard to  those jurisdictions would be undermined. We  also discuss verification costs in section 2.5.3 . Further, competent enforcement of the regulation might be necessary for a de facto Brussels Effect. Competent enforcement can reduce regulatory costs by reducing regulatory  uncertainty and ensuring that firms are compliant. Without enforcement, firms could  choose not to comply with the EU rules even  within the EU, undermining the opportunity  for de facto diffusion.  Fourt hly, demand and supply, within and outside the EU, must be relatively inelastic ( §2.4 ) in  that the market size does not change much in  response to a given change in regulatory costs  or in product quality. Low elasticity within the  EU in response to the new EU rules increases  the chance of companies remaining in the EU,  whereas low elasticity outside the EU increases  the chance of non-differentiation. We discuss  four determinants of inelasticity. First, if buyers  prefer compliant companies and products,  companies are more willing to pay the regulatory costs and are less responsive to regulation.  Second, if EU buyers can, without great effort,  move their consumption of AI products out of  the EU, then the demand is more elastic. Third,  the more substitutes or alternatives for a comparable price are available, the greater the likelihood that buyers substitute AI products with  alternatives – increasing the elasticity of nonEU and EU demand. Fourth, there are supplyside effects, where firms might e.g. start taking  longer to place their products on the EU market. Firms’ investments into the EU market being inelastic increases the chance of a de facto  Brussels Effect. For the EU, we are unlikely to  see immediate effects on EU consumption of AI  products – EU end consumers are unlikely to  e.g. move their consumption of AI products out  of the EU – but the increased regulatory burdens could decrease EU consumption over  time via supply-side effects. Outside the EU, we  argue, demand is likely inelastic in the regions  and domains where EU compliance is seen as  a quality signal or if EU norms have diffused. Lastly, we consider the regulatory cost associated with applying the EU standards globally  (in proportion to the market size ( §2.1) and the  existing production costs), i.e. the cost of nondifferentiation, compared to that associated  with producing non-EU compliant products,  the cost of differentiation ( §2.5 ). This section  is focused on how the production process and  costs change when the EU-compliant product  is also sold outside the EU. We argue that  some of the crucial factors determining nondifferentiation production cost in the AI industry are (i) whether compliance requires  early forking of an AI system – i.e. changes to  the foundational parts of the system – which  often results in higher duplication costs, (ii)  the variable cost accrued by offering EU-compliant products globally, and (iii) the extent to  which there is existing product differentiation  (reducing the costs of differentiation). This report contributes to the literature studying the drivers of regulatory diffusion. We  break down Bradford’s84second and fourth determinant of the de facto Brussels Effect, regulatory capacity and inelasticity, into four and  three components respectively, and generalise  both concepts to include further considerations. Our first determinant discusses favourable market properties, whereas Bradford only  discusses one such market property: market  size. Bradford describes the fifth component as  “compliance indivisibility.” We attempt to make  this criterion more precise by having it refer to  the difference in cost between non-differentiation and differentiation, and we offer a breakdown of these two costs. Different authors,  such as Bradford , usually discuss two channels of the de jure Brussels Effect. We suggest  four different channels, overall presenting a  hopefully more comprehensive picture.  2.1. Favourable Market  Properties The AI industry’s market properties are generally conducive to a de facto Brussels Effect:  the EU AI market is large in both absolute  84Bradford, TheBrusselsEffect:HowtheEuropeanUnionRulestheWorld.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•29 DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT What is the size of the EU AI market? There are  no highly rigorous estimates of the EU’s AI market size, as the industry is growing quickly and  there are disagreements about what counts as AI  and how much of current AI spending is on R&D.  Therefore, we believe it best to use multiple  methods to estimate it. We can start by looking at  AI spending – investments made in developing  and deploy ing AI – as a proxy of the EU AI market. The International Data Corporation estimates that European87 AI spending was approximately 17 billion US dollars in 2021 and is  projected to grow by 27% on average per year  from 2022 to 2025.88Given estimates of  global AI spending at $85 billion in 2021, the  EU’s share of global spending is around 20%.  This might be an under-estimate if we expect  the EU’s share of AI spending to go up as the  technology matures and if the US has a higher  share of investment in development than of  consumption of AI products. The EU Commission’s AI Act Impact Assessment used another  method: assuming that the EU AI market share  is similar to its market share in software, they  estimate the EU AI market at approximately  22% of the global AI market.89Another  meth od would be to assume that the EU AI  market will be at least proportional to its global  GDP share. Hence, the relative EU AI market  size may be at least 15% because this is the  EU’s share of global GDP in 2021.90Moreover,  projections assume that Europe’s position will  not significantly change over the following  years.91 Taking these togeth er, we believe the  EU’s AI market shar e is likely to be no lower  than 15% of the global market. This is a sizable market, which may well produce pressures in favour of a de facto Brussels Effect.  85Chad Damro, “MarketPowerEurope,” Journal of European Public Policy 19, no. 5 (June 1, 2012): 682–99; Daniel W. Drezner, “Globalization,Harmonization, and Competition: The Different Pathways to Policy Convergence,” Journal of European Public Policy 12, no. 5 (October 1, 2005): 841–59;  Vogel, TradingUp:ConsumerandEnvironmentalRegulationinaGlobalEconomy. 86If there are only small-to-medium enterprises (SMEs) and 60% of their profits are in the EU, then the relative market size is large (the absolute size of  a firm's customer base is small). Because of the small customer base for the firm, they might not be prepared to pay the fixed costs of regulatory  adaptation and would instead focus on the customer base outside the EU. 87One should note that in the following we use data from the European continent which includes countries, such as Norway and Switzerland, that are  not part of the EU.  88IDC, “EuropeanSpendingonArtificialIntelligenceWillReach$22Billionin2022,SupportedbyStrongInvestmentsAcrossBankingandManufacturing,SaysIDC,” IDC: The premier global market intelligence company, October 7, 2021. 89European Commission, “Commission Staff Working Document Impact Assessment Accompanying the Proposal for a Regulation of the European  ParliamentandoftheCouncilLayingDownHarmonisedRulesonArtificialIntelligence(ArtificialIntelligenceAct)andAmendingCertainUnionLegislativeActsSWD/2021/84Final.” 90IMF, “EuropeanUnion:ShareinGlobalGrossDomesticProductBasedonPurchasing-Power-Parityfrom2017to2027,” April 2022, Statista, 91IDC, “WorldwideArtificialIntelligenceSpendingGuide,” IDC: The premier global market intelligence company, accessed July 5, 2022.and relative terms (at least 15% of the global  AI market), and multinational companies dominate the global AI industry. However, many of  the AI applications that will have the highest  regu latory burdens imposed by the AI Act – highrisk AI systems – are in less globalised industries.  For example, many of the high-risk uses of AI are  in government services. Moreover , the EU AI relative market size may be reduced in the future if  the AI Act proves very costly.  2.1.1.MarketSize The larger the absolute EU market size, the more  incentivised companies will be to stay in the market when new legislation is introduced. A firm  might leave the EU market in response to stringent  regula tion, but if the absolute market size of the EU  market is large, the foregone profits of leaving the  EU market are also larger .  As the relativesize of the EU market increases, the  more likely companies are to sell EU-compliant  rather than non-EU-compliant products outside the  EU.85The profits of non-differentiation, i.e. of selling  and producing EU-compliant products worldwide,  increase with the absolute size of the market outside the EU. A bigger market outside the EU allows  firms to absorb additional fixed costs associated  with complying with non-EU rules or duplication of  production processes in exchange for potential  lowervariablecostsorhigherconsumptionofnonEU-compliant products. Hence, the likelihood of  the Brussels Effect increases with the absolute  market size within the EU and decrease s with the  absolute market size outside the EU. In other  words, the likelihood of the Brussels Effect will increase with the a bsolute and relative market  size of the EU.86
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•30 DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT This condition is exemplified by a comparison between European metal and chemical regulation. As the chemical market is  highly globalised, EU regulation, such as  REACH,95exhibited a strong de facto  Brussels Effect. In contrast, the metal industry is predominantly regional. As almost no international firm could spread  the EU blueprint to consumers elsewhere,  the metal regulation did not exhibit a  Brussels Effect.96 Multinational firms dominate the AI industry, making the AI market structure  conducive to a de facto Brussels Effect.  This interconnectedness is illustrated by  the fact that foreign markets were strongly  affected by the GDPR.97Based on a survey, PricewaterhouseCoopers estimated  that 68% of American companies were expected to spend $1–10 million on GDPR  compliance, and 9% of American companies would spend more than $10 million.98  For more details, see the appendix section 4.1 . However, some of the industries and applications classed as high-risk AI systems  fail to or only partly fulfil this criterion.99 Many high-risk systems in Annex III of the  proposed AI Act are likely to largely be  deployed by EU governments – e.g. for  border control, certain uses in education,  public benefit allocation, law enforcement, management of critical infrastructure, and administration of justice100– who 92Tatjana Evas, “EuropeanFrameworkonEthicalAspectsofArtificialIntelligence,RoboticsandRelatedTechnologies:EuropeanAddedValueAssessment:Study” (European Parliamentary Research Service, 2020). 93European Commission, “Commission Staff Working Document Impact Assessment Accompanying the Proposal for a Regulation of the European  ParliamentandoftheCouncilLayingDownHarmonisedRulesonArtificialIntelligence(ArtificialIntelligenceAct)andAmendingCertainUnionLegislativeActsSWD/2021/84Final.” 94This condition has not been discussed in Bradford, The Brussels Effect: How the European Union Rules the World; Björkdahl et al., Importing EU  Norms Conceptual Framework and Empirical Findings . Fini discusses that New Zealand industries are likely to adhere to the EU norms if they are  exporting a significant part of the goods to the EU, as has happened in the New Zealand wine industry. Melissa Fini, “TheEUasForceto‘DoGood’:  TheEU’sWiderInfluenceonEnvironmentalMatters,” Australian and New Zealand Journal of European Studies 3, no. 1 (May 5, 2011). 95REACH: European Parliament, “Regulation(EC)No1907/2006oftheEuropeanParliamentandoftheCouncilof18December2006Concerningthe  Registration, Evaluation, Authorisation and Restriction of Chemicals (REACH), Establishing a European Chemicals Agency, Amending Directive  1999/45/ECandRepealingCouncilRegulation(EEC)No793/93andCommissionRegulation(EC)No1488/94asWellasCouncilDirective76/769/ EECandCommissionDirectives91/155/EEC,93/67/EEC,93/105/ECand2000/21/EC,” CELEX number: 32006R1907, Official Journal of the European  Union L 396 49 (December 2006). 96Concerning REACH, the chemical regulation, see Hanson, CEMarking,ProductStandardsandWorldTrade ; Bradford, TheBrusselsEffect:Howthe  EuropeanUnionRulestheWorld . 97Though, it is important to stress that data-processing activities are much more common and distinct from the usage of AI systems. 98He Li, Lu Yu, and Wu He, “TheImpactofGDPRonGlobalTechnologyDevelopment,” Journal of Global Information T echnology Management 22, no. 1 (January 2, 2019): 1–6; PwC, “PulseSurvey:USCompaniesRampingUpGeneralDataProtectionRegulation(GDPR)Budgets,” GDPR Series (PwC, 2017). 99See AI Act, annex II and III for a list of the high-risk AI applications. 100See Table 1 for more details. Note that none of these estimates take into  account that EU regulation could reduce or  increase92the supply and demand in the EU  market. We discuss these dynamics and the  expected effect in section 2.4 on inelasticity. The AI Act does not regulate all AI systems,  however. What is the expected share of the  global market of high-risk AI systems, as  defined by the proposed AI Act? The Commission’s impact assessment of the AI Act  estimates that only 5–15% of AI systems on  the EU market will be considered highrisk.93It seems likely that the largest market  segments using high-risk AI systems will include AI systems used for recruitment, determining access to self-employment opportunities, and task allocation, likely affecting  many gig economy companies; multiple  uses in the financial services sector; and  sectors already covered by some existing  product safety regulation, such as the use of  AI in medical devices, toys, and machinery. 2.1.2. Oligopolistic Competition and  Multinational Companies In a ddition to sufficiently high absolute and  relative market size, the market must be adequately globalised and oligopolistic to produce a de facto effect.94Without companies  straddling multiple jurisdictions, there is no  possibility of a de facto Brussels Effect. If all  companies produced and sold goods in a  single country or region, no company would  bring regulatory norms to other jurisdic tions. 
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•31 DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 101There is some anecdotal evidence that for border control management, countries are very reluctant to contract or buy products from outside their  jurisdiction. iBorderCtrl, the only existent project implementing AI practices on the EU border, is a collaboration among many EU organisations and  institutes. Only BioSec, an international company, also participated. Clearview AI which provides AI law enforcement services for some US agencies  has been harshly criticised by EU governments (because of its avoidance of GDPR requirements). Robert Hart, “ClearviewAI—TheFacialRecognition  CompanyEmbracedByU.S.LawEnforcement—JustGotHitWithABarrageOfPrivacyComplaintsInEurope,” Forbes, May 27, 2021. 102Annex III, 5b. 103European Parliament, “Regulation(EC)No1907/2006oftheEuropeanParliamentandoftheCouncilof18December2006ConcerningtheRegistration,Evaluation,AuthorisationandRestrictionofChemicals(REACH),EstablishingaEuropeanChemicalsAgency,AmendingDirective1999/45/EC  andRepealingCouncilRegulation(EEC)No793/93andCommissionRegulation(EC)No1488/94asWellasCouncilDirective76/769/EECandCommissionDirectives91/155/EEC,93/67/EEC,93/105/ECand2000/21/EC,” 5. 104AI Act, annex II. 105Ajay Agrawal, Joshua Gans, and Avi Goldfarb, eds., TheEconomicsofArtificialIntelligence:AnAgenda , 2019. 106See e.g. Hal Varian, “ArtificialIntelligence,Economics,andIndustrialOrganization,” in The Economics of Artificial Intelligence: An Agenda, ed. Ajay  Agrawal, Joshua Gans, and Avi Goldfarb (University of Chicago Press, 2019), 399–419.will prefer their AI systems be developed in  the EU.101Financia l services companies are  also likely to have AI sys tems used “to evaluate the creditworthi ness of natural persons  or establish their credit score” covered by the  AI Act.102However, due to the differences in  national regulation, the financial services industry already sees significant regionalisation  in the business-to-consumer market, with few  companies providing credit checks internationally.  Even if an industry is regionalised, there can  still be a de facto Brussels Effect if the provision of AI products is globalised and if the  regulation would affect that provision. This  could for example be the case if regionalised industries relied heavily on foundation  models provided by big multinational technology companies and those models need  to be adjusted to meet the EU’s requirements. Whether this will be the case depends partly on how general systems (for  example large language models like  OpenAI’s GPT-3) that are adapted to a more  specific domain are handled by the AI Act.  The EU Council recently released a proposal where the responsibility to ensure  conformity of a high-risk AI system would  only go to the actor that deploys it in a highrisk domain, even if they use a general system to do so.103We discuss this more in section 2.6 . Other high-risk uses covered by the AI Act  are more likely to be highly globalised. In  particular, the AI Act classifies a range of  products already covered by various product  safety regulations – notably medical devices,  toys, and machinery – as high-risk.104Some of these industries are highly globalised with  a small number of multinational companies  dominating the market.  Further, a more oligopolistic market is more  likely to see a de facto Brussels Effect. Companies are more prepared to pay the fixed  costs of regulatory compliance if they have larger EU revenues. Further, as an oligopolistic  market includes fewer firms, the customer  base of every single firm will be greater. In addition, companies in an oligopolistic market  may find it easier to converge on the same  compliance strategy, all of them choosing nondifferentiation, and may face a greater need to  maintain a positive reputation. Therefore, the  more we can expect the AI industry to be dominated by big oligopolistic companies like IBM,  Amazon, Google, Facebook, and Apple,105as  well as companies in the medical devices industry, the more we can expect these firms to  stay in the EU market and pay the regulatory  costs. Whether this is the case will partly depend on the extent to which big technology  companies will be the main developers and  sellers of AI systems globally or if the market  becomes less concentrated as it matures.106 2.1.3.TerritorialScope A broader territorial scope of regulation, that is,  a further jurisdictional reach of a regulation,  makes the de facto Brussels Effect more likely  because it effectively increases the size of the  affected market. The territorial scope of a regulation is very broad if the regulation affects  companies even though they are only selling,  producing, or are registered outside the EU.  A broad territorial scope effectively increases the global proportion of the 
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•32 DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 107GDPR, art. 3. 108Bradford,TheBrusselsEffect:HowtheEuropeanUnionRulestheWorld, chap. 4. 109Greenleaf, “The‘BrusselsEffect’oftheEU’s‘AIAct’onDataPrivacyOutsideEurope,” 3. 110A private non-professional activity cannot be a user according to the EU AI Act. 111Greenleaf, 3.. 112AI Act, art. 26. 113Greenleaf, 3. 114Both examples are from Greenleaf, 4. For the second example, Greenleaf notes that even though this is not explicitly listed, it should fall under “essential private services and benefits”. 115See §4.3 and W. John Hopkins and Henrietta S. McNeill, “ExportingHardLawThroughSoftNorms:NewZealand’sReceptionofEuropeanStandards,” in Importing EU Norms: Conceptual Framework and Empirical Findings, ed. Annika Björkdahl et al. (Cham: Springer International Publishing, 2015), chap.  8; Fini, “TheEUasForceto‘DoGood’:TheEU’sWiderInfluenceonEnvironmentalMatters.” 116Bradford,TheBrusselsEffect:HowtheEuropeanUnionRulestheWorld, chap. 4. 117This is only true under the assumption that non-differentiation is profit-maximising. products to which the EU regulation applies,  making it more likely that a company uses  the EU regulation as its internal global policy.  Illustrations of such a broad territorial scope  are the General Data Protection Regulation  (GDPR) and Data Protection Directive (DPD).  These regulations apply to any organisation,  institute, and website which interacts with  European residents, offering goods or services or monitoring behaviour.107Similarly, EU  Competition Law effectively rules extraterritorially.108All else being equal, extraterritoriality makes a de facto Brussels Effect more  likely. Because the proposed AI Act does not have a  very broad territorial scope – in contrast to, for  instance, data protection or competition legislation – the conditions for regulatory diffusion  are not optimal. The EU AI Act includes some  extraterritoriality,109although not to the same  extent as the GDPR. Firms fall under the scope  of the regulation if they are the users110 or producers of an AI system whose output is used in  the EU.111 Exports from the EU are not covered.  For high-risk uses of AI, an EU importer must  make sure that the non-EU-produced product  has gone through the required conformity assessment,112introducing a measure of extraterritoriality.113For example, a non-EU company  providing a recruitment assessment tool for EU  companies using machine learning falls under  the EU AI Act. Similarly, a non-EU company  offering an AI-based assessment of medical  risks for an EU insurance company falls under  Annex III(5) of the proposed EU AI Act.114 Moreover , many past EU regulations have exhibited a de facto Brussels Effect with similar degrees of extraterritoriality as the proposed AI Act. One example of this is the numerous product  safety regulations under the New Legislative  Framework, as analysed in the appendix ( §4.3). It is possible for other jurisdictions to increase  the de facto territorial scope of the AI Act if  compliance with the EU requirements allows  access to their market. For example, New Zealand has incorporated the EU’s CE mark in its  national regulation, allowing CE-marked  products onto the EU market without additional checks.115 2.2. Regulatory Stringency A requirement for the de facto Brussels Effect is  that EU regulation be more stringent than the  regulation in other jurisdictions.116The forthcoming EU AI regulation will likely be more stringent  than that of other large jurisdictions such as the  US and potentially China. Among the jurisdictions in which a multinational company operates, the one with the  most stringent regulation is more likely to  shape the company’s global internal policy, if  that regulation is compatible across jurisdictions.117EU regulation, however, does not have  to be most stringent on all possible regulatory  dimensions for a de facto Brussels Effect to occur. It must only have non-overlapping obligations. The EU will likely create a more stringent regulatory regime for AI than the US will. EU  public opinion and regulatory culture are significantly more prone to produce stringent risk  regulation. This has not always been the case.  The US had more stringent risk regulation 
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•33 118Though some contest this point. See e.g. James Hammit et al., TheRealityofPrecaution,1stEdition (Routledge, 2010), chap. 15. 119Vogel, ThePoliticsofPrecaution:RegulatingHealth,Safety,andEnvironmentalRisksinEuropeandtheUnitedStates, 4–6. 120Bradford, TheBrusselsEffect:HowtheEuropeanUnionRulestheWorld , chap. 5. 121Arthur Neslen, “DonaldTrump‘TakingStepstoAbolishEnvironmentalProtectionAgency,’” The Guardian, February 2, 2017 122Vogel, ThePoliticsofPrecaution:RegulatingHealth,Safety,andEnvironmentalRisksinEuropeandtheUnitedStates, 34–36. 123Jean-Daniel Lévy and Pierre-Hadrien Bartoli, “Copyrights&TechGiants:WhatAretheExpectationsinEurope?” (harris interactive, February 2019). 124Lydia Saad, “AmericansSplitonMoreRegulationofBigTech,” August 21, 2019 125Baobao Zhang and Allan Dafoe, “Artificial Intelligence: American Attitudes and Trends” (Centre for the Governance of AI, Future of Humanity Institute, University of Oxford, January 2019) sec. 2; Eurobarometer, “AttitudestowardstheImpactofDigitisationandAutomationonDailyLife” (European Commission,  May 2017).  126This assessment relies, among others, on a comparison of EU AI Whitepaper and the Office of Management and Budget’s AI draft memorandum and the  respective submissions to the consultation process. The appearance of keywords such as safety, rights, trust or investment and their connotations differs  between the two jurisdictions. European Commission, “On Artificial Intelligence - A European Approach to Excellence and Trust COM/2020/65 Final,”  CELEX number: 52020DC0065, February 19, 2020; Russell T. Vought to Heads of Executive Departments and Agencies, “DraftMemorandumfortheHeads  of Executive Departments and Agencies, Guidance for Regulation of Artificial Intelligence Applications,” January 7, 2019; European Commission, “White PaperonArtificialIntelligence-aEuropeanApproach,” European Commission, accessed July 12, 2022; Regulations.gov, “DraftMemorandumtotheHeads  ofExecutiveDepartmentsandAgencies,GuidanceforRegulationofArtificialIntelligenceApplications,” Regulations.gov, accessed July 21, 2022. 127Russell T. Vought to Heads of Executive Departments and Agencies, “MemorandumfortheHeadsofExecutiveDepartmentsandAgencies,Guidancefor  RegulationofArtificialIntelligenceApplications,” November 17, 2020. And the Trump Administration criticised the EU for their potentially strict rules: David  Shepardson, “TrumpAdministrationSeekstoLimit‘Overreach’ofRegulationofArtificialIntelligence,” Insurance Journal, January 8, 2020.DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT between the 1960s and the 1990s, after which  EU regulation started becoming more stringent.118David Vogel describes this pattern119 and seeks to explain it. Firstly, he claims it  stems from an increase in public demand for  more stringent risk regulation in the EU and a  decrease in the US, partially as a consequence  of the success of regulation pursued in the  1960s to 1990s. For example, differences in  public opinion regarding food safety and data  privacy have driven laxer rules in the United  States and stricter rules in the EU, which might  also happen for AI regulation.120Secondly, risk  regulation has become politically polarised in  the US since the 1990s, while this has not occurred in the EU. Republican President Nixon  created the US Environme ntal Protection  Agency in 1970, while Donald Trump called  for its abolition during his presidency, indicating an increased polarisation in environmental risk regulation.121Thirdly, Vogel suggests, while the US has adopted regulatory  principles and approaches that make risk  regulation less likely, requiring formal risk  assessments based on claims with high  levels of scientific certainty, the EU has  done the opposite in e.g. enshrining the  precautionary principle in the 1992  Maastricht Treaty.122 EU citizens seem more favourably inclined  towards regulation of AI technology than do  their US counterparts. When asked in a 2019  poll whether companies like Google, Apple,  Facebook, or Amazon have been sufficiently  regulated by the EU in the past 5 years, 64%  of respondents said big tech companies had been regulated insufficiently.123In a similar  2019 US Gallup poll, 48% of Americans favoured more regulation of big tech companies.124Given the EU’s higher levels of existing  regulatory burden for big tech, these results  suggest preferences for significantly more  regulation in the EU than in the US. Other  survey data shows a less clear picture. For  example, a 2019 survey of US public opinion  found that 82% of respondents agreed with  the statement that “Robots and artificial intelligence are technologies that require careful  management”, while a 2017 Eurobarometer  survey found that 88% of EU respondents  agreed with the statement.125 The United States regulatory discourse on AI  differs from the European discourse in that it  focuses less on product safety or fundamental  rights, is more national security focused, and  is expected to be less stringent.126In 2020, the  Office of Management and Budget (OMB)  published guidelines for federal agencies  concerning AI regulation. While the OMB  does not have the authority to propose new  legislation, its framing and interest in AI governance are very different from those of the  2020 EU AI White Paper.127While the EU AI  White Paper discusses competitiveness, trustworthiness, and safety, the OMB AI memorandum is framed around breaking down barriers to in novation and the adoption of AI.  The memorandum states t hat “[a]gencies  must avoid a precautionary approach that  holds AI systems to such an impossibly high  standard that society cannot enjoy their benefits.”128Furthermo re, digital companies, particu-
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•34 128Vought to Heads of Executive Departments and Agencies, “DraftMemorandumfortheHeadsofExecutiveDepartmentsandAgencies,GuidanceforRegulationofArtificialIntelligenceApplications,” January 7, 2019. 129One indicator would be the difference in lobby spending. In the EU, the GAFAM companies report combined annual spending of around 22.5 million euros.  In the US in 2020, GAFAM spent 63.53 million US dollars (56 million euros using 2020 exchange rate). For the EU: Transparency International EU, “Integrity  Watch-EULobbyists,” Transparency International EU, accessed July 12, 2022. For the US: Senate Office of Public Records, “LobbyingExpensesofAmazon  intheUnitedStatesfrom2009to2020,” 2021, Statista, ; Senate Office of Public Records, “LobbyingExpensesofAppleintheUnitedStatesfrom2009to  2020,” January 2021, Statista; Senate Office of Public Records, “Lobbying Expenses of Microsoft in the United States from 2009 to 2020,” January 2021,  Statista; Senate Office of Public Records, “LobbyingExpensesofAlphabetIncintheUnitedStatesfrom2015to2021,” October 2021, Statista; Senate Office  of Public Records, “LobbyingExpensesofFacebookintheUnitedStatesfrom2009to2020,” April 2021, Statista.  130Hammit et al., TheRealityofPrecaution . 131Vogel, ThePoliticsofPrecaution:RegulatingHealth,Safety,andEnvironmentalRisksinEuropeandtheUnitedStates. 132However, others have argued that such a practice would already be incompatible with the GDPR from 2018. Veale and Borgesius, “DemystifyingtheDraft  EUArtificialIntelligenceAct—AnalysingtheGood,theBad,andtheUnclearElementsoftheProposedApproach.” It is also noteworthy that this ban will still  be changed by the European Parliament and the Council of the European Union. 133Nicolás Elena Sánchez, “PandemicSpeedsCallsforBanonFacialRecognition,” EUobserver, May 18, 2021. 134European Commission, “Public Consultation on the AI White Paper: Final Report,” November 2020, 11. 135Haley Samsel, “CaliforniaBecomesThirdStatetoBanFacialRecognitionSoftwareinPoliceBodyCameras,” Security Today, October 10, 2019; Leufer and  Lemoine, “Europe’sApproachtoArtificialIntelligence:HowAIStrategyIsEvolving.” 136Katharina Buchholz, “AmericansAcceptFacialRecognitionforPublicSafety,” Statista, June 10, 2020. 137Bradford, TheBrusselsEffect:HowtheEuropeanUnionRulestheWorld , chap. 5.larly Google, Amazon, Facebook, Apple, and Microsoft, are more influential in United States politics than in EU politics.129While some contest that  US and EU policy do not differ significantly in  their precaution across all policy domains,130the  difference does seem significant with regard to  product safety regulation.131 We therefore expect  less stringent AI regulation in the United States  than in the EU. The situation with regard to AI-powered facial  recognition is less clear but may nonetheless  indicate differences in regulatory culture  between the EU and other jurisdictions such  as the United States. The proposed AI Act includes a ban on “real-time” biometric identification for law enforcement purposes with certain  exceptions, such as particularly serious  crimes.132Belgium has found facial recognition  applications unlawful.133In the EU AI White Paper consultation, 55% of all citizens and 29% of  civil society called for a ban of remote biometric  identification systems in publicly accessible  spaces. Out of all respondents, 77% responded  that remote biometric systems should be  banned (28%), only allowed conditional on certain requirements being met (29%), or only allowed in certain cases (20%), with 17% of respondents not expressing an opinion.134 In part,  there have been similar tendencies in the  United States. The states of Oregon and New  Hampshire have enacted bans on using facial  recog nition technologies in law enforcement  body cameras. California introduced a threeyear moratorium on the same uses in January  2020.135 Further, the facial recognition debate has become charged by the Black Lives Matter  protests of 2020. However, as of June 2020,  59% of Americans still favoured facial recognition technology for law enforcement.136 China, on the other hand, may adopt more  stringent regulation than the EU, but would  only be likely to do so for private sector uses of  AI. For a more detailed assessment, see the  discussion in section 2.3.4 . The Chinese Communist Party (CCP) is unlikely to limit its ability  to use AI technology for e .g. surveillance and  censorship. Even if China adopted more stringent regulation than the EU, we should not  necessarily expect a de facto “Beijing Effect”.  Firms may seek to avoid risks to their reputation from potentially being regarded as cooperating with autocracies. For instance, firms  do not wish to be viewed as “complicit in state  censorship in the most speech-restricting nation”.137 More importantly, as discussed in section 2.5 , many globalised companies already  offer different products in China than in the  rest of the world. 2.3. Regulatory Capacity The EU’s generally high regulatory capacity –  which includes expertise, coherence within  and between relevant policy institutions, and  sanctioning authority – increases the chance  of discovery and sanctions of infracti ons  and ensures regulation is well-crafted,  though its capacity with regard to AI may be  weaker.138Moreover, being the first jur isdiction  to regulat e a particular issue increases the DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•35 chan ces for a de facto Brussels Effect; there  is a first mover advantage. For AI, the EU will  likely be the first large ju risdiction to comprehensively regulate the technology, it has  sufficient sanctioning authority, and it has set  up new AI policy bodies to gain more expertise. However, some argue the expertise that  current regulators’ have in AI may be limited.139 2.3.1. Regulatory Expertise Regulatory expertise means that relevant authorities have knowledge and resources relevant to the regulatory domain. Regulatory  expertise often reduces compliance costs  while still achieving the same regulatory  aims, making regulation more effective. Usually, the EU is regarded as having high  regulatory expertise, though its expertise  regarding AI is harder to judge. For instance, many EU civil servants have technical or economic PhDs.140Further,  European regulatory agencies that enforce  the EU product safety rules are led by experts.141For AI in particular, an assessment  of the skills of policymakers and institutional  expertise on the national and European  level is complicated as the issue is relatively  novel and there is no existing agency on the  subject.142 The Commission sought to address this by establishing technical expert  groups, such as the High-level expert group  on artificial intelligence143and the Expert Group on Liability and Emerging Technologies, while already having regulatory expertise on product safety testing.144 However, at the same time, the Commission  has been accused of lacking an evidencebased AI policy plan.145In places, the Commission’s AI Act draft seems to show a lack of  understanding of AI technology. For instance, the act requires “[t]raining, validation  and testing data sets [to] [...] be relevant, representative, free of errors and complete.”146 On common sense interpretations of these  requirements, it seems technically near impossible to ensure datasets are free of errors  and complete.147However, it is worth noting  that the recitals accompanying the Commission’s proposal and the French presidency of  the EU Council’s proposal both include  weaker, more achievable versions of the requirement.148 Lower regulatory expertise can increase the  regulatory costs for the relevant industry  and unnecessarily reduce product quality  by disallowing too many practices. This may  in turn lead to buyers substituting AI  products with alternatives and otherwise reducing their consumption of AI products. In  response, the EU market size ( §2.1.1 ) would  be reduced, making it less profitable to not  differentiate the EU and non-EU products,  as described in section 2.4 . This reduces  the likelihood of a de facto Brussels Effect.149DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 138The costs of noncompliance rise with regulatory capacity since authorities are more likely to identify and punish infractions, and these punishments tend to  be more severe. David Bach and Abraham L. Newman, “TheEuropeanRegulatoryStateandGlobalPublicPolicy:Micro-Institutions,Macro-Influence,” Journal of European Public Policy 14, no. 6 (September 1, 2007): 827–46. 139Leufer and Lemoine, “Europe’sApproachtoArtificialIntelligence:HowAIStrategyIsEvolving.” 140Bradford, TheBrusselsEffect:HowtheEuropeanUnionRulestheWorld, chap. 1. 141Christoph Ossege, “DrivenbyExpertiseandInsulation?TheAutonomyofEuropeanRegulatoryAgencies,” Politics and Governance 3, no. 1 (March 31, 2015): 101–13. 142See regarding the lack of technical expertise of US policymakers: Michael Horowitz and Lauren Kahn, “TheAILiteracyGapHobblingAmericanOfficialdom,” War on  the Rocks, January 14, 2020. This may certainly be true for European policymakers. However, one might argue that the problem is smaller for the Commission due  to its high proportion of PhDs in (technical) subjects. Bradford, TheBrusselsEffect:HowtheEuropeanUnionRulestheWorld, chap. 1. 143European Commission, “High-LevelExpertGrouponArtificialIntelligence,” Shaping Europe’s digital future, June 7, 2022. 144European Commission, “ExpertGrouponLiabilityandNewTechnologies(E03592),” Register of Commission expert groups and other similar entities, July  27, 2021. 145Leufer and Lemoine, “Europe’sApproachtoArtificialIntelligence:HowAIStrategyIsEvolving.” 146AI Act, art. 10 (3) 147See consultation submissions of e.g. Facebook, Google, Microsoft, DeepMind: Facebook, “Response to the European Commission’s Proposed AI Act” ; Google, “ConsultationontheEUAIActProposal”; Microsoft, “Microsoft’s Response to the European Commission’s Consultation on the Artificial Intelligence  Act,” August 6, 2021; DeepMind, “DeepMindResponsetotheArticialIntelligenceAct,” August 5, 2021. 148AI Act. recitals, 44: La Présidence Française du Conseil de l’Union européenne, “PropositiondeRèglementDuParlementEuropéenetDuConseilétablissantDesRèglesHarmoniséesConcernantL’intelligenceArtificielle(législationSurL'intelligenceArtificielle)etModifiantCertainsActesLégislatifsdel'Union  -TextedeCompromisdeLaPrésidence-Articles16-29.” 149Due to a lack of regulatory expertise, the EU might also be perceived as less authoritative on the topic, making the Blueprint Channel of the de jure Brussels  Effect ( §3.1) less plausible.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•36 150Bach and Newman, “TheEuropeanRegulatoryStateandGlobalPublicPolicy:Micro-Institutions,Macro-Influence.” 151Bradford, TheBrusselsEffect:HowtheEuropeanUnionRulestheWorld,36–37; Dempsey et al., “TransnationalDigitalGovernanceandItsImpactonArtificialIntelligence.” 152European Commission, “EUMemberStatesSignuptoCooperateonArtificialIntelligence,” Shaping Europe’s digital future, April 10, 2018,  153In contrast to a minimum harmonisation instrument, a maximum harmonisation instrument prohibits member states from passing national law which  exceeds the principles of the EU regulation. Veale and Borgesius, “Demystifying the Draft EU Artificial Intelligence Act — Analysing the Good, the  Bad,andtheUnclearElementsoftheProposedApproach.” 154It is worth noting that this harmonisation likely means that some countries will implement less strict regulation than they would have if it were not for  the EU-level rules. 155Alasdair R. Y oung, “Europe as a Global Regulator? The Limits of EU Influence in International Food Safety Standards,” Journal of European Public  Policy 21, no. 6 (2014): 904–22, Björkdahl et al., ImportingEUNormsConceptualFrameworkandEmpiricalFindings,vol.8,chap.8ff. Three-quarters  of Bradford's de facto Brussels Effect examples are regulations, the EU legislation that is directly implemented into national law, as opposed to directives  for policy fields which are not fully harmonised. Bradford, TheBrusselsEffect:HowtheEuropeanUnionRulestheWorld. 156For more, see appendix §4.1. 157Veale and Borgesius, “Demystifying the Draft EU Artificial Intelligence Act — Analysing the Good, the Bad, and the Unclear Elements of the Proposed  Approach.” 158One for each member state. They are expected to be staffed with between 1 and 25 FTEs. AI systems already covered by existing product safety regulation  will continue to be covered by their current notified bodies and market surveillance authorities.2.3.2.RegulatoryCoherence Regulatory coherence concerns the degree to  which the demands of regulatory targets are  clear and consistent.150The proposed EU regulation seems well set-up to ensure such coherence by (i) aiming to establish EU-level rules for  AI, instead of going through a period with national governments adopting their own policies,  and (ii) clearly identifying the relevant actors responsible for supervision and enforcement. As a collective of 27 member states, the  European Union at times has greater difficulty  finding common solutions to regulatory problems compared to other jurisdictions such as  China and the US. This can hinder a de facto  Brussels Effect. Importantly, it can also undermine the free movement of goods within the EU  and the EU single market, one of the union’s  core objectives. Thus, to achieve this goal, the  EU has put significant effort into harmonising  regulation since the 1990s.151 Coherence in aims and intentions is high for AI  regulation. In April 2018, EU member states  committed to a joint approach in a Declaration  of Cooperation on Artificial Intelligence.152The  draft EU AI Act published in April 2021 is a maximum harmonisation instrument,153meaning that  once the act is passed, national law cannot exceed the EU-level rules.  Maximum harmonisation and the resulting coherence make a de facto Brussels Effect more  likely.154For instance, food safety standards do  not exhibit a Brussels Effect, partly because the rules differ between EU member states, effectively shrinking the EU market covered by the  regulation and also because the EU is a preference outlier.155Even if AI regulation did not  achieve maximal harmonisation and coherence  in a first law, coherence can also develop over  time. The case of data protection regulation is illustrative, where the first efforts (notably in Germany) were national, followed by an EU directive in 1995 (which states could implement in  different ways). Fully harmonised EU-level regulation came with GDPR taking effect in 2018.156 Further, all else being equal, the Brussels Effect  of AI regulation will be greater if specific and  known regulatory bodies are clearly made responsible for the issue and for shaping and enforcing market rules. T o do so, the Commission,  in the EU AI Act proposed in April 2021, seeks to  set up a European Artificial Intelligence Board.157  New national market surveillance authorities  (MSAs) will be set up and specifically tasked  with enforcing the AI Act.158 2.3.3.SanctioningAuthority The sanctioning authority of a regulator, such  as the Commission, has two parts. First, it consists of creating laws with sufficient sanctioning clauses. Second, the Commission must  have the legal institutions and resources to  identify and sanction violations. The current AI  Act proposal includes signifi cant sanctioning  powers, including the abili ty to levy heavy  fines. It is less clear whether there wil l be  sufficient resources to identify and sanction  violations.DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•37 The EU tends to back up regulation with  sufficient sanctioning authority and capacity.  For instance, financial penalties in the case  of a violation of EU competition law can  amount to 10% of the company’s annual  turnover. The GDPR allows for fines of up to  4% of the company’s annu al turnover.159 What about sanctioning capacity? The enforcement of GDPR offers a helpful case  study. In the first year of the GDPR after it  came into force in May 2018, an estimated  91 fines were issued.160As of the end of  2021, there has been a total of 990 fines  and penalties – a significant increase in  fines per year.161Half a year after the  GDPR’s implementation, Google was fined  50 million euros;162in July 2021, the Luxembourg National Commission for Data  Protection issued Amazon a 746 million  euro fine;163and in December 2021, the  French National Data Protection Commission issued total fines of 200 million euros  to Google and its subsidiaries164as well as  60 million euros to Facebook.165 The budgets of the national Data Protection Commissions (DPCs), the enforcement agencies responsible for the GDPR,  have increased since the regulation’s introduction. The DPC in Dublin has significant responsibility for enforcing the GDPR  for Amazon, Facebook, and Google.166In  2016, it had an annual budget of 9 million  euros, which increased to 23 million in  2022, with another two million added per year since the introduction of the GDPR.167 However, it is still criticised for being too  slow, in particular with regard to crossborder cases. According to a 2021 Irish  Council for Civil Liberties report, “[a]lmost  all (98%) major GDPR cases referred to  Ireland remain unresolved.”168 Simila r to the GDPR, the EU product safety  framework has significant sanctioning capacity. Consider, for illustration, the case of toy  safety standards. While the legal toy safety  standards in the United States and Europe  are similar, there have been ten times as  many recalls of Chinese children’s toys in the  EU than in the United States.169Such sanctioning capacity at existing product safety  enforcers is important to AI Act enforcement,  as they will continue to be responsible for  product safety even when products introduce  AI systems.  The proposed AI Act allows for large penalties, which can be up to 6% of global  turnover or 30 million euros – whichever is  higher – for breaches of the Title II prohibitions  of e.g. social scoring or of the Title III data quality requirements for high-risk systems. For  other rules of the proposed AI Act, the maximums are lower: up to 20 million euros or 4% of  global turnover (whichever is higher) for noncompliance with other obligations in the law  and up to 10 million euros or 2% of global  turnover (whichever is higher) for providing incorrect, inc omplete, or misleading information to the r elevant authorities.170DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 159European Commission, “FinesforBreakingEUCompetitionLaw,” November 2011; “GDPR:Fines/Penalties,” GDPR, accessed July 12, 2022. 160Catherine Barrett, “EmergingTrendsfromtheFirstYearofEUGDPREnforcement,” Data, Spring 2020 16, no. 3 (2020): 22–25,  161CMS, “GDPREnforcementTracker,” accessed July 13, 2022. 162O. Tambou, “France·LessonsfromtheFirstPost-GDPRFinesoftheCNILagainstGoogleLLC.” European Data Protection Law Review 5, no. 1 (2019):  80–84,  163Which they intend to defend themselves against. Amazon.com, Inc., “Form10-Q,” Washington, D.C., June 30, 2021. 164CNIL, “Cookies:laCNILsanctionneGOOGLEàhauteurde150millionsd’euros,” CNIL, January 6, 2022; CNIL, “TheSanctionsIssuedbytheCNIL,” CNIL, December 1, 2021. 165CNIL, “Cookies:sanctionde60millionsd’eurosàl’encontredeFACEBOOKIRELANDLIMITED,” CNIL, January 6, 2022. 166This is primarily because their European headquarters are in Ireland. A fifth of all complaints referred between Data Protection Authorities are referred  to the Irish DPC, more than for any other. Johnny Ryan and Alan Toner, “Europe’s Enforcement Paralysis: ICCL ’s 2021 Report on the Enforcement  Capacity of Data Protection Authorities” (ICCL, 2021). 167Data Protection Commission, “DataProtectionCommissionStatementonFundingin2021Budget,” Data Protection Commission, October 13, 2020;  Barry O’Halloran, “DataProtectionCommissiontoReceive€2MillionExtraFunding,” The Irish Times, October 13, 2020. 168The Report of the Irish Council for Civil Liberties conclude: “Almost all (98%) major GDPR cases referred to Ireland remain unresolved.” Ryan and Toner,  “Europe’s Enforcement Paralysis: ICCL ’s 2021 Report on the Enforcement Capacity of Data Protection Authorities.” See also this 2020 critique from Dr  Eoin O’Dell: Irish Legal News, “DataProtectionWatchdogContinuestoSuffer‘indefensible’Underfunding,” Irish Legal News, octuber 14 2020 169Derek B. Larson and Sara R. Jordan, “PlayingItSafe:ToySafetyandConformityAssessmentinEuropeandtheUnitedStates,” International Review  of Administrative Sciences 85, no. 4 (December 1, 2019): 763–79. 170AI Act, art. 71.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•38 If the infringer is a public body, penalties  are chosen by the member states.171 However, there are reasons one might worry  the AI Act will not be sufficiently strictly enforced. Except for biometric identification systems and those systems already covered by  existing product safety regulation, every highrisk AI system can get the CE (European Conformity) label through internal self-assessments without involving external certifying  bodies, causing some to worry that compliance will not be sufficiently high.172On the  other hand, many CE-markings do not require  input from external certification bodies – often  called “notified bodies”. The AI Act would  simply put in place bodies charged with monitoring compliance across the industry.  The main enforcement bodies of the AI Act  are the market surveillance authorities  (MSA) in every member state, a common approach in EU product law.173MSAs are public  bodies with wide-ranging powers to obtain  information, apply penalties, withdraw  products, and oblige intermediaries to  cease offering certain products. It is compulsory for providers of high-risk AI systems  to inform an MSA of new risks and malfunctions and for providers to inform the MSA of  risks found in their post-marketing monitoring.174In the GDPR, users have a right to  lodge a complaint, and not-for-profit bodies  or associations can also do so on their behalf. That means that if one suspects that a  data-processing company acted unlawfully  and the company does not react, one can  file a report to the MSAs, which then have to  take further actions.175In contrast, while the proposed MSAs connected to the AI Act  may receive complaints from citizens, the  MSA is not required to investigate them,  something which has drawn criticism from  e.g. the Ada Lovelace Institute,176 the Future  of Life Institute,177and the Irish Council for  Civil Liberties.178For the enforcement of the  AI Act, the Commission estimates that 1–25  extra staffers will be hired per member  state,179likely growing over time.180Some  have argued that this number “is far too  small.”181It remains unclear whether the  sanctioning capacity will prove sufficient. To conclude, the AI Act includes high levels  of sanctioning authority, similar to that of the  GDPR, whereas its accompanying sanctioning capacity is more uncertain. It might be  that infringements are much harder to detect  for the AI Act than for the GDPR or that the  MSAs will not be staffed with sufficient expertise. It could also be that the lack of ability  for citizens to submit complaints to the MSAs  will lead to insufficient enforcement. It is difficult to know before the legislation and details of accompanying sanctioning authorities have been finalised. 2.3.4.FirstMoverAdvantage A de facto Brussels Effect for EU AI regulation  becomes more likely if the EU is the first jurisdiction to regulate this issue. This is firstly because it reduces the chance that other jurisdictions pass incompatible regulation.  Secondly, if the EU is the first mover and another jurisdiction does pass EU-incompatible  regulation – i.e. more stringent than the EU  regulation in some respect – it is more likely DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 171AI Act, art. 71(7). 172Melissa Heikkilä, “6KeyBattlesAheadforEurope’sAILaw,” POLITICO, April 21, 2021. 173Veale and Borgesius, “DemystifyingtheDraftEUArtificialIntelligenceAct—AnalysingtheGood,theBad,andtheUnclearElementsoftheProposed  Approach.” 174AI Act, art. 62. 175See Veale and Borgesius.; GDPR , art. 77 and 80. 176Alexandru Circiumaru, “ThreeProposalstoStrengthentheEUArtificialIntelligenceAct,” December 13, 2021. 177Future of Life Institute, “FLIPositionPaperontheEUAIAct” (Future of Life Institute (FLI), August 6, 2021). 178Irish Council for Civil Liberties to European Commission DG CNECT A, “FlawsinEx-PostEnforcementintheAIAct,” February 15, 2022. 179Note that the larger data protection authorities have hundreds of staff. European Commission, “CommissionStaffWorkingDocumentImpactAssessment  AccompanyingtheProposalforaRegulationoftheEuropeanParliamentandoftheCouncilLayingDownHarmonisedRulesonArtificialIntelligence  (Artificial Intelligence Act) and Amending Certain Union Legislative Acts SWD/2021/84 Final” , annex III, p. 25; European Data Protection Board, “First  Overview on the Implementation of the GDPR and the Roles and Means of the National Supervisory Authorities” (EDPB, February 26, 2019).  180AI Act, page 14 mentions that the capacities of the notified bodies have to “be ramped up over time”. 181Irish Council for Civil Liberties to European Commission DG CNECT A, “FlawsinEx-PostEnforcementintheAIAct,” February 15, 2022.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•39 182Engler, “TheEUAIActWillHaveGlobalImpact,butaLimitedBrusselsEffect.” 183As, say, measured by GDP. 184Agência Câmara de Notícias, “Câmaraaprovaprojetoqueregulamentausodainteligênciaartificial,” Portal da Câmara dos Deputados, September  9, 2021. English translation here . 185Agência Senado, “Brasilpoderátermarcoregulatórioparaainteligênciaartificial,” Senado Federal, March 3, 2022. English translation here. 186Ding, “ChinAI#168:AroundtheHorn(edition6)” ; Ding, “ChinAI#182:China’sRegulationsonRecommendationAlgorithms.” 187Such as the AI White Paper and results from the HLEG. European Commission, “WhitePaperonArtificialIntelligence-aEuropeanApproach” ; European Commission, “High-LevelExpertGrouponArtificialIntelligence.” 188This could happen if, for example, there is a trade-off between a system’s accuracy and its interpretability or if the introduction of human oversight  into a product makes it slower.that companies will continue to comply with  EU regulation in all other jurisdictions because they have already borne the fixed costs  for the EU regulation.  The EU seems likely to be the first major jurisdiction to pass comprehensive AI regulation.  However, given the slow pace of EU regulatory  processes and delays in negotiations of the AI  Act,182we may see smaller jurisdictions183adopt  comprehensive AI regulation before the EU  does, and we are already seeing large jurisdictions adopting regulation for parts of the AI  ecosystem. In September 2021, Brazil’s lower  parliamentary house, the Chamber of Deputies, agreed on a proposed law outlining how  AI would be regulated and the role of existing  regulators.184In April 2022, the Brazilian Senate tasked a commission with proposing a bill  on AI regulation, taking into account e.g. the  bill proposed by the lower house.185Similarly,  China has put in place regulation of recommender systems, and it proposed regulation  for content-generation systems in early  2022.186 However, the EU may still benefit from a first  mover advantage via its having published e.g.  the AI Act draft and various documents leading up to its drafting.187In doing so, other jurisdictions are e.g. more likely to ensure their  regulation remains compatible with the EU  approach. 2.4. Inelasticity within and  outside the EU Demand and supply within and outside the EU  must be relatively inelastic; that is, the decrease in the AI product market for any giv en  increase in compliance costs or decrease in  product quality as a result of new EU regulation on AI must be small. Positive elasticity, where  e.g. demand increases in response to the regulation, would contribute even more to a de facto  effect. However, we use the term “inelasticity”  for convenience and because negative elasticity seems more plausible. In section 1.1.2 , we  discussed the regulatory costs of EU regulation  for firms, which could be up to 17% of the investment in high-risk AI systems. The higher the  elasticity – that is, the more substan tially consumption changes for a given increase in regulatory cost or reduction in product quality – the (i)  more EU AI spending goes down and firms are  less likely to invest in the EU, and (ii) the less likely  firms decide to sell EU-compliant products abroad,  as the revenue from selling EU-compliant  products outside the EU would be smaller . We discuss four components of inelasticity. First, if  buyers have a preference for compliance and  compliant products, they are more willing to pay  the compliance costs. End consumers could be  more trusting of a regulated AI market and AI  products that bear a CE mark. This seems likely,  though it is possible that the EU-compliant  products will be see n as lower quality outside the  EU, e.g. if certain functionality is or is assumed to  be la cking.188Second, if EU buyers can,  without great effort, move their consumption  of AI products out of the EU, then the demand  is more elastic. Third, the more substitutes or  alternatives are available for a comparable  price, the greater the likelihood that buyers  substitute AI products with alternatives – increasing the elasticity of non-EU and EU demand. Fourth, firms’ investment decisions being inelastic further increases the chance of  de facto diffusion. We argue th at the elasticity of firms in response to new EU AI regulation is higher for a more competitive market and for smaller firms. Within the EU, we tentatively conclude that DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•40 immediate effects on EU consumption of AI  products are unlikely – EU end consumers are  unlikely to e.g. move their consumption of AI  products out of the EU – but that the increased regulatory burdens could decrease  EU consumption over time via supply-side  effects. As innovation and adoption of some  AI technologies become slower and more  costly, thus increasing barriers to entry, suppliers and developers may delay or avoid introducing products in the EU, e.g. choosing to  roll out their AI products in other markets first.  These higher barriers to entry are likely to  differentially affect smaller actors. The size of  these effects will crucially depend on the regulatory cost, which is difficult to estimate before the legislation has been finalised.189 Outside the EU, we conclude that demand is  likely inelastic in the regions in which EU  compliance is seen as a quality signal, e.g. if  EU norms diffuse to other markets. 2.4.1.PreferencesforCompliantProducts AI regulation could increase consumption of  AI by increasing trust in products and the  market, increasing legal certainty, and increasing EU harmonisation. Indeed, the EU  Commission seems to rely on this being the  case, arguing in its preamble to the draft AI  Act that “as a result of higher demand due  to higher trust, more available offers due to  legal certainty, and the absence of  obstacles to cross-border movement of AI  systems, the single market for AI will likely  flourish.”190Other jurisdictions have made  similar statements on the importance of  trust. For example, the White House Office  for Management and Budget has stated in  guidance that “the continued adoption and acceptance of AI will depend significan tly  on public trust.”191 What is the connection between product  safety regulation, trust, and the size of the  AI market? In short, when consumers  struggle to judge the quality of products,  product safety regulation can increase a  market and/or move it closer to a more socially optimal level of product safety. In such  markets, sellers will be incentivised to compete on metrics that consumers can perceive, such as price, in turn potentially leading to consumers losing trust in the  market192or to providers of more quality  goods leaving the market, there by reducing  their consumption.193This seems particularly  the case for “credence goods”, where a consumer is unaware of the quality, including its  safety, of a good even after having consumed  it, but it also applies in cases where judging  the quality of a product would take a lot of  effort.194It seems likely that some AI systems  are credence goods, especially when considering lack of discrimination an aspect of quality. This dynamic can be reverted if consumers  are provided with some way to identify  product quality. Product safety regulation is  one such way,195though it can also be addressed by industry-led standards, reputations,196and, potentially, consumer rating systems.  There are two other mechanisms by which  the market might grow: the AI Act increasing legal certainty and it providing a harmonised market. The EU AI market is not  unregulated. Existing regulations apply  when using AI systems e.g. for human resources functions. However, it might not always be clear how those regulations apply. DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 189 Some parts of the AI Act are impracticable or very difficult to achieve. If they remain in the final text, the compliance costs may be significant.  190AI Act, preamble 3.3: European Commission, “CommissionStaffWorkingDocumentImpactAssessmentAccompanyingtheProposalforaRegulation  of the European Parliament and of the Council Laying Down Harmonised Rules on Artificial Intelligence (Artificial Intelligence Act) and Amending  CertainUnionLegislativeActsSWD/2021/84Final.” 191 Vought to Heads of Executive Departments and Agencies, “MemorandumfortheHeadsofExecutiveDepartmentsandAgencies,GuidanceforRegulationofArtificialIntelligenceApplications,” November 17, 2020. 192 This dynamic is explored e.g. in OECD,FoodSafetyandQuality:TradeConsiderations (Paris Cedex, France: Organization for Economic Co-operation  and Development (OECD), 1999), 37–39. 193This is the classic “Lemons Problem” as discussed in George A. Akerlof, “TheMarketfor‘Lemons’:QualityUncertaintyandtheMarketMechanism,”  The Quarterly Journal of Economics 84, no. 3 (August 1, 1970): 488–500. 194This distinction was first used in Phillip Nelson, “InformationandConsumerBehavior,” The Journal of Political Economy 78, no. 2 (1970): 311–29,  195See Stephan Marette, Jean-Christophe Bureau, and Estelle Gozlan, “Product Safety Provision and Consumers’ Information,” Australian Economic  Papers 39, no. 4 (December 2000): 426–41; OECD, FoodSafetyandQuality:TradeConsiderations. 196Marette, Jean-Christophe Bureau, and Gozlan, “ProductSafetyProvisionandConsumers’Information.”
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•41 In putting in place new rules, the EU hopes to  increase legal certainty on how AI systems  can be used. Further, the AI Act is an attempt  to put in place one set of EU-level harmonised rules before national governments implement their own potentially incompatible  AI regulation. Thus, the AI Act could significantly reduce the cost of operating in the EU,  compared to the counterfactual situation  where companies would need to comply  with up to different 27 national regulations.  Outside the EU, buyers might consume  more of the EU-compliant product (including paying more for it) if they perceive it to  have more safety-enhancing features or  otherwise believe it to be more trustworthy,  increasing the revenue of non-differentiation. The perceived quality of EU-compliant products outside the EU varies widely.  For instance, the EU’s CE mark serves as a  signal of product quality in Australia and  New Zealand.197At the same time, consumers in other regions may be unwilling to  accept the higher price or loss in product  features associated with the CE mark’s regulatory burden and compliance costs. Similarly, customers outside the EU might  have a preference for companies that comply with the EU rules in their jurisdictions.  Customers may criticise companies who  choose differentiation for complying with  one standard for EU customers and another  for other customers. For instance, Nestlé has  been criticised for producing and selling  more-hazardous products in some developing countries.198The AI industry may be particularly vulnerable to criticisms of this kind  since the media has a large appetite for criticising the AI companies’ business practic es,  as illustrated by the “techlash of big tech”.199 Moreover, various examples demonstrate the  motivation of AI workers at major technology companies to engage in internal corporate  activism, which increases those companies’  potential to have their reputation harmed by  offering products of different standards.200 The extent to which trust and legal certainty  will be increased by the EU’s forthcoming AI  regulation remains to be seen and will depend largely on the result of ongoing legislative processes and how the requirements  in the AI Act are made more concrete in  standardisation efforts.  2.4.2.AbilitytoLeavetheMarket If buyers can easily move their consumption  of AI products outside of the EU AI regulation’s jurisdiction, that would significantly increase the elasticity of the EU market in response to that regulation, thereby reducing  the EU AI market and decreasing the chance  companies offer their AI products on the EU  market.  End consumers are unlikely to move out of the  EU in response to new AI regulation. For instance, if a restaurant’s price increases in the  EU, residents do not move out of the EU to enjoy lower restaurant prices. A regulation’s  scope, including whether that regulation applies to EU imports, influences the inelasticity  of buyers. If imports were out of scope, buyers  would find it practically costless to substitute  the regulated product. However, this is not the  case in the proposed AI Act, in line with  product safety regulation practices.  In contrast to end consumers, companies that  act as buyers in a B2B exchange might be  more willing to leave the EU market. For instance, if EU regulation makes a financial derivative more expensive to buy, a hedge fund  may not be prepared to pay a higher price for  a financial derivative in the EU and may in-DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 197Hopkins and McNeill, “Exporting Hard Law Through Soft Norms: New Zealand’s Reception of European Standards” ; Fini, “The EU as Force to ‘Do  Good’:TheEU’sWiderInfluenceonEnvironmentalMatters.” 198Nestlé has been criticised by EU consumers and consumer organisations because they do not follow specific guidelines in their factories in other producing countries, such as the Philippines, even though the goods produced in the factories are not sold on the EU market. Bradford, TheBrusselsEffect:  HowtheEuropeanUnionRulestheWorld, 36–37. 199We thank Shin-Shin Hua for this point. Darrell M. West, “TechlashContinuestoBatterTechnologySector,” Brookings, April 2, 2021. 200See Newton regarding US tech companies’ workers protesting e.g. cooperation with the military. Casey Newton, “Google’sInternalActivismIsSpreadingacrossTechCompanies,” August 14, 2019.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•42 stead move its assets out of the EU market.  Similarly, some businesses might be incentivised to move their operations out of the EU if  that allows them to avoid potentially onerous  obligations imposed by the AI Act. This may  be possible in some cases. For example, manufacturing companies may do so, as the AI Act  concerns the use of machinery, but not end  products of a manufacturing process that do  not include AI components. Manufacturing  companies may experience costs from the AI  Act in their potential use of worker management systems and in the use of machinery  (the AI Act terms machinery as a high-risk use  of AI and calls for existing product safety requirements for machinery to be made consistent with the AI Act).201However, moving such  operations is likely to be very costly and only  justified by very large compliance costs. Perhaps, therefore, added costs to manufacturing processes are more likely to affect decisions to invest in new manufacturing  facilities, rather than causing existing facilities  to move.  2.4.3.Substitutability The available substitutes within and outside  the EU are likely to be different. Within the  EU, the substitute for AI products covered by  the AI Act will likely be non-AI-based  products or solutions, including human labour. If the substitutability of AI products is  high within the EU – if it is easy to find comparable products or solutions at a comparable price – the chance of a de facto Brussels Effect is reduced, as EU customers will  likely opt for alternatives, reducing the EU  market size.  Over time, if AI systems continue to improve  and become deeply embedded in business  processes, we should expect it to become increasingly difficult to substitute them with  e.g. human labour. Over time, it will become  increasingly worth making the investment in AI systems. Even now, it is hard to believe  that AI systems such as recommender systems in news feeds or content platforms  could be effec tively replaced with non-AI systems. Thus, we do not expect substitutability  to have a large impact on the chances of a de  facto effect. The availability of substitutes for AI systems  could reduce the speed or change the direction of innovation as AI systems are incentivised to meet certain requirements and as the  cost of producing AI systems for the EU market increases. For example, some have argued that, due to higher taxes on labour than  capital investments, the current US tax code  incentivises investments in automation replacing human labour beyond what is socially optimal.202Further, some argue that incentives  should be introduced to promote the development of AI systems that complement rather  than displace human labour.203We are not  sure how the speed of innovation is likely to  be affected. We can further suggest that the  direction of innovation will change: the AI Act  will produce incentives to increase the performance and lower the production cost of AI  systems compliant with the EU rules.  Outside the EU, substitutability is likely to be  significantly higher: EU-compliant systems outside the EU will be competing with non-EUcompliant products. Thus, we should expect  the extent to which EU-compliant products are  bought outside the EU to be significantly more  sensitive to the changes in price and quality  brought about by compliance with EU rules.  The extent to which compliance with EU rules  makes a product better or more expensive is  therefore crucial to firms’ decisions of whether  to offer EU-compliant products outside the EU.  It is unclear how the substitutability of EU-compliant systems outside the EU will change over  time. The difference in pr ice and performance  could decrease over time as investment in DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 201AI Act, annexes II and III. 202Daron Acemoglu, Andrea Manera, and Pascual Restrepo, “DoestheUSTaxCodeFavorAutomation?,” Working Paper Series 27052 (National Bureau  of Economic Research, April 2020). 203Daron Acemoglu, “Harms of AI,” Working Paper Series 29247 (Cambridge, MA: National Bureau of Economic Research, September 2021); Anton  Korinek and Joseph E. Stiglitz, “SteeringTechnologicalProgress,” February 2021.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•43 developing the regulatory technologies to  ensure compliance with the requirements  ramps up. On the other hand, it could be that  the AI Act’s requirements become more onerous over time, e.g. if there are trade-offs  between a model’s accuracy and features required by the AI Act, if ensuring human oversight becomes harder with increasing speed  and complexity of AI systems, or if the regulation fails to keep up with technological developments. 2.4.4.Supply-SideElasticity Another important factor is the elasticity of  the firms supplying AI products. They might  change their behaviour in response to the EU  regulation or in response to changes in demand. The higher the de mand elasticity and  the higher the re gulatory cost, the lower the  profitability of supplying products to the EU  market. This might mean that firms, investors,  and entrepreneurs move their scarce resources (e.g. capital, human resources) out of  the EU market or delay investment in the EU  market. For example, they might first develop a  product for the non-EU market and only then  choose to take on the added compliance costs  required to expand into the EU market. This dynamic would reduce absolute and relative EU  AI spending – weakening the de facto Brussels  Effect (see §2.1.1 for a discussion). In sum, if the  sellers’ investments respond substantively to  regulatory costs, a de facto Brussels Effect is  less likely. We can start by looking at how profitability in the  AI industry could be affected by the AI Act. Estimates of the profit margin in the AI industry are  difficult and diverse. This might be because  profitability among AI firms differs drastically  and many AI and technology companies incur  losses for several years, even when they are  already public.204Some venture capitalists estimate that the profit margin of the average AI company is between 50 and 60%.205Regulation  which increases the costs by 10% could lead to  a profit margin of 40–50%. Thus, one might expect investors and entrepreneurs to deploy  their scarce resources in other markets if those  markets can garner higher returns. Competition  among AI firms and investors would dampen  this effect: the higher returns outside the EU  would attract more capital, driving down its  value and ability to gain such high returns.  Given EU consumers’ difficulty of moving their  AI consumption out of the EU and the potential  difficulties in finding substitutes for AI  products, companies may be able to raise  prices to keep profit margins at a similar level.  This could be possible provided the competition on the market is not too high.  Furthermore, the AI Act is likely to increase barriers to entry for the EU AI market, which might  mean that the profits of a company that succeeds in the EU are more secure.206This could  mean that large companies, with significant  compliance divisions already well set-up to react to new regulation, will not reduce their investments in the EU market, while small and medium enterprises do. This could in turn reduce  the innovativeness of the EU AI market over  time. The AI Act does include measures, such as  regulatory sandboxes,207to reduce burdens on  smaller actors, but it is unclear if they will be  sufficient.  The GDPR provides weak, inconclusive evidence on whether innovation and SMEs will be  stifled. A study ba sed on interviews with German start-ups whose products or business  models centre on personal data does not  find conclusive evidence as to w hether the  GDPR has increased or stifled innovation.208 Others report stifled innovation, as the  GDPR advantages large companies reducing competitiveness by increasing barriers  to entry.209DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 204Jeffrey Funk, “AIandEconomicProductivity:ExpectEvolution,NotRevolution,” IEEE Spectrum, December 5, 2019. 205Martin Casado and Matt Bornstein, “TheNewBusinessofAI(andHowIt’sDifferentFromTraditionalSoftware),” Future, February 16, 2020. 206This has been discussed, for example, in a classic essay by Michael Porter: Michael E. Porter, “How Competitive Forces Shape Strategy,” Harvard  Business Review, March 1, 1979. 207AI Act, art. 53. 208Nicholas Martin et al., “HowDataProtectionRegulationAffectsStartupInnovation,” Information Systems Frontiers 21, no. 6 (December 1, 2019): 1307–24, 
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•44 There could be even larger effects on EU innovativeness in AI if research and development would be directly affected by the AI  Act, regardless of whether a product has  been deployed on the market. If the regulation would also affect AI R&D, then we  would expect a bigger supply-side response  to the regulation, as research would likely  move out of the EU, reducing the amount of  AI talent in the region and weakening innovation clusters. To conclude, the response to the AI Act  among buyers and sellers could be sufficiently inelastic to undergird a de facto Brussels Effect. The inelasticity is contingent on  the preferences for compliant products. NonEU consumers are unresponsive to regulation if customers perceive EU-compliant  products to be higher quality and requirements don’t make a product less attractive to  customers, for example if complying with  them produces an inferior product in some  way. If buyers outside the EU are less willing  to pay for EU-compliant products, firms could  be discouraged from selling EU-compliant  products outside the EU as it would decrease  the revenue from non-differentiation.  2.5. Costs of Differentiation  The next crucial determinant of whether there  will be a de facto Brussels Effect is the cost of  differentiation and how it differs from that of  non-differentiation. The higher the relative cost  of choosing differentiation, the greater the  chance of a de facto effect. As illustrated in Figure 2 above, in choosing non-differentiation,  firms avoid paying additional fixed regulatory  costs as that cost has already been borne in  choosing to stay in the EU market. They also  avoid potential duplication costs and might  face lower verification costs outside the EU. On  the other hand, they will have to pay the variable compliance costs associated with offering  an EU-compliant product outside the EU. Before exploring the costs of non-differentiation versus differentiation in more detail, it is  useful to note that whether they choose nondifferentiation depends on earlier factors.  Firstly, the smaller the non-EU’s absolute market size ( §2.1.1 ), the smaller the EU variable  compliance cost of non-differentiation compared to the fixed costs involved in differentiation. The more oligopolistic the market structure ( §2.1.2 ), the more likely it is that  companies can coordinate their compliance  strategies, e.g. choosing to all offer non-differentiated products, meaning they are not put  at a disadvantage compared to their competitors. The EU’s Code of Conduct on Countering Illegal Hate Speech Online illustrates such  oligopolistic coordination.210 The big tech  companies, including Google and Facebook,  implemented the Code of Conduct worldwide.211 We divide our discussion of the relative cost  of differentiation into four sections. We consider (i) the additional cost associated with applying the EU standards globally, (ii) the duplication costs and effects of early forking, (iii)  the non-EU compliance costs associated with  differentia tion, and (iv) the extent to which  there is existing product differentiation. 2.5.1. Variable Costs of Non-Differentiation A company choosing to offer an EU-compliant product globally would already have incurred the related fixed costs ensuring EU  compliance, but incurs the additional costs  associated with offering this product globally. If those costs are low – i.e. it is cheap  to ensure all of one’s products are EU-compliant once compliance for the products  sold in the EU has been secured – a de  facto effect is more likely.  There are some r easons to think that these  variable costs are relatively small and that the  fixed costs will be an important factor. One of DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 209Michal S. Gal and Oshrit Aviv, “TheCompetitiveEffectsoftheGDPR,” Journal of Competition Law & Economics 16, no. 3 (September 9, 2020): 349–91. 210European Commission, “TheEUCodeofConductonCounteringIllegalHateSpeechOnline:TheRobustResponseProvidedbytheEuropeanUnion.” 211Bradford, TheBrusselsEffect:HowtheEuropeanUnionRulestheWorld , chap. 6.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•45 the most important features of digital  products is that they have high fixed development costs but small variable distribution  costs. This, many economists argue, is part of  why we might expect to see digital markets  and the AI industry as winner-take-most markets.212In addition, there are trends towards  the increasing capital expenditure required to  develop frontier AI models: since around  2010, the amount of computational resources  required to train machine learning models  that advance the state of the art has doubled  approximately every 6 months.213GPT-3, a  state-of-the-art large language model developed in 2020, is believed to have cost  around 4.6 million USD to train.214Further,  some of the AI systems classed as high-risk in  the AI Act are in industries with large upfront  capital investment in product development,  such as those used in medical devices (discussed further in §2.6.2 ).  On the other hand, the development of AI systems largely consisting of fixed costs does not  necessarily mean the same holds true for  compliance with EU regulation. For example,  to comply with various regulations and demands from its users, social media companies  are increasingly investing in content moderation, employing large numbers of content  moderators. One 2021 report suggested that  Facebook had between 15,000 and 35,000  content moderators.215As long as these content moderation tasks are not possible to  automate, we should expect moderator numbers to increase almost proportionally with  the size of the customer base.216 Concretely, some of the requirements imposed  by the AI Act may produce variable compliance  costs. This could be the case for requirements  that there is human oversight over the system, in  addition to risk management and post-market  monitoring. Some costs related to these requirements would likely already have been incurred in producing an EU-compliant product for the EU  market. For example, the company would  already have put in the work of integrating their  risk management and post-market monitoring  systems into their other business practices, e.g.  updating how decisions about product launches  are made. In addition, ensuring human oversight  might require designing user interfaces for the  overseers. It could also require retraining or adjusting of the underlying AI systems such that  their outputs are more interpretable to meet the  requirement that the human overseer can “fully  understand the capacities and limitations of the  high-risk AI system.”217However , these requirements also likely involve some variable costs, as  companies would likely need to hire additional  staff for risk management, post-monitoring, and  human oversight should they adopt these requirements globally rather than only in the EU.  The extent of these costs is a crucial factor in  whether EU-compliant products will be offered  outside the EU, as well as which requirements  are more likely to be complied with outside the  EU.  2.5.2.DuplicationCostsandEarlyForking Companies’ decisions of whether to offer EUcompliant products outside the EU will  largely depend on how fundamental the  changes needed to comply with the regulations will be. The more fundamental the  changes – the earlier the “fork” in the system  – and the costlier it is for the company to  maintain two separate products, the more  likely they are to choose non-differentiation.  In short, early forking often implies high duplication costs which incentivise companies  to offer one product globally once they have  developed an EU-compliant product. One can think of the production process of an  AI system as starting in the design phase,  wherein a company or a researcher decides  what AI system they are going to produce. DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 212Varian, “ArtificialIntelligence,Economics,andIndustrialOrganization.” 213Jaime Sevilla et al., “ComputeTrendsAcrossThreeErasofMachineLearning,” arXiv [cs.LG] (February 11, 2022), arXiv 214Chuan Li, “OpenAI’sGPT-3LanguageModel:ATechnicalOverview,” Lambda, June 3, 2020 215Billy Perrigo, “‘ISoldMySoul.’WhatsAppContentModeratorsReviewtheWorstMaterialontheInternet.NowThey’reAllegingPayDiscrimination,” Time, Originally published: July 15 2021. 216Though there are likely some economies of scale as e.g. Facebook has more resources to develop efficient processes and the like.  217AI Act, art. 14 §4a.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•46 Next, data is selected, collected, or generated, which the model is subsequently trained  on. In some cases, such as in self-playing reinforcement learning systems or GANs,218training and data generation happen simultaneously. In some cases, the model will  subsequently be fine-tuned or otherwise adapted to a specific use. After some testing and  evaluation, the model may be deployed. Customers will often engage with the system via  an API or some other user interface. Once the  system has been deployed, its performance  might be regularly evaluated and reviewed.219 Depending on the exact details of the regulation and the nature of the industry, compliance  can be achieved by separating – forking – the  system at different stages in the process.  Some requirements and systems may require  early changes in the process. Requirements  that an AI system is robust to external threats  or new unseen scenarios (e.g. distributional  shifts) could require training an entirely new  system on new data or using more robust algorithms. Requirements that high-risk AI models are neither biased nor discriminatory (AI Act  Recital (44) and Art. 15(3)220) could be fulfilled in  different ways. For example, high-risk products  are required to use less biased and more representative datasets with an aim to reduce the  resulting system’s bias.221Meeting such a requirement would require early forking, in the  data-collection process, perhaps requiring systems to be retrained if their original training  data did not meet the AI Act’s requirements. In  contrast, if AI companies could meet req uirements by e.g. fine-tuning models or otherwise  adjusting them after they have been trained,  the duplication costs could be much lower. In some cases, producers can maintain two separate products cheaply, e.g., by turning off a feature or by making superficial changes to the system. This is particularly common when the  change can be made via adjustments at the top  of the “technology stack.” For instance, T esla reduced the functionalities of their autopilot for  the EU market via a software update in order to  comply with a revision of driver assistance systems regulations in 2018 while leaving their cars  in other jurisdictions unchanged.222Similarly, the  AI Act proposes requirements that people be informed when they are engaging with e.g. a chatbot. This requirement could likely be met with a  superficial change – by a late forking of the system – by changing the user interface, e.g. by  adding a prominent statement saying that an AI  system is providing the outputs or by starting  any interaction by the chatbot introducing itself  as such. There are several reasons why early forking  may produce duplication costs. A core reason  is that it may substantially weaken the economies of scale for a product. AI companies usually  have large economies of scale.223As more  people use an AI product, more data becomes  available, improving the company’s product.  So-called foundation models,224such as  BERT,225GPT-3,226CLIP,227and Gopher,228are  large deep learning models which can be  used in a very wide range of systems –  sometimes because they can perform a wide  range of tasks and other times because the  task they can do is useful in a large number of  systems. Once the foundation model is trained,  it can be used in many downstream models or  specific applications, for example after some  fine-tuning. After training, the cost of bringing it DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 218A generative adversarial network (GAN) is a machine learning framework in which two neural nets contest with each other as a learning process, where  e.g. one system attempts to create an image indistinguishable from a photo and another tries to distinguish between the photo and the generated image. 219In the real world, many of these steps are not as neat as described. They may happen in tandem, companies might skip steps, or go back a step.  Furthermore, models are often updated after deployment as new training data is found or generated.  220AI Act.  221AI Act, art. 10. 222Fred Lambert, “TeslaNerfsAutopilotinEuropeduetoNewRegulations,” May 17, 2019. 223Varian, “ArtificialIntelligence,Economics,andIndustrialOrganization” ; Avi Goldfarb and Daniel Trefler, “ArtificialIntelligenceandInternationalTrade,” in The  Economics of Artificial Intelligence: An Agenda, ed. Ajay Agrawal, Joshua Gans, and Avi Goldfarb (University of Chicago Press, 2019), 463–92. 224Rishi Bommasani et al., “OntheOpportunitiesandRisksofFoundationModels,” arXiv (2021). 225Jacob Devlin et al., “BERT:Pre-TrainingofDeepBidirectionalTransformersforLanguageUnderstanding,” arXiv [cs.CL] (October 11, 2018), arXiv. 226Tom Brown et al., “LanguageModelsAreFew-ShotLearners,” in Advances in Neural Information Processing Systems 33 (NeurIPS 2020) (34th Conference on Neural Information Processing Systems, Curran Associates, Inc., 2020), 1877–1901. 227Alec Radford et al., “LearningTransferableVisualModelsFromNaturalLanguage,” in Proceedings of the 38th International Conference on Machine  Learning, ed. Meila Marina And Tong, vol. 139, Proceedings of Machine Learning Research (PMLR, 2021), 8748–63. 228Jack W. Rae et al., “ScalingLanguageModels:Methods,Analysis&InsightsfromTrainingGopher,” arXiv [cs.CL] (December 8, 2021), arXiv.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•47 to more customers is comparatively small. Such  potential variable costs might be computing  costs, customer service, and sales. Hence, if  complying with EU regulation requires changes  to the training and modelling process of the  foundation model,229differentiation could come  with substantial duplication costs. There are also  economies of scale regarding computational  power and talent. Producing an additional  produ ct unit tends to become cheaper the more  units are already produced. Therefore, differentiating a product into a compliant and a noncompliant product may lead to higher production costs of differentiation, especially if the forking happens early on, since the firm’s production process loses some economies of scale.  Engler argues that this dynamic means platforms whose algorithms are considered highrisk (e.g. LinkedIn’s algorithms for placing job  advertisements and job candidate recommendations) are particularly likely to choose  non-differentiation.230This seems true insofar  as foundational changes are required to the  system, which seems to be the case for many  requirements. However, certain requirements  could be met via shallow changes to the  product that could just be implemented in the  EU. Such requirements could include having  sufficient human oversight or those that can  be met via fine-tuning or filtering a model. We  discuss these dynamics further in section  2.6.2.2 . 2.5.3.Non-EUComplianceCostsof Differentiation If a company chooses to differentiate – offering non-EU-compliant products outside the EU  – they incur some other additional costs.  Firstly, they’ll need to be able to identify what  customers should be offered which product.  Secondly, they’ll need to comply with the regulation of the other jurisdictions.  Unlike companies only offering one EU-compliant product worldwide, companies choosing to  differentiate their products need to identify which products are available to which customers – the companies incur an additional identificationcost. The identification cost consists of  determining what jurisdiction applies to the  transaction by e.g. checking the customer’s IP  address or asking the customer to state where  they are based. Such identification costs depend not only on how costly it is to get to a certain level of accuracy in identification but also on  the cost of misidentifying a customer. Suppose  enforcement is stringent and likely, and hence,  the cost of falsely identifying an EU consumer as  a non-EU consumer is high. In that case, a company finds it optimal to pay for a higher accuracy  in identification, which increases the costs of  differentiation. In sum, the identification cost will  largely depend on the details of the final AI legislation and how liability is distributed among  customers, distributors, and producers.  Overall, we expect identification costs to be low  and mostly fixed, not requiring that companies do  much more than make a good faith effort to check  whether EU law applies to a particular transaction.  For example, we expect companies to have fulfilled their duty if they e.g. only offer their product  on an EU app store or to EU IP addresses. However , it remains to be seen whether this will be the  case.  A company choosing non-differentiation would  also need to ensure compliance with the requirements of other jurisdictions. We expect the compliance costs of other jurisdictions to be lower  than that of the EU, as the EU seems likely to  impose some of the most stringent requirements, at least at the time they come into  force, and because other jurisdictions are  likely to ensure a reasonably high level of  compatibility with EU regulation so as to not  disadvantage their firms’ trading with the EU . Firm s may in particular experience additional  verification costs in choosing to differentiate  their products. In deploying a different product  outside the EU, they would be less able to reuse do cumentation and other assets used to  ensure E U compliance than if they had chosen DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 229Such potential regulatory responses are discussed in chapter 5, especially 5.4 of Bommasani et al., “OntheOpportunitiesandRisksofFoundationModels.” 230Engler discusses the case of LinkedIn. Engler, “TheEUAIActWillHaveGlobalImpact,butaLimitedBrusselsEffect.”
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•48 non-differentiation. This is one reason jurisdictions with significant trade with the EU may be incentivised to establish unilateral recognition  schemes with the EU, allowing CE-marked  products on their markets with out additional regulatory approval or inspection. 2.5.4.ExistingProductDifferentiation If a company has already differentiated products  between two different markets, they are more  likely to continue down that path in response to  the new EU regulation.231For illustration, suppose EU AI regul ation would require companies to use a specific quality management system (QMS),232parts of which differ from the  industry’s current practices. If a company  does not already have differentiated  products between EU and non-EU markets,  then the new stricter requirements from the  EU market have them face the choice of  whether to upgrade their global QMS or  choose to have two separate ones. If the  company has already differentiated their  products, on the other hand, and already has  two separate QMSs, then the choice is  between upgrading both systems or just one  system, presumably incurring a larger fixed  cost for compliance. Relatedly, this means  that industries where there is more product  churn, i.e. products are replaced more often,  are more likely to see companies choose  non-differentiation.  Further, if a company already has differentiated their products, that indicates that  non-differentiation is particularly costly or  that differentiation is necessary for their  product. For example, if two jurisdictions  have sufficiently dissimilar non-overlapping legal requirements, differentiating  one’s products might become a necessity.  This seems particularly common in the financial industry where companies already spend significant resources adapting their  products to different jurisdictions’ legal requirements.  Sometimes, legal requirements can effectively enforce some amount of differentiation, making a de facto Brussels Effect  less likely. Data localisation laws, also  called data residency laws, are an example  of this. They require that data about a nation’s citizen or resident m ust be processed  and/or stored inside the country. China, India, and Indonesia have such laws. A dozen  others have discussed or implemented  them.233If the EU or member states adopt  such data localisation laws, which some  considered in 2013,234it would diminish the  attractiveness of product non-differentiation as parts of the processes for non-EU  data and EU data must be separated anyway.  Similarly, requirements that AI systems used  in the EU are trained on EU data could undermine a de facto effect. For example, in the  proposed AI Act, high-risk systems are required to “take into account, to the extent required by the intended purpose, … the specific geo graphical … setting in which the  high-risk system is intended to be used.”235 This requirement could undermine a de  facto Brussels Effect, if inter preted sufficiently strictly, e.g. such that supervised learning systems deployed in the EU must be  trained solely on EU data. This would particularly be the case if other jurisdictions implement similar requirements or if companies are  reluctant to offer a produ ct trained solely on  EU data in other jurisdictions. Less strict interpretations of the requirement, allowing e.g.  fine-tuning of the system on EU data, would  have a smaller effect.DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 231Engler . 232AI Act, art. 17. 233Anupam Chander and Uyên P. Lê, “DataNationalism,” Emory Law Journal 64, no. 3 (2015): 677 234Data localisation discussions also happened in the EU. In 2013, both France and Germany considered such rules. ChanderandLê,690ff . 235AI Act, art. 10 §4.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•49 2.6. Likelihood of a De Facto  Brussels Effect for Different  Industries and Regulatory  Requirements The above sections suggest that the AI industry as a whole may have many of the features that make a de facto Brussels Effect  more likely. However, what holds for AI in  general might not hold for the specific industries and AI systems that the EU AI regulation  will apply to. Though it is difficult to make  predictions on how these will interact – especially before the legislation has been finalised – this section offers some tentative predictions. The most common reasons we find  that a Brussels Effect might not occur is if (i)  the industry or compliance within it is already  regionalised (as discussed in §2.1 and parts  of §2.5 ), (ii) compliance with the requirements does not require early forking (as discussed in §2.5 ), (iii) the additional cost of  compliance with EU regulation abroad is  large even once compliance for EU products  has already been secured, and (iv) compliance with EU regulation does not increase  perceived product quality outside the EU,  making up for the additional compliance  costs.  We focus on the AI Act and updates to the  product liability regime. However, both the  DSA and the DMA could substantially influence the AI industry, and we encourage  other researchers to investigate their likelihood of de facto diffusion. This section proceeds by looking at particular requirements that will be introduced,  what industries and systems these requirements may affect, and discussing whether  the factors described above make a de facto  Brussels Effect likely or not. Section 2.6.1 explores the chance of a de facto effect in the  realm of limited-risk systems. Section 2.6.2focuses on high-risk systems, which will receive the most detailed discussion. Section  2.6.3 discusses prohibitions of certain limited-risk systems. Finally, section 2.6.4 concerns updates to the EU liability regime. 2.6.1.TransparencyObligationsforSomeLowerRiskAISystems The Commission’s proposed AI Act includes  provisions requiring deployers to inform users  if their system (i) interacts with humans and  (iia) is used to detect emotions or determine  association with (social) categories based on  biometric data, or (iib) generates or manipulates content, e.g. deep fakes or chatbots.236 As the costs of differentiation as well as the  regulatory costs for such systems are likely to  be low, we argue that a de facto Brussels  Effect is plausible insofar as norms shift such  that customers come to see disclosure as a  sign of a company or product being trustworthy.237 The differentiation costs and the compliance costs associated with these transparency requirements are likely low. A company using chatbots on their website can  comply with this requirement by adding a  small text box telling the customer they are  engaging with an AI system or starting the  conversation with the chatbot identifying itself as such. The differentiation costs are  similarly low. Companies could identify  whether a user is covered by EU law or not  via their IP address and make a slight  change to the user interface, e.g. by adding  a disclosure note. The revenue from non-differentiation depends on the preferences of non-EU consumers. A disclosed chatbot might be less  effective in providing customer service and  satisfaction. At the same time, norms around  the disclosure of AI systems could provide a  reputational boost from non-differentiation, DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 236However, Veale and Borgesius criticise the transparency obligation for category (iii) as being unenforceable. How can a market surveillance authority  find the undisclosed deep fakes? Veale and Borgesius, “DemystifyingtheDraftEUArtificialIntelligenceAct—AnalysingtheGood,theBad,andthe  UnclearElementsoftheProposedApproach.” . See also AI Act, Title IV. 237This is in contrast to Engler, who thinks it is more likely. Engler, “TheEUAIActWillHaveGlobalImpact,butaLimitedBrusselsEffect.”
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•50 by e.g. notifying non-EU customers if they are  engaging with a c hatbot. Consumers might  be distrustful of a company that has a reputation for not disclosing AI systems. In this  case, non-EU consumers would be unresponsive ( §2.4 ) because they prefer disclosure – increasing the revenue from non-differentiation and making a de facto Brussels  Effect more likely. Another factor is the extent to which non-EU customers would punish actors for holding a “double standard”,  having different transparency policies in the  EU and elsewhere. We could get a sen se of the chance of a Brussels Effect of such transparency obligations  by considering California’s 2018 Bot Disclosure Act.238This law requires some companies  interacting with Californian consumers, including importers to California, to highlight  when a user interacts with a bot. “Any publicfacing internet website, web application, or digital application” with more than ten million  unique monthly American visitors, i.e., the 80  most popular websites,239must disclose  bots.240Some commentators expected the  Bot Disclosure Act to exhibit a California  Effect.241Unfortunately, to date, no impact assessment or similar evaluation has been published to evaluate the California Effect of the  BOT Act. 2.6.2.ConformityAssessmentsforHigh-Risk  AISystems What parts of the E U’s regulation of high-risk  AI regulation are most likely to see a de  facto Brussels Effect? To answer this question, we first look at what high-risk uses of  AI (including in which industries) and what  requirements from the draft AI Act are most  prone to seeing de facto diffusion. For a re-cap of what systems are classified as highrisk and what requirements are imposed on  them, please refer back to section 1.1.2 and  Table 1 . 2.6.2.1. What High-Risk Uses of AI Are  Most Likely to See a De Facto Effect? We believe that we’ re most likely to see de  facto regulatory diffusion in the use of AI in  the following domains: (i) many of the  products already covered by existing  product safety regulation under the New  Legislative Approach, most notably medical devices; (ii) worker management, including hiring, firing, and task allocation;  (iii) some general AI systems or foundation  models used across a wide range of uses  and industries; and (iv) less confidently, the  use of AI in the legal sector and the use of  biometric identification and categorisation  of natural persons.242We argue that most  other uses considered high-risk in the proposed AI Act will not see a strong de facto  Brussels Ef fect, as the market structure or the  product differentiation is already regionalised  (see §§2.1.2 and 2.5). This is partly because  many of the uses deemed high-risk in the AI  Act are government uses of AI.  The majority of the high-risk uses of AI outlined  in the AI Act’s Annex III concern government  uses of AI, which naturally pushes in favour of a  regional market structure. These uses include  management and operation of certain critical infrastructure (e.g. road traffic); admission and  grading within educational settings; decisions  regarding granting or revoking access to public  benefits; various uses by law enforcement; uses  in migration, asylum, and border control management; and AI systems to assist judicial authorities (e.g. courts) in their work.243DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 238California Senate, “AnActtoAddChapter6(commencingwithSection17940)toPart3ofDivision7oftheBusinessandProfessionsCode,Relatingto  Bots,” Pub. L. No. 1001, CHAPTER 892 (2018), http://bcn.cl/2b6q3. It is also known as the BOT (“Bolstering Online Transparency”) Act or California Senate  Bill 1001. 239Quantcast, “AudienceMeasurement&AnalyticsPlatform,” Quantcast (Quantcast Inc, August 30, 2020). 240California Senate, AnacttoaddChapter6(commencingwithSection17940)toPart3ofDivision7oftheBusinessandProfessionsCode , relating to bots. 241CITRIS Policy Lab, “Fair,Reliable,andSafe:CaliforniaCanLeadtheWayonAIPolicytoEnsureBenefitsforAll,” Medium, May 28, 2019. The regulatory  diffusion of California legislation is often compared to the EU's regulatory diffusion. Historical examples for a “California Effect” include data privacy,  food safety, and vehicle regulation. Bradford, TheBrusselsEffect:HowtheEuropeanUnionRulestheWorld . California is frequently among the earliest  US states to adopt new legislation to strengthen democratic ideals, consumer rights, and individual freedom or rights. 242The first two of these four groups are also discussed in Engler, “TheEUAIActWillHaveGlobalImpact,butaLimitedBrusselsEffect.” 243AI Act, annex III.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•51 Beyond these government uses of AI, additional high-risk uses outlined in Annex III appear  to either have a regional market structure or  already have products differentiated along regional lines. One such example is the management and operation of critical infrastructure  such as the supply of water, gas, heating, and  electricity.244Though the market in these industries tends to be slightly more globalised earlier  in the supply chain (e.g. in producing and trading electricity), the markets for supplying these  commodities tend to be fairly regionalised, making a de facto Brussels Effect significantly less  likely.  High-risk uses of AI in the financial sector also  seem unlikely to us to see a de facto Brussels  Effect, due to a regionalised market structure  and having products differentiated along regional lines. Though the financial sector as a  whole is reasonably globalised, especially with  regard to financial services for corporations and  with regard to investment, the particular financial-sector uses picked out by the AI Act see less  globalisation: assessments of cred itworthiness  or credit scores of natural persons.245Such assessments tend to be carried out by national or  regional companies, partly because of differences in rules and regulations between jurisdictions.  There is still some chance that we will see a de  facto effect in these regionalised domains. The  most plausible mechanism by which this would  happen is if the provision of AI systems for these  uses is globalised – that is, if e.g. governments  procure systems for the high-risk uses and  those vendors are global actors – and/or if  compliance with EU requirements becomes  seen as a quality signal. The latter could end up  being the case, especially since these uses of  AI (e.g. the use of AI for admission decisions),  are likely to be controversial. Whether this effect ends up strong enough to produce a de  facto effect remains to be seen.  Moving on to the uses of AI we think are more  likely to see a de facto Brussels Effect, many of  the high-risk uses of AI in domains already  covered by other product safety regulations  appear likely to see a de facto Brussels Effect.  Such products (listed in the AI Act’s Annex II)  notably include medical devices and in vitro  diagnostic medical devices, but also another  ten domains already covered by product safety  regulation including machinery, personal protective equipment, radio equipment, and  toys.246 Medical devices seem likely to see a de facto  Brussels Effect if new requirements are introduced, as medical device companies tend to  produce one product for the global market and  are unlikely to leave the EU market. The medical device industry is large and dominated by  US- and EU-based companies. The EU being  one of the regions with the highest consumption of medical devices,247it seems unlikely that  companies will exit the EU market. Fur ther,  companies tend to offer one product globally,  seeking to ensure it is compliant with both EU  and US requirements (such compliance will as  a rule allow the product to enter many other  markets too).248This is partly because EU and  US requirements tend to be the most strict249 and because product differentiation tends to  be costly. A large part of the development  cost for medical devices is running studies to  prove their safety and efficacy,250and so any  changes that would require re-running those  studies would likely cause huge increases in  costs. As such, if the AI Act introduces new  requirements, it seems likely that companies will attempt to remain compliant with the  EU regulation globally.DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 244AI Act, annex III, §2. 245AI Act, annex III, §4b. 246Engler. 247Observatory of Economic Complexity (OEC), “MedicalInstruments,” OEC, accessed july, 09 2022. 248Industry & Analysis, “2016 Top Markets Report Medical Devices: A Market Assessment Tool for U.S. Exporters” ( International Trade Administration,  U.S. Department of Commerce, May 2016). 249Christa Altenstetter and Govin Permanand, “EU Regulation of Medical Devices and Pharmaceuticals in Comparative Perspective,” The Review of  Policy Research 24, no. 5 (September 2007): 385–405; EMERGO, “Europe Medical Devices Regulation (MDR) CE Marking Regulatory Process,”  EMERGO, August 23, 2017 250Aylin Sertkaya, Amber Jessup, and Rebecca DeVries, “Cost of Developing a Therapeutic Complex Medical Device for the U.S. Market,” 2019.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•52 A deeper investigation into whether de facto  diffusion is likely for machinery covered by  existing EU product safety regulation appears interesting, as AI systems are particularly like ly to have a large impact in manufacturing and because the consumption of  machinery plausibly has higher responsiveness than other goods covered by existing  product safety regulation. Much machinery will  be purchased and used by companies engaged in manufacturing, who could move thei r operations to countries with less stringent requirements on autonomous manufacturing  equipment should the AI Act prove too onerous.  There are a number of other industries also  covered by EU-wide product safety regulation  under the so-called “Old Approach”, including  automotive and aviation. Though these  product safety regulations are not directly  affected by the proposed AI Act – the AI Act  specifically says that only Article 84, which concerns the Commission’s duties to evaluate the  AI Act’s effects and implementation, will apply  to Old Approach product safety regulation –  the recitals of the AI Act state that the ex ante  requirements for high-risk systems “will have  to be taken into account when adopting relevant implementing or delegated legislation under those acts”. Aviation and automotive typically involve large fixed development and  production costs, incentivising companies to  produce one product for the global market, as  illustrated e.g. in Vogel’s early study of the California Effect.251As such, if the AI Act’s requirements for high-risk systems end up being applied to Old Approach product safety  regulation, it seems likely that it would produce  a de facto effect. What about general AI systems or “foundation  models”252that are used across a wide range of  applications? Examples of such systems include  general purpose visual recognition systems that  could be used for a wide range of tasks such as  identifying whether a video includes a certain  branded product. There are four routes by  which these systems end up complying with the  requirements for high-risk systems, potentially  creating a Brussels Effect. Providers of general  AI systems may (i) have legal requirements imposed on them in the AI Act, (ii) have contractual  duties to ensure compliance with some requirements, (iii) see reputational benefits from compliance, or (iv) want to directly apply the system  to high-risk domains, therefore incurring the relevant duties.  Whether providers of general purpose AI systems will have requirements imposed on them  by the AI Act is a matter of ongoing discussions  between the EU Council, Parliament, and Commission. While the originally proposed AI Act did  not include any language about general purpose systems, proposed updates to the act do.  In November 2021, the EU Council’s Slovenian  presidency proposed amendments to the AI Act  in a compromise text, according to which general purpose AI systems would not be considered high-risk unless they are explicitly intended for high-risk uses.253In contrast, a May 2022  compromise text b y the subsequent French  presidency of the Council would impose duties  on general purpose AI systems that may be  used by other actors in high-risk applications.254Such systems would need to comply  with a subset of the r equirements for high-risk  systems, concerning e.g. risk management,  data and data gov ernance, post-market monitoring, accuracy, and robustness.255The pro-DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 251See e.g. Vogel, TradingUp:ConsumerandEnvironmentalRegulationinaGlobalEconomy. 252Bommasani et al., “OntheOpportunitiesandRisksofFoundationModels.” 253European Parliament, “Regulation(EC)No1907/2006oftheEuropeanParliamentandoftheCouncilof18December2006ConcerningtheRegistration,Evaluation,AuthorisationandRestrictionofChemicals(REACH),EstablishingaEuropeanChemicalsAgency,AmendingDirective1999/45/EC  andRepealingCouncilRegulation(EEC)No793/93andCommissionRegulation(EC)No1488/94asWellasCouncilDirective76/769/EECandCommissionDirectives91/155/EEC,93/67/EEC,93/105/ECand2000/21/EC”article52a. 254La Présidence Française du Conseil de l’Union européenne, “PropositiondeRèglementDuParlementEuropéenetDuConseilétablissantDesRègles  HarmoniséesConcernantL’intelligenceArtificielle(législationSurL'intelligenceArtificielle)etModifiantCertainsActesLégislatifsdel'Union-Textede  CompromisdeLaPrésidence-Article3,Paragraphe1Ter,Articles4Bisà4Quater,AnnexeVI(3)et(4),Considérant12BisBis,” May 13, 2022. 255Specifically, they would comply with requirements from the AI Act regarding having a risk management system (Art. 9), data and data governance  (Art. 10), technical documentation (Art. 11), providing users with explicit instructions for use (Art. 13(2) and (13)(3)(a) to (e)), and requirements surrounding accuracy, robustness, and cybersecurity (Art. 15). They would also need to comply with additional requirements regarding e.g. providing their  customers with information needed for their compliance, conducting a lighter conformity assessment, and conducting post-market monitoring. La  PrésidenceFrançaiseduConseildel’UnioneuropéenneArt.4b.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•53 posal includes exemptions for small and medium enterprises as well as general systems  where the provider has explicitly excluded  any high-risk uses in the instructions of use for  the system.256 It seems plausible that there would be a  Brussels Effect for some general purpose  systems offered by large corporates if something similar to the French presidency’s proposal becomes law. This effect could be  dampened if companies choose to not allow  their system to be used for high-risk uses in  an effort to avoid potential controversial uses  of their systems. For example, OpenAI’s usage guidelines for their natural language  model GPT-3 explicitly disallows some uses  – for example applications that “help determine eligibility for credit, employment, housing, or similar essential services” – that the AI  Act would classify as high-risk.257Companies’  postures could change as the market in  these areas grows and as it becomes clearer  that negative effects in high-risk domains  can be avoided. Incentives to have general AI systems fulfil AI  Act requirements on high-risk systems could  also come from customers adapting the AI  system to high-risk uses. For example, a  company might wish to use a large language  model such as GPT-3 or Gopher to summarise candidates’ answers to questions in a hiring process. It may be difficult to build a compliant high-risk system using a non-compliant  general purpose system, in which case ensuring the general system’s compliance with  some of the AI Act’s requirements could become a contractual obligation. Such contracts could allow the provider of the general  system to charge a premium and would likely  benefit both parties, assuming it would be  cheaper for the provider of the general system to comply with the relevant requirements than for the purchaser to do so. Some requirements might fairly straightforwardly create such demand, such as requirements that the training procedure of  the relevant AI system be included in a highrisk system’s technical documentation.258 Other requirements concern the behaviour  of the model, such as its accuracy in the target setting. Whether this ends up requiring  adjustments to a general model adapted for  a high-risk use is largely an empirical question of how much the behaviour of an AI system can be shaped by e.g. fine-tuning it –  that is, training the system on some additional data more relevant to a desired task –  or filtering its outputs. If it is easier to ensure  compliance by making changes further  down in the technology stack, no changes  to the general system may be necessary.  There is ongoing work on this question in  e.g. the domain of natural language processing,259and it remains to be seen if such  tools will be sufficient or whether it is advantageous to instead train the foundation  model itself with compliance in mind.  Providers of general models may also be incentivised to ensure compliance with requirements for high-risk systems if it provides a  boost to their reputation. Compliance with the  high-risk requirements seems likely to be a  strong quality signal. Indeed, it is plausible  that some general models widely available  today via APIs from companies such as  Google, Hugging Face, Microsoft, and  OpenAI are already compliant with many of  the AI Act’s requirements for high-risk systems.  The AI Act classifies a number of worker management tools as high-risk, including those  that assist with or make decisions about access to employment or self-employment opportunities and task allocation. There has  been significant growth in such tools over the  past few years, in particular those used to assist with hiring decisions and to allocate tasks DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 256Though the exemption would not hold if there were sufficient reason to believe the system would be misused. La Présidence Française du Conseil  de l’Union européenne Art. 4c and 55a. 257OpenAI, “UsageGuidelines(responsibleUse):AppReview,” OpenAI’s API, accessed July 13, 2022. 258See AI Act, annex IV §2. 259See e.g. Irene Solaiman and Christy Dennison, “Process for Adapting Language Models to Society (PALMS) with Values-Targeted Datasets,” Advances in Neural Information Processing Systems 34 (2021).
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•54 on a micro level. The latter category includes  gig economy companies’ (e.g. Uber’s) use of AI  systems to allocate jobs to different workers  and the use of such systems in warehouse management260and by fast food companies.261 We are unsure whether the AI Act will produce a  de facto Brussels Effect for worker management  systems. On the one hand, uses of AI in these domains may be controversial – e.g. as evidenced  by the negative press Amazon received when  news broke that the CV screening system they  used was biased in favour of male applicants262– pushing companies to voluntarily comply with  stricter standards. On the other hand, it could be  that meeting the EU requirements has a significant negative impact on the performance of the  system. There might also be other pressures towards differentiation: the same traits may not be  indicators of a successful employee across regions, encouraging companies to train or finetune their AI systems for different jurisdictions. If  worker management systems are provided on international platforms, such as LinkedIn for job applications, a de facto Brussels Effect is likely because the costs of differentiation are higher .263 There is also a possibility of a de facto Brussels Effect in domains where companies have  particularly large needs to build trust in their  products. For example, this m ay be the case in  use cases that are seen as controversial or  sensitive, such as technologies for legal work  or in using biometric data to categorise or  identify individuals. In the former case, even  though the software is used by lawyers at  private firms rather than by the judicial authorities and would therefore not be covered by  the regulation, compliance with the strictest  possible standards is likely to be important for  customers.  In addition to the above, the AI Act’s requirements for high-risk systems might come to be seen as the gold standard for respon sible AI development and deployment. If so, these requirements could produce a de facto effect for systems that the AI Act does not consider high-risk.  This effect could be further bolstered if influential voluntary codes of conduct that the AI Act  encourages are set up and include requirements similar to those for high-risk systems.264 Whether such diffusion of high-risk requirements to non-high-risk sys tems, not only inside  the EU but also outside it, will take place is difficult to tell.  In summary, we believe that a de facto effect is  particularly likely for any changes to requirements in existing product safety regulation (e.g.  for medical devices) and that there may be a de  facto effect for general AI systems, worker  management systems, and other domains  where compliance with the AI Act is likely to be  a strong quality signal. A de facto effect connected to a number of high-risk uses of AI,  such as the use of AI in law enforcement or in  the financial sector, is made unlikely by the regionalised compliance or market structure.  Lastly, we may see de facto diffusion beyond  high-risk systems if the AI Act’s requirements  on high-risk uses of AI comes to be seen as the  gold standard for responsible AI development  and deployment. 2.6.2.2.WhatRequirementsforHigh-RiskAI SystemsAreMostLikelytoProduceaDe FactoEffect? The chance of a de facto effect differs not only  between high-risk uses of AI but also between the  requirements imposed on such systems. Which requirements are most likely to produce a de facto effect depends on a complex interaction of e.g. the  factorsoutlinedinsections 2.4and2.5.Thedevilwill  be in the details. Below, we will explore these dynamics for a subset of the requirements imposed  by the AI Act: those pert aining to data and data DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 260Arthur Cole, “AITechnologyModernizesWarehouseManagement,” November 1, 2021. 261Alex Glenn, “SpanishStartupReducedMcDonald’sWaitingTime,” August 26, 2021. 262Jeffrey Dastin, “AmazonScrapsSecretAIRecruitingToolThatShowedBiasagainstWomen,” REUTERS (Reuters, October 10, 2018). 263Engler, “TheEUAIActWillHaveGlobalImpact,butaLimitedBrusselsEffect.” 264AI Act, Title IX.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•55 governance, risk management systems and postmarketmonitoring,andtechnicaldocumentation,a s well as ac curacy, robustness, and cybersecurity.  First, the AI Act would introduce requirements  on the data used to train, validate, and test highrisk AI systems. The data should e.g. be “relevant, representative” and “have the appropriate  statistical properties”. At first glance, these requirements seem likely to produce a de facto  effect. They would often have effects early on in  the system’s life cycle, thus requiring early forking and introducing high costs to differentiation.  Once the costs for adaptation of the data-collection process are paid, using the same compliant  data for non-EU products might not be costly –  provided there are no steep trade-offs between  less biased and more accurate AI models.265 However, the requirements on data could undermine a de facto effect of the AI Act if they require training on local data; that is, if they require  or encourage companies to use EU data for AI  systems deployed in the EU. This would undermine a de facto effect as it would effectively  force companies to differentiate their products  between different jurisdictions. Such differentiation in turn lowers the chance of a de facto  effect as the cost of maintaining two different AI  systems has already been taken on (for details,  see §2.5 ). Parts of the requirements could be  read as encouraging training on local data: data  is meant to be “relevant [and] representative”,  and datasets should take into account “the characteristics or elements that are particular to the  specific geographical … setting within which the  high-risk AI system is intended to be used.” Second, the AI Act imposes requirements regarding internal company processes, such as  requiring there be adequate risk management systems and post-market monitoring.  Such requirements could produce a de facto  effect by causing more companies to set up  new processes and apply them globally, or if their existing processes are brought up to the  AI Act’s standards globally. If a company does  set up a new risk management system as a  result of the AI Act, it seems plausible to us  that such systems will often be applied worldwide, as companies commonly have risk management functions and the cost in setting up  such a system might be primarily fixed.266 The risk management and post-market monitoring requirements could also produce a de  facto effect indirectly. Even if the AI Act’s requirements do not diffuse outside the EU, such  enhanced risk management procedures could  identify risks and issues within the EU that  companies may feel compelled to address  globally. This would particularly be the case if,  for instance in the eyes of US courts, companies would have good reason to believe that the  problem identified in the EU would also exist in  the US. Speculatively, this could push some  companies away from de facto diffusion if they  wish to ensure that faults or risks identified for  their EU products are not applicable to the rest  of the world, causing them to differentiate their  products and risk management teams. Third, the AI Act introduces requirements on  documentation of companies’ AI systems, to  be shared with regulators267and users.268Similar to “model cards,”269an AI system should be  accompanied by information about its intended purpose, accuracy, performance across  different groups and contexts, likely failure  modes, and so on. Once such documentation  has been created, it will likely be advantageous  to provide it to the market outside the EU, insofar as the docu mentation is applicable to  those systems. It is a service which some  customers might appreciate and few will object to.  Fourth, requirements on accuracy, robustness, and cybersecurity of AI systems (Art.  15) are likely to exhibit a de facto Brussels DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 265Bommasani et al., “On the Opportunities and Risks of Foundation Models,” sec. 5.4. 266“setting up a new QMS may cost EUR 193,000–330,000 upfront plus EUR 71,400 yearly maintenance cost.” Renda et al., “StudytoSupportanImpact  AssessmentofRegulatoryRequirementsforArtificialIntelligenceinEuropeFinalReport(D5),” 12. 267AI Act, art. 11.  268AI Act, art. 13. 269Margaret Mitchell et al., “ModelCardsforModelReporting,” arXiv [cs.LG] (October 5, 2018), arXiv.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•56 Effect insofar as they (i) lead to updates in  the relevant underlying models, (ii) will not  substantially reduce product quality for nonEU consumers, and (iii) mainly consist of  fixed costs. A 2021 study for the Commission suggests that the requirement could be  implemented through technical solutions,  e.g. tests against adversarial examples,  model flaws, controlled studies in real-world  conditions, and brainstorming of possible external threats.270This knowledge produced  will then likely also affect the robustness of  the products sold outside the EU.  To conclude, based on our cursory assessment, requirements regarding accuracy, robustness, cybersecurity, and documentation  seem reasonably likely to produce a de facto  effect. We may see a de facto effect with regard to the data requirements, so long as  they do not introduce strong requirements to  train on local data. 2.6.3.ProhibitedAIPractices The proposed AI Act bans certain AI applications, including (i) certain “real-time” biometric identification systems for law enforcement, (ii) AI-based social scoring, and (iii) AI  systems used for subliminal manipulation.  For the most part, we should expect bans to  not produce a de facto effect, as companies  would simply not offer prohibited products  on the EU market.  Howe ver, there are two mechanisms by which  prohibitions could contribute to a de facto  effect. Firstly, some products that engage in  prohibited uses can be adjusted to steer clear  of prohibited uses. In such cases, there is a  possibility of a de facto effect if it is advantageous to remain in the EU market, make the  necessary changes, and apply those changes  globally. Secondly, prohibitions in the EU could change consumer preferences abroad,  making it more likely that companies could  see reputation al risks by offering EU-prohibited applications outside the EU.  The first mechanism may be important with  regard to the proposed prohibition of “subliminal techniques ... to materially distort a  person’s behaviour in a manner that causes  ... physi cal or psychological harm”.271Depending on the interpretation of such a ban, many AI  systems, e.g. those used for content moderation, could run the risk of engaging in prohibited uses. Should language similar to this make  it into the final text – though it seems far from  likely that it will272– companies are likely to put  a lot of effort into ensuring that their systems  are not considered manipulative, likely making  changes early in the production process, potentially causing a de facto Brussels Effect.  The second mechanism could play a role in the  prohibitions on social scoring and “real-time”  biometric identification systems used by law  enforcement. We might expect the latter to  have some effect on multinational AI companies, seeing as many of them have already  made commitments not to offer remote biometric identification to law enforcement. In  2020, Microsoft, Amazon, and IBM all announced that they would not offer facial recognition technology to US police departments or  for their use on body camera footage.273 A de jure Brussels Effect is more likely fo r these  prohibitions. We consider such a de jure Brussels Effect specifically in section 3.2 . 2.6.4.LiabilityofAISystems In addition to the AI Act, the Commission is  considering updates to the EU’s liability  rules with regard to AI systems.274Three  factors negatively affect our ability to as-DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 270Renda et al., “StudytoSupportanImpactAssessmentofRegulatoryRequirementsforArtificialIntelligenceinEuropeFinalReport(D5),” 132ff. 271AI Act, Title II, art. 5, §1a. 272We should expect forceful lobbying against there being ambiguity on this point in the final regulation. Facebook e.g. raised these concerns in their  submission to the AI Act. Facebook, “ResponsetotheEuropeanCommission’sProposedAIAct.” 273Though Microsoft noted that they may offer such products, if appropriate federal legislation is put in place.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•57 sess whether these changes will produce a  de facto effect. First, it is difficult to evaluate whether firms change decisions in response to any liability regulation. Scholars  have struggled to find such effects. Second,  for corporate actors to not simply take on  the liability but also to change trade-offs  and decisions because of the liability rules,  the liable actor along the supply chain must  be the one who can reduce the relevant risk.  Producers of AI systems, especially of increasingly generalised AI systems, could be  far removed from the end-users, potentially  limiting the number of cost-effective interventions they can undertake to reduce liability claims. If liability was placed on producers, they may be incentivised to simply take  on the liability risk or to transfer the related  costs to actors further along the AI supply  chain. Third, due to the invisibility of compliance, it is difficult to evaluate whether a de  facto Brussels Effect of product liability has  occurred in the past. Due to these uncertainties, no conclusive statement about a de  facto Brussels Effect of AI liability rules is  possible. However, we can conclude that  such regulatory diffusion is more likely if a  firm’s changes in response to the liability  rules are either at the beginning of the technology stack or entail mostly fixed costs,  such as post-market monitoring. However,  this does not necessarily mean that such interventions would be the most cost-effective  way of increasing the trustworthiness of AI  products while avoiding undue regulatory  burdens.  As of our writing, the Commission is actively  developing changes to the EU liability regime  concerning AI and other emerging technolo-gies – by either changing the Product Liability  Directive (PLD) or harmonising aspects of national civil liability law regarding the liability of  certain AI systems.275The latter could include  adopting strict liability for AI operators or the  adaptation of the burden of proof.276Hence, liability affects all categories of risks discussed  in this report. If a company conforms to all  product safety standards, it is still liable for  possible defects.277Liability regulation, complemented by product safety rules, determines who compensates users for damages incurred. Therefore, it has an ex ante  deterrence effect by encouraging companies  to adopt different internal procedures that  result in safer products.278Whether the liability  of AI exhibits de facto regulatory diffusion is  subject to several significant uncertainties,  which we’ll discuss below.  First, as the Commission has not yet published  draft AI liability rules, it is difficult to estimate its  effect on the AI industry. For instance, the extent to which the rules exhibit regulatory stringency is unknown.  Second, a firm’s response to liability regulation  is difficult to observe. In theory, one would expect that liability regulation changes the firm’s  trade-off between profits and risks of potential defects – altering their decisions.279But  how do we measure whether and how this  happens ? There is some evidence that firms  do change behaviour.280 However, because the Product Liability Directive (PLD) has not led to many court  cases,281one might suspect firms are not  strongly incentivised to change decisions because the cost of causing defects has not increased.DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 274European Commission, “Commission Collects Views on Making Liability Rules Fit for the Digital Age, Artificial Intelligence and Circular Economy,”  Internal Market, Industry, Entrepreneurship and SMEs, October, 20 2021. 275See e.g. Public consultation in October 2021: European Commission; European Commission, “InceptionImpactAssessment:ProposalforaDirective  AdaptingLiabilityRulestotheDigitalAgeandArtificialIntelligence,” June 6, 2021; European Commission, “CivilLiability–AdaptingLiabilityRules  totheDigitalAgeandArtificialIntelligence,” European Commission, 2021. 276European Commission and Directorate-General for Justice and Consumers, Liability for Artificial Intelligence and Other Emerging Digital Technologies  (Publications Office of the European Union, 2019); European Commission, “InceptionImpactAssessment:ProposalforaDirectiveAdaptingLiability  RulestotheDigitalAgeandArtificialIntelligence.” 277“The EU Product Liability Directive (PLD), that governs the responsibility for such defects, should be applied ‘without prejudice’ to the product safety  regime” European Parliament, “Directive2001/95/ECoftheEuropeanParliamentandoftheCouncilof3December2001onGeneralProductSafety  (TextwithEEARelevance),” CELEX number: 32001L0095, Official Journal of the European Union L 11, January 15, 2002, 4–17, art. 17. 278Andrea Bertolini, ArtificialIntelligenceandCivilLiability , PE 621.926 (European Parliament, 2020) 279John Prather Brown, “TowardanEconomicTheoryofLiability,” The Journal of Legal Studies 2, no. 2 (June 1, 1973): 323–49. 280Benjamin van Rooij, Megan Brownlee, and D. Daniel Sokol, “DoesTortDeter?InconclusiveEmpiricalEvidenceabouttheEffectofLiabilityinPreventingHarmfulBehaviour,” in The Cambridge Handbook of Compliance (Cambridge University Press, 2021), 311–25.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•58 In addition, the liability ought to fall on the  actor along the production process who can  reduce the likelihood and severity of a defect.  Some developers of AI systems, especially of  increasingly generalised AI systems, are far  removed from the end-users, limiting the  number of cost-effective interventions they  can undertake to reduce liability claims. In this  case, a profit-maximising producer would conceivably buy liability insurance, accept the risk  of liability claims, charge higher prices for  their system, or transfer some of the risks to  users of their system via contractual means.  And if firms are not reacting to liability  changes, the reaction cannot diffuse to other  world regions. For EU AI l iability law, developers likely hold  some liability.282In the PLD, “all producers involved in the production process should be  made liable”.283Hence, theoretically, all actors along the supply chain – who can reduce  the likelihood and severity of AI risks – also  have liability.  Third, the de facto regulatory diffusion of AI liability law is difficult to estimate. We find no  evidence on whether the PLD has exhibited a  de facto Brussels Effect. As noted above, firms’  response to liability regulation is not easily observable. It is even more difficult to evaluate  whether the response not only occurred but  also diffused to other world regions. Taken together, this should reduce our credence in de facto diffusion of the corporate  responses to AI liability rules.  Nonetheless, we now turn our attention towards non-differentiation for responses to liability regulation. We can conclude some gen-eral trends. Suppose the liability incentivises  actors to undertake more post-market monitoring than required for high-risk AI systems by  the EU AI Act. In that case, a de facto Brussels  Effect is likely because of the low costs of  non-differentiation – monitoring may be  mostly a fixed cost. Besides, if the most costeffective interventions to reduce defects are  early in the technology stack, the costs of  differentiation are much higher – increasing  the likelihood of a de facto Brussels Effect.  Hence, if the liable actors are the producers of  foundation models, they are less likely to divide compliance284and produce two different  products. However, suppose instead that only  downstream deployers respond to the liability  or that the API access and interface of the  foundation model will be changed. In that  case, a de facto Brussels Effect is less likely  because the costs of differentiation are lower.  It is a completely different question as to  whether compliance early or later on the stack  is the most desirable, i.e. most cost-efficient,  in achieving its regulatory aims.  To conclude, it is unclear whether changes in  liability rules for AI systems will produce a de  facto effect. This is because there is little evidence on whether and how liability rules in the  EU have changed company behaviour, there  is even more uncertainty about whether such  changes have had impacts outside the EU,  and it is not yet clear how the liability of AI systems will be distributed across the AI supply  chain. If liability requires changes early on in  the tech nology stack, e.g. changes to the  training of a foundation model, or requires  changes that once made are cheap to apply  outside the EU, a de facto effect seems more  likely.DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 281“From2000to2016,thosesufferinginjuriesbroughtatleast798claimstocourtinvokingtheProductLiabilityDirective;however,itislikelythat  morecasesweredecidedincourtandevenmoreweresettledoutofcourt.” European Commission et al., “Evaluation of Council Directive 85/374/ EEC on the Approximation of Laws, Regulations and Administrative Provisions of the Member States Concerning Liability for Defective Products:  Final Report” (European Union, 2018). 282European Commission, “CommissionStaffWorkingDocumentLiabilityforEmergingDigitalTechnologiesAccompanyingtheDocumentCommunicationfromtheCommissiontotheEuropeanParliament,theEuropeanCouncil,theCouncil,theEuropeanEconomicandSocialCommitteeand  theCommitteeoftheRegionsArtificialIntelligenceforEuropeSWD/2018/137Final,” CELEX number: 52018SC0137, April 25, 2018; European Commission, “InceptionImpactAssessment:ProposalforaDirectiveAdaptingLiabilityRulestotheDigitalAgeandArtificialIntelligence.” 283“Consolidated Text: Council Directive 85/374/EEC of 25 July 1985 on the Approximation of the Laws, Regulations and Administrative Provisions  oftheMemberStatesConcerningLiabilityforDefectiveProducts,” CELEX number: 01985L0374-19990604, June 4, 1999, recital 4 and art. 3. 284See Bommasani for potential interventions which could reduce the defects of foundation models. Bommasani et al., “OntheOpportunitiesandRisksof  FoundationModels.”
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•59 2.7. De Facto Brussels Effect  Conclusion In this section, we explored the dynamics of  the de facto Brussels Effect and applied  those to the context of AI and the EU AI Act.  We conclude that the AI industry as a whole  has many of the features needed to produce  de facto regulatory diffusion. We also conclude that some parts of the EU’s proposed  AI Act are likely to produce a de facto effect.  First, we outlined five factors which determine  the likelihood of a de facto Brussels Effect,  building and expanding on Anu Bradford’s  work285and arguing that these factors looked  reasonably favourable to a de facto effect in  the AI industry. The current and prospective  market for AI products in the EU is large. The  EU accounts for 5 to 20% of worldwide AI  spending. Moreover, multinational and oligopolistic firms dominate the AI industry – making non-differentiation more attractive (see  §2.1). The EU’s regulatory capacity is strong,  including the expertise, ability, and interest to  sanction non-compliance (see §2.3 ).  Further, EU AI regulation is expected to be  more stringent than other jurisdictions’ regulation because of the EU’s regulation-friendly  public opinion and regulatory culture (see  §2.2 ). In addition, the regulatory process is  ahead of other major jurisdictions, potentially  providing the EU with a first mover advantage  (see §2.3.4 ). However, some worry that the  proposed AI Act will place excessive demands  on AI companies, potentially leading to reduced consumption of and investment into AI  products in the EU (see §2.4 ). If some requirements are redesigned and hence less costly,  there could be significantly smaller effects on  the EU AI industry. EU consumers are unlikely  to start consuming non-EU products(e.g. by  moving out of the EU), though some might use  non-EU VPNs to access AI systems online.  Next, we explored the dynamics of non-differentiation, arguing that early forking, high perceived product quality as a result of compliance, and low variable costs to complying beyond the EU once EU compliance is secured are important factors in making a de  facto Brussels Effect more likely.  Second, we applied the above framework to  the specific requirements set out in the AI  Act on prohibited, high-risk, and limited-risk  uses of AI (see §2.6 ). Narrowing down on  these particular requirements, the EU AI Act  appears less likely to produce a de facto  effect than the previous sections might indicate, e.g. as the act focuses heavily on government and regional uses of AI.  In the Commission’s proposed AI Act, certain  AI applications, such as chatbots and deepfakes, have transparency requirements – it  must be disclosed that they are AI products.  In this case, the costs of differentiation are  low because only the interface has to be  changed. He nce, a de facto Brussels Effect  would only occur if the non-EU consumers  value disclosure or if the reputational costs of  differentiation are substantial.  High-risk AI practices are subject to product  safety requirements under the proposed AI  Act. De facto diffusion in cases where the  product is regionalised, e.g. because it is used  by governments or because the industry  already differentiates products between jurisdictions (such as in the financial sector or with  regard to some critical infrastructure), is less  likely. It is only likely to happen insofar as the  AI Act’s high-risk requirements come to be  seen as the gold standard of responsible use  of AI or if provision of these products is globalised, though the use is regional.  We believe that we’re most likely to see de  facto regulatory diffusion in the high-risk use  of AI in the following domains: (i) many of the  products already covered by existing  product safety regulation under the New Legislative Approach, notably medical  devices; (ii) worker management, including  hiring, firing, and task allocation; (iii) some  general AI systems or foundation models DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 285Bradford, “TheBrusselsEffect” ; Bradford, TheBrusselsEffect:HowtheEuropeanUnionRulestheWorld.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•60 used across a wide range of uses and industries; and (iv) less confidently, the use  of AI in the legal sector and the use of biometric identification and categorisation of  natural persons. There could also be diffusion of these standards outside high-risk  uses of AI if the requirements become  seen as the gold standard of responsible  AI development and deployment. We also  explore which requirements on high-risk  AI systems are most likely to see a Brussels Effect, highlighting requirements regarding data, risk management, documentation, and the accuracy, robustness,  and cybersecurity of high-risk AI systems  as reasonably likely to see diffusion.  Depending on the interpretation of the  outright prohibitions in the final AI Act,  many AI systems, particularly those used  for content moderation, risk bein g banned.  Should such strict language make it into  the final legislation, companies will likely  invest heavily in ensuring that their systems are for instance not considered manipulative. This may involve making  changes early in the production process,  potentially causing a de facto Brussels Effect because of substantial differentiation  costs. For AI liability updates,286the plausibility  of de facto regulatory diffusion is uncertain. First, it is difficult to evaluate whether  firms change decisions in response to liability regulation because such changes  are barely visible. Second, for corporate  actors to not simply accept the liability but  to change trade-offs and decisions because of the liability rules, the liable actor  along the supply chain must be the one  who can improve the source code or the  data-collection process or who makes deployment decisions. However, we can  conclude that regulatory diffusion is more likely if a firm’s changes in response to the  liability rules are either at the beginning of  the stack or entail mostly fixed costs, such  as post-market monitoring.287DETERMINANTS OF THE DE FACTO BRUSSELS EFFECT 286European Commission, “InceptionImpactAssessment:ProposalforaDirectiveAdaptingLiabilityRulestotheDigitalAgeandArtificialIntelligence” ; European Commission, “Commission Staff Working Document Impact Assessment Accompanying the Proposal for a Regulation of the European  ParliamentandoftheCouncilLayingDownHarmonisedRulesonArtificialIntelligence(ArtificialIntelligenceAct)andAmendingCertainUnionLegislativeActsSWD/2021/84Final.” 287This does not necessarily mean that such interventions would be the most cost-effective way of increasing the trustworthiness of AI products while  avoiding undue regulatory burden.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•61 Foreign jurisdictions may also adopt regulation that resembles EU regulation; a phenomenon termed the de jure Brussels  Effect.288Below, we describe four channels  that may produce a de jure Brussels Effect,  building on Bradford, Young, and Schimmelfennig & Sedelmeier.289First, foreign jurisdictions could adopt the blueprint voluntarily. Second, the EU may promote their  blueprint through multilateral agreements  or mutual recognition agreements. Third, a  de facto Brussels Effect can help cause a de  jure effect. For example, multinational companies may lobby their governments to adopt regulations similar to the EU because,  otherwise, their national competitors may  benefit from less stringent requirements.  Fourth, conditionality describes the situations in which another jurisdiction incorporates the EU blueprint because external  incentives provided by the EU, such as  trade requirements or treaties, encourage it.  The GDPR, as an instance of and an analogy  for AI regulation, caused regulatory diffusion partly through significant conditionality.  We argue that a de jure Brussels Effect with  respect to AI is plausible for at least parts of  the EU AI regulatory regime, though it is far  from certain. The Blueprint Channel will likely  be the most influential, seeing as the EU is  one of the first movers in reg ulating AI and is responding to regulatory pressures also felt  by other jurisdictions. We are reasonably  likely to see diffusion of the risk-based approach and the operationalisation of what  “trustworthy AI” entails. There is a decent  chance t hat other jurisdictions, in particular  liberal democracies, will prohibit some of the  same systems as the EU. It seems likely that  other jurisdictions will introduce transparency  requirements for e.g. chatbots and deepfakes,  though that would more accurately be termed  a “California Effect,” as California was first to  introduce such requirements with the BOT  Disclosure Act passed in 2018.290We are unsure how influential the list of high-risk systems in Annex III will be, i.e. those high-risk  systems not already covered by safety regulation, though it seems likely that AI systems’  use in domains like hiring and loan decisions  will be viewed as controversial across the  globe, as evidenced e.g. by current White  House proposals for an AI Bill of Rights.  What about the other channels? A de jure Brussels Effect via the Multilateralism Channel  seems most likely for those parts of EU regulation that could feed into international standard  setting processes, in particular, the requirements put on high-risk uses of AI. If a de facto  Brussels Effect of AI occurs, multinational companies are likely to lobby for EU-like AI regulation abroad, attempting to create a de jure  3.Determinantsofthe DeJureBrusselsEffect 288See Damro, “MarketPowerEurope” ; Bradford, “TheBrusselsEffect” ; Bradford, TheBrusselsEffect:HowtheEuropeanUnionRulestheWorld . Note  that the term is sometimes used specifically for what we term the De Facto Channel. Dempsey et al., “TransnationalDigitalGovernanceandItsImpact  onArtificialIntelligence.” 289Bradford discusses the channels we cover in §§3.1 and 3.3Bradford, “TheBrusselsEffect” ; Bradford, TheBrusselsEffect:HowtheEuropeanUnion  RulestheWorld . Schimmelfennig and Sedelmeier argue that one should distinguish between the channels discussed in §§3.1 and 3.4. Schimmelfennig  and Sedelmeier, “GovernancebyConditionality:EURuleTransfertotheCandidateCountriesofCentralandEasternEurope.” From Y oung, we added  the channel in §3.3 to the framework. Y oung, “EuropeasaGlobalRegulator?TheLimitsofEUInfluenceinInternationalFoodSafetyStandards.” 290CaliforniaSenate,AnacttoaddChapter6(commencingwithSection17940)toPart3ofDivision7oftheBusinessandProfessionsCode, relating  to bots.. It is also known as the BOT (“Bolstering Online Transparency”) Act or California Senate bill 1001.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•62 291Charles R. Shipan and Craig Volden, “TheMechanismsofPolicyDiffusion,” American Journal of Political Science 52, no. 4 (October 2008): 840–57. 292See e.g. EuropeanCommission,“AIAct” recital 3.3.effect (the De facto Channel). However, it is  uncertain how successful such efforts would  be. We remain unsure about the extent to  which the Conditionality Channel will cause  regulatory diffusion.  Before proceeding, it is worth noting that a  jurisdiction adopting EU-like regulation is not  sufficient to establish that there has been a  de jure effect. The EU’s actions must also  have played a causal role. This is because  the EU and the other jurisdictions might have  independently adopted the regulation for the  same reason, e.g. because they are responding to the same regulatory issues. This might  seem particularly likely in the case of AI since  it is a new regulatory domain where many  jurisdictions are facing similar regulatory  challenges, meaning some are likely to reach  for similar regulatory solutions. One relevant  factor in assessing whether there has been a  causal link is time – who adopted the regulation first – though it is important to note that  regulations can have a global impact even  before they are adopted, as visible in the AI  Act’s being discussed abroad. Another way  to assess the causal link is to trace specific  causal pathways by which the EU might  affect regulation abroad. Below, we outline  some of these pathways and speculate on  how likely they are to have an effect in the  EU case. We encourage other authors to  trace these pathways as the EU’s regulatory  regime is being designed and implemented. 3.1. Blueprint Adoption  Channel Foreign jurisdictions often copy EU regulations  believing this approach might meet their regulatory goals. This Blueprint Adoption Channel  is more likely if (i) the issue is on the political  agenda of other countries because of similar  concerns and interests, (ii) the EU is the first  mover for regulation, and (iii) the EU advertises  and promotes its regulation includ ing via networks and multilateral institutions. Such adop-tion might be the result of what Shipan &  Volden291call “learning” – adopting similar  regulation after it has been adopted and  proved successful – or “imitation” – adoption  before data on the success of the regulation  is available. We argue that (ii) and (iii) are relatively likely for AI regulation. Then, we describe the diffusion of EU AI policy principles  in recent years, arguing that this provides  some indication in favour of the EU’s issue  framings spreading internationally. However,  we also note that other jurisdictions adopting  EU-like regulation does not necessarily suggest that the EU caused this adoption. It may  be that the EU and the other jurisdictions are  responding to the same regulatory pressures.  First, the Blueprint Channel is more likely if  the issue regulated in the EU is also on the  political agenda of other countries and is so  out of similar concerns. Artificial intelligence  is on many policymakers’ agendas, though  their reasons differ. Some emphasise AI’s importance for national competitiveness and  economic growth, while others put more emphasis on the potential harms AI systems  might cause. Relative to other jurisdictions,  EU policymakers seem more focused on the  harms of AI. They also tend to place greater  weight on the claim that a thriving AI industry  requires public trust and that public trust relies on regulation.292 What parts of the AI Act seem most likely to  meet regulatory needs faced by other jurisdictions? Firstly, though jurisdictions may  differ in which AI systems they find worthy of  additional regulatory burdens, they will all  need to decide what rules such systems  should comply with. Thus, we expect the  EU’s requirements for high-risk systems to  end up being influential abroad. Secondly,  many populations in liberal democracies  worry about the use of AI systems by the  government, which might suggest the EU’s  list of prohibited uses of AI potentially could  become influential. DETERMINANTS OF THE DE JURE BRUSSELS EFFECT
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•63 293Hanson, CEMarking,ProductStandardsandWorldTrade p. 193. 294GDPR, art. 45. 295European Commission, “GeneralDataProtectionRegulationShowsResults,butWorkNeedstoContinue,” European Commission, July 24, 2019. 296European Commission, “Annex to the Communication from the Commission to the European Parliament, the European Council, the Council, the  EuropeanEconomicandSocialCommitteeandtheCommitteeoftheRegions,” December 7, 2018, 18. 297European Commission, “CommunicationfromtheCommissiontotheEuropeanParliament,theCouncil,theEuropeanEconomicandSocialCommitteeandtheCommitteeoftheRegionsShapingEurope’sDigitalFuture,” CELEX number: 52020DC0067, February 19, 2020, 14 “A strategy for standardisation, which will allow for the deployment of interoperable technologies respecting Europe’s rules, and promote Europe’s approach and interests on the global stage (Q3 2020).”; European Commission and Directorate-General for Communications Networks, Content and Technology,  “ShapingEurope’sDigitalFuture” (Publications Office, 2020). 298European Commission, EthicsGuidelinesforTrustworthyAI. 299OECD AI Policy Observatory, “TheOECDArtificialIntelligence(AI)Principles,” OECD AI Policy Observatory, accessed July 14, 2022. 300Leufer and Lemoine, “Europe’sApproachtoArtificialIntelligence:HowAIStrategyIsEvolving.”Thirdly, as AI systems become more prevalent in society and it becomes more difficult  to distinguish AI-generated speech, text, and  art from that generated by humans, it seems  likely that policymakers will feel a need to  have citizens be informed of the origin of the  content they are engaging with. Therefore,  one could expect the EU’s regulation on  transparency requirements for certain AI systems to influence how these other jurisdictions meet that regulatory challenge. However, if this happens, the term “California  Effect” would be more apt, as California was  the first to introduce such requirements with  the BOT Disclosure Act passed in 2018. If the EU publishes the first regulation on  some issue, it is more likely to be copied.  More jurisdictions will have an opportunity to  use the blueprint, and the EU could be seen  as the leader concerning the topic at hand  and its standards as the gold standard of responsible AI development. In section 2.3.4 , we  argue that it is likely that the EU is the first  mover among large jurisdictions proposing  comprehensive AI regulation.  Moreover, the EU’s promotion of its regulatory blueprint makes international adoption  more likely. The EU can promote a global  narrative that this blueprint solves an important problem, which makes copying more  likely. For instance, the worldwide promotion  of the CE marking was partly responsible for  its significant de jure Brussels Effect.293 Taking inspiration from the success of de jure  diffusion of the GDPR, the Commission plans  to promote its regulatory regime on AI. Many  smaller nations have adopted regulation that  is GDPR-adequate – where the GDPR allows transfer of personal data to a jurisdiction outside of the EU without specific authorization,  as the jurisdiction’s data protections are  deemed similar enough to the EU’s294– which the Commission also states as one  achievement in a 2019 assessment of the  GDPR.295 In the proposed AI Act, the Commission states  that “[s]pearheading the ethics agenda, while  fostering innovation, has the potential to become a competitive advantage for European  businesses on the global marketplace.”296 It  does so with an awareness of the global  effects the GDPR has had: “Many countries  around the world have aligned their legislation  with the EU’s strong data protection regime.  Mirroring this success, the EU should actively  promote its model of a safe and open global Internet.”297As an example, the EU’s ban and  conformity assessments of different biometric  identification systems could increase the international condemnation of such systems, limiting deployment even outside the EU’s borders. Further, the narrative diffusion of EU AI thinking since approximately 2018 provides valuable information regarding the international  susceptibility to adopting EU thinking on AI  and the future Blueprint Adoption Channel. A  2020 report from Access Now suggests that  the European “Trustworthy AI” approach, outlined in the EU’s High-level expert group’s Ethics Guidelines298has had a significant global  effect, e.g. via the OECD. Many of the concepts and related principles were included in  the OECD principles,299which were signed by  42 countries and heavily influenced a subsequent G20 declaration.300 EU member  states partially adopted the EU’s focus on AI  trustworthiness and human rights. After the DETERMINANTS OF THE DE JURE BRUSSELS EFFECT
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•64 301LeuferandLemoine. 302LeuferandLemoine. 303The AI Forum of New Zealand, “TrustworthyAIinAotearoa:AIPrinciples” (The AI Forum of New Zealand, March 2020), 2. 304Leufer and Lemoine, “Europe’sApproachtoArtificialIntelligence:HowAIStrategyIsEvolving,” 10 305Agência Senado, “Brasilpoderátermarcoregulatórioparaainteligênciaartificial” ; Agência Câmara de Notícias, “Câmaraaprovaprojetoqueregulamentausodainteligênciaartificial.” English translations here . 306Agência Senado, “Brasilpoderátermarcoregulatórioparaainteligênciaartificial” ; Agência Câmara de Notícias, “Câmaraaprovaprojetoqueregulamentausodainteligênciaartificial.” English translations here . 307Eric Lander and Alondra Nelson, “AmericansNeedaBillofRightsforanAI-PoweredWorld,” Wired, October 8, 2021. 308Scott, “ExtraterritorialityandTerritorialExtensioninEULaw” ; Bradford, TheBrusselsEffect:HowtheEuropeanUnionRulestheWorld. 309Joanne Scott, “FromBrusselswithLove:TheTransatlanticTravelsofEuropeanLawandtheChemistryofRegulatoryAttraction,” The American Journal of Comparative Law 57, no. 4 (October 1, 2009): 897–942.HLEG Ethics Guidelines were published and  before the Commission published its 2020 AI  White Paper, 17 national strategies were published by EU member states, of which five  countries explicitly mentioned “Trustworthy  AI”.301One member state, Malta, fully integrated the seven requirements of the EU Ethics  Guidelines for Trustworthy AI.  Several other countries have incorporated  EU language into their national AI strategies,  including Singapore and New Zealand. For  instance, New Zealand has taken up the EU  language and principles in its Aotearoa AI  Principles.302They explicitly mention that  they drew upon the European Commission’s  Ethics Guidelines for Trustworthy AI303and  also used a human rights approach.304However, it remains to be seen whether this narrative diffusion will lead to similar regulation.  Some jurisdictions are further along in their  regulatory processes. In April 2022, the  Brazilian Senate tasked a commission with  proposing a bill on AI regulation, taking into  account e.g. a bill proposed by the lower  house of the Brazilian National Congress.305 Though the Brazilian approach may diverge  from the EU’s regulatory regime – the lower  chamber’s proposal comprised a significantly more sectoral approach, not introducing new AI-specific regulators or regulation  – the forthcoming EU regime seems to be  given significant attention. The rapporteur  of the lower chamber said the EU’s efforts  were the main inspiration for the proposed  changes and that the Senate commission  will explicitly consider the EU regime.306 Policy discussions in the US are also starting to concern issues addressed by the EU’s AI Act, though it is unclear whether there is  a causal relationship. For instance, in October 2021, Eric Lander and Alondra Nelson  from the White House Office for Science  and Technology Policy published an opinion  piece in Wired , arguing that the US needed  an AI Bill of Rights.307They encouraged debate about what such updated rights in light  of AI technologies might be. They encouraged discussion of e.g. rights to not be subject to biased or unaudited algorithms, to  know if and how an AI system is influencing  decisions important to one’s civil liberties,  and to not be subject to pervasive and discriminatory surveillance, many of which the  AI Act seeks to protect. Their piece was accompanied by a Request for Information on  the use of AI for biometric technologies, including their use for “inference of attributes  including individual mental and emotional  states”, signalling interest in proposing concrete regulation. The extent to which such  efforts will make their way into regulation is  hard to predict. It would depend on the  amount of bipartisan support for such  efforts and the extent to which the Biden administration can introduce measures via executive powers. History suggests that a strong de jure Brussels Effect through the Blueprint Adoption  Channel reaching the US seems unlikely,  while China regularly takes inspiration from  EU regulation. In contrast to countries in the  Asia-Pacific, Latin America, or Eastern  Europe, only a few cases of a de jure Brussels Effect have been observed in the United  States.308One such case is the EU chemical  regulation REACH that led to both a de facto  and de jure Brussels Effects in the United  States.309It regulates chemical products un-DETERMINANTS OF THE DE JURE BRUSSELS EFFECT
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•65 310EuropeanCommission,“AIAct.” 311Scott, “FromBrusselswithLove:TheTransatlanticTravelsofEuropeanLawandtheChemistryofRegulatoryAttraction.” 312Scott. 313Vogel, ThePoliticsofPrecaution:RegulatingHealth,Safety,andEnvironmentalRisksinEuropeandtheUnitedStates. 314Samsel, “CaliforniaBecomesThirdStatetoBanFacialRecognitionSoftwareinPoliceBodyCameras.” 315For example, in 2019, Democrat Elissa Slotkin brought the Bot Disclosure and Accountability Act to Congress, co-sponsored by 4 Republicans. The  bill subsequently “died in committee.” Elissa Slotkin, “H.R.4536-116thCongress(2019-2020):BotDisclosureandAccountabilityActof2019,” September 27, 2019. 316For a longer description and list of such regulatory diffusion, see Bradford, The Brussels Effect: How the European Union Rules the World. For instance: chapter 5, p.153 for data protection legislation; chapter 7 page 225 for the RoHS directive; page 180 for the GMO labelling; pages 201, 203  for the chemical regulation REACH; some toy safety standards page 204; China’s 2008 Anti-Monopoly Law (pages 117 and 118); merger rules page 118 317Though note that it does not afford any protections against state uses of personal data. Lomas, “ChinaPassesDataProtectionLaw.” 318Bradford, TheBrusselsEffect:HowtheEuropeanUnionRulestheWorld , 118.  319Ding, “ChinAI #168: Around the Horn (edition 6)” ; Ding, “ChinAI #182: China’s Regulations on Recommendation Algorithms” ; Rogier Creemers and  Graham Webster, “Translation: Internet Information Service Deep Synthesis Management Provisions (Draft for Comment) – Jan. 2022,” DigiChina,  February 4, 2022.der the so-called New Approach of product  safety, just as the conformity assessments  for high-risk AI systems in the proposed AI  Act.310EU legislation, in particular REACH,  was cited in state-level reforms in the US  states of California, Massachusetts, and  Maine, and in American federal-level reforms, including the “Kid-Safe Chemicals  Act.”311Moreover, EU chemical regulation influenced the behaviour and thinking of  American producers, consumers, and the  public. For instance, it led to American consumers demanding more information about  the safety of chemicals and NGOs lobbying  for improvements to American chemical regulations.312 Despite the low base rate of a de jure Brussels  Effect for the US, AI could be different. AI is a  fairly new regulatory domain, where policymakers on both sides of the Atlantic may be facing somewhat similar regulatory pressures.  The citizens of both jurisdictions are, for example, worried that the government could use  AI technologies for repression. As a result of responding to the same regulatory pressures, and  the EU identifying appropriate mechanisms for  AI regulation first, the US might adopt regulation  inspired by the EU. This would most likely happen via US states first  passing regulation, which then diffuses to the  federal level. Since about the 1990s, many US  states have adopted more stringent risk regulation than the federal government, often inspired  by EU regulation.313We are already seeing this in  the case of AI, where Oregon, New Hampshire,  and California have banned the use of facial recognition software on body cam footage.314This more stringent regulation could then diffuse to  the US federal level, for example via the De  Facto Channel.315 This Blueprint Channel regularly reaches China  – the Chinese government has in the past  copied EU rules quickly after EU adoption. Examples include data protection legislation,  chemical regulation, toy safety standards, competition rules, merger rules, and genetically  modified organism (GMO) labelling.316In 2021,  China adopted the Personal Information Protection Law, which provides GDPR-like protections for citizens against private corporations.317 Chinese officials have also publicly stated that  they take inspiration from EU regulation. For instance, China’s former vice minister of commerce, Ma Xiuhong, said that “China has borrowed many experiences of European  Competition Law in various aspects for the enactment of Antimonopoly Law.”318 However, recent Chinese efforts to regulate AI  reduce the chance of de jure diffusion to China  with regard to AI regulation. Chinese regulators have charged ahead in some domains, regulating AI sooner and likely more stringently in  certain dimensions than the EU will. In March  2022, the Cyberspace Administration of China  adopted regulations for recommendation systems, including requirements for providers to  protect users’ personal information, to allow  them to conveniently turn off recommendation  services and to be informed about how the recommendation system works, and to ensure algorithms do not “go against public order and  good customs, such as by leading u sers to addiction or high-value consumption”.319In  January that same year, rules on AI-gener-DETERMINANTS OF THE DE JURE BRUSSELS EFFECT
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•66 ated content such as deepfakes were proposed, including provisions like requiring  consent from the subject of deepfake images, audio, or video, and that the recipient  of AI-generated content be made aware of  its source. This last provision may be inspired  by e.g. California’s BOT Disclosure Act,  though we have not found evidence on this  issue. As is common for Chinese regulation,  the proposal is significantly more far-reaching than EU proposals, stating that regulatees “may not produce, reproduce, publish,  or disseminate: information inciting subversion of State power or harming national security and social stability; obscenity and pornography; false information; information  harming other people’s reputation rights, image rights, privacy rights, intellectual property rights, and other lawful rights and interests ...”. Matt Sheehan argues that these  initiatives should not be ignored by western  observers: there may be lessons to learn  from the success or failure of these initiatives.320At the same time, the AI Act aims to  be more general and comprehensive than  the Chinese regulation. The South China  Morning Post discusses what Hong Kong  and China can learn from the AI Act.321 If the Blueprint Channel does reach China, it  is unlikely to do so for regulation curtailing  the government’s ability to use AI technology  for surveillance, censorship, and the like. The  Chinese Personal Information Protection Law  notably does not put any restraints on government use of data.  De jure diffusion via the Blueprint Channel  seems particularly likely for the requirements  imposed on high-risk systems. Firstly, many  jurisdictions beyond the EU may establish  more sectoral and piecemeal regulatory re-gimes for AI, where significant responsibility  is given to existing regulators and new domains in need of regulation as a result of advances in AI are dealt with one-by-one. For  example, the UK National AI Strategy suggested it would take a largely sectoral approach322and the same seems likely for  Brazil.323We are already seeing e.g. China  and US states producing regulation aimed  at specific regulatory challenges produced  by AI. Relatedly, the AI Act has been criticised for taking an overly product safety–focused lens on AI regulation.324This makes  diffusion of the structure of the EU regulatory regime less likely. Secondly, for major  EU trading partners, the main source of  trade friction with the EU would stem from  imposing requirements incompatible with  the EU on companies trading with the EU.  Whether the company is regulated by a sectoral regulator outside the EU and an AIspecific regulator within the EU has a less  significant impact. This is one mechanism  by which the EU’s requirements for high-risk  AI systems might become a gold standard  or a crucial starting point for other jurisdictions and actors attempting to make concrete responsible AI development and deployment practices. 3.2. Multilateralism Channel A de jure Brussels Effect can also be caused  by international standards being influenced  by EU norms.325For instance, this has been  the case for International Organization for  Standardization (ISO) standards. We argue  that this channel could work through international standard setting organisations (such  as the ISO, IEEE, and ITU) in which the EU has  historically had significant influence.326 Through such standard setting bodies, the EU DETERMINANTS OF THE DE JURE BRUSSELS EFFECT 320Matt Sheehan, “China’sNewAIGovernanceInitiativesShouldn’tBeIgnored,” Carnegie Endowment for International Peace, January 4, 2022. 321Andy Chun, “Europe’sAIRegulationSeeksaBalancebetweenInnovationandRisk.IsHongKongReady?,” South China Morning Post, March 18, 2022,  322Office for Artificial Intelligence, Department for Digital, Culture, Media & Sport, and Department for Business, Energy & Industrial Strategy, “NationalAI  Strategy” (HM Government, September 22, 2021). 323Agência Câmara de Notícias, “Câmaraaprovaprojetoqueregulamentausodainteligênciaartificial.” , English translation here . 324See e.g. Ada Lovelace Institute, “People, Risk and the Unique Requirements of AI: 18 Recommendations to Strengthen the EU AI Act” (Ada Lovelace  Institute , March 31, 2022). 325Y oung calls this regulatory diffusion through competition.Alasdair R. Y oung, “Liberalizing Trade, Not Exporting Rules: The Limits to Regulatory CoOrdinationintheEU’s‘newGeneration’PreferentialTradeAgreements,” Journal of European Public Policy 22, no. 9 (October 21, 2015): 1253–75. 326Engler suggests that CEN and ISO’s efforts for convergence should make this more likely. Engler, “The EU AI Act Will Have Global Impact, but a  LimitedBrusselsEffect” ; CEN-CENELEC, “ISOandIEC,” CEN-CENELEC, accessed July 14, 2022.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•67 is likely to be able to spread its conception of  what responsible deployment of AI systems  entails (e.g. its list of requirements for highrisk systems). In addition, there are also informal diplomatic routes through which the  EU norms influence other jurisdictions. Several multinational institutions are involved in the global AI policy dialogue.  Among them is the subcommittee of the ISO  that is developing international standards for  the AI industry.327Generally, the EU has significant influence in ISO negotiations.328For instance, the US’s decentralised regulatory  process for developing product standards,  compared to the more hierarchical structure  in the EU, puts the US at a disadvantage  globally at the ISO.329 However, the EU might have less influence in  standard setting for AI than other standard  setting processes, because the US and China  increasingly see AI and standard setting for AI  as important for national security, leading to  concerted efforts by both countries to exert influence. Chinese engagement has significantly increased since 2012.330Since the release of the China AI White Paper, the China  Electronics Standardization Institute has been  actively engaged in developing relevant international standards, including as an active  member of the ISO subcommittee focused on  AI standards.331In the US, there have been recent calls, for example from the National Institute on Standards and Technology (NIST),332to  increase US engagement in standard setting  processes for AI. Moreover, in international  negotiations, the EU is one of the most stringent regimes. This outlying preference could put the EU at a disadvantage if the standard  setting process is very structured and majority  rule decisions are made.333 Moreover, there can be international or bilateral mutual recognition agreements (MRAs). If the EU and the US sign an MRA, EU-compliant products can be sold in the US and vice  versa. Historically, the more stringent jurisdictions have been advantaged in the negotiation processes of the MRAs.334For more  details on the MRA for product safety, we  refer to the appendix of this report. This Multilateralism Channel, however, encompasses much more than the formal international institutions and agreements, such as  the ISO and MRAs, and can also occur on the  basis of informal bilateral negotiations. For  AI, the EU-US bilateral efforts illustrate such  an informal channel. In June 2021, the EU  and US launched the Trade and Technology  Council to “lead digital transformation.”335Its  goals include (i) cooperating on developing  compatible international standards and (ii) facilitating cooperation on regulatory policy  and enforcement. For both goals, working  groups were set up. The G7 countries also  pledged to support their respective “effective standard-setting” of AI systems.336 3.3. De Facto Effect Channel A de facto Brussels Effect can lead to a de jure  effect. Suppose there is a strong de facto Brussels Effect. In that case, foreign companies  who use the EU blueprint as their international policy already bear the compliance  cost and so will lobby other governments to DETERMINANTS OF THE DE JURE BRUSSELS EFFECT 327See the ISO website on AI Standards and their ongoing work: ISO, “ISO/IECJTC1/SC42.” 328Hairston, “Hunting for Harmony in Pharmaceutical Standards.” 329Walter Mattli and Tim Büthe, “Setting International Standards: Technological Rationality or Primacy of Power?,” World Politics 56, no. 1 (October  2003): 1–42; Y oung, “EuropeasaGlobalRegulator?TheLimitsofEUInfluenceinInternationalFoodSafetyStandards.” 330Mark Montgomery and Natalie Thompson, “WhattheU.S.CompetitionandInnovationActGetsRightAboutStandards,” Lawfare, August 13, 2021. 331The Big Data Security Standards Special Working Group of the National Information Security Standardization Technical Committee, “ArtificialIntelligence Security Standardization White Paper (2019 Edition),” trans. Etcetera Language Group, Inc. (Center for Security and Emerging Technology,  2019); Peter Cihon, “StandardsforAIGovernance:InternationalStandardstoEnableGlobalCoordinationinAIResearch&Development” (Center for  the Governance of AI Future of Humanity Institute, University of Oxford, April 2019). 332National Science and Technology Council, “U.S.LeadershipinAI:APlanforFederalEngagementinDevelopingTechnicalStandardsandRelatedTools” (National Science and Technology Council, August 9, 2019). 333Cihon, “StandardsforAIGovernance:InternationalStandardstoEnableGlobalCoordinationinAIResearch&Development.” 334Y oung, “EuropeasaGlobalRegulator?TheLimitsofEUInfluenceinInternationalFoodSafetyStandards” ; Y oung, “LiberalizingTrade,NotExporting  Rules:TheLimitstoRegulatoryCo-OrdinationintheEU’s‘newGeneration’PreferentialTradeAgreements.” 335European Commission, “EU-USLaunchTradeandTechnologyCounciltoLeadValues-BasedGlobalDigitalTransformation.”  336The White House, “CarbisBayG7SummitCommuniqué,” The White House, June 13, 2021.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•68 337Bradford, “TheBrusselsEffect.” 338They were only voluntary standards. However, the Commission had the right to change them to compulsory at any time in the future. Sally Eden,  Environmental Issues and Business: Implications of a Changing Agenda (Wiley, 1996), Implications; Beth A. Simmons, “The International Politics of  Harmonization:TheCaseofCapitalMarketRegulation,” International Organization 55, no. 3 (2001): 589–620. 339European Parliament, “Regulation(EC)No1221/2009oftheEuropeanParliamentandoftheCouncilof25November2009ontheVoluntaryParticipationbyOrganisationsinaCommunityEco-ManagementandAuditScheme(EMAS),RepealingRegulation(EC)No761/2001andCommissionDecisions2001/681/ECand2006/193/EC,” CELEX number: 32009R1221, Official Journal of the European Union L 342 1 (November 25, 2009), https:// eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32009R1221; Mattli and Woods, “InWhoseBenefit?ExplainingRegulatoryChangeinGlobalPolitics.” Also, see the discussion in Bradford, “TheBrusselsEffect.” 340For a similar discussion, see: Dale D. Murphy, “The Business Dynamics of Global Regulatory Competition,” in Dynamics of Regulatory Change: How  Globalization Affects National Regulatory Policies, ed. David Vogel and Robert A. Kagan (University of California Press, 2004). 341Sarah Perez, “AlphabetCEOSundarPichaiCallsforFederalTechRegulation,InvestmentsinCybersecurity,” TechCrunch, October 18, 2021. 342Chris Baraniuk, “TimCookBlasts‘Weaponisation’ofPersonalDataandPraisesGDPR,” BBC, October 24, 2018. 343Clare Duffy and CNN Business, “TopMicrosoftExecSaysOnlinePrivacyHasReached‘aCrisisPoint,’” CNN Business, October 14, 2019.  344Beth Simmons, “The International Politics of Harmonization: The Case of Capital Market Regulation,” in Dynamics of Regulatory Change: How Globalization Affects National Regulatory Policies, ed. David Vogel and Robert A. Kagan (University of California Press, 2004). 345Vogel, TradingUp:ConsumerandEnvironmentalRegulationinaGlobalEconomy. 346Birdsall and Wheeler discuss the de facto regulatory diffusion leading to de jure diffusion of US pollution standards to South American and other  developing countries. Birdsall and Wheeler, “Trade Policy and Industrial Pollution in Latin America: Where Are the Pollution Havens?” Perkins and  Neumayer find evidence for the hypothesis that the countries who have more transnational corporations and more imports are more likely to have  stricter automobile emission standards. Perkins and Neumayer, “Does the ‘California Effect’ Operate across Borders? Trading- and Investing-up in  AutomobileEmissionStandards” p. 232. For other US environmental standards influencing non-US countries see: Garcia-Johnson, ExportingEnvironmentalism:U.S.MultinationalChemicalCorporationsinBrazilandMexico ; DeSombre, “TheExperienceoftheMontrealProtocol:ParticularlyRemarkable,andRemarkablyParticular.”adopt the EU regulation, whereas domestic  competitors who do not operate in or export  to the EU do not.337Furthermore, countries  may be more inclined to implement regulation that has seen a de facto Brussels Effect  in their country, as passing such regulation  comes with smaller regulatory costs for their  companies. For instance, when European  corporate actors were subjected to an EU  regulation requiring Eco-Management and  Auditing Scheme (EMAS) standards on public disclosure of the results of company  policies,338they started an alliance with the  green movement to support diffusion of the  standard. Consequently, the ISO 14001  standard was adopted in 1996, copied from  the EU regulation.339 Market structure influences the strength of  this channel. Lobbying can be seen as a coordination problem: the bigger and the more  oligopolistic the firms, the stronger the lobbying, as firms can more easily cooperate in  providing the common pool resource.  Moreover, the greater the total market size,  the more likely firms will have enough political power to achieve their aim.340 However, though it seems plausible that  companies would engage in this lobbying  if they were subject to a de facto effect,  there is little reported evidence for this  channel leading to a de jure Brussels Effect  to date. The Eco-Management and Auditing Scheme (EMAS) standard is the only clear reported example we found. There is  some evidence that companies will start  lobbying governments if they are subject  to greater regulatory burdens from the EU.  Privacy regulation offers one such example. Since the GDPR took effect, CEOs  of Alphabet,341Apple,342and Microsoft343 have called for the US to pass similar regulation. However, it is difficult to tell the extent to which such public statements translate into on-the-ground lobbying efforts by  the companies and, if they do, whether  such lobbying would be successful. The De Facto Channel is seemingly more  common for the California Effect than the  Brussels Effect. US automobile emission  standards, capital market regulation,344pollution standards, and other environmental  standards have been diffused from the US  state level to the US federal level345and to  other countries through such a De Facto  Channel.346As such, we believe the De Facto  Channel is most likely to have an effect on  US federal policy via states adopting stringent EU-like regulation of AI. Though US  companies would likely strongly oppose  such state-level regulation if it risks their  profitability, once passed we predict that  many of those same companies would push  for similar regulation at the federal level. This  might be the most plausible route by which  EU-like regulation is eventually passed in the  US. DETERMINANTS OF THE DE JURE BRUSSELS EFFECT
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•69 In summary, contingent on a de facto Brussels Effect, we expect that multinational AI  firms will lobby other jurisdictions to pass  similar AI regulation, as the AI industry is relatively big and has an oligopolistic structure.  This is particularly likely to happen if some  US states, notably California, pass EU-like  regulation. We are unsure how suc cessful  such efforts would be. Further, we should  also expect legislators to be, on the margin,  more inclined to implement EU-compatible  legislation as it will introduce smaller compliance costs. It is unclear how successful  this would be.  3.4 Conditionality Channel Conditionality and external incentives can  also lead to the adoption of EU blueprints  abroad. This Conditionality Channel requires equivalence clauses and/or extraterritoriality, which are both unlikely for upcoming AI regulation. Equivalency clauses, especially common in  EU financial regulation,347are the clearest  example of conditionality. These clauses  condition ease of market access on the  demonstration of equivalent rules in home  markets. Countries that adopt EU-like rules  can trade more easily with the EU. For example, the Commission undertakes adequacy decisions for data protection regulation, concluding whether a third country,  one of its sectors, or an international organisation have equivalent data protection  levels. Such decisions permit cross-border  data transfer with diminished regulatory  burdens. Hence, foreign jurisdictions, including the United States and Japan, experienced external incentives to adopt stronger data protection regulation.348After Japan increased its data privacy standards, it received an adequacy decision from the EU,  improving data trade and transmission.349 A high degree of extraterritoriality can also  put pressure on other countries to implement EU-equivalent regulation.350The EU  has been shifting towards more extraterritoriality, expanding beyond the inclusion of EU  imports.351Extraterritoriality is a feature of  European aviation law, competition law, and  data privacy law. It was a significant cause of  the GDPR’s de facto and de jure Brussels  Effect (see appendix ). This Conditionality  Channel is significant if data privacy regulation is interpreted as an instance of AI regulation. AI product safety standards will likely  not exhibit the same degree of extraterritoriality. Whereas the GDPR applies to any entity  that handles any data from EU citizens, the AI  Act would only apply to companies that put  products on the EU market. Taken together, a de jure Brussels Effect of  AI is plausible. However, it might predominantly reach jurisdictions that have less geopolitical power. A de jure Brussels Effect is  more likely to reach China than the US (see  §3.1). The Multilateralism and Blueprint  Channels are the most likely channels. If a  de facto Brussels Effect occurs, it is plausible that multinational companies will lobby  other jurisdictions, though it is unclear  whether this will lead to success. While  there are several examples of this channel  as a California Effect, there is only one reported instance of such a de jure Brussels  Effect.DETERMINANTS OF THE DE JURE BRUSSELS EFFECT 347Jerome Deslandes, Magnus Marcel, and Cristina Pacheco Dias, “ThirdCountryEquivalenceinEUBankingandFinancialRegulation” (European Parliament, August 2019). 348Ivy Yihui Hu, “TheGlobalDiffusionofthe‘GeneralDataProtectionRegulation’(GDPR),” ed. K. H. Stapelbroek and S. Grand (Erasmus School of Social  and Behavioural Sciences, 2019) 349European Commission, “Adequacy Decisions: How the EU Determines If a Non-EU Country Has an Adequate Level of Data Protection,” European  Commission, accessed July 14, 2022,  350Raphael Bossong and Helena Carrapico, eds., EU Borders and Shifting Internal Security: Technology, Externalization and Accountability (Springer  International Publishing, 2016).  351For a recent clear example, see “DevelopmentsintheLaw:Extraterritoriality,” Harvard Law Review 124, no. 5 (2011): 1226–1304. Much of the discussion focuses on EU competition (antitrust) law. See. e.g., Berkeley Electronic Press, “FlyingTooHigh?ExtraterritorialityandtheEUEmissionsTrading  Scheme: The Air Transport Association of America Judgment,” Eutopia Law, 2012; Barbara Crutchfield George, Lynn V. Dymally, and Kathleen A.  Lacey, “Increasing Extraterritorial Intrusion of European Union Authority into U.S. Business Mergers and Competition Practices: U.S. Multinational  BusinessesUnderestimatetheStrengthoftheEuropeanCommissionfromG.E.-HoneywelltoMicrosoft,” Connecticut Journal of International Law 19,  no. 3 (2004): 571–616.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•70 We consider the history and causes of regulatory diffusion for (i) EU data protection legislation, (ii) the EU Product Liability Directive, and (iii) the product safety framework  and CE marking. 4.1. Data Protection The EU Data Protection Directive (DPD), a  potential analogy to AI regulation, led to regulatory diffusion via a de jure Brussels  Effect.352The 2018 General Data Protection  Regulation (GDPR) exhibited a strong de  facto Brussels Effect. Despite the recentness, the GDPR has led to a de jure Brussels  Effect in more than five countries.  One can learn about the AI Brussels Effect  from this case study as the market partly  overlaps; AI and privacy regulation affect  many of the same systems and products. We  tentatively conclude that the unique features  of data protection regulation were responsible for substantial parts of its de facto Brussels Effect. For data regulation, the forking  happens earlier on, and the wide extraterritorial claims increased the market size to  which the regulation applied. The de jure  Brussels Effect appears to have been mostly  caused by the attraction of foreign jurisdictions to the EU data protection blueprint, a  process that has been ongoing since the Council of Europe’s 1981 Convention 108 and  the EU’s 1995 Data Protection Directive.353 Assessing the potential of an AI Brussels  Effect requires careful consideration of China  and the United States since these countries  are home to the largest number of world-leading AI companies. The history of data protection regulatory diffusion indicates that China  experienced a de facto and de jure Brussels  Effect of limited scope, while the US saw a limited de facto effect and a de jure effect with  regard to some states. 4.1.1. The Analogy between Data Protection  andAIRegulation Scholars and politicians frequently refer to  data protection regulation as an analogue for  EU AI regulation.354The analogue is fitting in  that (i) both laws apply to similar companies,  including Amazon, Facebook, Google, IBM,  and Microsoft; (ii) they both regulate the technology B2C market; (iii) the regulatory target  is similar; and (iv) collected data is often used  in machine learning algorithms, one prominent AI technique. Data protection regulation can be considered  an instance of AI regulation as, for example,  the GDPR regulates aspects of AI development and deployment.355For example, Article  4.Appendix: CaseStudies 352Steven R. Salbu, “The European Union Data Privacy Directive and International Relations” (William Davidson Institute, December 2001). 353Lee A. Bygrave, “The‘StrasbourgEffect’onDataProtectioninLightofthe‘BrusselsEffect’:Logic,MechanicsandProspects,” Computer Law & Security Review 40 (April 1, 2021): 105460. 354However, the analogy might also be politically motivated (see the van der Leyen speech in the European Parliament) to make the plans on AI regulation look more impressive. Directorate-General for Neighbourhood and Enlargement Negotiations, “SpeechbyPresident-ElectvonDerLeyeninthe  EuropeanParliamentPlenaryontheOccasionofthePresentationofHerCollegeofCommissionersandTheirProgramme” ; EPIC, “AtG-20,Merkel  CallsforComprehensiveAIRegulation.” 355There are more ways through which the GDPR affected the AI industry. This includes data minimisation (5(1)(c)), accuracy (5(1)(d)), consent (which  might affect whether data from the internet can be scraped to train AI models), and repurposing of data. One might also wonder how the right to  erasure should be applied to an AI model which is already trained with one’s data. Giovanni Sartor and Francesca Lagioia, “TheImpactoftheGeneral  DataProtectionRegulation(GDPR)onArtificialIntelligence” ( European Parliamentary Research Service, June 2020).
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•71 5(1)(a) of the GDPR requires data processing  to be fair and transparent. This includes information fairness, i.e. providing data subjects  with information on how their data is used,  and substantive fairness, which means that  the content of an automated inference or decision must be fair.356This requirement challenges the application of AI models that are  biased or trained on biased data. Moreover,  principles from data protection regulation  might shape the AI landscape. The GDPR includes what some have called a right to explanation,357stating that data subjects have a  right to receive “meaningful information about  the logic involved” in automated decisions,  which would often be made by AI systems. However, while the GDPR might be an instance of AI regulation, there are also reasons to believe that the GDPR analogy is not  very informative when forecasting a Brussels Effect for other regulations of AI. First, if a firm has two internal data protection policies or data management processes, one EU-compliant and one noncompliant, the costs of differentiation (see  §2.5 ) may be high, and compliance is mostly  a fixed cost, making non-differentiation  more attractive. Second, suppose data protection rules require you to treat the input  data for AI systems differently. In that case,  this might have high costs of differentiation  because the data-collection and management processes are one of the first steps in  the production pipeline – forking happens  early on. Both make non-differentiation and  a de facto Brussels Effect more likely than it  is for other AI regulation (see §2.5 ). On the  other hand, there are examples of cases in  which the higher EU data privacy standards  for social media companies were not diffused to other jurisdictions – suggesting  non-differ entiation is not the profit-maximising choice in all scenarios. One illustration  might be the Facebook-owned messaging  app WhatsApp, which initiated a compulsory  data privacy update in January 2021. Some of  the most widely criticised parts of the regulation were only implemented for users outside  of Europe.358 Moreover, the GDPR applies to all data subjects that are physically in the EU. Unless a  website is intentionally not making itself available to EU IP addresses, they have to have a  GDPR-compliant version.359Hence, EU data privacy regulation has significant extraterritorial  jurisdictional claims, i.e. it governs activities occurring outside the jurisdiction’s border.360In  the DPD, GDPR’s non-harmonized predecessor, the definition of an establishment (Article 4), i.e. the territorial scope, was left to the  individual member states, which resulted in  different national laws having differing degrees of extraterritoriality.361 The GDPR directly  applies to all member states and thus reduces  legal uncertainty. While the DPD also had a de  jure Brussels Effect, the GDPR led to a strong  de facto Brussels Effect. The GDPR’s extraterritoriality could have contributed to its de facto  regulatory diffusion as it increased the effective market to which the regulation applies.  In addition, the lower regulatory burden of  moving data to jurisdictions the EU Commission considers to provide an adequate data  protection level has further bolstered a de jure  Brussels Effect. Concretely, these GDPR requirements mean that the Commission determines whether a country outside the EU  offers an adequate level of data protection.  Only when a jurisdiction has been determined  to provide adequate protection is personal APPENDIX: CASE STUDIES 356See also GDPR, recital 71; SartorandLagioia . 357Though this is contended by Watcher et al. with a compelling response in Selbst and Powles. Sandra Wachter, Brent Mittelstadt, and Luciano Floridi,  “Why a Right to Explanation of Automated Decision-Making Does Not Exist in the General Data Protection Regulation,” International Data Privacy  Law 7, no. 2 (May 1, 2017): 76–99, https://doi.org/10.1093/idpl/ipx005; Andrew D. Selbst and Julia Powles, “Meaningful Information and the Right to  Explanation,”InternationalDataPrivacyLaw7,no.4 (November 1, 2017): 233–42. 358Jenny Darmody, “Explainer:WhatYouNeedtoKnowabouttheWhatsAppUpdate,” Siliconrepublic, January 14, 2021. 359GDPR, art. 3. 360Deborah Senz and Hilary Charlesworth, “BuildingBlocks:Australia’sResponsetoForeignExtraterritorialLegislation,” Melbourne Journal of International Law 2, no. 1 (June 1, 2001): 69–121. Dan Jerker B. Svantesson, “TheExtraterritorialityofEUDataPrivacyLaw–ItsTheoreticalJustificationand  ItsPracticalEffectonU.S.Businesses,” Stanford Journal of International Law 50, no. 1 (2014): 53–102. Argument for significant extraterritoriality: Benjamin Greze, “TheExtra-TerritorialEnforcementoftheGDPR:AGenuineIssueandtheQuestforAlternatives,” International Data Privacy Law 9, no.  2 (April 21, 2019): 109–28. 361Svantesson, “TheExtraterritorialityofEUDataPrivacyLaw–ItsTheoreticalJustificationandItsPracticalEffectonU.S.Businesses.”
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•72 data allowed to flow from the EU (and Norway,  Liechtenstein, and Iceland) to that country  without requiring any further safeguards.  Twelve countries are on this whitelist, including  Israel, Uruguay, and Japan.362The United  States got a partial and temporary exemption.  The Commission revie ws the data protection  levels of these whitelisted countries every four  years. Japan went further , developing its own  whitelist.363These rules provide economic incentives for non-EU countries to adopt an EU-equivalent data protection level to ensure the free flow  of data. It is unclear whether there will be an analogous rule for AI products, as the AI Act does not  include any provisions on adequacy assessments.364 4.1.2.RegulatoryDiffusion The EU DPD led to regulatory diffusion via a de  jure Brussels Effect.365The 2018 GDPR exhibited  a strong de facto Brussels Effect. It has also led  to a de jure Brussels Effect in more than five  countries despite its recentness. In 1980 and 1981, international data privacy regulation efforts were initiated with two international agreements, the OECD’s nonbinding privacy principles and the binding Convention 108  of the Council of Europe (CoE).366In 1995, the EU  DPD followed,367which resembles its successor,  the 2018 GDPR, in its vast scope. The regulatory  targets are data-processing activities conducted  by organisations established in the EU, activities  offering goods or services (even if for free) to  data subjects situated in the EU (not restricted to EU citizens), and the mon itoring of such data  subjects. For instance, the US company Clearview AI falls under the GDPR.368It offers US law  enforcement agencies a service where they  can search for all photos369of an individual and,  for instance, identify them in CCTV footage.  Due in part to the Council of Europe Convention 108’s preceding and inspiring the EU DPD,  some have argued that the spread of  European data protection should not be  ascribed to the EU. As the Council of Europe,370 headquartered in Strasbourg, is separate from  the EU and includes more countries, some  have argued that the spread of these norms  should perhaps be termed a “Strasbourg  Effect”.371We will not discuss this question in  detail, as most commentators seem to agree  that the EU’s regulatory efforts played a significant role in the diffusion of European data  protection norms, regardless of its role in originating these norms. TheDataProtectionDirective The DPD led to a de jure Brussels Effect, partly  due to its unprecedented extraterritorial jurisdictional claims.372These extraterritorial demands were reasonable from the perspective  of European policymakers because they are required to provide adequate protection for  European citizens.373 Comprehensive data privacy l aws that apply to  all types of personal data have been adopted  by 145 countries, including India, Japan, Malay-APPENDIX: CASE STUDIES 362European Commission, “AdequacyDecisions:HowtheEUDeterminesIfaNon-EUCountryHasanAdequateLevelofDataProtection.” 363Paul M. Schwartz, “GlobalDataPrivacy:TheEUWay,” New Y ork University Law Review 94, no. 4 (October 2019): 771–818. 364AI Act. 365Salbu, “The European Union Data Privacy Directive and International Relations.” 366Council of Europe, “DetailsofTreatyNo.108,” Council of Europe, accessed July 14, 2022. Note that the Council of Europe is not an institution of the EU. 367European Parliament, “Directive95/46/ECoftheEuropeanParliamentandoftheCouncilof24October1995ontheProtectionofIndividualswith  RegardtotheProcessingofPersonalDataandontheFreeMovementofSuchData,” CELEX number: 31995L0046, Official Journal of the European  Communities L 281 31 (November 23, 1995), https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:31995L0046. (in the following: data protection directive).  368The Hamburger DPA deemed their behaviour illegal but only issued a narrow request rather than a pan-European order. NOYB, “Clearview AI  DeemedIllegalintheEU,butOnlyPartialDeletionOrdered,” noyb.eu, January 28, 2021. 369These pictures and the metadata were scraped from Facebook, Y ouTube, Venmo, etc. 370Not to be confused with the European Council, which is a part of the EU. 371Bygrave, “The‘StrasbourgEffect’onDataProtectioninLightofthe‘BrusselsEffect’:Logic,MechanicsandProspects.” 372Svantesson, “TheExtraterritorialityofEUDataPrivacyLaw–ItsTheoreticalJustificationandItsPracticalEffectonU.S.Businesses,” 53–102; European Parliament, “Directive95/46/ECoftheEuropeanParliamentandoftheCouncilof24October1995ontheProtectionofIndividualswithRegard  totheProcessingofPersonalDataandontheFreeMovementofSuchData” , art. 25 and 26.  373In the case of AI regulation, such extraterritoriality is most likely not necessary to protect the safety and interest of EU consumers. 374Graham Greenleaf, “GlobalDataPrivacyLaws2021:UncertainPathsforInternationalStandards,” Privacy Laws & Business International Report 169  (Privacy Laws & Business, 2021).
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•73 375Greenleaf, “TheInfluenceofEuropeanDataPrivacyStandardsOutsideEurope:ImplicationsforGlobalizationofConvention108.” 376Greenleaf. 377Greenleaf, “GlobalDataPrivacyLaws2021:UncertainPathsforInternationalStandards” ; Graham Greenleaf, “GlobalDataPrivacyLaws2021:DespiteCOVIDDelays,145LawsShowGDPRDominance,” Privacy Laws & Business International Report 169 (Privacy Laws & Business, 2021), https:// doi.org/10.2139/ssrn.3836348. 378Greenleaf, “TheInfluenceofEuropeanDataPrivacyStandardsOutsideEurope:ImplicationsforGlobalizationofConvention108.” 379Graham Greenleaf, “GlobalConvergenceofDataPrivacyStandardsandLaws:SpeakingNotesfortheEuropeanCommissionEventsontheLaunch  oftheGeneralDataProtectionRegulation(GDPR)inBrussels&NewDelhi,25May2018,” University of New South Wales Law Research Series 56  (University of New South Wales, May 25, 2018). 380Council of Europe, “CAHAI - Ad Hoc Committee on Artificial Intelligence,” Artificial Intelligence, accessed July 14, 2022. 381In contrast to a regulation, a directive can vary from member state to member state. Thus, a multinational company has to slightly adapt its compliance  to different national jurisdictions. Besides, a directive requires more regulatory costs, as not only the European institutions but also national institutions have to work on the law. 382This includes the right to be informed, the right of access, the right of rectification, the right to erasure, the right to restrict processing, the right to data  portability, the right to object, and rights related to automated decision-making and profiling. Griffin Drake, “NavigatingtheAtlantic:Understanding  EUDataPrivacyComplianceamidstaSeaofUncertainty,” Southern California Law Review 91, no. 1 (November 2017). 383Greenleaf, “GlobalConvergenceofDataPrivacyStandardsandLaws:SpeakingNotesfortheEuropeanCommissionEventsontheLaunchoftheGeneralDataProtectionRegulation(GDPR)inBrussels&NewDelhi,25May2018.” 384Greenleaf . 385Graham Greenleaf, “‘GDPRCreep’forAustralianBusinessesButGapinLawsWidens,” University of New South Wales Law Research Series 54 (University of New South Wales, June 6, 2018).sia, South Korea, Taiwan, South Africa, the Economic Community of West African States, and  some Latin American countries.374The pri vacy  laws of these countries are not only influenced by the earlier OECD guidelines or the  Council of Europe Convention, but they also  incorporate unique parts of the EU DPD. A  2012 study considered 33 of the 39 nonEuropean national data protection laws and  found that 19 out of 33 national privacy laws  contain at least 7 of the 10 elements which  were added to the DPD but were not present  in either the OECD and the CoE document.375 Thirteen out of the 33 contain at least nine of  these ten features.376All 75 non-European  data privacy laws enacted at least 7 out of 10  of the 1995 EU directive principles. The EU  Data Protection Directive exhibited a strong  de jure Brussels Effect. Because of the absence of studies on the potential de facto Brussels Effect of the DPD,  we do not further analyse whether there was  such an effect. However, a de facto effect  was undermined by the lack of harmonisation of the DPD. Due to its nature, the directive is less centralised in its implementation,  reducing the internal cohesion. This reduces  the market size and thus weakens the de  facto Brussels Effect.377 TheCouncilofEurope108Convention The Council of Europe 108 Convention also  exhibited regulatory diffusion and was adopted by countries which were not members of the CoE.378All 126 privacy laws worldwide  share the ten core elements from the CoE  Convention 108.379This might be relevant for  actors in the AI policy space as the CoE is  also developing AI regulation.380 TheGeneralDataProtectionRegulation In 2018, the GDPR replaced the DPD to (i)  achieve more harmonisation, (ii) adapt the  law to the new technology landscape, and  (iii) better govern international data transfers.  As a regulation rather than a directive, the  GDPR leads to greater regulatory consistency between EU member states, reducing  regulatory and other overhead costs.381 Moreover, the GDPR improved the legal enforcement system, stressed the importance  of individual rights, and changed the consent  definition.382Companies outside of Europe  are adopting GDPR compliance for their operations worldwide.383 Further, the regulation also affects businessto-business interactions. One example of this  phenomenon is Microsoft, which requires all  of its suppliers to be GDPR-compliant.384 Hence, for instance, Australian businesses  serving the business-to-business market,  which do not themselves have customers in  the EU, have been pressured by their multinational clients to ensure that their software  products will be GDPR-compliant.385 The  GDPR has exhibited a strong de facto Brussels Effect.APPENDIX: CASE STUDIES
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•74 386“Early examples just from Asia include Malaysia (data portability); Korea (4% administrative fines); Indonesia (“right to be forgotten”); and mandatory  data breach notification (DBN) in six countries.” Greenleaf, “GlobalConvergenceofDataPrivacyStandardsandLaws:SpeakingNotesfortheEuropeanCommissionEventsontheLaunchoftheGeneralDataProtectionRegulation(GDPR)inBrussels&NewDelhi,25May2018.” See also Greenleaf, “GlobalDataPrivacyLaws2021:UncertainPathsforInternationalStandards.” 387See for instance: Greenleaf, “GlobalDataPrivacyLaws2021:UncertainPathsforInternationalStandards.” 388European Commission, “AdequacyDecisions:HowtheEUDeterminesIfaNon-EUCountryHasanAdequateLevelofDataProtection.” 389EuropeanCommission. 390California State Legislature, “BillText-AB-375Privacy:PersonalInformation:Businesses,” June 29, 2018. 391Francesca Lucarini, “ TheDifferencesbetweentheCaliforniaConsumerPrivacyActandtheGDPR,” April 13, 2020. 392Virginia’s Legislative Information System, “2021SpecialSessionI:HB2307ConsumerDataProtectionAct;PersonalDataRightsofConsumer,Etc,”  LIS, accessed July 14, 2022. 393Sarah Rippy, “VirginiaPassestheConsumerDataProtectionAct,” International Association of Privacy Professionals, March 3, 2021. 394Jim Halpert et al., “TheWashingtonPrivacyActGoes0for3,” International Association of Privacy Professionals, April 26, 2021. 395Schwartz, “GlobalDataPrivacy:TheEUWay.” 396Schwartz. 397Bradford, TheBrusselsEffect:HowtheEuropeanUnionRulestheWorld , chap. 5. 398Bradford, chap.5 ; Zhang Xinbao, “StatusQuoOf,ProspectsforLegislationonProtectionofPersonalDatainChina,” ���� V6�� , 2007; Zhang  Xinbao and Liao Zhenyun, “ ���������������� ,” ��������� , 2007. 399Bradford, TheBrusselsEffect:HowtheEuropeanUnionRulestheWorld , chap. 5. 400Lomas, “China Passes Data Protection Law.”It is still too early to evaluate the final extent of  the de jure Brussels Effect of the GDPR. However, some evidence exists for de jure regulatory diffusion.386In 2019 and 2020, 13 new  countries adopted data privacy legislation  and 13 other countries updated existing laws,  of which the GDPR influenced almost all.387  The countries held adequate under the 1995  DPD can renew their status until 2022.388To  date, the EU has made adequacy decisions  approving 14 jurisdictions, including Argentina, Canada, Israel, South Korea, Japan, Switzerland, the United Kingdom, and New Zealand.389 In addition, some US states have or are in the  process of adopting regulation with elements from the GDPR. In 2018, California adopted the California Consumer Privacy Act,390  originally introduced as a ballot proposition,  with many similarities to the GDPR.391In 2021,  the Consumer Data Protection Act392was  signed into law in Virginia, with many similarities with the GDPR and the California Consumer Privacy Act.393Furthermore, there  have been repeated attempts to pass a similar law in Washington State.394 In addition, the European institutions have  shaped the global narrative surrounding data  privacy through their regulatory efforts.  While personal data might also be considered a commodity in the United States,  data privacy is regarded as a human right in  the EU. Importantly, this Europea n narrative  appears to have influenced the positions of  American technology companies. For in-stance, the president of Microsoft tweeted,  “We believe privacy is a fundamental human  right”.395Similarly, the CEO of Apple told CNN  that “privacy is a fundamental human right”.396 In the same vein, the European narrative on AI  – such as the concept of “trustworthy AI” –  may influence the positions and actions of  non-European AI companies. Moreover, the regulation might have also  strengthened certain industries. The GDPR  has provided a strong business case for privacy-enhancing technologies (PET). One  would expect that the GDPR will increase the  development and deployment of these techniques. However, since PETs are not mature  enough to be widely employed, it is currently  difficult to evaluate such diffusion.  China EU data protection rules have also influenced  China. The 2017 Cyber Security Law includes  explicit consent from the users and the requirement that the data used for processing  be adequate and not excessive.397This  Chinese policy process also received funding  from the Commission,398which also set up  policy dialogues between the two jurisdictions.399In August 2021, the Chinese government passed the Private Information Act.400 The Cyberspace Administration of China,  which has been encouraged in recent years  to fiercely enforce regulation in the technology industry, will enforce the act. At the same  time, not all EU aims of privacy legislation APPENDIX: CASE STUDIES
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•75 401On these grounds and the demands of the Chinese government, companies like Google withdrew from China. Matt Sheehan, “How Google Took on  China—and Lost,” MIT Technology Review, December 19, 2018. 402See §2.1.3 of this report or Bradford, TheBrusselsEffect:HowtheEuropeanUnionRulestheWorld . 403For more, see Bradford . 404Bach and Newman, “TheEuropeanRegulatoryStateandGlobalPublicPolicy:Micro-Institutions,Macro-Influence.” 405The directive called for an “essential equivalent”. This is not given in the case of the US privacy regulation. Schwartz, “Global Data Privacy: The EU Way.” 406Court of Justice of the European Union, “Judgment in Case C-362/14 Maximillian Schrems v Data Protection Commissioner: The Court of Justice  DeclaresThattheCommission’sUSSafeHarbourDecisionIsInvalid,” Press Release 117/15 (Court of Justice of the European Union , October 6, 2015);  European Commission, “EU-US Data Transfers: How Personal Data Transferred between the EU and US Is Protected,” European Commission, accessed July 14, 2022. New discussions were initiated in August 2020. 407Kenneth Propp, “ProgressonTransatlanticDataTransfers?ThePictureAftertheUS-EUSummit,” Lawfare, June 25, 2021. 408Vincent Manancourt, “DespiteEUCourtRulings,FacebookSaysUSIsSafetoReceiveEuropeans’Data,” POLITICO, December 19, 2021. 409Javier Argomaniz, “When the EU Is the ‘Norm-taker’: The Passenger Name Records Agreement and the EU’s Internalization of US Border Security  Norms,” Journal of European Integration 31, no. 1 (January 1, 2009): 119–36. 410Jennifer Daskal, “BordersandBits,” Vanderbilt Law Review 71, no. 1 (2018): 179. 411For a discussion see Schwartz, “Global Data Privacy: The EU Way.” E.g. The president of Microsoft, tweeted, “We believe privacy is a fundamental  human right.” In a similar fashion, Tim Cook, the CEO of Apple, told CNN that “privacy is a fundamental human right.”have been achieved in China. The Chinese  public sector is completely exempt. Digital authoritarianism, the blocking and filtering of online content, the social credit system, and facial  recognition techniques all clash with the aims  and values of EU data protection rules and are  not curtailed by the regulation adopted by the  Chinese Communist Party.401 ExtraterritorialityandtheUnitedStates The extraterritorial reac h of the GDPR contributed to the de facto and de jure GDPR Brussels  Effect.402 At the same time, the extraterritoriality  also illustrates how powerful and economically  advanced countries, especially the US, try to  resist the Brussels Effect.  While the US experienced de facto Brussels  Effects for various EU legislative efforts, including  the Code of Conduct regarding hate speech, parts  of the DPD, and the GDPR,403it can also resist selectively, sometimes successfully and sometimes  not.404The United States partially circumvented the  extraterritorial claims of the DPD and GDPR, particularly the requirements for international data transfers. The EU and the US adopted two data transmission agreements, the Safe Harbor agreement  in 2000 and the Privacy Shield in 2015, allowing  unhindered data transmission between the United  States and the EU. Both agreements were adopted even though the US data privacy standards  were not equivalent to the EU, which is a requirement for data transmission agreements in both the  DPD and GDPR.405Consequently, both data transmission agreements were declared invalid by the  European Court of Justice (ECJ) in 2015 and 2020,  respectively.406Since 2020, the US and the Commission have stated their intention to negotiate a new agreement. In June 2021, both sides asserted  theircommitmenttofindasuccessortothePrivacy  Shield.407At the same time, Politico reported that  Facebook, for instance, continues to send data  across the Atlantic.408 Inaddition, despite the EU’s data protection concerns, the United States and the EU have signed  bilateral passenger name record (PNR) agreements for flights.409These agreements allow for  the exchange of both the information provided  by passengers when they book tickets and when  checking in for flights, and the exchange of data  collected by air carriers for commercial purposes.  Both agreements are examples of the United  States resisting European pressure for regulatory  convergence. The US might have leveraged its  considerable regulatory capacity in customs  policy and homeland security, market size, or  geopolitical power . Despite the resistance of the United States,  both data transmission agreements potentially  led to a Brussels Effect: they brought the US  closer to the EU privacy standards.410The 2000  Safe Harbor Agreement encouraged company  self-regulation. By 2015, 4,500 US companies  had publicly affirmed the Safe Harbor principles. Consequently, the Safe Harbor agreement has indirectly led to a Brussels Effect in  the United States.  The United States has no omnibus privacy laws –  suggesting the absence of a de jure Brussels  Effect. Nevertheless, the EU discourse and regulation around data privacy has sig nificantly influenced the United States. The narrative around  data privacy in the United States appears to have  increasingly moved away from consumer safety APPENDIX: CASE STUDIES
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•76 andtowardsfundamentalrights.411Despitethetemporary special treatment received by the United  StatesintheDPDandGDPR,manyAmericancompanies have followed the Safe Harbor principles  and adopted stricter data protection practices than  required by the US government. The Safe Harbor  agreement called for self-regulatory efforts by  companies, which led to further agreements  between companies and more significant regulatory actions.412 4.1.3.Conclusion The EU data protection regime has exhibited a  strong de jure Brussels Effect. This was partly mediated via the international spread of the EU-supported narrative of data privacy as a human right,  a unique feature of European data protection  regulation. For instance, non-EU countries  passed stronger data protection clauses that  were not required in order to trade with the EU. In  a 2012 study, 28 out of 33 examined data privacy  laws also have border control data export limitations.413Similar to the EU, Japan created a whitelist of countries to which Japanese data can  flow.414 The European regulation also exhibited a de  facto Brussels Effect. However, it is unclear  whether this offers transferable insights for  (other) AI regulation since the de facto Brussels  Effect of data protection regulation may have  been due to unique features of this regulatory  target and design. First, the narrative change increased the revenue from non-differentiation.  Second, the extraterritorial claims also made  non-differentiation more attractive. Third, the  regulation required early forking, which increased the costs of diffe rentiation – making  non-differentiation more likely.4.2. Product Liability Directive As of January 2022, the Commission is preparing to propose AI-specific changes to the  EU liability regime – by either changing the  Product Liability Directive (PLD) or by harmonising aspects of national civil liability  law regarding the liability of certain AI systems.415The regulatory diffusion of the PLD  can inform us about the likelihood of a future Brussels Effect of AI liability rules. For  instance, if another jurisdiction has liability  regulation strongly influenced by the PLD,  then the EU AI liability becomes more attractive and feasible as a blueprint. In addition, the PLD and t he AI liability update  might share several features.  The PLD influenced the product liability legislation of many countries – evidence for a  future de jure effect of AI liability updates. US  liability law has much higher economic costs  and is less easy to copy than the PLD. This  made the de jure Brussels Effect more likely  as other jurisdictions were less likely to take  the US regulation as a blueprint. As discussed in section 2.6.4 , whether liability law  exhibited de facto regulatory diffusion is extremely difficult to study. Hence, one should  be less confident that future AI liability law  will lead to a de facto Brussels Effect. The Commission’s legislative efforts may include the adoption of strict liability for AI operators or the adaptation of the burden of proof.416 The EU AI White Paper 2020 and the Inception  Impact Report 2021417propose, among other  things, to include software in the definition of a  product and to shift the burden of proof more  towards the AI companies. In doing so, companies would be given the responsibility to  demonstrate the safety of their AI products, APPENDIX: CASE STUDIES 412Gregory Shaffer, “GlobalizationandSocialProtection:TheImpactofEUandInternationalRulesintheRatchetingUpofU.S.PrivacyStandards,” Yale  Journal of International Law 25, no. 1 (2000): 2–88. 413Greenleaf, “TheInfluenceofEuropeanDataPrivacyStandardsOutsideEurope:ImplicationsforGlobalizationofConvention108.” 414“Border control” data export limitations are found in almost all (28/33 examined) data privacy laws in all regions, though their strength varies a great  deal, and they are not yet in force in the laws of Malaysia and Hong Kong. Greenleaf. 415European Commission, “InceptionImpactAssessment:ProposalforaDirectiveAdaptingLiabilityRulestotheDigitalAgeandArtificialIntelligence” ; European Commission, “Commission Staff Working Document Impact Assessment Accompanying the Proposal for a Regulation of the European  ParliamentandoftheCouncilLayingDownHarmonisedRulesonArtificialIntelligence(ArtificialIntelligenceAct)andAmendingCertainUnionLegislativeActsSWD/2021/84Final.” Planned adoption by the Commission: third quarter 2022. European Commission, “CivilLiability–AdaptingLiability  RulestotheDigitalAgeandArtificialIntelligence.” 416European Commission, “Commission Staff Working Document Impact Assessment Accompanying the Proposal for a Regulation of the European  ParliamentandoftheCouncilLayingDownHarmonisedRulesonArtificialIntelligence(ArtificialIntelligenceAct)andAmendingCertainUnionLegislativeActsSWD/2021/84Final.” 417European Commission, “CivilLiability–AdaptingLiabilityRulestotheDigitalAgeandArtificialIntelligence.”
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•77 rather than requiring consumers to prove in  court that the AI product was defective. 4.2.1.RegulatoryDiffusion The PLD has become an internationally leading blueprint, having been copied in more  than a dozen countries. Iceland, Liechtenstein, Malta, Norway, and Switzerland voluntarily adopted it simultaneously with the EU –  these countries regularly opt for EU legislation because the EU is their main trading  partner.418Countries in Asia-Pacific, among  them Australia, China, Taiwan, Japan, Malaysia, Indonesia, and South Korea, adopted it  as a blueprint 7 to 15 years after the EU adoption.419Russia, Israel, and Quebec also used  the PLD as a blueprint.420 China is another example of a country to  which the European PLD diffused. The structure of China’s Tort Liability Law broadly follows the German civil code law, which implements the PLD. Moreover, China used the  PLD as a blueprint for the liability along the  supply chain, the burden of proof in liability  cases, and defining a defect.421 The European liability model has become  dominant on a global level such that “the  American approach has become almost an  outsider”.422There are two explanations for why the European rather than American liability model served as a blueprint. First, the  number of liability claims in the US, their  awards, and their publicity are significantly  higher than anywhere else in the world – involving substantial economic costs.423This  may have made the PLD, under which liability claims are harder to win and awards are  smaller, relatively more attractive.424Second,  the PLD is more concise and easier to understand than its American counterpart.425Taken  together, this de jure Brussels Effect might  show that EU-crafted liability law is attractive  for other jurisdictions. 4.2.2.ImpactsofEU-styleLiabilityLaw Despite the strong de jure Brussels Effect of  EU liability law, it is difficult to assess whether  there have been any flow-through effects on  company behaviour. The regulation has  caused only minor detectable changes in EU  courtrooms – conceivably suggesting the absence of any actual effect as companies do  not have enough pressure to change behaviour.426When EU consumers sue because of  product damages, they rarely rely on the PLD  but rather on pre-existing national law.427 There is only scarce evidence for litigation in  the countries using the EU blueprint of the  PLD, likely because the PLD is too restrictive  and only “supplemented pre-existing na-APPENDIX: CASE STUDIES 418“ConsolidatedText:CouncilDirective85/374/EECof25July1985ontheApproximationoftheLaws,RegulationsandAdministrativeProvisionsof  theMemberStatesConcerningLiabilityforDefectiveProducts.” 419Luke R. Nottage and Jocelyn Kellam, “Europeanisation of Product Liability in the Asia-Pacific Region: A Preliminary Empirical Benchmark,” Legal  Studies Research Paper, No. 07/30 (Sydney Law School, May 1, 2007), https://doi.org/10.2139/ssrn.986530. The adoption happened in the following  years: 1992. Australia; 1993, People’s Republic of China; 1994, Taiwan; 1995, Japan; 1999, Malaysia and Indonesia; 2000, Korea. 420Reimann, “ProductLiabilityinaGlobalContext:TheHollowVictoryoftheEuropeanModel,” European Review of Private Law 11, no. 2 (2003): 128–54,  See also William Boger, “TheHarmonizationofEuropeanProductsLiabilityLaw,” Fordham International Law Journal 7, no. 1 (1983): 1–60; Cheon-Soo  Kim, “TheoriesandLegislationofProductsLiabilityintheSoutheastAsianCountries,” Journal of Social Studies Research 55 (1999). For China, see  Claudius Hans Taschner and Karola Taschner, 10 Jahre EG-Richtlinie Zur Produkthaftung : Rückblick, Umschau, Ausblick, vol. 15, Schriftenreihe  Deutscher Jura-Studenten in Genf (Genève: Unité de droit allemand, Faculté de droit, 1996., 1996), 13–14. 421“Overall, it would appear that China has chosen to follow the EC Directive rather than the US Third Restatement.” Kristie Thomas, “TheProductLiabilitySysteminChina:RecentChangesandProspects,” The International and Comparative Law Quarterly 63, no. 3 (July 2014): 755–75. The same  conclusion was reached by: Reimann, “ProductLiabilityinaGlobalContext:TheHollowVictoryoftheEuropeanModel.” 422Reimann, “ProductLiabilityinaGlobalContext:TheHollowVictoryoftheEuropeanModel” ; Alfred E. Mottur, “TheEuropeanProductLiabilityDirective: A Comparison with U.S. Law. An Analysis of Its Impact on Trade and a Recommendation for Reform so as to Accomplish Harmonisation and  ConsumerProtection,” Law and Policy in International Business 25 (1993-1994). 423Mathias Reimann, “Product Liability,” in Comparative Tort Law: Global Perspectives, ed. Mauro Bussani and Anthony J. Sebok, Research Handbooks  in Comparative Law (Edward Elgar Publishing Limited, 2021), 236–63. 424Reimann, “ProductLiabilityinaGlobalContext:TheHollowVictoryoftheEuropeanModel.” 425Reimann; European Parliament, “Directive95/46/ECoftheEuropeanParliamentandoftheCouncilof24October1995ontheProtectionofIndividualswithRegardtotheProcessingofPersonalDataandontheFreeMovementofSuchData” , art. 1-13. Reinmann discusses the complexities of US  liability law, which differs for every state. In contrast, the EU PLD has already been translated into 20 languages. In sum, other countries might have  not even understood the US Law “Foreign drafters might have just adopted whatever they understood.” 426Reimann, “ProductLiabilityinaGlobalContext:TheHollowVictoryoftheEuropeanModel.” Although the reports of the European commission see  the limited number of court cases as a sign of success of the PLD, as summarised in Bertolini, ArtificialIntelligenceandCivilLiability,55ff. 427In its 2001 Report, the Commission mentioned barely a hundred court decisions under the new regime for the last fifteen years in all the member states combined. 428This might be because the directive and other laws merely supplemented national law and the literature is critical how much the directive has actually  harmonised European product liability law at all. See: Mathias Reimann, “LiabilityforDefectiveProductsattheBeginningoftheTwenty-FirstCentury:  Emergence of a Worldwide Standard?,” The American Journal of Comparative Law 51, no. 4 (October 1, 2003): 751–838; Jane Stapleton, “Product 
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•78 tional liability regimes”.428It is generally difficult to measure compliance with liability law  since compliance can look differently for  every company.  In general, there is only weak evidence for  companies adopting changes in response to  any liability law. For example, a 2021 metastudy finds limited but inconclusive evidence  that firms reduce risks, internalise externalities, and add safety precautions after liability  law was passed.429Therefore, it remains unclear whether multinational firms become  more cautious in response to liability law updates for AI products and services.  While it is difficult to evaluate whether liability law has d omestic effects on company  behaviour, as discussed in the previous  paragraph, it is even more difficult to assess whether there has been a de facto  Brussels Effect of liability law: whether multinational companies have changed their  practices outside the EU in response to the  PLD.430 4.2.3. Conclusion We conclude tentatively that an EU liability law update for certain AI systems is  likely to cause a de jure Brussels Effect.  Countries that already use the PLD as a  blueprint will find it easiest to copy the  European approach to regulating liability  for AI and other emerging technologies.  At the same time, however, it is difficult to  measure to what extent (i) firms change in  response to liability legislation; (ii) that response is global, i.e. a de facto Brussels  Effect occurs; and (iii) EU law was causally  responsible for the adoption of similar legislation abroad, a de jure Brussels Effect. 4.3. Product Safety and CE  Marking The proposed EU AI Act would largely be part  of the EU product safety regulatory regime.  The act outlines that high-risk AI systems,  those applied to specific use cases, should first  be self-assessed in conformity assessments  before being sold on the common market –  though biometric identification systems must  be assessed by a conformity assessment body.  Products which are regulated in the “New Legislative Framework”, the EU product safety regime, and include AI systems must also abide  by the product safety rules of the AI Act.431 The  AI requirements are tested by the product-specific conformity assessment body. The AI  product safety requirements also apply to the  other harmonisation regulation (see Annex II,  Section B). The New Approach for product  safety, i.e. recent EU product safety rules, has  historically caused both a de jure and de facto  Brussels Effect. Thus, upcoming AI product  safety regulation might also lead to regulatory  diffusion. EU product safety regulations apply  to all EU imports but exclude EU exports. In  general, EU product safety legislation exhibited a strong de jure and de facto Brussels  Effect, making a future Brussels Effect more  likely for AI-specific product safety rules. 4.3.1TheEUProductSafetyFramework The EU uses the New Approach to product  safety, which originated in the 1985 Council  resolution on a New Approach to T echnical  Harmonization and Standardization.432This socalled New Legislative Framework consists of  29 mostly product-specific directives. The PSD  establishes the legal framework that implements the New Approach to product safety.  The conformity assessments apply to all EU imports but not EU exports. For these products,  such as electronics and children’s toys, regulat-APPENDIX: CASE STUDIES 429van Rooij, Brownlee, and Daniel Sokol, “DoesTortDeter?InconclusiveEmpiricalEvidenceabouttheEffectofLiabilityinPreventingHarmfulBehaviour.” 430Sara F. Liebman, “The European Community’s Products Liability Directive: Is the U.S. Experience Applicable?,” Law and Policy in International Business  18 (1986): 795–98. 431See AI Act, annex II. 432Ray Tricker, CE Conformity Marking: And New Approach Directives (Butterworth-Heinemann, 2000), chapters 1, 2, and 5. For more info, see European  Commission, “NewLegislativeFramework,” Internal Market, Industry, Entrepreneurship and SMEs, accessed July 14, 2022; Jacques Pelkmans, “The  NewApproachtoTechnicalHarmonizationandStandardization,” Journal of Common Market Studies 25, no. 3 (March 1987): 249–69; Carsten Ullrich, “NewApproachMeetsNewEconomy:EnforcingEUProductSafetyinE-Commerce,” Maastricht Journal of European and Comparative Law 26, no. 4  (August 1, 2019): 558–84. 433For a list, see Wikipedia contributors, “CEMarking,” Wikipedia, The Free Encyclopedia, July 8, 2022.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•79 434Veale and Borgesius, “DemystifyingtheDraftEUArtificialIntelligenceAct—AnalysingtheGood,theBad,andtheUnclearElementsoftheProposedApproach.” 435The second option is not common. VealeandBorgesius. 436European Parliament, “Directive 2009/48/EC of the European Parliament and of the Council of 18 June 2009 on the Safety of Toys,” CELEX number:  32009L0048, Official Journal of the European Union L 170 1 (June 18, 2009): 1–37.  437Marco de Morpurgo, “The European Union as a Global Producer of Transnational Law of Risk Regulation: A Case Study on Chemical Regulation,”  European Law Journal 19, no. 6 (November 2013): 779–98. 438Notably, the costs of leaving a market regulatory stringency, such as the EU, increase with the size of the market at hand.  439Hanson, CEMarking,ProductStandardsandWorldTrade. 440For more, see “the trade to the top” Bradford, TheBrusselsEffect:HowtheEuropeanUnionRulestheWorld. 441Hopkins and McNeill, “ExportingHardLawThroughSoftNorms:NewZealand’sReceptionofEuropeanStandards.”ory bodies and internal and external industry  experts develop safety goals and conformity  assessments.433Instead of requiring firms to implement specific measures, firms have to reach  safety targets. T o this end, the firms that are responsible for proving that their products are  safe a re free to use any means. They can follow  voluntary standards by the European Committee  for Standardization (CEN) and the European  Committee for Electrotechnical Standardization  (CENELEC) or have the safety of their products  verified independently. In practice, most companies follow the CEN and CENELEC standards.434 The EU AI Act says that approved non-governmental bodies need to conduct conformity assessments for biometric identification systems.  In all other cases, firms conduct a self-assessment, potentially relying on the CEN or  CENELEC standards, or verify the safety with  an approved non-governmental body.435Afterwards, the product gets a CE (Conformité  Européenne) mark and can be sold on the EU  market. 4.3.2.RegulatoryDiffusion The safety targets and specific guidelines developed for particular CE marks have exhibited strong de jure a nd de facto Brussels  Effects, making a Brussels Effect for the upcoming CE marking of high-risk AI applications  likely. Several prominent examples of the Brussels Effect, such as the chemical regulation  REACH, are part of this New Approach to  product safety. Other examples of the Brussels  Effect include the directives on the Safety of  T oys (88/378/EEC),436 Machinery (89/3321/ EEC), Medical Devices (93/42/EEC), Pressure  Equipment (97/23/EC), T elecommunication  T erminal Equipment (98/392/EEC), and pharmaceuticals.437National standards, for products that are not  covered under the EU product safety legislation, are less likely to exhibit regulatory diffusion, plausibly because they lack — in contrast to the EU — the regulatory coherence  (§2.3.2 ) and market size ( §2.1.1 ) necessary to  influence the international market and foreign jurisdictions. Regulation on the  European level makes compliance more  worthwhile for multinational firms.438 The EU conformity marking also caused a de  jure Brussels Effect. For example, the Chinese  conformity marking, “CCC”, developed in  2003, is similar to the EU system, the “CE”  mark.439The international influence of the EU  conformity marking is in part due to its stringency.440Local regulation agencies seek to  comply with key trading partners. Since the  European regulation is the most stringent and  non-EU regulators aim to maintain access to  the EU market, these regulators effectively  comply with EU regulation. Several countries  have incorporated “CE” marks into their national legislation to support their export industry. For instance, New Zealand incorporated all EU conformity marking standards in its  national law, especially in industries with significant exports to the EU market.441The United  States, the United Kingdom, and other countries are converging towards the European  standard level of conformity marking. However, this development is much slower for the  United States.442 In addition to the de jure Brussels Effect for  EU conformity marking, New Zealand and  Australia have also experienced a de facto  Brussels Effect. For example, wine regulation  is weaker in both countries than the EU  product safety rules for wine. Nevertheless, Australian wine producers and exporters decided to APPENDIX: CASE STUDIES
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•80 comply with the EU export requirements, exemplifying a de facto Brussels Effect443Moreover , the  CE mark has become a promin ent product quality signal in New Zealand since the country lacks  a national product safety mark and the market is  dominated by Asian imports, which consumers  trust less.444This means that the revenue from  non-differentiation is higher. The Commission also uses free trade agreements as a channel to promote the regulatory diffusion of CE marking. For instance, the  free trade agreements with Mexico and Mercosur in 2019 include a commitment to the  local adoption of CE marking.445 Moreover, Canada, the United States, Australia, Switzerland, and New Zealand have  Mutual Recognition Agreements on Conformity Assessment (MRA) with the EU.446These  agreements entail the reciprocal acceptance  of conformity assessments for two jurisdictions with similar product safety levels and  equivalent assessment authorities for particular product families. If a country raises its  standards to a level on par with the CE mark  and establishes an MRA with the EU, the national industry avoids costs when trading with  the EU or expanding to the EU market. Hence,  the possibility of MRAs makes the copying of  EU-like regulation more attractive and a de  jure Brussels Effect more likely.447 There are three more explanations for the de jure  Brussels Effect exhibited by the EU product safety  regulations. First, the EU actively promoted its  product safety regulations worldwide.448Second,  the EU wields substantial influence in international  standard setting bodies, which have adopted as-pects of European product safety regulations and  serve as a channel for the de jure Brussels  Effect.449Third, corporate interest groups have a  strong interest in the convergence of product  safety standards for all globalised markets. For this  reason, medical technology companies lobbied  for the international convergence of medical  devices.450However , whether an internationally  harmonised standard setting procedure increases  or decreases the de jure Brussels Effect of CE  marking remains unclear . Convergence on standard setting could lead to international standards  being adopted that are lower than the EU rules,  therefore weakening the de jure and de facto  Brussels Effects.451On the other han d, some International Organization for Standardization (ISO)  standards are the same as the EU standards. For  example, the European standard EN 1050 (risk assessment for machinery) became ISO 14120, and  EN 292 (machinery safety) became ISO 1200-1.452 See also the discussion in section 3.2 . 4.3.3.Conclusion European product safety regulation and the CE  mark led to substantial global regulatory diffusion. The EU’s strategy to regulate only safety targets rather than specific safety precautions appears effective. This strategy ensures that  product safety does not hind er innovation and  supports the regulation of rapidly developing  technologies and products, such as AI systems.453The CE mark is considered a sign of  product quality, which increases the revenue  from non-differentiation and contributes positively to the de facto Brussels Effect.APPENDIX: CASE STUDIES 443Fini, “TheEUasForceto‘DoGood’:TheEU’sWiderInfluenceonEnvironmentalMatters.” 444Hopkins and McNeill, “ExportingHardLawThroughSoftNorms:NewZealand’sReceptionofEuropeanStandards.” 445For the 2019 agreement, see European Commission, “Trade Part of the EU-Mercosur Association Agreement Without Prejudice,” 2019, and for the  general strategy; Hanson, CEMarking,ProductStandardsandWorldTrade, 190. 446For a list of MRAs, see: European Commission, “MutualRecognitionAgreements,” Internal Market, Industry, Entrepreneurship and SMEs, accessed July 14, 2022. 447See Björkdahl et al., ImportingEUNormsConceptualFrameworkandEmpiricalFindings, vol. 8, chap. 8. 448Hanson, CEMarking,ProductStandardsandWorldTrade, 19. 449Hairston, “Hunting for Harmony in Pharmaceutical Standards.” 450In the past in the GHTF and after 2012 in the IMRDF International Medical Device Regulators Forum, “About IMDRF,” International Medical Device  Regulators Forum, accessed July 14, 2022. 451For a discussion, see Peter Cihon’s FHI report: Cihon, “Standards for AI Governance: International Standards to Enable Global Coordination in AI  Research & Development.” More specifically, international standards weaken the Brussels Effect if the standards are weaker than national laws  passed by non-EU countries in response to EU rules in the absence of international rules. 452Hopkins and McNeill, “Exporting Hard Law Through Soft Norms: New Zealand’s Reception of European Standards.” 453For discussion on for instance privacy by design: Eric Lachaud, “Could the CE Marking Be Relevant to Enforce Privacy by Design in the Internet of  Things?,” in Data Protection on the Move: Current Developments in ICT and Privacy/Data Protection, ed. Serge Gutwirth, Ronald Leenes, and Paul De  Hert (Dordrecht: Springer Netherlands, 2016), 135–62.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•81  References Acemoglu, Daron. “Harms of AI. ” Working Paper Series 29247 . Cambridge, MA: National Bureau of Economic Research, September 2021. https://doi.org/10.3386/w29247 . Acemoglu, Daron, Andrea Manera, and Pascual Restrepo. “Does the US T ax Code Favor Automation?”  Working Paper Series 27052. National Bureau of Economic Research, April 2020. https://doi.org/ 10.3386/w27052 . Ada Lovelace Institute. “People, Risk and the Unique Requirements of AI: 18 Recommendations to  Strengthen the EU AI Act. ” Ada Lovelace Institute , March 31, 2022. https://www.adalovelaceinstitute .org/policy-briefing/eu-ai-act/ . Agência Câmara de Notícias. “Câmara aprova projeto que regulamenta uso da inteligência artificial. ” Portal  da Câmara dos Deputados, September 9, 2021. https://www.camara.leg.br/noticias/811702-camaraaprova-projeto-que-regulamenta-uso-da-inteligencia-artificial . Agência Senado. “Brasil poderá ter marco regulatório para a inteligência artificial. ” Senado Federal, March  3, 2022. https://www12.senado.leg.br/noticias/materias/2022/03/30/brasil-podera-ter-marco-regulatorio-para-a-inteligencia-artificial . Agrawal, Ajay, Joshua Gans, and Avi Goldfarb, eds. The Economics of Artificial Intelligence: An Agenda,  2019. https://www.nber .org/books-and-chapters/economics-artificial-intelligence-agenda . Akerlof, George A. “The Market for ‘Lemons’: Quality Uncertainty and the Market Mechanism. ” The Quarterly Journal of Economics 84, no. 3 (August 1, 1970): 488–500. https://doi.org/10.2307/1879431 . Altenstetter , Christa, and Govin Permanand. “EU Regulation of Medical Devices and Pharmaceuticals in  Comparative Perspective. ” The Review of Policy Research 24, no. 5 (September 2007): 385–405.  https://doi.org/10. 1111/j. 1541-1338.2007 .00291.x . Amazon.com, Inc. “Form 10-Q. ” Washington, D.C., June 30, 2021. https://www.sec.gov/ix?doc=/Archives/ e d g a r / d a t a / 0 0 0 1 0 1 8 7 2 4 / 0 0 0 1 0 1 8 7 2 4 2 1 0 0 0 0 2 0 / a m z n - 2 0 2 1 0 6 3 0 . h t m#i5986f88ea1e04d5c91ff09fed8d716f0_103 . Argomaniz, Javier . “When the EU Is the ‘Norm-taker’: The Passenger Name Records Agreement and the  EU’s Internalization of US Border Security Norms. ” Journal of European Integration 31, no. 1 (January 1,  2009): 119–36. https://doi.org/10. 1080/07036330802503981 . Bach, David, and Abraham L. Newman. “The European Regulatory State and Global Public Policy: MicroInstitutions, Macro-Influence. ” Journal of European Public Policy 14, no. 6 (September 1, 2007):  827–46. https://doi.org/10. 1080/13501760701497659 . Baraniuk, Chris. “Tim Cook Blasts ‘Weaponisation’ of Personal Data and Praises GDPR. ” BBC. October 24,  2018. https://www.bbc.com/news/technology-45963935 .
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•82 Barrett, Catherine. “Emerging T rends from the First Y ear of EU GDPR Enforcement.” Data, Spring 2020  16, no. 3 (2020): 22–25. https://www.americanbar .org/groups/science_technology/publications/ scitech_lawyer/2020/spring/emerging-trends-the-first-year-eu-gdpr-enforcement/ . Berkeley Electronic Press. “Flying T oo High? Extraterritoriality and the EU Emissions T rading Scheme: The  Air T ransport Association of America Judgment. ” Eutopia Law, 2012. https://works.bepress.com/brianhavel/27/ . Bertolini, Andrea. Artificial Intelligence and Civil Liability. PE 621.926. European Parliament, 2020. https:// doi.org/doi/10.2861/220466 . Birdsall, Nancy, and David Wheeler . “T rade Policy and Industrial Pollution in Latin America: Where Are the  Pollution Havens?” Journal of Environment & Development 2, no. 1 (January 1993): 137–49. https:// doi.org/10. 1177/107049659300200107 . Björkdahl, Annika, Natalia Chaban, John Leslie, and Annick Masselot, eds. Importing EU Norms Conceptual  Framework and Empirical Findings. Vol. 8. United Nations University Series on Regionalism 8.  Springer International Publishing, 2015. https://doi.org/10. 1007/978-3-319-13740-7 . Blankertz, Aline, and Julian Jaursch. “What the European DSA and DMA Proposals Mean for Online Platforms. ” Brookings, January 14, 2021. https://www.brookings.edu/techstream/what-the-european-dsaand-dma-proposals-mean-for-online-platforms/ . Boger ,William.“TheHarmonizationofEuropeanProductsLiabilityLaw . ”FordhamInternationalLawJournal7 ,no.1(1983):  1–60 . https://ir .lawnet. fordham.edu/cgi/viewcontent.cgi?article=1081&conte xt=ilj . Bommasani,Rishi,DrewA.Hudson,EhsanAdeli,RussAltman,SimranArora,SydneyvonArx,MichaelS.Bernstein,etal.  “OntheOpportunitiesandRisksofFoundationModels. ”arXiv ,2021. https://doi.org/10 .48550/ARXIV .2108.07258 . Bossong,R aphael,andHelenaCarrapico,eds.EUBordersandShiftingInternalSecurity:T echnology ,Externalizationand  Accountability .SpringerInternationalPublishing,2016. https://doi.org/10 . 1007/978-3-319-17560-7 . Bradford,Anu.“TheBrusselsEffect. ”NorthwesternUniversityLawR eview107 .NorthwesternUniversitySchoolofLaw ,  2012. https://scholarship.law .columbia.edu/faculty_scholarship/271 . ———.“TheBrusselsEffectComesforBigT ech, ”December17 ,2020 . https://www .project-syndicate.org/commentary/eudigital-services-and-mark ets-regulations-on-big-tech-by-anu-bradford-2020-12 . ———. The Brussels Effect: How the European Union Rules the W orld. Oxford University Press, 2020 . https://doi.org/ 10 . 1093/oso/9780190088583.001.0001 . Brown,JohnPrather .“T owardanEconomicTheoryofLiability . ”TheJournalofLegalStudies2,no.2(June1,1973):323–49 .  https://doi.org/10 . 1086/467501 . Brown,T om,BenjaminMann,NickRyder ,MelanieSubbiah,JaredD .Kaplan,PrafullaDhariwal,ArvindNeelakantan,etal.  “LanguageModelsAreFew-ShotLearners. ”InAdvancesinNeuralInformationProcessingSystems33(NeurIPS  2020), 1877–1901. Curran Associates, Inc., 2020 . https://proceedings.neurips.cc/paper/2020/hash/ 1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html . Buchholz,Katharina.“ AmericansAcceptFacialR ecognitionforPublicSafety . ”Statista,June10 ,2020 . https://www .statista .com/chart/19321/facial-recognition-public-opinion/ . Bygrave, Lee A. “The ‘Strasbourg Effect’ on Data Protection in Light of the ‘Brussels Effect’: Logic, Mechanics and  Prospects. ”ComputerLaw&SecurityR eview40(April1,2021):105460 . https://doi.org/10 . 1016/j.clsr .2020 . 105460 . CaliforniaSenate.AnacttoaddChapter6(commencingwithSection17940)toP art3ofDivision7oftheBusinessand  ProfessionsCode,relatingtobots,Pub.L.No.1001,CHAPTER892(2018). http://bcn.cl/2b6q3 . CaliforniaStateLegislature.“BillT e xt-AB-375Privacy:PersonalInformation:Businesses, ”June29 ,2018. https://leginfo.legislature.ca.gov/faces/billT e xtClient.xhtml?bill_id=201720180AB375 . Casado, Martin, and Matt Bornstein. “The New Business of AI (and How It’s Different From T raditional Software). ” Future, February 16, 2020. https://future.com/new-business-ai-different-traditional-software/ .
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•83 CEN-CENELEC. “ISO and IEC. ” CEN-CENELEC. Accessed July 14, 2022. https://www.cencenelec.eu/european-standardization/international-cooperation/iso-and-iec/ . Chander , Anupam, and Uyên P . Lê. “Data Nationalism. ” Emory Law Journal 64, no. 3 (2015): 677 . https:// scholarlycommons.law.emory.edu/elj/vol64/iss3/2 . Chun, Andy . “Europe’s AI Regulation Seeks a Balance between Innovation and Risk. Is Hong Kong Ready?”  South China Morning Post, March 18, 2022. https://www.scmp.com/comment/opinion/article/3170674/europes-ai-regulation-seeks-balance-between-innovation-and-risk . Cihon, Peter . “Standards for AI Governance: International Standards to Enable Global Coordination in AI Research & Development. ” Center for the Governance of AI Future of Humanity Institute, University of  Oxford, April 2019. https://www.fhi.ox.ac.uk/wp-content/uploads/Standards_-FHI-T echnical-Report .pdf. Circiumaru, Alexandru. “Three Proposals to Strengthen the EU Artificial Intelligence Act, ” December 13,  2021. https://www.adalovelaceinstitute.org/blog/three-proposals-strengthen-eu-artificial-intelligenceact/. CITRIS Policy Lab. “Fair , Reliable, and Safe: California Can Lead the Way on AI Policy to Ensure Benefits for All. ”  Medium, May 28, 2019. https://medium.com/citrispolicylab/fair-reliable-and-safe-california-can-lead-theway-on-ai-policy-to-ensure-benefits-for-all-33895afd4a0f . CMS.“GDPREnforcementT racker . ”AccessedJuly13,2022. https://www .enforcementtracker .com/. CNIL. “Cookies: la CNIL sanctionne GOOGLE à hauteur de 150 millions d’euros. ” CNIL, January 6, 2022.  https://www.cnil.fr/fr/cookies-la-cnil-sanctionne-google-hauteur-de-150-millions-deuros . ———.“Cookies:sanctionde60millionsd’eurosàl’encontredeFACEBOOKIRELANDLIMITED. ”CNIL,January 6, 2022. https://www.cnil.fr/fr/cookies-sanction-de-60-millions-deuros-lencontre-de-facebookireland-limited . ———. “The Sanctions Issued by the CNIL. ” CNIL, December 1, 2021. https://www.cnil.fr/en/sanctions-issued-cnil . Cole, Arthur . “ AI T echnology Modernizes Warehouse Management, ” November 1, 2021. https://venturebeat .com/2021/11/01/ai-technology-modernizes-warehouse-management/ . Colvin, Jeremy. “Unchecked Ambiguity and the Globalization of User Privacy Controls Under the GDPR. ”  Edited by Jonathan Mayer . Senior Theses, Princeton University, 2019. http://arks.princeton.edu/ark:/ 88435/dsp010z709028q . “Consolidated T ext: Council Directive 85/374/EEC of 25 July 1985 on the Approximation of the Laws, Regulations and Administrative Provisions of the Member States Concerning Liability for Defective Products. ” CELEX number: 01985L0374-19990604, June 4, 1999. https://eur-lex.europa.eu/legal-content/ EN/ALL/?uri=CELEX:01985L0374-19990604 . Council of Europe. “CAHAI - Ad Hoc Committee on Artificial Intelligence. ” Artificial Intelligence. Accessed  July 14, 2022. https://www.coe.int/en/web/artificial-intelligence/cahai . ———. “Details of T reaty No. 108. ” Council of Europe. Accessed July 14, 2022. https://www.coe.int/en/web/ conventions/full-list?module=treaty-detail&treatynum=108 . Court of Justice of the European Union. “ Judgment in Case C-362/14 Maximillian Schrems v Data Protection  Commissioner: The Court of Justice Declares That the Commission’s US Safe Harbour Decision Is Invalid. ” Press Release 117/15. Court of Justice of the European Union , October 6, 2015. https://curia.europa.eu/jcms/upload/docs/application/pdf/2015-10/cp150117en.pdf . Creemers, Rogier , and Graham Webster . “T ranslation: Internet Information Service Deep Synthesis Management Provisions (Draft for Comment) – Jan. 2022. ” DigiChina, February 4, 2022. https://digichina.stanford.edu/work/translation-internet-information-service-deep-synthesis-management-provisions-draftfor-comment-jan-2022/ . Curry, David. “Food Delivery App Revenue and Usage Statistics (2022). ” Business of Apps, October 29,  2020. https://www.businessofapps.com/data/food-delivery-app-market/ .
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•84 ———. “T axi App Revenue and Usage Statistics (2022). ” Business of Apps, November 10, 2020. https://www .businessofapps.com/data/taxi-app-market/ . Damen, Mario. “The European Union and Its T rade Partners. ” Fact Sheets on the European Union. European Parliament, September 2021. https://www.europarl.europa.eu/factsheets/en/sheet/160/the-european-union-and-its-trade-partners . Damro, Chad. “Market Power Europe. ” Journal of European Public Policy 19, no. 5 (June 1, 2012): 682–99.  https://doi.org/10. 1080/13501763.2011.646779 . Darmody, Jenny. “Explainer: What Y ou Need to Know about the WhatsApp Update. ” Siliconrepublic, January 14, 2021. https://www.siliconrepublic.com/enterprise/whatsapp-update-facebook-data . Daskal, Jennifer . “Borders and Bits. ” Vanderbilt Law Review 71, no. 1 (2018): 179. https://scholarship.law.vanderbilt.edu/vlr/vol71/iss1/3 . Dastin, Jeffrey. “ Amazon Scraps Secret AI Recruiting T ool That Showed Bias against Women. ” REUTERS.  Reuters, October 10, 2018. https://www.reuters.com/article/us-amazon-com-jobs-automation-insightidUSKCN1MK08G . Data Protection Commission. “Data Protection Commission Statement on Funding in 2021 Budget. ” Data  Protection Commission, October 13, 2020. https://www.dataprotection.ie/en/news-media/press-releases/data-protection-commission-statement-funding-2021-bud-get#:~:text=The Data Protection  Commission . DCMS, and BEIS. “ A New pro-Competition Regime for Digital Markets - Government Response to Consultation,  Command Paper: CP 657 , ” May 6, 2022. https://www.gov .uk/government/consultations/a-new-pro-competition-regime-for-digital-markets/outcome/a-new-pro-competition-regime-for-digital-markets-government-response-to-consultation . DeepMind.“DeepMindR esponsetotheArticialIntelligenceAct, ”August5,2021. https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F2665473_en . DeloitteLLP .“DeliveringGrowth. ”DeloitteUnitedKingdom,November26,2019 . https://www2.deloitte.com/uk/en/pages/ financial-advisory/articles/delivering-growth.html . Dempsey ,Mark,K eeganMcBride,MeeriHaataja,andJoannaJ .Bryson.“T ransnationalDigitalGovernanceandItsImpact  on Artificial Intelligence. ” In The Oxford Handbook of AI Governance, edited by Justin Bullock, Y u-Che Chen, Johannes Himmelreich, V alerie M. Hudson, Anton K orinek, Matthew Y oung, and Baobao Zhang. Oxford University  Press,May19 ,2022. https://doi.org/10 . 1093/o xfordhb/9780197579329 .013. 16 . D e s l a n d e s ,J e r o m e ,M a g n u sM a r c e l ,a n dC r i s t i n aP a c h e c oD i a s .“ T h i r dC o u n t r yE q u i v a l e n c ei nE UB a n k i n ga n dF i n a n c i a lR e g u l a t i o n . ” E u r o p e a n P a r l i a m e n t , A u g u s t 2 0 1 9 . h t t p s : / / w w w . e u r o p a r l . e u r o p a . e u / R e g D a t a / e t u d e s / I D A N / 2 0 1 8 / 6 1 4 4 9 5 / I P O L _ I D A ( 2 0 1 8 ) 6 1 4 4 9 5 _ E N . p d f . DeSombre, Elizabeth R. “The Experience of the Montreal Protocol: P articularly R emarkable, and R emarkably P articular . ”  UCLAJournalofEnvironmentalLawandPolicy19 ,no.1(2000). https://doi.org/10 .5070/L5191019217 . “DevelopmentsintheLaw:Extraterritoriality . ”HarvardLawR eview124,no.5(2011):1226–1304. https://www .jstor .org/stable/ 25800158 . Devlin,Jacob,Ming- W eiChang,K entonL ee,andKristinaT outanova.“BER T :Pre-T rainingofDeepBidirectionalT ransformers  forL anguageUnderstanding. ”ar Xiv[cs.CL],October11,2018.ar Xiv . http://arxiv .org/abs/1810 .04805 . Ding,Jeffrey .“ChinAI#168:AroundtheHorn(edition6). ”ChinAINewsletter ,January9 ,2022. https://chinai.substack.com/p/chinai-168-around-the-horn-edition . ———. “ChinAI #182: China’ s R egulations on R ecommendation Algorithms. ” ChinAI Newsletter , May 9 , 2022. https://chinai.substack.com/p/chinai-182-chinas-regulations-on ?s=r . Di r e c t o r a t e - G e n e r a lf o rN e i g h b o u r h o o da n dE n l a r g e m e n tN e g o t i a t i o n s .“ S p e e c hb yP r e s i d e n t - E l e c tv o nD e rL e y e ni nt h eE u r o p e a nP a r l i a m e n tP l e n a r yo nt h eO c c a s i o no ft h eP r e s e n t a t i o no fH e rC o l l e g eo fC o m m i s s i o n e r sa n dT h e i rP r o g r a m m e . ”E u r o p e a nN e i g h b o u r h o o dP o l i c ya n dE n l a r g e m e n tN e g o t i a t i o n s ,N o v e m b e r2 7 ,2 0 1 9 . h t t p s : / / e c . e u r o p a . e u / n e i g h b o u r h o o d - e n largement/news/speech-president-elect-von-der-leyen-european-parliament-plenary-occasion-presentation-herc o l l e g e - 2 0 1 9 - 1 1 - 2 7 _ e n .
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•85 Drake, Griffin. “Navigating the Atlantic: Understanding EU Data Privacy Compliance amidst a Sea of Uncertainty . ”  SouthernCaliforniaLawReview91,no.1(November2 017). https://southerncalifornialawreview .com/wp-content/uploads/2018/02/91_163.pdf . Drezner , Daniel W . “Globalization, Harmonization, and Competition: The Different Pathways to Policy Convergence. ” Journal of European Public Policy 12, no. 5 (October 1, 2005): 841–59. https://doi.org/ 10. 1080/13501760500161472 . Duffy, Clare, and CNN Business. “T op Microsoft Exec Says Online Privacy Has Reached ‘a Crisis Point. ’” CNN  Business, October 14, 2019. https://edition.cnn.com/videos/business/2019/10/11/brad-smith-microsoftanti-trust-boss-files-orig.cnn-business . Eden, Sally. Environmental Issues and Business: Implications of a Changing Agenda. Wiley, 1996. Implications. EMERGO.“EuropeMedicalDevicesRegulation(MDR)CEMarkingRegulatoryProcess. ”EMERGO,August23,  2017 . https://www.emergobyul.com/resources/europe-medical-devices-regulation-mdr-ce-marking-regulatory-process . Engler , Alex. “The EU AI Act Will Have Global Impact, but a Limited Brussels Effect. ” Brookings, June 8, 2022.  https://www.brookings.edu/research/the-eu-ai-act-will-have-global-impact-but-a-limited-brussels-effect/ . EPIC. “ At G-20, Merkel Calls for Comprehensive AI Regulation. ” EPIC - Electronic Privacy Information Center ,  June 28, 2019. https://epic.org/at-g-20-merkel-calls-for-comprehensive-ai-regulation/ . Eurobarometer . “ Attitudes towards the Impact of Digitisation and Automation on Daily Life. ” European Commission, May 2017 . https://perma.cc/9FRT -ADST . EuropeanCommission.“ AdequacyDecisions:HowtheEUDeterminesIfaNon-EUCountryHasanAdequate  Level of Data Protection. ” European Commission. Accessed July 14, 2022. https://ec.europa.eu/info/ law/law-topic/data-protection/international-dimension-data-protection/adequacy-decisions_en . ———. “ Annex to the Communication from the Commission to the European Parliament, the European Council, the Council, the European Economic and Social Committee and the Committee of the Regions, ” December 7 , 2018. https://eur-lex.europa.eu/resource.html?uri=cellar:22ee84bb-fa04-11e8a96d-01aa75ed71a1.0002.02/DOC_2&format=PDF . ———. “Civil Liability – Adapting Liability Rules to the Digital Age and Artificial Intelligence. ” European Commission, 2021. https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12979-Civil-liabilityadapting-liability-rules-to-the-digital-age-and-artificial-intelligence_en . ———. “Commission Collects Views on Making Liability Rules Fit for the Digital Age, Artificial Intelligence and  Circular Economy. ” Internal Market, Industry, Entrepreneurship and SMEs, October , 20 2021. https:// ec.europa.eu/growth/news/commission-collects-views-making-liability-rules-fit-digital-age-artificial-intelligence-and-2021-10-20_en . ———.“CommissionStaffWorkingDocumentImpactAssessmentAccompanyingtheProposalforaRegulation  oftheEuropeanParliamentandoftheCouncilLayingDownHarmonisedRulesonArtificialIntelligence(ArtificialIntelligenceAct)andAmendingCertainUnionLegislativeActsSWD/2021/84Final. ”CELEXnumber:  52021SC0084, April 21, 2021. https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/ ?uri=CELEX:52021SC0084 . ———. “Commission Staff Working Document Liability for Emerging Digital T echnologies Accompanying the  Document Communication from the Commission to the European Parliament, the European Council,  the Council, the European Economic and Social Committee and the Committee of the Regions Artificial  Intelligence for Europe SWD/2018/137 Final. ” CELEX number: 52018SC0137 , April 25, 2018. https://eurlex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:52018SC0137 . ———. “Communication from the Commission to the European Parliament, the Council, the European Economic and Social Committee and the Committee of the Regions Shaping Europe’s Digital Future. ”  CELEX number: 52020DC0067 , February 19, 2020. https://eur-lex.europa.eu/legal-content/en/TXT/ ?uri=CELEX:52020DC0067 . ———. “EMAS – Environment, ” June 14, 2016. https://ec.europa.eu/environment/emas/index_en.htm .
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•86 ———. Ethics Guidelines for T rustworthy AI. Publications Office of the European Union, 2019. https://data.europa.eu/doi/10.2759/346720 . ———. “EU Member States Sign up to Cooperate on Artificial Intelligence. ” Shaping Europe’s digital future,  April 10, 2018. https://digital-strategy.ec.europa.eu/en/news/eu-member-states-sign-cooperate-artificialintelligence . ———. “EU-US Data T ransfers: How Personal Data T ransferred between the EU and US Is Protected. ” European  Commission.AccessedJuly14,2022. https://ec.europa.eu/info/law/law-topic/data-protection/internationaldimension-data-protection/eu-us-data-transfers_en . ———. “EU-US Launch T rade and T echnology Council to Lead V alues-Based Global Digital T ransformation. ”  EuropeanCommission-Pressrelease,June15,2022. https://ec.europa.eu/commission/presscorner/detail/en/IP_21_2990 . ———. “Expert Group on Liability and New T echnologies (E03592). ” Register of Commission expert groups  andothersimilarentities,July27 ,2021. https://ec.europa.eu/transparency/expert-groups-register/screen /expert-groups/consult?do=groupDetail.groupDetail&groupID=3592 . ———. “Fines for Breaking EU Competition Law, ” November 2011. https://ec.europa.eu/competition/cartels/ overview/factsheet_fines_en.pdf . ———.“GeneralDataProtectionRegulationShowsResults,butWorkNeedstoContinue. ”EuropeanCommission, July 24, 2019. https://ec.europa.eu/commission/presscorner/detail/en/IP_19_4449 . ———.“High-LevelExpertGrouponArtificialIntelligence. ”ShapingEurope’sdigitalfuture,June7 ,2022. https:/ /digital-strategy.ec.europa.eu/en/policies/expert-group-ai . ———. “Inception Impact Assessment: Proposal for a Directive Adapting Liability Rules to the Digital Age and  Artificial Intelligence, ” June 6, 2021. https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=PI_COM:Ares(2021)4266516 . ———. “Mutual Recognition Agreements. ” Internal Market, Industry, Entrepreneurship and SMEs. Accessed  July 14, 2022. https://ec.europa.eu/growth/single-market/goods/international-aspects-single-market/ mutual-recognition-agreements_en . ———.“NewLegislativeFramework. ”InternalMarket,Industry,EntrepreneurshipandSMEs.AccessedJuly14,  2022. https://ec.europa.eu/growth/single-market/goods/new-legislative-framework_en . ———. “On Artificial Intelligence - A European Approach to Excellence and T rust COM/2020/65 Final. ” CELEX  number: 52020DC0065, February 19, 2020. https://eur-lex.europa.eu/legal-content/EN/TXT/ ?uri=CELEX:52020DC0065 . ———. “Proposal for a Regulation of the European Parliament and of the Council Laying Down Harmonised  Rules on Artificial Intelligence (Artificial Intelligence Act) and Amending Certain Union Legislative Acts  COM/2021/206 Final. ” CELEX number: 52021PC0206, April 21, 2020. https://eur-lex.europa.eu/legalcontent/EN/TXT/?uri=CELEX:52021PC0206 . ———. “Proposal for a Regulation of the European Parliament and of the Council on a Single Market for Digital  Services(DigitalServicesAct)andAmendingDirective2000/31/ECCOM/2020/825Final. ”CELEXnumber: 52020PC0825, Dec, 15,2020. https://eur-lex.europa.eu/legal-content/en/TXT/?uri=COM:2020:825:FIN . ———. “Proposal for a Regulation of the European Parliament and of the Council on Contestable and Fair Markets in the Digital Sector (Digital Markets Act) COM/2020/842 Final. ” CELEX number: 52020PC0842,  December 15, 2020. https://eur-lex.europa.eu/legal-content/en/TXT/?uri=COM:2020:842:FIN . ———. “Public Consultation on the AI White Paper: Final Report, ” November 2020. ———. “Speech by Executive Vice-President V estager at the Press Conference on Fostering a European Approach to Artificial Intelligence, ” April 21, 2021. https://ec.europa.eu/commission/presscorner/detail/en/ speech_21_1866 . ———. “The EU Code of Conduct on Countering Illegal Hate Speech Online: The Robust Response Provided  by the European Union. ” Accessed July 11, 2022. https://ec.europa.eu/info/policies/justice-and-funda-
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•87 mental-rights/combatting-discrimination/racism-and-xenophobia/eu-code-conduct-countering-illegalhate-speech-online_en . ———. “T rade Part of the EU-Mercosur Association Agreement Without Prejudice, ” 2019. https://trade.ec.europa.eu/doclib/docs/2019/july/tradoc_158153. T echnical Barriers to T rade.pdf . ———. “White Paper on Artificial Intelligence - a European Approach. ” European Commission. Accessed July  12, 2022. https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12270-White-Paperon-Artificial-Intelligence-a-European-Approach/public-consultation_en . European Commission, and Directorate-General for Communications Networks, Content and T echnology.  “Shaping Europe’s Digital Future. ” Publications Office, 2020. https://doi.org/doi/10.2759/091014 . European Commission, Directorate-General for Internal Market, Industry , Entrepreneurship, and SMEs. “Evaluation of Council Directive 85/374/EEC on the Approximation of Laws, Regulations and Administrative Provisions of the Member States Concerning Liability for Defective Products: Final Report. ” European Union,  2018. https://doi.org/doi/10.2873/477640 . European Commission, and Directorate-General for Justice and Consumers. Liability for Artificial Intelligence  and Other Emerging Digital T echnologies. Publications Office of the European Union, 2019. https:// doi.org/doi/10.2838/573689 . European Data Protection Board. “First Overview on the Implementation of the GDPR and the Roles and  Means of the National Supervisory Authorities. ” EDPB, February 26, 2019. European Parliament. “2021/0170(COD), ” 2021. https://oeil.secure.europarl.europa.eu/oeil/popups/ficheprocedure.do?reference=2021/0170(COD)&l=en . ———. “Digital Markets Act: EP Committee Endorses Agreement with Council, ” May 16, 2022. https://www.europarl.europa.eu/news/en/press-room/20220516IPR29641/digital-markets-act-ep-committee-endorses-agreement-with-council . ———. “Digital Services Act: Agreement for a T ransparent and Safe Online Environment, ” April 23, 2022. https:// www.europarl.europa.eu/news/en/press-room/20220412IPR27111/digital-services-act-agreement-for-atransparent-and-safe-online-environment . ———. “Digital Services: Landmark Rules Adopted for a Safer , Open Online Environment, ” May 7 , 2022. https:/ /www.europarl.europa.eu/news/en/press-room/20220701IPR34364/digital-services-landmark-rulesadopted-for-a-safer-open-online-environment . ———. “Directive 95/46/EC of the European Parliament and of the Council of 24 October 1995 on the Protection of Individuals with Regard to the Processing of Personal Data and on the Free Movement of Such  Data. ” CELEX number: 31995L0046. Official Journal of the European Communities L 281 31 (November  23, 1995). https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:31995L0046 . ———. “Directive 2001/95/EC of the European Parliament and of the Council of 3 December 2001 on General  Product Safety (T ext with EEA Relevance). ” CELEX number: 32001L0095. Official Journal of the European Union L 11, January 15, 2002, 4–17 . https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/ ?uri=CELEX:32001L0095 . ———. “Directive 2009/48/EC of the European Parliament and of the Council of 18 June 2009 on the Safety  of T oys. ” CELEX number: 32009L0048. Official Journal of the European Union L 170 1 (June 18, 2009):  1–37 . https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32009L0048 . ———. “General Product Safety Regulation. ” Legislative T rain Schedule European Parliament, June 23, 2022.  https://www.europarl.europa.eu/legislative-train/theme-a-new-push-for-european-democracy/file-revisionof-the-general-product-safety-directive . ———. “Regulation (EC) No 1221/2009 of the European Parliament and of the Council of 25 November 2009  on the V oluntary Participation by Organisations in a Community Eco-Management and Audit Scheme  (EMAS), Repealing Regulation (EC) No 761/2001 and Commission Decisions 2001/681/EC and  2006/193/EC. ” CELEX number: 32009R1221. Official Journal of the European Union L 342 1 (November  25, 2009). https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32009R1221 . ———. “Regulation (EC) No 1907/2006 of the European Parliament and of the Council of 18 December 2006  Concerning the Registration, Evaluation, Authorisation and Restriction of Chemicals (REACH), Establish-
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•88 ing a European Chemicals Agency, Amending Directive 1999/45/EC and Repealing Council Regulation  (EEC) No 793/93 and Commission Regulation (EC) No 1488/94 as Well as Council Directive 76/769/EEC  and Commission Directives 91/155/EEC, 93/67/EEC, 93/105/EC and 2000/21/EC. ” CELEX number:  32006R1907 . Official Journal of the European Union L 396 49 (December 2006). https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32006R1907 . ———. “Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the ProtectionofNaturalPersonswithRegardtotheProcessingofPersonalDataandontheFreeMovementof  Such Data, and Repealing Directive 95/46/EC (General Data Protection Regulation) (T ext with EEA Relevance). ”OfficialJournaloftheEuropeanUnionL1191(May2016). https://eur-lex.europa.eu/legal-content/ EN/TXT/HTML/?uri=CELEX:32016R0679 . Evas, T atjana. “European Framework on Ethical Aspects of Artificial Intelligence, Robotics and Related T echnologies: European Added V alue Assessment : Study. ” European Parliamentary Research Service,  2020. https://doi.org/10.2861/94107 . Facebook. “Response to the European Commission’s Proposed AI Act, ” August 6, 2021. https://ec.europa.eu/ info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F2665607_en . Fefer , Rachel F. “EU Digital Policy and International T rade. ” R46732. Congressional Research Service, March  25, 2021. Fini, Melissa. “The EU as Force to ‘Do Good’: The EU’s Wider Influence on Environmental Matters. ” Australian  and New Zealand Journal of European Studies 3, no. 1 (May 5, 2011). https://doi.org/10.30722/anzjes. vol3.iss1. 15115 . Funk, Jeffrey. “ AI and Economic Productivity: Expect Evolution, Not Revolution. ” IEEE Spectrum, December 5,  2019. https://spectrum.ieee.org/ai-and-economic-productivity-expect-evolution-not-revolution . Future of Life Institute. “FLI Position Paper on the EU AI Act. ” Future of Life Institute (FLI), August 6, 2021. https:/ /ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethicaland-legal-requirements/F2665546_en . Gal, Michal S., and Oshrit Aviv . “The Competitive Effects of the GDPR. ” Journal of Competition Law & Economics 16, no. 3 (September 9, 2020): 349–91. https://doi.org/10. 1093/joclec/nhaa012 . Garcia-Johnson, Ronie. Exporting Environmentalism: U.S. Multinational Chemical Corporations in Brazil and  Mexico. Global Environmental Accord: Strategies for Sustainability and Institutional Innovation. MIT  Press, 2000. https://mitpress.mit.edu/books/exporting-environmentalism . Gaumond, Eve. “ Artificial Intelligence Act: What Is the European Approach for AI?” Lawfare, June 4, 2021.  https://www.lawfareblog.com/artificial-intelligence-act-what-european-approach-ai . GDPR. “GDPR: Fines / Penalties. ” Accessed July 12, 2022. https://gdpr-info.eu/issues/fines-penalties/ . George, Barbara Crutchfield, Lynn V . Dymally, and Kathleen A. Lacey. “Increasing Extraterritorial Intrusion of  EuropeanUnionAuthorityintoU.S.BusinessMergersandCompetitionPractices:U.S.MultinationalBusinesses Underestimate the Strength of the European Commission from G.E.-Honeywell to Microsoft. ”  Connecticut Journal of International Law 19, no. 3 (2004): 571–616. https://heinonline.org/HOL/LandingPage?handle=hein.journals/conjil19&div=5&id=&page= . Glenn, Alex. “Spanish Startup Reduced McDonald’s Waiting Time, ” August 26, 2021. https://euroweeklynews .com/2021/08/26/spanish-startup-reduced-mcdonalds-waiting-time/ . Global Times. “China Replaces US to Become Largest T rade Partner of EU, ” December 4, 2020. https://www .globaltimes.cn/content/1208990.shtml . Goldfarb, Avi, and Daniel T refler . “ Artificial Intelligence and International T rade. ” In The Economics of Artificial  Intelligence: An Agenda, edited by Ajay Agrawal, Joshua Gans, and Avi Goldfarb, 463–92. University  of Chicago Press, 2019. http://www.nber .org/chapters/c14012 . Google.“ConsultationontheEUAIActProposal, ”July15,2021. https://ec.europa.eu/info/law/better-regulation /have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F2662492_en .
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•89 Greenleaf, Graham. “‘GDPR Creep’ for Australian Businesses But Gap in Laws Widens. ” University of New  SouthWalesLawResearchSeries54.UniversityofNewSouthWales,June6,2018. https://ssrn.com/abstract=3226835 . ———.“GlobalConvergenceofDataPrivacyStandardsandLaws:SpeakingNotesfortheEuropeanCommission Events on the Launch of the General Data Protection Regulation (GDPR) in Brussels & New Delhi,  25 May 2018. ” University of New South Wales Law Research Series 56. University of New South Wales,  May 25, 2018. https://doi.org/10.2139/ssrn.3184548 . ———. “Global Data Privacy Laws 2021: Despite COVID Delays, 145 Laws Show GDPR Dominance. ” Privacy  Laws & Business International Report 169. Privacy Laws & Business, 2021. https://doi.org/10.2139/ ssrn.3836348 . ———. “Global Data Privacy Laws 2021: Uncertain Paths for International Standards. ” Privacy Laws & Business  International Report 169. Privacy Laws & Business, 2021. https://papers.ssrn.com/abstract=3836408 . ———. “The ‘Brussels Effect’ of the EU’s ‘ AI Act’ on Data Privacy Outside Europe. ” 171 Privacy Laws & Business  International Report 1, June 7 , 2021. https://papers.ssrn.com/abstract=3898904 . ———. “The Influence of European Data Privacy Standards Outside Europe: Implications for Globalization of  Convention 108. ” International Data Privacy Law 2, no. 2 (April 4, 2012): 68–92. https://doi.org/10. 1093/ idpl/ips006 . Greze, Benjamin. “The Extra-T erritorial Enforcement of the GDPR: A Genuine Issue and the Quest for Alternatives. ” International Data Privacy Law 9, no. 2 (April 21, 2019): 109–28. https://doi.org/10. 1093/idpl/ipz003 . Hairston, Deborah. “Hunting for Harmony in Pharmaceutical Standards. ” Chemical Engineering 104, no. 20  (1997). Halpert, Jim, Samantha Kersul, Jim Halpert, and Samantha Kersul. “The Washington Privacy Act Goes 0 for 3. ”  International Association of Privacy Professionals, April 26, 2021. https://iapp.org/news/a/the-washington-privacy-act-goes-0-for-3/ . Hammit, James, Michael Rogers, Peter Sand, and Jonathan B. Wiener . The Reality of Precaution. 1st Edition.  Routledge, 2010. https://doi.org/10.4324/9781936331802 . Hanson, David. CE Marking, Product Standards and World T rade. Edward Elgar , 2005. https://www.e-elgar .com/shop/usd/ce-marking-product-standards-and-world-trade-9781843767732.html . Hart, Robert. “Clearview AI — The Facial Recognition Company Embraced By U.S. Law Enforcement — Just  GotHitWithABarrageOfPrivacyComplaintsInEurope. ”Forbes,May27 ,2021. https://www.forbes.com/ sites/roberthart/2021/05/27/clearview-ai---the-facial-recognition-company-embraced-by-us-law-enforcement---just-got-hit-with-a-barrage-of-privacy-complaints-in-europe/?sh=5dc958f217f5 . Heaven, Will Douglas. “This Has Just Become a Big Week for AI Regulation. ” MIT T echnology Review, April 21,  2021. https://www.technologyreview.com/2021/04/21/1023254/ftc-eu-ai-regulation-bias-algorithms-civilrights/ . Heikkilä, Melissa. “6 Key Battles Ahead for Europe’s AI Law. ” POLITICO, April 21, 2021. https://www.politico.eu/ article/6-key-battles-europes-ai-law-artificial-intelligence-act/ . Hopkins, W . John, and Henrietta S. McNeill. “Exporting Hard Law Through Soft Norms: New Zealand’s Reception of European Standards. ” In Importing EU Norms: Conceptual Framework and Empirical Findings,  edited by Annika Björkdahl, Natalia Chaban, John Leslie, and Annick Masselot, 115–30. Cham: Springer  International Publishing, 2015. https://doi.org/10. 1007/978-3-319-13740-7_8 . Horowitz,Michael,andLaurenKahn.“TheAILiteracyGapHobblingAmericanOfficialdom. ”WarontheRocks,  January 14, 2020. https://warontherocks.com/2020/01/the-ai-literacy-gap-hobbling-american-officialdom/ . Hu, Ivy Yihui. “The Global Diffusion of the ‘General Data Protection Regulation’ (GDPR). ” Edited by K. H. Stapelbroek and S. Grand. Erasmus School of Social and Behavioural Sciences, 2019. hdl.handle.net/ 2105/50756 .
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•90 IDC. “European Spending on Artificial Intelligence Will Reach $22 Billion in 2022, Supported by Strong Investments Across Banking and Manufacturing, Says IDC. ” IDC: The premier global market intelligence company, October 7 , 2021. https://www.idc.com/getdoc.jsp?containerId=prEUR148297521 . ———. “Worldwide Artificial Intelligence Spending Guide. ” IDC: The premier global market intelligence company. Accessed July 5, 2022. https://www.idc.com/getdoc.jsp?containerId=IDC_P33198 . IMF. “European Union: Share in Global Gross Domestic Product Based on Purchasing-Power-Parity from 2017  to 2027 , ” April 2022. Statista. https://www.statista.com/statistics/253512/share-of-the-eu-in-the-inflationadjusted-global-gross-domestic-product/ . Industry&Analysis.“2016T opMarketsR eportMedicalDevices:AMarketAssessmentT oolforU .S.Exporters. ”InternationalT radeAdministration,U .S.DepartmentofCommerce,May2016. International Medical Device Regulators Forum. “ About IMDRF. ” International Medical Device Regulators Forum. Accessed July 14, 2022. https://www.imdrf.org/about . Irish Council for Civil Liberties. Letter to European Commission DG CNECT A. “Flaws in Ex-Post Enforcement  in the AI Act, ” February 15, 2022. https://www.iccl.ie/wp-content/uploads/2022/02/20220215_ICCL_AIActEnforcementLetter .pdf . Irish Legal News. “Data Protection Watchdog Continues to Suffer ‘indefensible’ Underfunding. ” Irish Legal  News, octuber 14 2020. https://www.irishlegal.com/articles/data-protection-watchdog-continues-to-suffer-indefensible-underfunding . ISO. “ISO/IEC JTC 1/SC 42. ” ISO, 2022. https://www.iso.org/committee/6794475.html. ———. “Standards by ISO/IEC JTC 1/SC 42: Artificial Intelligence. ” ISO, 2022. https://www.iso.org/committee/ 6794475/x/catalogue/p/0/u/1/w/0/d/0 . Kim, Cheon-Soo. “Theories and Legislation of Products Liability in the Southeast Asian Countries. ” Journal of  Social Studies Research 55 (1999). Korinek, Anton, and Joseph E. Stiglitz. “Steering T echnological Progress, ” February 2021. http://rcea.org/wpcontent/uploads/2021/04/Future-of-growth/Korinek.pdf . Lachaud,Eric.“CouldtheCEMarkingBeRelevanttoEnforcePrivacybyDesignintheInternetofThings?”InData  Protection on the Move: Current Developments in ICT and Privacy/Data Protection, edited by Serge  Gutwirth,RonaldLeenes,andPaulDeHert,135–62.Dordrecht:SpringerNetherlands,2016. https://doi.org/ 10. 1007/978-94-017-7376-8_6 . Lambert, Fred. “T esla Nerfs Autopilot in Europe due to New Regulations, ” May 17 , 2019. https://electrek.co/ 2019/05/17/tesla-nerfs-autopilot-europe-regulations/ . Lander , Eric, and Alondra Nelson. “ Americans Need a Bill of Rights for an AI-Powered World. ” Wired, October  8, 2021. https://www.wired.com/story/opinion-bill-of-rights-artificial-intelligence/ . LaPrésidenceFrançaiseduConseildel’Unioneuropéenne.“PropositiondeR èglementDuP arlementEuropéenetDu  ConseilétablissantDesR èglesHarmoniséesConcernantL ’intelligenceArtificielle(législationSurL ’intelligenceArtificielle) et Modifiant Certains Actes Législatifs de l’Union - T e xte de Compromis de La Présidence - Article 3, P aragraphe1T er ,Articles4Bisà4Quater ,Anne x eVI(3)et(4),Considérant12BisBis, ”May13,2022. https://artificialintelligenceact.eu/wp-content/uploads/2022/05/AIA-FRA-Art-34-13-May .pdf . ———.“PropositiondeR èglementDuP arlementEuropéenetDuConseilétablissantDesR èglesHarmoniséesConcernant  L ’intelligenceArtificielle(législationSurL ’intelligenceArtificielle)etModifiantCertainsActesL égislatifsdel’Union-T e xtede  CompromisdeL aPrésidence-Articles16-29 , ”February3,2022. https://www .statewatch.org/media/3131/eu-council-aiact-high-risk -users-providers-5756-22.pdf . L arson,DerekB.,andSaraR.Jordan.“PlayingItSafe:T oySafetyandConformityAssessmentinEuropeandtheUnitedS tates. ”  International R eview of Administrative Sciences 85, no. 4 (December 1, 2019): 763–79 . https://doi.org/ 10 . 1177/0020852317747370 .
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•91 L awrence,Christie,andSeanCordey .“TheCaseforIncreasedT ransatlanticCooperationonArtificialIntelligence. ”Editedby  L aurenZabierekandJuliaV oo.TheCyberProject,BelferCenterforScienceandInternationalA ffairsHarvardK ennedy  School,A ugust2020 . https://www .belfercenter .org/sites/default/files/2020-08/T ransatlanticAI.pdf . L eufer ,Daniel,andL aurelineL emoine.“Europe’ sApproachtoArtificialIntelligence:HowAIS trategyIsEvolving. ”accessnow ,  December 2020 . https://www .accessnow .org/cms/assets/uploads/2020/12/Europes-approach-to-AI-strategy-isevolving.pdf . L évy ,Jean-Daniel,andPierre-HadrienBartoli.“Copyrights&T echGiants:WhatAretheExpectationsinEurope ?”harrisinteractive, February 2019 . https://uploads.strikinglycdn.com/files/6b00b8ae-5f81-4931-a6cd-672794608080/Harris%20Interactive-CopyrightsandT echGiants.pdf . Li,Chuan.“OpenAI’ sGPT -3L anguageModel:AT echnicalOverview . ”L ambda,June3,2020 . https://lambdalabs.com/blog/ demystifying-gpt-3/ . Liebman,SaraF .“TheEuropeanCommunity’ sProductsLiabilityDirective:IstheU .S.ExperienceApplicable ?”L awandP olicy  inInternationalBusiness18(1986):795–98. Li,He,L uY u,andW uHe.“TheImpactofGDPRonGlobalT echnologyDevelopment. ”JournalofGlobalInformationT echnologyManagement22,no.1(January2,2019):1–6. https://doi.org/10 . 1080/1097198X.2019 . 1569186 . L omas, Natasha. “China P asses Data Protection L aw . ” T echCrunch, A ugust 20 , 2021. https://techcrunch.com/2021/08/20/ china-passes-data-protection-law/ . L ucarini,Francesca.“TheDifferencesbetweentheCaliforniaConsumerPrivacyActandtheGDPR, ”April13,2020 . https://advisera.com/eugdpracademy/blog/2020/04/13/gdpr-vs-ccpa-what-are-the-main-differences/ . Manancourt,Vincent.“DespiteEUCourtRulings,FacebookSaysUSIsSafetoR eceiveEuropeans ’Data. ”POLITICO ,December 19 , 2021. https://www .politico.eu/article/despite-eu-court-ruling-facebook -says-us-is-safe-to-receive-europeansdata/. Marette,S tephan,Jean-ChristopheBureau,andEstelleGozlan.“ProductSafetyProvisionandConsumers ’Information. ”A ustralianEconomicP apers39 ,no.4(December 2000): 426–41. https://doi.org/10. 1111/1467-8454.00102 . Martin, Nicholas, Christian Matt, Crispin Niebel, and Knut Blind. “How Data Protection Regulation Affects  StartupInnovation. ”InformationSystemsFrontiers21,no.6(December1,2019):1307–24. https://doi.org/ 10. 1007/s10796-019-09974-2 . Mattli,Walter ,andTimBüthe.“SettingInternationalStandards:T echnologicalRationalityorPrimacyofPower?”  World Politics 56, no. 1 (October 2003): 1–42. https://doi.org/10. 1353/wp.2004.0006 . Mattli, Walter , and Ngaire Woods. “In Whose Benefit? Explaining Regulatory Change in Global Politics. ” In The  Politics of Global Regulation, 1–43. Princeton University Press, 2009. https://www.degruyter .com/document/doi/10. 1515/9781400830732. 1/html . Microsoft.“Microsoft’sResponsetotheEuropeanCommission’sConsultationontheArtificialIntelligenceAct, ”  August 6, 2021. https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificialintelligence-ethical-and-legal-requirements/F2665556_en . Mitchell, Margaret, Simone Wu, Andrew Zaldivar , Parker Barnes, Lucy V asserman, Ben Hutchinson, Elena  Spitzer ,InioluwaDeborahRaji,andTimnitGebru.“ModelCardsforModelReporting. ”arXiv[cs.LG],October 5, 2018. arXiv . http://arxiv .org/abs/1810.03993 . Montgomery, Mark, and Natalie Thompson. “What the U.S. Competition and Innovation Act Gets Right About  Standards. ” Lawfare, August 13, 2021. https://www.lawfareblog.com/what-us-competition-and-innovation-act-gets-right-about-standards . Morpurgo, Marco de. “The European Union as a Global Producer of T ransnational Law of Risk Regulation: A  Case Study on Chemical Regulation. ” European Law Journal 19, no. 6 (November 2013): 779–98. https:/ /doi.org/10. 1111/eulj. 12065 . Mottur , Alfred E. “The European Product Liability Directive: A Comparison with U.S. Law. An Analysis of Its Impact on T rade and a Recommendation for Reform so as to Accomplish Harmonisation and Consumer  Protection. ” Law and Policy in International Business 25 (1993-1994).
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•92 Murphy, Dale D. “The Business Dynamics of Global Regulatory Competition. ” In Dynamics of Regulatory  Change: How Globalization Affects National Regulatory Policies, edited by David V ogel and Robert A.  Kagan. University of California Press, 2004. National Science and T echnology Council. “U.S. Leadership in AI: A Plan for Federal Engagement in Developing T echnical Standards and Related T ools. ” National Science and T echnology Council, August 9, 2019.  https://www.nist.gov/system/files/documents/2019/08/10/ai_standards_fedengagement_plan_9aug2019.pdf . Nelson, Phillip. “Information and Consumer Behavior . ” The Journal of Political Economy 78, no. 2 (1970):  311–29. https://doi.org/10. 1086/259630 . Neslen, Arthur . “Donald T rump ‘T aking Steps to Abolish Environmental Protection Agency. ’” The Guardian.  February 2, 2017 . https://amp.theguardian.com/us-news/2017/feb/02/donald-trump-plans-to-abolish-environmental-protection-agency . Newman, Abraham L., and Elliot Posner . “Putting the EU in Its Place: Policy Strategies and the Global Regulatory Context. ” Journal of European Public Policy 22, no. 9 (October 21, 2015): 1316–35. https://doi.org/ 10. 1080/13501763.2015. 1046901 . Newton, Casey. “Google’s Internal Activism Is Spreading across T ech Companies, ” August 14, 2019. https:// www.theverge.com/interface/2019/8/14/20804403/google-walkout-legacy-activism-microsoft-amazon . Nottage,LukeR.,andJocelynKellam.“EuropeanisationofProductLiabilityintheAsia-PacificRegion:APreliminary Empirical Benchmark. ” Legal Studies Research Paper , No. 07/30. Sydney Law School, May 1, 2007 .  https://doi.org/10.2139/ssrn.986530 . NOYB. “Clearview AI Deemed Illegal in the EU, but Only Partial Deletion Ordered. ” noyb.eu, January 28, 2021.  https://noyb.eu/en/clearview-ai-deemed-illegal-eu . Observatory of Economic Complexity (OEC). “Medical Instruments. ” OEC. Accessed july, 09 2022. https://oec .world/en/profile/hs/medical-instruments#exporters-importers . OECD. Food Safety and Quality: T rade Considerations. Paris Cedex, France: Organization for Economic Cooperation and Development (OECD), 1999. https://doi.org/10. 1787/9789264174115-en . OECD AI Policy Observatory. “The OECD Artificial Intelligence (AI) Principles. ” OECD AI Policy Observatory.  Accessed July 14, 2022. https://oecd.ai/en/ai-principles . Office for Artificial Intelligence, Department for Digital, Culture, Media & Sport, and Department for Business,  Energy & Industrial Strategy. “National AI Strategy. ” HM Government, September 22, 2021. https://www .gov .uk/government/publications/national-ai-strategy/national-ai-strategy-html-version . O’Halloran,Barry.“DataProtectionCommissiontoReceive€2MillionExtraFunding. ”TheIrishTimes.October  13, 2020. https://www.irishtimes.com/business/economy/data-protection-commission-to-receive-2-million-extra-funding-1.4380030 . OpenAI.“UsageGuidelines(responsibleUse):AppReview. ”OpenAI’sAPI.AccessedJuly13,2022. https://beta.openai.com/docs/usage-guidelines/app-review . Ossege, Christoph. “Driven by Expertise and Insulation? The Autonomy of European Regulatory Agencies. ”  Politics and Governance 3, no. 1 (March 31, 2015): 101–13. https://doi.org/10. 17645/pag. v3i1. 75 . Pelkmans, Jacques. “The New Approach to T echnical Harmonization and Standardization. ” Journal of Common Market Studies 25, no. 3 (March 1987): 249–69. https://doi.org/10. 1111/j. 1468-5965. 1987 .tb00294.x . Perez, Sarah. “ Alphabet CEO Sundar Pichai Calls for Federal T ech Regulation, Investments in Cybersecurity. ”  T echCrunch, October 18, 2021. https://techcrunch.com/2021/10/18/alphabet-ceo-sundar-pichai-calls-forfederal-tech-regulation-investments-in-cybersecurity/ . Perkins, Richard, and Eric Neumayer . “Does the ‘California Effect’ Operate across Borders? T rading- and Investing-up in Automobile Emission Standards. ” Journal of European Public Policy 19, no. 2 (March 1,  2012): 217–37 . https://doi.org/10. 1080/13501763.2011.609725 .
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•93 Perrigo, Billy. “‘I Sold My Soul. ’ WhatsApp Content Moderators Review the Worst Material on the Internet. Now  They’reAllegingPayDiscrimination. ”Time,Originallypublished:July152021. https://time.com/6080450 /facebook-whatsapp-content-moderators/ . Porter , Michael E. “How Competitive Forces Shape Strategy. ” Harvard Business Review, March 1, 1979. https:// hbr .org/1979/03/how-competitive-forces-shape-strategy . Propp, Kenneth. “Progress on T ransatlantic Data T ransfers? The Picture After the US-EU Summit. ” Lawfare,  June 25, 2021. https://www.lawfareblog.com/progress-transatlantic-data-transfers-picture-after-us-eusummit . PwC.“PulseSurvey:USCompaniesRampingUpGeneralDataProtectionRegulation(GDPR)Budgets. ”GDPR  Series. PwC, 2017 . https://quiksite.com/wp-content/uploads/2019/07/pwc-gdpr-series-pulse-survey.pdf . Quantcast. “ Audience Measurement & Analytics Platform. ” Quantcast. Quantcast Inc, August 30, 2020. https:/ /www.quantcast.com/products/measure-audience-insights/ . Radford, Alec, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, et  al. “Learning T ransferable Visual Models From Natural Language. ” In Proceedings of the 38th International Conference on Machine Learning, edited by Meila Marina And T ong, 139:8748–63. Proceedings  of Machine Learning Research. PMLR, 2021. https://proceedings.mlr .press/v139/radford21a.html . Rae, Jack W ., Sebastian Borgeaud, T revor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides,  et al. “Scaling Language Models: Methods, Analysis & Insights from T raining Gopher . ” arXiv [cs.CL], December 8, 2021. arXiv . http://arxiv .org/abs/2112. 11446 . Regulations.gov . “Draft Memorandum to the Heads of Executive Departments and Agencies, Guidance for  Regulation of Artificial Intelligence Applications. ” Regulations.gov . Accessed July 21, 2022. https:// www.regulations.gov/document/OMB-2020-0003-0001/comment . Reimann. “Product Liability in a Global Context: The Hollow Victory of the European Model. ” European Review  of Private Law 11, no. 2 (2003): 128–54. https://kluwerlawonline.com/journalarticle/European+Review+of+Private+Law/11.2/ERPL2003011 . Reimann, Mathias. “Liability for Defective Products at the Beginning of the Twenty-First Century: Emergence  of a Worldwide Standard?” The American Journal of Comparative Law 51, no. 4 (October 1, 2003):  751–838. https://doi.org/10.2307/3649130 . ———.“ProductLiability. ”InComparativeT ortLaw:GlobalPerspectives,editedbyMauroBussaniandAnthony  J. Sebok, 236–63. Research Handbooks in Comparative Law. Edward Elgar Publishing Limited, 2021. Renda, Andrea, Jane Arroyo, Rosanna Fanni, Moritz Laurer , Agnes Sipiczki, Y eung Timothy: Maridis George,  Meena Fernandes, et al. “Study to Support an Impact Assessment of Regulatory Requirements for Artificial Intelligence in Europe Final Report (D5). ” Luxembourg: European Commission, April 2021. https:// doi.org/10.2759/523404 . Rippy, Sarah. “Virginia Passes the Consumer Data Protection Act. ” International Association of Privacy Professionals, March 3, 2021. https://iapp.org/news/a/virginia-passes-the-consumer-data-protection-act/ . Rooij,Benjaminvan,MeganBrownlee,andD.DanielSokol.“DoesT ortDeter?InconclusiveEmpiricalEvidence  about the Effect of Liability in Preventing Harmful Behaviour . ” In The Cambridge Handbook of Compliance, 311–25. Cambridge University Press, 2021. https://doi.org/10. 1017/9781108759458.022 . Ryan, Johnny, and Alan T oner . “Europe’s Enforcement Paralysis: ICCL ’s 2021 Report on the Enforcement Capacity of Data Protection Authorities. ” ICCL, 2021. Saad, Lydia. “ Americans Split on More Regulation of Big T ech, ” August 21, 2019. https://news.gallup.com/poll/ 265799/americans-split-regulation-big-tech.aspx . Salbu, Steven R. “The European Union Data Privacy Directive and International Relations. ” William Davidson  Institute, December 2001. Samsel, Haley. “California Becomes Third State to Ban Facial Recognition Software in Police Body Cameras. ”  Security T oday, October 10, 2019. https://securitytoday.com/articles/2019/10/10/california-to-becomethird-state-to-ban-facial-recognition-software-in-police-body-cameras.aspx .
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•94 Sánchez, Nicolás Elena. “Pandemic Speeds Calls for Ban on Facial Recognition. ” EUobserver , May 18, 2021.  https://euobserver .com/health-and-society/148387 . Sartor , Giovanni, and Francesca Lagioia. “The Impact of the General Data Protection Regulation (GDPR) on  Artificial Intelligence. ” European Parliamentary Research Service, June 2020. https://doi.org/ 10.2861/293 . Schimmelfennig, Frank, and Ulrich Sedelmeier . “Governance by Conditionality: EU Rule T ransfer to the Candidate Countries of Central and Eastern Europe. ” Journal of European Public Policy 11, no. 4 (January 1,  2004): 661–79. https://doi.org/10. 1080/1350176042000248089 . Schwartz, Paul M. “Global Data Privacy: The EU Way. ” New Y ork University Law Review 94, no. 4 (October  2019): 771–818. https://heinonline.org/HOL/LandingPage?handle=hein.journals/nylr94&div=28&id=&page= . Scott, Joanne. “Extraterritoriality and T erritorial Extension in EU Law. ” The American Journal of Comparative  Law 62, no. 1 (January 1, 2014): 87–126. https://doi.org/10.5131/AJCL.2013.0009 . ———. “From Brussels with Love: The T ransatlantic T ravels of European Law and the Chemistry of Regulatory  Attraction. ” The American Journal of Comparative Law 57 , no. 4 (October 1, 2009): 897–942. https:// doi.org/10.5131/ajcl.2008.0029 . Selbst, Andrew D., and Julia Powles. “Meaningful Information and the Right to Explanation. ” International Data  Privacy Law 7 , no. 4 (November 1, 2017): 233–42. https://doi.org/10. 1093/idpl/ipx022 . Senate Office of Public Records. “Lobbying Expenses of Alphabet Inc in the United States from 2015 to 2021, ”  October 2021. Statista. https://www.statista.com/statistics/1035915/lobbying-expenses-of-alphabet-inc/ . ———. “Lobbying Expenses of Amazon in the United States from 2009 to 2020, ” 2021. Statista. https://www .statista.com/statistics/1035836/lobbying-expenses-of-amazon/ . ———. “Lobbying Expenses of Apple in the United States from 2009 to 2020, ” January 2021. Statista. https:// www.statista.com/statistics/1043061/lobbying-expenses-of-apple/ . ———. “Lobbying Expenses of Facebook in the United States from 2009 to 2020, ” April 2021. Statista. https:// www.statista.com/statistics/1035870/lobbying-expenses-of-facebook/ . ———. “Lobbying Expenses of Microsoft in the United States from 2009 to 2020, ” January 2021. Statista. https:// www.statista.com/statistics/1043105/lobbying-expenses-of-microsoft/ . Senate Republican Policy Committee. “Big T ech Gets Bigger , Calls for Antitrust Changes Get Louder . ” Senate  RPC,November18,2021. https://www.rpc.senate.gov/policy-papers/big-tech-gets-bigger-calls-for-antitrustchanges-get-louder . Senz,Deborah,andHilaryCharlesworth.“BuildingBlocks:Australia’sResponsetoForeignExtraterritorialLegislation. ” Melbourne Journal of International Law 2, no. 1 (June 1, 2001): 69–121. https://doi.org/10.3316/informit.317555450176533 . S e r t k a y a ,A y l i n ,A m b e rJ e s s u p ,a n dR e b e c c aD e V r i e s .“ C o s to fD e v e l o p i n gaT h e r a p e u t i cC o m p l e xM e d i c a lD e v i c ef o rt h eU . S .  M a r k e t , ”2 0 1 9 . S e v i l l a ,J a i m e ,L e n n a r tH e i m ,A n s o nH o ,T a m a yB e s i r o g l u ,M a r i u sH o b b h a h n ,a n dP a b l oV i l l a l o b o s .“ C o m p u t eT r e n d sA c r o s s  T h r e eE r a so fM a c h i n eL e a r n i n g . ”a r X i v[ c s . L G ] ,F e b r u a r y1 1 ,2 0 2 2 .a r X i v . h t t p : / / a r x i v . o r g / a b s / 2 2 0 2 . 0 5 9 2 4 . S h a f f e r ,G r e g o r y .“ G l o b a l i z a t i o na n dS o c i a lP r o t e c t i o n :T h eI m p a c to fE Ua n dI n t e r n a t i o n a lR u l e si nt h eR a t c h e t i n gU po fU . S .P r i v a c y  S t a n d a r d s . ”Y a l eJ o u r n a lo fI n t e r n a t i o n a lL a w2 5 ,n o .1( 2 0 0 0 ) :2 – 8 8 . h t t p : / / h d l . h a n d l e . n e t / 2 0 . 5 0 0 . 1 3 0 5 1 / 6 4 0 5 . S h e e h a n ,M a t t .“ C h i n a ’ sN e wA IG o v e r n a n c eI n i t i a t i v e sS h o u l d n ’ tB eI g n o r e d . ”C a r n e g i eE n d o w m e n tf o rI n t e r n a t i o n a lP e a c e ,J a n u a r y 4 , 2 0 2 2 . h t t p s : / / c a r n e g i e e n d o w m e n t . o r g / 2 0 2 2 / 0 1 / 0 4 / c h i n a - s - n e w - a i - g o v e r n a n c e - i n i t i a t i v e s - s h o u l d n - t - b e - i g n o r e d p u b - 8 6 1 2 7 . — — — .“ H o wG o o g l eT o o ko nC h i n a — a n dL o s t . ”M I TT e c h n o l o g yR e v i e w ,D e c e m b e r1 9 ,2 0 1 8 . h t t p s : / / w w w . t e c h n o l o g y r e v i e w . c o m / 2 0 1 8 / 1 2 / 1 9 / 1 3 8 3 0 7 / h o w - g o o g l e - t o o k - o n - c h i n a - a n d - l o s t / .
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•95 S h e p a r d s o n ,D a v i d .“ T r u m pA d m i n i s t r a t i o nS e e k st oL i m i t‘ O v e r r e a c h ’o fR e g u l a t i o no fA r t i f i c i a lI n t e l l i g e n c e . ”I n s u r a n c eJ o u r n a l ,J a n u a r y8 ,2 0 2 0 . h t t p s : / / w w w . i n s u r a n c e j o u r n a l . c o m / n e w s / n a t i o n a l / 2 0 2 0 / 0 1 / 0 8 / 5 5 3 8 6 4 . h t m . S h i p a n ,C h a r l e sR . ,a n dC r a i gV o l d e n .“ T h eM e c h a n i s m so fP o l i c yD i f f u s i o n . ”A m e r i c a nJ o u r n a lo fP o l i t i c a lS c i e n c e5 2 ,n o .4( O c t o b e r2 0 0 8 ) :8 4 0 – 5 7 . h t t p s : / / d o i . o r g / 1 0 . 1 1 1 1 / j . 1 5 4 0 - 5 9 0 7 . 2 0 0 8 . 0 0 3 4 6 . x . S i m m o n s ,B e t h .“ T h eI n t e r n a t i o n a lP o l i t i c so fH a r m o n i z a t i o n :T h eC a s eo fC a p i t a lM a r k e tR e g u l a t i o n . ”I nD y n a m i c so fR e g u l a t o r y  C h a n g e :H o wG l o b a l i z a t i o nA f f e c t sN a t i o n a lR e g u l a t o r yP o l i c i e s ,e d i t e db yD a v i dV o g e la n dR o b e r tA .K a g a n .U n i v e r s i t yo f  C a l i f o r n i aP r e s s ,2 0 0 4 . S i m m o n s ,B e t hA .“ T h eI n t e r n a t i o n a lP o l i t i c so fH a r m o n i z a t i o n :T h eC a s eo fC a p i t a lM a r k e tR e g u l a t i o n . ”I n t e r n a t i o n a lO r g a n i z a t i o n  5 5 ,n o .3( 2 0 0 1 ) :5 8 9 – 6 2 0 . h t t p s : / / d o i . o r g / 1 0 . 1 1 6 2 / 0 0 2 0 8 1 8 0 1 5 2 5 0 7 5 6 0 . S l o t k i n ,E l i s s a .“ H . R . 4 5 3 6-1 1 6 t hC o n g r e s s( 2 0 1 9 - 2 0 2 0 ) :B o tD i s c l o s u r ea n dA c c o u n t a b i l i t yA c to f2 0 1 9 , ”S e p t e m b e r2 7 ,2 0 1 9 . h t t p s : / / w w w . c o n g r e s s . g o v / b i l l / 1 1 6 t h - c o n g r e s s / h o u s e - b i l l / 4 5 3 6 ? r = 5 & s = 1 . S o l a i m a n , I r e n e , a n d C h r i s t y D e n n i s o n . “ P r o c e s s f o r A d a p t i n g L a n g u a g e M o d e l s t o S o c i e t y ( P A L M S ) w i t h V a l u e s - T a r g e t e d  D a t a s e t s . ”A d v a n c e si nN e u r a lI n f o r m a t i o nP r o c e s s i n gS y s t e m s3 4( 2 0 2 1 ) . h t t p s : / / p r o c e e d i n g s . n e u r i p s . c c / p a p e r / 2 0 2 1 / f i l e / 2 e 8 5 5 f 9 4 8 9 d f 0 7 1 2 b 4 b d 8 e a 9 e 2 8 4 8 c 5 a - P a p e r . p d f . S t a p l e t o n ,J a n e .“ P r o d u c tL i a b i l i t yi nt h eU n i t e dK i n g d o m :T h eM y t h so fR e f o r m . ”T e x a sI n t e r n a t i o n a lL a wJ o u r n a l3 4( 1 9 9 9 ) . Svantesson,DanJerkerB.“TheExtraterritorialityofEUDataPrivacyLaw–ItsTheoreticalJustificationandItsPractical  EffectonU .S.Businesses. ”StanfordJournalofInternationalLaw50,no.1(2014):53–102. https://law .stanford.edu/ publications/the-e xtraterritoriality-of-eu-data-privacy-law-its-theoretical-justification-and-its-practical-effect-on-u-sbusinesses/ . T ambou,O .“France ·LessonsfromtheFirstPost- GDPR Fines of the CNIL against Google LLC. ” European Data  Protection Law Review 5, no. 1 (2019): 80–84. https://doi.org/10.21552/edpl/2019/1/13 . T aschner , Claudius Hans, and Karola T aschner . 10 Jahre EG-Richtlinie Zur Produkthaftung : Rückblick, Umschau, Ausblick. V ol. 15. Schriftenreihe Deutscher Jura-Studenten in Genf. Gene ̀ ve: Unité de droit allemand, Faculté de droit, 1996., 1996. https://www.worldcat.org/title/10-jahre-eg-richtlinie-zur-produkthaftung-ruckblick-umschau-ausblick/oclc/49849759 . T aylor , Dan. “Op-Ed: The EU’s Artificial Intelligence Act Does Little to Protect Democracy. ” T ech.eu, March 14,  2022. https://tech.eu/2022/03/14/op-ed-the-eu-s-artificial-intelligence-act-does-little-to-protectdemocracy/ . The AI Forum of New Zealand. “T rustworthy AI in Aotearoa: AI Principles. ” The AI Forum of New Zealand,  March 2020. https://data.govt.nz/assets/data-ethics/algorithm/T rustworthy-AI-in-AotearoaMarch-2020.pdf . The Big Data Security Standards Special Working Group of the National Information Security Standardization T echnical Committee. “ Artificial Intelligence Security Standardization White Paper (2019 Edition). ”  T ranslated by Etcetera Language Group, Inc. Center for Security and Emerging T echnology, 2019.  https://cset.georgetown.edu/wp-content/uploads/t0121_AI_security_standardization_white_paper_EN.pdf . The White House. “Carbis Bay G7 Summit Communiqué. ” The White House, June 13, 2021. https:// www.whitehouse.gov/briefing-room/statements-releases/2021/06/13/carbis-bay-g7-summit-communique/ . Thomas, Kristie. “The Product Liability System in China: Recent Changes and Prospects. ” The International  and Comparative Law Quarterly 63, no. 3 (July 2014): 755–75. https://doi.org/10. 1017/ S0020589314000219 . T oner , Helen, Rogier Creemers, and Graham Webster . “T ranslation: Internet Information Service Algorithmic  Recommendation Management Provisions (Draft for Comment) – Aug. 2021. ” DigiChina, August 27 ,  2021. https://digichina.stanford.edu/work/translation-internet-information-service-algorithmic-recommendation-management-provisions-opinon-seeking-draft/ . T ransparenc y International EU. “Integrity Watch - EU Lobbyists.” Transparency International EU.  Accessed July 12, 2022. https://www.integritywatch.eu/organizations .
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•96 Tricker, Ray. CE Conformity Marking: And New Approach Directives. Butterworth-Heinemann,  2000. Ullrich, Carsten. “New Approach Meets New Economy: Enforcing EU Product Safety in E-Commerce.”  Maastricht Journal of European and Comparative Law 26, no. 4 (August 1, 2019): 558–84. https:// doi.org/10. 1177/1023263X19855073 . Varian, Hal. “ Artificial Intelligence, Economics, and Industrial Organization. ” In The Economics of Artificial Intelligence: An  Agenda,editedbyAjayAgrawal,JoshuaGans,andA viGoldfarb,399–419 .UniversityofChicagoPress,2019 . http:/ /www .nber .org/chapters/c14017 . V eale, Michael, and Frederik Zuiderveen Borgesius. “Demystifying the Draft EU Artificial Intelligence Act — Analysing  theGood,theBad,andtheUnclearElementsoftheProposedApproach. ”ComputerLawR eviewInternational  22,no.4(August1,2021):97–112. https://doi.org/10.9785/cri-2021-220402 . Virginia’ s Legislative Information System. “2021 Special Session I: HB 2307 Consumer Data Protection Act; Personal  Data Rights of Consumer , Etc. ” LIS. Accessed July 14, 2022. https://lis. virginia.gov/cgi-bin/legp604.e xe ?212+sum+HB2307 . V ogel,David.CaliforniaGreenin’:HowtheGoldenStateBecameanEnvironmentalLeader .PrincetonStudiesinAmerican Politics: Historical, International, and Comparative Perspectives. Princeton University Press, 2018. https:// press.princeton.edu/books/hardcover/9780691179551/california-greenin . ———.ThePoliticsofPrecaution:R egulatingHealth,Safety ,andEnvironmentalRisksinEuropeandtheUnitedStates.  Focus on Climate. Princeton University Press, 2012. https://press.princeton.edu/books/hardcover/ 9780691124162/the-politics-of-precaution . ———.T radingUp:ConsumerandEnvironmentalR egulationinaGlobalEconomy .HarvardUniversityPress,1995. https://www .hup.harvard.edu/catalog.php ?isbn=9780674900844 . V ought,RussellT .LettertoHeadsofExecutiveDepartmentsandAgencies.“DraftMemorandumfortheHeadsofExecutiveDepartmentsandAgencies,GuidanceforR egulationofArtificialIntelligenceApplications, ”January7 ,2019.  https://www . whitehouse.gov/wp-content/uploads/2020/01/Draft-OMB-Memo-on-R egulation-of-AI-1-7-19.pdf . ———. Letter to Heads of Executive Departments and Agencies. “Memorandum for the Heads of Executive DepartmentsandAgencies,GuidanceforR egulationofArtificialIntelligenceApplications, ”November17 ,2020. https:// www . whitehouse.gov/wp-content/uploads/2020/11/M-21-06.pdf . W achter ,Sandra,BrentMittelstadt,andL ucianoFloridi.“WhyaRighttoExplanationofA utomatedDecision-MakingDoesNot  Exist in the General Data Protection R egulation. ” International Data Privacy L aw 7 , no. 2 (May 1, 2017): 76–99 . https:// doi.org/10 . 1093/idpl/ip x005 . W est,DarrellM.“T echlashContinuestoBatterT echnologySector . ”Brookings,April2,2021. https://www .brookings.edu/ blog/techtank/2021/04/02/techlash-continues-to-batter-technology-sector/ . W i k i p e d i ac o n t r i b u t o r s .“ C EM a r k i n g . ” Wikipedia, The Free Encyclopedia, July 8, 2022. https://en. wikipedia.org/w/index .php ?title=CE_marking&oldid=1097041618 . Xinbao,Zhang.“StatusQuoOf ,ProspectsforLegislationonProtectionofPersonalDatainChina. ” ���� V6� �,2007 . https://www .pkulaw .com/qikan/f05bb82094835cf0eb706d00a2053d99bdfb.html . Xinbao,Zhang,andLiaoZhenyun. “ ���������������� . ”��������� ,2007 . http:// www .cqvip.com/qk/84470x/20072/24911277 .html . Y oung, Alasdair R. “Europe as a Global Regulator? The Limits of EU Influence in International Food  Safety Standards.” Journal of European Public Policy 21, no. 6 (2014): 904–22. https://doi.org/ 10. 1080/13501763.2014.910871 . ———. “Liberalizing T rade, Not Exporting Rules: The Limits to Regulatory Co-Ordination in the EU’s ‘new Generation’ Preferential T rade Agreements. ” Journal of European Public Policy 22, no. 9 (October 21, 2015):  1253–75. https://doi.org/10. 1080/13501763.2015. 1046900 . Zhang, Baobao, and Allan Dafoe. “ Artificial Intelligence: American Attitudes and T rends. ” Centre for the Governance of AI, Future of Humanity Institute, University of Oxford, January 2019.
THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•97  VISIT US AT GOVERNANCE.AICENTRE FOR THE GOVERNANCE OF AI 
