BRIEFING   Requested by the AIDA  committee  F       EN Policy Department for Economic, Scientific and Quality of Life Policies   Directorate -General for Internal Policies   Authors : Tjerk TIMAN, Anne  Fleur VAN VEENSTRA  and Gabriela BODEA   PE 662.936 – July  2021  Artificia I Intelligence  and public services   Introduction   The public sector aims to capture the benefits from using AI . Contrary to a commonly held opinion, there  is no indication that the uptake of AI in the EU public sector is lagging behind the uptake in other sectors1.  As co -legislator, the European Parliament plays an important role in the EU AI strategy that is characterised  by its focus on trust  and excellence, by promoting tools that enable growth, competitiveness and quality of  life in the EU, while safeguarding fundamental rights.  But while governments aim to upheld human rights,  unfortunately, not all applications in publ ic services have been developed responsibly. In the Netherlands,  for e xample , the use of the System Risk Indication ( SyRI ) system identifying social benefits fraud was   banned2. Furthermore,  in the recently proposed AI -regulation , some AI -applications that may be used in  public services such as  those that manipulate human behaviour  are specifically considered to pose an  unacceptable risk  and are forbidden3.  This briefing will discuss how AI can be used to improve public services, how public investments can  accelerate the societal uptake of responsible AI and thus stimulat e responsible AI developments in the  private sector, and what the benefits and challenges  of using Open Data for AI  are. First, we provide  background information on the definition and  uptake of AI in public services. Then , we identify  benefits  and  drivers of AI to improve public services. Subsequently , we pr esent  a number of challenges to the uptake and  its acceleration. Finally, t his briefing is concluded with recommendations. KEY FINDINGS   Artificial I ntelligence ( AI) has become  a key enabling technology  in public services  and its use has  increased over the past two years .  Ensuring explainabilty of AI systems in public services is crucial but difficult to achieve in case of  black box algorithms.   In AI applications in public services, focus is on law enforcement, surveillan ce and process optimisation.  AI for front -end public services seems less of a priority.   There is  a growing public concern over the development and use of AI in society . With the increase of it s  use, the potential for errors and harms  also increases.   The public sector should  lead the way in creating trustworthy AI. Regulatory sandboxing and pre procurement are key for creating trustworthy AI for public services.  
IPOL | Policy Department for  Economic, Scientific and Quality of Life Policies     PE 662.936 2  AI for public services   Different definitions of  AI in public services  are in use by various international organisations ,  authorities and expert groups . Many definitions vary by the level of detail of specifications given for the   possible outcomes4 and embedded technologies or methods5. For the purpose of this briefing we use the  short definition provided by the EU White Paper on AI published in 20206: “a collection of technologies that  combine , data, algorithms , and computing power” .  The OECD definition , already adopted by many EU Member States , explicitly specifies that AI targets human defined goals, highlighting where the final responsibility for AI out comes lie s7. The role and influence of  human responsibility in AI, however, becomes increasingly marginalised when complexity increases  (e.g.  through the  use of multiple data sources and combining different AI applications ). Ensuring explainabilty   of proce sses and trustworthiness is crucial but difficult to achieve in the case of  “black -box ”  algorithms  (i.e. difficult to explain how they work or how they reach certain decisions; this is especially the  case of forms of machine learning) . As such this provides us with many questions on  how to develop AI  responsibly and human- centred, which is especially relevant in public services .   One element of human- centredness is the degree of automation of decisions or services. The Figure  below  shows the dif ferent levels or stages of automation.   Levels and types of decision automation in public processes     Source:  Authors’ own elaboration  based on Arciszewski, Greef & Delft (2009)8 and Parasuraman, Sheridan & Wickens (2000)9.    When looking into what constitute public services, we refer to the EU Treaty of Rome and the official  classification of the functions of government ( COFOG ), in which it is defined as services of general interest  that correspond broadly to public services . However , between Member States  the interpretations differ  significantly and in practice includes a combination of private organi sations, public -private partnerships,  and non- profit organi sations. The European Parliament ’s own definition of public services  is: “an economic  
ArtificiaI Intelligence and public services      3 PE 662.936  activity of general interest defined, created and controlled by the public authorities and subject, to varying  degrees, to a special legal regime, irrespective of whether it is actually carried out by a public or private  body”10.   Public s ervices thus include  three categories11:  • Services of general economic interest , which are basic services that are carried out in return for  payment, such as postal services. These services are subject to European internal market and competition rules. Howev er, there may be derogations to these rules if necessary, to protect citizens'  access to basic services.   • Non -economic services , such as the police, justice and statutory social security schemes, are not  subject to specific European legislation or to intern al market and competition rules.   • Social services of general interest  are those that respond to the needs of vulnerable citizens  and are  based on the principles of solidarity and equal access. They can be both of an economic or non economic nature. Examples  include social security schemes, employment services and social housing.   A recent study of the use of AI in public services in the Netherlands  shows that AI has become a key  enabling technology in public services 12. Furthermore, this study  show s that  the use of AI in public  services has increased in  the past two years and  proliferates in the areas of inspection, enforcement and  detection by enforcement agencies and for process optimisation of various services internally. In the mid range of AI use are personalised services, maintenance and forecasting & policy making. The least frequent   use of AI  in public services is for  knowledge gathering and support of democratic processes. These different  types  of services mainly use  image recognition, speech/text recognition , and robotics. Also,  the use of  ‘stand -alone ’ machine learning  algorithms  is often observed.  Other studies of AI for public services also  indicate a significant dependence on the private sector for developing and delivering AI solutions for pub lic  services. While some government organisations develop in -house AI solutions, arguably a majority do not.  This dependence refers to the entire infrastructure of AI in public services and not just the front -end services.   The figure below depicts typical AI applications in public services.     Categorisation of AI applications in public services     Source:  Hoekstra, M., Chideock, C. & Veenstra, A.F. van (2021) Quickscan AI use in public services II .    Benefits of AI for public services  and drivers for its upta ke   Generic benefits of AI (including but not limited to its use in the public sector ) include organisational  benefits such as process optimisation and improvement of business intelligence. D ealing with large datasets  and knowledge graphs , for example  to find correlations and patterns over time or across domains, and the  possibility  to make fine -grained  predictions based on thes e patterns  makes AI perfectly suitable for  optimis ing operations in the public sector . Other recent studies have pointed to ec onomic benefits of  using AI in the public sector , projecting economic growth13 and an increase in jobs14, although the latter  
IPOL | Policy Department for Economic, Scientific and Quality of Life Policies     PE 662.936  4  may  also mean a change in type of labour, whereby low -skilled labour decreases  as a result of automati on.  AI may  help in the factory workplace or other assembly -line work, by aiding and co -working with humans  become more efficient or to reach higher quality . Other benefits connected to the workplace are better time  management, increased self -learning or co -learning and a better diffusion of innovation. Other benefi ts  mentioned and observed can be found in healthcare, where AI and more precisely forms of machine  learning have sped up scientific progress and helped tackle ‘grand challenges’15. AI solutions may also  have   positive impacts in the area of occupational health and safety , in sustainability , and in social welfare, with  dedicated roadmaps on how AI can help in achieving the Sustainable Development Goals16.   When focusing on AI in public services, besides the generic goals and potential benefits  we know from  digital government strategies  and programs (such as efficiency, time and costs savings, servic e  improvement, improved accessibility and inclusion of services), A I may  contribute to such goals in its own  particu lar way.  In different studies  performed by research institutes, NGO ’s, and the European Commissi on’s  own Joint Research Centre, empirical evidence was gathered on  the use of AI in  public services . This  empirical evidence shows a strong tendency towards app lications in the areas of security and  surveillance, and in internal process optimisation.    Recent case studies  have  shown  the potential  of AI  to improve  s o cia l s er vice  delivery  and  accessibility of public services through , for example ,  communicative AI in government -to-citizens web portals or digital  applications17. Another angle to improving the front -end interaction with  public services is through service robots to deliver social care, help in referring  citizens to the right counter, o r help with getting their automated  prescriptions, to name a few applications18. In that sense, AI can contribute to personalisation of services ,  although  it remains to be seen if and how chatbots or service robots can truly reach a level of intelligent  interaction needed .  Another form of aiding both citizens and internal  work processes is to use AI to help in case selection and  prioritis ing cases for public administrators or case workers, thereby optimi sing internal workflows   through more accurate predictions . Examples of this are a rando m forest -based AI system that helps  to  predict when citizen s get into problematic debt, in order to guide case workers to more targeted preemptive  interventions19, or A I-based systems that, ba sed on pattern recognition of combined datasets , h elp  to predict fraudulent behaviour .   The global pandemic has accelerated  public sector AI . For example,  many countries have developed Covid 19 apps20 directed at  both informing and controlling citizens , using app data and AI -based model s to  predict next steps in spreading and human behaviour , as well as applications that  allocate patients to beds  and impro ve the diagnostic process21. Such applications have often  been  developed in transparenc y  through the  use of publicly available nation -based dashboards22 and through coll aborations with researc h  institutes and oversight bodies23. Although uptake varie d per Member State and the harmo nisation  of crossborder digital infrastructures and protocols  remains challenging24, the wide uptake of AI -based tools and  applications during the pandemic  highlight s public sector readiness  and willingness to operational i se  existing technologies, develop alternatives and/or acquire the expertise to move rapidly form  prototype to  implementation . It, thereby,  provided experience in the much -needed process of  developing through  experimentation and testing, and learning -by-doing , not only in the level of the technology but also from  a legal, ethical and organisational po int of view .  The benefits of such applications seem obvious, as often they are connected to a specific need or problem.  However, in the case of AI system s geared towards process optimisation and internal business processes,  benefits might show on the long( er) term. Some of the benefits are time savings through more and  
ArtificiaI Intelligence and public services      5 PE 662.936  improved digital services and  an increase of predictive services which may  lead to a better allocation of  public resources . The use of AI may  also  aid in improving generic inclusiveness and accessibility of services.  Within public services, we have seen an increase of the use of AI, be it for decision support or to further gain  efficiency by completely automating processes. The use of AI in direct s ervice delivery between citizen and  government seems like an area in which there is much to gain, yet for now, not much evidence is found  underpinning such developments.     Summari sing, we identify the main benefits  of AI use in the public sector as follow s:  • Efficiency gains and internal process optimisation .  • Less human error and fraud, both internally and in services to businesses and citizens .  • Possibility to deliver more accessible and inclusive services: personalisation .  • Increase of anticipatory governance and policy: more accurate predictions .  Potential benefits as described above relate to particular drivers for  uptake of AI in the public sector. A n exploration of drivers for AI in the  public sector among st different Member States ’ representati ves25, has  show n that i n general Members States are looking both for better  monitoring and understanding of citizen behaviour, and also to make  better predictions and to offer  more tailored services. A  common  driver  or requirement to make this happen is the simplification of  regulatory frameworks  enabling and facilitating data sharing ( for  AI )  which  leads to improved data accessib ility. Also having better  capacity to process different languages  should get high priority  since  AI-based services will increas ingly  be either trained and/or used cross -border . Many AI applications are driven by efficiency goals, often by  streamlining  processes or enhanc ing detection capabilities through for instance patter ns and comparisons.  This efficiency gain  of AI aligns with generic drivers of digitisation of government  and as such provides a  mandate to explore how AI can be used  to deal with large amounts of tasks with limited funds. Although  this var ies widely per policy domain and/or department, the avail ability of useful data is both a driver  and a barrier  (in case of lacking data). Attracting experts with  the required digital skills  by public a u t ho rities   as well as the level of connectedness to ICT industry  will positively influence the uptake of AI for public  services .   Moreover, the way in which AI is being developed in the public sector, and by whom, may  have a maj or  influence in reali sing its benefits . Developing AI in -house may  increase transparency and auditability of AI  systems in the public sector . However, they may  also run the risk of lower performance, higher start -up costs,  less training data and  other  challenges in uptake compared to for instance an established private party who  is able to  co-develop and offer AI -based public services. In case  of the latter , however, data  and model  transparency as well as auditability of the system  become more challenging and as such would pose risks  to upholding public values or protecting fundamental rights. Again, it is important to understand the extent of potential risks and benefits in the context of a particular AI application in the public sector. When look ing  at benefits for  the public sector when it comes to applying AI, it is necessary to  understand what publ i c  sector goals are being aimed for or supp orted with the AI system.   Summari sing, we identify the main drivers  of AI use in the public sector as follows:   • Simplification of regulatory landscape .  • Sharing of best practices .   • Alignment of strength of AI (optimisation) and digital government goals .   
IPOL | Policy Department for Economic, Scientific and Quality of Life Policies     PE 662.936  6  • Earlier experience and investments in digitisation in the public sector .  • Level of digitisation in society: demand and uptake by citizens and governments of AI -based services .  Challenges and risks of AI for public services   While  there are benefits of  the use  of AI,  increas ed attention for AI in society and in the public sector has also   raised concerns  about the risks and harms AI -based system may  cause. While forms of AI , such as rule -based  systems based on expert knowledge,  have been long deployed in manners usually not considered harmful ,  there is increasing concern regarding the application of AI , and more specifically m achine learning , to  societal challenges . Not all AI systems are considered harmful  for individuals. Howe ver, the use of  predictive systems  in the public sector has already had undesired  consequences , espec ially when deployed  in forms of (semi) a lgorithmic decision making (ADM) . The SyRI , for example, was  an AI-based system usi ng  data from many different databases including personal and sensitive data to attribute a risk -prediction score  to citizens (risk of committing a crime or offence) . As mentioned earlier, t his system has been ruled  illegitimate and harm ful to human rights by a court of law .   This raises the  question what harm is or can be in relation to AI  and wh at that means for A I-based applications  and services in the public sector . Harm in a legal sense refers to damages or loss to a person or group  of  persons (be they natural or legal persons)26. The question of harm in relation to AI can be approached  from different perspectives . There is a technological perspective on risks and harms mainly in the AI subdomain of m achine learning , in which the unex plainably  of AI (black -box al gorithms) are a main concern.   Risks and harms can be approached from an ethical point of view  by  asking  what the moral underpinnings of us e or non- use of  forms of AI  are, e.g. to tackle challenges or solve a problem , and at what social ,  societal, economic or moral costs? Moreover, there is a legal viewpoint  to harms, related to the question of whom to appoint liability and  accountability claims  in relation to esta blished harms . The question is  whether our current lega l frameworks and democratic systems of  checks and balances are equipped to regulate AI risks and harms, when  taking the  recently  proposed regulation for AI in mind. Lastly, the viewpoint of citizens and their view on AI  risks and harms is of importance . How do people interpret this wave of AI  developments and what are their  main hopes, concerns and perceived risks  when it comes to AI? On all these fronts, fundamental and  applied research is ongoing, and even more is needed to understand and assess AI as a s ocio -technical  system  and its accompanying risks and harms.   Recent cases of governmental use of AI gone wrong ( e.g. the  afore mentioned SyRI system  in the  Netherlands , or the automation of grading in the UK27) have led to a growing public concern over the  development and use of AI in society28. Specifically , the use of AI poses a risk for the public sector because  it lea ds to opaque  procedures. Recent court cases have made explicit that harms indeed occur as a result of   this opacity . The se harms  evolve aroun d (among st other s) information asymmetry, not knowing about ADM   processes in government services, not being aware and not being informed about of being part of a dataset  used in an digital application, or being part of the outcome of a ‘fact -finding’ algor ithm that predicts a  certain likelihood of a citizen fallen into a particular category. Especially in policy areas such as  law  enforcement and fraud  detection, once citizens end up  on such a list, it can be life -destroying ( a ‘red flag’  will continue to  pop up in requests for benefits, childcare services, job -seeking etc .).   While usually  developed and implemented with the best of intentions, the citizen -data double that has been  created through datapoints and used by governments to create prediction s about future behaviour has  often  lead to dehumanisation  and increased bureaucratization of government. The role of AI cannot be  
ArtificiaI Intelligence and public services      7 PE 662.936  underestimated in the ongoing development of digiti sing government , while  being  far more scrutin ised  than private companies when i t comes to forms of AI and ADM . NGO ’s29 and privacy  and ethics advocates  follow closely if and how ethical guidelines for  AI are upheld and what kinds of policy domains benefit from  AI the most and at what risk. Scholars have mentioned computational violations of privacy, behaviour  influencing through hyper -personalisation, algorithmic opacity30 (not knowing when and how you are  dealing with an AI or not, and what predictions it has made about you), lack of diversity of norms that get  built in and aut omatically enforced31,  dehumanisation through hard -coding assumpti on  and values, irreproducibility of AI outcomes,  monopolies of complexity , and more fundamental l y  the negation of novel and public futures32, a n d power   asymmetries enhanced by algorithms witho ut clear  possibilities for redress33.   Some of these harms may  be amplified by the use of  particular forms of AI , and some already existed but  come to the surface through the application of AI .  Specific forms of AI, most notably black -box AI  (machine learni ng) and the application thereof in decision -making processes  in that regard  pose novel risks   that go beyond the known risks and harms that have resulted from an increasingly data driven  society34.   Summari sing, we identify the main risks  of AI use in the public sector as follows:   • Discrimination due to data bias and hard coding of presumptions .  • Transparency and explicability. Good governance principles and right to explanation of a decisi on  becomes more difficult when the use of AI and ‘bl ack-box’ algorithms for decision support or  algorithmic decision making is increasing .  • Dehumanisation of public services. Due to hardcoding of governmental processes and decision making, there is less and less leeway for exceptions or case- by-case circumst a nces (a u t om at ion  in   general and AI specifically does not deal well with exceptions or boundary cases) .  Barriers for uptake  of AI for public services   The risks that AI poses to human rights and public values contributed to the development of a European proposal for AI regulation . By this regulation  certain AI application domains  are considered to pose an  unacceptable risk will be prohibited, applications classified as high risk will be regulated, and lower -risk AI  will be left to voluntary self -regulation , certification , or labelling. The consequence f or public sector AI  depending on the policy area . For instance,  the safety and security domain ha s different needs and potential  uses for AI -based systems and services than the social care domain.   There are, however, some generic barriers to be addressed  for uptake of AI in the public sector. A first issue  is a generic lack of openness and transparency of AI applications  and the dataset and features  measured  or generated  in such applications. Moreov er, there is a barrier of expertise and capacity  within national  and local governments to develop AI -based applications in -house: as a result, governments either procure  of AI or  set up  public -private partner programs in which governments are responsible f or an AI system , but   they are not the  owner of the software. While  there are proven advantages of public -private partnership s,  in the case of AI this balance needs careful consideration  when it comes to ADM . The latter considerati on  would be helped by clea r (risk) frameworks to guide such decisions . So far, there are many ethics  frameworks  for AI 35, but they are difficult to translate into data science practice. Whereas the EC proposed a novel data  
IPOL | Policy Department for Economic, Scientific and Quality of Life Policies     PE 662.936  8  governance act36, the connection to AI and AI regulation still needs to be made and put into practice with in   an already complicated data regulation landscape.   Another barrier for uptake is uncertainty of the role and place of government in data ecosystems or the l ack   of data ecosystem tailored to governmental use. L ea v ing  exceptions aside37, many local governmental bodies or smaller  communities do not have the means to either organi se or be part of  a vivid data ecosystem, which is a minimal requirement to develop  AI. In terms of open data challenges, a first wou ld be how to develop  a data4AI  infrastructure38 as a necessary building block for training  AI that is safe, secure, robust  and (con)testable; a second would  be to find ways to independently scrutini se and test the AI models  used on robustness and performanc e on the long run. Although the new AI regulation hints at this, we have  seen very little regulatory sandboxes  or auditing frameworks in place. Although it is too early for thi s,  model robustness, auditability and explicability of outcomes is key in building reliable AI -based public  services. Other  challenges for many AI -based services in the public sector will be the non -transferability and  testability due to the dependency on a specific language in which the algorithm has been trained and tested   (if quali ty procedures are correctly followed) . Multilingual AI  and accompanied training data are one of  the grand challenges for communicative AI in Europe.   Summari sing the main barriers  for uptake are:   • Access to data for training and testing .  • Complex data regulation landscape .   • In-house AI expertise and proprietary systems and software.   • Transparency and accountability of AI systems .  • Multilinguistic datasets to train local AI models .   Recommendations for uptake of AI for public services   The public sector has  a very important role to play in the responsible development, deployment and use of  AI systems to address societal challenges. Whether as developer of in -house AI  systems, or as deployer of  commercial AI  systems , or as regulator of AI, the public sector d isposes over various tools which coul d be  used more actively and effectively than is currently the case.    Whereas most Mem ber States have national AI strategies and many public and private organisations have  published or are working on ethical frameworks a nd guidelines for responsible  or human -centric  AI, littl e   attention is paid to the practical reality of current  AI-based public services . Many of such services are  developed with external private entities. As such, litt le attention is paid to procurement processes around  AI in the public sector and the (lack of) reflection  of AI ethics terminology  and principles  in those processes.  Public procurement in particular holds significant potential in the responsible development and  deployment of comm ercial AI  systems for use in the public sector. The EU counts over 250,000 public  authorities. With a budget of about 2 trillion EUR per year (the equivalent of over 14% of the EU GDP39), they  are the main investors in areas such as social protection, healt h, transport, education, energy, public order  and safety, and defence. However, preliminary data  indicate that in public procurement of AI, price remains  the main selection and evaluation criterium, and strict criteria for the development of socially respo n sible  AI are rarely set. This could be actively enco uraged and supported by harmonis ed EU guidance (such as the  recently published EU guidance for socially responsible public procurement; or specific guidance for AI  public procurement40).   
ArtificiaI Intelligence and public services      9 PE 662.936  Next to public procurement, other tools  could be used to address specific challenges posed by AI in public  services. Amongst those currently explored are extended pre- procurement tasks , pre-commercial  procurement projects , technical and regulatory sandboxes , and testbeds.    Pre-procurement can be used in the public sector to assess in advance the feasibility of a potential AI  project in all its complexity: social, economic, technical, organi sational. In addition, it can be used to define  the social and economic requirements  with which the potential AI  system have to comply (such as  transparency, explainabilty, usability, etc.). There is no information about the current use of this due  diligence tool by the EU public sector.   Pre-commercial procurement projects are initiated by one or several public sector organi sat ion s  wo rking  closely with several suppliers of technical solutions . They aim for the development and prototyping of AI   systems that satisfy specific needs as defined by the public sector buyer. This tool is currently used  experimentally by the public sector41. Technical and regulatory sandboxes are controlled environments  in which AI  systems are developed and tested live.  In these environments  also the functioning of AI  systems  and their potential risks can be explored in a safe environment and used for regulatory purposes42. This tool  is also relatively recent and experimental.  There is an  opportunity  for the p ublic sector  to lead the way in  creating trustworthy AI . Based on recent insight s gathered from applied research regarding the use of AI in the public sector, we  recommend considering  the following :  1. Promote H uman Rights Impact assessment for AI (HRIAAI). Whereas Human Rights Impact Assessment in  itself is not new, in the context of AI in the public sector, there have been recent  developments to apply  this form of impact assessment.   2. Experimentation & r egulatory sandboxing. As proposed in the novel regulation, experimentation and  regulatory sandboxing are key in developing trustworthy AI in and for the public sector. We stress the need  to apply a multidisciplinary approach, with a strong emphasis on social science and humanities as being  currently underrepresented in such endeavours .  3. Education and explanation. If the aim is to take the wider public on board and develop true human -centric  AI, the public sector should be leading in demystifying AI and offer ing free and open education about AI.  Over the recent year, many such initiatives have been developed and deployed in both formal and  vocational/voluntary education: professional education within government about AI would truly help in  increasing public se ctor readiness for AI.   4. Recontextuali sation and rehabilitation of the citizens behind the datasets. In many cases in which publ i c  sector AI went wrong, the issue seemed to originate from a loss of context and impact on real lives of real people: if public s ectors AI developers and administrators are only confronted with numbers, graphs and  thresholds, the human side of AI gets lost.   5. Oversight and monitoring should be organised in a dynamic way. Many specifically self -learning ‘black box AI’ applications may  change over time due to optimisation and/or novel or added datasets or features.  As a result, oversight and evaluation of such systems also needs to be dynamic and equipped for the long  term. The conformity assessment as described in the proposed AI regul ation does not seem to capture the  long -term changes to the algorithms and accompanie d impact of AI, or ‘feature creep’ that might o ccur   over time. Moreover, many AI applications will operate within a ‘system of systems’; changing the  algorithm might have secondary effects on other technical or organisational processes. This makes the exercise of oversight and evaluation potentially more complex than in previous IT systems.  
IPOL | Policy Department for Economic, Scientific and Quality of Life Policies     PE 662.936  10  1  Veenstra, A.F. van, Bodea, G., Timan, T., Misuraca, G., & Noordt , C. van (2020). Assessment of the Use of Artificial Intelligenc e to  Support Public Services: Methodology and Roadmap. In : Virkar, S. et al. (eds.)  CEUR Workshop  Proceedings  2797, CEUR WS.org . (359 -361).   2  Case number / cause list number: C/09/550982 / HA ZA 18 -388 , ECLI:NL:RBDHA:2020:1878, Rechtbank Den Haag, C -09-550982 HA ZA 18 -388 (English) (rechtspraak.nl) .  3  Europea n Commission, Communication from the Commission to the European Parliament, the Council, the European Economic   and Social Committee and the Committee of the Regions. Fostering a European approach to Artificial Intelligence , Brussels  21.4.2021, COM(2021) 20 15, Proposal for a Regulation laying down harmonised rules on artificial intelligence | Shaping Europe’s  digital futur e (europa.eu) .   4  Villani, C., Bonnet, Y., & Rondepierre, B. (2018). For a meaningful artificial intelligence: towards a French and European strategy .  Conseil national du numérique , https://www.aiforhumanity.fr/pdfs/MissionVillani_Report_ENG -VF.pdf .  5  A definition of Artificial Intelligence: main capabilities and scientific disciplines . AI HLEG,  https://digital strategy.ec.europa.eu/en/library/definition -artificial -intelligence -main -capabilities -and-scienti fic-disciplines .  6  WHITE PAPER On Artificial Intelligence - A European approach to excellence and trust, COM(2020) 65 final,  https://e c.europa.eu/info/sites/info/files/commission -white -paper -artificial -intelligence -feb2020_en.pdf .  7  OECD (2019), Artificial Intelligence in Society , www.oe cd.org/going -digital/artificial -intelligence -in-society -eedfee77 -en.htm .   8  Arciszewski, H.F.R., Greef, T.E. & Delft, J.H. van (2009, November). Adaptive Automation in a Naval Combat Management System.   In:  IEEE Transactions on Systems, Man, and Cybernetics – Part A: Systems and Humans, 39(6), 1188 -1199.   9  Parasuraman, R., Sheridan, T.B. & Wickens, C.D. (2000, May). A model for types and levels of human interaction with automatio n.  In: IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans, 30(3), 286 -297.   10  Public Undertakings/Services in the EU: Summary - Part 2 (DG4 Study ECON W21) ,   https://www.europarl.europa.eu/workingpapers/econ/w21/sum -2_en.htm .  11  See EC: https://ec.europa.eu/info/topics/single -market/services -general -interest_en .  12  Hoekstra, M, Chideock, C. & Veenstra , A.F. van  (2021).  Quickscan AI in publieke dienstverlening II , Quickscan AI in publieke  dienstverlening II | Rapport | Rijksoverheid.nl .  13  Purdy, M., & Daugherty, P. (2016). Why artificial intelligence is the future of growth.  Remarks at AI Now: The Social and Economic   Imp lications of Artificial Intelligence Technologies in the Near Term, 1 -72.:  14  Gartner. (2017). Press release: Gartner Says By 2020, Artificial Intelligence Will Create More Jobs Than It Eliminates , AI Will Create  More Jobs Than It Eliminates | Gartner .  15  AlphaFold: a solution to a 50 -year -old grand challenge in biology. DeepMind  blog post ,   https://deepmind.com/blog/article/alphafold -a-solution -to-a-50-year -old-grand -c hallenge -in-biology .  16  AI & THE SUSTAINABLE DEVELOPMENT GOALS: THE STATE OF PLAY . Report by 2030vision , state -of-play -report.pdf  (2030vision.com) .  17  Eurofound (2020),  Impact of digitalisation on social services, Publications Office of the European Union , Luxembourg,  https://www.eurofound.europa.eu/public ations/report/2020/impact- of-digitalisation -on-soci al -services .  18  See for example  a news coverage on how a robot is used in the context of public service delivery in the UK , LocalGov.co.uk -  Your authority on UK local government -  Pepper the robot to take on social care tasks .  19  Steen, M., Timan, T., & Poel, I. van de (2021). Responsible innovation, anticipation and responsiveness: case studies of algorithms  in decision support in justice and security, and an exploration of potential, unintended, undesirable, higher -order effects.  AI and  Ethics , 1-15.  20  Chew , Alton Ming Kai, e t al.  (2020 ). Digital health solutions  for mental health disorders during  COVID -19. Frontiers in   Psychiatry , 11, 898.   21  Examples of AI developed for Covid in France . See : Intelligence artificielle et lutte contre la Covid -19 (orange.com) .  22  The European dashboard on Covid, f or example. See : COVID -19 situation updates (europa.eu) .  23  See for example in  France the organisation of expertise  around privacy -preservation in the TousAnticovid app : Info Coronavirus  COVID -19 - Application Tousanticovid | Gouvernement.fr .  24  See fo r exa mple: Covid -19 - why didn't Europe's tracing apps work? (euobserver.com) .  25  Colin van Noordt & Gianluca Misuraca & Marzia Mortati & Francesca Rizzo & Tjerk Timan, 2020. "AI Watch - Artificial Intelligen c e  for the public sector: Report of the "1st Peer Learning Workshop on the use and impact of AI in public services" , Brussels 11 -12  February 2020 ," JRC Working Papers  JRC120315, Joint Research Centre (Seville site). p p. 11.  26  Kleinig, J. (1978). Crime and the Concept of Harm.  American Philosophical Quarterly , 15(1), 27 -36.  27  See: The student and the algorithm: how the exam results fiasco threatened one pupil’s future | Education | The Guardian   28  BEUC (2019). Artificial Intelligence: what consumers say - Findings and policy recommendations o f a multi -country survey on AI,  beuc -x-2020 -078_artificial_intelligence_what_consumers_say_report.pdf .  29  Such as the NGO  AlgorithmWatch .   30  Ananny, M., & Crawford, K. (2018). Seeing without knowing: Limitations of the transparency ideal and its application to  algorithmic accountability.  New media & society , 20(3), 973 -989.                                                                 
ArtificiaI Intelligence and public services      Disclaimer and copyright . The opinions expressed in this document are the sole responsibility of the authors and do not necessarily represent  the official position of the European Parliament. Reproduction and translation for non -commercial purposes are authorised, provided the  sour ce is acknowledged and the European Parliament is given prior notice and sent a copy. © European Union, 2021.   © Images used under licence from Adobe Stock     IP/A/AIDA /2021- 01; Manuscript completed: July  2021; Date of publication: July  2021  Administrator s responsible: Frédéric GOUARDÈRES, Matteo CIUCCI ; Editorial assistant s: Catherine NAAS, Janetta CUJKOVA   Contact: Poldep -Economy -Science@ep.europa.eu   This document is available on t he internet at: www.europarl.europa.eu/supporting -analyses     Print  ISBN 978- 92-846- 8380- 2 | doi: 10.2861/306067 |  QA -06-21-004- EN-C  PDF  ISBN 978- 92-846- 8379- 6 | doi:  10.2861/59813 |  QA -06-21-004- EN-N   31  See for example : https://themarkup.org/2020 -in-review/2020/12/15/algorith ms-bias -racism -surveillance .  32  See for example : https://www.theguardian.com/commentisfree/2021/feb/05/jeff -b....  33  See for example : Human -centred AI in the EU - YouTube  for more elaboration on risks and potential harms .  34  Some of those known  risks are described here:  7 Types of AI Risk and How to Mitigate their Impact | by Babar Bhatti | Towards  Data Science .  35  Cath, C., Wachter, S., Mittelstad t, B., Taddeo, M., & Floridi, L. (2018). Artificial intelligence and the ‘good society’: the US, EU, and  UK approach.  Science and engineering ethics , 24(2), 505 -528.   36  Proposal for a REGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL on European dat a governance (Dat a  Governance Act). COM/2020/767 final ,  https://eur -lex.europa.eu/legal content/EN/TXT/PDF/?uri=CELEX:52020PC0767&from=EN .   37  One of those exceptions is the municipality of B arcelona, who  have developed open source software and tools to manage their  public services.  See: Barcelona: showcase of smart city dynamics - Smart City Hub .  38  Janssen, M.,  Charalabidis, Y. , & Zuiderwijk, A. (2012). Benefits, adoption barriers and myths of open data and open   government.  Information systems management , 29(4), 258 -268.   39  The European policy on public procurement can be found here:  https://ec.europa.eu/info/policies/public -procurement_en .  40  One example are the AI government procurement guidelines defined by the Office for Artificial Intelligence in the UK . See:  Guidelines for AI procurement -  GOV.UK (www.gov.uk) .  41  One example is the AI4Cities pre -commercial procurement project. The aim of the pr oject is to procure “R&D of solutions that  support cities’ transition to carbon neutrality via artificial intelligence (AI) and related enabling digital technologies. ( …) Two key  domains linked to the cities’ strategies and carbon -positive goals have been pre-selected: mobility and energy.” Initiators of the  project are a group of EU cities (Helsinki, Amsterdam, Paris, Copenhagen, Tallinn and Stavanger) with a shared interest in sm art  city applications and the reduction of greenhouse gas emissions. See: Achieving smart city climate commitments with AI -  Intelligent Transport .  42  One example is the regulatory sandbox for responsible AI set up by the Norwegian Data Protection Authority. The sandbox  serves a double purpose: for the Norwegian Data Protection Authority to increase their own knowledge about AI and develop  guidance for o rganizations using AI; and to help “individual organizations ensure compliance with relevant regulations and the  development of solutions that take privacy into account.” See: https://www.datatilsynet.no/en/regulations -and-tools/san dbo x for-artificial -intelligence/ .     
