Trustworthy AI - IBM ResearchSkip to main contentResearchFocus areasBlogPublicationsCareersAboutBackFocus areasSemiconductorsArtificial IntelligenceQuantum ComputingHybrid CloudBackAboutOverviewLabsPeopleCollaborateBackSemiconductorsBackArtificial IntelligenceBackQuantum ComputingBackHybrid CloudBackOverviewBackLabsBackPeopleBackCollaborateResearchFocus areasSemiconductorsArtificial IntelligenceQuantum ComputingHybrid CloudBlogPublicationsCareersAboutOverviewLabsPeopleCollaborateOpen IBM search fieldCloseHome↳ AI↳ Trustworthy AIJump to ...menu iconTopicsTrustworthy AIOur trust in technology relies on understanding how it works. It’s important to understand why AI makes the decisions it does. We’re developing tools to make AI more explainable, fair, robust, private, and transparent.Explore our topicsExplore our topicsOverviewArtificial intelligence systems have become increasingly prevalent in everyday life and enterprise settings, and they’re now often being used to support human decision-making. These systems have grown increasingly complex and efficient, and AI holds the promise of uncovering valuable insights across a wide range of applications. But broad adoption of AI systems will require humans to trust their output.

When people understand how technology works, and we can assess that it’s safe and reliable, we’re far more inclined to trust it. Many AI systems to date have been black boxes, where data is fed in and results come out. To trust a decision made by an algorithm, we need to know that it is fair, that it’s reliable and can be accounted for, and that it will cause no harm. We need assurances that AI cannot be tampered with and that the system itself is secure. We need to be able to look inside AI systems, to understand the rationale behind the algorithmic outcome, and even ask it questions as to how it came to its decision.

At IBM Research, we’re working on a range of approaches to ensure that AI systems built in the future are fair, robust, explainable, account, and align with the values of the society they’re designed for. We’re ensuring that in the future, AI applications are as fair as they are efficient across their entire lifecycle. Our workWhy we’re teaching LLMs to forget things ExplainerKim Martineau07 Oct 2024AIGenerative AINatural Language ProcessingTrustworthy AIA toxic language filter built for speedNewsKim Martineau09 Sep 2024AIFoundation ModelsOpen SourceTrustworthy AITeaching AI models to improve themselves ResearchPeter Hess14 Aug 2024AIComputer ScienceExplainable AIGenerative AINatural Language ProcessingTrustworthy AITrustworthy GenerationIBM and RPI researchers demystify in-context learning in large language modelsNewsPeter Hess25 Jul 2024AIAI TransparencyExplainable AITrustworthy AIIBM reaffirms its commitment to the Rome Call for AI ethicsNewsMike Murphy15 Jul 2024AIFairness, Accountability, TransparencyTiny benchmarks for large language modelsNewsKim Martineau03 Jun 2024AIAI TestingFoundation ModelsGraniteSee more of our work on Trustworthy AITopicsAI TestingWe’re designing tools to help ensure that AI systems are trustworthy, reliable and can optimize business processes. Adversarial Robustness and PrivacyWe’re making tools to protect AI and certify its robustness, and helping AI systems adhere to privacy requirements.Explainable AIWe’re creating tools to help AI systems explain why they made the decisions they did. Fairness, Accountability, TransparencyWe’re developing technologies to increase the end-to-end transparency and fairness of AI systems. Trustworthy GenerationWe’re developing theoretical and algorithmic frameworks for generative AI to accelerate future scientific discoveries. Uncertainty QuantificationWe’re developing ways for AI to communicate when it's unsure of a decision across the AI application development lifecycle.Science for Social GoodIBM Science for Social Good partners IBM Research scientists and engineers with academic fellows, subject matter experts from NGOs, public sector agencies, and social enterprises to tackle emerging societal challenges using science and technology. Explore the initiativePublicationsNavigating the Complexities of Generative AIs: Ethical, Social, and Legal ImplicationsVyoma Rajeshkumar Gajjar2024ADSA 2024MoJE: Mixture of Jailbreak Experts, Naive Tabular Classifiers as Guard for Prompt AttacksGiandomenico CornacchiaKieran Fraseret al.2024AIES 2024Distillation of knowledge and opinion of LLMs in an opinion dynamic frameworkNgoc Lan HoangMichail Smyrnakiset al.2024INFORMS 2024Monetizing Currency Pair Sentiments through LLM ExplainabilityLior LimonadFabiana Fournieret al.2024ECAI 2024Securing Floating-Point Arithmetic for Noise AdditionNaoise HolohanStefano Braghinet al.2024CCS 2024On Robustness-Accuracy Characterization of Language Models using Synthetic DatasetsChing-yun KoPin-Yu Chenet al.2024COLM 2024View all publicationsBuilding trustworthy AI with WatsonOur research is regularly integrated into Watson solutions to make IBM’s AI for business more transparent, explainable, robust, private, and fair.Learn moreIBM LogoFocus areasFocus areasSemiconductorsArtificial IntelligenceQuantum ComputingHybrid CloudQuick linksQuick linksAboutPublicationsBlogEventsWork with usWork with usCareersCollaborateContact ResearchDirectoriesDirectoriesTopicsPeopleProjectsFollow usFollow usNewsletterXLinkedInYouTubeContact IBMPrivacyTerms of useAccessibility
