                                        J R C  T E C H N I C A L  R E P O R T   AI Watch   Beyond pilots: s ustainable implementation  of AI in public services   EUR 30868  EN 
           This publication is a technical report by the Joint Research Centre (JRC), the European Commission’s science and knowledge se rvice. It aims  to provide evidence -based scientific support to the European policymaking process. The scientific output expressed does not imply a policy  position of the European Commission. Neither the European Commission nor any person acting on behalf of the Commission is res ponsible  for the use that might be made of this publication. For information on  the methodology and quality underlying the data used in this  publication for which the source is neither Eurostat nor other Commission services, users should contact the referenced sourc e. The  designations employed and the presentation of material on the maps do not imply the expression of any opinion whatsoever on the part  of the European Union concerning the legal status of any country, territory, city or area or of its authorities, or concernin g the delimitation  of its frontiers or boundaries.     Contact information   Name: European Commission, Joint Research Centre (JRC), Digital Economy Unit   Address: Via Enrico Fermi 2749, 21027 Ispra (VA), Italy   Email:  EC-AI-WATCH@ec.europe.eu     EU Science Hub   https://ec.europa.eu/jrc       JRC126665     EUR 30868  EN      PDF ISBN 978-92-76-42587 -8 ISSN 1831 -9424  doi:10.2760/440212                                  Luxembourg: Publications Office of the European Union, 2021     © European Union, 2021                     The reuse policy of the European Commission is implemented by Commission Decision 2011/833/EU of 12 December 2011 on the reus e  of Commission documents (OJ L 330, 14.12.2011, p. 39). Except as otherwise noted, the reuse of this document is authorised un der the  Creative Commons Attribution 4.0 International (CC BY 4.0) licence ( https://creativecommons.org/licenses/by/4.0 ). This means that reuse is  allowed provided appropriate credit is given and any  changes are indicated. For any use or reproduction of photos or other material that is  not owned by the EU, permission must be sought directly from the copyright holders.     All content © European Union, 2021, except where otherwise stated.     How to cite thi s report: Molinari F., van Noordt C., Vaccari L , Pignatelli F. and Tangi L. , AI Watch . Beyond pilots: s ustainable implementation  of AI in public services , EUR 30868 EN, Publications Office of the European Union, Luxembourg, 2021, ISBN 978-92-76-42587 -8,  doi:10.2760/440212 , JRC 126665 .    
     Contents   Acknowledgements  ................................ ................................ ................................ ................................ ................................ ................................ ................................ .......... 1  Abstract  ................................ ................................ ................................ ................................ ................................ ................................ ................................ ................................ ....... 2  Forewo rd................................ ................................ ................................ ................................ ................................ ................................ ................................ ................................ ..... 3  Executive summary  ................................ ................................ ................................ ................................ ................................ ................................ ................................ .......... 5  1 Background and vision  ................................ ................................ ................................ ................................ ................................ ................................ .........................  8  1.1 Research backgroun d ................................ ................................ ................................ ................................ ................................ ................................ ..............  8  1.2 Policy background  ................................ ................................ ................................ ................................ ................................ ................................ .......................  9  1.3 What this report is about  ................................ ................................ ................................ ................................ ................................ ................................ .. 10  2 Definition s and concepts  ................................ ................................ ................................ ................................ ................................ ................................ ................  12  2.1 From adoption to implementation: the process of AI technology appropriation ................................ .........................  12  2.2 Putting AI innovation in cont ext: the proposed analytical framework ................................ ................................ ...................  15  2.3 What can we learn? Towards a systemic view of AI appropriation in the public sector  ................................ ...... 18  3 Lessons from the US and China  ................................ ................................ ................................ ................................ ................................ ..............................  21  3.1 The terms of the techno -economic race  ................................ ................................ ................................ ................................ ............................  21  3.2 Stimulating the use of AI in the US government  ................................ ................................ ................................ ................................ ....... 24  3.3 Stimulating the use of AI in the Chinese government  ................................ ................................ ................................ ..........................  26  3.4 Key take -aways  ................................ ................................ ................................ ................................ ................................ ................................ .........................  28  4 Challenges to AI implementation in the EU public sector  ................................ ................................ ................................ ...............................  30  4.1 Looking for a critical mass of AI investment  ................................ ................................ ................................ ................................ .................  30  4.2 Data quali ty, availability and interoperability  ................................ ................................ ................................ ................................ ...............  32  4.3 Talent attraction and skill improvement  ................................ ................................ ................................ ................................ ............................  35  4.4 Input, throughput, and output legitimacy o f AI use  ................................ ................................ ................................ ................................  36  4.5 Enabling user -centric services with and by AI  ................................ ................................ ................................ ................................ ..............  38  5 Policy implications ................................ ................................ ................................ ................................ ................................ ................................ ................................ . 41  5.1 In search of a critical mass for the “champions” of AI for government  ................................ ................................ ..............  41  5.2 Tackling data availability and quality as an example of market failure  ................................ ................................ ............  45  5.3 Emphasising AI explainability as another key facet of accountability  ................................ ................................ ..................  47  5.4 Fully exploiting the degrees of freedom allowed by Innovative Public Procurem ent ................................ ............  48  6 Conclusion and way forward  ................................ ................................ ................................ ................................ ................................ ................................ ...... 54  6.1 On governing with AI in the Public Sector  ................................ ................................ ................................ ................................ ........................  54  6.2 On governing AI in the Public Sector  ................................ ................................ ................................ ................................ ................................ ..... 56  6.3 Main insights from the report towards an analytical framework for evaluating AI impact in  government  ................................ ................................ ................................ ................................ ................................ ................................ ................................ .................  57  List of abbreviations  ................................ ................................ ................................ ................................ ................................ ................................ ................................ .... 60  List of figures  ................................ ................................ ................................ ................................ ................................ ................................ ................................ .....................  62  List of tables  ................................ ................................ ................................ ................................ ................................ ................................ ................................ ........................  63  References  ................................ ................................ ................................ ................................ ................................ ................................ ................................ .............................  64  Glossary  ................................ ................................ ................................ ................................ ................................ ................................ ................................ ................................ ... 74 
  1   Acknowledgements   Several people contributed to this report. The authors would like to thank the editor Francesco Pi gnatelli and  the internal reviewers Montserrat Lopez Cobo, Marina Manzoni, Sven Schade and Peter Ulrich  from the JRC as  well as Dietmar Gattwinkel from DG CNECT , for reading earlier drafts and providing their comments and advice  on both structure and conte nts. We are also grateful to the following colleagues and experts for their opinions  and support: Dragan Cisic, Marco Combetto,  Joe Cullen, Enrico Ferro, Sergio Gusmeroli , Rony Medaglia , and  Francesco Niglia, who also provided an input on AI user centricit y. All errors remain the sole responsibility of the  authors.   Authors   Francesco Molinari  - Independent Researcher   Colin van Noordt  - Tallin University of Technology   Lorenzino Vaccari  - Independent  Researcher   Francesco Pignatelli  - European Commission, Joint  Research Centre   Luca Tangi  -  European Commission , Joint Research Centre    
  2   Abstract   Artificial Intelligence (AI) is a peculiar case of General Purpose Technology that differs from other examples in  history  because  it embeds specific uncertainties or ambiguous character that may lead t o a number of risks  when used to support  transformative  solutions in the public sector.  AI has extremely powerful and, in many  cases, disruptive effects on the internal management, decision -making and service  provision  processes  of public  administration. O ver the past few years, the European Union and its Member States have designed regulatory  policies and initiatives to mitigate the AI risks and make its opportunities a reality for national, regional and  local government institutions. ‘AI Watch ’ is one of these initiatives which has, among its goals , the monitor ing  of European Union’s industrial, technological, and research capacity in AI and the develop ment  of an analytical  framework of the impact potential of AI in the public sector. This report , in parti cular, follows a previous  landscaping study and collection of European cases, which was delivered in 2020.   This document first introduces the concept of AI appropriation in government, seen as a sequence of two  logically distinct phases, respectively named  adoption and implementation of related technologies in public  services and processes. Then, it analyses the situation of AI governance in the US and China and contrasts it to  an emerging, truly European model, rooted in a systemic vision and with an empha sis on the revitalised  role of  the member states in the EU integration process,  Next, it points out some critical challenges to AI  implementation in the EU public sector, including: the generation of a critical mass of public investments, the  availability  of widely shared and suitable datasets, the improvement of AI literacy and skills in the involved  staff, and the threats associated with the legitimacy of decisions taken by AI algorithms alone. Finally, it draws  a set of common actions for EU decision -makers willing to undertake the systemic approach to AI governance  through a more advanced equilibrium between AI promotion and regulation.   The three main recommendations of this work include  a more robust integration of AI with data policies, facing  the is sue of so -called “explainability of AI”  (XAI), and broadening the current perspectives of both Pre Commercial Procurement (PCP) and Public Procurement of Innovation (PPI) at the service of smart AI purchasing  by the EU public administration. These recommen dations will represent the baseline for a generic  implementation roadmap for enhancing the use and impact of AI in the European public sector.   
  3   Foreword   This report is published in the context of AI Watch, the European Commission knowledge service to monit or the  development, uptake and impact of Artificial Intelligence (AI) for Europe, launched in December 2018.    AI has become an area of strategic importance with the potential to be a key driver of economic development.  AI also has a wide range of potential  social implications. As part of its Digital Single Market Strategy, the  European Commission put forward in April 2018 a European strategy on AI in its Communication "Artificial  Intelligence for Europe". The aims of the European AI strategy announced in th e communication are:     To boost the EU's technological and industrial capacity and AI uptake across the economy, both by the  private and public sectors      To prepare for socio -economic changes brought about by  AI    To ensure an appropriate ethical and legal f ramework.    In December 2018, the European Commission and the Member States published a “Coordinated Plan on Artificial  Intelligence”,   on the development of AI in the EU. The Coordinated Plan mentions the role of AI Watch to monitor  its implementation.    Subsequently, in  February 2020,  the Commission unveiled its vision for a digital transformation that works for  everyone.  The Commission  presented  a White Paper  proposing  a framework for  trustworthy  AI based on  excellence and trust.    Furthermore, in April 202 1 the European Commission proposed a set of actions to boost excellence in AI, and  rules to ensure that the technology is trustworthy. The proposed Regulation on a European Approach for Artificial  Intelligence and the update of the Coordinated Plan on AI a im to guarantee the safety and fundamental rights  of people and businesses, while strengthening investment and innovation across EU countries. The 2021 review  of the Coordinated Plan on AI refers to AI Watch reports and confirms the role of AI Watch to sup port the  implementation and monitoring of the Coordinated Plan .  AI Watch monitors the European Union’s industrial, technological and research capacity in AI; AI -related policy  initiatives in the Member States; uptake and technical developments of AI; and A I impact. AI Watch has a  European focus within the global landscape. In the context of AI Watch, the Commission works in coordination  with Member States. AI Watch results and analyses are published on the AI Watch Portal  (https://ec.europa.eu/knowledge4policy/ai -watch_en ).   From AI Watch in -depth  analyses,  we will be able to understand better the European Union’s areas of strength  and areas where investment is needed. AI Watch wil l provide an independent assessment of the impacts and  benefits of AI on growth, jobs, education, and society.    AI Watch is developed by the Joint Research Centre (JRC) of the European Commission in collaboration with the  Directorate -General for Communicat ions Networks, Content and Technology (DG CONNECT).     This document  specifically addresses the following objective of AI Watch:   ”To provide an overview and analysis of the use and impact of AI in public services ”.   Particularly , it is a follow up to the f irst-year activities of AI Watch1 towards the investigation of the effective  uptake of AI in the public sector, that goes beyond the piloting phase . As such,  it builds on the knowledge gained  after the collection of 230 AI use cases  from EU  (Member States  and A ssociated States ) national, regional and  local government  officially presented in July 2020 . This output  has received  extensive  feedback from policy  experts and practitioners , notably  in the 2nd peer learning workshop with MS representatives held on S eptember  29th, 2020  (van Noordt & Pignatelli, 2020) .   While additional field research activities are now under way (including an EU wide survey and case specific  interviews) , in order  to take full stock of that knowledge , this report elaborates on the evidence gathered so far  and makes additional reflections on the common characteristics and the critical aspects observed in most real life cases. In so doing, the concept of AI appropriation , i.e., t he union of adoption and im plementation phases ,  in government is introduced, defined as a sequence of two logically distinct (and sometimes recurring or                                                    1 https://ec.europa.eu/jrc/en/publication/eur -scientific -and-technical -research -reports/ai -watch -artificial -intelligence -public -services   
  4   alternating , rather than linearly consecutive ) phases, respectively name d adoption  and implementation  of  related technologies.    Keeping the two phases separate surely holds heuristic value, confirm ed from the preliminary outputs of  field  activities . Moreover , it provides support to drawing several policy relevant implications, touching on both   strategic  directions introduced by a previous Science for Policy report  of the AI Watch serie s (Misuraca and van  Noordt, 2020) : “governing with AI ” on the one hand, and “ governing AI” on the other.    In the first direction , the key question is to determine whether and under which conditions AI appropriation can  become  supportive of a durable and positively  impact ful transformation  of EU public processes and services , in  line with the  provisions of the Tallinn Ministerial Declaration  on eGovernment . This requires a more advanced  equilibrium between AI promotion and AI regulation going beyond the experimental nature of many ob served  cases . In the second direction , a number of  challenges  are associa ted with  AI implementation and use in  government , which have been outlined  by several theoretical and empirical research studies and are  summarised in this report . The comparison with the US and China leads to highlighting the basic and distinc tive  elements of a truly European governance model of AI . A governance model which could overcome the  fragmentation of the EU GovTech market and set  out the conditions for reconciling ethical values with  technology adoption and implementation .  The latter r eflections , among others, will be further extended and integrated with another forthcoming AI Watch  publication , and will be shaped in the form of a proposed policy roadmap for securing the transition to an AI  enabled and digital ly transformed government  in Europe .  
  5   Executive summary   The present document is structured in six Sections: here we summarize the main take -aways for the reader .  In Section  1 (Background and vision) , a brief overview is provided of the research and policy state of the  art behind  this report and the whole AI Watch initiative.  The narrative starts  by considering AI as a General   Purpose  Technology , due to its distinctive features of pervasiveness, fast pace of diffusion, and innovation spawning tendency, which are also common to other e xamples of general  purpose technolog ies in history.  However, being a family of emergent, numerous and diversified technologies (not to speak about the  proliferation of custom solutions) AI also holds traits  of uncertainty and ambiguity , which  require multi ple  rounds of experimentation before a solution is adopted and  may generate issues or delays  in the materialisation  of expect ed impacts  from  its implementation and use . These traits make the adoption and implementation of  AI more complex and different from  the adoption and implementation of “conventional” Information and  Communication Technology (ICT) . In fact, in t he EU public sector , despite the good number of early adopters  from various national (and regional, and city) governments , AI-enabled public sec tor innovation – not to say,  transformation – often appears as the result of several concurrent elements, which are barely technological  in  essence . These include legal, organisational, work force-related , environmental, ethical  or societal aspects  that  are often overlooked by a perspective embedded in technology determinism. The crucial relevance of most of  those elements for the success or failure of AI solution implementation has started to be noted in the empirical  search activities of AI Watch . To fit t hese considerations into a realistic representation of the Public Sector  environment, the proposed approach is systemic : it take s into account the whole multi -layered and  networked operational scenario, exploring the complex interactions among actors, proc esses,  decisions and behaviours . This approach is necessary for research that goes  beyond the an alysis of some  individual, pilot AI project s.   Section 2  (Definitions and concepts)  introduce s the notion of AI appropriation  as one of the overarching  contribu tions of this technical report to wards  developing an analytical framework of the potential impact of AI.  Appropriation usually comes as the result of two consecutive ( though  often cyclically recurring) and conceptually  distinct phases, which are name d adop tion and implementation  of related technologies2. With some  preliminary  confirmation from the just started  field study work at AI Watch, the existence of a gap is highlighted  between the phase where AI is tested and evaluated for potential use in public se rvice, and the phase where its  injection and adaptation transform s the service (and its provider) more or less permanently. This gap is  noteworthy for two reasons: first , qualitative analysis  of a considerable number of known AI cases has shown  that they successfully completed the phase of adoption but then found a number of unexpected issues right  in the phase of implementation , which led to a total dismantling of the initial technology deployment.  Second , any analytical framework for assessing the impact potential of AI in government would miss a crucial  component if it only focuse s on AI adoption  rather than  also on implementation  through service  transformation and interoperability . In th e latter phase, which some authors also call  technology  “institution alisation” or “instrumentalisation”, the AI component is permanently embedded in the functioning  model  of the public sector organisation . This may ha ve been done in ways that ultimately affect , and are  affected by,  the broader context the organisation belo ngs to : thereby including, but not being limited to,  collaboration with other agencies and bodies and the genera tion of perceived value for public service  beneficiaries . The main research question behind this report is how European public policy can and sh ould  contribute to a higher fraction of AI implementation efforts to go beyond technological and organi sational pilots   developed  in very specific contexts .   Section 3  (Lessons from the US and China)  makes some steps beyond the rhetoric al argument that Euro pe  is falling behind the US and China in a techno -economic  “AI race”, coming to the encouraging conclusion that  under the perspective of AI governance, the EU gap does not seem to be as huge as shown by other metrics,  such as number of companies  or amounts  of investment. Indeed, one of the main conclusions  from th is  comparison with the US and China is the common lack of policy focus on the actual appropriation of AI                                                    2 (McKinsey, 2020b)  defines adoption  as the decision of an economic entity to invest in AI technology – as distinct from the decision to  integrate it into the organizational processes, which is close to our understanding  of AI implementation.   
  6   technologies in the practice of government . Europe might be in a favourable position to counteract earlier and  more extensively . However, t wo main conditions  need to be  met:   — First, unlike  several  eGovernment benchmarking exercises of the past, the demand side  – or the observed  benefits of AI implementation to service beneficiaries, the EU citize ns and businesses – should receive a  similar (if not higher) level of attention than the supply side  of AI. This is to avoid a  mere count of AI  solutions successfully trialled out, but never having become (permanently ) used or still experiencing  problems i n terms of scalability or interoperability .   — Second, a  systemic approach  to facilitating AI in the eGovernment should be adopted ; setting out  an AI  governance  vision  that can be shared by  all EU Member States, but also Regional and ( major) City  government s. Defining a common  strategic direction  will facilitate  reciprocal exchange and continuous  learning from the best available experiences  of AI take -up.   The section conclude s with a slightly different  declination of  the known concept of European “exception alism”,   and by detecting the “weak signs ” of an emerging, truly European model of AI governance . The model  is  rooted in EU intergovernmentalism, acknowledging the peculiarities of the “business of government ”3 and  looking at the infrastructural elements o f AI development and deployment in the public sector, not just as a  collection of preconditions for implementation, but also as targets of a n embryo nic shared agenda for enabling  “governance of AI, with A I”.  Section 4  (Challenges to AI implementation in th e EU public sector)  follows  the above line of reasoning  and raises a number of relevant challenges to the attention of policy makers at EU, national, regional and local  levels, willing to engage in and contribute to the proposed  direction of AI governance :  — The f irst of these challenges is the gener ation of a  critical mass of public investments  in AI, nominally  allowed by the endowments of the upcoming Digital Europe Programme . Two main risks might hamper this  challenge : the dispersion of financial resources  across multiple and heterogeneous projects (possibly also  duplicating similar efforts in different countries) and the inadequate rooting, or embedment, of the newly  developed solutions in the  practice of  EU public administration (p ossibly preventing the p rojects to go  beyond adoption and into implementation ).  — A second  policy challenge is making high quality datasets  available, interoperable, and continuously  updated , maintained  and published , that are required for the training and adaptation of all types of AI  algorithms  (supervised, unsupervised, reinforced)  and more generally for the progress and sharing of  benefits of government digitalisation in all EU countries. In doing so, the risk might be to have “wells of  excelle nce” on case selected based  on the  data underlying AI-enabled solution , surrounded by “deserts of  exclusion”. In other words, the risk might be to qualify the AI solution and select the best ones based on  the quality of underlying data excluding elements li ke the relevance and innovativenes s of the technological  innovation.   — A third has to do with attracting young  tech talents  in public administration and widely improving the  literacy and skills  of existing staff, particularly in the most “peripheral ” public bodies and agencies with  respect t o the ongoing trends. This may sound paradoxical, as the challenge of making innovation happen  by introducing a comparatively complex technology might itself be better suited to attract competent and  smart staff.” But, in fact,  the reverse is also true, th ough probably more difficult to explain: without  adequate digital capabilities available in -house , some governments may not even be able  to replicat e the  most success ful use cases they come to know about by adapting  already  developed AI solutions to their  specific site requirements , since ensuring successful appropriation of AI requires digital skills as well . This  can be particularly unfortunate given the technological and organisational singularity of solution s discussed  before.   — A fourth group of challen ges is associated with the changing concept of legitimacy  for those  governments making more decisive steps towards AI implementation. The design of AI systems may lead  to developers taking political decisions with limited oversight from public managers and  elected officials,  not to mention the citizens or other stakeholders ( “Input legitimacy challenge ”). Especially in delicate or  complex tasks, such as the award of competitions, some controversial decisions taken by opaque                                                    3 In the remainder of this report, we will consistently use the word “business” to make reference, without distinction, to the core activities  of a private or Public Sector organisation. In the latter case, we will also speak of th e “business  of government”, an expression that should  be rather familiar to researchers in public administration: see e.g. the book by Kessler & Kelley (2000)  or the homonymous research centre  by IBM ( http://www.business ofgovernment.org/  ). 
  7   machine  algorithms  in the place o f human beings can be more difficult to justify , and even  lead  to prosecut ion and sanction s for law infringement ( “Throughput legitimacy challenge ”).   — Moreover , and as shown by the field evidence gathered in the context of AI Watch  so far, when moving  from controlled to real life condition s of operation , the use of some AI systems may induce unexpected  and unwanted consequences to the internal equilibria of an organisation or the surrounding  environment , including some external stakeholders, while at the sa me time not significantly  outperforming previous working methods or decision -making  approaches ( “Output legitimacy challenge ”).   — Finally, the diffused implementation of user centric mechanisms  for service transformation, particularly  at the local level, in  line with the eight fundamental principles of the Tallinn Declaration on eGovernment,   is posed as a complementary requirement to achieving a sustained organisational change in the public  body or agency involved in AI implementation.        Section 5  (Policy  implications)  draws some lessons  from the previous discussion  and proposes a set of  common actions for EU decision makers  willing to undertake the systemic approach to AI governance  towards  a more advanced equilibrium between AI promotion and regulation i n the public sector . The EU’s AI strategy has  at its heart the high level objective of b alancing regulation and uptake, through the establishment of  ecosystems of excellence and trust  between parties, hence  the correct balance shall be pursued . The underly ing  idea is that if AI innovation could generate common and shareable assets for many European (at least national  and regional) public bodies and agencies, the formation and development of a new wave of AI start-ups  participating in the GovTech arena would  gain momentum, overcoming the fragmentation of the EU single  market which is more  prominent than in the US and China.  We believe this argument should make an integral  part of our analytical framework for impact assessment of AI implementation and use in t he European public  sector.  Starting from these considerations, three main suggestions or recommendations come to the  forefront4:   — Stronger integration of AI with data policies ;   — Facing the issue of so -called “explainability of AI” ; and   — Broadening the current perspective s of both Pre-Commercial Procurement ( PCP) and Public Procurement of  Innovation ( PPI) at the service of smart AI purchasing  by the EU public administration .   Section 6  (Conclusion and way forward)  summarizes the key  arguments made throughout  the report and  relates them to the upcoming work in AI Watch for the public sector during the year 2021 . In particular , we  highlight the crucial importance of co -design, and therefore user and stakeholder engagement in  public service transformation proces ses, as an alternative way to negotiate the scope and purpose of AI  enabled innovation and therefore achieve reconciliation between ethical values and technology shaping . In this  perspective, our proposed analytical framework for AI impact assessment  – apart from highlight ing the  need to reinforce four feedback loops (design, adoption, implementation and use) that materialise across its  dynamic phases – paves the way for a sound integration of people, alongside algorithms, data and computing  power, in the c ommonly accepted definition of AI : therefore, its implementation may n ever be completely  successful if it is only done “for” the people, but needs to be achieved together  “with” them .                                                     4 These recommendations will be the starting point for a more in depth analysis that will result in a roadmap and an extensive list of  recommendations towards the adoption of AI in the Public Sector. Those results will be part of the next report within the AI Watch.  
  8   1 Backgro und and vis ion  This introductory Section is structured in three parts . The first ( “Research background ”) provides a brief overview  of the global problem tackled, which is to explore the conditions for AI to produce durable transformative effects  in the EU -27 public  sector organisations adopting and implementing it. The  second part (“Policy background ”)  frames this technical report within the scope of the AI Watch for the public sector initiative of the European  Commission and in continuity with its work schedule. The third and final part (“What this report is about”)  introduces the vision behind the proposed analytical framework for assessing  the AI  impact potential in EU  government  - which is to ignite and support a process of systemic learning among public sector experts and  practitioners  - and briefly outlines the con tents of the following five Sections  of this report .  1.1 Research background    AI is a portmanteau word standing for a collection of technologies that mimic or improve the capacities of the  human brain – including perception , reasoning , and action  (Misuraca and van Noordt, 2020) . The term is not  new, as it holds a long history, dating back to the post -WWII period. However, it gained popularity and  widespread diffusion at the turn of the millennium, with the progress in the so -called data economy5 (the real  “fuel” of AI) and the exponential growth of computing power  (the “engine” of AI) allowing the generation and  validation of more and more complex algorithms and the emergence of promising applications in a variety of  business domains.   For its positive impacts on total factor productivity at the firm and industry level, AI is more and more defined  as the General  Purpose Technology of the 21st century  (Bassetti, Borb on Galvez, Del Sorbo, & Pavesi, 2020) .  According to the economic literature  (Jovanovic & Rousseau, 2005) , the three distinctive features of a General   Purpose Technology , which are s hared by e.g. the steam engine at the dawn of the industrial revolution and  electricity at the beginning of the 20th century, are: pervasiveness , meaning that the technology is used in  vast amounts of applications - as, for instance, electricity is used fo r heating and lighting , but also as a fuel for  cars and trains (Korzinov & Savin, 2016) ; fast pace of diffusion , facilitated by its cross -sectoral nature, wit h  various different industries at the same time taking benefit from productivity improvements as well as  influencing technological adoption in other, related industries (Andergassen, Nardini, & Ricottilli, 2016) ; and  finally an innovation -spawning tendency  in terms of new produ cts and services, which unfolds and gains  momentum across time (Cantner & Vannuccini, 2012) .    However, if we borrow part of the definition of emerging technology by Rotolo et al., (2015) , “its most prominent   impact … lies in the future and so in the emergence phase [it] is still somewhat uncertain and ambiguous ”. Such  uncertainty and ambiguity  are magnified by the fact that th e specific AI technologies (not to speak about  custom solutions) are so numerous and diversified  that only by narrowing the focus on each of them it would  be possible to assess their actual time to market (Girasa, 2020) . Said differently, multiple rounds of  experimentation are required before an AI solution is adopted and this may generate issues or delays  in the  materialisation of the expected impacts from its implementation and use.   While the potential of AI is great , it is far from straightforward that this promising technology gets  applied in the public s ector . Current examples of AI used in public services show that there are many different  underlying factors and conditions to ensure the adoption of these technologies, starting from ensuring data  access to develop AI  models up to generating end -user accep tance (Desouza, Dawson, & Chenok, 2020) . AIenabled public sector innovation is however  the result of several concurrent elements, which are  barely technological in essence  (van Noordt & Misuraca, 2020b) . These includ e legal, organisational,  workforce -related , environm ental, ethical  or societal  aspects  that are often overlooked by a perspective  embedded in technology determinism . Public sector organisations must be ready  or, at least , should strive to  strongly advance in all such aspects before they can start developing  or using AI to maximize its potential and  minimize related risks.  Unfortunately, these other requirements are often overlooked , with most  resources going to technological development. This is  not the best choice , as the state of digitalization in the  public sector across the European Union, from the central administration down to the local administrations, still                                                    5 https://eur -lex.europa.eu/content/news/building_EU_data_economy.html   
  9   requires significant progress  in all aspects, and not only technological, in order  to benefit the most from the  potential of AI.   Current trials a nd experiments involving AI in government now and soon are likely to determine to which extent  they are going to drive the digital transformation of Europe’s public administration. In fact, as also highlighted  by recent publications of the JRC, there is st ill very little knowledge about the effects and consequences of the  use of AI technologies within public administration  (Barcevičius et al., 2019; Misuraca and van Noordt, 2020) .  Empirical work is very scarce on how developed AI solutions work in practice and whether they are  obtaining intended results successfully , which is crucial for establishing a common knowledge base  to  share best practices among public administrations across borders. While there have been mentions of  successful pilots with AI in the public sector, it remains challenging for public  bodies to integrate these solutions  into the day -to-day operations of the administration. If this remains difficult, it could be that successful pilots  of AI halt after a time, due to the end of funding, lack of personnel to ensure continu ity or other causes, thus  wasting the opportunity to have a sustainable and positive im pact on the business  of government. The challenge  of overcoming ‘ever -pilots’  or ensuring integration in regular work practices is not new in public sector  innovation, but critical to harness the potential benefit of AI for the time being.   This challenge is not unrelated to the discourse on AI as General Purpose Technology , because  the diffusion of  AI technologies in the public sector can certainly contribute to the modernisation of European public  administration, but also support the emergence of industri al “champions” in this key technological  domain , potentially able to play the role of pan -European service providers.   In fact, compared with the US and China, the value of the European market for GovTech solutions – which AI  empowered government applicatio ns are part of – is only a small fraction according to available estimates  However investments are expected to grow in the next years.   Before the Covid19 crisis, a study from the Polish Economic Institute  report s that the European expenditures  on  new techn ologies for public administration are in the range of €22 billion per year, about 6% of global demand ,  though expected to treble until 20256.   Moreover, a recent  publication by the JRC (Dalla Benetta, Maciej, & Nepelski, 2021)  report s that the  AI  investments for the  European  public sector account for 41% of total AI investments in 2019. This includes  outlays on AI education as well as the adoption of AI technologies by the public sector.  Compared to 2018, in  2019 AI investments in the EU grew by approx imately  €2.1-2.5 billion  (39%). If growth will remain constant , by  2025 the AI investments will reach €22.4 billion . Hence it will  surpass  the target, set at € 20 billion .  On the supply side, a very similar proportion was found in global GovTech deals (only 7% compared with 85%  in the US) according to the Founders Intelligence think tank7. It is quite likely that this situation has remained  unchanged during  the pandemic, also in light of the low propensity to spend on ICT R&D of the EU public sector,  which will be supported with ev idence  in Section 4 of this report.   1.2 Policy background    To gain better visibility of the above issues, in December 2018 the European Commission launched a dedicated  initiative  denominated “AI Watch ”. The initiative is  a monitorin g tool of the progress and achievements of the  Coordinated Plan on the Development and Use of AI “Made in Europe”  (European Commission, 2018a, 2018b,  2021b) . A specific activity within AI Watch deals with AI in the public sector  and, i n a recently published study   (Misuraca and van Noordt, 2020) , presented the results of a first exploratory mapping of the use of AI in EU  national, regional, and local government bodies and agencies. An inventory of 230 (and counting) interesting  cases of AI adoption was built, covering all 27 EU Member States, as well as Norway, Switzerland, and the UK.  Also, a narrow focus was set on eight i llustrative examples, highlighting the problems and perils of AI  implementation. In particular, the findings from case histories revealed that the ethical, societal and  organisational/HR implications of AI use  in government  should be a matter of high conce rn for  prospective adopters, notably because of the difficulty of predicting impacts in full when relevant decisions are  taken. Another important piece of evidence was that not only the technologies but also their uses were                                                    6 Source: https://polandin.com/42532388/govtech -market -in-europe -to-treble -by-2025 -polish -think-tank  7 Source: https://medium.com/founders -intelligence/govtech -is-europe -missing -out-again -7815251e4617   
  10   rather diverse  and the respectiv e maturity levels quite heterogeneous . This  result prevented the  authors from drawing too general conclusions in terms of usefulness, sustainability, and cost -benefit  comparison. Finally, the geographical spread and thematic s cope  of reported  cases were often wide , but  also unevenly distributed across Member States, government  functions8, and tiers of public administration . This  was probab ly due to the use of secondary sources, of heterogeneous nature, for data collection, which hindered  comparability  to a great extent .  Additionally, the collection also included several proofs of concept and temporary experimental trials ,  not only permanent embeddings in the realm of public service (or policy), showing the importance of keeping  up the distinction between “adoption ” and “implementation ” of AI . Moreover, a  few specific cases, mentioned as  running at the time of first gathering, were later found to have been discontinued because of various  reasons , including significant criticism received from the general public , pressure from adversarial political  forces or even executive orders from local courts of criminal justice.   Further , the AI Watch for the public sector study included a “deep dive” into eight detailed case histories ,  which confirmed that the ethical, priv acy and social responsibility related concerns associated with the concept  of “trustworthy AI ”, as first introduced by the High Level Expert Group on AI (HLEG) appointed by the European  Commission9 were fully grounded.   Even if  the evidence obtained in the study was an early exploration  of the underlying (still largely  unknown) universe of EU public sector organisations , the study proposed a taxonomy based on 10 “AI  typologies” , not with the ambition of systematizing a fast-evolving domain, but  with the more  practical  intention of mapping the potential uses of this technology, as detected from the inside of the application cases.   Despite all the mentioned limitations, a number of findings are noteworthy from that study, which constitute s  a sort of starting po int for this follow -up publication. These include:   — A hands -on demonstration of the increasing importance gained by  AI in the EU -27 public sector10,  both in support of existing processes and services – with an eye on efficiency, effectiveness and quality –  and of their digital transformation into radically new ones;   — The experimental nature of many , potentially highly impactful, but still waiting to be validated or  finalised, thematic applications ;  — The huge  diversity of used technologies and related solutions , still in search of a critical mass for  permanent establishment at government site and of a credible scalability pathway for EU - (or national -)  wide diffusion or replication11;  — Widespread  awareness of the role of public policy  to promote and facilitate, but  also regulate and  manage AI implementation in the practice  of government, as witnessed by the concurrent emergence of  national strategies – though at different speeds – in almost all EU Member States ; and  — The need was highlighted to develop a socio -econom ic impact assessment framework , looking  beneath the surface of the supposedly unequivocal benefits of AI take -up in government.   1.3 What this report is about    In continuity with this work schedule, this publication aims to develop an analytical framework of th e  impact potential of AI in government . It does so by elaborating further reflections on available evidence –                                                    8 These were defined according to the COFOG functional classification of government originally developed by the OECD in 1999 an d  published by the United Nations, see: https://unstats.un.org/unsd/classifications/Family/Detail/4 , which is well established in statistical  research and practice. However, it should be borne in mind that such a “b usiness oriented” definition of activities of public relevance leaves  room for the inclusion (although only in few cases, such as in healthcare) of a number of entities that are not actually gove rned by public  law.   9 https://ec.europa.eu/digital -single -market/en/high -level-expert -group -artificial -intelligence   10 The analysis and database of cases also included evidence from non -EU countries such as Norway, Switzerland and the UK.   11 With all possible caveats related to the sampling mechanism, a relative prevalence was spotted in the observed cases of the f ollowing  AI applications: Chatbots, Intelligent Digital Assistants, Virtual Agents and Recommenda tion Systems – followed at some distance by  Predictive Analytics, Simulation and Data Visualisation.  
  11   also from third parties – as well as other noteworthy elements of the previous AI Watch for the public sector  study. The latter also included a su rvey of national AI strategies and the inputs gathered from EU Member  States at a first Peer Learning Workshop held in February 202012, which was followed by a second edition in  September 2020, the results of which are separately reported by another JRC pub lication (van Noordt and  Pignatelli, 2020)13 and are taken into account as inputs for the reasoning attempted here.   Our starting assumption, better elaborated in Section 2 of this report,  but still lacking firm empirical evidence  in support,  is that a successful appropriation of AI brings with it a higher level of complexity than  “conventional” ICT . Said differently, the chances that (other things being equal) a private or e ven public sector  organisation may plan and execute successfully and in a given time all the steps belonging to the adoption and  implementation process are lower in the case of AI than ICT, with a greater likelihood of interrupting, stopping  of reiterating  some step.   In particular, for public administrations, the following key analytical, but also very pragmatic questions arise:  what kind of evidence is available about the successful implementation of AI in public administrations?  Which   are the  immediate re sults and longer -term outcomes/impacts? How long did it take to materialise that evidence?  How many resources (financial, human, etc.) has been used?  To fit this analysis into a realistic representation  of the surrounding environment, the proposed approach  is systemic : that is, it recognises that in order to  understand the dynamics and potential impact of AI in such an important part of society as government, it will  be necessary to go beyond the study of individual pilot site results and look at the broade r interaction of actors,  processes and decisions/behaviours as they occur in a multi -layered and networked operational scenario.   Learning must be systemic, because of the complexity of the European policy scenario, far higher than the  corresponding US and Chinese systems  analysed in Section 3 , but also because of the need of singling out and  widely sharing the most successful experiences of AI appropriation, in order to make them replicable and  scalable in other EU public administration contexts.   To grasp these opportunities in full, the thesis of this report is that  the sustainable implementation of AI  in public services  is a key element  for the uptake of A I in public services . In order to reach this  sustainable use of AI, specific attention should be devo ted to the appropriation  process , defined in  the report as the sum of adoption and implementation . As the first step in that direction , Section 4  proposes a reasoned list of the crucial challenges  that the EU public sector is fa cing at all levels on the  way towards a diffused adoption and implementation of AI in its daily practice .   Section 5 – the last before the conclusions  – proposes a set of common actions for EU decision -makers willing  to undertake the systemic approach to A I governance towards a more advanced position  between AI promotion  and regulation in the public sector. Such a position is primarily suited at the level of coordination between the  European Commission and the Member States.    The concluding Section 6 summa rizes the key arguments made throughout the report and relates them to the  upcoming work in AI Watch during the year 2021 . It also presents the first version of the analytical framework  for AI impact assessment in the public sector, which is associated with a number of testable implications for  future field work, both with in AI Watch and outside it .   In the coming months and years, adequate finance will be mobilised to support the experimental deployment  of AI solutions in the EU public sector. This is enco uraging, however, it remains of tantamount importance that  these resources are finalised to a human -centric reshaping of government practice in Europe and that the  introduction of AI enabled components in processes and services  becomes pervasive at all adm inistration levels ,  including across the country borders.                                                     12 https://knowledge4policy.e c.europa.eu/ai -watch/ai -watch -peer-learning -workshop -ai-use-impact -public -services_en    13 For a full overview of the current  situation at EU level the reader can consult the following URL: https://knowledge4policy.ec.europa.eu/ai watch/national -strategies -artificial -intelligence_en   
  12   2 Definitions  and concepts   This Section gathers most of the concepts acting as theoretical foundations  of the proposed analytical  framework of AI impact assessment in government.  In particular, three main messages are delivere d to  the attention of EU experts and practitioners , to start  materialising the “systemic way ” of policy -oriented  learning introduced in the first Section of this report:   — The a nalysis and evaluation of the impact potential of AI in  government should not stop at the phase of  adoption , but continue up to  includ ing the outputs and outcomes of the implementation phase . These two  phases jointly constitute what we  name  technology appropriation in general, and AI appropriation  specifically . See the following  paragraph 2.1 for more details ;   — For the success of AI appropriation , “context matters”, in all its aspects, which are not necessarily only  technical (e.g. they may be also legal, societal, or organisational)  and add to  the requirements of  the  expected users of the newly introduced solutions. See paragraph 2.2 for an in-depth  discussion ;  — While evidence is being gathered from individual AI case studies in terms of benefits and drawba cks, a  systemic learning approach should be followed, enabling public policy, at EU and Member State levels,  without forgetting the Regional and (at least the major) City governments14, to build the conditions for AI   take-up trials to be truly transformativ e for the public sector, leaving the status of technological and  organisational singularities . How to achieve this goal  is presented in the final paragraph 2.3 of this Section .  2.1 From adoption to implementation: the process of AI technology appropriation   Technology  is broadly considered as a social construct , resulting from the convergence of the needs,  tensions, ideas and actions (even contradictory sometimes) of human beings and social groups (Pinch & Bijker,  1984) . However, technology is also known to shape the course of societal life , if not determining it, for the  various aspects it touches and affects, which may well include cultural practices and interpersonal relations –  as the examples of personal computing (Robinson, Barth, & Kohut, 1997) , mobile phones (Ling, 2010)  and social  media networks (Simplilearn, 2016)  convincingly demonstrate. These two opposite perspectives used to be  contrasting each other, however , in the past few decades  they have evolved into a unitary vision that speaks in  terms of co-construction of technology and society  (Feenberg, 2010) .  Government  – meant as a group of people with the authority to rule a community , depending on whether  professionally or politically engaged  – is also part of society. It can exercise power in various ways,  as outlined  above.  Because of its larg e purchasing power ( public procurement accounts for almost 25% of GDP  in Europe),   government can pull innovation to market  and it can also be a prime mover, or a leader when it comes to  technology change . In doing so,  the fundamental act igniting the process is a public purchase, realised according  to the rules of public procurement : “of innovation”, if the case applies, or traditio nal procurement .   Put this way – i.e. with government seen as an integral part of societ y, and having the possibility of initiating or  supporting the adoption and diffusion processes (Rogers, 2010)  of novel technologies, particularly those with  the stamina of positive and widespread impacts on the population – the vision of technology and society being  reciprocally co -constructed gains two more analytical dimensions . On the one hand, g overnment uncovers an  additional policy instrument promptly available, that is public procurement, which can be used to accelerate or  redirect technological change in the local or global environments; for example, towards sustainability (United  Nations, 2017) . On the other hand, by introducing more and more technologies in its own area of operation,  government inevitably transforms itself and the way it delivers value to other societal actors – such as citizens  and businesses, but also the policy makers and civil servants who work within it15.   The th eory (and practice) of technology adoption in government  has a long history and plenty of evidence  is now available, including controversial endeavours and unachieved goals. Quite interestingly, Vedung’s original  discourse on policy instruments was motivat ed by a perceived lack of understanding  – more than twenty years                                                    14 In facts, s everal regions have their own AI strategy and some  cities are in the forefront with respect to AI adoptio n. See for example the  DT4REGIONS projec t: https://openlivinglabdays.com/enacting -digital -transformation/     15 A specific field of research and practice is digital transformation  of government (Hinings, Gegenhuber, & Greenwood, 2018) , which has  gained prominence  in the recent academic debate. However, we prefer using the more generic concept of technology adoption and  implementation, to align better with some of our reference sources (Jennie Carroll and Andrew Feenberg, above all) and also t o include  non-digital technologies (Barley, 1986; Delaney, Timbrell, & Chan, 2008)  in the picture we are trying to draft herein.  
  13   ago – on the tools that could be used by public decision -makers willing to interfere with the course of societal   actions  (Vedung, 1998) . Usually , such interference is referred to as governance  (Hufty, 2011) : a topic widely  studied, and practised, over the past decades, in all its possible articulations (actors, stakeholde rs, territories,  goals, needs, processes, even supportive technologies) . There is  one major exception: the problems and perils  of technology  implementation . Technology implementation  comes right after the adoption phase and  describes the transformative imp acts of the permanence of that technology in the body of the organisation .  Keeping adoption and implementation conceptually distinct brings advantages16. The most important is  to  highlight the existence of a gap that is connatural to any process of technolo gy appropriation17. This gap   separates the phase where innovation is tested and evaluated for potential use from the phase where the  underlying, technology enhanced product or service process is permanently affected and transformed into  something different than what it used to look like before.   Figure 1. Technology appropriation disentangled.     Source: JRC, own  elaboration .  The existence of this gap, which is made evident in Figure 1 by the frac ture between the two halves of the  rectangle, is even more clear if we read the (exemplary) list of tasks belonging to each of the two phases. There  is little overlap if any at all. However, the most important thing is that the global process of appropriat ion  may well become cyclical  – that is, with its two phases of adoption and implementation alternating and  repeating across time, in the framework of the same business application. This is because there is no guarantee  that even a successful ending of a te chnology trial – particularly in, but not limited to, public sector organisations  – will immediately and almost automatically yield the embedment of the corresponding technology, as it was  trialled, in the daily operation of that organisation.    Echoes of this distinction between adoption and implementation can also be retrieved in the organisational  literature stream initiated by James March (1991)  when describing the fundamental tension – determined by  the scarcity of  available resources – between exploration  “captured by terms such as search, variation, risk  taking, experimentation, play, flexibility, discovery, innovation ” and exploitation , “including such things as   refinement, choice, production, efficiency, selecti on, implementation, execution ”.                                                    16 Similar to the ones introduced by the taxonomy propos ed by (Vedung, 1998) .  17 By this term, we roughly point at the union of adoption and implementation, also bearing in mind that individual and group us ers of a  certain technology after it is embedded in an organisational setup make changes to both the technology and the environm ent, which  inevitably feed back into both steps of the singled -out process (Barley, 1986; Carroll, 2004) .  
  14   Whatever direction the organisation takes is unsatisfactory: exploration without exploitation may look like an  unjustified investment of time and efforts in knowledge development or acquisition, while exploitation without  exploration brings with it a number of risks related to a superficial appraisal of the convenience of that specific  knowledge appropriation for the good functioning and long -term survival of the organisation18. The suggestion  from Levinthal & March (1993)  is therefore to find a proper balan ce between the two, a goal that is however  far more easily stated than achieved.   Two major modes of balancing out have been highlighted in the literature, both termed ambidexterity  to  signify the capacity of an organisation, including a government body or agency (Choi & Chandler, 2015) , to play  on both fronts successfully. In particular, structural ambidexterity  occurs when a  private or public  entity   manages to create distinct subunits or working teams, each specialising in  either exploration or exploitation  activities (Gupta, Smith, & Shalley, 2006) . We could think of something comparable in those public sector  organisations having distinct offices for – say – IT support or procurement and service operations . On the other  hand, sequential ambidexterity  takes p lace when organisations alternate exploration with exploitation  phases across time (Tushman & O’Reilly, 1996) . This brings us back to the cyclical nature of technology  appropriation outlined in Figure 1 above.   Reflecting on the conceptual distinction and actual gap between adoption and implementation is vital when it  comes to new and innovative technologies – such as AI, the main subject of this report .  In fact, innovative  technologies have the potential to bear huge transfo rmative  implications, even though those implications  remain largely unknown , due to conceptual confusion between the two phases and the presence of few,  anecdotal information available on the implementation  phase .   Unfortunately, and as witnessed by anothe r JRC Technical Report (Bruno, Schiavone Panni, Marchetti, Molinari,  & Valente Covino, 2020)  analysing more than 150 pilot experiments of  public service digitalisation: “ The  propensity of pilot owners to share results and lessons learned in a structured manner is q uite limited and this  adds noise to the evaluation of scalability potentials, not to mention the difficulty of defining reliable reuse or  transfer pathways involving other public sector organisations than those in the original pilots. This lack of  informat ion is particularly undesired in case of new and emerging technologies, such as blockchain or Artificial  Intelligence, which naturally lend themselves to being trialled in very similar – yet never too much – pilot  contexts, thus increasing the risk of ‘rei nventing the wheel’ – i.e. of duplication, if not proliferation, of limited  size experiments ”.  In fact, even the analysis done within AI Watch over a meaningful number of AI cases  known  has shown  that  many projects  successfully completed the adoption phase  before finding  some unexpected , yet critical , issues .  This happened often in the phase of implementation  and it led to a  partial or  total dismantling of the initial  technology deployment . Typical issues were legal issues, biased recommendations , staff res istance and some  others . The reasons for such a  failure are certainly manifold, depending on  the case specificities , but they can  probably be reconnected to the observed gap between the first and the second phase of technology  appropriat ion.   Indeed, payin g utmost attention to adoption  is well justified by the predominantly experimental nature of  current AI solutions , which are hardly consolidated in standard product s or service s that can be purchased  off-the-shelf  and installed without further elaboration  and adaptation . However , the need for experimentation,  in our opinion, should also include  the way public administration and its external environment are  transform ed  after the implementation of AI, as well as  the immediate and deferred ( mostly non-technolo gical) consequences  of that transformation .  As a matter of fact, the complexities and peculiarities of public service  requirements at all levels – local,  regional, national – are so binding that each success story can be described  with a complex appropriat ion  process that goes far beyond a mere transfer of an AI solution already operational in the private sector. Although  we are still missing supporting evidence, we hypothesize that the level of direct engagement of public buyers  with private suppliers in t he co -design, experimentation and refinement of AI prototypes was comparatively  higher than the hypothetical benchmark of installing an IT solution already available off -the-shelf.  On many  occasions, the “power” of AI was not leveraged with a full -blown so lution, but through the more nuanced and                                                    18 An appraisal which usually consists in extrapolating from explorations undertaken elsewhere (in the case of public administra tion this is  often the private sector).  
  15   subtle insertion of AI technology elements  – such as the capacity to analyse data, to propose answers, or  to interact with human beings – into a specific stage of the service delivery process. A considerable number of  cases allegedly never went beyond the trial or piloting phase. In a few instances, the decision to “go live” was  reverted because of unexpected complications or negative impacts on society, human rights etc. This makes  a “plug and play” AI solution difficult to be  successfully implemented in a government context : the  best way to ensure success  is the realisation of several rounds of multidisciplinary testing, refinement and  validation prior to final technology embedment.    2.2 Putting AI innovation in context : the proposed analytical framework   Figure 2 is an idealistic representation of the scope of the evaluation . Given a certain collection of technologies,  for instance , those globally termed “AI technology families ” in the collection  on the left-hand  side; their  appropriation inside an organisation usually starts with the creation of a subset of potentially suitable  technologies .  Figure 2. The proposed analytical framework .     Source: JRC, own  elaboration .  How technology choice is executed depends on several factors, the influence of which is highlighted by the use  of arrows.   We know that the previous study (Misuraca and van Noordt, 2020)  clustered AI technologies according to three   main research and application strands , name ly Perception, Reasoning and Action . “Perception stands for the  capacity of an intelligent machine, be it a pie ce of software or a robot, to understand (give meaning to) the  signals coming from the external world - such as images, either still or in motion, and sound, e.g. music or  speech. (…) Reasoning is … the goal to replicate/improve a human being’s capacity to  analyse and draw  inferences from the data and information received from the external world . (…) Action [points at] a wide variety  of application domains … both in software industry … and in hardware manufacturing ”.   The technology chosen is expected to be  a combination of technologies belonging to one or more strands that  are suitable for the purpose . Hence, k nowing wh ich strand should be selected is the first move towards the  choice .    The choice is expected to be subsequent  to an analysis of user require ments  (the elaborated needs of people  inside and outside the organisation, who are going to be affected by or engaged in the future use of the AI  
  16   solution) :. It is extremely important to scrutinize the needs  of the users  to see where the automation of  perception, reasoning or action (or a combination of the three) are desirable .  Finally, this exercise does not happen in a vacuum, but is or can be influenced by a number of  contextual  factors , i.e. crucial aspects of a public sector organisation’s operational  environment other than the specific  needs and requirements that the chosen technology promises to fulfil. Contextual factors may include  for  instance : the nature of the service or process at hand, peer pressure from other organisations or a specific  endor sement  of technology change from key stakeholder groups. The following table provides a tentative list  of such influential factors , the relevance of which is now being empirically assessed through direct interviews  with AI Watch for public sector case owne rs.  Table 1. Tentative  list of contextual factors .  CATEGORY  EXAMPLES   POLITICAL  FACTORS  Elected officials  endorsing the experimentation of that technology and/or its embedment in the  administrative or policy processes   ORGANISATION AL  FACTORS  Support by the top and/or middle management and/or the frontline staff involved in the technology  trial and/or the permanent implementation of its results  inside the organisational structures   INFRASTRUCTURAL  FACTORS  Availability of supporting d atasets or IT equipment within the organisation adopting or  implementing that technology innovation   DEMAND RELATED  FACTORS  Needs expressed by third parties, i.e. other public organisations and/or their users interacting with  the one engaged in technology acquisition    TECHNICAL  FACTORS  Response  to user needs offered by that technology  and complementarity /interoperability  with other  IT solutions already in place  of the same or similar kind   SUPPLY RELATED  FACTORS  Integration of an external IT partner with functional  expertise or specific  capacity of the IT staff  internal to the organisation   FINANCIAL  FACTORS  Availability of adequate, “ad hoc ” funding to the project  and/or the embedment of its results in the  current business practice   LEGAL FACTORS  A clear f ramework incentivising technology innovation , early re solution of data privacy and/or  security aspects, other  legal or regulatory requirements   ETHICAL FACTORS  Expected/actual  and especially unwanted consequences of technology implementation to people,  social groups, the environment etc.   DOMAIN FACTORS  In addition to the factors listed above, there could be  various other factors, more fragmented and  partially overlapping , which are dependent on the specific application domain (e.g. Health) and also  on the specific geographic location (e.g. cultural  factors )  Source: JRC, own elaboration.   During the adoption phase (see Figure 1) both the user requirements and (some or all of ) the aforementioned   contextual factors oper ate, and to a great  extent interoperate  with each other , along the familiar sequence of  steps normally associated with new technology experimentation:  solution design, technical development, testing  and val idation. These  steps  are visualised by  a set of sm all vertical rectangles, of diminishing height because  of the “narrowing down” process that usually starts from an initial range of options or alternative designs and  prototypes to reach the final  status of tested  and validated  technology  deploy ment .  Howev er, experience shows that any adopted technology  rarely survives as such to the phase of  implementation , as defined in the previous  paragraph 2.1 – i.e. a situation that is no longer experimental, but  close to permanent take -up of the newly developed solution  in real use contexts . In fact, it is quite  likely tha t  during and because of usage, aspects related to human behaviour come to the surface, which were not planned  by the developers  (Bagozzi, 2007; Bailey & Barley, 2019) . More generally, and as shown in the right part of the  above p icture , the first use of a technology solution  inevitably leads to check its actual performance against 
  17   the user requirements and the contextual factors considered as most influential on its choice and initial  configuration. This  may lead to a variety of a lternative outcomes, including dismissal (Option 1),  confirmation without revisions  (Option 2), or a reiteration  of the design -development -testing -validation   process , to achieve a different type of custom solution  (Option 3).   This variety of outcomes is mi rrored by the evidence gathered in the AI Watch cases mentioned in  (Misuraca  and van Noordt, 2020)  and probably also reflects the field expe riences of most readers of this report. For the  purposes of this report, which are related to the delivery of an analytical framework for assessing the impact  potential of AI in government – indeed, one of the main expected outputs of the AI Watch  for the public sector  activity as a whole – the discussion  should highlight three important implicatio ns:  1. The f irst use of an AI solution is c rucial  to refine or perfect its initial deployment . Probably more so  because of the highly experimental nature of AI and t he absence of suitable “plug and play” applications  not need ing further customisation . However, it is not easy to achieve first use  in controlled  conditions  within real or realistic public sector environments , and this may be an obstacle for a more  diffuse d take -up of AI in government ;  1. Relevant user requirements , for shaping AI adoption , should not only reflect citizen and business needs  in terms of service transformation but also extensively include governmental actors , from civil servants  using the newly introduced solution  in their daily work  to managers responsible for service delivery  and  held accountable for its quality, transparency, etc.;   2. Alongside requirements , contextual factors are also very important . These are not only technical or  infrastructur al but legal, societal, organisational , ethical  etc. Roles and accountability have to be assigned  and defined appropriately.  A tentative list is provided in Table 1 above and their consideration as potential  drivers or barriers should accompany both phase s of the AI appropriation process, i.e. not only adoption  (or exploration) but also implementation (or exploitation).   When looking at context systematically, however, the first allowance to be made is its uncontrolled variability  across time. This means th at the same contextual factors may change, or act differently in relation to the same  AI appropriation process , including because they are influenced by the appropriation process itself .  For example, in a related study , De Nigris et al., 2020  described the connection between AI take -up and Covid19  in terms that can be paraphrased as follows: in many EU countries, the curve of newly adopted AI solutions in  healthcare has become almost as exponential as the contagion curve itself. Despite the absence of systematic  field evidence, we can speculate that the unusual pressure (both in terms of time and scope) from the external  and unforeseen circumstances related to the pandemic  among other effects  has forced many national  authorities in charge of public health care to take a fresh look at the datasets they were already in possession  of, as well as increasing th e amount of funding available and allowed for more risk taking . For sure, the huge  amount of potentially useful (if not vital) but till then unexploited information demanded a totally new approach  to data handling and sharing, which was to be made compatib le with the changing user requirements, as forced  by the emergency situation.   Put in this way, fighting  the data overload issue and increasing the  quality of  intelligence  may have been  the two  most relevant needs fulfilled by choosing AI as a technological  solution . Nevertheless,  there is more:  proceeding from adoption to implementation, healthcare users may have started to  create  new datasets or trial  new uses of data that weren’t considered relevant in the former, indubitably quieter  and more predictable,   scenario.  On the one hand, this new data may have acted as a solid justification for continuing the use of that  solution. On the other hand, it would require a  supplement of reflection on the compliance with all the contextual  aspect s (above all ethical a nd legal factors).   Whether  that could be the start of one of those  massive imitation and emulation processes that are well known  in the organisational learning literature (DiMaggio & Powell, 1983)  through which innovation becomes  widespread in the public sector it is too early to say. What can be anticipated is that its materialisation woul d  most likely need a supplement of result analysis, strategic planning and maybe concerted action among the EU  and Member States.   Also, in light of this example , however,  it seems  indispensable to include the implementation phase – which  other authors cal l technology “ institutionalisation ” or “instrumentalisation ” – into the scope of AI impact  evaluation. During that phase, the use of an algorithm or any other developed component becomes permanently 
  18   embedded in the functioning model of the public sector or ganisation, in ways that ultimately affect, and are  affected by, the broad er context the organisation belongs to . This can also include interoperability with existing  datasets and services, creation of new AI -enables services, and  collaboration with other agencies and bodies in  the generation  of perceived value for public service beneficiaries.   2.3 What can we learn? Towards a systemic view of AI appropriation in the public  sector   The broadened analytical perspective proposed in this Section has two major imp lications in terms of the  evaluation approach . The first  is to transcend the consideration of AI as a technological singularity , i.e.  something that came out of the blue and the organisational or societal impacts of which cannot be controlled  for (Vinge, 1993) . The second  is to overcome the specular  appraisal of AI as an organisational or service  singul arity, based on the assumption that success (or failure) , of a certain AI technology appropriation , is  irredeemably related to the specific conditions framing that process, and those conditions are unique and will  never be  replicable in different locations . Overcoming this aspect  means  going beyond the narrative  of a single ,  unique  case (Schon, 1983) , looking at  “what works for whom  and in what circumstances ” (Tilley, 2000) . This  implies starting  the analysis and evaluation of a case with the goal to describe and generalise  the changes  that occur in a public sector organisation – and in the broader context , it belongs to – as a result  of AI appropriation . Mapping these changes ca n help qualify the anecdotal  evidence extracted from the cases  analysed by the AI Watch for the public sector activity  so far , in terms of lessons learned and suggestions for  improvement, scalability potential or avoidance of duplicate efforts . Positioned as they are at the stage of  implementation, rather than adoption, of AI  technology  in government, the  cases mapped deep dive into the  “black box” of public service redesign, reengineering, and restructuring – in one word, innovation. And any  innovation is either pervasive, or ubiquitous, outside and inside an organisation, or cannot even be named as  such (Bachman & Bozzone, 201 1). This report goes exactly in this direction, and more research is still to come  within the AI Watch.   Of course, some of the changes brought about may be negative, rather than positive. Just a  mention  of the  known challenges, and often barriers and con straints, related to ICT (not only AI) take-up in government is  enough to show that the devil is really  in the details. Nevertheless,  the learning aspect may concern which new   regulatory initiatives or investment programmes are most appropriate to enhance the positive and  reduce the negative consequences of transform ing the business practice of the public bodies or agencies  involved .  However, at this stage , the information  already available from previous studies is too qualitative and anecdotal   and it is ma inly looking at specific case studies . Therefore , in the remainder of this report , we will  focus on  what public policy  should  learn  from th e available  collection of cases (including failure stories) in such a  way to make learning as systemic as the nature of the cases themselves  seems to suggest.   In his seminal article, Evert Vedung (1998)  introduced a popular taxonomy of policy instruments, suggesting  that research on their functioning, effectiveness and impacts was still in its infancy at the time:   — Regulation  (“Sticks ”), which obliges people and organisations to a certain proactive behaviour against the  threat of a penalty or punishment;   — Incentives  (“Carrots ”), mostly of economic or financial nature, although subsequent evidence has  suggested that ot her influential ‘nudges’ should be considered, such as reputation and confidence/trust  (Reisch et al., 2017);   — Persuasion  (“Sermons ”), the defining property of which is the use of rational arguments to motivate certain  patterns of behavioural change.   Accor ding to Vedung, but also common sense, the “ degree of constraint intended by the policymakers ” declines  from “Sticks” to “Carrots” and from “Nudges” to “Sermons”. This leaves the issue partly unattended of which  degrees of freedom  societal actors are left with (or keep for themselves) by each instrument ; including in, but  not limited to, the exercise of innovation and use of technology in real life application domains.  However, the  role government can play is much broader, particularly in relation to diffus ing digitalisation processes, which 
  19   have influence not only on the technolog ical change  but also on the very evolution of societ y (of which, public  sector transformation is a part).    Analysing the possible roles the  Public Sector can play in the diffusion of AI, we can borrow from a taxonomy   Borrás and Edler (2020)  have suggested for the area of Smart Cities . In fact, research on smart cities is closely  related to research on AI, above all because  local government is one of  the greatest producers of big data –  the fuel of the AI engine – worldwide  (Allam & Dhunny, 2019) . Six of the 13 roles identified by Borrás and Edle r  (2020)  are directly pertinent to an AI implementation  process :  — Facilitator  of some change dynamics autonomously initiated by the private sector  (European Commission,  2011) ;  — Lead user and co -designer of particular  solutions to public needs , technology supported ;  — Direct initiator of p rojects  for the transformation of the targeted (governed) community/constituency;   — Promoter of third -party  solutions that need to be experimented in a real or realistic environment;   — Enabler of societal engagement , thus encouraging the participation of activ e stakeholders in defining  the direction of change; and   — Gatekeeper , thus regulating access and fruition of public spaces , resting under its ownership , by other  involved actors.   The existence o f these roles acknowledge s the existence of a broad network of a ctors that revolve around AI  implementation. This network include s both governmental and non -governmental actors. The latter  deserve  specific attention. In fact , those are actors external to the governmental body but  their collective and individual  behavio urs contribute to the achievement of the desired (or unexpected) outputs and outcomes. This element  is often highl ighted  in the various cases of AI appropriation.   This is one of the possible meanings that can be attributed to the distinction introduced by  the previous study   (Misuraca and van Noordt, 2020)  between “ governing with AI ” and “ governing AI ”. In fact,  these are not two  separate and d istinct policy lines, but simply two sides of the same coin, with the important, additional element  constituted by the  already highlighted importance of the  context in which operations  are taking place, described  and generat ing their implications.   This vi sion is not new and has recently gained even more visibility and momentum. Two examples may suffice  to demonstrate this .  First, the OECD Observatory of Public Sector Innovation, after reviewing national AI strategies, concluded that  the most robust (and th erefore useful) ones are those holistic and systems focused  – i.e. that “ encompass  all the various level of government and are attuned to structures and systems within the public sector that AI  can influence or are trialled within.  They are also considerat e of the interactions of other sectors and  stakeholders ” (Santos & Héang, 2019) .   Second , in a recent JRC Technical Report on Projecting Opportunities for I Ndustrial Transitions (POINT), AI is  considered an industrial theme of growing global importance  for the EU Regions and Member States  engaged in re fining or extending the priorities of the respective Smart Specialisation Strategies (S3), in  preparation for the next multi -annual financing period of the Structural Funds 2021 -2027. In accordance with  criterion No. 6 of the enabling condition of Good Gov ernance, appropriate actions to manage the industrial  transition  are those “ that harness cross -portfolio complementarities (e.g. between ministries and between  levels of governance) and cross -stakeholder coordination (e.g. between businesses and broad cons tituencies of  consumers/users) ” (Pontikakis et al., 2020) .   Already in 2018, however, the EU as a whole , rather than individual countries or regions, was identified as  the ideal dimension for coordination of AI adoption and implementation policies , especially  in, though  not limited to, the public sector. This is one of the key commitments of the Declaration of Cooperation on  Artificial Intelligence19, signed by all Member States, which also embraced the sharing of best practice examples                                                    19 https://ec.europa.eu/digital -single -market/en/news/eu -member -states -sign-cooperate -artificial -intelligence   
  20   in procuring and using A I in government, as well as in open data development and deployment. The connection  between AI, Open Data and public sector digitalisation  is also documented in the White Paper on Artificial  Intelligence20 and the European Data Strategy21 – both issued on th e same day in February 2020 by the new  Von der Leyen Commission.   As usual, a strategic direction is the first element of any viable policy. Now it certainly is  the case that at a high  political level the directio n is very clear: quoting the White Paper on Artificial Intelligence – A European  approach to excellence and trust  (European Commission, 2020d) , “the Commission is committed to enabling  scientific breakthrough, to preserving the E U’s technological leadership and to ensuring that new technologies  are at the service of all Europeans – improving their lives while respecting their rights ”. This directi on is also  widely shared among the EU Member States, all of whom – including Norway, Switzerland and UK – are among  the signatories of the Declaration of Cooperation on AI adopted on 10th April 2018 and reconfirmed with very  few deviations within the National AI Strategies as also indicated by the Coordinated Plan on AI (European  Commission, 2018b)  and its recent review (European Commission, 2021a) .  When it comes to AI in government, however, the picture becomes fuzzier. As  Misuraca and van Noordt (2020)   pointed out in their overview of state of the art, a “ sermon based ” approach seem to prevail in those EU countries  that are taking action to stimulate the use of AI in public policies and services. Soft po licy instruments abound,  such as awareness raising campaigns, calls to improve data quality, and employee training initiatives. However ,  and with some  exceptions, their inspiration does not seem to go beyond considering public administration’s role  as inst rumental to (and maybe peripheral in) achieving the European goal of value laden and ethically  responsible AI development and deployment.   As a matter of fact, public administration is not identical to any other potential (corporate) adopter  of AI  that is already active in th is market. Hence AI appropriation should not be pursued, however, by the  mechanical transposition of technologies that worked well (or at least seemed to work well ) in the private sector ,  despite the fact that AI takes on the distinctiv e features of a General Purpose Technology: pervasive, fast -paced  in its diffusion, and innovation spawning . In fact , the distinctive traits of public administration in general,  and the EU public sector specifically, are so peculiar and influential that the diffusion of AI  technologies evidently follows alternative pathways , which must be understood first, and then coherently  acted upon.                                                         20 COM(2020) 65 final. Online : https://ec.europa.eu/info/publications/white -paper -artificial -intelligence -european -approach -excellence -andtrust_en    21 COM(2020)  66 final. Online: https://ec.europa.eu/info/sites/info/files/communication -european -strategy -data-19feb2020_en.pdf  
  21   3 Lessons from the US and China   In Section 2 we have made the argument that a systemic view  is needed to overcome the sin gularities of AI  take-up in the  public sector.  Here after a quick comparison with US and China , we highlight that a lack of policy  focus on the actual level of appropriation of AI technologies in government is common to all, though the EU  might be in a mor e favourable position to counteract this limitation earlier and more extensively. Specifically,  paragraph 3.1 outline s, as a general and common issue  to the three regions , that very little information is  currently available on A I take -up and use in the respective Public Sector , and to a great extent also private   sectors. Then, the next two paragraphs 3.2 and 3.3 briefly report about known initiatives – in the US and China ,  respectively  – to stimulate the use of AI solutions in public administration. Finally, paragraph 3.4 wraps up the  previous discussion and proposes to translate the systemic approach in terms of policy challenges and  implications,  thus introduc ing the reader to the contents of the following  two Section s.  3.1 The terms of the techno -economic race   In the discourse about AI development, a global race between the US, China and the EU is often mentioned  as  ongoing  (Craglia et al., 2018) . International comparisons in terms  of private  investments, research and  education  projects , market applications and other metrics related to AI development  are often mentioned   within this discourse. Moreover, t here is a great interest to identify the big players in the AI field, as it is believed  that successful AI companies can bring substantial economic (and geopolitical) benefits . This is consequent to   considering  that AI bu siness models tend to have a ‘winner takes all -effect’ (Makridakis, 2017) : successful AI  services tend to have more users  involved in their use,  which  in return bring s more data to the company owning  the service, allowing for further optim isation of the initial AI system  and gaining further advantage on the  competition .   One of the most common ly mentioned metrics is the size of private investments  into AI  the three  regions  can record . McKinsey has estimated that the US holds by far the lead in this ranking , with around 20  times higher value than Europe  between 2012 and 2018. In China, private in vestments have also increased  rapidly in the last few years, leading to  approach the US performance quite closely now  (McKinsey, 2019) . Since  70% of global AI investment comes from private companies, this is a significant gap government  funding is inadequate to cover . In addition to having th is large volume of investment , the US is also home  to many of the large st technology companies who are also able to gather large quantities of data from people  all over the world , which can  be used for further developing their AI app lications (Craglia et al., 2018) . Europe ,  instead , has far less venture and public capital invest ed in GovTech solutions , which makes it challenging  for  EU start -ups to access adequate resources  and grow . Some countries, indeed , have been allocating  more  finance recently , such as the UK, Germany and France, which has turned the UK already into one of the top five  global markets for AI investments. However , in the Southern, Easte rn and the smalle st European countries  far  fewer investments in AI  have materialised in general. This points at another anomaly in the comparison with  the US and China, with the EU not only lagging behind significantly in terms of private sector investment  but  also suffering from an unequal  distribution among its Member States.  This could mean that, over time , gaps  between European countries might widen and lead to furthering the unequal distribution of  potential benefits from AI uptake in their societies  (Shearer, Stirli ng, & Pasquarelli, 2020) .   These findings are further supported by a related  analysis of  techno -economic segments conducted at AI  Watch (De Prato et al., 2019) . This showed that  overall most AI play ers are located  in the US with a  high number  of firms involved in AI development. According to this analysis, the US is strongly represented in all thematic  areas of AI, such as Computer Vision, Robotics and Automation, Natural Language Processing and others.  Additionally , the report shows that China  closely  follows the US in terms of  a number  of active AI players , with  many specializing in Computer Vision, Machine Learning and Connected and Automated Vehicles, and has the  highest number of governmental and  research institutions involved in AI. The EU also takes a strong role  worldwide, but mostly in research.   The analysis also shows that few AI companies in the EU file for patents and many of them are quite young  compared to the US and China. Among the pos sible reasons for this performance,  the principal seems  (McKinsey,  2019)  to point at the lack of human resources in the domain, low levels of employment in the ICT industry, a  structural lack of innovation propensity in the private sector and the existence of only a limite d number of tech 
  22   hubs in Europe.  Moreover, there are also some US-based c ompanies entering the EU market where there is only  a limited number of EU players.  In particular, this phenomenon is observed at the local level o the take-up of  local digital twins by cities.   While the EU lags behind in terms of private sector investment, the European academic sector is much  stronger . For more than 20 years, t he most influential academic papers on AI have come from European  research institutions (McKinsey, 2020a) . However, the AI Index 2019 reports t hat authors of AI publications  from the US gain more citations than the EU’s and China’s academic publications (Perrault et al., 2019) .   The reverse side of AI development is uptake. Here international compa risons are less easy because  very little  information is available worldwide about  the use of AI in companies  and public sector organizations .  A few surveys have identified and measure d the propensity to adopt  AI in businesses, but especially China is  not represented in them. Additionally, not all surveys use comparable methodologies or give general results for  the entire region. Often the components of the technology families are not clearly described , there can be   different understandings of what  AI is or is not, the sophistication of used analytical techniques is varying  and  the purpose for which AI is adopt ed is vaguely defined. Thus, it remains difficult to compare adoption  rates, specialisations and purposes for adoption .     As an example, a global stud y done by McKinsey in 2020 shows that 50% of  respondents adopted AI in at least  one business function (McKinsey Analytics, 2020) . That  ratio was in fact lower than  the year before, with 58%  of the respondents doing so  in 2019 . A closer look, however, shows th at this difference is explained due to a  slight change in the survey question. So, AI adoption was considered to be more or less equal to last year across  the different regions, showing that there was not  a large differen ce between the US, China and the EU . Similarly,  a survey done by the firm Cognilytica in January 2020 reported  that 40% of industry respondents were currently  implementing at least one AI project or plan. Their findings highlight ed that companies from the US were more   actively engaged  in the short term than in both the EU and China , which  seem to have more propensity for  the  long term (Cognilytica, 2020) .  The EC also carried out a survey among companies to assess their  propensity to adopt  AI technologies (European  Commission, 2020c) . This found out that 42% of EU-27 enterprises are using at least one AI technology.   However, a similarly sized  group of 40% of respondents stated they did not use AI nor intended to do so in the  following two years. Technology wise, no AI family has a particularly high uptake, as the Figure below shows.  
  23   Figure 3. Propensity to adopt AI acros s EU-27 enterprises.      Source: (European Commission, 2020c) .  Larger enterprises  are more than two times more likely to become adopters of AI compared to smaller and  medium si zed enterprises, which shows that many smaller organizations do not have the current resources to  exploit these technologies to achieve corporate value. Additionally,  there is a big gap between the reported 42%  of companies using AI technologies, and the f act that when asked about specific families, the adoption rates  are much lower. For instance, only 3% of enterprises declared to be using sentiment analysis and 13% AI for  anomaly detection and process optimization. One of the reasons may be a different un derstanding of what  AI is and is not : the respondents may make another mental association when asked about AI rather than its  specific applications, a difficulty already noted in empirical research on AI (Krafft, Young, Katell, Huang, &  Bugingo, 2019) . Finally, EU entrepreneurs report significant obstacles limiting AI adoption, such as the  lack of skills within existing staff a nd the costs of implementing AI  technologies from scratch within  their organizations.   This lack of information concerning  firm level adoption is similar , possibly even more scarce,  in the case of   government. Despite the fact that more information is avail able about the proposed governance strategies and  initiatives  with regards to AI, as documented  in overviews such as  (Cath et al., 2018; Craglia et al., 2018; van  Noordt & Misuraca, 2020a) , very little information is available on the (current  prospective ) use of A I  in EU public administration . The s ame goes for US and China, not to mention that similar comparability  problems would emerge in the case of survey data. In fact, most of the comparisons between the EU, China  and the USA regarding the use of  AI by governm ents seems solely based on strategic policy document analysis  or intentions of use – rather than actual deployment.   In the following two paragraphs , a brief overview of initiatives undertaken by the US and Chinese governments  to stimulate the use of AI in  the public sector is provided .   
  24   3.2 Stimulating the use of AI in the US government   In the US, the Federal Government has been designing  initiatives to develop trustworthy AI for  government services , aligned with the constitution and the creation of nation al value. Several Federal  agencies have already been using AI for various purposes, such as processing grant applications, checking for  compliance, improving of nautical charts, predictive maintenance and more. Indeed, a first mapping of the  federal use of AI technologies showed 142 uses of AI in the most significant federal a gencies   (Engstrom, Ho, Sharkey, & Cuéllar, 2020a) . These solutions are reported  to make the government more  responsive, effective, and efficient. Th us, the US administration plans to continue  expand ing the use of AI in the  public sector.   The Federal Administration also noted that there are talent and workforce challenges limiting the increased use  of AI in government. Therefore, it is looking into how to leverage expertise from the private sector to  develop strate gies to increase organizational trust in adopt ing AI. In addition, some federal agencies  are exploring new approaches to hire, train and retain existing workers with new skills to innovate government  practice with AI technologies (The White House, 2020a) .   Sharing expertise and best practice with AI  is seen as an important mechanism to discover meaningful  use cases and re -use existing applications. Thus, several hubs have been established in a number of  federal agencie s. In the General Services Administration, the AI C enter of Excellence  has been established to  assist in developing AI solutions, but also help organizations in assessing their AI readiness (GSA Centers of  Excellence, 2020) . Similar ly, the Department of Defence has established a Joint Artificial Intelligence Centre in  order to execute the AI strategy of the institution. This acts as a central hub to accelerate organizational  adoption of AI. Lastly, the Department of Energy has established an Artificial Intelligence a nd Technology Office  to coordinate activities among various administrations (The Whi te House Office of Science and Technology  Policy, 2020a) .   Naturally, it is essential to improve building citizen s’ trust in the use of AI in government through a  proper governance approach.  Thus, in an executive order signed in December 2020, the Federal  Government  has put forward a number of principles AI in the government should adhere by during design, development,  acquisition and usage (The White House, 2020b) . Similarly to  the EU proposals on an ethical AI use , these  principles include AI being:    — Lawful and respectful  to the American values .   — Purposeful  so that the benefits significantly outweigh the risks .  — Accurate, reliable, and effective  in line with the purpose it was used for .  — Safe, secure, and resilient  so that any malicious exploitation c an be avoided .  — Understandable , so that its ways of  operation and outcomes can be understood by experts in the same  subject matter .    — Responsible and traceable , so that the roles and responsibilities of people are well ass igned. The whole  process of design, development, acquisition  and use, its inputs and outputs , should be documented and  made traceable .  — Regularly tested  against these principles to ensure that performance and outcomes are consistent with  their intended use.    — Transparent , so that agencies can disclose relevant information to stakeholders in accordance with the  law.  — Accountable , so that agencies can be held accountable for implementing and enforcing safeguards of AI.   In 2021, a roadmap will be published with policy guidance to support the implementation of these principles  across various agencies so that their AI use is consistent with the order. In addition, an inventory will be  prepared by each agency with their AI use cases  to improve interagency coordinati on and the  implementation of the use and reuse of AI. It is planned to have th is collection of  inventories to be made public  to the extent it is possible having in mind  applicable law and policy  constraints . Furthermore, the Presidential 
  25   Innovation Fellows  program will establish an AI track  with the aim to attract experts to help with the design,  development, acquisition and use of AI in government , so as to increase the level of AI expertise in federal  government (The White House Office of Science and Technology Policy, 2020b) .   Under the new Presidency of Biden, the use of AI by the Federal Government remains one of the key strategic  pillars in advancing on trustw orthy AI in government. Work is ongoing to support and coordinate the use of AI  in Federal administrations, mostly through the CSA AI Center of Excellence  which has been introduced before .  In January 2021 the National AI Initiative 22 has been launched, whi ch aims to have the USA lead the world in  the development and use of AI in the private, but also the public sector. Federal agencies seem to be tasked  with a leading role in contributing to both facilitating AI development and uptake of AI across society. Application  areas of importance in this initiative are agriculture,  environment,  financial services, healthcare, national  security and defence, science, transportation , infrastructures , weather forecasting and the COVID -19 pandemic.  The National AI Initiat ive is coordinated and supported by the National Artificial Intelligence Initiative Office,  located in the White House Office of Science and Technology Policy. The State or lower levels of public  administration in the US seem to be investing  far less into the development and adoption of AI, although  strong statements cannot be made , due to a lack of empirical research on the topic .   To support innovation at the local level, another important initiative under the Presidency of Biden focuses on  local governme nt: in the Infrastructure Plan proposed during his campaign, President Biden promised to launch  a yearly USD 1 billion competitive gr ant programme to help five cities pilot new planning strategies and Smart  City technologies that can serve as models for th e country.   Some U.S. cities seem to be waking up to the technology. Despite that, s urveys show that many State  administrations in the US do not seem to be ready for the next level of digital transformation . A  2019 survey conducted among IT executives of the 45 State agencies sh owed that only 1% of them have  achieved broad  AI adoption. Most AI adoption is merely in the Proof of Concept or Piloting phase. It is  not  yet being used in the core government processes (Center for Digital Government, IBM, & NASCIO, 2019) .  One of the key reported challenges is that core enablers of  AI adoption, such as organisational readiness ,  have not made progress  in recent years . The aforemen tioned  survey shows that the most significant  barriers to AI adoption at the State level  is an outdated legacy IT infrastructure, poor organizational  culture and lack of relevant skills.  In fact , two -thirds of the respondents  to that survey respectively  highlighted that  (72%) d id not have a ny policy in place regarding the responsible use of AI and (60%)  did not have a n actionable  framework to evaluate the risk s of AI implementation . While th e survey  was conducted before the announcement of the federal princ iples and actions described before, it shows the  importance of diffusing governance principles for AI across multiple levels of public administration – including  those who are  less likely to have the needed resources to invest heavily into AI. What  the cur rent state of AI  deployment is on the municipal level is currently not known, as no study or survey could be found which assesses  the diffusion  of AI at this level of government.   Finally , there is mixed support in the US public opinion to  the development of AI according to a survey  of Americans. Support for developing AI varies between different subgroups, with those  who are male, with a  higher income or a computer background being  more likely than women  and people with lower education or  income. However, Americans show  little confidence in governmental organisations to manage the  development and use of AI technologies . Instead, they place greater trust in technology companies us ing  AI for the best interest – although , there was not a majority of Americans placing a ‘great deal’ or ‘fair amount’   of trust  in any kind of institution. Finally,  this does show that many Americans may be apprehensive of the  deployment of AI by government institutions, likely to cause some trust issues if the technology gets rushed  or  is deployed opaquely (Zhang & Dafoe, 2019) . Trust in government heavily correlates with citizens approval of  government use of AI, although it varies on a case by case basis (Carrasco, Mills, Whybrew, & Jura, 2019a) .                                                     22 https://www.ai.gov/strategic -pillars/applications/#National -Security -and-Defense   
  26   3.3 Stimulating the use of AI in the Chinese government   Recently t he Chinese government plans for AI use in government services included a number of highly  controversial initiatives , especially from a European perspective,  such as the Social Credit System (see  below) or the setting up of invasive surveillance systems using AI technologies to monitor minority groups.  These initiatives aside, the Chin ese AI strategy is also focused on improving public services and  governance through the help of AI technologies . Thus, public sector organisation s are exploring actively AI  projects to address real -life problems.   In 2017, the Chinese State Council release d the New Generation Artificial Intelligence Development Plan which  has been acting as a unifying document for China’s various AI objectives. This document lays out the importance  of developing AI in various Chinese sectors, including public administration . However, other central government  policies also stimulate public sector digitalisation , providing a favourable environment for exploring the use of  ICT and AI in many application domains  (Chen, Ran, & Gao, 2019a) .  A common misunderstanding is that th e national  AI strategy is pushed heavily from the top; in fact, the Plan  is  not a directive, but more a wish list, where the lower levels of government are expected to play a vital  role to take forward the actual transformation of society through AI (Roberts et al., 2020a) . The  nation al strategy seems to focus more on technological development, whereas experimentation and pilots are  expected to be stimulated at the local level. Some local governments indeed  have taken the frontrunner role  and implemented AI going far beyond the current  national AI policy, but also sparking some controversies. For  example, cities are starting to adopt smart city initiatives , creating digital twins23. There, tech giants are tasked  with creating open innovation platforms to boost local innovation ecosystems . Partnerships with smaller  companies or start -ups are argued to be less prevalent, which clearly differs from the European approach  (Elliott, 2020a) .  Although much more research is needed to understand how AI applications are deployed in the Chinese public  sector , despite the  great emphasis on develop ing AI for the provi sion of public services , the applications used  in China  are not described as being cutting edge or high ly sophisticat ed technology. Instead,  their  strength lies in the integration of various systems and capability to  quickly  scale up  – about the  same as mentioned for the AI currently in use in the US administration (Engstrom, Ho, Sharkey, & Cuéllar,  2020b) . Moreover, the actual delivery of AI -enabled public services seems to be mostly due to large technology  companies favoured by the central government.   An overview of AI development in China cannot exclude one of the main flagship programmes of the Chinese  government: The Social Credit System . This is an overarching policy initiative that aims to make individuals,  businesses, legal institutions, and government more trustworthy by aggregating public data and improving  Chinese law  enforcement  (Creemers, 2018a) . Sharing of data across various public sector departments is  used  to evaluate how someone is likely to comply  with legal and contractual obligations , so as to improve the civic  virtue of the population . The programme, however, has been perceived as an Orwellian government  nightmare , by the Western media  in particul ar, as some local governments and private companies have been  experimenting with the use of social scoring based on the data collected in the city and other  administrations . However, some do highlight that the Western view on China  is incomplete , as the So cial  Credit System faces many barriers in implementation, and the scoring still mostly relies on administrative  documents, rather than including behavioural and third -party data – as these initiatives often fail to materialise   (Drinhausen and Brussee, 2021 ).   However, in areas where (local initiatives of) the Social Credit System have been implemented  a negative  score  can have significant consequences for citizens, such as limiting crediting, banning travels, or being exclud ed  from using private services. T hose with higher scores can for example gain discounts on public transport or  priority access to government services. It is to be noted that  according to some researchers,  these initiatives  are regarded as experimental and not directly related to the centr al government’s strategic plans. In fact, most  of the cases lack technical sophistication and are still based on pen and paper at the moment (Roberts et al.,  2020b) . Furthermore,  the opacity of AI affects the effectiveness of the Social Credit System as a                                                    23 J.Watts KPMG https://www.amcouncil.com.au/membership/special -interest -group/data -in-asset -manag ement/100001 -shanghai -gets-adigital -twin.html  
  27   whole, as citizens need to learn and  understand how the decisions taken by the machine work so they can act  accordingly. Without this  extra  transparency, social control may be  strongly  limited as it is not possible to define   what the machines see as ‘correct’ behaviour (Creemers, 2018b) .  However, even recently, the Social Credit  System is regarded as a disjointed mix of pilots, and large gaps remain in data completeness and data transfers  across Chinese public administrations. Despite existing implementation gaps, recent initiatives placed forward  by the Chinese government show to resolve data governance challenges, and in the roadmap for a ‘rule of law  society’, the social credit system is a key instrument to do so  (Reilly, Muyao Lyu, and Robertson , 2021 ).   The use of AI in China for security and policing purposes is advanced. There has been a lot of investments and  government effort s to apply AI technologies for security or counterterrorism purposes, with especially  widespread surveill ance being put in place in the Xinjiang region to track the local Uyghur population (Roberts  et al., 2020b) .   As the underlying ideology of social engineering and transformability of individuals  through social  control  is unlikely to change, it is likely that the Social Credit System will develop further and existing challenges  related to data sharing will be resolved (Creemers, 2018b) . Citizens in China do indicate the highest level  of support for government applications of AI (Carrasco, Mills, Whybrew, & Jura, 2019b) , but not much   additional information exists with regards to their perspective on government’s AI deployment  to ‘reward and  punish’ citizens based on actions taken.   Despite the fact that the Chinese government is exploring and deploying even more controversial surveillance  technologies, there are  still legal and ethical challenges for the in troduct ion of AI in the public sector ,  just like in the EU and US . Concerns such as who is to be held accountable when governments base their  decisions on AI or when something goes wrong are plaguing Chinese ad ministrations just as much. Civil servants  state their concerns on whether the AI systems can be regarded just as legitimate as human beings  or lead to  unfairness in public service delivery , especially  to vulnerable groups (Chen, Ran, & Gao, 2019b) .   In this respect ,  China has also been working on the adoption of AI ethical principles and frameworks ,  which seem to align with global discussions  and principles  (Elliott, 2020b) . In 2019, a Chinese expert committee  released 8 recommendations  that should be ad opted  during AI dev elopment (Laskai & Webster, 2019) :  — Harmony and friendliness : Enhancing the common well -being of humanity should be the objec tive of AI  since the beginning and thus should conform to human values and morality. Adequate security safeguards  should be put in place to avoid potential abuse.   — Fairness and justice : The development of AI should promote fairness and justice, the rights a nd interests  of stakeholders and promote equality of opportunity. This should be done by raising the level of technology  and eliminating bias and discrimination.   — Inclusivity and sharing : All AI should promote green development and be environmentally frien dly,  promote inclusive development by ensuring social divides should be removed and avoid data or platform  monopolies.   — Respect privacy : Personal privacy and individual’s rights should be respected and protected during AI  development.   — Secure/safe and cont rollable : AI systems should improve their transparency, explainability, reliability  and controllability continuously to make them more trustworthy. This includes that the safety and the  security of AI systems are strong.   — Shared responsibility : Social resp onsibility among developers, users and other parties should be strong,  and thus should follow relevant regulation s, ethics, and norms closely. An AI accountability mechanism  should be established to clarify the different stakeholder’s responsibilities. People should have the right to  know and comprehend  potential risks and impacts.   — Open collaboration : Exchanges and cooperation across disciplines, regions, organizations, and others  should be encouraged for the development and governance of AI. International  dialogue should be followed  to promote the formation of an international governance framework, standards and norms, with full respect  of each country’s principles and practices.  
  28   — Agile governance : The natural laws of AI development should be respected, bu t the search for new ways  to develop AI and resolve risks should be encouraged. Potential future risks of AI should be anticipated to  ensure that AI moves in a direction beneficial for society.   Despite the similarit ies with the European and American ethic al principles , China  is expected  to place  a  stronger emphasis on social responsibility than individual rights in the interpretation of these principles. At the  moment, most of these ethical norms and standards are limited to the statement of high-level pri nciples,  although there are emerging debates on how to raise data protection and privacy standards as well as ethic al  compliance , and a new regulation has recently been introduced  in that sense , although with many exceptions  for governments and state -endor sed companies (Roberts et al., 2020b) .   How the se ethical system s will be put into action, given the different interpretations in the  EU, US and China ,  will help clarify where si milarities and differences in governance approaches to AI in the public sector  do exist   (Elliott, 2020b) .   3.4 Key take -aways   As mentioned before, only a few studies about the use of AI in government services in the US and in China have  been conducted, which makes the lack of comparable field research even more evident than  for the private  sector (see e.g.  Sousa et  al. (2019) . Apart from the controversial cases of adoption, AI applications already in  use that are highly successful may neither  be shared publicly nor have gained much research attention (Elliott,  2020b) . This poses limitation s on the possibility of  understand ing where and how AI solutions are  deployed for enhancing government capacity , but also, what the practical effects are of their us age and  reuse . Globally speaking , we can conclude that there seems to be an enormous gap between used metrics  to track and me asure the comparative progress in AI investment and academic research, and the  reality of AI deployment in public service s and  processes24.   With this caveat, the gap in AI take -up in the public sector  between the EU, US and China does not  seem to be as gre at as shown by other metrics , which focus on research and investments, although it is  too early to make strong conclusions due to the severe lack of data on this topic. Federal or national  administrations seem to be implement ed far more policies and initia tives to make their organizations ready for  AI, although more time is needed to assess if and how they will be successful in stimulating AI uptake.   Conversely,  both local governments and SMEs seem to be plagued by similar implementation barriers ,  which lim it the diffusion of AI where it may gain a significant impact . As noted for the micro and small  enterprises from the private sector, it looks like the limited size and quality of IT endowments  and skills prevent   public administration in all three regions from making significant steps towards  digitalization in general and AI  enabled service  transformation  in particular.  This lack of expertise and hands -on experience in using AI in  government is also likely to limit the public sector’s ability to govern the d evelopment of AI in society with  coherent public polic ies.  In this perspective, there can be opportunities for the three regions to learn from their respective  experiences with the promotion of AI  and decide if and how to replicate each other’s success sto ries – while  understanding that policy and cultural differences may limit the extent to which AI can be developed and/or  adopted in the other regions. However, this should  not be meant as an invitation to start measuring  which region uses more AI and which  less, as this metric by itself would say very little about the  impact and the public value gained from the use or reuse of this technology . The deployment of AI per  se should not be a target, but always take into consideration the needs of the citizens an d the opportunities for  better public service. The mere headcount of AI solutions successfully trialled out but never become  permanently used or still experiencing problems in terms of scalability or interoperability should not be  considered as a relevant success indicator. In other words, t he risk should be avoided that too much policy and  research attention is put on the supply side of AI -enabled innovation in public administration, without  considering the demand side, a common tendency in eGovernment com parisons (Savoldelli, Codagnone, &  Misuraca, 2012) .                                                    24 In the forthcoming LORDI (Local and Regional Digital Indicator Framework ) will provide further improved  framework to measure take -up  of digital technologies at sub -government level , see https://living -in.eu/  
  29   Howev er, the key lesson learned from this comparison is that despite the rhetoric that Europe is falling behind  the US and China in the “AI -race”, there is room  for an EU initiative aimed at reinforcing  appropriation  of AI technologies in the practice of govern ment , which aligns with the “systemic way” of policy -oriented  learning introduced in the previous Sections of this report and may substantially reverse the outcomes of  benchmarking trends and developments in th e public sector domain.   To grasp these opportu nities in full, the thesis of this report is that the sustainable implementation of AI  in public services is a key element for the uptake of A I in public services. In order to reach this  sustainable use of AI, specific attention should be devoted to the ap propriation process, defined in  the report as the sum of adoption and implementation. This approach aims at preventing the appearance   of unwanted and unforeseen effects. This thesis was probably implicit already in the suggestion made by  Misuraca and Noord (2020)  to take distance from the slippery narrative (or simply the trap) of AI  exceptionalism , reconsidering it as a phenomenon that is not “ immune to existing governan ce structures,  policies and laws ”, and requires more than a mere extension of existing national rules and multilateral  agreements to be successfully managed.   Along the same line of thought, we propose to re -elaborate the concept in a more positive (and enc ompassing)  fashion, by reaffirming the primacy of a European exceptionalism  – a controversial notion in the eyes of the  constitutionalists (Bradford & Posner, 2011; Nolte & Aust, 2013) , less so of the economists (Rifkin, 2004) . In  the domain at hand, this primacy should be broken down  in (at least) three concurrent and qualifying directions,  all of them pointing at a more advanced equilibrium between AI promotion and regulation in the EU public  sector:   — Focusing on the fundamental ly distinctive  traits of the functioning  of government  organi zations  and  acknowledging their peculiarities: transparency  and accountability to the constituencies, efficiency and  effectiveness in functioning, fairness and discretion in decision making , and focusing on creating public  value  – even when participatory o r shared. This can also mark a difference, as th is Section 3 has show n,  between the European governance model and its global competitors such as the US and China;   — Aiming  to devise and tackle the “ challenges ” of AI development an d deployment in the public sector, as a  collection of preconditions, in terms of methods and tools for nation - and EU -wide implementation, but  also elements of a first embryo of a “governance of AI, with AI” shared agenda. Section 4 will analyse a  considerable number of those challenges in some detail;   — Enhancing the goal of policy convergence among EU Member States on how to govern the contrasting  forces behind the emergence and pervasiveness of the AI phenomenon, driving  them to  a synthesis in which  the whole is more than the sum of its parts. In this endeavour, the most distinctive elements of the  “European intergovernmentalism ” (Moravcsik, 1993)  might prove useful: a union of equals, united in  diversity , a preference for non -binding policy rules and the allowance for different speeds of compliance,  as epitomised by the Open Method of Coordination25. In Section 5 we will propose a set of policy actions  that belong  to this logic. Among them , as we will argu e, public procurement of innovative AI solutions  would play a decisive role , going even further beyond the known advantages – widely explored by both  literature and practice – in terms of “smart purchasing” in and by government bodies and agencies.                                                       25 The open method of coordination may be described as a form of ‘soft’ law. It is a form of intergovernmental policy -making that does  not result in binding EU legislative measures and it does not require Member States  to introduce or amend their laws. https://eur lex.europa.eu/summary/glossary/open_method_coordination.html#:~:text =The%20open%20method%20of%20coordination,introduce%20 or%20amend%20their%20laws . 
  30   4 Challenges to AI implementation in the EU public sector   This Section overview s a number of systemic challenges which can be relevant for  the attention of policy makers  at EU, national, regional and local levels, willing to engage in and contribute to the propos ed direction of AI  governance , integrating promotion and regulation more effectively . Paragraph 4.1 points at the generation of   adequate funding  for the public sector organisations engaged in AI adoption. This funding should  be nominally  supplie d by the upcoming Digital Europe Programme, but  can also be hampered in practice by two main risks:  dispersion of financial resources across multiple and heterogeneous projects (possibly duplicating similar  efforts in different countries) and inadequate rooting, or embedment, of the newly developed solutions in the  practice of public administration, possibly from different “tiers” and locations, including across national borders.   Then paragraph 4.2 identifies a  second policy challenge i n making quality datasets and infrastructures  diffusely  available, interoperable, and continuously updated and maintained, for the needs  of the novel AI algorithms  and more generally for the progress and sharing of benefits of gover nment digitalisation in all EU countries. In  turn, paragraph  4.3 also taking stock of a discussion done in the previous Section 3 in comparison with US and  China, outlines the third challenge of attracting young tech talents in public administration and widely improving  the literacy and skills of existing staff, particularly in the most “peripheral” public bodies and agencies (from  Southern and Eastern Europe as well as the smallest sized EU Countries) . Then paragraph 4.4 associates a  fourth group of challenges to an evolving  concept of legitimacy for those governments making more decisive  steps towards AI implementation. Finally, paragraph 4.5 focus on e nabling user -centric services with and by AI   and, to do so, describes how the goal of public s ervice transformation, particularly at the local level, can and  should be aligned  with the eight fundamental principles of the Tallinn Declaration on eGove rnment, to achiev e  sustained organisational change in the public body or agency involved in AI implementation .  4.1 Looking for a critical mass of AI investment   The Europe 2020 strategy adopted in 201026 set the long -standing objective to devote 3% of EU Gross D omestic  Product (GDP) to Research and Development – the so -called R&D intensity. According to the latest evidence  from Eurostat27, Member States have increased their spend ing on R&D during the 2008 -2018 decade by about  0.,3 GDP points, however without reach ing the target. In fact, R&D intensity in the EU -27 stood at 2,18% in  2018, while it was 1,87% in 2008. Compared to other major economies, it is about the same ratio as in China  (2,14%) but lower than the OECD average28 (2,38%), the United States (2,82%), J apan (3,28%) and South Korea  (4,53%). In nominal terms, the EU spend ing on R&D in 2018 – that is, what statisticians call Gross Domestic  Expenditure on R&D (GERD) – was close to €294,5 billion, or about €660 per inhabitant. Only 1/9 of that  amount  – roughly 0,24% of EU-27 GDP – can be attributed to the government sector , a ratio that  remained constant all along the decade, as  the graph below shows.   During the same period, the R&D intensity of the higher education sector increased by 10% (corresponding to  about 0,05% of GDP) but only during the first two years, then stagnated at a twice as high level as in  government (0,48% of GDP). Taken together, universities and public administration have not increased  their annual R&D spend above €220 per inhabitant (at 2018 prices) over the past 10 years . However,  it is noteworthy that such level in proportion to GDP is comparatively higher in the EU than in the  US, Japan and  China, and only lower than in South Korea. In fact, the 2018 public R&D intensity (summing up government  and university spend ing) was 0,72% of EU -27 GDP, but only 0,66% in the US, 0,63% in Japan, 0,49%  in China, while it was  0,83% in South Korea29.  Meanwhile , R&D expenditure of the private, non -profit sector has remained negligible (only 0,01% of GDP across  the decade ). Therefore, almost the entire growth in the R&D intensity between 2008 and 2018 has  stemmed from additional investments of th e EU-27 business enterprise sector , as Figure 4 clearly  exhibits.                                                     26 http://ec.europa.eu/info/strategy/european -semester/framework/europe -2020-strategy_en    27 Eurostat, Statistics Explained. R&D Expenditure. Latest data update: September 2020. Online: https://ec.europa.eu/eurostat/statistics explained/index.php?title=R_%26_D_expenditure#R_.26_D_expenditure_by_sector_of_performance    28 OECD, Main Science and Technology Indicators. Latest data update: August 2020. Online: http://www.oecd.org/sti/msti.htm    29 European Commission, Science, Research and Innovation Performance of the EU 2020. A fair, green and digital Europe. Latest da ta  update: May 2020. Online: https://ec.europa.eu/info/publications/science -research -and-innovation -performance -eu-2020_en   
  31   Figure 4. Gross Domestic Expenditure on R&D by sector of performance, EU -27, 2008 -2018 (% relative to GDP).     However, according to the 2015 e dition of the OECD Frascati Manual30, the contribution of the public sector to  national R&D can also be measured through Government Budget Allocations to R&D (GBARD)  31in a given  year. This alternative approach is still in its infancy but promises to be more  informative than recording the  intramural spend ing of government units, because it rules out what is reimbursed by a third party, such as a  public grant, or repaid through a loan, which allows setting a specific focus on government’s autonomous  investment  capacity (notably financed by taxation). On the other hand, there is a likely overestimate of yearly  spend ing because both the capital and current costs are included therein, with multi -annual projects being  attributed to the year(s) in which they are bud geted (Eurostat, 2020) . This overestimate is partly or fully offset  by the f act that local government funds and the budgets of public corporations are currently not included in the  calculation.   Another aspect of interest of such an alternative approach is that data on public funding of ICT R&D  is also  made available as part of the  global budget figure. This includes the support to all ICT -related R&D spend ing in  every sector of the economy, including the NACE rev.2 industry entitled “84 Public Administration and Defence.  Compulsory Social Security” – the closest proxy available to what we name d the business of government.  Roughly speaking, this is what the national government allocates for ICT research and development for its own  purposes.   To get an impression of the size of this budget allocation, the following table compares EU -27 with the US  across the same decade 2008 -2018 as above. Figures are calculated in millions of current Euros PPS32 and  also shown in proportion to total GBARD for the same year. Comparable data for China, Japan and Korea are  not available  (Mas et al., 2020) .                                                    30 http://www.oecd.org/i nnovation/inno/frascati -manual.htm    31 National public funding to transnationally coordinated R&D is defined as the total budget funded by the government (central, regional,  local), as measured by GBARD directed to transnational public R&D performers and t ransnational public R&D programmes   32 PPS stands for Purchasing Power Standards. It is a sort of artificial currency used to make the US and EU GDP comparable in v olume  only, i.e. not considering the effect of price differences between countries. Euros are current for the year, i.e. the price differences due to  the phenomenon of national inflation are still operating between years.   
  32   Table 2. EU-27 vs. US Public Budget Allocations to ICT R&D in Government (millions of current EUR PPS)     2008  2009  2010  2011  2012  2013  2014  2015  2016  2017  2018   EU-27 180,30  156,89  140,11  105,59  85,97  86,96  90,33  86,79  74,95  98,16  95,44  % 3,6%  3,0%  2,6%  1,9%  1,6%  1,6%  1,6%  1,5%  1,3%  1,6%  1,5%   US 1130,8 7 1253,9 4 1318,7 6 1223,2 1 1142,0 2 1014,1 1 1007,6 6 997,87  995,61  1011,1 2 1024,6 3  % 15,1%  15,9%  18,5%  18,7%  16,4%  16,2%  15,7%  14,6%  13,9%  14,7%  14,0%   Source: PREDICT 2020 dataset ( https://ec.europa.eu/jrc/sites/jrcsh/files/government_budget_allocations_for_ict_rd_predict2020.zip ).  In every single year after 2010, the a mounts budgeted for in -house ICT R&D investments by EU -27 (national  and regional) governments have been less than one tenth of the corresponding ones in the US33. Summing up  by row, the cumulative contribution of the EU -27 public sector to its own ICT R&D h as been €1,2  billion in 11 years, or about a quarter of Euro per inhabitant, per year compared with more than  €12 billion in the US , almost 3,5 Euros per inhabitant34, so very low in comparison . Indeed, little can be  said about the comparative quality of pu blic spend ing or the return on the respective investments, but these  figures reflect the reality we should be starting from in our discourse on the EU public sector’s capacity to  transform itself by the ap propria tion of innovative digital technologies, not ably including AI amongst them.   Moreover, t o ignite a true embedment process of novel ICT – hence also AI solutions - in the public  administration  in Europe , making their initial adoption diffused and permanent , beyond the mere and  localised experimentatio n of promising (but sometimes also “fancy”) innovations, a dedicated injection of  financial resources is indispensable35. Just as an example, the proposed budget  for the entire Digital Europe  programme is in the range of €7,5 billion in 7 years, thus of com parable size to the gap outlined in Table 2  above. In particular, the estimated allocation for AI is about €2,2 billion in 2021 -2027. G iven the starting levels  of R&D spend outlined above, the expected impacts of those extra resources  – in terms of lever, if not  also return on investment – can be quite significant even in the short to medium term , especially when  combined with additional investment .   In this framework, the key question for the authors of this report is not whether adequate finance will supp ort  the experimental deployment  of AI solutions in the European public sector for the years ahead. Evidently, this  can be assumed as a matter of fact, including of an order of magnitude – right now, unpredictable in its future  size – sufficient to generate  transformative impacts. Instead, our matter of concern are the infrastructural  conditions and the systemic mechanisms  to be exploited by policy makers willing to make sure that  successful AI innovations introduced by early adopters  from specific EU countr ies (and regions, and cities)  become permanently embedded in the business of government and really pervasive at all  administration levels  – according to the legal competences of public bodies and agencies and having in mind  the political discretions of man agers and elected officials – within and particularly across the EU national  country borders .  We consider this question both timely and justified by evidence. Quite surprisingly, research in this area is  moving its first steps , almost as if the evaluation of those enabling or preventing factors did not deserve a  systematic (and most probably systemic) approach. The remainder of this Section constitutes a contribution in  that direction.   4.2 Data quality, availability  and interoperability   One of the most fundamen tal requirements of AI is data. By definition,  AI relies  on access being ensured to the  “right” kind of data on which to perform its analyses , and which in most cases is augmented by the results of  the analyses themselves . For many Public Sector  organizati ons though , fulfilling this re quirement i s a challenge,  due to a variety of obstacles in obtaining data of the quality and format  they require .                                                     33 As it is known, EU -27 and the US (and China) are all about the same size in terms of GDP expressed in Purchasing Power Standar ds  (PPS). In 2017 they were representing 16%, 16,3% and 16,4% of the world GDP, respectively. See Eurostat news release 84/2020,  The  2017 results of the International Comparison Program. China, US and EU are the largest economies in the world. Latest data May 2020.   https://ec.europa.eu/eurostat/documents/portlet_file_entry/2995521/2 -19052020 -BP-EN.pdf/bb14f7f9 -fc26-8aa1-60d4 -7c2b509dda8e    34 These figures change little if we move to constant prices, using a deflator for the expenses reported in Table 2 for both EU -27 and US.   35 These were also the conclusions of the 2nd peer review workshop of the AI Watch for the Public Sector initiative, held on 29th September  2020, with MS representatives. See van Noordt and Pignatelli (2020) . 
  33   A key obstacle  lies in existing data infrastructure and organisational capabilities within the public  sector . As the strength of AI come s from the data it is “trained ” on, the need for a resilient, high -quality and  accessible data infrastructure is crucial (Harrison et al., 2019) . However, not all government bodies or agencies   have adequately digitalized their internal operations and services in the past decades, which leads to a  significant gap between the ambition of using novel AI technologies and the organizational  readiness to do this  (European Commission, 2020b) . Thus, while AI innovation may bring great benefits to  public sector m odernisation , the less prepared public organization  and agencies  may have the remarkable   difficulties in achieving implementation .  Another related obstacle lies in the fact that sometimes no data on service delivery can be combined with  available  external data . Indeed, some of the successful experiments of AI in the public sector – such as the  City of Helsinki’s analysis of citizen feedback at its offices36 - succeed  in combin ing external with internal  performance data in order to grasp  new insights into how routine operations influence certain contextu al  factors . Naturally, if no or just too scanty  internal evidence  is available because  of the digital immaturity of a  public sector  organization, most of those insights will be lost , as only external data will be available  for analysis.   Thus, public sector organizations that are genuinely interested in implement ing AI in their operations  must find ways to manage at the best their priorities , not leaving behind required  improvement to   the current level of digiti zation , aiming to  ensur e that  all evidence about service  is digital by default. This  should not be seen as a barrier to entry , though , but more as  an opportunity to fasten  digital transformation  of government finding AI adop tion as an additional stimulus . Of course, while AI’s potential can  accelerate the digital transformation efforts of public administration and ensure they include data governance  as targets, it is likely that additional efforts are still required to ensure that the maximum for AI is gain ed from  ongoing and past digitalization.   In fact, the digitalization of public  processes requires good  data governance, allowing the generation of reliable  and useful sources  for later analys es. Buildi ng a strong data governance system in public sector  organization s  has been highlight ed as one of the most impactful element s on the development of trustworthy AI and  consolidati on of take-up by the end -users (Janssen, Brous, Estevez, Barbosa, & Janowski, 2020) .   Fortunate ly, several EU governments  have already transformed  many of their services and digitized most  of  the previously analogue information  reservoirs . For a further advancement of AI in the Public Sector, it  is now to be  considered crucial to improve the quality  and accessibility  of their datasets . As also  highlighted in a previous study , Member State AI strategies normally dedicate attention to improving both the  data quality as well as its accessibility (van Noordt, Medaglia, & Misuraca, 2020) .   Despite these efforts,  there are still many barriers to opening, sharing, and reusing data belonging to   different public  sector  organizations . This should probably be one  of the next step s in the data  curation process .   Scholars have highlight ed the barriers to making government data openly available to the general public –  ranging from poor interest or data litera cy of civil servants, limited endorsement from middle or to p  managers, legal barriers, institutional constraint s related to  regulation or policy , or supply  bottlenecks such as lack of financial resources or of a technical infrastructure suitable to publish data on  (Janssen, Charalabidis, & Zuiderwijk, 2012) . Most of these barriers are also common to data sharing with other  organisations.    But there is more: data available in an open  format may often be of poor quality or too heterogeneous ,  which makes it difficult to extract the information embedded in it (Hellberg & Hedström, 2015) . Alternatively,  shared data i s often ‘pre -processed’, removing much of the information  and limiting re -use by other  actors  (Lämmerhirt, Rubinstein, & Montiel, 2017) . Finally, evidence from the Global Op en Data Index comparing  the publications of government data worldwide shows that it is often difficult to find the “right” data  online , due to the high number and variety of websites, platforms and protocols. As a consequence, while there  is an ongoing tre nd to feed AI with big data by external sources, limited evidence is available on how open or                                                    36 See among others  AI experiments  (in Finnish), https://digi.hel.fi/projektit/helsinki -tekoaly -kokeilut/   
  34   shared data  in public administration assist AI development and deployment (Janssen, Konopnicki, Snowdon, &  Ojo, 2017) . In that direction , the forthcoming D ata Spaces  Initiative37 will enable new data sharing scenarios.    The need for interoperable data sources also applies to the deployment of the Internet of Things (IoT), which  generates data that is often used in urban projects together with AI. Some large  European cities have been  frontrunners in deploying sensors and IoT devices to support public service delivery and gaining real -time  insight s into a variety of urban processes. However, the deployment of sensors is still far from mainstream (ElHaddadeh, Weerakkody, Osmani, Thakker, & Kapoor, 2019) . Thus, future developments in IoT should  consider the analytical possibilities offered by a synergy with AI technologies .   One of the best ways to ensure compatibility between IoT sensor  data and other  sources  is through  achieving full interoperability of government systems (Kankanhalli, Charalabidis, & Mel louli, 2019) . Thus,  grasp ing the opportunities of AI and IoT together may be an accelerator for public administration  as a whole  to finalise  its digital transformation .   A recent phenomenon, noted by some researchers (Klievink, Van Der Voort, & Veeneman, 2018) , is the creation  of ad-hoc, informal and small sized partnerships  where government actors work together with other public  or private acto rs to exchange data related to solv ing a public challenge38. Such collaborations are regarded as  promising examples of a new governance instrument , apt to generate value out of various datasets and to  obtain new capabilities or create new public services. In that direction , it is worth mentioning  the effort made  by OASC ( Open & Agile Smart City ) through the definition of MIMs  (Minimal Interoperability Mechanisms ). MIMs ’  objective is to provide the technical foundation for procurement and deployment of urban data platforms and  end-to-end solutions in cities and communities worldwide39  Despite the potential, however, research has highlighted that  extending such inter-organizational  collaborations to AI development and adoption is not straightforward due to the need for  interoperability  between different data sets to ensure data integration, but also to organizational, legal,  and political factors  restricting  the scope of  such partnerships. In a recent study, fears with regards to privacy  and cybersecurity in data  sharing are shown to lead to the risk that AI projects get halted. It is therefore crucial  for public organizations to introduce ways to share data in a secure and trustworthy manner (Campion, Gasco Hernandez, Jankin Mikhaylov, & Esteve, 2020) .   Arguably, to ignite a diffused interest in collaborative data sharing among public and private actors, new and  well-functioning  data ecosystems  need to  be developed. As the value in many of the se collaborations lies  in the exchange and combination of several  datasets  (e.g. required to train AI models) , which  were previously  not made available  by public administration, there is a lot of potential in ensuring that digital technology take up also o ccurs in local businesses and citizens40.   The more digitalization occurs in the nearby ecosystem, the more data is likely to be available for  potential AI projects involving the public sector.  Naturally, these data ecosystems need to be developed  in such a  way as to protect citizens’ rights and meet the public good (Calzada & Almirall, 2020) . While some  pilots of AI can take place in digital ly immature environments, data governance foundations should be  established in all layers of government before AI is really scaled up across services  and across  borders . Particularly, public bodies and agencies  should treat open data programmes according to an  ecosystemic approach : combining both policy initia tives for building reliable data infrastructures as well as  the engagement of relevant stakeholders (Dawes, Vidiasova, & Parkhimovich, 2016) . Ensuring that different  actors establish connections, relations and understand each other’s needs is key to create a  trustworthy and thriving local da ta ecosystem  prone to improve  with time.   Initiatives such as the EU  Digital Innovation Hubs can reinforce and strengthen these ecosystems , and  most importantly, allow public sector organizations to harness the innovative spirits of businesses and citizens                                                     37 https://digital -strategy.ec.europa.eu/en/policies/strategy -data  38 See the JRC DigiTranscope on B2G data sharing models, the B2G data sharing workshops and the forth coming Data Act ,  39 https://mims.oascities.org/   40 See forthcoming Data S pace for Smart C ommunities , https://digital -strategy.ec.europa.eu/en/library/expert -workshop -common -european smart -communities -data-space  
  35   to come up with promising solutions to pressing local issues41. Digital Innovation Hubs has played a key role in  stimulating and implementing regional and local innovation strategies . Inde ed, they can also be excellent  training  organizations for advancing the internal use of AI in the public sector  (European Commission, 2021c) .  This requires their further establishment and diffusion across the EU and those already in  place should be  expanded with additional resources to stimulate public sector innovation using AI as well .   4.3 Talent attraction and skill improvement   The aim  to develop and use AI in government organizations may, however, encounter issues if not accompanie d  by a similar interest in boosting the AI skills, litera cy and awareness of civil servants. Many public bodies and  agencies have great difficulty in obtaining tech talents and governing and evaluating  their internal  ICT systems  (Mergel, 2019) , though knowing  that an adequate s killset is crucial for any digital transformation  process (Mergel, Edelmann, & Haug, 2019) .   For digital transformation projects involving AI, the lack of expertise is even more crucial. It is often mentioned  that capacities are missing  within public sector organizations  both for developing AI and for  work ing  with it, understand ing its strengths and limitations . As a result, m ost AI professionals tend to flock to the  private sector where  the benefits , also in terms of recognition,  are sig nificantly higher (Wirtz, Weyerer, & Sturm,  2020) .   Therefore, invest ments in training and capacity building, but also talent attraction are required to ensure that  every public sector organisation  can have  access to the right capabilities to develop and use AI, as well as young  AI professionals seeing government as a concr ete possibilit y of career advance ment . However, a vision  is also  needed about which and how AI should be used so that the training can be developed accordingly.    As also highlighted in a recent AI Watch workshop (van Noordt & Pignatelli, 2020)  actions are ongoing on the  national administrative layer to raise awareness, train civil servants and establish knowledge hubs  – such as  data labs  – where  AI resources are shared across different departments o f the administration . Howe ver, lower  tiers of government may require ad hoc initiatives  to ensure they too have access to relevant AI resources.   Without such interventions, the public sector may become increasingly dependent on external  AI  consultants , with  evident  risks of vendor lock-in and transparency threats  due to the limited understanding o f  how AI affect s the internal operations of government and perhaps to the additional inflexibility to change if   something goes wrong  (Andersen, Lee, & Henriksen, 2020) .    It is also likely that, without adequate digital capabilities and skills within the public sector, some  bodies or  agencies may face significant difficulties in adopting the AI solutions successfully de ployed  elsewhere or just replicating some  case studies  with the needed adaptations . To build an effective  governance framework,  skills and competencies should extend as much to governance “with AI” as to  governance “of AI”  (Kuziemski & Misuraca, 2020) .  Such lack of governance  capacities does not only prevent or limit AI innovation in individual government bodies  and agencies, but also at regional level, with the recurrent paradox that the lack of capacity i s predominant i n  the regions that would need them most because they fail to catch up  (Muscio, Reid, & Rivera Leon, 2015) . In  fact, the Covid19 crisis revealed that the geographical spread of online availability of public services, internet  access and digital literacy in Europe is not as broad  as imagined. Despite the improvements, even recently  made, strong differences stil l exist between rich, poor, urban and rural areas (European Committee of the  Regions, 2020) .   While public administration has been to some extent forced to digitalise some processes and work practices  due to Covid19, it remains unclear whether these trends will lead to a mor e profound reform  and  therefore require the attraction of further expertise and expertise  on organisational  and process reengineering .  Indeed, w orking remotely and having gained an expanded network capacity cannot be considered a full digital  transformatio n while many non -value -adding processes still remain the same without redesigning  organisational activities and roles proactively (Gabryelczyk, 2020) .                                                    41 For more information regarding the Digital In novation Hubs part of the Digital Europe Programme, see also: https://ec.europa.eu/digital single -market/en/digital -innovation -hubs  
  36   4.4 Input, throughput, and  output legitimacy  of AI use   There has been much research on identifying various ethical concerns related  to deploying AI as there are   indeed  a number of issues potentially arising from the way AI operates (Dignum, 2018) . For government  deployment of AI,  this brings  specific risks, among which the following particularly stand out (Dwivedi et al.,  2019; Mittelstadt, Allo, Taddeo, Wachter, & Floridi, 2016) :  — Producing u nfair outcomes , as AI al gorithms can amplify some discriminatory biases already present in  societies. This can result in AI bas ing decisions or recommendations on human factors, which  is against the  rule of law  to consider , such as gender, race, o r sexuality. Even when certain sensitive data is omitted from  the learning process, AI can still amplify hidden biases in the data through proxies such as postal codes  for  marginal or troublesome urban neighbourhoods . The actions taken by AI systems are on ly as good as the  data they are  based  on. . This  require s a full awareness of the quality and  possible  limitations of the data  used to feed the AI system . Particularly when  dealing with marginalized groups, public bodies and  agencies using AI should always  avoid having these  systems worsen existing inequalities in  societ y rather than helping resolv e them.   — Increasing the opacity of decisions , due to the “black box ” nature of some AI algorithm s. Despite some  recent advancements in explainable  or interpretabl e AI, most AI systems in certain cases  remain   inaccessible, overly complex , self organising , not sufficiently transparent, which makes it incomprehensible  why AI suggested or took certain decisions. This also limits the ability of public administration to justify the  decisions  taken by the AI systems , monitor and correct them . This lack of transparency and accountability  of AI-informed or enabled decisions bring s not only ethical but also legal and political consequence s, as  citizens may have difficulties in accepting and enforc ing the decisions taken by their  governments . In that sense , the Amsterdam42 and Helsinki43 AI Registr ies for transparency purpose s are  good example s in the direction to explicit communicate and explain where AI is deployed and how auto matic  decision s are taken, describing clearly potential opacity when is the case.    — Threat ening the privacy of citizens  unduly  is also a risk, as most AI systems require significant  amounts of (personal) data to perform accurately. This introduces two types  of issues, the hiddenness of  the real extent  (and possible severity)  of data collection practices and the unwanted knowledge  gained from data analysis . As the example, also highlighted as a risk in the GDPR, of merging public  with restricted or even anony mised data shows, the k nowledge produced through analysi ng various linked  sources is at risk of  reveal ing highly private or sensitive information which citizens arguably would not want  to have disclosed (Janssen & van den Hoven, 2015) . In addition, the continuous deployment of various AI  systems t hat monitor and track people could establish some form of Big Brother government , reducing  trust in public administration and the legitimacy of democratic power .  — Promoting  an “algocra cy” scenario , that is  a subtle  and extreme form of technocracy, whereby machine  algorithms , rather than  AI empowered people, collect informatio n, take actions and administer the rules of  a State. In that sense , further investigations are ongoing  in order to explore  in which cases there is a real  need for such complex and self -organizing algorithms . Paradoxically, this potential algorithm -based  governance system , instead of  amplify ing and enabling human involvement  in public processes ,  tends to restrict it , inducing further  limitation s of citizen  opportunities to participate in decision making  (Danaher, 2016) .  These risks  may pose huge challenges to the  legitimacy of public sector organizations . On the one  hand, AI technologies are seen as improving the outcomes of policymaking  and governmental operations by  making t hem more effective and efficient . On the other hand, AI itself could severely undermine the legitimacy  of governments in three di stinct areas, namely Input gathering, Throughput generation, and Output delivery   (Starke & Lünich, 2020) .                                                    42 Amsterdam AI Registry: https://a lgoritmeregister.amsterdam.nl/en/ai -register/   43 Helsinki AI Registry: https://ai.hel.fi/en/ai -register/  
  37   Figure 5. Key challenges to government legitimacy by AI adoption.     Source: JRC, own elaboration.   Firstly , the input legitimacy  of government is challeng ed because  the design of the AI systems require s  developers to make political decisions that may be difficult to detect or correct  at a later stage  (Mulligan & Bamberger, 2019) . There is often  limited political or citizen oversight in the design and  deployment of “where, when, and how ” AI systems get used in government services . As also shown  by the “DigiGov ” study, citizens are watchful  when their personal data is used – sometimes without thei r  awareness or explicit approval – by private sector organizations asked to work with public administration in the  development of AI systems  (Barcevičius et al., 2019) . Similarly, most marginalized groups risk being   insufficiently involved or represented in  digital transformation processes , leading to bias es and false (e.g. using  sentiment analysis  in social media  as a proxy for public support  soft political decision making  across society as  a whole  (Giest & Samuels, 2020) . Not considering the political context and t he wishes of some categories of  citizens while using AI may thus severely reduce the input legitimacy of governments.   Secondly, the throughput legitimacy  of government  may be reduced when decisions become increasingly  more difficult to scrutinize or explai n (Burrell, 2016) . The level of opacity with which  some  AI systems  make certain decisions and the uncertainty on how the ir decisions are made could greatly diminish citizen trust  in public administration . Civil servants themselves, when complex tasks get au tomated, may have the  impression that the fairness of the procedure gets threatened44. Fully replacing people in tasks that used to rely  on human skills may thus lead to a lack of perceived fairness. Only for tasks that are regarded as simple  and less compl ex, AI may be preferable , although the outcomes of implementation should be examined on  a case by case basis and require careful deliberation (Nagtegaal, 2020) . In addition, it may always be possible  that during the development or the deployment of AI, some laws get broken due to the data collection  practices, unwarranted data sharing or the infringement of citizen s’ privacy rights (Meijer & Thaens, 2020) .  Altho ugh indispensable,  legal safeguards m ight be regarded as unwanted obstacles  during the  development of AI systems, which  would thus lead to unlawful use of AI. Consistently with this , the risk must  be reduced as much as possible . Moreover, the level of risk  is different with respect to the area of application  for example areas like  environmental monitoring and climate adaptation  are expected to have fewer  privacy related issues.   Thirdly, the output legitimacy  of government may be harmed when the AI systems a re not functioning as  good as expected . As mentioned before, the recommendations and decisions taken by AI may be heavily  biased or flawed due to poor development or unproven performance in complex social settings. Often, AI                                                    44 Good practice may be the Amsterdam Fair AI contract clauses, wh ere clauses are automated  by the development of the so -called Fair AI  MIM (Living -in.eu).  
  38   systems hardly work as well in real life conditions 45as they do in controlled environments  and make  more errors tha n expected  (Bailey & Barley, 2019; Coiera, 2019) . Alternatively, the performance of using deep  learn ing or other opaque machine learning methods in the development of AI systems may only have a slightly  better predictive accuracy  compared to less complex and more transparent techniques such as regression  analysis using only a handful of variables  (Dressel & Farid, 2 018; Salganik et al., 2020) . Furthermore, the  development and governance of AI systems may require significant organisational resources  which  may be overlooked at first,  thus ultimately  limiting the cost reductions AI was supposed to bring to the  organisa tion. Having many, expensive and opaque algorithmic systems the performance of which is unclear  may in fact reduce the effectiveness of government dramatically  (Andersen et al., 2020) .   4.5 Enabl ing user-centric  services  with and  by AI   AI is often used for increasing the quality of public service deliver y and a large number of application s are under  development in this area. Indeed, the main objectives of introducing the AI in governments’ services relate to:  a) improve internal  processes; b) enhance and enabling faster policy -making mechanisms, and c) improve the  participation and experience of citizens and business users when using public services  (Misuraca and van Noordt,  2020).   This is a set of operational targets, which  support the political commitment that the EC established at the EU  level on significant priorities towards ensuring high quality, user -centric digital public services for citizens and  seamless cross -border public services for businesses.  This vision is reflected in the eight fundamental user  centricity principles  as defined by the Tallinn Declaration on Digital Government46.   User-centricity counts on new digital technologies, and therefore also on AI, for strengthen ing trust in  governments . In particular, they focus on  increasing transparency, responsiveness, reliability, and integrity of  public governance.   A direct consequence of that is the need to embed the discussion on AI with the discussion on user -centric  services: governments have to pl ace citizens at the centre of public services and governance and AI can and  should support this challenge.   For doing so, a stream of research on AI in the public sector should look at how to connect user centricity and  service design principles with AI. T his section is giving evidence to this stream  and set s the ground for further  research in the field.   As a brief background, user  centricity challenge relates directly to tackling the issue of low satisfaction with  public services and distrust in governmen t and public administration . This may be  because  of delays  in fully  embrac ing digitalisation of public services , or surviving biases and discriminations  in making them accessible,  or lack of transparency, reliability or accountability during and after deli very. Moreover , with  ICT skills becoming  more widespread  across generations , the global expectations in terms of  technolog ical performance and  capacities may  also increase, which is not always joined, however, by concurrent improvements in usability  featur es, particularly to the benefit of the less expert groups . The reasons could be found also in the  customisation phases that bring from the user -centric principles to the user -centric operative services. User  engagement procedures must be contextualised in the territory on which the service will act and on the target  users .   The first attempts of using new digital technologies for enhancing user-centric services may be found at the  local level, thanks to the efforts made within the smart cities.  The smart cities phenomenon is increasingly seen  as far more than simply endowing an urban area with some technological infrastructure, rather as the creation                                                    45 There is a  forthcoming AI Testing and  Experimentation Facilities to further sustain the development and deployment of AI. https://digital strategy.ec.europa.eu/en/activities/testing -and-experimentation -facilities   46 The 2017 “Tallinn Declaration on Dig ital Government” provides eight clear principles Member States should commit to, with the purpose  of redesigning public services around the user needs. These principles have been translated into a sort of additional “rights ” for citizens,  who should expect  to: digitally interact with their administration; find accessible, secure and available services; experience a reduction of  the administrative burden; receive services that are fully delivered online; being empowered and engaged in proposing new ser vice i deas  and suggestions for improvement; being removed of any barriers and incentivised to the use of digital services; protected in their personal  privacy sphere and allowed control of their data; enabled to activate redress and complaint mechanisms.  
  39   of a place where citizens live in a smarter way and allocate their time and resources more efficiently and  productively. This kind of lifestyle change alter s citizens’  perspective of the world and promote shifts in their  behaviours and expectations, in particular, towards urban  services. Moreover, with the level and intensity of  demand becoming higher, service au tomation proves vital to alleviate pressure on government’s delivery  capacity and continue enhancing the quality of urban experience.   Many European cities have already realised the importance of user centricity. Howe ver, a systematic collection  of success stories is still missing47. Cities have the ambition to support service (re)design with clear insights on  the specific profiles of prospective beneficiaries and their aspirations in terms of quality and performance, u p  to the point of letting citizens and businesses participate in the development and validation of the new digital  public services that are expressly tailored on their needs.  Actors in these stories are , therefore: the general  public, city networks (partic ularly for interoperability and scaling), regional and local government bodies and  policymakers, innovation and technology hubs,  living labs,  science parks, university incubators, civil and social  rights activists, not for profit associations etc.   Yet, it is still often difficult to reach various groups of citizens and businesses through digital public services  only. And the relationship between empowerment and outreach is unavoidably two -way: while the removal of  pre-emptive barriers and constraints to the  use of electronic services does influence diffusion, their persistence  as user centricity issues may negatively affect the digital transformation and therefore the trustworthiness and  accountability of governments (European Commission, 2019c) .   As a general remark, following the trend already ongoing on user centricity, it is  important  that implementation  of user  centricity principles in AI appropriation start s at the local level . As for general service redesign,  cities should let the users participate in the  appropriation of AI and, more generally, have always a careful eye  on the eight fundamental user centricity principles when approaching the introduction of AI.   We can assume that AI solutions  only designed and implemented following the user centricity pr inciples can at  full potential , for example, help reduce the administrative burden, support in resolving resource allocation  problems, take up complex tasks, and deal  with the heterogeneity and complexity of data sources. However , its  inner nature  and influential role  in transform ing government action and interacti on with its stakeholders  can  also enabl e the enhancement  of user centricity  in the next generation of public services, (especially) at the local  level.   Accordingly , authors such as (Barbero et al., 2016; Ferro, Loukis, Charalabidis, & Osella, 2013; Fredriksson,  Mubarak, Tuohimaa, & Zhan, 2017)  highlight that big data analytics, algorithms, and machi ne learning, provide  a number of advantages to governments throughout the entire policy cycle.  User centricity challenges and  opportunities can be detected also by looking at the phases of the policy cycle.    Firstly, in the phase of agenda -setting, the implementation  of AI may significantly increase the effectiveness   of citizen  participation  through refined ways of annotating and grasping their feedback through sentiment  analysis, crowdsourcing and physical or virtual (even including  augmented reality or virtual r eality ) co-creation   sessions .   Secondly, human -machine interaction has the potential to enhance efficiency, effectiveness and accuracy of  policy making , also in the direction of better user centricity of the resulting services . For instance, predic tive  analytics may indicate the priority of focus ing more on prevention, instead of just reacting , to crises and other  societal problems. Or a more faithful handling and representation of service usage data may assist in  developing more targeted, personali sed interventions and even ‘nudges’ to beneficiaries. These approache s  have been applied in healthcare,  environmental and traffic management48, education and other social services  of general interest.    Thirdly, progress  in user centricity requires a “sustai ned organisational change”  in the involved public body or  agency. This change has been defined  as “altering existing organisational practices, changing organisational  processes and/or tasks of government staff”  (Misuraca, 2012) . Such requirement is in line with the most  accredited vision of user centricity as a mindset , rather than an organisational status to be reached; an                                                    47 Ongoi ng efforts funded by the EU include the Co -Val dashboard ( https://www.co -val.eu/dashboard/municipalities ) and the Designscapes  geo database of urban innovation initiatives ( http://designscapes.eu/funded -initiatives/ )   48  see DUET (digital twins) H2020 project or LEAD (H2020 project) on digital twins in urban mobility.  
  40   approach  to be followed, for instance in service (re)design and delivery, rather than the specific methods and  tools enabling it; and a collection of moving target s, depending on the interim progress made so far and  also on the evolving expectations of citize ns and businesses  in terms of service quality, usability and  trustworthiness .   Starting from the assumption described above, and t aking Figure 2 (from Section 2) for approaching AI  appropriation in the Public Sector , user centricity principles can be enabled  in the process of AI appropriation at  the governmental level through a variety  of service s co-design and participatory activities.  It appears that the  AI itself is an enabling technology for user cent ricity and it could be included in the cyclic process that  brings to  the AI appropriation maturity . Table 3 offers a bird’s eye view of this conceptual scheme. In detail, column 1  refers to single phases of the proc ess of AI appropriation, column 2 provides a list of activities paving the way  to the implementation of user centricity processes and, finally, column 3 suggests the most relevant AI  typologies supporting the mentioned activities.   Table 3. User centricity cultivation within the process of AI appropriation .  PHASES OF AI  APPROPRIATION  ACTIVITIES FOR ENABLING USER CENTRICITY  SUPPORTIVE TYPES OF AI  USER REQUIREMENT  ANALYSIS  Perform quantitative and qualitative studies, such as  surveys a nd interviews to understand citizens’ needs  and identify which of those should be (re)addressed with  the help of new or revised, AI -enabled public services  Natural Language Processing, Text Mining  and Speech Analytics Tools   ANALYSIS OF CONTEXTU AL  FACTORS  Complement available evidence with e.g. fresh  environmental or perception data generated through  interacting with the stakeholders who are to be served  Predictive Analytics, Simulation and Data  Visualisation Applications   NEED ANALYSIS AND  TECHNOLOGY CHOIC E Build rough prototypes to pre -test related ideas for  sustainability and scalability, and iterate if needed  Chatbots, Intelligent Digital Assistants,  Virtual Agents and Recommendation  Systems   SERVICE (RE) DESIGN AND  (RE) DEVELOPMENT  Generate insights and  create new service concepts and  processes based on the above findings  All of the above   SERVICE TESTING AND  EVALUATION  Balance quantitative and qualitative measures to assess  performance and impact on users  All of the above   CHECK AGAINST  CONTEXTUAL FACTO RS Craft stories, share experiences, describe successful  cases and lessons learned – also to inspire actions of  other administrations in a logic of scalability and reuse  Predictive Analytics, Simulation and Data  Visualisation Applications   CHECK AGAINST US ER  REQUIREMENTS  Refine ideas and gather feedback from stakeholders to  deliver better services that will be adopted by citizens  Natural Language Processing, Text Mining  and Speech Analytics Tools   Source : JRC, own elaboration.   All these activities belong to  a human -centred approach  that is transformative of the way governments  engage with prospective beneficiaries to gather their pre-emptive insights and offer better responses to their  needs and requirements. In so doing, people are p ositioned  at the centre of public service transformation , across  all steps from ideation to prototyping to validation . This can contribute to achieving user centricity in AI -enabled  public services and  also leads to increased citizens trust and an enhanced resilience of the socia l and economic  systems  (Alzahrani, Al -Karaghouli, & Weerakkody, 2017) .  Finally, and by no means surprisingly, user centricity principles can be more effectively guaranteed if sound  achievements are also ensured for the previously outlined challenges in terms of e.g. skills im provement, data  availability and accuracy, interoperability of datasets and processes as well as, more generally, increased  sharing and collaboration propensity among administrations.    
  41   5 Policy implication s   This Section draws some overall suggestions that s et the ground for identifying a list of policy implication s from  the previous discussion . With a high -level approach, we made the first attempt to support  EU decision makers   that are willing to undertake the systemic approach to AI governance  towards a mor e advanced equilibrium  between AI promotion and regulation in the public sector . This equilibrium should be redefined at the  predominant space of high -level coordination between the European Commission and the Member States, that  is the macro level.   Accor dingly,  the next three paragraphs formulate as suggestions or recommendations:   1. a stronger integration of AI with data policies, to face the issue of the so-called “explainability of AI”   (Arrieta et al., 2019; Vilone & Longo, 2020)   2. to broaden the current perspectives of both Pre-Commercial Procurement (P CP) and Public  Procurement of Innovation (PPI) at the service of smart AI purchasing by the EU public administration49.   As reported at the beginning, the main goal of the entire report was to set the theoretical ground on which  future research can build a precise and detailed list of recommendations. For this reason in this Section  will  contain only ,  some bounded high-level suggestions that shall and will be detailed in further researches that  are conducted within the AI Watch. Hence, the three policy impl ications reported are the direct result of the  analysis reported in the previous chapter and aim at being neither exhaustive nor extremely detailed or refined.   5.1 In search of a critical mass for the “champions” of AI for government   In Section  3 of this report, an attempt at benchmarking EU with US and China was made in terms of the  respective performance s of their governance systems  in framing, promoting, and regulating the use of AI  solutions within the public sector . While the sc arcity of comparable data, other than merely anecdotal  or  qualitative  evidence , impedes any definite judgment on the real degree of AI take -up at the different tiers of  administration, it seems quite reasonable  to affirm  that this is a key dimension of the  global techno economic race  too.   In fact, the  economic  implication s of a growing demand for AI solutions  in any sector and country – above and  beyond the gains in productivity and efficiency of the appropriation “pioneers” – include the formation and  growth of a wave of specialised technology providers or the consolidation of the existing or emerging national  industry  players  in that domain. Making  a compar ison of the demand side of the three markets  is made  – as  far as government is concerned, but more g enerally in all sectors where digital solutions can be successfully  deployed  – it is necessary to concede that Europe is at disadvantage , compared  to the US and China, because   of the relative fragmentation of the European GovTech market, and the need to ad just solutions based on the  national contexts.  (Probst, Pedersen, Lefebvre, & Dakkak -Arnoux, 2018) .   However, i f one looks at the supply side  of the AI industry , assuming that the trends of globalisation of the pre Covid19 e ra will be to a great extent resumed  in the coming years , it would  seem quite logical  for European  firms  born after the successful deployment of some technologies  in Europe to become  more competitive and  start serv ing US or China based clients with their original  and innovative products and services. In deed, there is  already a wide set of AI solutions  experimented  in many domains that could be rather easily scaled from a  single/local  experimentation site  to multiple/global business locations.  Of course,  various aspects of market  segmentation would still be operational, in cluding language barriers: it may be the case that automatic speech  to text  services in Croatian language underperform those working in English , or that analysing the sentiment of  social media posts may not be as great as a business in Malt ese as in French or Spanish . Even so – as highlighted  by a quick look into the growth pathways of IT “giants” such as Facebook, Google or Twitter – a number of  technological , as well as commercial synergies , could be exploited irrespective of  the language spoken in the  countries the se AI innovators  are operating in .   Discussing the most appropriate policy measures to promote the growth  in market size  and internationalisation  of European AI industry would obviously exceed the scope of this report. However, the important poi nt here is  that there may be  another way of tackling the same issue, particularly for government -oriented AI solutions .                                                    49 the forthcoming EU Adopt AI programme  is expected to offer a support to this  
  42   This is to promote the reuse and transfer of AI implementation best practice examples , starting from  those within the same EU country, then analysing the conditions for their replication  in other EU countries , up  to the possibility of identify ing a new generation of cross -border or pan-European public services  that leverage  AI as a common enabler .    In fact, while a number of  value -adding AI solutions successfully t rialled so far seem to refer to specific digital  infrastructures, datasets and service  delivery  environments, others  are agnostic with respect to the domain  of application . This is the case of AI tools such as automatic translato rs or transcri bers which, once developed   and tested , can be effectively re-used in different situation s without the need for further adaptation . For  example, the European Commission recently launched an online machine translation service called  eTranslatio n50, which is available to registered EU users free of charge. Other  AI prototype s that have  proven useful in specific context s may require little effort to be extended to similar or related ones .  Another example is  a solution recent ly develop ed in the Neth erlands to interpret handwritten documents, such  as those stored  in historical archives, and convert them into a digital format. Such use of AI could also prove  helpful  for government bodies and agencies still rely ing on paper exchange with some service be neficiaries,  rather than adopt ing a “natively digital ” approach , which the organisation might not yet be ready . After digiti sing  and analysing  the files through  AI, new  applications could become viable , leading to further  insights to act upon.   While such examples look reasonable to follow and expand further, for many reasons they are not   representative of the current scenario in the EU public administration. In fact, with all the caveats suggested by  all-too-scanty empirical evidence, the following  two (clusters of) barriers seems to prevail  at the moment :  — The “AI for government ” supply side  seem s comparatively less market -ready than the broader  GovTech industry it belongs to . This may not necessarily be due to a lack of technology maturity (low  TRL), altho ugh this could be perceived to some extent if we tried to disentangle the generic categorisation  of AI typologies – such as Machine Learning or Robotic Process Automation – into their individual  components showing high grades of heterogeneity in terms of t ime to market. Our impression is that such  heterogeneity hides a more general issue, which is related to a comparatively higher difficulty in gaining a  critical mass of commercial applications of a certain AI technology, which is a prerequisite to turn the  latter  into a commercially viable and attractive product or service.   — While several collections of developer tools exist  indeed , such as Google ’s AI Hub51, Amazon’s AWS52,  Microsoft ’s AzureML53, Cognitive Services54,  and ML.Net Model Builder55, or IBM Develop er56 and Watson57,  it is rather unusual that a “plug and play” solution can be immediately adopted as it is taken from off -theshelf. Instead, in order to achieve a satisfactory degree of AI appropriation in a public service environment,  a supplement of loca l configuration and custom installation is usually needed, which leads to additional  "pains and perils" during onsite experimentation. The latter is witnessed by the significant number of case  histories gathered in the AI Watch collection, which do es not s eem to have ever left the "ongoing project"  status, due to unexpected problems that emerged during the transition from adoption to implementation.  Conversely, from an overview of the various GovTech startup and business listings that are published from  time to time in the US58, in Europe59, and worldwide60, the reality emerges of  many “champions” of AI  for government  – i.e. bearers or inventors of a cutting -edge technology, which is now available to the  public buyer – not selling the AI application as such , but only as a component of a broader solution,  which is supposed to fulfil the domain - and context - related requirements of the business case(s) it  addresses . Moreover, the ERASMUS Data Analytics Centre’s study identified that one of the main obstacles  to sc aling up  smart city  digital solutions was - and still is  - the lack of interoperable, standards -based  platforms61 that would allow public administrations to manage large amounts of data from heterogeneous                                                    50 https://ec.europa.eu/info/resources -partners/machine -translation -public -administrations -etransl ation_en    51 https://aihub.cloud.google.com/    52 https://aws.amazon.com/free/machine -learning/?nc1=h_ls    53 https://azure.microsoft.com/en -us/services/machine -learning/#product -overview    54 https://azure.microsoft.com/en -us/services/cognitive -services/   55 https://dotnet.microsoft.com/apps/machinelearning -ai/ml -dotnet/model -builder    56 https://developer.ibm.com/technologies/artific ial-intelligence/    57 https://www.ibm.com/watson   58 Such as  https://www.govtech.com/100/2021    59 Such as  https://view.publitas.com/public -1/the -european -govtech -150-the-startups -driving -europes -govtech -revolution/    60 Such as https://aithority.com/ait -featured -posts/100 -emerging -govtech -startups -you-should -know -about/    61 See: https://www.rsm.nl/about -rsm/news/detail/14476 -smart -cities -need-to-trust-technology -and-data-quality/  
  43   data sources.  Compared with the private sector, government has  a more heterogenous range of  business needs to fulfil , which are inextricably related to the contextual factors presented in Paragraph   2.2. Additionally, even within the same country or region, therefore under a common legal system, the  organis ational, process - and service - level peculiarities  outnumber the commonalities among  public bodies and agencies , which makes every AI appropriation quite often a single case. This is  witnessed by a number of global surveys of the “AI maturity” of (usually large sized) organisations from  various industries, including the public sector. With this term, which is broken down  in different ways  depending on who has carried out the survey, the implication is made that every organisation follows a  sort of learning and capacity building process, which will ultimately lead it to make strategic use of AI in  its processes and therefore to grasp all the benefits and impacts from implementation. For example,   according to a 2021 survey of the Boston Consulting Group62, the Public Sector has the second highest  share  of organisations that are not AI mature  (only the  Consumer industry  fares worse) . Quite  reasonabl y, this is explained  by the prevalence  of AI applications that interface human beings, as users or  beneficiaries, rather than fabrica tion processes or B2B transactions.  A previous research by Capgemini,  released in mid -202063, showed that only 9% of surveyed government bodies and agencies had been  successful in going beyond the stage of pilot or small -scale deployment o f AI, compared to 27% in life  sciences and – surprisingly enough – 21% in retail and 17% in consumer products.     It remains very difficult (and mission critical) to define a  prompt and clear scalability pathway for  the “average” AI for government applicatio ns. According  to the Boston Consulting Group, this pathway  should consist of 10% introduction of algorithms, 20% of new technologies and 70% of embedment of AI into  the existing business processes and ways of working64. In practice , it is not very frequent that public sector  organizations invest twice as much in people and processes as they do in AI algorithms and technologies .  We add to this that current best practice examples of AI implementation and use in the EU public  sector are not easily retrievable o r accessible65. While many government organizations are indeed  conducting experiments, there is no clear stocktaking of the different initiatives, also to avoid the  replica of similar or identical failure stories . Therefore, it proves difficult to know whic h AI works, which  does not, which contributes to societal goals and which threatens public confidence (AlgorithmWatch, 2020a) .  More proactive sharing of results, both good and bad, from the use of AI in public services or policies , should  be encouraged, such as the establishment of AI repositorie s as initiated by the Cities of Amsterdam, Helsinki  and Nantes, which are already sharing which AI they are using and for which purposes  (Floridi, 2020) . Expanding  this initiative could help both citizens , as well as other city governments,  see what AI really is about and what  value it can bring to them. This calls for the creation of a (probably federated) repository of good practice  examples, widely accessible to potential adopters, less focused on the AI tools having the potential of being  implemented locally66, and more on the characteristics of the public sector envi ronments that would be  surrounding them.   Further to the above, even the AI innovation projects, which  were not successful , should be openly  shared outside the organizational borders. Often, such projects are not made public – unless they  had been negatively  covered in the press, see for example (AIAAIC, 2021)  - which limits peer learning  across other organizations, increasing the odds of the same mistakes occurring again in another project.  This  goal should be part of a broader cultural transformation  of the EU public sector, in the direction of considering  failure as an integral component of any systematic approach to innovation, and even more than so, a  precondition for success  (Stamm, 2018) . One important reason fo r failure is that AI should not be deployed  just because it is possible to use it . While experimentation on proofs of concept should be encouraged,  active deployment of AI should always be aimed at solving a relevant service requirement and  creating public  value67. ICT-enabled innovation in the public sector cannot be disconnected from end user                                                    62 https://www.bcg.com/publications/2021/the -four-stages -of-responsible -ai-maturity    63 https://w ww.capgemini.com/research/the -ai-powered -enterprise/    64 See https://www.bcg.com/capabilities/digital -technology -data/artificial -intelligence    65 See DT4REGIONS  project   The DEP will also call for the creation of AI catalogues in cities (AI catalogues of AI -enabled solutions).   66 For example, in a collection like https://www.thedevmasters.com/ai -tools   67 See AI 4CITIES pre -commercial procurement of AI -enabled solutions by 6 cities for reducing GHG emissions  (https://ai4cities.eu/ ) 
  44   needs and expectations, which might lead to unintended and negative consequences (Benbunan -Fich, Desouza,  & Andersen, 2020) . If too little consideration is given to this aspect during AI implementation, this could lead to  a signif icant backlash by citizens, reducing trust in the administration as well as future AI projects. Given the  tendency of many AI systems to make (significant) errors, and the opacity of AI’s decision support mechanisms,  the opportunity of AI to achieve effici ency gains should be measured against other public values  such as accountability, resilience and inclusiveness.   More generally, a culture of innovation within EU public administration should be encouraged . While  there are still many unknowns with regard to  the effects and potential of AI in government contexts, this should  not be a barrier to trying out (small) experiments and seeing what benefit they could provide to the  administration. Staff who work with policy issues daily are likely to have innovative ideas on how to  improve public services, but often do not have the opportunity to work on these ideas . A risk - and  innovation - adverse culture, limiting public management support or funding, may be one of the root causes why  innovation in the public sector  does not occur. However, for stimulating the use of AI in the public sector, such  a culture should be widely diffused  (in the sense of  Everett Rogers , 2010) .  In this respect, initiatives such as the Experimentation Accelerator in Helsinki could be replicated in other  administrations. This is a new programme where internal  civil staff are encouraged to come up with  innovations utilizing AI, which  can be experimented in a relatively short time  with limited funding.68  Naturally, this goes hand in hand with improving the digital skills and literacy of civil staff . Therefore,  internal training programmes on using data, both generalist as well as specialist, should be encouraged and  introduced to ensure that all public bodies and agencies have access to the capabilities needed for adopting AI  and using AI in their organizations.   To conclude, apart from any further opportunity offered to EU service providers by the ongoing or upcoming AI  governance initiatives in the US and China, only scalability of the most successful applications delivered  by the European GovTech “champions” can  lead Europe to fully grasp the benefits of AI  implementation . Scaling AI is a complex task though, requiring far more than a one -off experimentation in  real or realistic environments .  In the following three sections , we highlight  a set of policy initiativ es, some of which have already been initiated ,  that we see as particularly apt  to counteracting the two clusters of barriers introduced above. Quite interestingly,  most of the m would not duplicate, but simply add to or qualify the contents of the national AI strategies  monitored by AI Watch and overviewed in a previous JRC Science for Policy report  (Misuraca and van Noordt,  2020) . What would ma ke a real difference is the systemic approach, already introduced in Section 3 as part of  a truly European AI governance model, based on a tight collaboration between the European Commission and  Member States (possibly also incl uding Regional and large sized City governments).   Should this collaboration not materialise in full , the EU might be exposed  to the risk of proceeding with   AI innovation in the public sector in an uncoordinated manner69, as the experience of Covid19 tracing   apps during the pandemic crisis has shown.  According to a recent study  by IFRI, the French Institute of  International Relations  (Tonon, 2020) , the persistent lack of an effective  European strategy for the  GovTech   industry  in general, and for AI in government specifically, might result in a  permanent  advantage to  Chinese  and American actors, which benefit from governmental support both at home and abroad.  On this aspect,  leverage towards a more coordinated approach to the defini tion of AI-related standards at the EU level can  support European growth .  However , and despite the lack of comparable empirical evidence in the US and China, our qualitative view is  that the peculiarities and heterogeneities of the public sector are recurr ent phenomena also  in those countries ,  which are therefore experiencing  similar difficulties to the EU in making AI scalable therein . Therefore, our  tentative conclusion  – much in the same way as  we put it  in Section 3 with rega rd to AI governance in general                                                    68 This is an initiative by the city to encourage employees to come up with experiments using AI and scale workable solutions, s ee also :  https://www.hel.fi/uutiset/en/kaupunginkanslia/helsinki -develops -experiment -activities -with-artificial -intelligence    69 EC DG CONNECT has  recently formally relaunched a Member States ‘Expert group on Artificial Intelligence and Digitalisation of  Businesses’. This expert group will specifically focus on AI .One of the main tasks of the group will be to follow -up and implement ation of  the actions proposed in the Coordinated Plan (including for the public sector) , https://ec.europa.eu/transparency/expert -groupsregister/screen/expert -groups/consult?lang=en&groupID=3795  
  45   – is that  the gap between Europe , the US and China , in terms of critical mass for active national “ AI  for government champions” , potentially able to play as global service providers, has chances  to be filled  in, provided the negative influence of market  fragmentation  and lack of policy coordination  is  neutralised .   5.2 Tackling data availability and quality as an example of market failure   As discussed in Section 4, it seems rather uncontroversial that m ost AI technologies – including those developed  for and/or deployed in the public sector – find their rationale and justification in the need to handle large  volumes of data, of various nature and sources, with a speed or sophistication or simply coverage it would be  impossible to reach when only using human reasoning and computing capacity. Indeed, one of the key drivers  of “next generation AI ” (aka Artificial Superintelligence  see Bostrom  (2014 ) and  Yamp olskiy  (2015)    is exactly  the expectation that the growing proliferation of data generated on the fly in all sectors of individual and  community life c ould not be successfully managed, interpreted and turned to the common good without the  use of powerful  AI algorithms and other c omputing , sensing and visualisation techniques that outperform the  sheer possibilities of fered by  our brain and senses.   In this context, it seems more than a bit of a paradox that the top EU industry players, gathered under the  umbrella of the so -called Big Data Value Association (BDVA), presenting itself as “ the private counterpart to the  European Commission to implement the Big Data Value PPP program ”, point at the fundamental lack of “ cross sectoral, unbiased, high -quality and t rustworthy data ” to unleash the potential of AI innovation in Europe and  beyond  (BDVA, 2019) .   If such a lack is evident in industry, one could easily imagine an even worse situation in the public sector. Despite  some 20 years of open data policies, initiatives and exa mples of good practice in Public Sector Information (PSI)  disclosure, there remains room for improvement of open government data sets . The situation can well be  summarized in the following quote from the 2017 edition of the Open Data Barometer: “ Government  data is  usually incomplete, out of date, of low quality, and fragmented. In most cases, open data catalogues or portals  are manually  fed as the result of informal data management approaches. Procedures, timelines, and  responsibilities are frequently uncle ar among government institutions tasked with this work. This makes the  overall open data management and publication approach weak and prone to multiple errors ” (World Wide Web  Foundation, 2017) .  In a recent  paper,  (Concilio & Molinari, 2021)  propose to look at this situation as a textbook example of market  failure – a concept borrowed from the economy – as the existing framework of incentives to PSI  disclosure is evidently not compelling enough to accompany public bodies and agencies across the  whole lifecycle of data publication, maintenance, continuous update, and quality assurance ,  improving the data sharing paradigm . The implications of such lack of incentives are even more substantive  if one consider s the case of an AI solution that uses, but also adds new data to the original set by a continuous  machine inte lligence and decision -making process. Knowing how sensitive the decisions of a n algorithm  can be  to changes of the underlying PSI structure, we can probably realise how seriously the concerns of BDVA should   be taken – before it gets too late.   As a matter o f fact, the February 2020 Communication on “A European strategy for data” (European  Commission, 2020a)  proposed a roadmap of investments and policy measures aimed  at the creation of a  European -governed data sharing space : a sort of “sin gle market for data”, open to the integration of sources  from all over the world , but complying with the European principles and rules of privacy, security, safety and  ethics . The Communication  was followed by a public consultation, which highlighted the i mportance of making  every PSI that possibly holds commercial value  available free of charge, without restrictions and accessible via  Application Programm ing Interfaces  (APIs)70.   Then in November 2020 , the Commission adopted a propos al for Regulation on dat a governance71 (the so called Data Governance Act), which is now under discussion at the E uropean  Parliament.  The proposal buil t on                                                    70 See https://data.europa.eu/en/highlights/data -governance -act-open-data-directive    71 https://ec.europa.eu/digital -single -market/en/news/proposal -regulation -european -data-governance -data-governance -act  
  46   an Impact Assessment exercise, stating that the limited amount of data sharing may be  caused by insufficient   trust and cultur e, by a lack of structures and processes conducive to the collection and reuse of PSI, or by  technical obstacles to the reuse of data  for the common good . Feedback on the Data Governance Act was  received until early February 2021, with the participation of  149 EU organisations72.  The vision  of both policy documents  – the Communication and the Regulation proposal – is to intervene with  concrete actions at the EU level, without interfering with, and possibly building on or facilitating the concurrent  developme nt of sectorial strategies carried out by the Member States.   Using the taxonomy of policy instruments from Vedung (1998)  recalled in  Section 2, we can suggest two distinct  approaches to inspire those actions, one more based on “sticks ”, the other on “ carrots ”:   — The opportunity of the Data Governance Act might be grasped to impose – rather than simply  recommend – the refinement and update of existing data ecosystems as well as their federation   as proposed by the GAIA -X proje ct and AISBL73. Particular attention should be paid to predefin ing and  implementing the  rules of interoperability (in the broadest sense, thus including the cultural, the semantic  as well as the legal and organisational dimensions, alongside the technical o ne, as per the European  Interoperability Framework – EIF  (European Commission, 2017b)74.   — As proposed by Concilio and Molinari (2021), forthcoming , a simpler in tervention – to be coordinated at the  European level, but not necessarily ruled centrally75 – might take the form of provi ding direct subsidies  to regional and local governments  engaged in disclosing and maintaining their own datasets clean ,  updated  and acc essible over time.  Moreover to push the supply (PS) to  meet demand  (businesses), focusing  the effort on opening and maintaining the most usefu l and high value PS datasets.  In so doing, the negative  externalities of the aforementioned market failure  could a t least be reduced, if not fully compensated for.    It seems quite obvious that the two options are neither fully new nor incompatible with one another. Particularly  the former proposal echoes the European Commission’s view to create common data spaces differentiated by  domain, such as for the EU Green Deal supported by the Digital Europe Programme, granting a pivotal role to  climate -neutral and smart cities and communities (European Commission, 2019b, 2020a) . Another similar  initiative is the Covid19 Data Portal76, which was launched in April 2020 to bring together and share relevant  datasets to accelerate coronavirus research. In a similar vein, we might think of building a federation of  local government datasets  with a specific orientation to promoting AI enabled  services according to a reuse  logic.   Federations of datasets can be for example obtained by reinforcing the use of web standards (W3C, 2009)  and  by the permanency of both data sources and technical enablers such as APIs (Grzenda & Legierski, 2019) . The  latter one, in particular , is expected by both data providers and application developers, also and primarily to  develop AI applications that need to access big volume s of data in a fast, updated and reliable way. API -based  access becomes the only choice for some AI applications when near -real-time data streams are exposed. In  particular, high volume, variety and velocity data, requires API -based exposition rather than a file download.  Indeed, the ability to use and design APIs is one of the key competencies identified in a study on open data  value capability architecture (Zeleti & Ojo, 2017) , rewarded by the Open Government Data Portal Index (OGDPI)  proposed by (Thorsby, Stowers, Wolslegel, & Tumbuan, 2017)  and recently recognised as one of the key enablers  of digital government (Boyd, Vaccari, Posada, & Ga ttwinkel, 2020) . The research w ork made at the JRC has also  emphasized the potential of API’s for digital government and includes additional recommendation s on how to  improve the use of APIs across Europe.                                                     72 For more informatio n see https://ec.europa.eu/info/law/better -regulation/have -your-say/initiatives/12491 -Data-sharing -in-the-EUcommon -European -data-spaces -new-rules- and https://data.europa.eu/en/highlights/high -value -datasets   73 https://www.data -infrastructure.eu/GAIAX/Navigation/EN/Hom e/home.html    74 This was also recognised as a priority in the Coordinated Plan on Artificial Intelligence (European Commission, 2018) which r equired  actions to make datasets more easily accessible in practice and facilitate aggregation by adopting the “des ign and implementation of  interoperable data and meta -data formats as well as the deployment of standardised Application Programming Interfaces (APIs)”.   75 For instance, one of the pillars of the EU Recovery and Resilience Facility (RRF) is about digitalisa tion of public administration. See  https://ec.europa.eu/info/business -economy -euro/recovery -coronavirus/recovery -and-resilience -facility _en. In turn, the AI White Paper  (European Commission, 2020d) predicts that “ to stimulate private and public investment, the EU will make available resources from the  Digital Europe Programme, Horizon Europe as well as from the European Structural and Inv estment Funds to address the needs of less -  developed regions as well as rural areas ”.   76 https://www.covid19dataportal.org/   
  47   A feasibility study of either intervention excee ds the scope of this report but could be easily drafted and made  accessible to all EU stakeholders for consultation and contributions in the very short term. As both options are  not necessarily linked to AI requirements, so that released datasets may prove  to serve broader scopes, an idea  might be to “start small” and make an inventory of the kinds of dataset reused in AI in some active  locations  (or specifically indicated in existing data catalogues such as the European Data Portal77) and  suggest them for p ublication in others . On this direction is moving the Data Space for Smart C ommunities   initiative, with the objective of setting up a governance s tructure for data sharing, with a focus on t he most  useful data .  What ever the direction is taken,  we would lik e to stress here the vital need for integrating the EU level  agenda for AI development and deployment with a firmer consideration of data policies and their  implementation prospects , having in mind that for many reasons, the Member State  level may not be t he  most appropriate one to promote data sharing  in a harmonious and effective manner. This would be the first  in a row of three proposed instantiations of our concept of “ European AI policy exceptionalism ”.   5.3 Emphasising AI explainability as another key fac et of accountability   The idea of explaining to lay people – be they the purchasers or the end users of an AI solution – the inner logic  of its learning or inferential algorithm s has always been around as a parallel research thread to the mainstream  thinki ng and is normally referred to as eXplainable Artificial Intelligence (XAI) . This is  not a marketing or  trust building feature , however. Scholars engaged in XAI research have highlighted a number of crucial  dilemmas, which might be more easily solved by opening up the “black box” of machine reasoning and making  it fully transparent and interpretable in its design and ways of operation. Such dilemmas includ e the trade -off  between accuracy and simplicity of the functional descriptions of an AI system (Bernease, 2019) , the so -called  “infobesity” (information overload) versus selective use of info rmation according to the interests or preferences  of target stakeholders (Przegalinska, 2019) , and the reasonableness of a n AI model ’s predictions contrasted  with the  effective power of disruption of the underlying patterns of logic (Gilpin et al., 2018) .     As far as Europe is concerned, the principle of AI explainability has gained recognition after the entry into force  of the GDPR – the EU/EEA General Data Protection Regulation, No. 2016/679 – in May 2018. Articles 13(2)(f),  14(2)( g), and 15(1)(h) of the GDPR require s data controllers to provide data subjects with “ confirmation as to  whether or not personal data concerning him or her are being processed, and, where that is the case, access to  the personal data ” as well as to specifi c information about “ the existence of automated decision -making,  including profiling, referred to in Article 22(1) and (4) and, at least in those cases, meaningful information about  the logic involved, as well as the significance and the envisaged conseque nces of such processing for the data  subject ”. In brief, this set of articles imposes notification duties on data controllers “ to ensure fair and  transparent processing ” whenever AI solutions are in use that have fully or partly automated decision -making  or user profiling . Moreover , the data subjects enjoy a right to access, not only the personal data created  throughout AI processing, as long as it pertains (although as a derivative) to their own profiles, but also a  supplement of technical information conc erning the purpose, nature and modalities of th is innovative way of  data elaboration .   Whether these legal provisions should be considered as the introduction of a new “ right to explanation ” or  the recognition of a pre -existing right has been widely debate d among jurists and philosophers (see e.g. Selbst  and Powles, 2017  for a discussion). Whatever the opinion one may want t o express, the substance of the  problem is clear: not only are data subjects entitled to receive that supplement of information, but its contents  must be “ meaningful ” – i.e. sufficiently detailed and specific to motivate an action, or reaction, from their side.  And the nature of such possible (re)action is well described in Article 22(3) of the GDPR providing that when  automated decision -making is contractually necessary or consensual, certain safeguards for data subjects must  apply, including “ at least the  right to obtain human intervention on the part of the controller, to express his or  her point of view and to contest the decision ”. This is because according to Article 22(1) data subjects “ have the  right not to be subject to a decision based solely on au tomated processing, including profiling, which produces  legal effects concerning him or her or similarly significantly affects him or her ”. Article 22(2) –(4) specifies the  limited circumstances whereby automated decision -making is permitted, and caters for  different safeguards                                                    77 https://data.europa.eu/en   
  48   so that data subjects can effectively exercise their own “ rights and freedoms and legitimate interests ”. Finally,  the non -binding Recital 71 reaffirms that safeguards for data subjects “ should include specific information to  the data subject and the right to obtain human intervention, to express his or her point of view, [and] to obtain  an explanation of the decision reached after such assessment and to challenge the decision ”.  To summarise, the emphasis given by the GDPR to safeguard the “ rights and freedoms and legitimate  interests ” of data subjects when AI solutions are in place has certainly contributed to supporting  the case of AI explainability . However, this is only part of the story. Indeed, depending on the complexity as  well a s the novelty of the AI solution compared with the state of the art, the data controller  itself is likely  to suffer from the same lack of “ meaningful information about the logic involved ” as its data  subjects . This would inevitably impact the users of th e solution, be they employees at the same organisation  that delivers an AI enabled public service or direct beneficiaries of that service or simply external stakeholders  to the service environment, thus formally deprived of the safeguards introduced by Artic le 22 of the GDPR78.   Omitting to consider this broader set of stakeholders is a severe limitation because they belong to the target  community of administrative accountability  - the ability of government to give a satisfactory account of  the use of power an d resources, including,  and though not being limited to, AI in public service. If no proper  account can be given of the way certain decisions are taken by AI - because some of the dilemmas the XAI  literature has singled out are actually in operation – how can the legal obligations to accountability be properly  addressed? More generally speaking, if some of the obstacles to making machine reasoning fully transparent  and interpretable materialise at the stage of solution development, what are the implications  for the purchasing  process itself? Should it be stopped or complemented by an extra round of reflection and evaluation, before –  rather than after – the final solution has gone in to operation?   We conclude this subsection by stressing that despite some re cent attempts at systematising the XAI research  domain, “ there are still important scientific issues that must be tackled. Firstly, there is no agreement among  scholars on what an explanation exactly is and which are the salient properties that should be c onsidered to  make it effective and understandable for end -users, in particular non -experts. Secondly, the construct of  explainability is a concept borrowed from Psychology, since it is strictly connected to humans, and it is also  linked to other constructs  such as trust, transparency and privacy. Thirdly, this concept has been invoked in  several fields, such as Physics, Mathematics, Social Sciences and Medicine. All this make its formalisation and  operationalisation a non -trivial research task ” (Vilone & Longo, 2020) .  Direct financial support  from the EU to a dedicated, inevitably multi -disciplinary, research agenda  on such  topics, would give a tremendous impulse to a knowledge -based approach  to AI implem entation that we  recognize and refer to as the second core instantiation of our proposed concept of “ European AI policy  exceptionalism ”.   Such support would be fully in line with the provisions of the 2019 Communication on ‘Building Trust in Human Centric Artificial Intelligence’, setting out as principles that “ processes and data sets used must be tested and  documented at each step such as planning, training, testing and deployment. This should also apply to AI  systems that were not developed in -house but acquired elsewhere ” and that “ it is important to log and document  both the decisions made by the systems, as well as the entire process (including a description of data gathering  and labelling, and a description of the algorithm used) that yielded the deci sions. Linked to this, explainability  of the algorithmic decision -making process, adapted to the persons involved, should be provided to the extent  possible. Ongoing research to develop explainability mechanisms should be pursued. In addition, explanations   of the degree to which an AI system influences and shapes the organisational decision -making process, design  choices of the system, as well as the rationale for deploying it, should be available (hence ensuring not just data  and system transparency, but a lso business model transparency) ”.(European Commission, 2019a)   5.4 Fully exploiting the degrees of freedom allowed by Innovative Public  Procurement   According to a DG GROW study  (European Commission, 2017a)  only 1,7% of the contract awards in EU28 dated  between 2009 and 2015 saw the involvement of a successful bidder that  was not located in the same country                                                    78 See al so forthcoming EU Digital Principles (DG CNECT D2)  
  49   as the contracting authority and was not domestically owned. In terms of value, the figure was 3% of all  contracts between €1.000 and €200 million documented on the Tenders Electronic Daily  (TED) database.  However, the same percentages increased considerably, up to 21,9% and 20,4% respectively, when the  successful bidder was based in the same country as the contracting authority but was a subsidiary of a foreign  company.   Compared with the private sector, import penetrat ion, or the share of goods and services purchased from other  countries than where the buyer resides, was estimated to be 10% lower in the EU public sector. That was only  an average, however. In fact, the study showed that at the product level, import penet ration was actually more  often higher in the public than in the private sector, while the opposite was true for services, and especially for  crucial  government functions like security, public administration and defence, social security, education and  healt h. These five functions alone represented over 58% of public sector purchasing at the time and were all  heavily tilted towards domestic purchasing. To some extent , this result was unsurprising as the provision of  services is more likely to be dependent on geographical proximity and language barriers. Beside s this, there are  maybe also security and privacy concerns about the subject involved that  holds /stores the data and  about   where the data are stored (especially if it involves personal data)   For instance , 75% of contracts awarded in the Republic of Ireland to non -Irish companies were won by UK  bidders and 69% of the Slovakian ones by Czech firms. Furthermore, certain services are inherently non tradable since they cannot be produced and delivered in separ ate locations. The conclusion was therefore that  in the aggregate, the nature of what is purchased prevails on any other source of domestic bias on the part of  contracting authorities.   The implications of AI take -up for the practice of procurement – especi ally in the private sector – have already  been noted and commented on by many observers before.   Based on a quick survey of the grey literature worldwide, the most prominent impacts and benefits are those  shown in Table 4. With the  needed adjustments, it is possible to argue that they also apply to the corresponding  phases of a public procurement process.  
  50   Table 4. AI-supported public procurement. Overview of potential benefits79.  PROCUREMENT  PHASE  DESCRIPTION OF POTENTIAL IMPACTS  AND BENEFITS  (A) (B) (C) (D) (E) (F)  INTERNAL NEEDS  RECOGNITION  Supplier market innovation scouting based on big data and  advanced analytics to detect new technologies, product  substitutes, new suppliers and start -ups.        PLANNING AND  BUDGETING  Linking the R&D strategy with the procurement strategy and the  project portfolio, supported through digital dashboards/ KPIs, jour  fixes, etc.         PREPARATION OF THE  CALL FOR TENDER  Virtual Personal Assistants guiding the pr ocurers to select the  most appropriate purchasing tools. AI algorithms to find hidden  opportunities across multiple levers.         CALL PUBLICATION AND   HANDLING OF RFI/Q&A  Use of chatbots and virtual assistants as user friendly interfaces  to the prospec tive bidders.   Enhancement of the strategic leadership skills of the  procurement staff.           RECEPTION OF  PROPOSALS  Accelerated execution of procurement activities.           EVALUATION OF  RECEIVED PROPOSALS  Improved profiling of bidders through r efined analyses of their  track records.   Better capacity to analyse and compare received bids.           CONTRACT  NEGOTIATION AND  SIGNATURE  Advanced contract analytics. Improved management of risks and  contingencies. Cognitive procurement advisors providin g  summaries, recommendations and advice           MONITORING OF  CONTRACT EXECUTION  Gathering field information and processing it automatically to  generate performance alerts. Predictive supplier risk management  to detect supplier failures or frauds early on.           PAYMENTS AND  DISPUTE SETTLEMENTS  Digital procure -to-pay solutions. Automated tracking of target  achievements and bonus/malus payments.            CUSTOMER FEEDBACK  AND RECORD KEEPING  Digital claim management system with integrated automa tic  warning systems. Availability of real time spend data.          OTHER  ORGANISATIONAL  BENEFITS  Improved communication and information exchange between the  procurement office and other critical business  functions /departments. Greater automation of menia l tasks.         Key: (a) = Biedron (2020) , (b) = Malone (2019) , (c) = McCrea (2018) , (d) = Prakash (2018) , (e) = Schreiber et al. (2016) , (f) Meulen (2017) .  Source: JRC, own elaboration.     In this scenario, the instrumental rela tions between AI and procurement can become relevant in two  distinct directions :   1. To support the execution of public tender procedures on the one hand , by using AI technologies  within the procurement process.   With such terms as “cognitive procurement” or “procurement 4.0”, the ongoing trend is highlighted towards an  increasing availabili ty of AI resources in support of the purchasing process. However, and to paraphrase the  conclusions of a comprehensive study by (Meulen, 2017) , it is not advisable that all p rocurement phases  embrace AI immediately and at the same time . Despite the plethora of success stories one can hear about, a  feeling to be resisted is the “ fear of missing out, causing a ‘big bang’ adoption approach ”. In fact, not all  technologies have the  same level of maturity, and several organisational factors may condition implementation ,  including the skills and experiences of procurement staff. Therefore, a time frame of 6 to 12 months should be  allowed for even the simplest solutions to generate the ir positive impacts. More complex technology  investments  such as AI supported market intelligence, contract drafting and authoring, and bid evaluation,  among others, should be prioritized in an arc of 12 to 18 months.     2. To promote or accelerate the  penetrat ion of  AI in government , by using innovative procurement  methods as a way to facilitate the introduction of AI within governments   Some of the documents or reports monitored by AI Watch do include invitations to contracting authorities to  adopt AI solutions  to improve the efficiency, timeliness and transparency of tender procedures. In France, the  report entitled “For a meaningful Artificial Intelligence: Towards a French and European strategy” by the                                                    79 See upcoming Ado pt AI programme that will  consider increa sing take up of AI in the Public S ector and in the procurement process itself  
  51   Parliament Member and mathematician Cédric Villani80 analy sed how AI could support public procurement in  enhancing its existing workflows. In the UK, the House of Lords Select Committee on Artificial Intelligence report  entitled “AI in the UK: ready, willing and able?” estimated savings of £4bn a year by the exte nded use of AI  across government departments81. In Belgium, the AI4Belgium program paving the way for a concerted national  strategy highlighted the need for SMEs and contracting authorities to closely collaborate on projects related to  the redesign of publi c procurement processes82. Also, the Norwegian government representatives who  responded in early 2020 to an AI Watch survey did mention the scenario of enhancing procurement processes  using AI technologies, making them more inclusive, accessible, fast and r obust. Finally, Malta was developing  at that time a template for the procurement of emerging technologies (including AI) and would enact a training  and awareness programme for civil servants in order to equip them with the required AI related skills (Misuraca  and van Noordt, 2020) . Does this mean that until we reach a standard way of offering AI services  to public  administration  (e.g. in the c loud – one of the additional priorities of the European Data Strategy Communication )  there will be no future for AI beyond time limited and resource constrained experimentation? Not necessarily,  in our opinion. The reason for this is that apart from the oc casional participation in R&D and innovation projects,  government bodies and agencies do not have a single way to purchase AI , but at least two:   — What we can name “ Traditi onal Procurement ” – i.e. oriented to products and services that are well  established on their market of reference, the technical specifications of which can be clearly and fully  described in the public tender documentation, and the competition for which can be based on the best price  quality ratio, also referred to as MEAT (Most Economical ly Advantageous Offer) . In case the product, service  or process bought is simply new to the public procurer, we can say innovation is not even purchased per se  – as we can assume that someone else has already implemented it before – but for the positive ou tcomes  it brings to the organisation, for instance, because it enables similar or even better services delivered to  the general public at reduced unit costs ;  — And “Innovation Procurement ”, or “Procurement of Innovation ” – where the above characteristics can   be relaxed to some extent. According to an acknowledged definition (European Commission, 2018) , this  term refers to any purchasing process that targets one or both of the following aspects: the process  of  innovation (such as research and development of pr oducts, services or processes, which do not exist yet on  the market) and/or the outcomes  of innovation (a product, service or process that is new to the market or  simply new to the public procurer). In the first instance, the public sector organisation act s as a buyer  of  R&D services. In the second instance, as an early adopter  of third party’s R&D results.   Involving small sized enterprises that can work agile on new AI solutions certainly  require s the use of innovative  procurement schemes. Such use should be encouraged to facilitate more start -ups and smaller  businesses to work together with public administration at all levels .  Around this topic, t he EC has  recently published a study 83on the uptake of emerging technologies in public procurement, which pres ented  potential use -cases for AI in public procurement, set up an online repository of projects and gave  recommendations for the next steps.   A major impulse to Innovation procurement was given by the modernised EU framework (based on the Directives  2014/23 /EU, 2014/24/EU and 2014/25/EU) , which introduced or reinforced the possibility of using a negotiated  procedure  for the adaptation of existing or readily available solutions of particularly complex nature, and/or  the technical specifications of which canno t be established with sufficient precision. In these circumstances, the  competitive procedure with negotiation  or the competitive dialogue  can be used. Alternatively, if the  market does not offer a satisfactory solution or an adaptation of existing solutio ns is unlikely to meet the needs  of the public buyer, R&D services can be procured to develop a tailor -made innovative solution and/or a set of  detailed technical specifications to enable t raditional procurement of the respective products, services or  processes. That is the case where an innovation partnership  or a pre-commercial procurement  procedure  84can be initiated.                                                     80 Available at https://www.aiforhumanity.fr/pdfs/MissionVillani_Report_ENG -VF.pdf     81 See https://publications.parliament.uk/pa/ld201719/ldselect/ldai/10 0/100.pdf    82 See https://www.ai4belgium.be/wp -content/uploads/2019/04/report_en.pdf    83 See https://ec.europa.eu/growth/single -market/public -procurement/digital/emerging -technologies_en   84 See project example AI4CITIES pre -commercial procurement of 6 cities  (https://ai4cities.eu/ ) 
  52   Whatever the approach chosen, the essence of Innovation procurement is to introduce elements of formal  negotiation  between the buyer and t he supplier(s), before, rather than after, the materialisation of an  offer and the award of the same (usually according to the MEAT principle). This together with the fact that  obviously a solution being purchased in this way is relatively far from the mar ket and/or generically or partially  described by the available technical specifications, makes Innovation Procurement the preferred or  recommended way of purchasing AI in government .    Thanks to such negotiation, the public buyer can , to a great extent , transfer most of the AI implementation  risks from the delivery (or contractual) to the bidding (or pre -contractual) phase. In other words,  rather than first selecting the supplier and the solution based on precarious elements of evaluation, and then  jointly undertaking the definition of the technological, organisational, and service level configuration of the  post-implementation scenario, multiple solution options and the respective suppliers can be made to compete  with one another, based on their capacity to  fulfil the stated objectives for the AI initiative in full.   There are of course differences  between the various Innovation procurement procedures in terms of scope  and purpose of the negotiation(s) they admit. For example, in the competitive procedure wit h negotiation , the  public buyer has a more precise idea than in the competitive dialogue of the nature and characteristics of the  solution envisaged. Or in the innovation partnership the negotiation is made before making a price for the entire  set of R&D a ctivities and the delivery of a full blown solution, while in pre -commercial procurement a stepwise  process is followed, never ending with a final purchase of a commercial result but anyway leading to the  definition of multiple viable configurations of the  same target product or service.   In any case, the conclusion is that all these Innovation procurement procedures, if properly carried out, go well  beyond the known advantages – widely explored by both literature and practice – in terms of “smart purchasing ”  in and by government bodies and agencies. With specific reference to AI, they can enable a more prudent  and reflective approach to implementation, which promises to overcome or at least reduce the  likelihood of some of the challenge s outlined in Section 4 in relation to the experimental nature of those  solutions.   Unfortunately, and with a bit of paradox, not the same attention has been spent so far on the way governments  might allocate their financial resources to buy AI soluti ons according to Innovative Procurement rules – in the  EU countries, the 2014 procurement directives and the national legislation transposing them – than on the likely  impacts of AI on the public procurement processes.   Two partial exceptions are:   — The UK Cabinet  Office’s Guidelines for AI Procurement85, issued on 8 June 2020, and   — City of Amsterdam’s contract clauses for procuring T rustworthy AI , and  — The WEF - World  Economic Forum’s - AI Procurement in a Box  toolset, also released in the same month86.  Furthermo re, the reference to public procurement (of innovative, but also tradit ional goods and services) as a  valuable engine for AI to become more widespread is present  the White Paper on Artificial Intelligence  with the  action 6 about the “ Adopt AI Programme ” (European Commission, 2020e)  and in most policy orientation  papers, including from the OECD (Berryhill, Heang, Clogher, & McBride, 2019) , the World Economic Forum, CEPS  (Renda, 2019) , and PWC for the European Commission (forthcoming)87.  However, if we look at the issue in  perspective, it would be highly beneficial for a variety of reasons to pursue  a joint promotion initiative at EU level of both Innovation Procurement and AI in the Public Sector,  highlighting the reciprocal benefits and particularly the extra degrees of f reedom allowed by a correct use of  the former in a view to appropriately implementing the latter.   Part of this initiative should certainly be the sharing of existing good practice s on AI purchasing  from e.g.  the already identified (from the AI Watch team)  case studies, if not a wide capacity building programme  –                                                    85 https://www.gov.uk/governmen t/publications/guidelines -for-ai-procurement/guidelines -for-ai-procurement    86 https://www.weforum.org/reports/ai -procurement -in-a-box   87 Source: https://ec.europa.eu/digital -single -market/en/news/benchmarking -national -innovation -procurement -investments -and-policy frameworks -acros s-europe    
  53   concerted with the Member States – to increase and diffuse the competencies and capacities of “smart AI  purchasing” within the EU national, regional and local public sector bodies and agencies.   Finally, and as a derivative, we might envisage the creation of a freely available collection of technical  tools and maybe templates of tender and negotiation documents , as for example of Amsterdam, turned  into a guidance document (re -usable)  has been  alread y being standardised across the  Netherlands ,  to facilitate  the implementation of AI solutions under controlled conditions. However, a similar booklet to the UK and WEF  examples provided above would already be a (non -minimalistic) start of the process.   With the above, we have exhausted our proposed shortlist of three instantiations of the concept of “ European  AI policy exceptionalism ”. Now the time to move to the end of this short journey.  
  54   6 Conclusion  and way forward   This Section  is composed of three  concept ual blocks.  Paragraph 6.1 proposes to create the conditions for  establish ing a more advanced equilibrium between AI promotion and regulation , to go beyond the predominantly  experimental nature of many observed cases, which can o nly be considered  technological and organisational  singularities . Paragraph  6.2 focuses on the ethical dimension of  AI and the possibility for government bodies  and agencies to  conceive and  become “ first testers”  of trustworthy AI principle s. Paragraph 6.3  concludes with  a summary of the key arguments made throughout the report and relates them to the upcoming work in AI  Watch for the Public Sector activities during the year 2021.   6.1 Governing with AI in the Public Sector   During the Covid19 pandemic , interest in AI has not lessened. In particular , as shown in a recent JRC publication  (De Nigris et al., 2020)  its great potential  was acknowledged to assist clinical research , ensure better compliance  with quarantine  obligations  and contact tracing requirements , measure and predict mobility behaviours and  virus diffusion t rends . Moreover , due to  the restrictions  accompanying the  lockdown , AI has been regarded  as a key technolog y to tackl e and cop e with the associated changes in work, study and life practices   (Naudé, 2020)  as well as to tackle environmental challenges (monitor, react, pr edict)  The enthusiasm on  harnessing the benefits provided by a responsible and trustworthy use of AI has therefore stayed very high on  the policy and media agenda.  Some countries, like Estonia, had committed to introducing at least 50 working  AI applications in the Public Sector by the end of 2020 (Government of the Republic of Estonia, 2019) , which  has been successful ly achieved.   First, AI reposi tories  have been introduced in some EU cities . This highlight the extremely important role of  transparency when approaching AI. The obscurity of  algorithms is something that public administrations have  to take into account, not only for their internal ethi cal judgments but also for clarify ing to citizens and firms  how the algorithm is used and why and to what extend the algorithm is trustable. For this, publicly available  repositories, inventories or registers of AI in  use at public administrations is a nec essary starting point for  providing transparency, explanations and trust in the use of AI in government.   Second, the possible role of Digital Innovation Hubs has been considered to bring together various actors,  share knowledge and best practices. This is  fostering the systemic approach on AI where different competences  should be brought together for the appropriation of an AI solution by public administrations , by bringing the  local AI ecosystem together and sharing best practices in both developing and a pplying AI within the  organisation .   Covid19 has also interfered – negatively this time – with the pace of development of some of the cases from  EU (MS and AS) national, regional and local government presented in July 2020 by the AI Watch for the Public  Sector initiative  (Misuraca and van Noordt, 2020) . With the focus now being narrowed down on the most  inspiring  ones, which are further explor ed through an online survey88 and specific interviews with the case  owners, a preliminary conclusion is that not only the AI technologies, but also their uses are rather diverse and  the respective maturity levels, geogra phic quite heterogeneous. Finally, th e geographical spread and thematic  scope  of reported cases were indeed wide, but also unevenly distributed across Member States, government   functions, and tiers of public administration .   Apart from the obvious limits of representation of this quantitative  analysis, a comparison with the US and  China points at a lower level of integration of the various systems and applications, and therefore  a less pronounced capability to quickly scale up . However, the situation in terms of AI take -up rates and  diffusion of consolidated technologies doesn’t seem much different from Europe, particularly looking at local  public administration and the smallest sized bodies and agencies. What is really worrisome is the fragmentation  of the EU single market for GovTech solution s in general and AI -enabled specifically, which is more prominent  than in the other countries and should be overcome by a supplement of policy coordination  among the  key European stakeholders .                                                    88 https://ec.europa.eu/eusurvey/runner/IA -of-AI-public -sector  
  55   Such coordination should operate at three distinct, “ ecosystemi c” levels : European , national /regional  and  organisational .   — At the European  level (i.e. the predominant space of coordination between the European Commission and  the Member States)  the aggregation of existing experiences and good practice examples should b e oriented  at creat ing the next generation of AI enabled public services  and processes  - inspired by value  creation and human centricity principles  - the technological roots of which could  be made common, and the  respective instantiations interoperable by default; thus, turning the limited technology maturity of AI and  the correlated need for experimentation, from a barrier into an opportunity for the accelerated digital  transformation of the entire EU government.   — At the national /regional  level  (i.e. the  Member State  area of legal and jurisdictional competence, but also  recommended cooperation between Member and Associated States, as stipulated by the Coordinated Plan  on AI) shared resources and collaboration spaces should be established - including e.g. leg al and  administrative sandboxes, data repositories, etc. - to promote the instantiation of processes of reuse and  scaling (up/out/deep) of individual take-up cases  recognised as excellent or simply replicable with the  needed adjustments, in other national or multi -national Public Sector environments .    — At the organisational  level  i.e. (where punctual or singular AI solutions are adopted and implemented in  the specific Public Sector environments) the generation of new success stories  in digital   transformatio n of existing public services or p rocesses should be enhanced by appropriate  public  procurement guidelines,  capacity building and training initiatives89 of Public Sector staff , data literacy  programmes for adults and students , reforms of administrative and legal instruments, etc.   With more and more government bodies and agencies utilising AI, or planning to do so , the issue of financially  supporting Public Sector demand is also very relevant.  Compar ed with the EU with the US government budget  allocations to ICT R&D – which AI experimentation or innovation is part of – Europe needs to regain order  of magnitude in terms of PPS  (Purchasing Power Standard90) expenditure .   Just to give three examples:   — The European Commission’s reported investment on AI in the (stil l ongoing , in terms of funded projects )  Horizon 2020 programme  for R&D and innovation has been in the range of €1,5 billion having the entire  economy as the target91, thus including, though not being limited to, public administration as an application  field.  — Further to that, the new Digital Europe Programme (DEP)  which aims to build a diffused infrastructural  and knowledge capacity for AI in Europe, complementing other EU programmes such as Horizon Europe for  research and innovation and the Connecting Europe Facility for digital infrastructure, originally proposed a  budget of €2,2 billion92 – still waiting for a final definition in the approved Multiannual Financial Framework  2021 -2027 – for opening up the use of AI in both the private and the public sectors.   — Finally, Artificial Intelligence and Human Machine Interfaces are already in the scope of a Thematic Smart  Specialisation Platform  co-led by the Emilia -Romagna Region and the National government of Slovenia  since May 201893. Although the scope of the S3 Platform seems currently limited to promoting the  deployment of a few demonstrative cases in the AI field, it seems reasonable to predict that such  partnership will grow up and consolidate even further in the new programming period  2021 -2027 , including  a possible extension to government case studies94.                                                    89 DT4REGIONS will develop training material and MOOC to help regions implement AI .   90 https:// ec.europa.eu/eurostat/statistics -explained/index.php?title=Glossary:Purchasing_power_standard_(PPS)   91 https://ec.europa.eu/info/research -and-innovation/research -area/industrial -research -and-innovation/key -enabling -technologies/artificial intelligence -ai_en     92 https://ec.europa.eu/digital -single -market/en/europe -investing -digital -digital -europe -programme    93https://s3platform.jrc.ec.europa.eu/ en-US/w/interregional -partnership -for-smart -specialisation -on-artificial -intelligence -and-human machine -interface   94 Curren tly it includes 2 Member States and 10 NUTS -2 Regions, namely: Emilia -Romagna and Autonomous Province of Trento (IT), Slovenia  (SI), Baden -Württemberg (DE), Navarra (ES), North -Brabant and East Netherlands (NL), Salzburg (AT), Hungary (HU), Provence -Alpes -Cote  d'Azur and Auvergne -Rhone -Alpes (FR), Örebro -lan (SE).   
  56   Thus, in their mul tiple roles of early adopters, promoters and facilitators, not only rule setters and supervisors,  EU governments at all levels and in all Member States, regions and cities can do a lot to make AI Innovation  far more widely impactful than a technological or  organisational singularity .  Having in mind the conspicuous heterogeneity of the EU national strategies for AI established until now, it is  probably important to reach a broader consensus on a set of common actions that could be conferred to the  EU regulat ory or soft coordinating level, in order to promote a more harmonised approach to AI implementation  in public administration, cutting across the country differences and valorising the peculiar aspects of the Public  Sector as a whole.   Conversely, innovation  policies of Member States and Regions should not stay focused on stimulating the  deployment of AI per se , without considering that such technologies may not be the answer for each and every  issue  related to service improvement or transformation . However, there have been important achieve ments  that could be regarded as crucial to ensure that the challenges of Public Sector digitalization are being  overcome, and that could serve as inspiration to use AI sustainably and durably .    To help systematize the curr ent scenario analysis and point at credible directions for improvement, another,  ongoing activity  of AI Watch  will be a collection of policy recommendations taking the shape of a n EU-wide  roadmap for securing the transition to AI enabled and digitally tran sformed government.   6.2 On governing AI  in the Public Sector   Governing AI is as relevant as a policy issue as using it for government or governance related purposes.  Especially in the EU, this issue has been answered  in terms of an ethical approach to the deve lopment and  deployment of such technologies in operating environments.   The High -Level Expert Group on AI published a set of 7 key requirements in order to ensure that AI is  trustworthy  (High -Level Expert Group on Artificial Intelligence (HLEG), 2019) . Through the Assessment List for  Trustworthy AI (ALTAI)95, developers and deployers of AI can assess  by themselves whether their solution s  are in line with these principles (High -Level Expert Group on AI (HLEG), 2020) . The assessment list is  intended for use  by a multidisciplinary team of people , each having specific competen cies on the various  requirements. It is expected that by following the Assessment List, organizations implementing new AI systems  or applications can identify associated risks and consequently act to minimize or even avoid th em. The  Assessment List is made  with flexibility in mind and encourages organizations to further develop the guidelines  to fit  into their specific sector as well. Such guidelines and requirements are also key to include within AI  Procurement procedures, as key risks of AI could be mitig ated already at the start, during and following the  completion of procurement processes.   A related, though not completely clear concept is Ethical AI. Great progress has been recently made in igniting  a worldwide debate on this topic, although the various  stakeholders have slightly different interpretations of it.  AlgorithmWatch keeps an inventory of all published AI ethical guidelines, which is currently including more than  160 different publications from all over  the world  (AlgorithmWatch, 2020b) . Previous research had  analyse d 84 ethical AI documents published by various business es, NGOs  and (international) governmental  organizations, highlight ing that some principles such as tra nsparency, fairness, justice, and responsibility were  quite common  in all. However , not a single one of th ose principles was found in all of the scrutinised documents  (Jobin, Ienca, & Vayena, 2019) . Despite this, many governments worldwide have issued policy documents  highlighting the n eed for ethical AI  (European Parliamentary Research Service (EPRS), Scientific Foresight  Unit (STOA), 20 20). This is also the case of most national strategies of EU countries monitored by the AI Watch  initiative  and has been highlighted by the recent “Proposal for a Regulation laying down harmonised rules on  artificial intelligence ( Artificial Intelligence Act)”96.  The development  and deployment of ethical AI applications could involve governance  challenges  in the Public  Sector . These are  made more serious by the commitment of public administration to be accountable , not  only for its decisions and decision -making mechanisms but also for the – anticipated or unwanted – societal  implications of moving from the realm of AI experimentation to the permanent embedment  of AI solutions  in                                                    95 https://futurium.ec.europa.eu/en/european -ai-alliance/pages/altai -assessment -list-trustworthy -artificial -intelligence   96 https://digital -strategy.ec.europa.eu/en/library/proposal -regulation -european -approach -artificial -intelligence   
  57   processes and services . This poses the question of whether more concrete and ope rationalised ethical AI  guidelines could  be proposed and tested first within a public administration environment , for  example within “regulatory sandboxes”97 and with AI Testing and Experimentation Facilities .  Such a question is not easy to answer . For exam ple, self-attributed guidelines  could possibly be designed by an  external panel of experts (such as the HLEG on AI) and then be used by government bodies and agencies in  relation to the service to be delivered. An alternative option would be to rely on som e of the (even too many)  templates and blueprints that can be retrieved in the state of the art. There are also ongoing standard setting  efforts, for example at IEEE, which are reported about by (European Parliamentary Research Service (EPRS),  Scientific Foresight Unit (STOA), 2020) . However, we think it is more likely that in different countries and layers   of public administration (e.g. cities or regions) the preference would go towards developing their own guidelines  rather than using those made available by other Public Sector organisations. In which case, apart from the issue  of finding adequate resource s to support the activity, the risk of proliferation of approaches and  interpretations  would still become apparent.   Moreover , this does not assure that involved staff would understand and operationalize these guidelines in an  intended way. Therefore, it is crucial for governments to anticipate how guidelines will be worked with  and whether the users of those guidelines have the appropriate expertise and capacity to apply  them . For example, Digital Innovation Hubs  should be able to support public administrat ions with procurement  and be multipliers of useful templates and processes.  This echoes the discourse made in this report on the  crucial importance of specific training and cultural transformation of civil servants involved in AI development  and deployment .  6.3 Main insights from the report towards an analytical framework for evaluating  AI impact in government     To conclude, Figure 6 summari zes and offers a visual representation of  the key arguments made throughout  this report . Those ar guments can be considered as the first attempt at an analytical framework for eva luating  AI impact in government.   Figure 6. Analytical framework for AI impact assessment.     Source: JRC, own  elaboration .                                                    97 https://digital -strategy.ec.europa.eu/en/library/proposal -regulation -european -approach -artificial -intelligence    
  58   The four analytical dimension s of the framework include: design, adoption, implementation and use of AI  solutions in the Public Sector . Let’s now comment on them in turn :  — During the design  phase, a key contextual element to borrow is the need for explainable  AI. This has been  already discussed in Paragraph 5.3 as well as  in the previous one. The main potential benefit, also self reinforcing in case the feedback loop acts in the right direction, can be grasped in terms of accountability  for th e government body or agency engaged in this exercise. There can be other relevant aspects of course,  but the idea is to focus on the most important ones. Note that the discourse previously made on AI can be  fully recovered here. Finally, a  testable implica tion is that whenever explainable AI is given emphasis to,  the level of accountability (however measured) increases, both within the same and between different  public sector organisations.   — During the adoptio n phase, the principles of trustworthy AI  find ap propriate room . Indeed, this is the locus  of experimentation, where technology is tested and evaluated for potential use. Again, some of the  arguments made in paragraph 6.3 – especially on the importance of co -design  together wi th end users and  stakeholders  – can and should be referred  to here . A testable implication can be that the more services are  co-created , the better their “smart” alignment with  Assessment List for Trustworthy Artificial Intelligence   (ALTAI )98 requirements – where smart means that the benefits would largely outnumber the critical aspect s  of ethical compliance .  — During the implementation  phase, as it is known from the definition and analysis provided in Section 2,  the main expectatio n is to permanently embed the AI innovation into the involved government body’s or  agency’s business practice. Therefore, a strong recommendation coming from the external context is to  make this innovation user centric , as far as the associated digital pub lic services are concerned. In so doing,  the chances of transforming the “business of government” in a visibly durable and sustainable fashion  should probably be enhanced. This can also be the testable implication of this feedback loop: the more user  centr ic is the AI enabled services while in operation, the more pervasive and radical will be the  transformation  of government practice .  — During the use phase, citizens and businesses enjoy the benefits and suffer from the criticalities of AI  enabled public proc esses and services. Here the known concept of co-production  should be made applicable  so that beneficiaries are actively and seamlessly engaged in co -delivering (and perhaps, also co -evaluating)  the promise of government transformation. This is expect ed to  contribute to legitimising public  administration in the eyes of its reference stakeholders and therefore enhance the level s of confidence and  trust within the constituency . Based on the currently  too immature stage of most AI applications  in the  state of the art , it is doubt ful that sufficient empirical evidence exists to support this testable implication .  However , this stream of  field research would also contribute to answering the broader question of whether  AI innovation improves  or undermines  governmen t’s democratic legitimacy.   How the future of AI -enabled innovation in government is going to look like depends in our opinion  largely on the four analytical dimensions outlined above, and if the related feedback loops are  reinforced and in which direction (i.e. as “virtuous” or “vicious” cycles) in  the coming years. In fact, history  tells us that the Public Sector’s digital transformation has not proceeded  as linear ly or predictabl y as it is often  mentioned, but in a more  complex  and full of ups and downs  way, depending on a variety of contingent  factors  (Barcevičius et al., 2019) .  In this situation,  what we propose to do in the future analysis is to start with this analytical framework and to  integrate  it with  the known definition of AI, which also the White Paper has made its own (see European  Commission, 2020e , p. 2), with the following simple, yet clear -cut statement: AI is not only about algorithms,  data and computing power , but also about people . Therefore, its implementation may n ever be  completely successful is only done “for” the people, but needs to be done together “with” them .  This attitude will probably help break the ultimate barrier preventing the inclusion of governm ent in the range  of the downstream industries affected by the concurrent adoption and widespread implementation of AI as a  General Purpose Technology, driven by the convergent attitude of multiple actors – both public and private –  who use it as an input t o enhance the performance (however defined, but without excluding ethical and societal  compliance) of the respective application environments.                                                     98 https://digital -strategy.ec.europa.eu/en/library/assessment -list-trustworthy -artificial -intelligence -altai-self-assessment  
  59   Based on the results illustrated in this report, f uture work will be dedicated to use the analytical framework  conclusions in the development of a generic implementation Roadmap for the use of AI in the Public Sector and  to increase a diffused human -centric and value -creation oriented AI deployment in the European Public Sector  and may  possibly  serve as a concrete in put to the Better Regulation package99.                                                    99 https://ec.europa.eu/info/law/law -making -process/planning -and-proposing -law/better -regulation -why-and-how_en   
  60   List of abbreviations   AI Artificial Intelligence   AIA Algorithmic Impact Assessment   API Application Programming Interface   AS Associated State(s)   BDVA  Big Data Value Association   COFOG  Classification Of the Functio ns Of Government   EEA European Economic Area   EU European Union   GBARD  Government Budget Allocation for R&D   GDP Gross Domestic Product   GDPR  General Data Protection Regulation   GovTech  Government Technology   GSA General Services Administration   HLEG  High Level Expert Group   ICT Information and Communication Technology   IoT Internet of Things   JRC Joint Research Centre   MEAT  Most Economically Advantageous Tender   MS Member State(s)   NACE  Nomenclature statistique des Activités économiques dans la Communauté Européenne   OECD  Organisation for Economic Cooperation and Development   OGDPI  Open Government Data Portal Index   PCP Pre-Commercial Procurement   POINT  Projecting Opportunities for INdustrial Transitions   PPI Public Procurement of Innovation   PPS Purchasing  Power Standard (s)  PSI Public Sector Information  
  61   Q&A Questions and Answers   R&D Research and Development   RFI Request For Information   RRF Recovery and Resilience Facility   S3 Smart Specialisation Strategy   SDGs  Sustainable Development Goals   TED Tenders  Electronic Daily   TRL Technology Readiness Level   UN United Nations   WEF World Economic Forum   XAI eXplainable Artificial Intelligence  
  62   List of figures   Figure 1. Technology approp riation disentangled.  ................................ ................................ ................................ ................................ ...... 13  Figure 2. The proposed analytical framework.  ................................ ................................ ................................ ................................ .............  15  Figure 3. Propensity to adopt AI across EU -27 enterprises.  ................................ ................................ ................................ .................  23  Figure 4. Gross Domestic Expenditure on R&D by sector of performance, EU -27, 2008 -2018 (% relative to  GDP).  ................................ ................................ ................................ ................................ ................................ ................................ ................................ ........ 31  Figure 5. Key challeng es to government legitimacy by AI adoption.  ................................ ................................ ..............................  37  Figure 6. Analytical framework for AI impact assessment.  ................................ ................................ ................................ ..................  57   
  63   List of tables   Table 1. Tentative list of contextual factors.  ................................ ................................ ................................ ................................ .................  16  Table 2. EU -27 vs. US Public Budget Allocations to ICT R&D in Government (millions of current EUR PPS)  ........ 32  Table 3. User centricity cultivation within the process of AI appropriation.  ................................ ................................ ...............  40  Table 4. AI -supported public procurement. Overview of potenti al benefits. ................................ ................................ ..............  50   
  64   References   AIAAIC. (2021). AI, algorithmic and automation incident and controversy repository (AIAAIC)  repository.  Retrieved May 4, 2021, from https://www.aiaaic.org/aiaaic -repository   AlgorithmWatch. (2020a). Automating society report 2020 . Retrieved from  https://automatingsociety.algorithmwatch.org/wp -content/uploads/2020/12/Automating -Society Report -2020.pdf   AlgorithmWatch. (2020b , April). AI Ethics Guidelines Global Inventory. Retrieved December 15, 2020, from  https://inventory.algorithmwatch.org/   Allam, Z., & Dhunny, Z. A. (2019). On big data, artificial intelligence and smart cities. Cities , 89, 80–91.  https://doi.org/10.1016/j. cities.2019.01.032   Alzahrani, L., Al -Karaghouli, W., & Weerakkody, V. (2017). Analysing the critical factors influencing trust in e government adoption from citizens’ perspective: A systematic review and a conceptual framework .  Retrieved from https://brads cholars.brad.ac.uk/handle/10454/11683   Andergassen, R., Nardini, F., & Ricottilli, M. (2016). Innovation diffusion, general purpose technologies and  economic growth. Structural Change and Economic Dynamics , 40.  https://doi.org/10.1016/j.strueco.2016.12.003   Andersen, K. N., Lee, J., & Henriksen, H. Z. (2020). Digital sclerosis? Wind of change for government and the  employees. Digit. Gov.: Res. Pract. , 1(1), 1 –14. https://doi.org/10.1145/3360000   Arrieta, A. B., Díaz -Rodríguez, N., Del Ser, J., Bennetot, A., Ta bik, S., Barbado, A., … Herrera, F. (2019). Explainable  Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI.  ArXiv:1910.10045 [Cs] . Retrieved from http://arxiv.org/abs/1910.10045   Bachman, B., & Bozzone, S . (2011). Pervasive innovation: Taking innovation throughout the organization.  Business and Information Technology Faculty Research & Creative Works . Retrieved from  https://scholarsmine.mst.edu/bio_inftec_facwork/132   Bagozzi, R. P. (2007). The legacy of th e technology acceptance model and a proposal for a paradigm shift.  Journal of the Association for Information Systems , 8(4). https://doi.org/10.17705/1jais.00122   Bailey, D. E., & Barley, S. R. (2019). Beyond design and use: How scholars should study intell igent technologies.  Information and Organization , 30(2), 100286. https://doi.org/10.1016/j.infoandorg.2019.100286   Barbero, M., Coutuer, J., Jackers, R., Moueddene, K., Renders, E., Stevens, W., … Versteele, D. (2016). Big data  analytics for policy making . Retrieved from Deloitte website:  https://joinup.ec.europa.eu/sites/default/files/document/2016 07/dg_digit_study_big_data_analytics_for_policy_making.pdf   Barcevičius, A. E., Cibaitė, G., Gineikytė, V., Klimavičiūtė, L., Matulevič, L., Misuraca, G., & Vanin i, I. (2019). Exploring  digital government transformation in the EU  (No. EUR 29987). https://doi.org/10.2760/17207   Barley, S. R. (1986). Technology as an occasion for structuring: Evidence from observations of CT scanners and  the social order of radiology departments. Administrative Science Quarterly .  https://doi.org/10.1017/CBO9780511618925.007   Bassetti, T., Borbon Galvez, Y., Del Sorbo, M., & Pavesi, F. (2020). Artificial Intelligence – impact on total factor  productivity, e -commerce & fintech  (JRC No. EU R 30428). Retrieved from Publications Office of the  European Union website: https://publications.jrc.ec.europa.eu/repository/handle/111111111/61622   BDVA. (2019). Towards a European data sharing space —Enabling data exchange and unlocking AI potential .  Retrieved from  https://www.bdva.eu/sites/default/files/BDVA%20DataSharingSpace%20PositionPaper_April2019_V1. pdf  Benbunan -Fich, R., Desouza, K. C., & Andersen, K. N. (2020). IT -enabled innovation in the public sector:  Introduction to the special issue. European Journal of Information Systems , 29(4), 323 –328.  https://doi.org/10.1080/0960085X.2020.1814989   Bernease, H. (2019). The promise and peril of human evaluation for model interpretability. ArXiv:1711.07414  [Cs, Stat] . Retrieved from http://arxiv.org/abs/1711.0 7414  
  65   Berryhill, J., Heang, K. K., Clogher, R., & McBride, K. (2019). Hello, World: Artificial intelligence and its use in the  public sector . Retrieved from OECD website: https://www.oecd -ilibrary.org/governance/hello world_726fd39d -en  Biedron, R. (2020, Ju ne 17). Artificial Intelligence in procurement. Retrieved May 3, 2021, from PLANERGY  Software website: https://planergy.com/blog/ai -in-procurement/   Borrás, S., & Edler, J. (2020). The roles of the state in the governance of socio -technical systems’ transfo rmation.  Research Policy , 49, 103971. https://doi.org/10.1016/j.respol.2020.103971   Bostrom, N. (2014). Superintelligence: Paths, dangers, strategies  (Reprint edition). OUP Oxford.   Boyd, M., Vaccari, L., Posada, M., & Gattwinkel, D. (2020). An Application P rogramming Interfaces (APIs)  framework for digital government.  Retrieved from Publications Office website:  https://data.europa.eu/doi/10.2760/772503   Bradford, A., & Posner, E. A. (2011). Universal exceptionalism in international law  (SSRN Scholarly Paper N o. ID  2770597). Retrieved from Social Science Research Network website:  https://papers.ssrn.com/abstract=2770597   Bruno, I., Schiavone Panni, A., Marchetti, V., Molinari, F., & Valente Covino, B. (2020). A multi -dimensional  framework to evaluate the innovat ion potential of digital public services: A step towards building an  Innovative Public Services Observatory in the EU  [EUR - Scientific and Technical Research Reports].  https://doi.org/10.2760/09628   Burrell, J. (2016). How the Machine “Thinks:” Understandi ng Opacity in Machine Learning Algorithms. Big Data  & Society , January -, 1–12. https://doi.org/10.2139/ssrn.2660674   Calzada, I., & Almirall, E. (2020). Data ecosystems for protecting European citizens’ digital rights. Transforming  Government: People, Proce ss and Policy , 14(2), 133 –147. https://doi.org/10.1108/TG -03-2020 -0047   Campion, A., Gasco -Hernandez, M., Jankin Mikhaylov, S., & Esteve, M. (2020). Overcoming the challenges of  collaboratively adopting Artificial Intelligence in the public sector. Social S cience Computer Review ,  0894439320979953. https://doi.org/10.1177/0894439320979953   Cantner, U., & Vannuccini, S. (2012). A new view of general purpose technologies  (No. 2012 –054). Retrieved  from Friedrich -Schiller -University Jena website: https://ideas.rep ec.org/p/jrp/jrpwrp/2012 -054.html   Carrasco, M., Mills, S., Whybrew, A., & Jura, A. (2019a). The Citizens Perspective on the Use of AI in Government .  Retrieved from https://www.bcg.com/publications/2019/citizen -perspective -use-artificial -intelligence govern ment -digital -benchmarking   Carrasco, M., Mills, S., Whybrew, A., & Jura, A. (2019b). The Citizens Perspective on the Use of AI in Government.  In Boston Consulting Group .  Carroll, J. (2004). Completing design in use: Closing the appropriation cycle . 337 –347.  Cath, C., Wachter, S., Mittelstadt, B., Taddeo, M., Floridi, L., Wachter, S., … Cath, C. (2018). Artificial Intelligence  and the ‘Good Society’: The US, EU, and UK approach. Science and Engineering Ethics , 24(2), 505 –528.  https://doi.org/10.1007/s11948 -017-9901 -7  Center for Digital Government, IBM, & NASCIO. (2019). Delivering on Digital Government: Achieving the Promise  of Artificial Intelligence . Retrieved from  https://iapp.org/media/pdf/digital_government_artificial_intelligence.pdf   Chen, T., Ran, L., &  Gao, X. (2019a). AI innovation for advancing public service. Proceedings of the 20th Annual  International Conference on Digital Government Research , 100 –108.  https://doi.org/10.1145/3325112.3325243   Chen, T., Ran, L., & Gao, X. (2019b). AI innovation for a dvancing public service. Proceedings of the 20th Annual  International Conference on Digital Government Research , 100 –108.  https://doi.org/10.1145/3325112.3325243   Choi, T., & Chandler, S. M. (2015). Exploration, Exploitation, and Public Sector Innovation: A n Organizational  Learning Perspective for the Public Sector. Human Service Organizations: Management, Leadership &  Governance , 39(2), 139 –151. https://doi.org/10.1080/23303131.2015.1011762   Cognilytica. (2020). Global AI Adoption Trends & Forecast 2020 . Ret rieved from  https://www.cognilytica.com/2020/01/22/global -ai-adoption -trends -forecast -2020/  
  66   Coiera, E. (2019). The last mile: Where Artificial Intelligence meets reality. Journal of Medical Internet Research ,  21(11), e16323. https://doi.org/10.2196/16323   Concilio, G., & Molinari, F. (2021). The un -exploitable smartness of open data. Sustainability . Retrieved from  Forthcoming   Craglia, M., Annoni, A., Benzcur, P., Bertoldi, P., Delipetrev, B., De Prato, G., … Vesnic Alujevic, L. (2018). Artificial  intelligenc e: A European perspective  (JRC No. EUR 29425 EN). Retrieved from Publications Office of the  European Union website: https://ec.europa.eu/jrc/en/publication/artificial -intelligence -european perspective   Creemers, R. (2018a). China’s social credit system: An evolving practice of control. SSRN Electronic Journal ,  222(2015), 59 –71. https://doi.org/10.2139/ssrn.3175792   Creemers, R. (2018b). China’s Social Credit System: An Evolving Practice of Control. SSRN Electronic Journal ,  222(2015), 59 –71. https://doi.org/10 .2139/ssrn.3175792   Dalla Benetta, A., Maciej, S., & Nepelski, D. (2021). AI watch: 2020 EU AI investments .  https://doi.org/10.2760/0175141   Danaher, J. (2016). The threat of algocracy: Reality, resistance and accommodation. Philosophy and Technology ,  29(3), 245–268. https://doi.org/10.1007/s13347 -015-0211 -1  Dawes, S. S., Vidiasova, L., & Parkhimovich, O. (2016). Planning and designing open government data programs:  An ecosystem approach. Government Information Quarterly . https://doi.org/10.1016/j.giq.2016.01 .003  De Nigris, S., Gómez -González, E., Gómez Gutierrez, E., Martens, B., Iglesias Portela, M., Vespe, M., … Junklewitz,  H. (2020). Artificial Intelligence and Digital Transformation: Early lessons from the COVID -19 crisis,  Craglia, M. editor(s)  (JRC No. EUR 30306 EN). https://doi.org/10.2760/166278   De Prato, G., López Cobo, M., Samoili, S., Righi, R., Vázquez -Prada Baillet, M., & Cardona, M. (2019). The AI techno economic segment analysis  (JRC No. EUR 29952). Retrieved from Publications Office of the Europ ean  Union website: http://op.europa.eu/en/publication -detail/ -/publication/d4893b4e -0f38 -11ea -8c1f01aa75ed71a1/language -en  Delaney, P., Timbrell, G., & Chan, T. (2008). A marxian model of technology appropriation. Proceedings of the  JAIS Theory Developmen t Workshop. Sprouts: Working Papers on Information Systems , 8(1), 1 –37.  Desouza, K. C., Dawson, G. S., & Chenok, D. (2020). Designing, developing, and deploying artificial intelligence  systems: Lessons from and for the public sector. Business Horizons , 63(2), 205 –213.  https://doi.org/10.1016/j.bushor.2019.11.004   Dignum, V. (2018). Ethics in artificial intelligence: Introduction to the special issue. Ethics and Information  Technology , 20(1), 1 –3. https://doi.org/10.1007/s10676 -018-9450 -z  DiMaggio, P. J., & P owell, W. W. (1983). The iron cage revisited: Institutional isomorphism and collective  rationality in organizational fields. American Sociological Review , 48(2), 147 –160.  https://doi.org/10.2307/2095101   Dressel, J., & Farid, H. (2018). The accuracy, fairne ss, and limits of predicting recidivism. Science Advances , 4(1),  eaao5580. https://doi.org/10.1126/sciadv.aao5580   Dwivedi, Y. K., Hughes, L., Ismagilova, E., Aarts, G., Coombs, C., Crick, T., … al,  et. (2019). Artificial Intelligence  (AI): Multidisciplina ry perspectives on emerging challenges, opportunities, and agenda for research,  practice and policy. International Journal of Information Management , (August), 101994.  https://doi.org/10.1016/j.ijinfomgt.2019.08.002   Edquist, C. (2001). The systems of innov ation approach and innovation policy: An account of the state of the art .  El-Haddadeh, R., Weerakkody, V., Osmani, M., Thakker, D., & Kapoor, K. K. (2019). Examining citizens’ perceived  value of internet of things technologies in facilitating public sector  services engagement. Government  Information Quarterly , 36(2), 310 –320. https://doi.org/10.1016/j.giq.2018.09.009   Elliott, H. (2020a). The AI powered State: China’s approach to public sector innovation. Retrieved May 1, 2021,  from https://www.nesta.org.uk/ feature/ai -powered -state/   Elliott, H. (2020b). The AI Powered State: China’s approach to public sector innovation .  Elzen, B., Geels, F. W., & Green, K. (2004). System innovation and the transition to sustainability: Theory, evidence  and policy . Edward Elga r Publishing.  
  67   Engstrom, D. F., Ho, D. E., Sharkey, C. M., & Cuéllar, M. -F. (2020a). Government by Algorithm: Artificial Intelligence  in federal administrative agencies . Retrieved from https://www.ssrn.com/abstract=3551505   Engstrom, D. F., Ho, D. E., Sharke y, C. M., & Cuéllar, M. -F. (2020b). Government by Algorithm: Artificial Intelligence  in Federal Administrative Agencies. In SSRN Electronic Journal . https://doi.org/10.2139/ssrn.3551505   European Commission. (2011). Social experimentation: A methodological guide for policy makers . Retrieved  from https://ec.europa.eu/social/BlobServlet?docId=7102&langId=en   European Commission. (2017a). Measurement of impact of cross -border penetration in public procurement,  Final report.  Retrieved from Publications Office of the European Union website:  http://op.europa.eu/en/publication -detail/ -/publication/5c148423 -39e2 -11e7 -a08e -01aa75ed71a1   European Commission. (2017b). The new European interoperability framework (EIF) [Text]. Retrieved March 12,  2019, from ISA2—European Co mmission website: https://ec.europa.eu/isa2/eif_en   European Commission. Communication on Artificial Intelligence for Europe . , Pub. L. No. COM/2018/237 (2018).   European Commission. Communication on the Coordinated Plan on Artificial Intelligence . , Pub. L.  No.  COM/2018/795 (2018).   European Commission. Communication on Building Trust in Human -Centric Artificial Intelligence . , Pub. L. No.  COM/2019/168 (2019).   European Commission. Communication on the European Green Deal . , Pub. L. No. COM/2019/640 (2019).   European Commission. (2019c). eGovernment benchmark 2019: Empowering Europeans through trusted digital  public services. Insight report.  Retrieved from Publications Office of the European Union website:  http://op.europa.eu/en/publication -detail/ -/publication/ c896937b -f554 -11e9 -8c1f01aa75ed71a1/language -en  European Commission. A European strategy for data COM/2020/66 . , Pub. L. No. COM/2020/66 (2020).   European Commission. (2020b). eGovernment benchmark 2020: EGovernment that works for the people .  Retrieved fro m https://digital -strategy.ec.europa.eu/en/library/egovernment -benchmark -2020 egovernment -works -people   European Commission. (2020c). European enterprise survey on the use of technologies based on artificial  intelligence . https://doi.org/10.2759/759368   European Commission. White Paper on Artificial Intelligence – A European approach to excellence and trust . ,  Pub. L. No. COM/2020/65 (2020).   European Commission. (2020e). White paper on Artificial Intelligence: A European approach to excellence and  trust. Retr ieved from https://ec.europa.eu/info/files/white -paper -artificial -intelligence -european approach -excellence -and-trust_en   European Commission. (2021a). Coordinated Plan on Artificial Intelligence 2021 Review. Retrieved May 7, 2021,  from https://digital -strategy.ec.europa.eu/en/library/coordinated -plan-artificial -intelligence -2021 review   European Commission. Coordinated plan on Artificial Intelligence 2021 review (ANNEXES to the Communication  from the Commission to the European Parliament, the European Counci l, the Council, the European  Economic and Social Committee and the Committee of the Regions Fostering a European approach to  Artificial Intelligence) . , COM/2021/205 § (2021).   European Commission. (2021c). Digital Innovation Hubs: Helping companies and pub lic administrations make  the most of digital opportunities. Retrieved May 6, 2021, from https://digital strategy.ec.europa.eu/en/library/digital -innovation -hubs-helping -companies -and-public administrations -make -most -digital   European Committee of the Region s. (2020). 2020 barometer of regions and cities . Retrieved from  https://cor.europa.eu/en/our -work/Pages/EURegionalBarometer -2020.aspx   European Parliamentary Research Service (EPRS), Scientific Foresight Unit (STOA). (2020). The ethics of artificial  intelli gence: Issues and initiatives. Retrieved May 3, 2021, from  https://www.europarl.europa.eu/thinktank/en/document.html?reference=EPRS_STU(2020)634452   Eurostat. (2020). Government budget allocations for R&D (GBARD) (gba). Retrieved May 4, 2021, from  https://e c.europa.eu/eurostat/cache/metadata/en/gba_esms.htm  
  68   Feenberg, A. (2010). Between reason and experience: Essays in technology and modernity  (Illustrated edition).  Retrieved from https://mitpress.mit.edu/books/between -reason -and-experience   Ferro, E., Loukis,  E. N., Charalabidis, Y., & Osella, M. (2013). Policy making 2.0: From theory to practice.  Government Information Quarterly , 4(30), 359 –368. https://doi.org/10.1016/j.giq.2013.05.018   Floridi, L. (2020). Artificial Intelligence as a public service: Learning  from Amsterdam and Helsinki . 3–8.  Fredriksson, C., Mubarak, F., Tuohimaa, M., & Zhan, M. (2017). Big data in the public sector: A systematic literature  review. Scandinavian Journal of Public Administration , 21(3), 39 –62.  Gabryelczyk, R. (2020). Has COVID -19 accelerated digital transformation? Initial lessons learned for public  administrations. Information Systems Management , 37(4), 303 –309.  https://doi.org/10.1080/10580530.2020.1820633   GEP. (2018). Artificial intelligence and its impact on procurement and supply chain . Retrieved from  https://sig.org/system/tdf/srcDocs/Artificial_Intelligence_and_Its_Impact_on_Procurement_and_Suppl y_Chain_White_Paper_2019.pdf?file=1&type=node&id=14913&   Giest, S., & Samuels, A. (2020). ‘For good measure’: Data gaps in a big d ata world. Policy Sciences ,  (0123456789). https://doi.org/10.1007/s11077 -020-09384 -1  Gilpin, L. H., Bau, D., Yuan, B. Z., Bajwa, A., Specter, M., & Kagal, L. (2018). Explaining explanations: An overview  of interpretability of machine learning. 2018 IEEE 5t h International Conference on Data Science and  Advanced Analytics (DSAA) , 80–89. https://doi.org/10.1109/DSAA.2018.00018   Girasa, R. (2020). AI as a disruptive technology. In Artificial Intelligence as a Disruptive Technology: Economic  Transformation and Go vernment Regulation  (pp. 3 –21). https://doi.org/10.1007/978 -3-030-35975 1_1  Government of the Republic of Estonia. (2019). Estonia’s national artificial intelligence strategy 2019 -2021 .  Retrieved from https://e -estonia.com/nationa -ai-strategy/   Grillitsch, M., & Asheim, B. (2018). Place -based innovation policy for industrial diversification in regions.  European Planning Studies . https://doi.org/10.1080/09654313.2018.1484892   Grzenda, M., & Legierski, J. (2019). Towards increased understanding of open data use  for software  development. Information Systems Frontiers . https://doi.org/10.1007/s10796 -019-09954 -6  GSA Centers of Excellence. (2020). Accelerate adoption of Artificial Intelligence to discover insights at machine  speed . Retrieved from https://coe.gsa.gov /docs/2019/AIServiceCatalogNov19.pdf   Gupta, A., Smith, K., & Shalley, C. (2006). The interplay between exploration and exploitation. Academy of  Management Journal , 49. https://doi.org/10.5465/AMJ.2006.22083026   Harrison, T., F. Luna -Reyes, L., Pardo, T., De  Paula, N., Najafabadi, M., & Palmer, J. (2019). The data firehose and  AI in Government . 171 –176. https://doi.org/10.1145/3325112.3325245   Hellberg, A. S., & Hedström, K. (2015). The story of the sixth myth of open data and open government.  Transforming Gov ernment: People, Process and Policy , 9(1), 35 –51. https://doi.org/10.1108/TG -042014 -0013   High-Level Expert Group on AI (HLEG). (2020). The assessment list for trustworthy Artificial Intelligence (ALTAI) .  https://doi.org/10.2759/002360   High-Level Expert Gr oup on Artificial Intelligence (HLEG). (2019). Ethics guidelines for trustworthy AI . Retrieved  from https://digital -strategy.ec.europa.eu/en/library/ethics -guidelines -trustworthy -ai  Hinings, B., Gegenhuber, T., & Greenwood, R. (2018). Digital innovation an d transformation: An institutional  perspective. Information and Organization , 28(1), 52 –61.  https://doi.org/10.1016/j.infoandorg.2018.02.004   Hufty, M. (2011). Investigating policy processes: The Governance Analytical Framework (GAF). In Research for  Sustai nable Development: Foundations, Experiences, and Perspectives  (pp. 403 –424).   Janssen, M., Brous, P., Estevez, E., Barbosa, L. S., & Janowski, T. (2020). Data governance: Organizing data for  trustworthy Artificial Intelligence. Government Information Quarte rly, 37(3), 101493.  https://doi.org/10.1016/j.giq.2020.101493   Janssen, M., Charalabidis, Y., & Zuiderwijk, A. (2012). Benefits, adoption barriers and myths of Open Data and  Open Government. Information Systems Management , 29(4), 258 –268.  https://doi.org/10 .1080/10580530.2012.716740  
  69   Janssen, M., Konopnicki, D., Snowdon, J. L., & Ojo, A. (2017). Driving public sector innovation using big and open  linked data (BOLD). Information Systems Frontiers , 19(2), 189 –195. https://doi.org/10.1007/s10796 017-9746 -2  Janss en, M., & van den Hoven, J. (2015). Big and Open Linked Data (BOLD) in government: A challenge to  transparency and privacy? Government Information Quarterly , 32(4), 363 –368.  https://doi.org/10.1016/j.giq.2015.11.007   Jobin, A., Ienca, M., & Vayena, E. (2019 ). The global landscape of AI ethics guidelines. Nature Machine  Intelligence , 1(9), 389 –399. https://doi.org/10.1038/s42256 -019-0088 -2  Jovanovic, B., & Rousseau, P. L. (2005). General purpose technologies  (No. w11093).  https://doi.org/10.3386/w11093   Kankan halli, A., Charalabidis, Y., & Mellouli, S. (2019). IoT and AI for smart government: A research agenda.  Government Information Quarterly , 36(2), 304 –309. https://doi.org/10.1016/j.giq.2019.02.003   Kelemen, A. (2020). Supporting sustainability transitions un der the European Green Deal with cohesion policy.  Toolkit for national and regional decision -makers . Retrieved from European Commission Directorate General for Regional and Urban Policy website:  https://ec.europa.eu/regional_policy/en/information/publicati ons/guidelines/2020/supporting sustainability -transitions -under -the-european -green -deal-with-cohesion -policy -toolkit -for-national and-regional -decision -makers   Kessler, T. G., & Kelley, P. A. (2000). The business of government . Vienna, Va: Berrett -Koehler P ublishers.   Klievink, B., Van Der Voort, H., & Veeneman, W. (2018). Creating value through data collaboratives: Balancing  innovation and control. Information Polity , 23(4), 379 –397. https://doi.org/10.3233/IP -180070   Korzinov, V., & Savin, I. (2016). Pervasi ve enough? General purpose technologies as an emergent property .  https://doi.org/10.13140/RG.2.2.15495.39848   Krafft, P. M., Young, M., Katell, M., Huang, K., & Bugingo, G. (2019). Defining AI in policy versus practice . Retrieved  from http://arxiv.org/abs/1 912.11095   Kuziemski, M., & Misuraca, G. (2020). AI governance in the public sector: Three tales from the frontiers of  automated decision -making in democratic settings. Telecommunications Policy , 44(6), 101976.  https://doi.org/10.1016/j.telpol.2020.101976   Lämmerhirt, D., Rubinstein, M., & Montiel, O. (2017). The state of Open Governement data in 2017 . Retrieved  from https://blog.okfn.org/files/2017/06/FinalreportTheStateofOpenGovernmentDatain2017.pdf   Laskai, L., & Webster, G. (2019, June 17). Translation: Ch inese Expert Group Offers “Governance Principles” for  “Responsible AI.” Retrieved December 17, 2020, from New America website:  https://www.newamerica.org/cybersecurity -initiative/digichina/blog/translation -chinese -expert -group offers -governance -principles -responsible -ai/  Levinthal, D. A., & March, J. G. (1993). The myopia of learning. Strategic Management Journal , 14(S2), 95 –112.  https://doi.org/10.1002/smj.4250141009   Ling, R. (2010). New tech, new ties: How mobile communication is reshaping social cohesion . Cambridge, Mass:  The MIT Press.   Makridakis, S. (2017). The forthcoming Artificial Intelligence (AI) revolution: Its impact on society and firms.  Futures , Vol. 90, pp. 46 –60. https://doi.org/10.1016/j.futures.2017.03.006   Malone, S. (2019). How will machin e learning affect public procurement? Retrieved May 3, 2021, from Supply  Management website: https://www.cips.org/supply -management/opinion/2018/november/how -tosurvive -the-public -sector -shift-to-ai/  March, J. G. (1991). Exploration and Exploitation in Org anizational Learning. Organization Science , 2(1), 71 –87.  https://doi.org/10.1287/orsc.2.1.71   Mas, M., Fernandez de Guevara Radoselovics, J., Robledo, J. C., Cardona, M., Righi, R., Samoili, S., & Vazquez Prada Baillet, M. (2020). The 2020 PREDICT: Key fact s report: An analysis of ICT R&D in the EU and  beyond  (JRC No. EUR 30305). Retrieved from Publications Office of the European Union website:  https://data.europa.eu/doi/10.2760/291872  
  70   McCrea, B. (2018). 4 Ways Artificial Intelligence impacts procurement. Re trieved May 3, 2021, from  https://www.sourcetoday.com/supply -chain/article/21867095/4 -ways -artificial -intelligence -impacts procurement   McKinsey. (2019). Cutting through the noise: How banks can unlock the potential of APIs. Retrieved February 7,  2020, from  https://www.mckinsey.com/industries/financial -services/our -insights/banking matters/cutting -through -the-noise -how-banks -can-unlock -the-potential -of-apis  McKinsey. (2020a). Global survey: The state of AI in 2020 . Retrieved from https://www.mckinsey.com/bus iness functions/mckinsey -analytics/our -insights/global -survey -the-state -of-ai-in-2020   McKinsey. (2020b). How nine digital frontrunners can lead on AI in Europe . Retrieved from  https://www.mckinsey.com/business -functions/mckinsey -digital/our -insights/how -nine-digital -front runners -can-lead-on-ai-in-europe   McKinsey Analytics. (2020). Global survey: The state of AI in 2020 .  Meijer, A., & Thaens, M. (2020). The dark side of public innovation. Public Performance & Management Review ,  0(0), 1 –19. https://doi.org/1 0.1080/15309576.2020.1782954   Mergel, I. (2019). Digital service teams in government. Government Information Quarterly , 36(4), 101389.  https://doi.org/10.1016/j.giq.2019.07.001   Mergel, I., Edelmann, N., & Haug, N. (2019). Defining digital transformation: Re sults from expert interviews.  Government Information Quarterly , 36(4), 101385. https://doi.org/10.1016/j.giq.2019.06.002   Meulen, R. van der. (2017). Prepare for the impact of AI on procurement. Retrieved May 3, 2021, from  https://www.gartner.com/smarterwit hgartner/prepare -for-the-impact -of-ai-on-procurement/   Misuraca, G. C. (2012). Assessing ICT -enabled Innovation for Governance and Policy Making  (École polytechnique  fédérale de Lausanne). https://doi.org/10.5075/epfl -thesis -5497   Misuraca, G., & van Noordt,  C. (2020). Overview of the use and impact of AI in public services in the EU  (JRC No.  EUR 30255). Retrieved from Publications Office of the European Union website:  https://ec.europa.eu/jrc/en/publication/eur -scientific -and-technical -research -reports/ai -watchartificial -intelligence -public -services   Mittelstadt, B. D., Allo, P., Taddeo, M., Wachter, S., & Floridi, L. (2016). The ethics of algorithms: Mapping the  debate. Big Data & Society , 3(2). https://doi.org/10.1177/2053951716679679   Moravcsik, A. (1993). Preferences and Power in the European Community: A Liberal Intergovernmentalist  Approach. JCMS: Journal of Common Market Studies , 31(4), 473 –524. https://doi.org/10.1111/j.1468 5965.1993.tb00477.x   Mulligan, D. K., & Bamberger, K. A. (2019). Procurement as policy: Administrative process for machine learning.  SSRN Electronic Journal . https://doi.org/10.2139/ssrn.3464203   Muscio, A., Reid, A., & Rivera Leon, L. (2015). An empirical test of the regional innovation paradox: Can smart  specialisation overcome the p aradox in Central and Eastern Europe? Journal of Economic Policy Reform ,  18(2), 153 –171. https://doi.org/10.1080/17487870.2015.1013545   Nagtegaal, R. (2020). The impact of using algorithms for managerial decisions on public employees’ procedural  justice. Government Information Quarterly , (January), 101536.  https://doi.org/10.1016/j.giq.2020.101536   Naudé, W. (2020). Artificial intelligence vs COVID -19: Limitations, constraints and pitfalls. AI & SOCIETY ,  (0123456789). https://doi.org/10.1007/s00146 -020-00978 -0  Nolte, G., & Aust, H. P. (2013). European exceptionalism? Global Constitutionalism , 2(3), 407 –436.  https://doi.org/10.1017/S2045381713000038   North, D. C. (1990). Institutions, institutional change and economic performance  (59262nd edition). Cambridge  ;  New York: Cambridge University Press.   Perrault, R., Shoham, Y., Brynjolfsson, E., Clark, J., Etchemendy, J., Grosz Harvard, B., … Mishra, S. (2019). Artificial  Intelligence index 2019 annual report . Retrieved from  https://hai.stanford.edu/sites/g/files/sbiy bj10986/f/ai_index_2019_report.pdf   Pinch, T. J., & Bijker, W. E. (1984). The social construction of facts and artefacts: Or how the sociology of science  and the sociology of technology might benefit each other. Social Studies of Science , 14(3), 399 –441. 
  71   Pontikakis, D., Fernández Sirera, T., Janssen, M., Guy, K., Marques Santos, A., Boden John, M., & Moncada Paterno’  Castello, P. (2020). Projecting Opportunities for INdustrial Transitions (POINT): Concepts, rationales and  methodological guidelines for territ orial reviews of industrial transition  (JRC No. EUR 30375). Retrieved  from Publications Office of the European Union website:  https://publications.jrc.ec.europa.eu/repository/handle/111111111/60962   Prakash, S. (2018, May 23). The profound benefits of AI a doption in procurement. Retrieved May 3, 2021, from  Medium website: https://towardsdatascience.com/the -profound -benefits -of-ai-adoption -inprocurement -7f1e90dcdfc6   Probst, L., Pedersen, B., Lefebvre, V., & Dakkak -Arnoux, L. (2018). Digital transformation m onitor. USA -China -EU  plans for AI: Where do we stand?  Retrieved from https://ati.ec.europa.eu/sites/default/files/2020 07/USA -China -EU%20plans%20for%20AI%20 %20where%20do%20we%20stand%20%28v5%29.pdf   Przegalinska, A. (2019). State of the art and future of a rtificial intelligence . Retrieved from  https://www.europarl.europa.eu/RegData/etudes/BRIE/2019/631051/IPOL_BRI(2019)631051_EN.pdf   Renda, A. (2019). Artificial Intelligence . Retrieved from https://www.ceps.eu/ceps -publications/artificial intelligence -ethics -governance -and-policy -challenges/   Rifkin, J. (2004). The European dream: How Europe’s vision of the future Is quietly eclipsing the American dream.  Foreign Affairs , 83. https://doi.org/10.2307/20034170   Roberts, H., Cowls, J., Morley, J., Taddeo, M., Wang,  V., & Floridi, L. (2020a). The Chinese approach to artificial  intelligence: An analysis of policy, ethics, and regulation. AI & Society , 4(1), 64 –75.  https://doi.org/10.1007/s00146 -020-00992 -2  Roberts, H., Cowls, J., Morley, J., Taddeo, M., Wang, V., & Fl oridi, L. (2020b). The Chinese approach to artificial  intelligence: An analysis of policy, ethics, and regulation. AI & SOCIETY , 4(1), 64 –75.  https://doi.org/10.1007/s00146 -020-00992 -2  Robinson, J. P., Barth, K., & Kohut, A. (1997). Social impact research:  Personal computers, mass media, and use  of time. Social Science Computer Review , 15(1), 65 –82.  https://doi.org/10.1177/089443939701500107   Rogers, E. M. (2010). Diffusion of innovations, 4th Edition . Retrieved from  https://books.google.it/books?id=v1ii4QsB 7jIC  Rotolo, D., Hicks, D., & Martin, B. (2015). What is an emerging technology? Research Policy , 44, 1827 –1843.  https://doi.org/10.1016/j.respol.2015.06.006   Salganik, M. J., Lundberg, I., Kindel, A. T., Ahearn, C. E., Al -Ghoneim, K., Almaatouq, A., … al,  et. (2020). Measuring  the predictability of life outcomes with a scientific mass collaboration. Proceedings of the National  Academy of Sciences of the United States of America , 117(15), 8398 –8403.  https://doi.org/10.1073/pnas.1915006117   Santos, R., & Héan g, K. K. (2019, September 5). How public sector AI is going from hype to reality. Retrieved  January 10, 2021, from https://apolitical.co/en/solution_article/how -public -sector -ai-is-going -fromhype-to-reality   Savoldelli, A., Codagnone, C., & Misuraca, G. (2 012). Explaining the eGovernment paradox: An analysis of two  decades of evidence from scientific literature and practice on barriers to eGovernment. ACM  International Conference Proceeding Series , 287 –296. https://doi.org/10.1145/2463728.2463784   Schon, D. A. (1983). The reflective practitioner: How professionals think in action  (1st edition). Retrieved from  https://www.amazon.com/Reflective -Practitioner -Professionals -Think -Action/dp/0465068782   Schreiber, B., Janssen, R., Weaver, S., & Peintner, S. (2016, Oc tober 25). Procurement 4.0 in the digital world.  Retrieved May 3, 2021, from Arthur D Little website:  https://www.adlittle.com/en/insights/viewpoints/procurement -40-digital -world   Selbst, A. D., & Powles, J. (2017). Meaningful information and the right to e xplanation. International Data Privacy  Law, 7(4), 233 –242. https://doi.org/10.1093/idpl/ipx022   Shearer, E., Stirling, R., & Pasquarelli, W. (2020). Government AI Readiness Index. Oxford Insights , 4–143. 
  72   Simplilearn. (2016, March 14). What is the real impac t of social media  ? Retrieved January 8, 2021, from  Medium website: https://medium.com/@Simplilearn/what -is-the-real-impact -of-social -media 2afd57cfd538   Sousa, W. G. de, Melo, E. R. P. de, Bermejo, P. H. D. S., Farias, R. A. S., & Gomes, A. O. (2019). How and where is  artificial intelligence in the public sector going? A literature review and research agenda. Government  Information Quarterly , (July). https://doi.org/10.1016/j.giq.2019.07.004   Stamm, B. von. (2018). Failure in innovation: Is there such a thin g? In Management for Professionals . Strategies  in failure management  (Kunert S. (eds), pp. 27 –45). https://doi.org/10.1007/978 -3-319-72757 -8_3  Starke, C., & Lünich, M. (2020). Artificial intelligence for political decision -making in the European Union: Eff ects  on citizens’ perceptions of input, throughput, and output legitimacy. Data & Policy , 2.  https://doi.org/10.1017/dap.2020.19   The White House. (2020a). Executive order on promoting the use of trustworthy Artificial Intelligence in the  Federal Government . Retrieved December 18, 2020, from The White House website:  https://www.whitehouse.gov/presidential -actions/executive -order -promoting -use-trustworthy artificial -intelligence -federal -government/   The White House. (2020b, December 3). Executive Order on Prom oting the Use of Trustworthy Artificial  Intelligence in the Federal Government | The White House. Retrieved December 15, 2020, from  Whitehouse.gov website: https://www.whitehouse.gov/presidential -actions/executive -order -promoting use-trustworthy -artificial -intelligence -federal -government/   The White House Office of Science and Technology Policy. (2020a). American Artificial Intelligence Initiative:  Year One Annual Report .  The White House Office of Science and Technology Policy. (2020b, December 3). Promoting  the Use of  Trustworthy Artificial Intelligence in Government | The White House. Retrieved December 15, 2020,  from Whitehouse.gov website: https://www.whitehouse.gov/articles/promoting -use-trustworthy artificial -intelligence -government/   Thorsby, J., Stower s, G. N. L., Wolslegel, K., & Tumbuan, E. (2017). Understanding the content and features of  open data portals in American cities. Government Information Quarterly , 34(1), 53 –61.  https://doi.org/10.1016/j.giq.2016.07.001   Tilley, N. (2000). Realistic evaluat ion: An overview. Founding Conference of the Danish Evaluation Society , 8.  Citeseer.   Tonon, C. (2020). La GovTech, nouvelle frontière de la souveraineté numérique . Retrieved from Ifri website:  https://www.ifri.org/fr/publications/etudes -de-lifri/govtech -nouvelle -frontiere -de-souverainete numerique   Tushman, M. L., & O’Reilly, C. A. (1996). Ambidextrous organizations: Managing evolutionary and revolutionary  change. California Management Review , 38(4), 8 –29. https://doi.org/10.2307/41165852   United Nations. (20 17, September 27). Global review of sustainable public procurement. Retrieved January 10,  2021, from UNEP - UN Environment Programme website:  http://www.unenvironment.org/resources/report/2017 -global -review -sustainable -public -procurement   van Noordt, C., Me daglia, R., & Misuraca, G. (2020). Stimulating the uptake of AI in public administrations:  Overview and comparison of AI strategies of European Member States. In S. Virkar, M. Janssen, I.  Lindgren, U. Melin, F. Mureddu, P. Parycek, … H. J. Scholl (Eds.), EGOV-CeDEM -ePart 2020: Proceedings  of Ongoing Research, Practitioners, Workshops, Posters and Projects of the International Conference  EGOV -CeDEM -ePart 2020  (pp. 269 –278). CEUR.   van Noordt, C., & Misuraca, G. (2020a). Evaluating the impact of artificial int elligence technologies in public  services: Towards an assessment framework. In Proceedings of the 13th International Conference on  Theory and Practice of Electronic Governance  (pp. 8 –16). Retrieved from  https://doi.org/10.1145/3428502.3428504   van Noordt, C ., & Misuraca, G. (2020b). Exploratory insights on Artificial Intelligence for government in Europe.  Social Science Computer Review , 089443932098044. https://doi.org/10.1177/0894439320980449   van Noordt, C., & Pignatelli, F. (2020). 2nd peer learning worksh op on the use and impact of AI in public services .  Retrieved from https://joinup.ec.europa.eu/collection/elise -european -location -interoperability -
  73   solutions -e-government/document/report -2nd-peer-learning -workshop -use-and-impact -ai-public services   Vedung, E.  (1998). Policy Instruments: Typologies and Theories. Carrots, Sticks and Sermons: Policy Instruments  &amp; Their Evaluation. Rist, Ray C; Bemelmans -Videc, Marie -Louise; Vedung, Evert, Eds., . Retrieved  from https://www.academia.edu/42748022/Policy_Instrume nts_Typologies_and_Theories   Veldhuizen, C. (2020). Smart Specialisation as a transition management framework: Driving sustainability focused regional innovation policy? Research Policy , 49(6), 103982.  https://doi.org/10.1016/j.respol.2020.103982   Vilone, G. , & Longo, L. (2020). Explainable Artificial Intelligence: A systematic review. ArXiv:2006.00093 [Cs] .  Retrieved from http://arxiv.org/abs/2006.00093   Vinge, V. (1993). Technological singularity . Retrieved from  https://frc.ri.cmu.edu/~hpm/book98/com.ch1/vin ge.singularity.html   W3C. (2009, December 5). Improving access to government through better use of the web —W3C note . Retrieved  from  https://d1wqtxts1xzle7.cloudfront.net/4177376/improving_access_to_government_through_the_bett er_use_of_the_web.pdf   Wirtz, B. W., Weyerer, J. C., & Sturm, B. J. (2020). The dark sides of Artificial Intelligence: An integrated AI  governance framework for public administration. International Journal of Public Administration , 43(9),  818–829. https://doi.org/10.1080/01900692.2020.174 9851   World Wide Web foundation. (2017). Open data barometer global report, 4th edition . Retrieved from https://idl bnc-idrc.dspacedirect.org/bitstream/handle/10625/57676/57620.pdf   Yampolskiy, R. V. (2015). Artificial Superintelligence: A futuristic approac h (1° edizione). Retrieved from  https://www.amazon.it/Artificial -Superintelligence -Futuristic -Roman -Yampolskiy/dp/1482234432   Zeleti, F. A., & Ojo, A. (2017). Open data value capability architecture. Information Systems Frontiers , 19(2),  337–360. https://do i.org/10.1007/s10796 -016-9711 -5  Zhang, B., & Dafoe, A. (2019). Artificial Intelligence: American attitudes and trends  (SSRN Scholarly Paper No. ID  3312874). https://doi.org/10.2139/ssrn.3312874    
  74   Glossary   Accountability  The ability of government to give a satisfactory account of the use of power and  resources .  Adoption  The phase of technology appropriation where an innovation is tested and evaluated  for potential use. Aka Exploration .  AI appropriation  The union of adoption and implementation phases – more  cyclically recurrent than  linearly consecutive .  Algocracy  A form of technocracy, whereby machine algorithms, rather than people, collect  information, take actions and administer the rules of a State .  Algorithm  A set of instructions designed to perform a  specific task .  Cocreation  Collaborative development of new and innovative products, services, solutions  by a  number of users and stakeholders .  Codesign  Collaborative design .  Concretisation  The process of combining multiple functions within fewer struct ures.  Coproduction  Collaborative implementation of existing services by beneficiaries and providers .  Design  The thought ful activity  of delivering information on business requirements, technical  specifications and development procedures related to new tec hnologies, products or  services .    Deployment  Embedment of a new technology in business operations .  Development  Prototyping, testing and validation of a new technology in controlled environments .  Explainability  The possibility to explain the functioning  of something in full .  Exploitation  See Implementation .  Exploration  See Adoption .  Implementation  The phase of technology appropriation where the underlying product or service  delivery process is permanently affected and transformed. Aka Exploitation (se e).  Instrumentalisation  The activity of sense making of a certain technology. Can be analytically separated  into Primary and Secondary  instrumentalisation .  Interpretability  The possibility to describe a  cause and effect relationship in full .  Primary  Instrumentalisation  The activity of decontextualising technical art efacts to reduce them to their useful  aspects   Secondary  Instrumentalisation  The activity of integrating the simplified technical art efacts into the natural and  social environments .   Technica l Code  A criterion that selects between alternative feasible Technical Designs in terms of a  social goal .  
  75   Use The action of using something for a purpose .  User Centricity  The ability of putting the person or customer at the heart of the process of servi ce.   
      GETTING IN TOUCH WITH THE EU   In person   All over the European Un ion there are hundreds of Europe Direct information centres. You can find the address of the centre  nearest you at: https://europa.eu/european -union/contact_en   On the phone or by email   Europe Dire ct is a service that answers your questions about the European Union. You can contact this service:   - by freephone: 00 800 6 7 8 9 10 11 (certain operators may charge for these calls),   - at the following standard number: +32 22999696, or   - by electronic ma il via: https://europa.eu/european -union/contact_en   FINDING INFORMATION ABOUT THE EU   Online   Information about the European Union in all the official languages of the EU is available on the Europa website at:  https://europa.eu/european -union/index_en   EU publications   You can download or order free and priced EU publications from EU Bookshop at: https://publications.europa.eu/en/publications .  Multiple copies of free publications may be obtained by contacting Europe Direct or your local information centre (see  https://europa.eu/european -union/contact_en ). 
     KJ-NA-30868 -EN-N    doi:10.2760/440212   ISBN 978-92-76-42587 -8 
