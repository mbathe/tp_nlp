appgThe New Frontier:  Artificial Intelligence at Work A final report produced by the  All-Party Parliamentary Group on the Future of Work November 2021
The New Frontier: Artificial Intelligence at Work Strategic research partnerChairs’ introduction   Our Inquiry   Our key findings  Our recommendations  Recommendation 1  An Accountability for Algorithms Act  Recommendation 2  Updating digital protection  Recommendation 3  Enabling a partnership approach  Recommendation 4  Enforcement in practice  Recommendation 5  Supporting human-centred AI  Our conclusion  Annex 1  Endnotes  Acknowledgements  Report information 03 04 06 09 11 14  17  19  21 24 26 27 30 31 The APPG and IFOW would like to thank  the Joseph Rowntree Charitable Trust  for supporting this inquiry.
The New Frontier: Artificial Intelligence at Work   03 The new National AI Strategy1 details plans to invest in innovation  across the country and rightly recognises the importance of getting  the governance right, at the national and international level. As the  evidence we have considered shows, however, there is an urgent  need to bring forward robust proposals to protect people and  safeguard our fundamental values.  The AI Strategy recognises the broad ethical, social and economic  impacts of modern technology and the implications for British  industries, labour supply and skills. Specifically, it acknowledges  the need to understand and address the risks and harms to work  and workers presented by AI; and to involve people from diverse  backgrounds in this process. These are pressing needs which must  be met if we are to fulfil the objectives of the AI Strategy and drive  a digital transformation to benefit people across the country.  Our All Party Parliamentary inquiry finds that AI is transforming  work and working lives across the country in ways that have  plainly outpaced, or avoid, the existing regimes for regulation.  With increasing reliance on technology to drive economic recovery  at home, and provide a leadership role abroad, it is clear that the  Government must bring forward robust proposals for AI regulation  to meet these challenges.  A sharp focus on the most pressing challenges faced at work,  where stakes are especially high, will help translate the  Government’s intention to shape a world of responsible  technology into action. Our All Party Parliamentary inquiry offers  a roadmap for the next phase of the AI Strategy. In our view, the  Government must take this road if it is to meet new challenges and  seize the potential of modern technology to fulfil the ambitions of  the AI Strategy and improve future work and working lives across  the United Kingdom in service of the public interest. David Davis MP , Clive Lewis MP , and Lord Jim Knight Chairs’ introduction
The New Frontier: Artificial Intelligence at Work   04 The All Party Parliamentary Group on the Future of Work (‘the APPG’)  brings together parliamentarians, industry and civil society to foster  understanding of the challenges and opportunities of technology and  the future of work. We collaborate to develop practical solutions that  will shape a future of better work across the UK. As part of our mission to advance understanding and practical  solutions to shape a future of better work,2  our inquiry was established  in May 2021 in response to growing public concern about AI and  surveillance in the workplace and the Institute for the Future of Work’s  (‘IFOW’) report ‘The Amazonian Era’3 . Our inquiry, which ran from May  to July 2021, examined the use and implications of surveillance and  other AI technologies used at work; and considered practical policy  solutions to meet the challenges and opportunities we have found.  This report outlines the APPG’s key findings and recommendations  based on the evidence about AI at work that we have considered.  Our recommendations are aimed at ensuring our AI ecosystem is  genuinely human-centred, principles-driven and accountable to  shape a future of better work. They are centred around a proposal  for an Accountability for Algorithms Act (‘the AAA’).4  The AAA offers an overarching, principles-driven framework for  governing and regulating AI in response to the fast-changing  developments in workplace technology we have explored throughout  our inquiry. It incorporates updates to our existing regimes for regulation,  unites them and fills their gaps, whilst enabling additional sector-based  rules to be developed over time. The AAA would establish; a clear  direction to ensure AI puts people first, governance mechanisms to  reaffirm human agency, and drive excellence in innovation to meet the  most pressing needs faced by working people across the country. Our focus is the frontier of changes to work but our recommendations  inform the wider debate about AI governance and regulation as part of  the UK’s AI Strategy. The proposals we make are not restricted to AI alone, because it is  not always possible, or helpful, to isolate AI from other forms of  significant algorithmic decision-making.5  In this report, we use the  term ‘algorithmic systems’ in recognition of the fact that both fully  automated and semi-automated decision making technologies rely  on wider human decision making processes to impact work.Our Inquiry Our Inquiry 
* ‘It’s about  explosive growth.  It’s no longer  just about Uber,  Amazon warehouses  etc, it’s in  professional  services firms,  universities,  every workplace  you can think of.’ Jeremias Adams-Prassl  Professor in the Faculty of Law at the University of Oxford
Our key findingsThe New Frontier: Artificial Intelligence at Work   06 We are living through a period of technological transformation that  is already having a profound impact on the work and working lives  of people across the UK.6  AI and other data-driven technologies are  a primary factor of this transformation.7  Although many of these  changes were taking place pre-pandemic, there has been a marked  increase in the use of AI technologies in the workplace. Use of  algorithmic surveillance, management and monitoring technologies  that undertake new advisory functions, as well as traditional ones,  has significantly increased during the pandemic.8  Before COVID-19, the dominant impact of technology on work was  considered to be the substitution of human labour by machine, but  the rise of remote working has increased public concern about the  impact of remote monitoring and management. The evidence we have  considered, however, demonstrates that the impacts of AI on work  and workers are wide ranging beyond surveillance or substitution.9  We find that the pace, depth and breadth of wider workplace  transformation has accelerated. AI technologies are changing the  nature of work, who does it and how it is done.10   AI offers invaluable opportunities to create new work and improve  the quality of work if it is designed and deployed with this as an  objective.11 However, we find that this potential is not currently  being materialised. Instead, a growing body of evidence12 points  to significant negative impacts on the conditions and quality of  work across the country. Pervasive monitoring and target setting  technologies, in particular, are associated with pronounced negative  impacts on mental and physical wellbeing as workers experience  the extreme pressure of constant, real-time micro-management and  automated assessment.  These adverse impacts span the entire range of ‘Good Work’ principles  set out in the Good Work Charter13 (Annex 1) endorsed by the APPG  and incorporating the rights and freedoms protected in the European  Social Charter and International Covenant on Economic, Social and  Cultural Rights: access to work, fair pay, terms and conditions for work;  equality, dignity and autonomy; support, participation and learning.  Research from the IFOW and others shows that Good Work closely  correlates with good health and wellbeing; and that poor quality work  correlates with poor health and wellbeing.14 The evidence we have  heard indicates that adverse impacts of AI are economy-wide but that  key workers in essential service sectors have been hit particularly hard.15‘The dignity of workers is  under assault in our emerging  algorithmically driven working  environment… this is now  threatening some of the deeper  structures that have for centuries  functioned as supports for  individual liberty, social freedom  and collective flourishing. ’  Dr David Leslie  Ethics Theme Lead at  The Alan Turing Institute
The New Frontier: Artificial Intelligence at Work   07 Our key findings A core source of anxiety is a pronounced sense of unfairness and  lack of agency around automated decisions that determine  access or fundamental aspects of work. Workers do not understand  how personal, and potentially sensitive, information is used to  make decisions about the work that they do;16 and there is a  marked absence of available routes to challenge or seek redress.  Low levels of trust in the ability of AI technologies to make or support  decisions about work and workers follow from this.17 We find that  there are even lower levels of confidence in the ability to hold the  designer, developers, and users of algorithmic systems meaningfully  accountable for their responsible governance.18   In spite of this, there is wide measure of optimism that policy-makers  can reset this trajectory with appropriate direction and robust  regulatory response. Our dedicated hearing on AI and regulation  revealed that our laws have been far outpaced by magnitude  and pervasive use of AI at work. We accept the evidence of Helen  Mountfield QC, supported by detailed analysis in the Mind the Gap  Report,19 that our existing framework of regulation is inadequate  to promote innovation and fair play together.20 We find that the  challenges we have identified lie between data protection, labour  and equality laws. Rather than being acknowledged and caught by  our existing approach to regulation, they are obscured by it, which  means that many of the adverse impacts we have seen are set to  be projected into the future, ‘shaping the future in the image of  the past’ .21   Technological development is an inevitability, but there is nothing  inevitable about the way AI technologies shape our working lives. It is  the role of the law to shape innovation and organisational behaviours  in ways which serve the public interest. And it is the role of legislators  to regulate for real accountability and real AI innovation, squarely  addressing the toughest challenges we face and redirecting our  trajectory towards the high road: human-centred AI and the creation  of better work for all. ‘We must be intentionally  inclusive otherwise, we will be  unintentionally exclusive, and  that’s when we’ve been seeing  some of these harms. We need  to regulate to consider the  collective, as well as individual  harm else structural inequalities  will be projected into the future,  and magnified. ’  Anne-Marie Imafidon MBE Founder of Stemettes and  Trustee, IFOW
* ‘Where does  responsibility lie  at management and  board levels for  the harms and risks  that are created in  this new world?...  If we don’t talk  about structural  inequality and  structural harm,  we will miss the  boat.’ Andrew Pakes Head of Research at Prospect Union
The New Frontier: Artificial Intelligence at Work 09 The APPG’s recommendations are aimed at ensuring our AI  ecosystem is human-centred and properly accountable to shape a  future of Good Work. Our first and outstanding recommendation  is that the Government introduce a new, cross-sector, principlesdriven regulatory framework to promote strong governance and  innovation together: an Accountability for Algorithms Act (AAA).  The AAA would shift our emphasis to preventative action and  governance in the public interest. The AAA would include new rights  and responsibilities, subject to a risk-based threshold, to ensure that  all significant impacts from algorithmic decision-making on work or  workers are considered and that appropriate action is always taken.  This approach would benefit the best of British innovators and British  business as well as working people across the country. 1  An Accountability for Algorithms Act  The Act would establish a simple, new corporate and public sector  duty to undertake, disclose and act on pre-emptive Algorithmic  Impact Assessments (AIA). This duty would apply from the earliest  stage of design and deployment of algorithmic systems at work and  require rigorous ex ante assessment and ex post facto evaluation  of risks and other impacts on work and workers. AIAs would always  include a dedicated equality impact assessment. 2 Updating digital protection   The AAA would raise the floor of essential protection for workers  in response to specific gaps in protection from adverse impacts of  powerful but invisible algorithmic systems. These would include an  easy-to access right for a full explanation of purpose, outcomes and  significant impacts of algorithmic systems at work, a summary AIA  and means for redress. A right to be ‘involved’ in shaping the design  and use of algorithmic systems at work would be introduced to  help better manage impacts on work and workers and to safeguard  the social license and democratic governance of these systems.  These new rights would be set out in a dedicated schedule to the  AAA: ‘Worker Rights for the age of AI’ .Our recommendations
The New Frontier: Artificial Intelligence at Work   10 Our recommendations 3 Enabling a partnership approach To boost a partnership approach and recognise the collective  dimension of data processing, some additional collective rights are  needed for unions and specialist third sector organisations to exercise  new duties on members or other groups’ behalf. This could be further  supported by the Government establishing an AI Partnership Fund to  allow the TUC to build on and diversify the work of their AI Working  Group and develop training to give working people the tools and  knowledge required to interact, comprehend and challenge the use  of AI at work as appropriate. Our proposed partnership approach also  offers further opportunities for skills development and investment in  collaboration with the private sector. 4 Enforcement in practice The joint Digital Regulation Cooperation Forum (DRCF) should be  expanded with new powers to create certification schemes, suspend  use or impose terms and issue cross-cutting statutory guidance, to  supplement the work of individual regulators and sector-specific  standards. The forum should be equipped and funded to run  regulatory sandboxes to pilot new approaches to actively promote  equality as part of the AIAs, as well as to rigorously enforce existing  and new obligations. 5 Supporting human-centred AI The principles of Good Work should be recognised as fundamental  values, incorporating fundamental rights and freedoms under national  and international law, to guide development and application of a  human-centred AI Strategy. This will ensure that the AI Strategy  works to serve the public interest in vision and practice, and that its  remit extends to consider the automation of work. In parallel to the  AI Strategy, the Cabinet Office should initiate a Work 5.0 Strategy to  squarely address the challenges and opportunities of automation  as a result of AI and other modern technologies and ensure a  human-centred transformation of work across the UK. 
The New Frontier: Artificial Intelligence at Work   11 The established principles of AI governance22 should be put on a statutory footing, together with  the ethico-legal principal of equality, promoted in response to the specific challenges at work.  The AAA would establish a new duty to undertake, disclose and act on pre-emptive AIA applicable  across the public and private sectors. To inspire and shape the best of British innovation, this duty  should apply from the earliest stage of design and deployment of algorithmic systems at work and  require rigorous prior evaluation of risks and other impacts on work and workers. The duty would  extend to the responsibility to make appropriate design choices23 and modifications where risks  have been identified in the AIA. It must include a dedicated equality impact assessment.24   At present, corporations are not required to produce any  assessment of how the AI or other algorithmic systems they are  adopting could, or do impact work or their workforce. This means  that adverse impacts, including significant wellbeing and equality  impacts, tend to be neglected until the damage is done. Research  has demonstrated that algorithmic systems are having deleterious  impacts on good work across all key legal principles.25 We therefore propose that the main feature of the AAA is a new  corporate duty of prior assessment and appropriate action.  The public sector equality duty should be enhanced to mirror  the AIA duty and extended to the private sector.  Creating a new duty to produce pre-emptive AIAs would shift  regulatory emphasis to active, anticipatory intervention from the  more limited, retrospective evaluation of algorithmic systems  through the judicial system. The uncertainty of this operating  environment is as problematic for those developing algorithmic  technologies and employers as it is for workers. Adopting a  pre-emptive model of regulation would create a clear direction  and stable environment for businesses and people. We recommend  that the positive and negative impacts on Good Work are considered  as part of the ex ante impact assessment before algorithmic  systems are procured or deployed and that impacts are evaluated  ex post facto on an ongoing basis. This approach will support  human-centred technological innovation that creates value for  as many people as possible, rather than extracts value.‘In general, the Equality Act does  not impose any obligations on  employers or software designers  or anyone else to think about  or avoid discrimination and  disadvantage as a proactive  duty… Human beings and  organisations that use machines  of this kind have to take  responsibility. If we don’t design  the future we want, the future will  be designed by accident. ’ Helen Mountfield QC Expert in constitutional, human rights  and equality lawRecommendation 1  An Accountability for Algorithms Act 
The New Frontier: Artificial Intelligence at Work   12 Recommendation 1  An Accountability for Algorithms Act  Tabitha Goldstaub, Chair of the AI Council, told our inquiry that a  fresh regulatory approach would be necessary in order to unlock  the opportunities of AI and make the world a better place: ‘The thinking in the UK is that companies should be required and  encouraged to consider and remedy any adverse impacts as soon  as possible in the innovation cycle, not post event. The opportunity  is for the UK to do better, and lead globally. ’  Tabitha Goldstaub, Chair of the UK Government’s AI Council The new AIA duty should be subject to a risk-based, contextual  threshold. The main criteria for establishing risk will be where  algorithmic systems have significant impacts on work or workers,  including when they determine access, terms and conditions of  work. The process should integrate assessment of the inherent risks  of AI with assessment of the wider impacts on work and working  people, and it should be rigorous, dynamic and ongoing through  the deployment and life cycle of the algorithmic system. The new  duty should be accompanied by a statutory code setting out factors  to be considered in the evaluation process.  To be effective and meet new challenges, an AIA model must have  4 planks:26 1  Identifying individuals and communities who might be impacted   by algorithmic decisions, particularly vulnerable groups, before  procurement or deployment. This ‘pinpointing’ component will  form the basis for multi-stakeholder engagement and participation  throughout the process of assessment. Workers should always be  treated as key stakeholders.27 2  Undertaking a risk analysis aimed at outlining potential  pre-emptive actions in the context at hand. This component  operates the precautionary principle and is directed at preventing  individual and social injury, promoting design and deployment  that is aimed at improving work and working lives. The Good Work  Charter28 can be used as a checklist to consider potential impacts  on work and workers and help integrate socio-technical with  technical dimensions. 
The New Frontier: Artificial Intelligence at Work   13 Recommendation 1  An Accountability for Algorithms Act  3 Taking appropriate action in response to the analysis undertaken.  Those subject to the duty across the innovation cycle and supply  chain29 would be required to assess governance mechanisms and  make appropriate design choices and modifications to address  harms and mitigate the risks identified. Transparency about the  approach taken and choices made should be mandated.   4 Ongoing impact assessment and appropriate responsive action.   This plank would also ensure that the assessment process by which  impacts on work and workers have been considered by those  designing and deploying algorithmic systems was articulated,  shared and begins at the earliest stage of innovation and then  continues through its life cycle. It would also ensure a higher level  of transparency about the beneficial or harmful impacts under  consideration, and about the process itself. In our view, mandated AIAs are the most practical mechanism to  promote good innovation, good practice, and good governance  of AI used at work, if undertaken rigorously both before and after  deployment.30 The law should articulate the overarching aim and  basic requirements of an algorithmic assessment, but not how  these requirements should be met. The AIA must be built on the  4 planks set out above and include an element of independent  evaluation. Regulators and industry bodies should coordinate to  provide additional guidance and ensure rigorous enforcement  of the duty. Guidance at a sector level would provide detailed  standards and advice on how to meet them. ‘For the future to work for the people,  the data and the power dynamics  around this new superpower need to  be managed to ensure that the tech  does not continue to ravage our  privacy, widen skills and poverty gaps,  increase inequality and strengthen  the structures that keep people down,  no matter what they do. ’ Tabitha Goldstaub  Chair of the UK Government’ s AI Council 
The New Frontier: Artificial Intelligence at Work   14 The AAA should raise the floor of essential protection for workers in response to specific gaps in  protection from adverse impacts of powerful but invisible algorithmic systems, many of which  originate from the US. These would include an easy-to-access right to a full explanation of  purpose, outcomes and significant impacts of algorithmic systems at work, including the impact  assessment itself. A right to be ‘involved’ in shaping the design and use of algorithmic systems at  work would be introduced to help understand and better manage impacts on work and workers  and to safeguard the social license and democratic governance of these systems. A right to flexible  working unless there is a strong business case not to do so; incorporate the ability to disconnect   outside agreed working hours; and ensure reasonable notice for shift work so that flexible working  is not used as a cover for exploitative employment practices. These rights deserve a dedicated  Schedule in the Accountability for Algorithms Act: Rights for Workers in the Age of AI. Our inquiry showed numerous ways in which all stakeholders  would benefit from wider engagement and increased  understanding about why and how algorithmic systems were  impacting work and workers. Technologists, employers and  employees are often unaware of the impacts of algorithmic  systems31 which impedes deliberate, better use and hampers  collaborative decision-making in the longer-term interests of  people and businesses. Workers are not confident of how their  data is being used, and how this is making decisions about their  performance,32 leading to a sense of unfairness and an absence  of agency and effective remedy. This is associated with low levels  of trust in the ability of AI to make fair, transparent and  accountable decisions.33 For clarity and fairness, we therefore propose establishing a new,  freestanding right for a full explanation of purpose and outcomes  and impacts of algorithmic systems at work, which would include  access to relevant AIAs.34 This right would enable workers to find  out the use of, purpose for and metrics within AI technologies used  to monitor, allocate work, pay and discipline workers as modelled  by the new Californian Bill in the US and the subject of a new  consultation on “ a Bill of Rights for an AI-Powered World” .35   The right for an explanation would be mirrored by a new  transparency duty on employers to disclose such information,  alongside any AIA. Additional, sensitive information would be  available to regulators on request so that they are able to perform  their monitoring and enforcement functions.Recommendation 2  Updating digital protection  ‘We were given these productivity  targets based on what we were  told was the speed others were  working at. We had no oversight  of the algorithm itself and no  sense that those targets other  people were hitting were real.  We were just told these were the  rates other people were hitting  and if we did not hit those, we  could lose our job. ’ James Bloodworth  Journalist and Author
The New Frontier: Artificial Intelligence at Work   15 Recommendation 2  Updating digital protection  Explanations must be clear and comprehensive to enable workers  without technical knowledge of algorithms to understand a  decision, and would articulate the means of redress.  Concerns have been raised by developers about how a ‘full  explanation’ duty could expose them to IP infringement and  open up the algorithm to be exploited or ‘gamed’ by workers.36   We therefore propose that the layered approach recommended  by the The Information Commissioner’s Office (ICO) and the Turing  Institute37 is adopted to ensure that meaningful, legally binding  explanations can be implemented in practice, while the legitimate  interests to protect IP and other sensitivities are safeguarded.  We believe that this model of explanation addresses concerns  about the feasibility of explainability expressed by developers  and would not impede innovation. A right to consultation is established in labour law and industrial  practice,38 but our inquiry found a striking absence of consultation  where AI and algorithmic systems were being introduced at work,  even when the systems carried significant financial or wellbeing  risks. Polling by the TUC and Britain Thinks revealed that only 31%  of workers agree with the statement that staff at their workplace  are consulted before new technology is introduced.39 The evidence  we received suggests that in non-unionised workplaces it is  commonplace to have no consultation.40 This is an unnecessary  obstacle to the responsible design, development and deployment  of technology which points to the need for workers to have an  enhanced right to meaningful consultation from the earliest stage  when algorithmic systems are being considered for adoption at  work. We conceive of this enhanced form of consultation as a right  to be ‘involved. ’  Survey data from the IFOW found that 49% of USDAW union  members felt that higher levels of consultation would result  in better design and more effective application of algorithmic  systems, better suited to their needs, as well as those of the  business.41 We therefore recommend a new right for all workers  to have reasonable ‘involvement’ in the design and deployment  of algorithmic systems likely to have significant impacts on work  or workers. This would address immediate challenges in the  workplace and help bridge the divide between those who design,  and those who feel, AI impacts. ‘When you don’t understand  what data is being collected  about you, how would you go  about rectifying a decision made  with it?’ Emma Wright  Director and Council at  The Institute of AI
The New Frontier: Artificial Intelligence at Work   16 Recommendation 2  Updating digital protection  The evidence we have heard suggests that workers feel constantly  ‘on call’ and unable to control their working patterns where  algorithmic systems are used to direct shift allocation. In practice,  the concept of ‘flexible working’ is often used as a cover for poor  employment practices that depend on automated instructions to  personal telephones made at the last-minute.42 A right to flexible working would establish a requirement that all  roles would be advertised as being flexible and a presumption that  reasonable requests made for flexible working would be permitted  unless there was a good business case for why not. Meaningful  flexibility is also closely associated with an ability to disconnect  outside working hours, and to ensure reasonable notice is given for  shift work, and the cancellation of shift work for planning purposes  and to protect family lives. We therefore recommend new rights for  flexible working, disconnect and reasonable notice, as well as rights  to a full explanation and involvement, for workers in a digital age.  The advantages for workers are plain but these new rights will also  help ensure business models are sustainable in the longer term. “Women are having to cancel  their care responsibilities to  respond to shift scheduling at  the last minute, workers are no  longer talking to each other to  keep optimum pace, disabled  workers are quitting or being let  go due to an inability to perform  against these standards… the  impact of these systems can be  seen beyond any given workforce.  It is impacting communities and  changing what ‘work’ is. ” Dr Abigail Gilbert  Head of Research at the Institute for  the Future of Work 
The New Frontier: Artificial Intelligence at Work   17 To apply the principle of collaboration in the 2021 Digital Regulation Plan, Government should  facilitate and cement social partnership working within the AI ecosystem. As a first step, we  recommend that new collective rights are established for unions and NGOs to exercise our  new individual rights for a full explanation and involvement, with the permission of individual  members. We also recommend a new, freestanding right for unions to be consulted whenever  ‘high risk’43 AI tools are being introduced to workplace, as sought by the TUC in ‘Work and the  AI Revolution’44. The excellent work of the TUC Working Group should be diversified and scaled,  with the support of an AI Partnership Fund, extending to the development of a worker AI training  programme, bringing further opportunities for reskilling and investment in collaboration with  specialist organisations and the private sector. In addition, there should be union representation  on relevant governance bodies.  The 2021 Digital Regulation Plan rightly states that regulation  should take a ‘collaborative approach’ by, for example, working  with business to test out new interventions and models.  Partnership working applies the principle of collaboration further:  it means a tripartite approach in which businesses and employees  work together in a collaborative manner to address challenges  and maximise opportunities for mutual benefit. The evidence we  have heard points to poor levels of communication and needless  divides which hamper constructive partnership working to get  the best out of AI at work.45 This should start with employers  informing relevant trade unions when algorithmic systems with  significant impacts are adopted in a workplace so that meaningful  consultation can commence. We recognise the historic role unions have played in upholding  and enforcing workplace protections.46 The evidence we have  heard suggests that the most egregious examples of workplace  surveillance and abuse of AI are happening in workplaces that  unions have been unable to access. We recommend that unions  are supported in accessing physical and digital workspaces.  In addition, unions should also be allowed to develop new roles  within the AI ecosystem to redress a growing imbalance of  information and power and help deliver genuinely human-centred  AI in the public interest.  The evidence we have considered shows that algorithmic systems  work by making assumptions about individuals, and classifying  them into groups on the basis of some shared data points.47 This is  used to predict and shape future behaviour. In order to understand Recommendation 3  Enabling a partnership approach  ‘We advocate a world of work  where everyone can benefit from  new technology and innovation,  not just employers and  technology companies. In that  respect, we encourage education,  awareness raising, collaboration  and consultation, empowering  workers with knowledge about  the importance of their data and  information as to how technology  operates. ’ Mary Towers  AI Working Group Lead at the  Trade Union Congress
The New Frontier: Artificial Intelligence at Work   18 Recommendation 3  Enabling a partnership approach impacts on work and workers however, as the AI Strategy aims to  do, group and relative outcomes must be examined. This demands  a collective approach, without exclusive reliance on individual  rights. In these circumstances, it is crucial to harmonise individual  and collective mechanisms for accountability. Unions are well-placed to be a helpful resource throughout the  process of assessing and redressing algorithmic impacts by liaising  with the workforce in a straightforward, digestible manner and  communicating their views to governing bodies and beyond them.  Properly equipped and supported, they may be able to help run  early AIA pilots, for instance via technology forums48 or dedicated  technology union representatives to advance the practice of social  partnership at regional and sector levels as AI is dispersed across  the country.  The AI Strategy focuses on attracting the best AI talent rather than  boosting AI literacy among working citizens. Given the importance  of AI to drive digital transformation across the UK, we therefore  propose an additional role for the TUC: to develop and deliver  AI training to workers. This course should be fully funded by the  Government and then rolled out to a representative proportion of  the non-unionised workforce.49 We recommend that the TUC AI  Working Group is supported to work with independent, charitable  organisations such as the Turing Institute and training programmes  are designed in collaboration with employers. The partnership  approach would therefore also create new opportunities for the  Government to work hand in hand with employers and third sector  organisations to develop and invest in upskilling the UK workforce,  as well as with trade unions. ‘We would love to see social  partners involved in this which we  don’t tend to see in the UK setting  and which we know from our  colleagues in unions elsewhere in  Europe there is a much stronger  sense of this. ’ Andrew Pakes  Research Director at Prospect Union
The New Frontier: Artificial Intelligence at Work   19 The Government’s DRCF was established with the excellent  intention of ensuring greater cooperation on digital and  online regulatory matters. It currently consists of the ICO, the  Competition and Markets Authority (CMA) and the Office of  Communications (Ofcom).  However, the expert witnesses at our inquiry session on  enforcement and the law gave a very mixed picture in terms  of responsibility and accountability, with multiple regulators,  inspectorates and enforcement agencies involved.50 The  witnesses spoke to clear gaps in the mandates and resources  of our existing regulators, and difficulties in accessing current  workforce protections. This is not helped by limited mechanisms  for transparency. In addition, equality policy is not integrated or  enforced outside the Equality and Human Rights Commission  (EHRC) which has led to widespread confusion about the  capacity of AI technologies to replicate the inequalities of  the past. The evidence we have heard suggests that to make the UK a  world-leader in governance as well as innovation, we need  new mechanisms and resources to establish regulatory  common capacity and enforce the AAA, alongside existing  protections.51 The members and remit of the DRCF should be  expanded to include the EHRC and new single enforcement  body for employment rights. The DRCF should be supported  with specialist, interdisciplinary team working horizontally to  develop cross-cutting statutory guidance, joint investigations  and strategic test cases, as well as work up guidance on AI for  individual regulators. ‘We need to build greater  understanding of what AI is both  within our institutions and in the  general public. We have to do  something to fill the gaps that  are created as our regulatory  framework doesn’t go far enough.  If you were to put a drug on the  market, it has to go through  various tests. Is there a role for  something like that with AI?’ Emma Wright  Director and Council at  The Institute of AIThe Government’s DRCF should be expanded with new powers to create certification schemes,  suspend use or impose terms and issue cross-cutting statutory guidance, to supplement the work  of individual regulators and sectors-specific standards. The forum should be equipped and funded  to run regulatory sandboxes to pilot new approaches to promote equality as part of the AIAs, as  well as to rigorously enforce existing and new obligations.Recommendation 4  Enforcement in practice 
The New Frontier: Artificial Intelligence at Work 20 Recommendation 4  Enforcement in practice The DRCF should be equipped to establish and run regulatory  sandboxes52 to experiment with different approaches, making  and enforcing modifications as result of AIAs, and options to  proactively promote equality. This can start now and may inform  refinement of the AAA in its passage through Parliament, as well  as more detailed statutory guidance. In addition, detailed sector  guidance and support can be worked up over time. We think this  will be important but the challenges we have explored at work  (which is not a ‘sector’) demonstrate that regulation cannot rest  on a sectoral approach. Parliament should keep the work of the DRCF under close review.  The Government may need to consider a specialist AI regulator in  due course. ‘Our regulatory regimes were  designed before a world of  machine learning and AI…  You need a level playing field  and a set of rules everyone abides  by to ensure the responsible  innovation everyone wants  to see. ’ Jeremias Adams-Prassl Professor in the Faculty of Law at the University of Oxford 
The New Frontier: Artificial Intelligence at Work   21 The principles of Good Work should be recognised as fundamental values to guide development  and application of a human-centred AI Strategy. This will ensure that the AI Strategy works to serve  the public interest in vision and practice, and that its remit extends to consider the automation  of work. In parallel to the AI Strategy, the Cabinet Office should initiate a Work 5.0 Strategy to  squarely address the challenges and opportunities of automation as a result of AI and other modern  technologies, and ensure a human-centred transformation of work across the UK. The evidence we have heard throughout our inquiry suggests  that significant impacts on Good Work53 are rarely appreciated or  prioritised in the design and deployment of AI at work, even though  the principles of Good Work capture some of the most fundamental  values and rights of our citizens.  The AI Strategy purports to protect the public and our fundamental  values without articulating what these are, how they will steer  development of the Strategy, or how they will be applied to new  mechanisms for governance. The evidence in our inquiry points to  a central role for Good Work principles in Phase 2 of the Strategy.  If we focus on future Good Work, this will knit the Pillars of the  Strategy together, ensuring that growth and innovation go hand  in hand with respect for the fundamental values and rights of  our citizens. A sharper focus on Good Work for all will enable  the development of human-centred AI and a human-centred AI  ecosystem. This means that the Government should support new  functions, funding streams and challenges for UKRI to ensure that  the UK leads in the innovating for human-centred AI aimed at  creating good future work.  Our inquiry has highlighted the striking and often adverse  impacts AI can have on work and workers, including automation.  We are therefore surprised that the automation of work is only  lightly referenced within the AI Strategy. We strongly support the  recommendation of the Works and Pensions Committee that an  overarching Work 5.0 Strategy54 is needed to shape and protect  future work in the age of AI and automation. This should be  initiated as soon as possible for consultation and development  alongside the AI Strategy. Recommendation 5  Supporting human-centred AI  ‘We need to be principle-driven;  we need to be human centred  and we need to look across the  entire life cycle, not be reactive  at the end. ’ Anne-Marie Imafidon MBE Trustee at the IFOW and  Co-Founder of Stemettes
Our inquiry has found that the challenges we have explored fall  between our existing frameworks. In a similar vein, the ‘future  of work’ risks falling between Government Departments, rather  than deserving of a dedicated cabinet office with a cross-cutting  remit. This is illustrated by the AI Strategy’s incomplete attention  to automation and impacts on work, in contrast to the EU-US  Inaugural Joint Statement on technology made on 29 September  2021.55 We therefore oppose that the Cabinet Office initiate and  co-ordinate the development of a cross-department Work 5.0  Strategy aimed at understanding the impacts of automation on  work and ensuring that new technology and innovation promote  prosperity and wellbeing across the country through better work.Recommendation 5  Supporting human-centred AIThe New Frontier: Artificial Intelligence at Work   22 ‘The UK can do better and is  very well placed to lead globally  if we can incorporate and build  on the strengths that we have in  governance and ethics, as well as  AI innovation because it is really  important that we own and tackle  the thornier issues. Then we can  lead globally, have clear rules,  be trustworthy and earn the  public trust. ’ Tabitha Goldstaub Chair of the UK Government's  AI Council 
* ‘We need to be  principle-driven;  we need to be human  centred and we need  to look across the  entire life cycle,  not be reactive at  the end.’ Anne-Marie Imafidon MBE Trustee at the Institute for the Future of Work and Co-Founder of Stemettes
The New Frontier: Artificial Intelligence at Work   24 The evidence contributed to this inquiry from  organisations across civil society, business,  the trade union movement, and academia has  made a compelling case that a fresh approach to  regulation is needed to maximise the opportunities  and address the challenges of fast-paced  technological change at work. Our governance  framework must not only keep pace with pervasive  use of AI at work. It must anticipate change and  shape a better future of work too. A new focus  on the creation of Good Work and tackling the  workplace challenges we have identified head on  will ensure innovation and governance of the best,  most-human centred AI working for people and  the public interest. If our proposed approach is  adopted, the UK is well placed to fulfil the potential  of the AI Strategy and produce a gold standard  template to lead globally in the innovation and  governance of responsible modern technology. Our conclusion
* ‘We advocate a   world of work where   everyone can benefit   from new technology   and innovation,   not just employers   and technology   companies.’ Mary Towers AI Working Group Lead, Trade Union Congress
The New Frontier: Artificial Intelligence at Work   26 1 Access      Everyone should have access to good work 2 Fair pay    Everyone should be fairly paid 3 Fair conditions    Everyone should work on fair conditions set out on fair terms 4 Equality    Everyone should be treated equally and without discrimination 5 Dignity     Work should promote dignity 6 Autonomy    Work should promote autonomy 7 Wellbeing    Work should promote physical and mental wellbeing 8 Support    Everyone should have access to institutions and people who  can represent their interests 9 Participation    Everyone should be able to take part in determining and   improving working conditions 10 Learning    Everyone should have access to lifelong learning and   career guidance The Good Work Charter Annex 1
1  National AI Strategy: https://www.gov.uk/government/publications/national-ai-strategy   2  APPG mission statement: https://www.futureworkappg.org.uk/ 3  Gilbert, Abigail and Anna Thomas (2021). ‘The Amazonian Era: How algorithmic systems are eroding good work’ IFOW.   https://www.ifow.org/publications/the-amazonian-era-how-algorithmic-systems-are-eroding-good-work     4 An Accountability for Algorithms Act (AIA) was first proposed by the Equality Task Force, as outlined in   ‘Mind the Gap: The Final Report of the Equality Task Force’ , IFOW (2020).  https://www.ifow.org/publications/mind-the-gap-the-final-report-of-the-equality-task-force   5 For a review of the issues in defining AI in policy, see: Krafft, P . M., Meg Young, Michael Katell, Karen Huang, and Ghislain Bugingo. “Defining AI in policy   versus practice. ” In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, pp. 72–78. 2020.   6  See for reference to the experience of change at an individual level: TUC, (2021) ‘Technology Managing People: The Worker Experience’   https://www.tuc.org.uk/research-analysis/reports/technology-managing-people-worker-experience; and   Gilbert, Abigail and Anna Thomas (2021) ‘The Amazonian Era: How algorithmic systems are eroding good work’ IFOW   https://www.ifow.org/publications/the-amazonian-era-how-algorithmic-systems-are-eroding-good-work    and at the level of labour markets: Laws, Athene Helen. “Inequality in Labour Markets. ” PhD diss., University of Cambridge, 2020; Prassl, Jeremias.   Humans as a service: The promise and perils of work in the gig economy. Oxford University Press, 2018.   7  Autor, David H.   “Wiring the labor market. ” The Journal of Economic Perspectives 15, no. 1 (2001): 25–40.  8  Evidence by Abigail Gilbert, Mary Towers and Jeremias Prassl during APPG evidence sessions on the 18th May 2021 and 8th June 2021. 9  IFOW have identified 6 types of automation impact, including substitution (where tasks previously conducted by a worker are conducted by a machine)   telepresence (where tasks previously conducted by a person in a specified location can be conducted remotely) augmentation (the improvement of   work delivery through technological assistance) creation (the creation of new tasks and potentially new jobs as a result of technology) transference   (where tasks previously conducted by a worker are conducted by a consumer) and intensification (whereby technology schedules greater density of  tasks, leading to negative impacts on the worker). 10  Evidence by Abigail Gilbert, Mary Towers and Andrew Pakes during APPG evidence sessions on the 18th May 2021 and 13th July 2021. Regarding   distribution of work, see also literatures on Routine Biased Change and the polarisation of labour markets; and polarisation of hours of work. See in   particular for a recent analysis of UK labour markets: Laws, Athene Helen. “Inequality in Labour Markets. ” PhD diss., University of Cambridge, 2020. 11 Evidence by Tabitha Goldstaub during APPG evidence session on the 13th July 2021.   See also: Cooley, Mike. “ Human-centred systems. ” In Designing human-centred technology, pp. 133–143. Springer, London, 1989;   Olivieri, Emily, and Loredana Isacsson. “ Exploring guidelines for human-centred design in the wake of AI capabilities: A qualitative study. ” (2020). 12  For some literature see: Muller, Zane. “ Algorithmic Harms to Workers in the Platform Economy: The Case of Uber. ” Colum. JL & Soc. Probs. 53 (2019): 167;   Wood, Alex J. Algorithmic management consequences for work organisation and working conditions. No. 2021/07. JRC Working Papers Series on   Labour, Education and Technology, 2021; Todolí-Signes, Adrián. “Making algorithms safe for workers: occupational risks associated with work   managed by artificial intelligence. ” Transfer: European Review of Labour and Research (2021): 10242589211035040; Slaughter, Rebecca Kelly,   Janice Kopec, and Mohamad Batal. “Algorithms and Economic Justice: A Taxonomy of Harms and a Path Forward for the Federal Trade Commission. ”   Yale Journal of Law & Technology 23 (2020): S1-S1. 13  The Good Work Charter. https://www.ifow.org/publications/the-ifow-good-work-charter   14  IFOW (2021) The Good Work Monitor. https://www.ifow.org/resources/the-good-work-monitor 15  Evidence by Abigail Gilbert during the APPG Evidence session on the 18th May 2021, referencing the Amazonian Era: Gilbert, Abigail and Anna Thomas   (2021) ‘The Amazonian Era: How algorithmic systems are eroding good work’ IFOW.   https://www.ifow.org/publications/the-amazonian-era-how-algorithmic-systems-are-eroding-good-work   16   In an IFOW survey in partnership with USDAW found 67% of workers asked ‘If my data is used to assess or make predictions about my performance,   I know how it is used to do so’ responded that they were ‘not at all confident’ (N= 974), fieldwork completed between August and October, 2020.  17  Evidence by Mary Towers during APPG evidence session on the 18th May 2021,   referencing TUC report ‘Technology managing people – The worker experience’: https://www.tuc.org.uk/AImanifesto 18 Evidence by Abigail Gilbert and Mary Towers during APPG evidence session on the 18th May 2021. 19 IFOW (2021) ‘Mind the Gap: The final report of the Equality Task Force’:   https://www.ifow.org/publications/mind-the-gap-the-final-report-of-the-equality-task-force  20 As the CDEI have acknowledged, there is a need for concerted action to address the risks of automated decision making at work.   https://www.gov.uk/government/publications/cdei-publishes-review-into-bias-in-algorithmic-decision-makingThe New Frontier: Artificial Intelligence at Work 27 Endnotes
The New Frontier: Artificial Intelligence at Work 28 Endnotes  21 Evidence from Helen Mountfield QC during the APPG evidence session held on the 18th May 2021.    See also: Birhane, Abeba. “ The Impossibility of Automating Ambiguity. ” Artificial Life 27, no. 1 (2021): 44–61.  22  For an overview, see Leslie, David, et al (2021) ‘Artificial Intelligence, Human Rights, Democracy and the Rule of Law: A Primer’ The Alan Turing Institute.   https://www.turing.ac.uk/sites/default/files/2021-03/cahai_feasibility_study_primer_final.pdf  23 For an overview of human decisions taken in the design process, see the report of the Equality Task Force (2021) ‘Mind the Gap: The final report of the   Equality Task Force’:   https://www.ifow.org/publications/mind-the-gap-the-final-report-of-the-equality-task-force 24 An initial proposal for an Equality Impact Assessment, developed through consultation is set out in: Graham, Logan, Abigail Gilbert, Joshua Simons,   Anna Thomas(2020) Artificial Intelligence in Hiring: Assessing Impacts on Equality. IFOW.   https://uploads-ssl.webflow.com/5f57d40eb1c2ef22d8a8ca7e/5f71d338891671faa84de443_IFOW%2B-%2BAssessing%2Bimpacts%2Bon%2Bequality.pdf   25  See Gilbert, Abigail and Anna Thomas ‘The Amazonian Era: How Algorithmic Systems are Eroding Good Work’ IFOW 2021; and ‘Case for the Importance of   Good Work Through Technology Introduction’ Forthcoming, IFOW CIPD and Carnegie.  26  Evidence by David Leslie during APPG evidence session on the 13th July 2021. See also Human Rights, Democracy, and the Rule of Law Assurance   Framework for AI Systems, the Turing Institute, 2021. 27 There is growing support for the involvement of consumers of technology, particularly where those consumers are citizens. See: BEIS ‘The Use of Public   engagement for Technological Innovation’ BEIS Research Paper Number 2021/003 This principle should be equally extended to workers.  28 The Good Work Charter. https://www.ifow.org/publications/the-ifow-good-work-charter   29  Human decisions are taken at various stages in the creation of an algorithmic system. IFOW identify 7 key stages in the mind the gap report.   Such human decisions should be understood and outlined for effective transparency. Algorithmic systems, which can be ‘imported’ to the UK without   regulatory checks or certifications easily, as non-tangible goods, can be designed without due regard to UK law. This is outlined in: Graham, Logan,   Abigail Gilbert, Joshua Simons, Anna Thomas (2020) Artificial Intelligence in Hiring: Assessing Impacts on Equality IFOW.   https://uploads-ssl.webflow.com/5f57d40eb1c2ef22d8a8ca7e/5f71d338891671faa84de443_IFOW%2B-%2BAssessing%2Bimpacts%2Bon%2Bequality.pdf     30 This approach is already being taken by various international governments. See more: Moss, Emanuel, Elizabeth Anne Watkins, Jacob Metcalf, and   Madeleine Clare Elish. “ Governing with algorithmic impact assessments: six observations. ” Available at SSRN 3584818 (2020) and Ada Lovelace Institute,    AI Now Institute, and Open Government Partnership (2021) ‘Algorithmic Accountability for the Public Sector’   https://www.adalovelaceinstitute.org/report/algorithmic-accountability-public-sector/    with methods for co-construction of impacts outlined in: Metcalf, Jacob, Emanuel Moss, Elizabeth Anne Watkins, Ranjit Singh, and Madeleine Clare Elish.   “Algorithmic impact assessments and accountability: The co-construction of impacts. ” In Proceedings of the 2021 ACM Conference on Fairness,   Accountability, and Transparency, pp. 735–746. 2021. 31 While many workers are often unaware of the presence of algorithmic systems in the workplace, research also finds that employers are often unaware   of what data is being collected and for what purposes: In 2019, less than a third of CEOs who admitted they collect extensive data on their workforces   personally feel that their companies use the data responsibly. Ellen Sheng. Employee Privacy in The U.S. is at Stake as Corporate Surveillance   Technology Monitors Workers’ Every Move, CNBC (Apr. 15, 2019),   https://www.cnbc.com/2019/04/15/employee-privacy-is-at-stake-as-surveillance-tech-monitors-workers.html   cited in Nelson, Josephine, Management Culture and Surveillance (December 16, 2019). 43 Seattle U. L. Rev. 2, 631 (2020) (Berle XI symposium on   Corporate Culture). Available at SSRN: https://ssrn.com/abstract=3504408   32  In an IFOW survey in partnership with USDAW found 67% of workers asked ‘If my data is used to assess or make predictions about my performance,   I know how it is used to do so’ responded that they were ‘not at all confident’ (N= 974), fieldwork completed between August and October, 2020.   33 For a discussion of the limitations of common ‘transparency’ approaches in AI governance, see: Ananny, Mike, and Kate Crawford.   “Seeing without knowing: Limitations of the transparency ideal and its application to algorithmic accountability. ” new media & society 20,   no. 3 (2018): 973–989.  34 We note existing rights and their limitations under the GPDR as set out in Mind the Gap; and that some key rights and/or open access to them are   currently the subject of a public consultation. In the mean time, we encourage voluntary disclosure of data protection impact assessments.    Please see Prospect Union’s Guidance on DPIAs for further information. Note that some worker protections in the GPDR are currently subject to public   consultation and therefore at risk. 35 https://www.theguardian.com/us-news/2021/sep/10/california-bill-amazon-warehouse-quotas and   https://www.wired.com/story/opinion-bill-of-rights-artificial-intelligence/ 36  See an overview of the debate in: Casey, Bryan, Ashkon Farhangi, and Roland Vogl.   “Rethinking Explainable Machines: The GDPR’ s ‘Right to Explanation’  Debate and the Rise of Algorithmic Audits in Enterprise. ”   Berkeley Tech. LJ 34 (2019): 143.   
The New Frontier: Artificial Intelligence at Work 29 Endnotes  37 “Differentiating the way you are providing information in an audience-responsive manner can help you avoid creating explanation fatigue in your   customers (by saying too much) and at the same time allow you to protect your intellectual property and safeguard your system from being gamed. ”    https://ico.org.uk/for-organisations/guide-to-data-protection/key-dp-themes/explaining-decisions-made-with-ai/  38 For an overview of responsibilities, see: https://www.gov.uk/informing-consulting-employees-law    39  TUC (2020) ‘Technology managing people – The worker experience’ . https://www.tuc.org.uk/AImanifesto   40 Evidence by James Bloodworth during APPG evidence session on the 18th May 2021. 41  Evidence provided by Abigail Gilbert to the evidence session on the 18th May 2021 drawing on IFOW (2021) An Amazonian Era, suggests that the   deployment of some algorithmic systems without due regard to workers needs could be undermining productivity, rather than enhancing it.    42 The Amazon era provides evidence of the ‘liquidisation’ of the work force in Part 3. The transformation of contracts as enabled and aligned to greater     prediction of demand for labour via algorithm is also discussed in: https://www.tuc.org.uk/AImanifesto 43 There is a growing debate around how to classify algorithmic systems, or AI, as High Risk. As noted by Jeremias Prassl in his evidence, the EU are   considering all work-based applications as potentially high risk. The EU’s proposed AI Regulation bans applications which could cause “physical or   psychological” harm through the use of “subliminal techniques” or by exploiting vulnerabilities of a “specific group of persons due to their age,   physical or mental disability. ” This would render many of the systems identified in recent research, such as The Amazonian Era, high risk.    44  Note TUC Manifesto additional proposals which could supplement our recommendations in due course. In this report we are focusing on top    recommedations only: https://www.tuc.org.uk/AImanifesto  45 We heard that the use of algorithmic systems can strategically reduce levels of communication within organisations.   See for instance: Amazonian Walker, Michael Brian. “Disrupting Precarity: An Enquiry into Worker Voice in Nonstandard Employment. ” PhD diss., 2020.     46  Evidence by James Bloodworth during APPG evidence session on the 18th May 2021. 47 See more information on this process in: Soofi, Aized Amin, and Arshad Awan. “Classification techniques in machine learning: applications and issues. ”   Journal of Basic and Applied Sciences 13 (2017): 459–465. And an identification of issues as they relate to work, among other contexts in:    https://www.gov.uk/government/publications/cdei-publishes-review-into-bias-in-algorithmic-decision-making  48 Professor Jeremias Prassl noted in his evidence to the inquiry that the model of Works Councils in Germany proved constructive in the development   and implementation of technology in the workplace.     49  CDEI review into bias in algorithmic decision-making:  https://www.gov.uk/government/publications/cdei-publishes-review-into-bias-in-algorithmic-decision-making 50 Evidence by Helen Mountfield QC, Emma Wright and Jeremias Prassl during APPG evidence session on the 18th May 2021.     51  Evidence by Helen Mountfield QC, Emma Wright and Jeremias Prassl during APPG evidence session on the 18th May 2021.      52  This could run in a similar format to the model developed by the ICO: https://ico.org.uk/for-organisations/regulatory-sandbox/  53 Good Work is defined by the Charter principles set out here: https://www.ifow.org/publications/the-ifow-good-work-charter 54  A Work 5.0 Strategy could mirror the approach taken in the Danish Disruption Council, or German Work 4.0 strategies. For more information see:   ‘A Better Future for Work: the World after Covid-19’ Future of Work Commission, IFOW 2020.      55  ‘European Union and the United States intend to jointly undertake an economic study examining the impact of AI on the future of our workforces,   with attention to outcomes in employment, wages, and the dispersion of labour market opportunities. Through this collaborative effort, we intend to   inform approaches to AI consistent with an inclusive economic policy that ensures the benefits of technological gains are broadly shared by workers   across the wage scale’ .
AcknowledgementsThe New Frontier: Artificial Intelligence at Work  30 With special thanks to  the following experts who  gave evidence during the  APPG’s inquiry sessions:Professor Jeremias  Adams-Prassl Jeremias is Professor in the Faculty  of Law at the University of Oxford.  Jeremias is primarily interested in  Employment Law and European  Union Law. He is the author of The  Concept of the Employer, a co-editor  of The Autonomy of Labour Law, and  one of the editors of The Contract of  Employment. James Bloodworth  James is a writer and journalist. He is  a former editor of the blog Left Foot  Forward, and his work has appeared in  the Guardian, Spectator, Independent  and Wall Street Journal. James is the  author of ‘Hired: Six Months Undercover  in Low-Wage Britain’ (2018), which has  been longlisted for the 2019 Orwell  Prize. Dr Abigail Gilbert  Abby is Head of Research at IFOW and  was co-author with Anna Thomas of  ‘An Amazonian Era: How Algorithmic  Systems are Eroding Good Work’ . Tabitha Goldstaub Tabitha is the Chair of the UK  Government's AI Council and a member  of the TechUK board. Tabitha is the  co-founder of CogX, a festival and online  platform that enables thousands of  thought leaders to host their own public  or private live video sessions and build  interactive meaningful conversations  with their audience. Anne-Marie Imafidon MBE Anne-Marie is Head Stemette and  co-founder of Stemettes – an awardwinning social enterprise inspiring  girls and young women into Science,  Technology, Engineering and  Mathematics roles. Anne-Marie is a  Trustee at IFOW.Dr David Leslie David is the Ethics Theme Lead at  The Alan Turing Institute. He is the  author of the UK Government’s official  guidance on the responsible design and  implementation of AI systems in the  public sector, a co-badged guidance on  AI explainability published by the ICO  and The Alan Turing Institute. Helen Mountfield QC  Helen is a renowned practitioner and  expert in constitutional, human rights  and equality law. Helen was co-chair,  of the independent Future of Work  Commission and chair of the IFOW’s  Equality Task Force. Andrew Pakes Andrew is the Research Director and  one of the Deputy General Secretaries  at Prospect Union representing  over 152,000 members across tech,  specialist, engineering and professional  roles. He leads Prospect’s work around  tech, AI, data rights and the future of  work. He is also a Visiting Fellow at the  ESRC funded Digital Futures of Work  Research Centre looking at worker  experiences of digital surveillance. Mary Towers  Mary is an employment rights officer at  the Trade Union Congress (TUC) and has  been leading their AI project alongside a  union working group, looking at the use  of AI in the employment relationship.  The group published a research report  in 2020 and manifesto and legal report  in March 2021. Emma Wright Emma is Director of the Institute of AI,  a cross party non-profit, working with  legislators across the globe.
This report was commissioned  by the All-Party Parliamentary  Group on the Future of Work.It was researched and written with  support from The Institute for the  Future of Work. This is not an official publication of  the House of Commons or the House  of Lords. It has not been approved  by either House or its committees.  All-Party Parliamentary Groups are  informal groups of Members of both  Houses with a common interest in  particular issues. The views expressed  in this report are those of the group.The All Party Parliamentary  Group on the Future of Work The All Party Parliamentary Group on  the Future of Work brings together  parliamentarians, industry and civil  society to foster understanding of  the challenges and opportunities of  technology and the future of work.  We collaborate to develop practical  solutions that will shape a future of  better work across the UK.  The Institute for the Future  of Work The Institute for the Future of  Work is an independent think tank  exploring how new technologies are  transforming work and working lives.  We research and develop practical  solutions to promote people’s future  wellbeing and prosperity.  Co-founded by Nobel prize winning  economist Sir Christopher Pissarides,  technologist Naomi Climer CBE and  employment barrister Anna Thomas,  we work at the intersection of  government, industry and civil society  to shape a fairer future through  better work. Report informationThe New Frontier: Artificial Intelligence at Work   31
Copies of the report can be downloaded from  the APPG website at: www.futureworkappg.org.ukappg
