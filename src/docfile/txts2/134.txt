              Strasbourg, 25 January  2019                                                  T-PD(2019)01              CONSULTATIVE COMMITTEE OF THE CONVENTION FOR THE PROTECTION   OF INDIVIDUALS WITH REGARD TO AUTOMATIC PROCESSING   OF PERSONAL DATA     (Convention 108)           GUIDELINES ON ARTIFICIAL INTELLIGENCE  AND  DATA PROTECTION                          Directorate General of Human Rights and Rule of Law      
       November 2018     1   Artificial Intelligence1 (“AI”) based systems, software and devices (hereinafter referred to as AI  applications)  are providing new and valuable solutions to tackle needs and address challenges  in a variety of fields, such as smart home s, smart cities, the industrial sector, healthcare  and  crime prevention . AI applications may represent a useful tool for decision making in particular  for supporting evidence -based and inclusive policies. As may be the case with other   technological innovations, these applications may have  adverse consequences for individuals  and society.  In order to prevent this , the Parties to Conve ntion 108 will ensure and enable that  AI development and use respect the rights to privacy and data protection  (article 8 of the  European Convention on Human Rights ), thereby enhancing human  rights and fundamental  freedoms.   These Guidelines provide a set of baseline measures that governments, AI developers,  manufacture rs, and service providers  should follow  to ensure that AI applications do not  undermine the human dignity and the human rights and fundamental freedoms of every  individual, in particular with regard to the right to data protection .2  Nothing in the present Guidelines shall be interpreted as precluding or limiting the provisions of  the European  Convention on Human Right s and of Convention 108 . The se Guidelines  also take  into account the new safeguards of the  modernised  Convention 108 (more commonly referred  to as “Convention 108+”)3.    I. General guidance    1. The protection of human dignity and safeguard ing of human rights and fundamental  freedoms, in particular the right to the protection of personal data, are essential when   developing and adopting AI applications that may have consequences on individuals  and society.  This is especially important  when AI applications are used in decision making processes .     2. AI development relying on  the processing of  personal data should  be based on the  principles of Convention 108 +. The key elements of this approach are: lawfulness,  fairness,  purpose sp ecification,  proportionality of data processing, privacy -by-design  and by  default, responsibility  and demonstrat ion of compliance  (accountability) ,  transparency, data security and risk management.   3. An approach  focused on avoiding and mitigating the potential risks of processing  personal data  is a necessary element of responsible innovation  in the field of AI .   4. In line with the guidance on risk assessment provided in the Guidelines on Big Data   adopted by the Committee of Convention 108  in 20174, a wider view of the possible  outcomes of data processing should be adopted . This view should  consider not only  human rights and fundamental freedoms but also the functioning of democracies and  social and ethical values .  5. AI applications must at all time s fully respect the rights of data subjects , in particular in  light of article 9 of Convention 108+ .  6. AI applications  should allow meaningful control  by data subjects  over the data  processing and related effects on individual s and on society .                                                                    1 The following definition of AI is  currently  available  on the Council of Europe’s website   https://www.coe.int/en/web/human -rights -rule-of-law/artificial -intelligence/glossary : “A set of sciences,  theories and techniques whose purpose is to reproduce by a machine the cognitive abilities of a human  being. Current developments aim, for instance, to be able to entrust a machine with complex tasks  previously delegated to a human.”   2 These Guidelines follow and build on the Report on Artificial Intelligence (“Artificial Intelligence and Data  Protection: Challenges and Possible Remedies”) available at :   https://rm.coe.int/artificial -intelligence -and-data-protection -challenges -and-possible -re/168091f8a6   3 Amending Protocol CETS n°223 to the Convention for the Protection of Individuals with regard to  Automatic Processing of  Personal Data.   4 https://rm.coe.int/t -pd-2017 -1-bigdataguidelines -en/16806f06d0   
       November 2018     2   II. Guidance for developers , manufacture rs and service providers     1. AI developers , manufacture rs and service providers  should adopt a value s-oriented  approach in the design of their products and services, consistent with Convention 108 +,  in particular with article 10.2,  and other relevant instruments of the Council of Europe.   2. AI developers , manufacture rs and service providers  should  assess the possible adverse  consequences of AI applications on  human rights and fundamental freedoms, and,  considering these consequences , adopt a precautionary approach based on  appropriate risk prevention  and mitigation measures .  3. In all phases of the processing, including data collection, AI developers , manufacture rs  and service providers  should adopt a human rights by-design approach and avoid any  potential biases , including  unintentional or hidden , and the risk of discrimination or other  adverse  impacts on the human rights and fundamental freedoms of data subjects .  4. AI developers should critically assess the quality,  nature , origin  and amount of personal  data used, reducing unnecessary, redundant or marginal data  during the development ,  and training phases and then monitoring the model’s accuracy as it is fed with new  data. The use of synthetic data5 may be considered as one possibl e solution to  minimise the amount of personal data processed  by AI applications .    5. The risk of adverse impacts on individuals and society due to de-contextualised data6  and de -contextualised algorithmic models7 should be adequately considered  in  developing and using AI applications .  6. AI develop ers, manufacture rs and service providers  are encouraged to set up and  consult  independent committees of experts from a range of fields, as well as engage  with independent academic institutions, which can contribute to design ing human rights based and ethically and socially -oriented AI  applications , and to detect ing potential bias.  Such committees may play an especially  important role in areas where transparency  and stakeholder engagement can be more difficult due to competing interests and  rights , such as in the field s of predictive justice, crime prevention and detection .  7. Participatory forms of risk assessment, based on the active engagement of the  individuals and groups  potentially affected by AI applications, should be encouraged .  8. All products and services should be designed in a manner that ensures the right of  individuals not to be subject to a decision significantly affecting them based solely on  automated processing , without having their views taken into consideration .  9. In order to enhance users’ trust, AI developers , manufacture rs and service providers   are encouraged to design their products and services in a manner that safeguards  users’ freedom of choice over the use of AI , by provid ing feasible  alternatives to AI   applications .  10. AI developers, manufacturers, and service providers should adopt forms of algorithm  vigilance that promote the accountability of all relevant stakeholders throughout the  entire life cycle of  these applications , to ensure compliance with data protection and  human rights law and principles.   11. Data subjects should  be informed if they interact with an AI application  and have a right  to obtain information on the  reasoning underlying AI data processing operations  applied  to them. This should  includ e the consequences of such reasoning .  12. The r ight to object should be ensured in relation to processing based on  technologies  that influence the opinions and personal development  of individuals .                                                                5 Synthetic data are generated from a data model built on real data. They should be representative of the  original real data. See the definition of synthetic data in OECD. ‘Glossary of Statistical Terms’. 2007.  http://ec.e uropa.eu/eurostat/ramon/coded_files/OECD_glossary_stat_terms.pdf  (“An approach to  confidentiality where instead of disseminating real data, synthetic data that have been generated from one  or more population models are released”).   6 This is the risk of ign oring contextual information characterising the specific situations in which  the  proposed AI -based solutions should be used .  7 This happens when AI models, originally designed for a specific application, are used in a different  context or for different purposes.  
       November 2018     3   III. Guidance for  legislators and policy makers     1. Respect for the principle of accountability, the adoption of risk assessment procedures  and the application of other suitable measures, such as codes of conduct and  certification mechanisms , can enhance t rust in AI products and services.   2. Without prejudice to confidentiality safeguarded by law, p ublic procurement procedures  should impose on AI developers, manufacturers, and service providers specific duties of  transparency , prior assessment  of the impact of data processing on human rights and  fundamental freedoms,  and vigilance on the potential adverse effects and  consequences of AI applications (hereinafter referred to as algorithm vigilance8).  3. Supervisory authorities should be provided with sufficient resources to  support  and  monitor the algorithm vigilance programmes of AI developers, manufacturers, and  service providers .   4. Overreliance on the solutions provided by AI applications  and fears of challenging  decisions suggested by AI applications risk altering the autonomy of human intervention  in decision -making processes. The role of human intervention in decision -making  processes and the freedom of human decision makers not to rely on the result  of the  recommendations provided using AI should therefore be preserved .   5.  AI developers, manufacturers, and service providers  should consult supervisory  authorities  when AI applications have the potential to significantly impact the human  rights and funda mental freedoms of data subjects .  6. Cooperation should be encouraged  between data protection supervisory authorities and  other bodies having competence related to AI , such as: consumer protection ;  competition ; anti-discrimination ; sector regulators and  media regulatory authorities.   7. Appropriate mechanisms should be put in place to ensure the independence of the  committees of experts mentioned in Section II.6.   8. Individuals , groups, and other stakeholders should be informed and actively involved in  the debate on what role AI should play in shaping social dynamics, and in decision making processes affecting them .   9. Policy makers should invest  resources in digital literacy and education to increase data  subjects’ awaren ess and understanding of AI applications and their effects. They should  also encourage professional training for AI developers to raise  awareness and  understa nding of the potential  effects of AI on individuals and society.  They should  support research in human rights -oriented AI.                                                               8 On the notion of algorithmic vigilance, as adoption of accountability, awareness and risk management  practices related to potential adverse effects and consequences throughout the entire life cycle of these  applications see also 40th International Conference of Data Protection and Privacy Commissioners,  Declaration on Ethics and Data Protection in Artificial Intelligence, guiding principle no. 2 . See also the  Report on Artificial Intelligence (f ootnote  2), Section II.4  
