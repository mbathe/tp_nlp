 The Institute for  Ethical AI in  Education   The Ethical Framework  for AI in Education  The Institute for Ethical AI in Education has been kindly funded by: 
Introduction The Institute for Ethical Al in Education was conceived by Sir Anthony Seldon, Priya Lakhani  OBE, and Professor Rose Luckin in the summer of 2018, and launched in October of that year,  with the aim of developing an ethical framework that would enable all learners to beneﬁt  optimally from AI in education, whilst also being protected against the known risks this  technology presents. The Founders and the Chair of the Institute, Lord Tim Clement-Jones suggested a 2.5 year  timetable, after which the Institute is to be wound up . The Institute’s work has been funded by  McGraw Hill, Microsoft Corporation, Nord Anglia Education, Pearson PLC; and by a  discretionary grant from John Fairbairn at Esmee Fairbairn Foundation. Its day-to-day  operations have been managed by Executive Lead, Tom Moule. In February 2020, the Institute published its Interim Report: Towards a Shared Vision of Ethical  Al in Education, which provided an overview of the applications of Al in education, outlined the  risks and beneﬁts posed by Al's use, and put forward a blueprint for an ethical framework,  along with six overarching questions. These questions, which were designed to guide further  research, related to stakeholders' perspectives on the risks and beneﬁts of Al in education,  how tensions between risks and beneﬁts might be resolved, and how ethical principles could  be put into practice. Building Consensus The Interim Report also emphasised the need to build consensus around how Al should be  used in education. To create consensus, following on from The Interim Report, the Institute  embarked upon a programme of wide consultation designed to listen to and learn from the  perspectives of a cross-section of stakeholders. Between March and July 2020, a series of expert interviews were conducted, during which  policymakers, academics, philosophers and ethicists, industry experts, and educators (whose  expertise ranged from teaching students with special educational needs, to lifelong learning)  were consulted. Whilst most of the interviewees were from either the UK or the USA, the  Institute also consulted with experts from Africa, Asia, Australia, and South America. Distilling  insights from these expert interviews, the Institute published a second report in September  2020 - Developing a Shared vision of Ethical Al in Education - which reﬁned the overarching  questions, and aimed to inform and focus future consultations. Between October and December 2020, eight roundtables were held, including three dedicated  to participation by young people. These events allowed a broad range of stakeholders to make  their contributions. 
In November 2020, The Institute convened The Global Summit on the Ethics of Al in  Education. To ensure the event could go ahead despite measures to protect against the  spread of Covid-19, an early decision was made to hold the Global Summit virtually. By doing  so, the Institute was able to bring together over 200 experts and authorities in ﬁelds related to  Al in education from around the globe in order to arrive at a shared understanding of the  ethical implications of using Al In education, and to make recommendations on how Al should  be designed and applied ethically in practice. The Ethical Framework for AI in Education Having consulted with a wide range of stakeholders in these ways, the Institute is now in a  position to put forward The Ethical Framework for Al In Education. The Framework is grounded  in a shared vision of ethical Al in education and will help to enable all learners to beneﬁt  optimally from Al in education, whilst also being protected against the risks this technology  presents. The Framework is aimed at those making procurement and application decisions  relevant to AI in education. Leaders and practitioners in educational settings are themselves key to ensuring that learners  can beneﬁt optimally from Al whilst being protected against its risks because it is they who  have the ﬁnal say over which resources are used. By using the Framework at the procurement  stage, decision makers can help ensure that only ethically designed resources are used and  procured, and can therefore ideally incentivise suppliers to design Al ethically and with  learners' best interests at heart. The Framework empowers leaders and practitioners to drive the design, procurement and  application of AI on behalf of learners. But it cannot and must not be solely their responsibility  to ensure that learners beneﬁt optimally from Al in education. Those designing Al resources  are ultimately responsible for ensuring that systems do not, amongst other things, discriminate  against any group of learners, that they do not manipulate users, and that resources are  designed in a pedagogically sound way. Instead of developing a separate framework for those designing and developing AI systems,  the Framework incorporates ethical expectations of designers and developers. In a number of  cases, the Framework explicitly states that during the procurement process, decision makers  should insist upon relevant information to conﬁrm that AI resources were designed ethically.  The Framework provides a robust mechanism for preventing learners from being exposed to  unethically designed AI resources. If organisations designing, developing and supplying AI  resources cannot provide the information insisted upon in the Framework, the Institute expects  this to rapidly impact on procurement decisions. It is also expected that designers must adhere to local laws and policies in relation to data  protection, for example the Age Appropriate Design Code (also commonly referred to as the 
Children’s Code) developed by the Information Commissioner’s Ofﬁce. Furthermore, by  September 2021, The Institute urges that all suppliers of AI products and services for  educational purposes should adhere to the requirements speciﬁed in The Ethical Framework  for AI in Education. In particular, these organisations are encouraged to take account of the  information that procurers will insist upon, and take proactive steps to ensure they are able to  provide all the information needed to demonstrate their resources are designed ethically. Wider Reform It is clear to the Institute for Ethical AI in Education that reforms in education are needed to  ensure that all learners can beneﬁt optimally from the use of AI in education. AI has the  potential to combat many of the deep-rooted problems facing education systems and learners  themselves: from a narrow and shallow curriculum, to entrenched social immobility. AI could  allow societies to move away from an outdated assessment system and it could also enable  high-quality, affordable lifelong learning to become universally available. Whilst it is outside of the Institute’s scope to put forward a blueprint for how these reforms  could be facilitated through the use of AI, it can be said with certainty that reforms will not  deliver beneﬁt to all learners if the digital divide is not closed decisively and quickly. During school closures due to Covid-19 the reality of digital exclusion was laid bare. Those  learners who lacked adequate access to devices and internet connections suffered most. The  critical loss of learning for many of the most disadvantaged young people could and should  have been avoided. The same mistakes will be less likely to be repeated if the work of the  Institute is heeded. In the long-term, the pandemic may prove to be a watershed moment for education. By  utilising AI ethically and with purpose, societies can look forward to addressing previously  overwhelming educational inequalities and enabling all learners, from all backgrounds, to  achieve their full potential, as long as there is universal and equal access to the necessary  hardware, infrastructure and connectivity. The Institute for Ethical AI in Education hence urges all governments to guarantee that every  single learner has adequate access to a device and an internet connection, and to heed the  recommendations in the F ramework. Only then will all learners be able to beneﬁt optimally  from AI in education.
The Ethical Framework for AI in Education Objective Criteria Checklist  Achieving Educational  Goals. AI should be used  to achieve well-deﬁned  educational goals based  on strong societal,  educational or scientiﬁc  evidence that this is for  the beneﬁt of learner (see  Annex Section 1 for  justiﬁcation)1.1Establish and specify the  educational goal that AI is being  used to achieveHave you clearly identiﬁed the educational goal  that is to be achieved through the use of AI?  (Pre-procurement) 1.2Establish how each relevant AI  resource has the capacity to  achieve the educational goal  speciﬁed aboveCan you explain why a particular AI resource  has the capacity to achieve the educational  goal speciﬁed above? (Pre-procurement) 1.3Specify the intended impact of  using AIWhat impact do you expect to achieve through  the use of AI, and how will you measure and  assess this impact? (Pre-procurement) 1.4Insist that suppliers provide  information about how their AI  resource achieves the desired  objectives and impacts. This may  include information relating to the  assumptions behind the  algorithmWhat information have you received from the  suppliers, and are you satisﬁed that the AI  resource is capable of achieving your desired  objectives and impacts? (Procurement) 1.5Insist that any measures of  student performance are aligned  with recognised and accepted  test instruments and/or  measures that are based on  societal, educational or scientiﬁc  evidenceWhat information have you received from the  suppliers, and are you satisﬁed that measures  of student performance are aligned with  recognised and accepted test instruments and/ or measures that are based on societal,  educational or scientiﬁc evidence?  (Procurement) 1.6Monitor and evaluate the extent  to which the intended impacts  and your stated objectives are  being achievedHow will you monitor and assess the extent to  which the intended impacts and objectives are  being achieved? (Monitoring and Evaluation) 1.7Insist that suppliers conduct  periodic reviews of their AI  resources to ensure these are  achieving the intended goals and  not behaving in harmful,  unintended waysCan the supplier conﬁrm that periodic reviews  are conducted, and that these reviews verify  that the AI resource is effective and performing  as intended? (Monitoring and Evaluation) 1.8Where the impacts of using AI as  intended are found to be  unsatisfactory, identify whether  this is due to how the resource  was designed, how the resource  is being applied, or a  combination of both factors.  Create an action plan for  achieving improved impactsIf the impacts of using AI as intended were not  satisfactory, why was this the case? What  steps will you take in order to achieve improved  impacts? (Monitoring and Evaluation) 
Objective Criteria Checklist  Forms of Assessment.   AI should be used to  assess and recognise a  broader range of  learners' talents (see  Annex Section 2 for  justiﬁcation)2.1Establish how AI can be used to  provide insights into a broad  range of knowledge,  understanding, skills and  personal well-being development  in a way that is based on  evidenceWhat knowledge and understanding, and which  skills are you intending to measure through the  use of AI? Which features of AI will enable  these to be assessed, and how will  assessments be conducted in practice?  (Implementation) 2.2Establish how AI resources can  be used to enhance and  demonstrate the value of:  formative approaches to  assessment, studying learning  processes as well as outcomes,  and supporting social and  emotional development and  learner well-beingIn what ways is AI being used to enhance and  demonstrate the value of formative approaches  to assessment, studying learning processes as  well as outcomes, and supporting social and  emotional development and learner well-being?  (Implementation) Administration and  Workload.  AI should  increase the capacity of  organisations whilst  respecting human  relationships (see Annex  Section 3 for justiﬁcation)3.1Identify ways that AI could be  used to improve current  processes in your organisationWhich processes could be improved through  the use of AI, and how do you intend to use AI  to improve these processes?   (Pre-procurement) 3.2Conduct and implement a risk  assessment to establish  whether/how using AI to improve  current processes in your  organisation could undermine or  marginalise educators and/or  other relevant practitioners Will implementing the actions arising from this  risk assessment ensure that educators and/or  other relevant practitioners are not undermined  or marginalised as a result of using AI?   (Pre-procurement) 3.3Create and implement a change  management strategy and  ensure institutional commitment  for implementing AI in your  organisationWill the change management strategy, along  with institutional commitments, enable AI to be  effectively utilised across your organisation?  (Implementation) 3.4Monitor and evaluate the extent  to which processes are being  improvedHow will the extent to which processes are  being improved be monitored and assessed?  (Monitoring and Evaluation) 3.5Where improvements in  processes are unsatisfactory,  identify the reasons for this and  develop an action plan for  achieving better outcomesWere the changes to processes due to the  implementation of AI satisfactory or  unsatisfactory? Where unsatisfactory outcomes  were yielded, are you conﬁdent that the action  plan will enable better outcomes to be  achieved? (Monitoring and Evaluation) 
Objective Criteria Checklist  Equity. AI systems  should be used in ways  that promote equity  between different groups  of learners and not in  ways that discriminate  against any group of  learners (see Annex  Section 4 for justiﬁcation)4.1Insist that suppliers provide  relevant information to conﬁrm  that appropriate measures were  taken, and continue to be taken,  to mitigate against biases as part  of the design of the resource and  within the data sets used for  trainingWhat information have you received from the  suppliers, and are you satisﬁed that  appropriate measures were taken, and  continue to be taken, to mitigate against biases  as part of the design of the resource and within  the data sets used for training?   (Pre-procurement) 4.2Develop and implement a  strategy to reduce the digital  divide amongst the cohort of  learners you have responsibility  forWill the implementation of this strategy ensure  that all learners for whom you are responsible  are able to access and beneﬁt from AI?  (Pre-procurement) 4.3Insist that suppliers provide  relevant information to conﬁrm  that resources have been  designed in order to be  accessible to and suited to the  needs of learners with additional  needs, which could be either  cognitive or physicalWhat information have you received from the  suppliers, and are you satisﬁed that AI  resources have been designed in order to be  accessible to and suited to the needs of  learners with additional needs, which could be  either cognitive or physical?   (Pre-procurement) Autonomy. AI systems  should be used to  increase the level of  control that learners have  over their learning and  development (See Annex  Section 5 for justiﬁcation)5.1Insist that suppliers provide  relevant information to conﬁrm  that AI resources were not  designed, and will never be  designed, to coerce learnersWhat information have you received from the  suppliers, and are you satisﬁed that AI  resources were not designed, and will never be  designed, to coerce learners?   (Pre-procurement) 5.2Insist that suppliers provide  relevant information to conﬁrm  that where AI is used to  positively inﬂuence learners'  behaviours, this use of AI is  supported by societal,  educational or scientiﬁc evidenceWhat information have you received from the  suppliers, and are you satisﬁed that where AI is  used to positively inﬂuence learners'  behaviours, this use of AI is supported by  societal, educational or scientiﬁc evidence?  (Pre-procurement) 5.3Where a predictive AI system  legitimately predicts that an  unfavourable outcome will occur  (e.g. a student being expelled,  failing an exam, or dropping out  of a programme), do not penalise  or hold the relevant individual to  account for an unrealised  outcome. Instead, take preemptive action to prevent the  unfavourable outcome occurringIn your context, what unfavourable outcomes  might an AI system predict? What harmful  action could potentially be taken based on this  prediction? What positive steps could be taken  to prevent the predicted outcome from  happening? (Implementation) 5.4Insist that suppliers provide  relevant information to conﬁrm  that AI resources are not  designed to encourage addiction  amongst learners, or to compel  learners to extend their use of a  resource beyond a point that is  beneﬁcial for their learningWhat information have you received from the  suppliers, and are you satisﬁed that AI  resources are not designed to encourage  addiction amongst learners, or to compel  learners to extend their use of a resource  beyond a point that is beneﬁcial for their  learning? (Pre-procurement)
Objective Criteria Checklist  Privacy. A balance  should be struck between  privacy and the legitimate  use of data for achieving  well-deﬁned and  desirable educational  goals (see Annex Section  6 for justiﬁcation)6.1Ensure compliance with relevant  legal frameworks to ensure that  the use of pupil data for the  stated purposes is permittedCan you conﬁrm that your organisation  complies with all relevant legal frameworks?  (All Stages ) 6.2Where the use of AI could be  considered to be surveillance of  learners, provide a clear  justiﬁcation of why this use of AI  beneﬁts learners either directly  or indirectly.What uses of AI could be considered to be  surveillance of learners, and how could these  beneﬁt learners - either directly or indirectly? (Pre-procurement) 6.3Ensure that where organisations  have chosen, or are obligated to  assess students on a continuous  basis (potentially as a  replacement for summative  assessments), there are  designated safe spaces in which  learners are not assessedIn contexts where institutions have chosen or  are obligated to assess students on a  continuous basis, how have you ensured that  there are designated safe spaces in which  learners are not assessed? (Implementation) 6.4Where a system processes data  (including but not limited to  personal or sensitive data) that  could be considered health data  insist that suppliers provide  relevant information to conﬁrm  that this data is required for  educational purposes and that  processing this data will beneﬁt  learnersWhat information have you received from the  suppliers, and are you satisﬁed that this data is  required for educational purposes and that  processing this data will beneﬁt learners? (Preprocurement) 
Objective Criteria Checklist  Transparency and  Accountability.  Humans  are ultimately responsible  for educational outcomes  and should therefore  have an appropriate level  of oversight of how AI  systems operate (See  Annex Section 7  for  justiﬁcation)7.1Conduct a risk assessment to  establish whether AI resources  could undermine the authority of  practitioners and disrupt  accountability structures, and  take action based on the risk  assessmentWill implementing the actions arising from this  risk assessment ensure that the authority of  educators and/or other relevant practitioners is  not undermined, and that accountability  structures are not disrupted as a result of using  AI? (Pre-procurement) 7.2Insist that suppliers make explicit  whether there were any tradeoffs between accuracy and  explainability in the design of the  AI resource, specifying where  any compromises have been  made and providing a  justiﬁcationHave you received the relevant information  from the suppliers? Where compromises have  been made, are you satisﬁed with the  justiﬁcation you have received?   (Pre-procurement) Informed Participation.  Learners, educators and  other relevant  practitioners should have  a reasonable  understanding of artiﬁcial  intelligence and its  implications (See Annex  Section 8 for justiﬁcation)8.1Teach students about artiﬁcial  intelligence and its societal and  ethical implicationsWhere in the curriculum, or when during  extracurricular time, will students be taught  about this? What content will they learn?  (Implementation) 8.2Provide educators and/or other  relevant practitioners with  sufﬁcient training to ensure that  they are able to use AI resources  effectively, discerningly and with  conﬁdence. As part of this  training, educators and  practitioners should be trained to  scrutinise the decisions made  and behaviours displayed by AI  systems, in order to guard  against undue deferenceWhat will the content of this training be, and  how much training will educators and/or other  relevant practitioners receive?  (Implementation) Ethical Design.  AI  resources should be  designed by people who  understand the impacts  these resources will have  (see Annex Section 9 for  justiﬁcation)9.1Insist that suppliers provide  relevant information to conﬁrm  that a range of stakeholders (e.g.  learners, educators, careers  advisers, youth workers) were  consulted as part of the design  processWhat information have you received from the  suppliers, and are you satisﬁed that a range of  stakeholders (e.g. learners, educators, careers  advisers) were consulted as part of the design  process? (Pre-procurement) 9.2Insist that suppliers provide  relevant information to conﬁrm  that a diverse range of people  contributed to the design and  development of the AI resourceWhat information have you received from the  suppliers, and are you satisﬁed that a diverse  range of people contributed to the design of the  AI resource? (Pre-procurement) 9.3Ensure that the supplier can  conﬁrm that AI resources were  designed by practitioners who  have had training on the ethical  implications of AI in educationWhat information have you received from the  suppliers, and are you satisﬁed that AI  resources were designed by practitioners who  have had training on the ethical implications of  AI in education? (Pre-procurement) Licenced under Creative Commons Attribution-NoDerivatives 4.0 International .  Please see disclaimer on the Institute’s website
Conclusion The Institute has now concluded its 2.5 year task, but the need to apply ethical principles to AI  in education will only grow year on year.   To reinforce The Ethical Framework for AI in Education, the Institute encourages governments  and civil society actively to take steps to ensure that learners, educators and all members of  society have a strong understanding of AI and its ethical implications. Informed users will  invariably be in a better position to make full use of AI whilst diligently guarding against its risks,  and whilst The Ethical Framework for AI in Education does not necessitate prior knowledge of  AI, a strong understanding of AI will aid judicious use of the Framework. A number of countries  are already making progress towards achieving this goal. For instance, the United Kingdom’s AI  Roadmap urges the government to commit to achieving ambitious goals for AI and data literacy. The Institute would like to thank all those who participated in the roundtables, the Global  Summit, and the expert interviews, along with everyone else who has supported our work.  Above all the Institute would like very warmly to thank all members of the Institute’s Advisory  Council and International Advisory Group (a full list of members is available on our website ).  They all took precious time out from their very busy lives to guide and steer the Institute. The  Institute would like ﬁnally to thank those organisations who have funded the Institute’s work:  McGraw Hill, Microsoft Corporation, Nord Anglia Education, and Pearson PLC. Looking towards the future, for learners to beneﬁt from AI that is both ethically designed and  applied, the Institute’s mission must live on through the continued efforts of those with the  power to inﬂuence the development and deployment of AI in education, and also through The  Ethical Framework for AI in Education itself. Only if well-intentioned people from diverse  backgrounds continue to work together with the interests of learners, especially the most  disadvantaged, in mind, will we ensure that AI is truly going to ﬁnd its optimal use, which  maximises its potential, and minimises its downsides. The active engagement of governments globally, and the United Nations, and those involved in  education at all levels is, as the Institute has repeatedly stated, sine qua non. It will be for  others, in the UK and beyond, to take forward the Institute’s mission and reﬁne the Framework  in light of new developments. The Institute welcomes such developments, be that a foundation  - which could be transnational - the development of kitemarks and accreditation schemes, or  further research into how AI can be used in education to maximise the gains of learners,  especially the most vulnerable, while mitigating the known risks .
When you think of the future of AI in education,  what images come to your mind? Visions of screens? Robotics and circuitry? I wonder if your first thought includes any people; the close and crucial relationships between leaders and pupils, educators, communities and employers that shape the world around us. At Pearson, it is the people in education who are  our priority; teaching staff, school leaders, students and families alike. Given our passion and focus on digital, lifelong learning, we pride ourselves on working hand in hand with educators to deliver learning through engaging, immersive and highly personalised experiences. Whether people love the idea or fear it, the impact  of AI on learning and the world of work is evident. By supporting the work of the Institute of Ethical AI in Education (IEAIED), we are proud to be part of the conversation about how we harness AI’s potential, to amplify great teaching and use these technologies to boost every child’s ability to thrive. The sector has already made incredible progress  – not least over the past twelve months. And, with further developments on the horizon many of our educators are already preparing for it. In our recent poll of 7000 teachers, one in seven believe that we will see an increased use of AI educational resources and in our Pearson Global Learner Survey 1 of  11,000 learners, 70% of learners in the UK, US and Europe believe that AI will have a positive impact on education.  Even before Covid created a new focus on remote  and hybrid learning, Pearson has supported teachers and schools with digital resources, benefitting a diverse range of pupils. Almost 4 million students globally access our digital learning service ActiveLearn and Pearson’s Online Schools provide full-time education to over 105,000 children and young people a year using our online learning platforms. In the STEM sector, we developed the pioneering  KS2 service Maths Flex, building on the foundations of White Rose Maths to shape highly interactive pathways for improved maths practice *. Using  established techniques and expert knowledge, and placing our user privacy as paramount, the service provides a truly personalised learning pathway for pupils, with the programme ‘flexing’ to each individual’s style. It targets areas of strength and weakness; leads students down a learning route appropriate to their needs; automarks work to reduce teacher workload and generates easy-to-read insights on which children need stretch and intervention.  For myself and my colleagues, the human-centric  nature of the IEAIED framework is paramount and we are proud to demonstrate our commitment to efficacy and ethical products, both in creating new products and in the completion of research, including a new longitudinal study into the impact of remote teaching pedagogy on learners. We’re dedicated to ensuring that AI-enabled  pathways such as Maths Flex are just one of the many unrivalled tools in the Educator’s Toolkit: one that allows schools to focus on the areas that most require it; to refine what they know about the pupils they care for without discrimination or bias; and to ensure that the progress of every child is counted. People are using technology in every aspect of  their lives and they are now embracing it as part of their education. From online degrees and AI tools to smart devices, people see the future of learning made easier and more engaging with technology.  As leaders, educators, parents, carers, and as  members of a global, online community, we have a shared responsibility to lay strong, ethical foundations for this tech-powered future. In partnership with the IEAIED, Pearson is ready to take learning to the next level for all learners.   Want to know more about Pearson’s  learnings and developments in AI?   Visit go.pearson.com/digitallearning    to find out more. Sharon Hague is Senior Vice President for  Schools at Pearson and a member of the Institute of Ethical AI in Education   advisory group.  Follow Pearson on Twitter   @PearsonSchools PEUK B0255 1 https://www.pearson.com/content/dam/global-store/global/resources/Pearson_Global_Learner_Survey_2019.pdf  Finding togetherness  through tech * Maths Flex follows the White Rose Maths scheme of work but is not endorsed by White Rose Maths.
About Nord Anglia Education  Nord Anglia Education (NAE) is the world’s leading premium schools organisation, with 73  schools across 30 countries. Our schools go beyond traditional learning  to deliver a high  quality, transformational education to 67,000 students from kindergarten through to the end  of secondary school. We offer multiple internationally recognised curriculums, including the  English Curriculum, the International Baccalaureate, the Swiss Maturité and the US  Curriculum, amongst others.  Our global scale enables us to recruit and retain world-leading teachers and to offer our  students unforgettable experiences  through our partnerships with world-renowned  institutions The Juilliard School, the Massachusetts Institute of Technology and UNICEF. As  part of the NAE family, every student can connect and collaborate on our Global Campus  online platform to bring their learning to life  beyond the classroom.  Founded in 1972 in the United Kingdom, initially offering learning services such as Englishas-a-foreign-language classes, NAE opened its first international school in 1992: the British  School Warsaw. In the 2000s, NAE began a strategic focus on premium international  schools, with rapid growth in Asia, the Americas, China and across Europe and the Middle  East. In July 2019, the company relocated its headquarters from Hong Kong to London. “We applaud the important work undertaken by the Institute for  Ethical AI in Education . The Ethical Framework for AI in Education is  a major milestone in best practice that will help unlock AI’s potential  as a means to transform teaching and learning.  “We are committed to ensuring that the Framework sits at the heart of  our education technology procurement decisions. We believe that the  Framework provides clarity and consistency that will benefit  educators, learners and resource providers for years to come.”  For more information, please visit www.nordangliaeducation.com
    The information contained  in this document represents the current view of Microsoft Corporation on the issues discussed as of the date of publication. Because Microsoft must respond to changing market  conditions, it should not be interpreted to be a commitment on the part of Micro soft, and Microsoft cannot guarantee the accuracy of any information presented after the date of publication.    © 20 20 Micros oft Corporation. All rights reserved .    Respons ible AI in Education   With the emergence of artificial intelligence, the opportunity to provide truly  personali sed, accessible learning and experiences to all students around the world is now  upon us. Microsoft ’s mission in education is to empower every student on the planet to  achieve more. We believe e ducation leaders should consider opportunities to introduce  new technologies like AI into the design of learning and technological blueprints to  expand the horizon for driving better outcomes and efficiencies for every student and  institution around the world.   Microsoft’s AI B usiness School  offers a  learning path for education ; designed to  help  education leaders, decision -makers and students,  understand how AI can enhance  the learning environmen t. Designed to empower learners to gain specific, practical  knowledge to define and implement an AI strategy , the learning path is available  on Microsoft Learn , a free platform to support learners of all ages and experi ence levels  via interactive, online, self -paced learning. Included is  a specific module focusing on  six  principles that we believe should guide AI development and use — fairness, reliability  and safety, privacy and security, inclusiveness, transpar ency, and accountability.  For us,  these principles are the cornerstone of a responsible and trustworthy approach to AI .     We believe that students to day will be the changemakers of tomorrow, so empowering  them with the tools and opportunities to learn new skills and be future leaders is core to  our mission.  Imagine Cup Junior provides students aged 13 to 18 the opportunity to learn  about technolog y and how it can be used to positively change the world. The global  challenge introduc es students to AI and  Microsoft’s AI for Good  initiatives to come up  with ideas to solve social, cultural and environmental issues.     Ensuring A I is open to all across  the education system: whether leaders, students or  teachers will enable more responsible, ethical and fair use .  
McGraw Hill (MH), a leader in learning science  and digital  courseware , enforces the ethical  use of Artificial Intelligence to  achieve educational goals . Supporting Learning Integrity:  McGraw Hill Connect® offers remote  proctoring and browser-locking  capabilities that enable instructors  to support academic integrity and  assessment security, with features like  preventing students from navigating  away from a test environment,  verifying students’ identities, and  monitoring them as they complete  assessments. Instructors have  the choice to select from a wide  range of options and customize the  assessment experience based on  educator preference, institutional  objectives, or an accrediting body’s  requirements. Offering coaching and feedback  on writing skills:  Connect’s Writing  Assignment helps students improve  their written communication skills and  conceptual understanding with built-in  grammar and writing review.  Delivering personalized reading  and study experiences through  SmartBook® 2.0 : Instructors can  assign Connect’s adaptive reading  experience with SmartBook 2.0.  Rooted in advanced learning science  principles, SmartBook 2.0 delivers  to each student a personalized  experience, focusing students on their  learning gaps, ensuring that the time  they spend studying is time wellspent. Meet students where they are  in Math:  Building on 20 years of  experience in adaptive learning,  ALEKS® offers a personalized Math  journey with unique backgrounds  and foundational knowledge; every  student starts in a different place.  ALEKS helps instructors provide the  equitable support and structure each  student needs for success. MH solutions give faculty choice, protect the learner’s privacy,   and help all learners achieve. mheducation.com/highered
  
