                                                                                          Page 1/5                                                                                             © National Council  for AI     Egyptian Charter for Responsible AI   2023  v1.0  Introduction and Background   As the use of Artificial Intelligence (AI) systems becomes more prevalent, the need has arisen  for all stakeholders to become more aware of their potential risks and limitations. Despite their  undeniable benefits, AI systems, if designed, deployed or used incorrectly, can pose  significant risks. Among those are: biased  or wrong results, data drift, lack of transparency,  lack of legal responsibility, lack of fairness and equality, to name but a few.     Governments , international organizations , as well as larg e corporations are therefore waking  up to the necessity of governing AI projects properly to ensure those risks are mitigated or  minimized . As part of its efforts to build an AI industry, which started over 2 years with  the  launch of the National AI S trategy, Egypt has taken a leading role in drafting several of the  ethics guidelines around AI in different international organizations  such as the OECD,  UNESCO, G20, and the expert group established by the UN to address issues related to  autonomous weapons, in addition to other  international organizations and initiatives.  In  addition, it is leading teams within the African Union and the Arab League working to unify  ethical recommendations for AI on the regional level, to ensure that the priorities, needs , and  special circumstances of our societies are considered .     Egypt's efforts were met with worldwide recognition as it became the first Arab or African  country to adhere to the OECD Princi ples on Responsible AI, and an early a dopter of the  UNESCO sta ndard-setting instrument on AI e thics. As most of these recommendations are  non-binding and quite generic, it is incumbent upon the different countries to develop their own  local interpretations of these guidelines and translate them into actionable insights and policies  for decision makers in government, academia, industry , and civil society.   Document Scope   This document serves as the first attempt at articulating Egypt's interpretation of the various  guidelines on ethical and responsible AI, adapted to the local context and combined with  actionable insights to help ensure the responsible development, deployment, management ,  and use of AI systems in the country. It draws upon the guidelines developed by the OECD,  UNESCO, WHO, IEEE, EU, as well as by many lead ing countries such as Singapore, UK, US,  Australia , and others. Although most international guidelines are still non -binding, it is  expected that a set of standards would soon be issued by international organizations  for AI  systems worldwide (the EU AI Act  being the first such standard). In that regard, this document  serve s 2 purposes:  
                                                                                          Page 2/5                                                                                             © National Council  for AI     1. To be a “ soft launch ” to empower citizens to expect and demand the best from the use of  AI and for all stakeholders to be aware of ethical considerations related to AI and  incorporate those  considerations into their AI adoption plans.   2. To signal Egypt's readiness to follow responsible AI practices, something many investors  as well as AI ranking bodies look to measure a country’s readiness for AI investment and  adoption. It woul d also help to communicate Egypt’s needs and priorities to foreign AI  developers looking to develop or market their products in the country.     It is expected that this document shall be reviewed on an annual basis to ensure its continuous  currency and relevance. It is also expected that a public consultation shall take place prior to  each revision to ensure that the perspectives of all stakeholde rs are considered.     The document is divided into two parts:   • General Guidelines , which are overarching rules applicable to all members of the  ecosystem,   • Implementation Guidelines , which are technical considerations, mainly applicable to any  entity developing, deploying , or managing an AI system.     Each guid eline is tagged with the most relevant key principle of responsible AI.   General Guidelines   1. The primary goal of using AI in  Government is the well -being of citizens, including  combating poverty, hun ger, inequality, illiteracy, and corruption; achieving prosperity and  inclusion; increasing fairness and transparency; augmenting human capabilities;  protecting the environment; invigorating economic growth and opening new markets and  job opportunities for  Egyptians. [Human -Centeredness]    2. Any end -user using an AI system has the fundamental right to know when he or she is  interacting with an AI system and not a human being, for example in the case of  automated call centers. [Transparency and Explainability]   3. No individual should be harmed by the introduction of an AI system. Special  considerations must be taken to protect vulnerable and marginalized groups such as  children,  PWDs, and those of an inferior economic or educational level. Sample  considerati ons include checking potential data bias, tuning system parameters  periodically, and preferring development team diversity. [Fairness]   4. Appropriate mechanisms should be in place to allow anyone adversely affected by an AI  system to challenge its outcome bas ed on plain and easy -to-understand information on  the factors, and the logic that served as the basis for the prediction, recommendation, or  decision. [Fairness]   5. Documented policies and processes should be  in place to quickly respond to and resolve  any adv erse outcomes caused by the unauthorized use of AI systems. [Fairness]   6. AI systems should not be designed to primarily replace human labor except in cases that  pose danger or risk to human wellbeing. If job losses are inevitable as a side effect of an  other wise beneficial AI system, measures should be taken by the system owner  (Government, private sector, or other) to ensure a fair transition for workers as AI is  deployed, such as through training programmes along the working life, support for those 
                                                                                          Page 3/5                                                                                             © National Council  for AI     affected  by displacement, and access to new opportunities in the labor market.  [Human Centeredness]   7. All stages of t he life cycle of the AI system, including data collection, hosting, and  engineering, and system development, testing, deployment, continuous operation,  monitoring , and maintenance, are subject to the relevant laws of the Arab Republic of  Egypt, including laws of consumer protection , personal data protection, and anticybercrimes . [Accountability]   8. Certification mechanisms for AI systems or simi lar forms of regulation are  introduced by  the appropriate regulatory bodies in the different domains to ensure the safety,  transparency, robustness, and reliability of AI systems based on each domain’s  requirements.  [Accountability]   9. International efforts should be pursued continuously to develop guidelines for the  responsible use of AI in military applications. [Human -Centeredness]   10. Ultimate responsibility and accountability for the behavior  and outcomes of an AI system  must always lie  with natural or legal persons. AI systems should not be given legal  personality themselves. To ensure this, any regulatory framework should be consistent  with the principle of human oversight and establish a comprehensive approach focused  on the actors an d the technological processes involved across the differen t stages of the  AI systems life cycle.  [Accountability]   11. Final Human Determination is always in place. This means that ultimately, humans are in  charge of making decisions, and are able to modify, stop, or retire the AI system if deemed  necessary. Individuals with that power must be decided upon by the owner of the system.   [Security and Safety ]  12. All members of the AI ecosystem, especially academic and educational institutions,  should promote capacity  building and public awareness programmes about AI  development, including various AI technologies such as supervised, unsupervised, and  reinforcement machine learning, and  the opportunities and  challenges brought about by  those technologies. Those  programm es should encourage multi -disciplinary collaboration  and should be accessible to technical and non-technical groups alike . [Transparency  and Explainability]   13. AI systems that support entrepreneurship through innovative start -ups and MSMEs  should be encourage d and made a priority in order to achieve economic prosperity  and  society welfare . [Human -Centeredness]   Implementation Guidelines   1. AI systems should be robust, secure , and safe throughout their entire lifecycle so that, in  conditions of normal use, foreseeable use , misuse, reward hacking, or other adverse  conditions, they function appropriately and do not pose unreasonable safety risk.   [Security and Safety]   2. Ideally, any  AI project should be preceded by a pilot or proof of concept (PoC) to ensure  the technical viability of the solution. Specific success criteria should be set and only if  those are met can the pilot be deemed successful and ready for large -scale  implementa tion. [Accountability]   3. Additional measures should be in place  in case of sensitive or mission -critical AI  applications, including additional measures to ensure data protection , beneficiary  engagement, and avoid ance of  any harm resulting from applications. [Security and  Safety]  
                                                                                          Page 4/5                                                                                             © National Council  for AI     4. AI projects that go into production must be developed by qualified entities with proven  experience in product -grade AI solution  development. The teams should be diverse  enough to include system architects, AIOps  and QA engineers, cybe rsecurity experts,  software engineers (non -AI engineers that develop the application or platform hosting the  AAI models), data scientists, AI engineers (specialty will depend on the nature of the  project), at least one domain expert , and one project manage r. [Accountability]   5. Domain experts are a crucial part of any AI team. They are the professionals who  understand the business problem and can guide the team in terms of data availability and  quality, as well as validating the relevance of the results to the  problem at hand.  [Accountability]   6. Government entities, private companies, academic and research organizations, and any  other entities developing AI systems should work with a representative sample of the  beneficiaries of their AI systems.  [Fairness ]  7. Developers of AI systems must adopt a systematic risk management approach as part of  the system development lifecycle, which augments and complements the usual software  development lifecycle (SDLC) to include risks specific to AI systems such as privacy, d igital  security, safety , and bias.  [Security and Safety]   8. Developers of AI systems should always strive to provide transparent and explainable AI  solutions. The degree of explainability required will vary according to the application  domain and project requ irements, but project sponsors must be clear on the potential  tradeoff between the accuracy/quality and explainability of any given model. When in  doubt, developers should opt for simpler models with higher degrees of explainability,  without compromising t he minimum desired quality and accuracy.  [Transparency and  Explainability]   9. Developers of AI systems are encouraged to examine and address the cultural impact of  AI systems, especially Natural Language Processing applications such as automated  translation a nd voice assistants impacted by  the nuances of human language and  expression. Such addressing  should provide input for the design and implement ation of  strategies that maximiz e the benefits from these systems by bridging cultural gaps and  increasing human understanding, as well as minimizing negative implications such as the  reduction of use, which could lead to the disappearance of endangered languages, local  dialects, and tonal and cultural variations associated with human language and  expression.  [Fairne ss]  10. All members of the AI ecosystem, including government agencies, academic and  educational institutions, and private sector companies, should facilitate access by the  scientific community to their data for research purposes, provided that such access doe s  not come at the expense of privacy. [Accountability]   11. The use of any data must be pre -authorized by the data owner except in the case of data  available in the public domain. Personally identifiable data must be anonymized and/or  encrypted depending on the  domain, and express written consent from the data owner  must be obtained according to applicable laws. Data inputs should be comprehensive, and  as much as possible, disaggregated, with corrections of  distortions like invisibility of  minorities .  [Security  and Safety]   12. AI systems, especially data -driven models, must be monitored regularly while in production  to ensure no data drift occurs. In those cases, the quality of the data must be reviewed  and if needed, the underlying models need to be changed to accommodate changes in  data.  [Fairness]   13. Foreign companies looking to roll out their AI products in Egypt must adhere to these  guidelines, and must also ensure that their models  have been trained using local data, 
                                                                                          Page 5/5                                                                                             © National Council  for AI     relevant to the Egyptian market  and availed  through law-abiding mechanisms , and that  they adhere to local customs and religious and social traditions and norms. Proper testing  of these systems must be performed to ensure their quality and accuracy, before they are  introduced to the Egyptian market.  [Fairness ]  14. All Government AI projects must be preceded by a thorough impact assessment to ensure  maximum benefit from the technology, while respecting the guidelines of responsible and  ethical AI development. Specifically, the following questions should b e asked:   a. What is the problem to be solved, and is AI the best way to solve it or are there other  ways that could be cheaper, faster, or more reliable?   b. Is the data required for the project ready and of sufficient volume and quality to ensure  the desired out put?  c. Are the underlying processes properly engineered? AI is not a solution for broken  processes but a technique to optimiz e certain variables. If the underlying process is  broken or inefficient, this problem will only be amplified by the use of an AI syst em.  d. What is the financial impact of the solution, both direct (project cost) and indirect,  including potential loss of jobs?   e. What is the social impact, if any?   f. What is the environmental impact, if any?   g. Is the data available diverse enough to cover all pote ntial use cases of t he solution, in  order to minimiz e bias? For example, in the case of healthcare solutions, is data  available from different ethnicities, genders, age groups, and medical conditions, in  addition to any other factors that might impact the outcome?   All of the above points must be weighed against the impact and expected result of  implementing the solution using non -AI technologies. Only if the benefits (including  positive impacts) outweigh the costs (including any negative impact), can the project be  approved.  [Accountability]   15. Government AI projects should be implemented using components from the National AI  Platform once completed. Until then, any project should be implemented in a modular,  service -oriented way, and using open source and white box/non -proprietary technologies  to ensure tr ansparency and maintainability. [Accountability]   16. Government AI projects, similar to Digital Transformation projects, should be  commissioned and supervised by Ministry of Communications and Information Technology   (MCIT) in order to ensure compliance with th ese guidelines and the credibility and quality  of data and developers involved in the development of AI systems.  MCIT  presents  periodic ally on status of those projects to the National AI Council.  [Accountability]      
