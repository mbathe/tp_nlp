I Recommendation Unboxing Artificial Intelligence:   10 steps to protect Human Rights

Unboxing Artificial Intelligence:  10 steps to protect Human Rights By the Council of Europe Commissioner for Human Rights Council of Europe
Cover photo:  © Shutterstock.com © Council of Europe, May 2019 Printed at the Council of EuropeAcknowledgements: The Commissioner would like  to express her gratitude to  Nani Jansen Reventlow, human  rights lawyer and Director of  the Digital Freedom Fund, and  Jonathan McCully, independent  consultant and Legal Adviser  to the Digital Freedom Fund,  for their invaluable assistance  and expertise in preparing this  Recommendation.
Page 3Contents INTRODUCTION  5 RECOMMENDATIONS  7 1 - Human rights impact assessment 7 2 - Public consultations 8 3 - Obligation of member states to facilitate the implementation of  human rights standards in the private sector 9 4 - Information and transparency 9 5 - Independent oversight  10 6 - Non-discrimination and equality 11 7 - Data protection and privacy 11 8 - Freedom of expression, freedom of assembly and association, and  the right to work  12 9 - Remedies 13 10 - Promotion of “AI literacy”  14 CHECKLISTS  17 ANNEX DEFINITIONS   24

Page 5Introduction  The impact of Artificial Intelligence (AI) on human rights is one of the  most crucial factors that will define the period in which we live. AI-driven  technology is entering more aspects of every individual’s life, from smart  home appliances to social media applications, and it is increasingly being  utilised by public authorities to evaluate people’s personality or skills,  allocate resources, and otherwise make decisions that can have real and  serious consequences for the human rights of individuals. As stressed by  the Commissioner for Human Rights in a Human Rights Comment , finding  the right balance between technological development and human rights  protection is therefore an urgent matter.  In accordance with the mandate of the Commissioner for Human Rights  to promote the awareness of and effective observance and full enjoyment  of human rights in Council of Europe member states as well as to provide  advice and information on the protection of human rights (Articles 3 and  8 of Resolution (99) 50 of the Committee of Ministers), the Commissioner  issues this 10-point Recommendation on AI and human rights. There is currently no agreed definition of “Artificial Intelligence” . However,  for the purposes of this Recommendation, AI is used as an umbrella term  to refer generally to a set of sciences, theories and techniques dedicated  to improving the ability of machines to do things requiring intelligence.  An AI system is a machine-based system that makes recommendations,  predictions or decisions for a given set of objectives. It does so by: (i)  utilising machine and/or human-based inputs to perceive real and/or virtual  environments; (ii) abstracting such perceptions into models manually or  automatically; and (iii) deriving outcomes from these models, whether by  human or automated means, in the form of recommendations, predictions  or decisions.  A list of further relevant terminology used in this Recommendation can be  found in the Glossary in the Annex. 
Page 6 - Unboxing Artificial IntelligenceAI involves opportunities as well as risks; human rights should be  strengthened by AI, not undermined. This Recommendation on AI and  human rights provides guidance on the way in which the negative impact  of AI systems on human rights can be prevented or mitigated, focusing on  10 key areas of action. The Recommendation builds on work done in this area by the Council of  Europe, in particular the European Ethical Charter on the use of artificial  intelligence in judicial systems , the Guidelines on Artificial Intelligence  and Data Protection , the Declaration by the Committee of Ministers on the  manipulative capabilities of algorithmic processes  and the Study on the  human rights dimensions of automated data processing techniques and  possible regulatory implications , as well as the report of the United Nations  Special Rapporteur on the promotion and protection of the freedom of  opinion and expression, addressing the implications of artificial intelligence  technologies for human rights in the information environment. It is rooted  in the existing universal, binding and actionable framework provided by the  international human rights system, including the human rights instruments  of the Council of Europe.  The Recommendation is addressed at member states, but the principles  concern anyone who significantly influences – directly or indirectly – the  development, implementation or effects of an AI system. AI developed in  the private sector should be held to the same standards as that developed  in the public sector if and when there is any intention to work with public  bodies and public services.  The annexed checklist identifies actionable points for each key area,  providing general guidance on operationalising the recommendations.  
Page 7Recommendations 1 - Human rights impact assessment Member states should establish a legal framework that sets out a procedure  for public authorities to carry out human rights impact assessments (HRIAs)  on AI systems acquired, developed and/or deployed by those authorities.  HRIAs should be implemented and operationalised in a similar vein as  other forms of impact assessment conducted by public authorities, such as  Regulatory Impact Assessments and Data Protection Impact Assessments.  Member states may delineate the types of AI system that are subject  to HRIAs under the law, but such delineations must be comprehensive  enough to cover all AI systems that have the potential to interfere with an  individual’s human rights at any stage of the AI system lifecycle. As part of the HRIA legal framework, public authorities should be required  to conduct a self-assessment of existing and proposed AI systems. This  self-assessment should evaluate the potential impact of the AI system on  human rights taking into account the nature, context, scope, and purpose  of the system. Where a public authority has not yet procured or developed  a proposed AI system, this assessment must be carried out prior to the  acquisition and/or development of that system.  The HRIAs must also include a meaningful external review of AI systems,  either by an independent oversight body or an external researcher/auditor  with relevant expertise, in order to help discover, measure and/or map  human rights impacts and risks over time. Public bodies should consider  involving National Human Rights Structures (NHRSs) in carrying out this  meaningful external review.  Self-assessments and external reviews should not be limited to an  evaluation of the models or algorithms behind the AI system, but should  include an evaluation of how decision-makers might collect or influence  the inputs and interpret the outputs of such a system. It should also include  an assessment of whether an AI system remains under meaningful human  control throughout the AI system’s lifecycle.  
Page 8 - Unboxing Artificial IntelligenceIn circumstances where the self-assessment or external review discloses  that the AI system poses a real risk of violating human rights, the HRIA  must set out the measures, safeguards, and mechanisms envisaged for  preventing or mitigating that risk. In circumstances where such a risk has  been identified in relation to an AI system that has already been deployed  by a public authority, its use should be immediately suspended until the  abovementioned measures, safeguards and mechanisms have been  adopted. Where it is not possible to meaningfully mitigate the identified  risks, the AI system should not be deployed or otherwise used by any public  authority. Where the self-assessment or external review discloses a violation  of human rights, the public authority must act immediately to address and  remedy the violation and adopt measures to prevent or mitigate the risk of  such a violation occurring again.  The HRIAs, including research findings or conclusions from the external  review process, must be made available to the public in an easily accessible  and machine-readable format. Public authorities should not acquire AI systems from third parties in  circumstances where the third party is unwilling to waive restrictions on  information (e.g. confidentiality or trade secrets) where such restrictions  impede or frustrate the process of (i) carrying out HRIAs (including carrying  out external research/review), and (ii) making HRIAs available to the public. Public authorities should be required to conduct HRIAs on a regular basis,  and not only at the point where public authorities acquire and/or develop  AI systems. HRIAs should, at the very least, be undertaken at each new  phase of the AI system lifecycle and at similarly significant milestones. 2 - Public consultations State use of AI systems should be governed by open procurement standards,  applied in a transparently run process, in which all relevant stakeholders  are invited to provide input. Member states should consider updating their  access to information, open government, and public procurement laws and  policies to reflect AI-specific requirements.  Member states should allow for public consultations at various stages of  engaging with an AI system, and at a minimum at the procurement and  HRIA stages. A meaningful public consultation process entails timely and  prior publication of all relevant information on the AI system that facilitates a  proper understanding of its operation, function, and potential or measured  impacts. Consultations should provide an opportunity for all stakeholders,  including state actors, private sector representatives, academia, the nonprofit sector, the media and representatives from marginalised and affected 
Recommendations  - Page 9groups or communities, to provide input. NHRSs act as a bridge between  civil society and state authorities and can help conduct meaningful  consultations. 3 - Obligation of member states to facilitate the  implementation of human rights standards in the  private sector Member states should effectively implement the UN Guiding Principles on  Business and Human Rights and the Recommendation CM/Rec(2016)3 of  the Committee of Ministers to member states on human rights and business.  They should do so in a non-discriminatory manner with due regard to  gender-related risks. In addition, they should set out clearly the expectation  that all AI actors (e.g. AI creators, owners, manufacturers, managers, service  providers and other AI enterprises) who are domiciled or operate within  their jurisdiction, should likewise implement these principles throughout  their operations. In order to comply with their positive and procedural obligations under the  European Convention on Human Rights, member states should apply such  measures as may be necessary to protect the human rights of individuals  against violations by AI actors throughout AI systems’ entire lifecycle.  Member states should specifically ensure that their legislation creates  conditions that are conducive to the respect for human rights by AI actors  and do not create barriers to effective accountability and remedy for AIrelated human rights violations. Member states should apply additional measures to require AI actors  to respect human rights, including, where appropriate, by carrying out  human rights due diligence. Member states should require AI actors to  take effective action to prevent and/or mitigate the harms posed by their  AI systems, and AI actors should be transparent about efforts to identify,  prevent, and mitigate the harms posed by their AI systems. Member states  should provide for adequate consequences if identified risks of adverse  human rights impacts are not duly mitigated and addressed. 4 - Information and transparency The use of an AI system in any decision-making process that has a meaningful  impact on a person’s human rights needs to be identifiable. The use of an  AI system must not only be made public in clear and accessible terms,  individuals must also be able to understand how decisions are reached and  how those decisions have been verified.
Page 10 - Unboxing Artificial IntelligenceIf an AI system is used for interaction with individuals in the context of  public services, especially justice, welfare, and healthcare, the user needs  to be notified and the possibility of recourse to a professional upon request  and without delay must be communicated. Those who have had a decision  made about them by a public authority that is solely or significantly  informed by the output of an AI system should be notified and be promptly  provided with the aforementioned information.  Oversight over an entire AI system must also be enabled by transparency  requirements. This can be either in the form of public disclosure of  information on the system in question, its processes, direct and indirect  effects on human rights, and measures taken to identify and mitigate  against adverse human rights impacts of the system, or in the form of  an independent, comprehensive, and effective audit. In all cases, the  information made available should allow for meaningful assessment of  the AI system. No AI system should be complex to the degree it does not  allow for human review and scrutiny. Systems that cannot be subjected to  appropriate standards of transparency and accountability should not be  used. 5- Independent oversight  Member states should establish a legislative framework for independent  and effective oversight over the human rights compliance of the  development, deployment and use of AI systems by public authorities and  private entities. This legislative framework may include mechanisms that  consist of a combination of administrative, judicial, quasi-judicial and/or  parliamentary oversight bodies effectively cooperating with each other.  Member States should consider empowering, where appropriate, existing  NHRSs so they can perform a role in providing independent and effective  oversight over the human rights compliance of AI systems. Oversight bodies should be independent of the public authorities and  private entities developing, deploying or otherwise using the AI systems, and  they must be equipped with appropriate and adequate inter-disciplinary  expertise, competencies and resources to carry out their oversight function. Independent oversight bodies should proactively investigate and monitor  the human rights compliance of AI systems, receive and handle complaints  from affected individuals, carry out periodic reviews of AI system capabilities  and technological developments more generally. They should have the  power to intervene in circumstances where they identify (a risk of) human  rights violations occurring. They should also regularly report to parliament  and publish reports about their activities.
Recommendations  - Page 11Public authorities and private parties should be required to provide all the  information necessary for effective oversight of AI systems upon request  and regularly report to the oversight bodies. They should implement  oversight bodies’ recommendations regarding human rights impacts of  AI systems. Oversight processes must also be transparent and subject to  appropriate public scrutiny and the decisions of the oversight bodies must  be subject to appeal or independent review. 6 - Non-discrimination and equality In all circumstances, discrimination risks must be prevented and mitigated  with special attention for groups that have an increased risk of their rights  being disproportionately impacted by AI. This includes women, children,  older people, economically disadvantaged persons, members of the LGBTI  community, persons with disabilities, and “racial” , ethnic or religious groups.  Member states must refrain from using AI systems that discriminate or lead  to discriminatory outcomes and, within their jurisdiction, protect individuals  from the consequences of use of such AI systems by third parties. The active participation of and meaningful consultation with a diverse  community that includes effective representation from these groups in  all stages of the AI lifecycle is an important component of prevention and  mitigation of adverse human rights impacts. In addition, special attention  needs to be paid to transparency and accessibility of information on the  training data used for the development of an AI system. HRIAs and other  forms of human rights due diligence should be repeated at regular intervals  and appropriate and accessible avenues for accountability and redress  made available. Member states should apply the highest level of scrutiny when using AI  systems in the context of law enforcement, especially when engaging in  methods such as predictive or preventive policing. Such systems need  to be independently audited prior to deployment for any discriminatory  effect that could indicate de facto profiling of specific groups. If any such  effects are detected, the system cannot be used.  7 - Data protection and privacy The development, training, testing and use of AI systems that rely on the  processing of personal data must fully secure a person’s right to respect for  private and family life under Article 8 of the European Convention on Human  Rights, including the “right to a form of informational self-determination” in  relation to their data.
Page 12 - Unboxing Artificial IntelligenceData processing in the context of AI systems shall be proportionate in  relation to the legitimate purpose pursued through such processing, and  should at all stages of the processing reflect a fair balance between the  interests pursued through the development and deployment of the AI  system and the rights and freedoms at stake. Member states should effectively implement the modernised Council  of Europe Convention for the Protection of Individuals with regard to  Automatic Processing of Personal Data (“Convention 108+”) as well as  any other international instrument on data protection and privacy that is  binding on the member state. The processing of personal data at any stage  of an AI system lifecycle must be based on the principles set out under  the Convention 108+, in particular (i) there must be a legitimate basis laid  down by law for the processing of the personal data at the relevant stages  of the AI system lifecycle; (ii) the personal data must be processed lawfully,  fairly and in a transparent manner; (iii) the personal data must be collected  for explicit, specified and legitimate purposes and not processed in a way  incompatible with those purposes; (iv) the personal data must be adequate,  relevant and not excessive in relation to the purposes for which they are  processed; (v) the personal data must be accurate and, where necessary,  kept up to date; (vi) the personal data should be preserved in a form which  permits identification of data subjects for no longer than is necessary for  the purposes for which those data are processed.  Member states should introduce a legislative framework that provides  appropriate safeguards where AI systems rely on the processing of  genetic data; personal data relating to offences, criminal proceedings  and convictions, and related security measures; biometric data; personal  data relating to “racial” or ethnic origin, political opinions, trade-union  membership, religious or other beliefs, health or sexual life. Such safeguards  must also provide protection against this data being processed in a  discriminatory or biased way.   8 - Freedom of expression, freedom of assembly and  association, and the right to work  In the context of their responsibility to respect, protect and fulfil every  person’s human rights and fundamental freedoms, member states should  take into account the full spectrum of international human rights standards  that may be engaged by the use of AI.  Freedom of expression: Member states should be mindful of the obligation  to create a diverse and pluralistic information environment and the adverse  impact AI-driven content moderation and curation can have on the 
Recommendations  - Page 13exercise of the right to freedom of expression, access to information, and  freedom of opinion. Member states are also encouraged to consider taking  appropriate measures to regulate technology monopolies to prevent the  adverse effects of concentration of AI expertise and power on the free flow  of information. Freedom of assembly and association: Special attention should be paid  to the impact the use of AI systems in content moderation can have on  the freedom of assembly and association, especially in contexts where  these freedoms are difficult to exercise offline. The use of facial recognition  technology should be strictly regulated by member states, including  through legislation setting out clear limitations for its use, and public  transparency to protect the effective exercise of the right to freedom of  assembly.    Right to work: The potential of AI to accelerate automation and thereby  negatively impact the availability of work should be carefully monitored.  Regular assessments should be made to track the number and types of  jobs created and lost due to AI developments. Adequate plans should be  developed for reschooling and reassigning jobs to those workers clearly  affected by a decrease in the demand for human labour. Member states  should also adapt education curricula to ensure access to jobs requiring  competences related to AI systems. 9 - Remedies AI systems must always remain under human control, even in circumstances  where machine learning or similar techniques allow for the AI system to  make decisions independently of specific human intervention. Member  states must establish clear lines of responsibility for human rights violations  that may arise at various phases of an AI system lifecycle. Responsibility and  accountability for human rights violations that occur in the development,  deployment or use of AI Systems must always lie with a natural or legal  person, even in cases where the measure violating human rights was not  directly ordered by a responsible human commander or operator. Anyone who claims to be a victim of a human rights violation arising from  the development, deployment or use by a public or private entity of an  AI system should be provided with an effective remedy before a national  authority. Moreover, member states should provide access to an effective  remedy to those who suspect that they have been subjected to a measure  that has been solely or significantly informed by the output of an AI system  in a non-transparent manner and without their knowledge.  Effective remedies should involve prompt and adequate reparation and 
Page 14 - Unboxing Artificial Intelligenceredress for any harm suffered by the development, deployment or use  of AI systems, and may include measures under civil, administrative, or,  where appropriate, criminal law. NHRSs can be such a source of redress,  through rendering their own decisions in accordance with their respective  mandates.  Member states should provide individuals with the right not to be subject  to a decision significantly affecting them that is based on automated  decision-making without meaningful human intervention. At the very  least, an individual should be able to obtain human intervention in such  automated decision-making and have their views taken into consideration  before such a decision is implemented.  Member states must ensure that individuals have access to information in the  possession of a defendant or a third party that is relevant to substantiating  their claim that they are the victim of a human rights violation caused by an AI  system, including, where relevant, training and testing data, information on  how the AI system was used, meaningful and understandable information  on how the AI system reached a recommendation, decision or prediction,  and details of how the AI system’s outputs were interpreted and acted on. When national authorities consider challenges to human rights violations  caused by the development, deployment or use of AI systems, they must  show appropriate scepticism towards the “allure of objectivity” presented  by AI systems and ensure that individuals challenging human rights abuses  are not held to a higher standard of evidence compared to those responsible  for the measure being challenged.  10 - Promotion of “AI literacy” The knowledge and understanding of AI should be promoted in  government institutions, independent oversight bodies, national human  rights structures, the judiciary and law enforcement, and with the general  public. Member states should consider establishing a consultative body  within government to advise on all AI-related matters. Those involved directly or indirectly in the development or application of AI  systems need to have the necessary knowledge and understanding of how  it functions and be informed about its impact on human rights. In order for  such actors to be informed about the impact of their systems on human  rights, they must also be made aware of the spectrum of human rights  standards that might be engaged by their work. Member states should invest in the level of literacy on AI with the general  public through robust awareness raising, training, and education efforts, 
Recommendations  - Page 15including (in particular) in schools. This should not be limited to education  on the workings of AI, but also its potential impact – positive and negative  – on human rights. Particular efforts should be made to reach out to  marginalised groups, and those that are disadvantaged as regards IT literacy  in general.

Page 17ChecklistsHuman rights impact assessmentDo’s DO take steps to introduce laws and regulations requiring HRIAs to  be conducted in relation to AI systems that have been or may be  acquired, developed and/or deployed by public authorities. DO promptly carry out HRIAs in relation to all AI systems that  have already been deployed/are already being used by any public  authority at the time the relevant legal framework on HRIAs has  been adopted. Otherwise, HRIAs must first be conducted prior to  the acquisition and/or development of an AI system by a public  authority. DO continuously monitor the implications of AI systems on human  rights throughout their lifecycle, and carry out regular HRIAs at each  new phase of the lifecycle and when there are changes in context,  scope, nature and purpose of the systems. Don’ts DO NOT  fail to meaningfully consult with and get input from  relevant stakeholders, including civil society organisations and  those with relevant expertise in AI and human rights, when  introducing a legal framework on HRIAs. DO NOT  conduct HRIAs in a non-transparent manner, and do not  use or facilitate the use of laws on confidentiality, privacy, trade  secrets, state secrecy, or intellectual property to frustrate the  carrying out or publication of HRIAs. DO NOT  acquire, develop, deploy or use an AI system that has the  potential of interfering with human rights in circumstances where  (i) it has not been subject to an HRIA, or (ii) an HRIA has disclosed  that the AI system poses a real risk of violating human rights, and  no measures, safeguards, or mechanisms have been adopted for  preventing or mitigating the identified risks.
Page 18 - Unboxing Artificial IntelligencePublic consultationsDo’s DO apply open procurement standards and a transparent process  to the use of AI systems. DO include all stakeholders in public consultations, including  the affected groups or communities, at a minimum during the  procurement and HRIA stages. Don’ts DO NOT  provide for public consultations without taking adequate  measures to make them meaningful, including timely prior  publication of all relevant information related to the AI system, and  actively seeking the engagement of all relevant stakeholders.Obligation of member states to facilitate the implementation of  human rights standards in the private sectorDo’s DO carry out an audit of existing criminal and civil laws, as well as  other equivalent liability regimes, to identify gaps or obstacles for  holding AI actors to account for AI-related human rights violations. DO enforce existing laws where necessary to meet the state duty  to protect the human rights of individuals against violations by AI  actors. DO take steps to ensure AI actors “know and show” that they are  meeting their responsibility to respect human rights, including  through transparent human rights due diligence processes that  involve the identification of the human rights risks associated with  their AI systems, and taking effective action to prevent and/or  mitigate the harms posed by such systems. Don’ts DO NOT  treat laws, policies and regulations that are applicable to  the AI sector as being isolated from, or uninformed by, the human  rights obligations on member states. DO NOT  facilitate the implementation and enforcement of human  rights standards in the AI sector in a discriminatory manner.
Checklists  - Page 19Information and  transparencyDo’s DO provide all necessary information for individuals to understand  when and how AI systems are being used, especially in the context  of public services. Don’ts DO NOT  use AI systems that are complex to a degree that they  cannot be subjected to human review and scrutiny by appropriate  standards of transparency and accountability. 
Page 20 - Unboxing Artificial IntelligenceIndependent oversightDo’s DO legislate for the establishment of a framework for independent  and effective oversight over the human rights compliance of AI  systems, drawing on existing oversight bodies including NHRSs  where possible. DO take steps to ensure all relevant oversight bodies have  access  to sufficient expertise, have received appropriate training on AI  systems and their implications for human rights, and have received  adequate funding and other resources in order to carry out their  functions effectively. DO ensure that the functions of the relevant oversight bodies  are adequate for the purpose of investigating and monitoring all  actors, whether public or private, that may be responsible for AI  system human rights violations (including those that occur during  their development, testing and use). Don’ts DO NOT  limit the functions and powers of oversight bodies to  such an extent that they are unable to meaningfully intervene  in circumstances where they identify (a risk of) human rights  violations occurring. DO NOT  compromise the institutional, operational, financial and  personal independence of the oversight bodies responsible for  investigating and monitoring the human rights compliance of AI  systems. DO NOT  deprive, or allow others to deprive, oversight bodies of  the information necessary for them to carry out their functions  effectively, including by depriving them of access to (training  and testing) datasets, AI inputs/outputs, models/algorithms,  operational guidance and human rights due diligence.
Checklists  - Page 21Non-discrimination and  equalityDo’s DO prevent and mitigate discrimination risks of the use of AI  systems for groups that have an increased risk of their rights being  disproportionately impacted by it. DO apply the highest level of scrutiny when using AI systems in  the context of law enforcement, especially to avoid profiling of  individuals belonging to specific groups. Don’ts DO NOT  use AI systems or allow third parties to use AI systems that  discriminate or lead to discriminatory outcomesData protection and privacyDo’s DO carry out a review and assessment of existing data protection  laws to determine whether they sufficiently protect the right  to respect for private life and the right to data protection in the  context of AI systems, and institute legal reform where they do not. DO proactively take steps to ensure that private and public entities  involved in developing, deploying and using AI systems respect  data subjects’ rights and meet their obligations under applicable  data protection laws. Don’ts DO NOT  provide broad and disproportionate data processing  exemptions or immunities to those who develop, deploy or use AI  systems. DO NOT  permit the development or use of AI systems that rely on  training or testing datasets that have been collected or otherwise  processed in violation of the right to respect for private life and the  right to data protection. DO NOT  permit the development or use of AI systems that process  personal data, either as input or output data, in violation of the  right to respect for private life and the right to data protection.
Page 22 - Unboxing Artificial IntelligenceFreedom of expression, freedom of  assembly and association, right to workDo’s DO take into account the full range of international human rights  standards potentially engaged by the use of AI. DO be mindful of the impact AI-driven content moderation  and curation can have on the exercise of the right to freedom of  expression, access to information, and freedom of opinion. DO strictly regulate the use of facial recognition technology to  allow effective exercise of the right to freedom of assembly. DO monitor the potential negative impact of AI on the right to work  and plan for mitigation, including through schooling. Don’ts DO NOT  permit or facilitate the development, deployment or use  of AI systems that violate any of the human rights protected under  international human rights standards.
Checklists  - Page 23RemediesDo’s DO carry out an assessment of existing laws, including civil, criminal  and administrative laws, and institute reform where those laws do  not provide an effective remedy to those claiming to be a victim of a  human rights violation arising from the development, deployment  or use of an AI system. DO ensure that liability regimes clearly establish who is legally  responsible for the whole spectrum of human rights violations that  may occur at each phase of an AI system’s lifecycle. DO ensure that the judiciary and other relevant national authorities  do not place inappropriate weight on the assumed/perceived  accuracy or objectivity of an AI system, and that they provide an  equality of arms between the victim and the defendant in cases  challenging human rights violations caused by AI systems. Don’ts DO NOT  permit the development, deployment or use of AI systems  that operate wholly outside of any human control.   DO NOT  allow for individuals to be subject to an automated decision  that significantly affects them in circumstances where they have not  been provided with an opportunity to obtain meaningful human  intervention and have not had their views taken into consideration  before the decision has been implemented.Promotion of AI literacyDo’s DO establish a consultative government body to advise on AIrelated matters. DO promote knowledge and understanding of AI and human  rights for all, ranging from those involved in the development of AI  systems, to the general public. Don’ts DO NOT  limit AI literacy efforts to technological aspects without  including its potential impact on human rights.
Page 24 - Unboxing Artificial IntelligenceAnnex   Definitions  For the purpose of this Recommendation, the following terms should be  understood as follows: Algorithm : A finite suite of formal rules/commands, usually in the form  of a mathematical logic, that allows for a result to be obtained from input  elements. Artificial Intelligence (AI) : An umbrella term that is used to refer to a set  of sciences, theories and techniques dedicated to improving the ability of  machines to do things requiring intelligence. AI system : A machine-based system that can make recommendations,  predictions or decisions for a given set of objectives. It does so by utilising  machine and/or human-based inputs to: (i) perceive real and/or virtual  environments; (ii) abstract such perceptions into models manually or  automatically; and (iii) use model interpretations to formulate options for  outcomes. AI system lifecycle : A set of phases concerning an AI system that involve: (i)  planning and design, data collection and processing, and model building; (ii)  verification and validation; (iii) deployment; (iv) operation and monitoring;  and (v) end of life. Automated decision-making : A process of making a decision by  automated means. It usually involves the use of automated reasoning to aid  or replace a decision-making process that would otherwise be performed  by humans. It does not necessarily involve the use of AI but will generally  involve the collection and processing of data. Machine learning : A field of AI made up of a set of techniques and algorithms  that can be used to “train” a machine to automatically recognise patterns in  a set of data. By recognising patterns in data, these machines can derive  models that explain the data and/or predict future data. In summary, it is  a machine that can learn without being explicitly programmed to perform  the task. Model : An actionable representation of all or part of the external  environment of an AI system that describes the environment’s structure  and/or dynamics. The model represents the core of an AI system. A model  can be based on data and/or expert knowledge, by humans and/or by  automated tools like machine learning algorithms.  Personal data : Information relating to an identified or identifiable natural  person, directly or indirectly, by reference to one or more elements specific 
Annex - Definitions  - Page 25to that person. S ensitive personal data  concern personal data relating to  “racial” or ethnic origin, political opinions, religious or philosophical beliefs,  trade union membership, as well as genetic data, biometric data, data  concerning health or concerning sex life or sexual orientation.  Personal data processing : Any operation or set of operations performed  or not using automated processes and applied to personal data or sets  of data, such as collection, recording, organisation, structuring, storage,  adaptation or modification, retrieval, consultation, use, communication by  transmission, dissemination or any other form of making available, linking  or interconnection, limitation, erasure or destruction.

ENThe Commissioner for Human Rights is an independent and impartial  non-judicial institution established in 1999 by the Council of Europe to  promote awareness of and respect for human rights in the member states. The activities of this institution focus on three major, closely related areas : •  country visits and dialogue with national authorities and civil society,  •  thematic studies and advice on systematic human rights work, and  •  awareness-raising activities. The current Commissioner, Dunja Mijatović, took up her  functions in April 2018. She succeeded Nils Muižnieks  (2012-2018), Thomas Hammarberg (2006-2012) and Álvaro   Gil-Robles (1999-2006). www.commissioner.coe.int   The Council of Europe is the continent’s leading   human rights organisation. It comprises 47 member  states, 28 of which are members of the European  Union. All Council of Europe member states have  signed up to the European Convention on Human  Rights, a treaty designed to protect human rights,  democracy and the rule of law. The European Court  of Human Rights oversees the implementation   of the Convention in the member states.www.coe.int
