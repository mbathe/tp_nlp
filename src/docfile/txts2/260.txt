REGUL ATING FOR EUROPE ANAI THAT PROTECTS AND ADVANCES EQU ALITY P O S I T I O N  P A P E R  L A Y I N G D O W N R E C O M M E N D A T I O N S A N D C O R E C O M P O N E N T S F O R F U T U R E E U L E G I S L A T I O N O N A R T I F I C I A L I N T E L L I G E N C E
2 Regulating for European AI that Protects and Advances Equality  is published by Equinet, European  Network of Equality Bodies. Equinet  brings together 47 organisations from across Europe  which are  empowered to counteract discrimination as national Equality Bodies across the range of grounds  including age, disability, gender, race or ethnic origin, religion or belief, and sexual orientation.    Equinet members : Commissioner for the Protection from Discrimination, Albania  | Austrian  Disability Ombudsman, Austria  | Ombud for Equal Treatment, Austria  | Unia (Interfederal Centre for  Equal Opportunities), Belgium  | Institute for Equality between Women and Men, Belgium  |  Institution of Human Rights Ombudsman, Bosnia and Herzegovina  | Commission for Protection  against Discrimination,  Bulgaria  | Office of the Ombudsman,  Croatia  | Ombudsperson for Gender  Equality,  Croatia  | Ombudswoman for Persons wit h Disabilities, Croatia  | Office of the  Commissioner for Administration and the Protection of Human Rights (Ombudsman), Cyprus  | Office  of the Public Defender of Rights, Czech Republic | Danish Institute for Human Rights, Denmark  |  Gender Equality and Equa l Treatment Commissioner, Estonia  | Ombudsman for Equality, Finland |  Non -Discrimination Ombudsman,  Finland | Defender of Rights, France  | Public Defender  (Ombudsman), Georgia | Federal Anti -Discrimination Agency, Germany  | Greek Ombudsman,  Greece | Office of the Commissioner for Fundamental Rights, Hungary  | Irish Human Rights and  Equality Commission, Ireland | National Office Against Racial Discrimination, Italy  | Ombudsperson  Institution, Kosovo*  | Office of the Ombudsman, Latvia | Office of the Equal Opportunities  Ombudsperson, Lithuania  | Centre for Equal Treatment, Luxembourg  | National Commission for the  Promotion of Equality, Malta | Commission for the Rights of Persons with Disability, Malta | Council  on Preventing and Eliminating Discrimination and Ensuring Equality, Moldova | The Protector of  Human Rights and Freedoms (Ombudsman), Montenegro | Netherlands Institute for Human Rights,  Netherlands  | Commission for Prevention and Protection against Discrimination,  North Macedonia  |  Equality and Anti -Discrimination Ombud,  Norway  | Commissioner for Human Rights, Poland |  Commission for Citizenship and Gender Equality, Portugal  | Commission for Equality in Labour and  Employment, Portugal | High Comm ission for Migration, Portugal | National Council for Combating  Discrimination, Romania | Commissioner for Protection of Equality, Serbia  | National Centre for  Human Rights,  Slovakia | Advocate of the Principle of Equality, Slovenia  | Council for the Elimination  of Ethnic or Racial Discrimination, Spain |Institute of Women, Spain | Equality Ombudsman, Sweden   | Equality and Human Rights Commission, UK – Great Britain | Equality Commission for Northern  Ireland, UK – Northern Ireland    *This designation is without prejudice to positions on status and is in line with UNSCR 1244/1999  and t he ICJ Opinion on the Kosovo declaration of independence. E quinet  Secretariat | Place Victor Horta, 40 | 1060 Brussels | Belgium |    info@equineteurope.org | www.equineteurope.org     ISBN 978-92-95112 -49-0 (Online)     © Equinet  20 21 - Reproduction is permitted provided the source is acknowledged.    This is a publication of Equinet’s Secretariat , prepared based on the information, contributions and  comments provided by members of the Equinet Cluster on Artificial Intelligence . The veracity of the  information provided is the responsibility of each member of the Cluster. The views expressed in it belong to the author and neither Equinet nor the European Commission are liable for any use that  may be made of the information contained therein. This information does not necessarily reflect the  position or opinion of individual members of Equinet or the European Commission.   Acknowledgements   Author : Milla Vidina, Equinet, European Network of Equality Bodies   Formatting : Teresa Pedreira, Equinet, European Network of Equality Bodies  
  3   Contents   Objective and Context  ................................ ................................ ................................ ...... 4  Recommendations  ................................ ................................ ................................ ...........  5  I. Equality should be a central consideration in any EU regulation on AI.  ..................... 5  II. Establish effective and accessible complaint and redress mechanisms for rights -  holders agai nst AI -induced breaches of equality and fundamental rights  ........................ 5  III. Apply a fundamental rights -based approach to defining “harm” and “risk”, not one  rooted in product safety models.  ........................................................................................ 6  IV. Require ex ante and ex post equality impact assessments for the entire life cycle of  AI systems.  .......................................................................................................................... 6  V. Assign mandatory and enforceable ‘equality duties’ to all AI developers and users.  7  VI. Make risk differentiation only possible after a mandatory equality and h uman rights  impact assessment.  ............................................................................................................ 8  VII. Make national- level enforcement effective through an obligation of national  supervisory authorities under the future AI Regulation to consult with equality bodies  and other national fundamental rights regulators  ............................................................. 8  VIII. Make the establishment and secure and adequate resourcing of national and  European- level cooperation mechani sms between the different bodies involved in its  enforcement mandatory.  .................................................................................................... 9      
  4   Objective and Context  The following  key recommendations are the building blocks on the present Equinet Position Paper  on the forthcoming legislative proposal by the European Commission, which is expected to introduce  a risk -based approach to addressing a number of ethical and legal issues r aised by AI. The Inception  Impact Assessment o f this legislative proposal describes the first specific aim under the proposal’s  general objective in the following manner: “ […]  (a) to ensure the effective enforcement of rules of  existing EU law meant to protect safety and fundamental rights and avoid illegal discrimination by  ensuring the relevant documentation for the purposes of private and public enforcement of EU rules.”   Equality is explicitly and prominently addressed as one of the leading human  rights concerns related  to the impact of AI systems , which the proposed regulation is going to address. The role of equality  bodies is expected to be affected, among others ways, by the possible designation of new AI -specific  auditing and enforcement mech anisms, which will also exercise their powers with respect to  protecting the right to non -discrimination.   Based on the Equinet Report on  AI and on our two submissions to the European Commission’s  consultation on AI ( one targeted and one general), the current recommendations aim to reflect the  position of equality bodies on the below two overarching questions, namely:    How to protect equality in the context of AI -enabled systems    How to ensure that the role and powers of equality bodies are augmented and effectively  taken into account when designing and developing the broader infrastructure of  enforcement and redress of rights in the context of AI systems.   This paper should be read in conjunction with Equinet’s  ambitions and proposals for EU legislation  on equality bodies . I t views AI systems and their future regulation as part and parcel of a broader  discussion on the impl ications of new technologies and digitalization for equality and non discrimination,  and proposes an equality mainstreaming approach, as an overarching and horizontal  requirement, through all recommendations.   
  5   Recommendations   I. Equality should be a central consideration in any EU regulation on  AI.  By their  very nature, AI systems work through mechanisms of exclusion and differentiation, hence  presenting disproportionately large risks to the protection of equality. Equality enhances the  effectiveness of other fundamental rights, could be a precondition for their enjoyment and its  violation by AI systems has a much larger and more systemic detrimental effect on society. This results from the specific nature of AI -enabled technology, which acts on a large scale  and in non transparent and hard to predict ways, allowing harm and breaches of the non -discrimination  principle to occur during the entire life cycle of AI development, deployment and use. The risk to the protection of equality that AI systems pose is further exacerbated by the use of these systems for decision -making in several critical spheres of human life, such as employment, education, social  security, and law enforcement.   To acknowledge and address the specific and substantive challenges to the non -discrimination  principle that AI systems present, the future Artificial Intelligence Act (AIA) should contain explicit  references to the protection of equality as a leading fundamental rights concern.  This need is all the  more pressing due to the fact tha t AI systems challenge the ability of the existing non -discrimination  legal framework to protect against algorithmic discrimination, for example, through allowing unequal treatment alongside algorithmically constituted categories of differentiation which d o not  fit into the existing legally protected grounds.  To remedy these limitations, through incorporating an explicit acknowledgement of non -discrimination as a leading fundamental rights objective of the  regulation, the future AIA could provide mechanism s for identifying and redressing the full range of  possible AI -enabled discriminatory practices.   II. Establish effective and accessible complaint and redress  mechanisms for rights- holders against AI-induced breaches of  equality and fundamental rights   The cur rent draft AIA proposes no mechanism for citizens’ complaints and for the provision of  redress. This is especially problematic in the context of an AI -specific regulation, as denied access to  justice for victims is at the heart of the challenge that AI -enabled technologies pose to equality and  human rights. To remedy this, the future AIA should contain explicit and clear provisions for individual and collective redress, including effective remedies  for algorithmic harm caused by any AI  system, regardless of its risk classification.  The future Act should also contain effective enabling conditions for exercising the right to redress.   These conditions should include, at a minimum, individual rights to  people impacted by AI systems,  including the right not to be subject to AI systems not compliant with the future AIA, as well as the right to be provided with an intelligible and accessible explanation for decisions involving the use of  an AI system withi n the scope of the Act.   Related to that, the AIA should include a clear and accessible mechanism for existing fundamental  rights regulators, such as equality bodies, as well as for public interest organisations to lodge a 
  6   complaint with national supervisory authorities for AI systems which threaten equality and  fundamental rights protection, as well as provisions that this complaint triggers an investigation into the system.    The involvement of equality bodies, through a legal obligation to be consulted  by national  supervisory authorities under the proposed Act, would strengthen redress possibilities under the  future AIA and ensure complementarity and reinforcement of impact between the new AI -specific  redress mechanism and existing specialised non- discr imination redress mechanisms such as equality  bodies. Through their focus on support and advise to individual victims of discrimination, including  through handling complaints and litigation work, national equality bodies are uniquely wellpositioned to con tribute to the provision of redress against AI -induced breaches of equality.   III. Apply a fundamental rights -based approach to defining “harm” and  “risk”, not one rooted in product safety models.     Article 7 of the current Proposal defines adverse impact and harm in a way that is rather unclear and  without sufficient alignment with existing equality and fundamental rights legislation in the EU.  The  classification of an AI system as high -risk is based exclusively on existing product safety legislation  and accordingly, does not reflect the unique nature of harm that results from fundamental rights  violations.  Protection against high -risk products from the perspective of consumer safety is not the  same  as protection against high- risk products from the perspective of their impact on fundamental  rights.  The legal safeguards for these distinct risks (product safety vs. fundamental rights) should be differentiated accordingly by the future EU AIA, with equality and fundamental rights receiving  stricter and enhanced protection through more and more demanding mandatory requirements. The  process of risk assessment, which will lead to a determination about the applicable requirements, should involve impacted groups and communities and this mandatary participation should be explicitly stipulated in the text of the future AIA.   Any regulatory definition and categorization of “harm” for the purpose of protecting equality and human rights should be grounded in a  broader and more inclusive understanding of harm — one  that takes in to account the immaterial, as well as societal and collective, nature of harm when it  comes to equality and human rights.      IV. Require ex ante and ex post equality impact assessments for the  entire life cycle of  AI systems.   Risk prediction and risk detection through mandatory equality impact assessments should happen for AI systems , which uses show evident discrimination risks,  during the entire life cycle of AI  development, deployment and use .  This would enable a preventive and proactive approach to  equality protection, thereby precluding that individuals and/or entire communities are turned into victims by these systems.  Given the intrinsic significance of equality and its horizontal reach in relation to other human rights, its protection through mandatory ex ante and ex post impact assessments should involve third parties and not be solely entrusted to the developers and users of  AI systems.  
  7   A compelling rationale for making equalit y impact assessments mandatory in the context of AI  systems is also given by the existing General Data Protection Regulation. Article 35 (3)(a) of the  GDPR requires Data Protection Impact Assessments for all  machine learning systems, and since  these systems constitute one of the prominent categories of AI -enabled technologies, if EU’s future  Act on AI doesn’t require mandatory impact assessments, this could lead to fragmented and inconsistent protection against AI -induced risks to equality and human righ ts.   To preclude this and  also in order to ensure legal certainty, the future AIA should create a requirement fo r ex ante and ex  post equality impact assessments for the entire life cycle of AI systems, which is aligned with and takes into account the results of data protection impact assessments under the GDPR.     V. Assign mandatory and enforceable ‘equality duties’ to all AI  developers and users.   Equality mainstreaming is enshrined as a legal duty in Articles 8 and 10 of the Treaty of the  Functioning of th e EU and has been established as a priority in EU’s recent policy agenda through the  setting up of a dedicated Task Force on Equality, specifically tasked to mainstream equality in all EU policies. ‘Equality Duties’  1— defined as positive legal obligation s to promote equality and prevent  discrimination, going beyond the general obligation to refrain from discrimination —are an essential  tool for equality mainstreaming.   Equality duties will complement the effect of equality impact assessments by creating o bligations for AI developers and users to proactively monitor the effects on  equality of the AI systems they develop and/or use as well as of their own institutional practices  through recruiting and promoting a diverse workforce, which develops and/or uses  these AI systems.    The proposed regulation on AI should prioritize — in its desired impact and, consequently, in the  choice of suggested means for achieving this impact — the prevention of equality and human rights  violations by AI systems. To this end, clear ‘equality duties’ should be assigned to AI owners and  creators, including safeguards that these duties can be effectively enforced and the capacity to issue  effective, proportionate and dissuasive sanctions.        1 Equinet's work on the equality mainstreaming practices of equality bodies in Europe, namely  “Compendium of Good Practices in Equality Mainstreaming ” (2021) and ‘ Making Europe More Equal:  A Legal Duty? ’ (2016), identified three main categories of statutory equality duties in place in Europe:  1) Preventive du ties are statutory duties on organisations (public and private) to take measures to  prevent discrimination, harassment or sexual harassment in employment or in the provision of goods and services. 2) Institutional duties are statutory duties on organisatio ns (public and private) to  promote equality for employees or for people accessing their services. 3) Mainstreaming duties  require public authorities to have due regard to the need to promote equality in carrying out their  functions, including legislating, budgeting, regulating, and policy making. Equality duties with respect  to the development and use of AI systems should encompass all three types of duties— preventive  (public and private duty -holders), institutional (public and private duty -holders) and mainstreaming   (public duty -holders as a minimum).  
  8   VI. Make risk differentiation only possible after a mandatory equality and  human rights impact assessment.   Mandatory impact assessments — both ex ante and ex post — should be the basis for determining  risk levels. Those impacted by AI systems should be consulted and otherwise involved in the design,   development and use of impact assessments. Only once risks have been  clearly identified and  assessed through mandatory ex ante and ex post impact assessments, should measures based on  risk differentiation (e.g. level of oversight, sizes and types of sanct ions and compensation) be  enabled under the future Artificial Intelligence Act. For example, the future Act could allow approaches on monitoring, redress and sanctions to be modulated according to levels of risk identified based on recurrent impact assessm ents.    VII. Make national -level enforcement effective through an obligation of  national supervisory authorities under the future AI Regulation to  consult with equality bodies and other national fundamental rights  regulators   If one of the key objectives of the proposed Regulation on AI is to protect against the potential negative impact of AI systems on fundamental rights, then market surveillance authorities alone or  in collaboration with other national sectoral regulators outside of the fundamental rights area  are  not sufficient to ensure effective ex post enforcement of the regulation in the field of fundamental  rights.    Specialized public bodies focused on monitoring and enforcing fundamental rights, including  equality bodies, are better equipped to protect those rights compared to other national regulators,  whose mandate is not focused on fundamental rights.  Therefore, national e quality bodies should be  consulted whenever enforcement of the future AI Regulation is related to protecting the principle of  equality and the right to non- discrimination.  To ensure consistent and robust enforcement of the future AIA within and across EU jurisdictions, the future Act should create and clarify the specific roles and institutional division of labour be tween  multiple relevant national supervisory and enforcement authorities, including market surveillance authorities, data protection authorities, equality bodies and other existing fundamental rights  regulators. The current Proposal does not provide a clear structure for differentiating and  coordinating the respective supervision and enforcement tasks of the multiple relevant national  regulators, whose participation is required to ensure effective implementation of the future horizontal regulation.   The o nly explicit mention of cooperation between existing national supervision and enforcement  authorities is limited to the following two references: 1)  the power to request and access any documentation maintained following this regulation; 2) where needed, r equest market surveillance  authorities to organize testing of the high -risk AI system through technical means. This opens the  door to potential confusion, duplication of labor and inter- institutional completion, ultimately  weakening the enforcement of the future Regulation.  
  9   VIII. Make the establishment and secure and adequate resourcing of  national and European -level cooperation mechanisms between the  different bodies involved in its enforcement mandatory.   There needs to be national governance structure on AI in the form of a framework for cooperation  of national competent authorities under the proposed AI Regulation in order to enable their  collaboration and develop needed capacity.  Equality bodies are key  partners in the enforcement of  national human rights legislation, and as such, they should be part of this national governance  framework.    AI systems have a complex nature and cross -sectoral use. This means that protecting equality from  AI- related threa ts requires active collaboration and several partnerships, and therefore, the national  supervisory authorities suggested by the EU’s Proposal on AI cannot and should not work in silos.    Thus, the future EU regulation on AI has a key role to play in encour aging governments to  establish  the necessary institutional structures, which enable — on a regular and sustainable basis — these  crucial partnerships and connections.     Equality bodies are key partners in its enforcement and as such, they should be conne cted to  specialized AI oversight and monitoring bodies, as well as to other regulators, which partake in  enforcing the proposed regulation at the national level.    As highlighted by Equinet Report on AI  and by the accompanying document Summary and  Framework for Action for Equality Bodies , AI s ystems have a complex nature and cross -sectoral use.  This means that protecting equality from AI - related threats requires active collaboration and several  partnerships. National equality bodies need to work with national and regional authorities as well as  with actors typically considered non- traditional for the equality field. These may include, for  example, sectoral regulators such as Data Protection Authorities and Consumer Protection  Authorities, computer and data scientists and engineers, within bot h the private sector, academia,  digital rights NGOs and standardization bodies.  The EU has a key role to play in creating an enabling  institutional environment for establishing — on a regular and sustainable basis — these crucial  partnerships and connecti ons.   
ALBANIA Commissioner for the Protection from Discriminationwww.kmd.al AUSTRIA Austrian Disability Ombudsmanwww.behindertenanwalt.gv.at AUSTRIA Ombud for Equal Treatmentwww.gleichbehandlungsanwaltschaft.gv.at BELGIUM Institute for the Equality of Women and Menwww.igvm-iefh.belgium.be BELGIUM Unia (Interfederal Centre for Equal Opportunities)www.unia.be BOSNIA AND HERZEGOVINA Institution of Human Rights Ombudsman of Bosnia and Herzegovinawww.ombudsmen.gov.ba BULGARIA Commission for Protection against Discriminationwww.kzd-nondiscrimination.com CROATIA Office of the Ombudsmanwww.ombudsman.hr CROATIA Ombudsperson for Gender Equalitywww.prs.hr CROATIA Ombudswoman for Persons with Disabilitieswww.posi.hr CYPRUS Commissioner for Administration and Human Rights (Ombudsman)www.ombudsman.gov.cy CZECH REPUBLIC Public Defender of Rightswww.ochrance.cz DENMARK Danish Institute for Human Rightswww.humanrights.dk ESTONIA Gender Equality and Equal Treatment Commissionerwww.volinik.ee FINLAND Non-Discrimination Ombudsmanwww.syrjinta.fi FINLAND Ombudsman for Equalitywww.tasa-arvo.fiFRANCEDefender of Rightswww.defenseurdesdroits.fr GEORGIA Public Defender of Georgia (Ombudsman)www.ombudsman.ge GERMANY Federal Anti-Discrimination Agencywww.antidiskriminierungsstelle.de GREECE Greek Ombudsmanwww.synigoros.gr HUNGARY Office of the Commissioner for Fundamental Rightswww.ajbh.hu IRELAND Irish Human Rights and Equality Commissionwww.ihrec.ie ITALY National Office against Racial Discrimination - UNARwww.unar.it KOSOVO* Ombudsperson Institutionwww.oik-rks.org LATVIA Office of the Ombudsmanwww.tiesibsargs.lv LITHUANIA Office of the Equal Opportunities Ombudspersonwww.lygybe.lt LUXEMBURG Centre for Equal Treatmentwww.cet.lu MALTA Commission for the Rights of Persons with Disabilitywww.crpd.org.mt MALTA National Commission for the Promotion of Equalitywww.equality.gov.mt M OLDOVA   Council on Preventing and Eliminating   Discrimination and Ensuring Equalitywww.egalitate.md M ONTENEGRO Protector of Human Rights and F reedoms  (Ombudsman)www.ombudsman.co.me NETHERLANDS Netherlands Institute for Human Rightswww.mensenrechten.nlNORTH MACEDONIA Commission for Prevention and Protection against Discriminationwww.kszd.mk NORWAY Equality and Anti-Discrimination Ombudwww.ldo.no POLAND Commissioner for Human Rightswww.rpo.gov.pl PORTUGAL Commission for Citizenship and Gender Equalitywww.cig.gov.pt PORTUGAL Commission for Equality in Labour and Employmentwww.cite.gov.pt PORTUGAL High Commission for Migrationwww.acm.gov.pt ROMANIA National Council for Combating Discriminationwww.cncd.ro SERBIA Commissioner for Protection of Equalitywww.ravnopravnost.gov.rs SLOVAKIA Slovak National Centre for Human Rightswww.snslp.sk SLOVENIA Advocate of the Principle of Equalitywww.zagovornik.si SPAIN Council for the Elimination of Ethnic or Racial Discriminationwww.igualdadynodiscriminacion.igualdad.gob.es   SPAINInstitute of Womenwww.inmujer.es SWEDEN Equality Ombudsmanwww.do.se UNITED KINGDOM - GREAT BRITAIN Equality and Human Rights Commissionwww.equalityhumanrights.com UNITED KINGDOM - NORTHERN IRELAND Equality Commission for Northern Irelandwww.equalityni.org * This designation is without prejudice to positions on status, and is in line with UNSCR 1244/1999 and the ICJOpinion on the Kosovo declaration of independence.Equinet Member Equality Bodies ISBN  978-92-95112-49-0  | © Equinet 2021 www.equineteurope.org 
