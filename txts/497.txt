N° 4594  N° 464   ASSEMBLÉE NATIONALE S ÉNAT  CONSTITUTION DU 4 OCTOBRE 1958  QUATORZIÈME LÉGISLATURESESSION ORDINAIRE 2016 - 2017 Enregistré à la présidence de l’Assemblée nationale Enregistré à la présidenc e du Sénat   le 15 mars 2017 le 15 mars 2017  RAPPORT  au nom de  L’OFFICE PARLEMENTAIRE D'ÉVALUATION  DES CHOIX SCIENTI FIQUES ET TECHNOLOGIQUES  POUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE,  UTILE ET DÉMYSTIFIÉE  TOME I : Rapport PAR  M. Claude DE GANAY, député et Mme Dominique GILLOT, sénatrice  Déposé sur le Bureau de l’Assemblée nationale  par M. Jean-Yves LE DÉAUT,  Président de l’Office  Déposé sur le Bureau du Sénat  par M. Bruno SIDO,  Premier vice-président de l’Office   bat 
          Composition de l’Office parlementaire d’évaluation des choix scientifiques  et technologiques          Président  M. Jean-Yves LE DÉAUT, député    Premier vice-président   M. Bruno SIDO, sénateur        Vice-présidents   M. Christian BATAILLE, député M. Roland COURTEAU, sénateur   Mme Anne-Yvonne LE DAIN, députée M. Christian NAMY, sénateur   M. Jean-Sébastien VIALATTE, député Mme Catherine PROCACCIA, sénateur             DÉPUTÉS      SÉNATEURS   M. Bernard ACCOYER  M. Gérard BAPT  M. Alain CLAEYS  M. Claude de GANAY  Mme Françoise GUÉGOT  M. Patrick HETZEL  M. Laurent KALINOWSKI  M. Alain MARTY  M. Philippe NAUCHE  Mme Maud OLIVIER  Mme Dominique ORLIAC  M. Bertrand PANCHER  M. Jean-Louis TOURAINE      M. Patrick ABATE   M. Gilbert BARBIER    Mme Delphine BATAILLE    M. Michel BERSON   M. François COMMEINHES   Mme Catherine GÉNISSON   Mme Dominique GILLOT   M. Alain HOUPERT   Mme Fabienne KELLER   M. Jean-Pierre LELEUX   M. Gérard LONGUET   M. Pierre MÉDEVIELLE   M. Franck MONTAUGÉ   M. Hervé POHER          
 - 3 -            « Science sans conscience n’est que ruine de l’âme  »  Rabelais       « Dans la vie, rien n’est à craindre, tout est à co mprendre »  Marie Curie      « L’intelligence, ça n’est pas ce que l’on sait, mais  ce que l’on fait  quand on ne sait pas  »  Jean Piaget                                         

 - 5 -      S O M M A I R E   Pages  SYNTHÈSE DU RAPPORT  .................................................. ...................................................   11   INTRODUCTION  .................................................. ................................................... ...............  15   PREMIÈRE PARTIE :  ÉLÉMENTS DE CONTEXTE  .................................................. ..........  19   I. LA DÉMARCHE DE VOS RAPPORTEURS  .................................................. ....................  19   A. DE LA PROCÉDURE DE SAISINE À L’ADOPTION D’UN CAL ENDRIER DE  TRAVAIL ........................................... ................................................... ................................  19   1. L’origine et l’instruction de la saisine  .................................................. ................................  19   2. Un calendrier de travail très resserré  .................................................. .................................  20   B. LE CHAMP DES INVESTIGATIONS DE L’ÉTUDE ......... ..................................................  20   1. L’étude de faisabilité du rapport conclut à la p ertinence d’une étude spécifique de  l’OPECST  .................................................. ................................................... ......................  20   2. Un ciblage délibéré sur un nombre limité de prob lématiques et de pistes d’investigation  .......  23   C. LA MÉTHODE DE TRAVAIL .......................... ................................................... .................  26   1. Une méthode de travail fondée sur des auditions bilatérales et des déplacements en  France et à l’étranger  .................................................. ................................................... ......  26   2. L’organisation d’une journée d’auditions publiqu es au Sénat le 19 janvier 2017  ...................  27   3. La consultation d’ouvrages, de rapports et d’art icles parus sur le sujet  .................................  28   II. L’HISTOIRE DES TECHNOLOGIES D’INTELLIGENCE ARTI FICIELLE ET DE  LEURS USAGES  .................................................. ................................................... ............  31   A. DES TECHNOLOGIES NÉES AU MILIEU DU XX E SIÈCLE ........................................... ..  31   1. La préhistoire de l’intelligence artificielle et  sa présence dans les œuvres de fiction  ...............  31   2. Les premières étapes de formation des technologi es d’intelligence artificielle au  XXe siècle, la notion d’algorithme et le débat sur la définition du concept d’intelligence  artificielle  .................................................. ................................................... .......................  33   3. « L’âge d’or » des approches symboliques et des raisonnements logiques dans les années  1960 a été suivi d’un premier « hiver de l’intellig ence artificielle » dans les années 1970  ......  38   4. Un enthousiasme renouvelé dans les années 1980 a utour des systèmes experts, de leurs  usages et de l’ingénierie des connaissances précède  un second « hiver de l’intelligence  artificielle » dans les années 1990  .................................................. ......................................  40   5. Les autres domaines et technologies d’intelligen ce artificielle : robotique, systèmes  multi-agents, machines à vecteur de support (SVM), réseaux bayésiens, apprentissage  machine dont apprentissage par renforcement, progra mmation par contraintes,  raisonnements à partir de cas, ontologies, logiques  de description, algorithmes  génétiques…  .................................................. ................................................... ...................  42 
- 6 - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE         B. L’ACCÉLÉRATION RÉCENTE DE L’USAGE DES TECHNOLOGI ES  D’INTELLIGENCE ARTIFICIELLE GRÂCE AUX PROGRÈS EN AP PRENTISSAGE  AUTOMATIQUE (« MACHINE LEARNING ») ................ ................................................  5 4   1. Les découvertes en apprentissage profond (« deep  learning ») remontent surtout aux  années 1980, par un recours aux « réseaux de neuron es artificiels » imaginés dès les  années 1940  .................................................. ................................................... ....................  54   2. L’apprentissage profond connaît un essor inédit dans les années 2010 avec l’émergence  de la disponibilité de données massives (« big data  ») et l’accélération de la vitesse de  calcul des processeurs  .................................................. ................................................... .....  56   3. Les technologies d’intelligence artificielle con duisent, d’ores et déjà, à des applications  dans de nombreux secteurs  .................................................. ................................................  6 9   4. Par leurs combinaisons en évolution constante, c es technologies offrent un immense  potentiel et ouvrent un espace d’opportunités trans versal inédit  ..........................................  79   5. L’apprentissage automatique reste encore largeme nt supervisé et fait face au défi de  l’apprentissage non supervisé  .................................................. ............................................  81   III. CARACTÉRISTIQUES GÉNÉRALES DE LA RECHERCHE EN INTELLIGENCE  ARTIFICIELLE ET ORGANISATION NATIONALE EN LA MATIÈR E  ......................  82   A. LES CARACTÉRISTIQUES DE LA RECHERCHE EN INTELLIG ENCE  ARTIFICIELLE ...................................... ................................................... ............................  82   1. La place prépondérante de la recherche privée, d ominée par les entreprises américaines  et, potentiellement, chinoises  .................................................. .............................................  82   2. Une recherche essentiellement masculine  .................................................. ...........................  86   3. Une interdisciplinarité indispensable mais encor e insuffisante  .............................................  87   4. Une recherche soumise à une contrainte d’accepta bilité sociale assez forte sous l’effet de  représentations catastrophistes de l’intelligence a rtificielle  .................................................. .  93   5. Une recherche en intelligence artificielle qui s ’accompagne de plus en plus  d’interrogations et de démarches éthiques  .................................................. ..........................  98   B. TABLEAU DE LA RECHERCHE FRANÇAISE EN INTELLIGENC E ARTIFICIELLE .....  98   1. De nombreux organismes publics interviennent dan s la recherche en intelligence  artificielle  .................................................. ................................................... .......................  98   2. Quelques exemples de centres, de laboratoires et  de projets de recherche  ............................... 101   3. Une reconnaissance internationale de la recherch e française et qui s’accompagne d’un  phénomène de rachat de start-up et de fuite des cer veaux lié aux conditions attractives  offertes à l’étranger  .................................................. ................................................... ......... 103   4. Une communauté française de l’intelligence artif icielle encore insuffisamment organisée  et visible  .................................................. ................................................... ......................... 104   5. La sous-estimation des atouts considérables de l a France et le risque de « décrochage »  par rapport à la recherche internationale en intell igence artificielle  ...................................... 106   DEUXIÈME PARTIE :  LES ENJEUX DE L’INTELLIGENCE ART IFICIELLE  ................... 111   I. LES CONSÉQUENCES ÉCONOMIQUES ET SOCIALES DE L’IN TELLIGENCE  ARTIFICIELLE  .................................................. ................................................... ............... 111   A. D’IMPORTANTES TRANSFORMATIONS ÉCONOMIQUES EN COU RS OU À  VENIR ............................................. ................................................... ................................... 111   1. L’évolution vers une économie globalisée dominée  par des « plateformes »  ............................ 111   2. Un risque de redéfinition, sous l’effet de ce no uveau contexte économique, des rapports  de force politiques à l’échelle mondiale  .................................................. ............................... 115  
 - 7 -    3. Des bouleversements annoncés dans le marché du t ravail : perspectives de créations,  d’évolutions et de disparitions d’emplois  .................................................. ............................ 116   B. LA SOCIÉTÉ EN MUTATION SOUS L’EFFET DE L’INTELLI GENCE  ARTIFICIELLE ...................................... ................................................... ............................ 122   1. Les défis lancés par l’intelligence artificielle  aux politiques d’éducation et de formation  continue  .................................................. ................................................... ......................... 122   2. Une révolution potentielle de notre cadre de vie  et de l’aide aux personnes  ........................... 123   3. Le défi de la cohabitation progressive avec des systèmes d’intelligence artificielle dans la  vie quotidienne  .................................................. ................................................... ............... 125   II. LES QUESTIONS ÉTHIQUES ET JURIDIQUES POSÉES PAR  LES PROGRÈS  EN INTELLIGENCE ARTIFICIELLE  .................................................. .............................. 128   A. LES ANALYSES PRÉSENTÉES PAR D’AUTRES INSTANCES P OLITIQUES ................. 128   1. Les deux rapports issus des institutions de l’Un ion européenne : Parlement européen et  Comité économique et social européen (CESE)  .................................................. ................... 128   2. Les trois rapports de la Maison Blanche  .................................................. ............................. 129   3. Le rapport de la Chambre des Communes du Royaume -Uni  ..................................................  133   4. Les initiatives chinoises et japonaises en intel ligence artificielle accordent une place  contrastée aux questions éthiques  .................................................. ...................................... 135   5. La stratégie du Gouvernement français pour l’int elligence artificielle : un plan qui arrive  trop tard pour être intégré dans les stratégies nat ionales destinées au monde de la  recherche  .................................................. ................................................... ........................ 140   B. DES « LOIS D’ASIMOV » À LA QUESTION CONTEMPORAIN E DE LA  RÉGULATION DES SYSTÈMES D’INTELLIGENCE ARTIFICIELLE  .............................. 142   1. Dépasser les « lois d’Asimov » pour envisager un  droit de la robotique  ................................. 142   2. Les questions juridiques en matière de conceptio n (design), de propriété intellectuelle et  de protection des données personnelles et de la vie  privée  .................................................. ... 144   3. Les divers régimes de responsabilité envisageabl es et ceux envisagés  ..................................... 153   4. Les différenciations du droit applicable selon l e type d’agents autonomes : robots  industriels, robots de service, voitures autonomes et dilemmes éthiques afférents  .................. 157   C. LA PRISE EN COMPTE GRANDISSANTE DES ENJEUX ÉTHIQ UES ............................. 162   1. Le cadre national de la réflexion sur les enjeux  éthiques de l’intelligence artificielle  .............. 162   2. Les nombreuses expériences anglo-saxonnes de réf lexion sur les enjeux éthiques de  l’intelligence artificielle  .................................................. ................................................... .. 173   3. Le travail en cours sur les enjeux éthiques au s ein de l’association mondiale des  ingénieurs électriciens et électroniciens (Institut e of Electrical and Electronics  Engineers ou IEEE)  .................................................. ................................................... ........ 185   4. Une sensibilisation insuffisante du grand public  à ces questions et un besoin de partage  en temps réel de la culture scientifique et de ses enjeux éthiques  ........................................... 189   III. LES QUESTIONS TECHNOLOGIQUES ET SCIENTIFIQUES QUI SE POSENT  EN MATIÈRE D’INTELLIGENCE ARTIFICIELLE  .................................................. ....... 191   A. LES SUJETS D’INTERROGATION LIÉS AUX ALGORITHMES UTILISÉS PAR LES  TECHNOLOGIES D’INTELLIGENCE ARTIFICIELLE .......... ........................................... 191   1. Les questions de sécurité et de robustesse  .................................................. ........................... 191   2. Les biais et les problèmes posés par les données  nécessaires aux algorithmes  d’apprentissage automatique  .................................................. .............................................. 192   3. Le phénomène de « boîtes noires » des algorithme s de deep learning appelle un effort de  recherche fondamentale vers leur transparence  .................................................. ................... 193   4. La question des bulles d’information dites « bul les de filtres »  .............................................. 195  
- 8 - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE       B. LES SUJETS D’INTERROGATION LIÉS À LA « SINGULARI TÉ », À LA  « CONVERGENCE NBIC » ET AU « TRANSHUMANISME » ..... .................................... 195   1. La « singularité », point de passage de l’IA fai ble à l’IA forte peut, à long terme,  constituer un risque  .................................................. ................................................... ....... 195   2. Un prophétisme dystopique indémontrable scientif iquement  ................................................. 197   3. Les questions posées par la « convergence NBIC »  .................................................. .............. 202   4. La tentation du « transhumanisme »  .................................................. .................................. 202   TROISIÈME PARTIE :  LES PROPOSITIONS DE VOS RAPPORT EURS  ........................ 205   I. POUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE  ............................................ 205   Proposition n° 1 : Se garder d’une contrainte jurid ique trop forte sur la recherche en  intelligence artificielle, qui - en tout état de ca use - gagnerait à être, autant que possible,  européenne, voire internationale, plutôt que nation ale  .................................................. ....... 205   Proposition n° 2 : Favoriser des algorithmes et des  robots sûrs, transparents et justes, et  prévoir une charte de l’intelligence artificielle e t de la robotique  ........................................... 206   Proposition n° 3 : Former à l’éthique de l’intellig ence artificielle et de la robotique dans  certains cursus spécialisés de l’enseignement supér ieur  .................................................. ...... 208   Proposition n° 4 : Confier à un institut national d e l’éthique de l’intelligence artificielle et  de la robotique un rôle d’animation du débat public  sur les principes éthiques qui  doivent encadrer ces technologies  .................................................. ....................................... 208   Proposition n° 5 : Accompagner les transformations du marché du travail sous l’effet de  l’intelligence artificielle et de la robotique en m enant une politique de formation  continue ambitieuse visant à s’adapter aux exigence s de requalification et d’amélioration  des compétences  .................................................. ................................................... .............. 209   II. POUR UNE INTELLIGENCE ARTIFICIELLE UTILE, AU SE RVICE DE  L’HOMME ET DES VALEURS HUMANISTES  .................................................. ............ 210   Proposition n° 6 : Redonner une place essentielle à  la recherche fondamentale et revaloriser  la place de la recherche publique par rapport à la recherche privée, tout en encourageant  leur coopération  .................................................. ................................................... .............. 210   Proposition n° 7 : Encourager la constitution de ch ampions européens en intelligence  artificielle et en robotique, tout en poursuivant l e soutien aux PME spécialisées, en  particulier les start-up  .................................................. ................................................... .... 212   Proposition n° 8 : Orienter les investissements dan s la recherche en intelligence artificielle  vers l’utilité sociale des découvertes  .................................................. ................................... 213   Proposition n° 9 : Élargir l’offre de cursus et de modules de formation aux technologies  d’intelligence artificielle dans l’enseignement sup érieur et créer, en France, au moins un  pôle d’excellence international et interdisciplinai re en intelligence artificielle et en  robotique  .................................................. ................................................... ........................ 213   Proposition n° 10 : Structurer et mobiliser la comm unauté française de la recherche en  intelligence artificielle en organisant davantage d e concours primés à dimension  nationale, destinés à dynamiser la recherche en int elligence artificielle, par exemple  autour du traitement de grandes bases de données na tionales labellisées  ............................... 215   Proposition n° 11 : Assurer une meilleure prise en compte de la diversité et de la place des  femmes dans la recherche en intelligence artificiel le  .................................................. ........... 215   III. POUR UNE INTELLIGENCE ARTIFICIELLE DÉMYSTIFIÉE  ..................................... 216   Proposition n° 12 : Organiser des formations à l’in formatique dans l’enseignement  primaire et secondaire faisant une place à l’intell igence artificielle et à la robotique  .............. 216   Proposition n° 13 : Former et sensibiliser le grand  public à l’intelligence artificielle par des  campagnes de communication, l’organisation d’un sal on international de l’intelligence  artificielle et de la robotique et la diffusion d’é missions de télévision pédagogiques  ............... 217   Proposition n° 14 : Former et sensibiliser le grand  public aux conséquences pratiques de  l’intelligence artificielle et de la robotisation  .................................................. ...................... 219  
 - 9 -    Proposition n° 15 : Être vigilant sur les usages sp ectaculaires et alarmistes du concept  d’intelligence artificielle et de représentation de s robots  .................................................. ..... 219   CONCLUSION  .................................................. ................................................... .................... 221   SAISINE DE L’OFFICE  .................................................. ................................................... ...... 223   RÉUNION DE L’OPECST DU 14 MARS 2017 : ADOPTION DU R APPORT  .................... 225   LISTE DES PERSONNES RENCONTRÉES  .................................................. ........................ 253   I. PERSONNES RENCONTRÉES PAR LES RAPPORTEURS EN VUE  DE L’ÉTUDE  DE FAISABILITÉ  .................................................. ................................................... ........... 253   II. PERSONNES RENCONTRÉES PAR LES RAPPORTEURS EN VU E DE  L’ÉTABLISSEMENT DU RAPPORT  .................................................. .............................. 254   A. EN FRANCE ...................................... ................................................... ................................ 254   B. À L’ÉTRANGER ................................... ................................................... .............................. 260   BIBLIOGRAPHIE  .................................................. ................................................... ................ 269    

SYNTHÈSE  DU  RAPPORT  - 11  -         SYNTHÈSE DU RAPPORT    LES OBSERVATIONS   L’essor récent des technologies d’intelligence arti ficielle représente un  bouleversement de nature à transformer profondément nos sociétés et nos  économies  mais reste soumis à une contrainte d’acceptabilité  sociale assez forte  sous l’effet de représentations souvent catastrophistes. Le concept d’intelligence  artificielle renvoie à des technologies multiples , nées dans la seconde moitié du  XX e siècle, qui reposent sur l’ utilisation d’algorithmes . Ces technologies, dont les  combinaisons sont en évolution constante, conduisen t d’ores et déjà à des  applications dans de nombreux secteurs et ouvrent un espace d’opportunités  inédit , à même de révolutionner notre cadre de vie et l’a ide aux personnes. Les  progrès en ce domaine posent des questions auxquell es toute la société doit être  sensibilisée : quels sont les opportunités et les risques qui se dessinent ? La France  et l’Europe sont-elles dans une position satisfaisante dans la course mondiale qui  s’est engagée ? Quelles places respectives pour la recherche publique et la  recherche privée  ? Quelle coopération  entre celles-ci ? Quelles priorités pour les  investissements dans la recherche ? Quels principes éthiques, juridiques et  politiques doivent encadrer ces technologies ? La régulation doit-elle se placer au  niveau national, européen ou international  ?  L’irruption de l’intelligence artificielle au cœur du débat public remonte à  un peu plus de deux ans, après la diffusion d’une  lettre d’avertissement sur ses  dangers potentiels , publiée en janvier 2015, signée par 700 chercheur s et  entrepreneurs, lancée pour alerter l’opinion publiq ue et insister sur l’urgence de  définir des règles éthiques. Il est frappant de con stater qu’ aucun argument sérieux  ne venait étayer cette première mise en garde quant  au risque présumé de dérive  malveillante . Pourtant, même sans justification, ni preuve, cet te alerte a contribué à  renforcer les peurs et les angoisses irrationnelles  induites par le déploiement des  technologies d’intelligence artificielle . Tout au long de l’année 2016, les initiatives  en ce domaine se sont multipliées à un rythme effré né. Après l’irruption de  l’intelligence artificielle dans le débat public en  2015, l’année 2016 et le premier  trimestre 2017 ont en effet été jalonnés de nombreux événements et rapports .  Devant cet emballement, alors que les progrès se fo nt à une vitesse exponentielle et  reposent de plus en plus sur un financement privé a ux moyens considérables, il est  indispensable que la réflexion soit conduite de manière sereine e t rationnelle , afin  de démystifier les représentations biaisées de ce concept  et de mettre en avant les  opportunités  et les risques  qui lui sont liés .   Ces représentations excessives, qui peuvent être to talement opposées, sont  accentuées par la phase générale de progrès dans la quelle on se situe : en effet, la  période récente s’apparente à un véritable « printe mps de l’intelligence artificielle ».  Cette période polarise donc les opinions, qui peuve nt être des angoisses excessives  mais aussi des espoirs démesurés : les cycles d’espoirs et de déceptions qui  jalonnent l’histoire de cette technologie invitent à ne pas trop s’enthousiasmer et à  faire preuve d’attentes réalistes . 
- 12  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Les applications sectorielles présentes ou futures, ric hes de la capacité  prédictive de ces technologies, sont d’envergure co nsidérable  et les évolutions  peuvent cependant être rapides, que l’on pense par exemple à l’éducation, à  l’environnement, à l’énergie, aux  transports, à l’aéronautique, à l’agriculture, au  commerce , à la finance, à la défense, à la sécurit é, à la sécurité informatique, à la  communication, aux loisirs, à la santé, à la dépend ance ou, encore, au handicap .  Le présent rapport fournit un état de la recherche sur le concept  d’intelligence artificielle et fait le point sur de nombreux autres rapports parus  récemment  sur le sujet en France et dans le monde. Il présen te aussi les enjeux  éthiques, juridiques, économiques, sociaux et scien tifiques de ces technologies ,  parmi lesquels la place prépondérante de la recherc he privée, dominée par les  entreprises américaines et, potentiellement, chinoi ses, l’accélération du passage à  une économie globalisée dominée par des « plateform es », les transformations du  marché du travail, les régimes de responsabilité, l es biais et les problèmes posés par  les données et les algorithmes, le phénomène de « b oîtes noires » des algorithmes et  la question des « bulles d’information ». Il évoque , par ailleurs, certains sujets  d’interrogation liés à la « singularité », à la « c onvergence NBIC » et au  « transhumanisme » et souligne la nécessité d’une prise en compte grandissante de  règles éthiques .  Les progrès  en intelligence artificielle sont d’abord et avant  tout  bénéfiques . Ils comportent aussi des risques , qu’il serait malhonnête de nier. Mais  ces risques peuvent et doivent être identifiés, anticipés et maîtrisés . L’ imminence   d’une superintelligence  ne fait pas partie de ces risques à court et moyen  termes  mais relève du fantasme. À  long terme , la réalité de cette menace n’est pas  certaine . Le présent rapport se veut une première contribut ion à un travail  indispensable d’identification, d’anticipation et d e maîtrise des risques réels. Ce  travail de démystification et d’objectivation doit être collectif, interdisciplinaire et  international .  Ni quête vaine ni projet de remplacement de l’homme  par la machine,  l’intelligence artificielle représente une chance à s aisir pour nos sociétés et nos  économies . La France doit relever ce défi . Il convient donc d’aller au-delà des  apparences et de regarder la réalité scientifique d errière les espoirs et les angoisses  s’exprimant en réaction au développement de cette t echnologie afin que le débat  public puisse s’engager sereinement .  Le rapport se prononce pour une intelligence artificielle maîtrisée, utile   et démystifiée : maîtrisée, parce que ces technologies devront êtr e les plus sûres,  les plus transparentes et les plus justes possibles  ; utile parce qu’elles doivent,  dans le respect des valeurs humanistes, profiter à tous  au terme d’un large débat  public ; démystifiée, enfin, parce que les difficul tés d’acceptabilité sociale  constatées résultent largement de visions catastrophistes sans fondement . Plutôt  qu’une hypothétique confrontation dans le futur ent re les hommes et les machines,  qui relève d’une forme de science-fiction dystopiqu e, les rapporteurs sont  convaincus du bel avenir de la complémentarité homme-machine . Nous allons  bien plus vers une  intelligence humaine augmentée que vers une intelli gence  artificielle concurrençant l’homme. 
SYNTHÈSE  DU  RAPPORT  - 13  -       LES PROPOSITIONS    I. Pour une intelligence artificielle maîtrisée    Proposition n° 1 : Se garder d’une contrainte jurid ique trop forte sur la recherche en  intelligence artificielle, qui – en tout état de ca use – gagnerait à être, autant que possible,  européenne, voire internationale, plutôt que nation ale.  Proposition n° 2 : Favoriser des algorithmes et des  robots sûrs, transparents et justes et  prévoir une charte de l’intelligence artificielle e t de la robotique.   Proposition n° 3 : Former à l’éthique de l’intellig ence artificielle et de la robotique dans  certains cursus spécialisés de l’enseignement supér ieur.   Proposition n° 4 : Confier à un institut national d e l’éthique de l’intelligence artificielle et  de la robotique un rôle d’animation du débat public  sur les principes éthiques qui doivent  encadrer ces technologies.   Proposition n° 5 : Accompagner les transformations du marché du travail sous l’effet de  l’intelligence artificielle et de la robotique en m enant une politique de formation continue  ambitieuse visant à s’adapter aux exigences de requ alification et d’amélioration des  compétences.    II. Pour une intelligence artificielle utile, au se rvice de l’homme et des valeurs  humanistes    Proposition n° 6 : Redonner une place essentielle à  la recherche fondamentale et revaloriser  la place de la recherche publique par rapport à la recherche privée tout en encourageant leur  coopération.   Proposition n° 7 : Encourager la constitution de ch ampions européens en intelligence  artificielle et en robotique, tout en poursuivant l e soutien aux PME spécialisées, en  particulier les start-up.   Proposition n° 8 : Orienter les investissements dan s la recherche en intelligence artificielle  vers l’utilité sociale des découvertes.   Proposition n° 9 : Élargir l’offre de cursus et de modules de formation aux technologies  d’intelligence artificielle dans l’enseignement sup érieur et créer – en France – au moins un  pôle d’excellence international et interdisciplinai re en intelligence artificielle et en  robotique.   Proposition n° 10 : Structurer et mobiliser la comm unauté française de la recherche en  intelligence artificielle en organisant davantage d e concours primés à dimension nationale,  destinés à dynamiser la recherche en intelligence a rtificielle, par exemple autour du  traitement de grandes bases de données nationales l abellisées.   Proposition n° 11 : Assurer une meilleure prise en compte de la diversité et de la place des  femmes dans la recherche en intelligence artificiel le.   
- 14  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        III. Pour une intelligence artificielle démystifiée     Proposition n° 12 : Organiser des formations à l’in formatique dans l’enseignement primaire  et secondaire faisant une place à l’intelligence ar tificielle et à la robotique.    Proposition n° 13 : Former et sensibiliser le grand  public à l’intelligence artificielle par des  campagnes de communication, l’organisation d’un sal on international de l’intelligence  artificielle et de la robotique et la diffusion d’é missions de télévision pédagogiques.   Proposition n° 14 : Former et sensibiliser le grand  public aux conséquences pratiques de  l’intelligence artificielle et de la robotisation.   Proposition n° 15 : Être vigilant sur les usages sp ectaculaires et alarmistes du concept  d’intelligence artificielle et de représentations d es robots.   
INTRODUCTION  - 15  -         INTRODUCTION    L’intelligence artificielle  n’est pas un simple terrain de jeu , même  si les victoires des systèmes AlphaGo  au jeu de Go face au champion Lee  Sedol en mars 2016 et Libratus  au Poker face à quatre joueurs professionnels  en janvier 2017, ou, auparavant celles de Watson  au jeu télévisé Jeopardy  en  2011 et de Deep Blue  aux échecs face à Garry Kasparov en 1997, pourraie nt le  laisser penser.  Après la révolution qu’ont représentée Internet et les technologies  de l’information et de la communication au cours de s vingt dernières années,  un nouveau bouleversement pourrait transformer prof ondément nos  sociétés et nos économies : l’essor, l’accélération  exponentielle et la  diffusion massive des technologies d’intelligence a rtificielle .  Ces opportunités , qui pourront apporter dans notre futur des  progrès  dans de nombreux domaines , ne font pas suffisamment l’objet  d’une analyse sereine et objective , sans doute sous l’effet d’une opinion  publique souvent mal informée, voire désinformée  en raison de  représentations catastrophistes issues de la scienc e-fiction et d’analyses  médiatiques alarmistes.  L’irruption de l’intelligence artificielle au cœur du débat public  remonte à un peu plus de deux ans, après la diffusi on d’une  lettre  d’avertissement sur les dangers potentiels de l’int elligence artificielle ,  publiée en janvier 2015 et signée par 700 personnal ités, le plus souvent des  scientifiques et des chefs d’entreprises, rejoints par plus de 5 000 signataires  en un an. Elle a été lancée pour alerter l’opinion publique et insister sur  l’urgence de définir des règles éthiques et une cha rte déontologique pour  cadrer la recherche scientifique dans ce domaine, q u’elle soit publique ou  privée.  Il est frappant de constater qu’ aucun argument sérieux ne venait  étayer cette première mise en garde quant au risque  présumé de dérive  malveillante . Pourtant, même sans justification, ni preuve, cet te alerte a  contribué à renforcer les peurs et les angoisses irrationnelles  induites par  le déploiement des technologies d’intelligence arti ficielle .  De plus, cette naissance du débat public sur le suj et de l’intelligence  artificielle selon un mode alarmiste a été suivie d ’une certaine confusion en  raison de la publication, en juillet 2015, d’une autre lettre signée par plus de  mille personnalités demandant l’interdiction des ro bots tueurs , à savoir les  armes autonomes aptes à sélectionner et combattre d es cibles sans  intervention humaine, en arguant du fait que l’inte lligence artificielle  pourrait à terme être plus dangereuse que des ogive s nucléaires. Cette lettre  a été publiée lors de l’ouverture de la Conférence internationale sur  l’intelligence artificielle qui s’est tenue à Bueno s Aires en 2015 et à la suite de 
- 16  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        deux réunions d’experts qui s’étaient tenues à Genè ve sur les armes  autonomes.  Après ces deux événements marquants, 2016 a ensuite  fait figure  d’année de l’intelligence artificielle, marquée par  l’attribution de la chaire  d’informatique du Collège de France à Yann LeCun en  février 2016 1 ou par  l’événement largement commenté du 15 mars 2016, lor sque le système  d’intelligence artificielle AlphaGo,  créé par l’entreprise britannique  DeepMind, rachetée en 2014 par Google, a battu le champion de Go, Lee  Sedol , avec un score final de 4 à 1. Cette victoire marq ue l’histoire des  progrès en intelligence artificielle  et contredit la thèse de ceux qui  estimaient une telle victoire impossible , tant le jeu de Go exige une subtilité  et une complexité propres à l’intelligence humaine.   Tout au long de l’année 2016, parallèlement aux inv estigations  conduites par vos rapporteurs, les initiatives en m atière d’intelligence  artificielle se sont multipliées à un rythme effrén é. Après l’irruption de  l’intelligence artificielle dans le débat public en  2015, l’année 2016 et le  premier trimestre 2017 ont en effet été jalonnés de  nombreux événements et  rapports , dont il serait difficile de faire ici une liste e xhaustive.  Pour mémoire, peuvent être mentionnés plusieurs tra vaux sur  lesquels le présent rapport va revenir plus loin : les rapports sur  l’intelligence artificielle du Parlement européen, de la Maison Blanche (trois  rapports), de la Chambre des Communes, de l’associa tion mondiale des  ingénieurs électriciens et électroniciens (Institut e of Electrical and Electronics  Engineers ou IEEE), de la commission de réflexion s ur l’éthique de la  recherche en sciences et technologies du numérique (CERNA) de l’Alliance  des sciences et technologies du numérique (Allisten e) (deux rapports 2), de  l’Institut national de recherche en informatique et  en automatique (Inria), de  l’Institut Mines-Télécom, du Club informatique des grandes entreprises  françaises (Cigref), du Syndicat des machines et te chnologies de production  (SYMOP), de l’association française pour l’intellig ence artificielle (AFIA), de  l’association française contre l’intelligence artif icielle (AFCIA) etc. Des  conférences d’envergure nationale ou internationale  ont aussi été organisées  sur le sujet par les Nations unies, l’OCDE, la Fond ation pour le futur de la  vie, le MEDEF, l’AFIA, la Commission Supérieure du Numérique et des  Postes (CSNP) entre autres. Enfin, l’initiative « F rance IA », lancée par le  Gouvernement en janvier 2017, s’est accompagnée de l’annonce d’un plan  national pour l’intelligence artificielle en mars 2 017.                                                    1 Yann LeCun, directeur de la recherche en intellige nce artificielle de Facebook, professeur  d’informatique et de neurosciences à l’Université d e New York, a ainsi prononcé en tant que titulaire  de la chaire annuelle « Technologies informatiques et sciences numériques » du Collège de France, le  4 février 2016 à 18h, au Collège de France, sa leço n inaugurale intitulée « Le deep learning, une  révolution en intelligence artificielle ». Il y fai sait valoir que « comme toute technologie  puissante, l’intelligence artificielle peut être ut ilisée pour le bénéfice de l’humanité entière  ou pour le bénéfice d’un petit nombre aux dépens du  plus grand nombre  ».  2 Le premier porte sur l’éthique du chercheur en rob otique et l’autre sur l’éthique en apprentissage  automatique. 
INTRODUCTION  - 17  -       Devant cet emballement, alors que les progrès se fo nt à une vitesse  exponentielle et reposent de plus en plus sur un fi nancement privé aux  moyens considérables, il est indispensable que la réflexion soit conduite de  manière sereine et rationnelle , afin de mettre en avant les opportunités  tout autant que les risques de l’intelligence artif icielle , de partager la  connaissance en vue de rassurer le public et de démystifier les  représentations biaisées . Comme le disait Marie Curie, « dans la vie, rien n’est  à craindre, tout est à comprendre  ».  L’intelligence artificielle suscite en effet enthousiasme, espoir et  intérêt, aussi bien que méfiance, incrédulité ou op positions . À l’heure où  les impacts de ces technologies, souvent par leur c apacité prédictive,  deviennent de plus en plus significatifs, y compris  dans la vie quotidienne de  chacun de nous, et où les frontières entre l’homme et la machine semblent  pouvoir s’effacer peu à peu, les choix scientifiques et technologiques à  opérer doivent, plus que jamais, pouvoir l’être en connaissance de cause .  Ces représentations excessives de l’intelligence ar tificielle, qui  peuvent être totalement opposées, sont accentuées p ar la phase générale  d’enthousiasme dans laquelle nous nous situons : en  effet, selon les  observations cycliques observées depuis un demi-siè cle, la période récente  s’apparente à un véritable « Printemps de l’intelli gence artificielle ». Cette  période polarise ainsi les opinions, qui peuvent êt re des angoisses  excessives mais aussi des espoirs démesurés : les cycles d’espoirs et de  déceptions qui jalonnent l’histoire de l’intelligen ce artificielle invitent à ne  pas trop s’enthousiasmer en faisant preuve d’attent es irréalistes  à l’égard  des technologies existantes ou de celles mises à di sposition dans un avenir  proche.  Il convient donc d’aller au-delà des apparences et de regarder la  réalité scientifique derrière les espoirs et les an goisses s’exprimant en raison  du développement de l’intelligence artificielle. Le débat public ne peut pas  s’engager sereinement dans l’ignorance des technolo gies mises en œuvre,  des méthodes scientifiques et des principes de l’in telligence artificielle .  C’est pourquoi vos rapporteurs ont entendu mettre e n lumière et partager la  connaissance de l’état - à cet instant donné - de c es technologies en constante  évolution.  Ils se posent la question de savoir comment développer une culture  de la responsabilité  et une prise en compte des questions éthiques  au sein  de la communauté des chercheurs en intelligence art ificielle et en robotique 1  et au-delà, parce qu’ils n’oublient pas que « science sans conscience n’est que                                                    1 Cette question, analysée plus loin, a fait l’objet  du premier rapport de la commission de réflexion  sur l’éthique de la recherche en sciences et techno logies du numérique (CERNA) de l’alliance des  sciences et technologies du numérique (Allistene). Allistene regroupe en effet les organismes de  recherche publics concernés par le numérique, notam ment par l’intelligence artificielle, comme le  CNRS, le CEA, Inria, la CPU, la CDEFI et l’Institut  Mines-Télécom. L’INRA, l’INRETS et  l’ONERA en sont membres associés. Ce rapport est ab ordé au IV de la présente étude. Il peut être  trouvé ici : https://hal.inria.fr/ALLISTENE-CERNA/hal-01086579v1  
- 18  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        ruine de l’âme  », ainsi que l’affirmait Rabelais. Ils jugent qu’i l relève du devoir  citoyen de diffuser et partager la connaissance sci entifique et technologique.  Les progrès en intelligence artificielle posent des  questions  auxquelles toute la société doit être sensibilisée : quels sont les opportunités  et les risques qui se dessinent ? La France et l’Europe sont-elles dans une  position satisfaisante dans la course mondiale qui s’est engagée ? Quelles  places respectives pour la recherche publique et la recherche privée  ?  Quelle coopération  entre celles-ci ? Quelles priorités pour les  investissements dans la recherche en intelligence artificielle ? Qu els  principes éthiques, juridiques et politiques doivent encadrer ces  technologies ? La régulation doit-elle se placer au niveau national,  européen ou international  ? Devant ces interrogations, vos rapporteurs  estiment qu’il est de la responsabilité des pouvoir s publics de proposer un  point d’équilibre qui devra toujours être remis en débat à proportion des  découvertes scientifiques, de leurs transferts et d e leurs usages. Tel est l’objet  même du présent rapport.  Afin de prévenir les discours catastrophistes mais aussi un  risque  de futures désillusions , il est nécessaire d’ opérer un bilan objectif de l’état  de l’art en matière scientifique et technologique s ’agissant de « l’intelligence  artificielle ». C’est le rôle de l’OPECST et c’est la mission que se sont donnée  vos rapporteurs : ils ont souhaité faire le point sur la recherche et les usages  des technologies d’intelligence artificielle , en souligner les enjeux multiples  et les riches perspectives, car ils sont animés d’une préoccupation  pédagogique en vue de faciliter le partage des conn aissances scientifiques  et technologiques . 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 19  -         PREMIÈRE PARTIE :   ÉLÉMENTS DE CONTEXTE    I.  LA DÉMARCHE DE VOS RAPPORTEURS  A.  DE LA PROCÉDURE DE SAISINE À L’ADOPTION D’UN CALEND RIER  DE TRAVAIL  1.  L’origine et l’instruction de la saisine  L’Office parlementaire d’évaluation des choix scien tifiques et  technologiques (OPECST) a été saisi le 29 février 2 016, en application de  l’article 6 ter  de l’ordonnance n° 58-1100 du 17 novembre 1958 rel ative au  fonctionnement des assemblées parlementaires introd uit par la loi  n° 83-609 du 8 juillet 1983 qui le crée, par la com mission des affaires  économiques du Sénat, d’une demande d’étude sur l’i ntelligence  artificielle.  La victoire, dans le même temps, du système Alpha Go, sur le  champion de Go, Lee Sedol, confirmait, s’il en était besoin la pertinence de  cette saisine , tant cet événement marque l’ampleur des progrès e n  intelligence artificielle.  Vos rapporteurs étaient d’ores et déjà convaincus d e l’intérêt de ce  sujet, compte tenu de sa forte visibilité dans l’ac tualité et la vie publique.  Ainsi, votre rapporteure Dominique Gillot avait été  sensibilisée aux  enjeux de l’intelligence artificielle lors du collo que annuel de la conférence  des présidents d’université (CPU) organisée en 2015  sur le thème  « Université 3.0 » ouvert par Bernard Stiegler, dir ecteur de l’Institut de  recherche et d’innovation (IRI) du centre Georges P ompidou et professeur à  l’Université de Londres. La conclusion de ce colloq ue évoquait même  l’« Université 4.0 ».   En outre, plusieurs rapports de l’OPECST ou des tab les rondes  organisées par l’Office 1 avaient déjà traité partiellement ce sujet. Elle  abordait donc cette problématique avec la volonté, comme d’ailleurs le  rapporteur Claude de Ganay, d’éclairer et de faire partager une culture  scientifique, technique et industrielle, en adéquat ion totale avec la démarche  du CNCSTI 2 qu’elle préside.  Lors de sa réunion du 18 mai 2016, l’Office a désig né vos deux  rapporteurs pour conduire l’étude. Dans un contexte  de délais très                                                    1 Ces travaux sont récapitulés un peu plus loin.  2 Le Conseil national de la culture scientifique, te chnique et industrielle, placé auprès du ministre  chargé de la culture et du ministre en charge de la  recherche, « participe à l’élaboration d’une  politique nationale en matière de développement de la culture scientifique, technique et industrielle,   en cohérence avec les grandes orientations de la st ratégie nationale de la recherche ».  
- 20  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        contraints, une étude de faisabilité a été réalisée puis présen tée le 28 juin  2016  en application des articles 19 1 et 20 2 du règlement intérieur de l’Office.  L’OPECST ayant pour vocation d’ anticiper les questions complexes  d’ordre scientifique et technologique qui pourraien t se poser au  législateur , il doit pouvoir lui fournir des explications circonstanciées sur  des enjeux dont les risques et les opportunités aur aient été difficiles à  identifier sans son éclairage .  2.  Un calendrier de travail très resserré  L’étude de faisabilité n’ayant pu être présentée à l’OPECST que fin  juin 2016 et le calendrier des travaux parlementair es ayant été interrompu fin  février 2017 en raison des échéances électorales (p résidentielle et législatives  puis sénatoriales), vos rapporteurs n’ont réellemen t pu disposer que d’un  peu plus de six mois pour effectuer leurs investiga tions, ce qui est très court  étant donné l’importance du sujet. Ce délai contrai nt leur interdisant  d’élaborer un rapport faisant un point complet sur l’ensemble des questions  posées par l’intelligence artificielle, ils ont pré cisé le champ des  investigations de l’étude. Sans chercher à épuiser le sujet, ils ont voulu  réaliser un travail exploratoire, travail qui devra  être poursuivi, d’autant que  la recherche, l’innovation et la communication scie ntifique et technologique  ne cessent d’avancer.  B.  LE CHAMP DES INVESTIGATIONS DE L’ÉTUDE  1.  L’étude de faisabilité du rapport conclut à la pert inence d’une  étude spécifique de l’OPECST  L’étude de faisabilité a tout d’abord établi un bilan des précédents  travaux de l’Office  et des autres travaux  sur l’intelligence artificielle  conduits récemment en dehors de son cadre .  À travers cette revue des rapports de l’OPECST il s ’agissait de voir si  une étude analogue avait été conduite et de détermi ner ce qu’il était  pertinent d’analyser de manière plus spécifique con cernant l’intelligence  artificielle.                                                    1 « Article 19 : Le rapporteur procède d’abord à une  étude de faisabilité, qui a pour objet : d’établir   un état des connaissances sur le sujet, de détermin er d’éventuels axes de recherche et d’apprécier les   possibilités d’obtenir des résultats pertinents dan s les délais requis, de déterminer les moyens  nécessaires pour engager valablement un programme d ’études. Pour cette étude de faisabilité, le  rapporteur peut demander le concours des membres du  conseil scientifique, avec l’accord du viceprésident de cet organisme. »  2 « Article 20 : Le rapporteur soumet à la délégatio n les conclusions de son étude de faisabilité. Il  propose : soit de ne pas poursuivre les travaux, so it de suggérer à l’auteur de la saisine une nouvell e  formulation de celle-ci, soit d’engager un programm e d’études conduisant à l’établissement d’un  rapport. » 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 21  -       Ainsi, l’OPECST a, dernièrement, rendu en 2016 un rapport sur les  robots et la loi , reprenant le compte rendu d’une audition publique   organisée le 10 décembre 2015 1. Auparavant, et en allant du plus récent au  plus ancien, l’Office a rendu plusieurs travaux sur  le thème du numérique,   démentant la thèse du livre de Laure Belot, « La déconnexion des élites.  Comment Internet dérange l’ordre établi ? »2.  Il a ainsi travaillé sur le numérique au service de  la santé 3, sur la  sécurité numérique 4, sur le big data  dans l’agriculture 5, sur les drones et la  sécurité des installations nucléaires 6, sur les nouveaux moyens de  transports 7, sur les nouvelles technologies d’exploration et d e thérapie du  cerveau 8, et, précédemment, sur la gouvernance mondiale de l’Internet 9, sur  les conséquences de l’évolution scientifique et tec hnique dans le secteur des  télécommunications 10 , sur les enjeux de société posés par le monde virt uel 11 ,  sur les techniques d’apprentissages en matière info rmatique 12 , sur l’entrée  dans la société de l’information 13  et sur les conséquences de la révolution  numérique 14 .  L’Office n’a cependant jamais travaillé directement et globalement  sur l’intelligence artificielle , même si certains enjeux, tels que l’impact sur  la santé, la protection des données ou les moyens d e transport, ont pu être  entrevus à l’occasion de précédentes études menées.  Il semblait donc tout à                                                    1 Les robots et la loi, Jean-Yves Le Deaut et Bruno Sido , rapporteurs, Sénat, n° 570 (2015-2016).  2 Ce livre fait valoir l’argument d’une prétendue fa ible connexion des élites avec les enjeux de  transformation massive de nos sociétés sous l’impac t de la révolution numérique.  3 Le numérique au service de la santé, Catherine Procaccia et Gérard Bapt, rapporteurs, Sé nat  n° 465 (2014-2015).  4 Sécurité numérique et risques : enjeux et chances p our les entreprises , Anne-Yvonne Le  Dain et Bruno Sido, rapporteurs, Sénat n° 271 (2014 -2015).  5 La place du traitement massif des données (big data ) dans l’agriculture : situation et  perspectives , Jean-Yves Le Deaut, Anne-Yvonne Le Dain et Bruno Sido, rapporteurs, Sénat n° 614  (2014-2015).  6  Les drones et la sécurité des installations nucléai res, Jean-Yves Le Deaut et Bruno Sido,  rapporteurs, Sénat n° 267 (2014-2015).  7  Les nouvelles mobilités sereines et durables , Denis Baupin et Fabienne Keller, rapporteurs  Sénat n° 293 (2013-2014).  8 Les enjeux des nouvelles technologies d'exploration  et de traitement du cerveau, Alain  Claeys et Jean-Sébastien Vialatte, rapporteurs, Sén at n° 476 (2011-2012).  9 La gouvernance mondiale de l'Internet, Claude Birraux  et Jean-Yves Le Deaut, rapporteurs,  Sénat n° 219 (2005-2006).  10  Les conséquences de l'évolution scientifique et te chnique dans le secteur des télécommunications,  Pierre Laffitte et René Tregouet, rapporteurs, Séna t n° 159 (2001-2002).  11   Images de synthèse et monde virtuel : techniques e t enjeux de société , Claude Huriet,  rapporteur, Sénat n° 169 (1997-1998)  12  Les techniques des apprentissages essentiels pour u ne bonne insertion dans la société de  l’information , Franck Sérusclat, rapporteur, Sénat n° 383 (1996- 1997).  13  La France et la société de l’information : un cri d ’alarme et une croisade nécessaire , Pierre  Laffitte, rapporteur, Sénat n° 213 (1996-1997).  14  Les nouvelles techniques d’information et de commun ication : l’Homme cybernétique ,  Franck Sérusclat, rapporteur, Sénat n° 232 (1994-19 95). 
- 22  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        fait nécessaire d’approfondir ce thème à travers un e étude intégrée  approfondie.  Les rapporteurs se sont ensuite interrogés sur l’ex istence d’une  étude analogue concernant l’intelligence artificiel le effectuée en dehors de  l’OPECST. Pour répondre à cette question, différent es publications  nationales et européennes ont été passées en revue,  sans identifier de rapport  public faisant le point sur ces technologies, ni su r les opportunités et les  risques qu’elles incarnent .  Alors que ces opportunités et ces risques, en lien avec l’évolution des  techniques, l’accélération des capacités des machin es, la disponibilité de  masses de données énormes et les usages de l’intell igence artificielle  devaient de toute évidence être identifiés et évalu és, les pouvoirs publics  paraissent ne pas avoir pris toute la mesure de l’e njeu, bien que cela fût  souhaitable .  Deux exceptions ont été relevées : une initiative é manant d’une  députée européenne et le travail d’une association missionnée par la  Commission européenne. En effet, au sein des instit utions de l’Union  européenne, Mme Mady Delvaux, présidente d’un group e de travail du  Parlement européen sur la robotique et l’intelligen ce artificielle, a rendu  public, le 31 mai 2016, un projet de rapport contenant des recommandations  à la Commission européenne relatives à des règles d e droit civil pour la  robotique, assorti d’une motion portant résolution du Parlement européen .  Antérieurement, l’association EuRobotics  (« European Robotics Coordination  Action  »), en charge du programme de recherche de l’Union  européenne en  robotique, qui a pour objectif de favoriser le déve loppement de la robotique  en Europe, a proposé le 31 décembre 2012 un projet de livre vert sur les  aspects juridiques de la robotique 1.  D’autres initiatives, moins en rapport avec l’intel ligence artificielle,  ont néanmoins été mentionnées dans l’étude de faisa bilité. Au niveau  national, le Parlement a débattu et adopté, en 2016 , le projet de loi pour une  République numérique 2. Également en 2016, la commission « Technologies  de l’information et de la communication » (TIC) de l’Académie des  technologies  a produit une note interne  répondant à la question suivante :  « l’accélération des nouvelles technologies numériq ues produit-elle des  inquiétudes et une difficulté d’acceptation de la s ociété ? ». En 2015,  l’Académie des technologies a rendu une communication sur le « big data  »  et a poursuivi les activités de son groupe de trava il « Vers une technologie  de la conscience ? ». Initiés en 2014 et animés par  Gérard Sabah et Philippe                                                    1 Cf. http://www.eu-robotics.net/cms/upload/PDF/euRobotic s_Deliverable_D.3.2.1_Annex_Suggesti  on_GreenPaper_ELS_IssuesInRobotics.pdf    2 Cf. le rapport Sénat n° 534 (2015-2016) de M. Chri stophe-André Frassa, ainsi que les avis n 524,  525, 526 et 528 respectivement de M. Philippe Dalli er, au nom de la commission des finances, de  Mme Colette Mélot, au nom de la commission de la cu lture, de l’éducation et de la communication,  de M. Patrick Chaize, au nom de la commission de l’ aménagement du territoire et du développement  durable, et de M. Bruno Sido, au nom de la commissi on des affaires économiques. 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 23  -       Coiffet, les travaux de ce groupe de travail n’ont pas débouché sur un  rapport. En 2009, l’Académie des technologies avait , en revanche, sur  décision de son conseil académique, publié une brochure de dix questions  sur l’intelligence artificielle et la technologie  posées à l’académicien Gérard  Sabah. Il ne s’agissait pas pour autant formellemen t d’un rapport, d’un avis  ou d’une communication de l’Académie des technologi es sur le thème de  l’intelligence artificielle. Les précisions apporté es par cette brochure étaient  cependant utiles pour éclairer la réflexion et les discussions sur le sujet.  Enfin, il faut mentionner une lettre de veille du pôle de compétitivité Cap  Digital  sur l’intelligence artificielle en 2015 1 et le fait que l’Agence nationale  de la recherche  (ANR) ait consacré un de ses « cahiers »2 au thème de  l’intelligence artificielle et de la robotique en 2 012, intitulé « Intelligence  Artificielle et Robotique : Confluences de l’Homme et des STIC »3.  De manière plus significative, en 2015, la commission de réflexion  sur l’éthique de la recherche en sciences et techno logies du numérique   (CERNA) de l’alliance des sciences et technologies du numérique (Allistene),  sous la présidence de Max Dauchet, a rendu son premier rapport public   consacré à l’éthique de la recherche en robotique 4.  La même année, pour mémoire, le colloque annuel de la conférence  des présidents d’université (CPU) ouvert par Bernard Stiegler, directeur de  l’Institut de recherche et d’innovation (IRI) du ce ntre Georges Pompidou et  professeur à l’Université de Londres, a eu pour thè me « L’Université 3.0 »,  l’intelligence artificielle avait été évoquée  et l’idée d’« Université 4.0 » avait  conclu ce colloque, renvoyant ainsi au processus pr ogressif dans lequel  s’inscrit désormais la production de la connaissanc e et la diffusion des  savoirs.  Aucun de ces travaux ne semblant de nature à dispen ser l’OPECST  d’engager une réflexion plus approfondie sur le thè me de l’intelligence  artificielle , vos rapporteurs ont proposé de poursuivre leur pr éparation d’un  rapport de l’OPECST sur l’intelligence artificielle  dans un cadre et selon des  modalités déterminés et approuvés par leurs collègu es.  2.  Un ciblage délibéré sur un nombre limité de problém atiques et  de pistes d’investigation   Vos rapporteurs ont souhaité préciser le champ d’investigations  retenu , permettant de répondre à la saisine transmise par  la commission des  affaires économiques du Sénat et de contribuer à faire connaître et partager                                                    1 Cf. http://www.craft.ai/images/posts/craft-ai-interview ed-by-capdigital/craft_ai_article_cap_digital.pdf    2 Cahier n° 4, mars 2012.  3 Cf. http://www.agence-nationale-recherche.fr/fileadmin/ user_upload/documents/2012/CahierANR-4-Intelligence-Artificielle.pdf    4 Cf. https://hal.inria.fr/ALLISTENE-CERNA/hal-01086579v1   
- 24  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        ce qu’est aujourd’hui, et ce que peut devenir demai n l’intelligence  artificielle .   Les enjeux de ce thème d’étude sont tout autant sci entifiques et  technologiques que politiques, sociétaux, économiqu es, philosophiques,  éthiques 1, juridiques, éducatifs, médicaux, ou, encore, mili taires.  Compte tenu des délais impartis, il leur a fallu ne  retenir que   certaines problématiques du champ de l’intelligence  artificielle pour la  conduite de leurs investigations, en ayant le souci  d’optimiser la  plus-value relative du rapport . Les différents thèmes pouvant être traités  ont été circonscrits et parmi eux, neufs domaines d ’investigation au moins  peuvent être distingués :  1.   La recherche publique en intelligence artificielle  et les technologies  informatiques ;  2.   La recherche privée en intelligence artificielle ( dont la question de  la place des géants de l’Internet) ;  3.   Les enjeux philosophiques et éthiques de l’intelli gence artificielle ;  4.   Les enjeux politiques et juridiques de l’intellige nce artificielle ;  5.   Les enjeux éducatifs de l’intelligence artificiell e ;  6.   Les enjeux économiques, industriels et financiers de l’intelligence  artificielle (dont les systèmes et moyens de transp orts) ;  7.   Les usages de l’intelligence artificielle en matiè re de technologies  médicales (pour l’aide au diagnostic, la thérapeuti que,  l’épidémiologie, la chirurgie…) ;  8.   Les usages de l’intelligence artificielle pour la défense et les  technologies militaires ;  9.   Le projet transhumaniste d’homme augmenté.  Les aspects scientifiques et technologiques constit uant le cœur de  métier de l’OPECST et sa plus-value spécifique par rapport aux autres  commissions et délégations parlementaires, les poin ts 1 et 2 ont été  retenus . La place considérable prise par la recherche priv ée pose la question  des enjeux de pouvoir et de sécurité par rapport à la r echerche publique .  Elle touche même aux problématiques de souveraineté et d’indépendance  nationale , d’autant plus que la colonisation numérique améri caine est une  réalité incontestable.  Les points 3, 4 et 5 ont aussi été retenus car ils soulèvent des  questions essentielles . Ils couvrent d’ailleurs déjà un champ très large  d’investigation. Les  enjeux philosophiques, éthiques, politiques,                                                    1 L’éthique est une discipline philosophique qui por te sa réflexion sur les fondements de la morale.  Elle envisage donc les normes, les limites et les d evoirs de celle-ci. L’éthique se définit aussi comm e  un ensemble de principes moraux qui sont à la base de la conduite d’un sujet. 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 25  -       juridiques et éducatifs 1 de l’intelligence artificielle sont en effet  majeurs et  les identifier devrait permettre de  dépasser les peurs et les inquiétudes  exprimées en vue d’engager un débat public plus ser ein à ce sujet.  Les enjeux financiers, économiques et industriels ( point 6) n’ont  pas été écartés mais  mis au second plan dans la mesure où ce domaine   correspond moins directement à la mission et à la p lus-value apportée par  l’OPECST.  Les usages de l’intelligence artificielle en matièr e médicale   justifieraient  un rapport à part entière et vos rapporteurs ont donc mis cette  dimension de côté dans l’attente de prochains trava ux. Ils évoquent toutefois  ces usages dans le présent rapport mais de manière souvent illustrative.  Le point 8 sur les usages de l’intelligence artific ielle pour la  défense et les technologies militaires a été écarté  pour deux raisons : d’une  part, il s’agit d’un sujet qui relève assez largeme nt d’une régulation  internationale et, d’autre part, l’accès à l’inform ation aurait été extrêmement  difficile compte tenu de la sensibilité du sujet. L a confidentialité et la  discrétion étant de mise en matière de recherche mi litaire, vos rapporteurs  n’ont pas souhaité s’engager dans cette voie.   Enfin, le point 9 sur le transhumanisme est partiellement abordé,  davantage sous l’aspect des enjeux éthiques de l’in telligence artificielle . Il  n’y avait pas lieu de traiter spécifiquement du tra nshumanisme, mouvement  controversé, bien éloigné de l’intérêt général rech erché par vos rapporteurs :  il relève en effet davantage du projet idéologique que de la réalité  scientifique et couvre de plus un champ différent d e celui de l’intelligence  artificielle. Il inclut par exemple une partie des biotechnologies, ainsi que  d’autres technologies émergentes.  Vos rapporteurs ont estimé que l’angle d’entrée le plus fécond en  matière d’intelligence artificielle était de mettre l’accent sur les enjeux  éthiques car ils permettent d’aborder de manière tr ansversale la plupart  des aspects retenus de manière prioritaire, à savoir la recherche publique et  privée ainsi que les enjeux philosophiques, politiq ues, juridiques et éducatifs  de l’intelligence artificielle.  Sous couvert d’une focalisation sur « l’éthique de l’intelligence  artificielle » , il a été possible de poursuivre des investigation s dans chacun  de ces sous-domaines, en mettant en évidence les op portunités et les risques  que représente l’intelligence artificielle.                                                    1 La note « Quelles priorités éducatives pour 2017-2027 ? »  de France Stratégie, parue en mai  2016, s’interroge sur les conditions de réussite du  virage du numérique. Elle a conduit à un débat  public le 13 juin 2016. Elle se demande comment pre ndre appui sur le numérique pour améliorer les  pédagogies, sur quels niveaux d’enseignement faire porter en priorité les investissements en matière  de numérique, s’il faut privilégier le développemen t préalable de contenu pédagogique numérique ou  bien l’équipement des élèves, des établissements ou  des enseignants et, enfin, sur quelles collectivit és  faire reposer la charge de ces financements. Une no te de la fondation Terra Nova du 10 mars 2016  intitulée « L’école sous algorithme »  appelle à développer la culture numérique dans le monde  éducatif et à un travail de l’OPECST sur les techno logies éducatives. 
- 26  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Cette réflexion sur les questions éthiques a été co nduite au sens  large  et s’est étendue de l’éthique de la recherche en i ntelligence artificielle  jusqu’à l’éthique des robots intelligents, en passa nt par la revue de  l’ensemble des démarches éthiques engagées en la ma tière.  Elle présentait aussi l’intérêt de ne pas céder à la tentation de  définir un cadre juridique contraignant , qui aurait eu pour inconvénient de  figer des règles en codifiant des préceptes moraux et, partant, de gêner et de  ralentir l’innovation. Vos rapporteurs, au terme de  leurs investigations, ne  sont toujours pas convaincus de l’urgence d’une intervention légi slative ou  réglementaire en matière d’intelligence artificiell e, en raison de son  caractère très évolutif . Pour eux, une focalisation sur l’éthique de  l’intelligence artificielle permet à la fois de rép ondre à des préoccupations de  court terme mais aussi de plus long terme. Pour les  premières, vos  rapporteurs retiennent un propos de Laurence Devill ers, professeure à  l’Université Paris IV Sorbonne et directrice de rec herche au Laboratoire  d’informatique pour la mécanique et les sciences de  l’ingénieur (LIMSICNRS, campus Paris-Saclay) : « L’utilisation de systèmes informatiques  fonctionnant à partir d’apprentissage machine, met en lumière la nécessité d’une  réflexion éthique sur les limites et performances d es systèmes, surtout lorsqu’ils  s’adaptent en continu. Ces systèmes amènent une rup ture technologique et juridique  par rapport aux algorithmes classiques paramétrable s.  » Sur le long terme, vos  rapporteurs ont entendu l’appel que Yann LeCun a la ncé lors de sa leçon  inaugurale au Collège de France : « dans quelques décennies, quand nous  pourrons peut-être penser à concevoir des machines réellement intelligentes, nous  devrons répondre à la question de comment aligner l es valeurs des machines avec les  valeurs morales humaines  ». Même s’il s’agit d’une question de long terme, elle  mérite d’être posée dès aujourd’hui . C’est d’ailleurs le thème du travail 1  conduit en 2016 et 2017 par l’association mondiale des ingénieurs électriciens  et électroniciens (Institute of Electrical and Elec tronics Engineers ou IEEE).  Ces technologies doivent, en effet, être maîtrisées, utiles et faire  l’objet d’usages conformes à nos valeurs humanistes .  C.  LA MÉTHODE DE TRAVAIL  1.  Une méthode de travail fondée sur des auditions bil atérales et  des déplacements en France et à l’étranger  À la suite de l’adoption de  l’étude de faisabilité  le  28 juin 2016, vos  rapporteurs ont procédé à des auditions bilatérales  et effectué des  déplacements.   Ce point est développé en annexe du présent rapport , avec une  présentation des auditions bilatérales et des dépla cements de vos                                                    1 Cf. le site http://standards.ieee.org/develop/indconn/ec/autono mous_systems.html   
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 27  -       rapporteurs en France et à l’étranger (États-Unis, Royaume-Uni, Suisse,  Belgique).  Il s’agissait pour mémoire des déplacements suivant s :  – un déplacement aux États-Unis d’Amérique  du 22 au 29 janvier  2017, pour rencontrer des spécialistes de l’intelli gence artificielle, à  Washington à l’Institut de technologie du Massachus etts (MIT), à la Harvard  Kennedy School of Government , à l’Université de Washington, à l’Université de  Stanford, à l’Université de Berkeley, ainsi que des  représentants de Facebook  (Menlo Park, Palo Alto), de Google (Mountain View),  d’Apple (Cupertino) et  de Salesforce (San Francisco)… ;  – trois déplacements en Europe : à Genève  du 21 au 22 septembre  2016 (HBP et BBP du Brain Mind Institute de l’École polytechnique fédérale  de Lausanne, EPFL), au Royaume-Uni du 13 au 16 décembre 2016 (Chambre  des Communes, Royal Society, Alan Turing Institute , Future of humanity  Institute de l’Université d’Oxford, CSER et LCFI de Cambridge …) et à  Bruxelles du 8 au 9 février 2017 (laboratoire d’intelligence artificielle de  l’Université libre de Bruxelles, institutions europ éennes…) ;   – un déplacement en France métropolitaine, à Arcachon du 26 au  30 septembre 2016, pour participer à un séminaire s ur l’éthique de  l’intelligence artificielle organisé par la commiss ion de réflexion sur l’éthique  de la recherche en sciences et technologies du numé rique d’Allistene  (CERNA).  2.  L’organisation d’une journée d’auditions publiques au Sénat le  19 janvier 2017  Une journée d’auditions publiques a été conduite au  Sénat le  19 janvier 2017 1. L’organisation de cette journée a conduit une rev ue  spécialisée à conclure que « les pouvoirs publics s’emparent de la question de  l’intelligence artificielle »2.   Vos rapporteurs relèvent que ces auditions ont cons titué un record  d’audience  pour le Sénat 3. La chaîne Public Sénat en a tiré une émission  spéciale, diffusée le lendemain de la journée d’aud itions 4.                                                    1 Pour les auditions du 19 janvier 2017 matin, le li en est le suivant :  http://videos.senat.fr/video.302142_588070cd0faea.r eunion-pleniere-opecst  et pour celles de l’aprèsmidi du 19 janvier 2017 : http://videos.senat.fr/video.303157_5880bb6877f24.r eunion-pleniereopecst    2 https://www.sciencesetavenir.fr/high-tech/intellige nce-artificielle/les-pouvoirs-publics-s-emparentde-la-question-de-l-intelligence-artificielle_10989 9   3 Selon les données disponibles à la fin du mois de janvier 2017 : sur Facebook, la vidéo a été regardé e  en direct par 97 182 personnes, puis en différé par  8 600 personnes. Sur le site Internet du Sénat, le   nombre de consultations de la vidéo s’élève à 1 839 .  4 https://www.publicsenat.fr/emission/les-matins-du-s enat/table-ronde-intelligence-artificielle-51796   
- 28  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        3.  La consultation d’ouvrages, de rapports et d’articl es parus sur le  sujet  Vos rapporteurs ont enrichi leurs connaissances par  la consultation  d’ouvrages, de rapports et d’articles parus sur le sujet . Il existe peu de  « manuels » d’intelligence artificielle sur le marc hé. Un état de la  connaissance, intitulé Panorama de l’intelligence artificielle, ses bases  méthodologiques, ses développements 1, a été dirigé en 2014 par Pierre  Maquis, Odile Papini et Henri Prade. Il s’agit, ave c ses trois volumes, de l’un  des manuels plus complets en langue française, même  si d’autres ouvrages  plus anciens ont pu être consultés 2.  La troisième édition du manuel de Stuart Russell et Peter Norvig  « Artificial Intelligence : A Modern Approach »  reste inégalée 3. Vos  rapporteurs ont rencontré l’un de ses deux auteurs,  Stuart Russell,  professeur à Berkeley, très engagé dans le débat pu blic sur l’intelligence  artificielle. Une traduction française de cet ouvra ge est disponible, avec le  concours de Laurent Miclet et Fabrice Popineau.    Écrit par deux experts de renommée mondiale, cet ou vrage constitue une  référence incontournable en matière d’intelligence artificielle dont il présente les  principaux concepts (logique, probabilités, mathématiques discrètes et continues,  perception, raisonnement, apprentissage, prise de d écision et action). Il analyse  l’intelligence artificielle à travers le concept d’ agents intelligents. Chaque chapitre est  illustré par des exemples et des activités, allant d’exercices de réflexion à des exercices de  programmation, en passant par l’approfondissement d es méthodes décrites, soit plus de  500 activités au total. Les auteurs exposent commen t un système réussit à percevoir son  environnement de manière à analyser ce qui s’y pass e, et comment il transforme la  perception qu’il a de son environnement en actions concrètes.                                                     1 Préfacé par Paul Braffort, le livre est édité par Cépaduès. Le volume 1 traite de la représentation  des connaissances et de la formalisation des raison nements, le volume 2 des algorithmes pour  l’intelligence artificielle et le volume 3 des fron tières et des applications de l’intelligence artifi cielle.  2 Le manuel classique, mais daté, est celui de Gérar d Tisseau et Jacques Pitrat, « Intelligence  artificielle : problèmes et méthodes » , Presses universitaires de France, 1996. Hugues Be rsini a  fait paraître un ouvrage de vulgarisation chez Elli pse en 2006 : « De l’intelligence humaine à  l’intelligence artificielle ».   3 Stuart Russell et Peter Norvig, « Artificial Intelligence:  A Modern Approach »,  Prentice Hall,  2010. Un autre manuel plus ancien peut être cité, c elui de Michael R. Genesereth et Nils J. Nilsson,  « Logical Foundations of Artificial Intelligence » , Los Altos Californie Morgan Kaufmann, 1987. 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 29  -       Voici une liste des sujets couverts dans leur ordre  d’exposition : les contributions  historiques des mathématiques, de la théorie des je ux, de l’économie, de la théorie des  probabilités, de la psychologie, de la linguistique  et des neurosciences ; les méthodes qui  permettent de prendre des décisions lors de l’établ issement d’un projet, en tenant compte  des étapes à venir ; les différentes manières de re présenter formellement les connaissances  relatives au monde qui nous entoure ainsi que le ra isonnement logique fondé sur ces  connaissances ; les méthodes de raisonnement qui pe rmettent d’établir des plans et donc de  proposer des actions à entreprendre ; la prise de d écisions en environnement incertain, avec  les réseaux bayésiens et des algorithmes tels que l ’élimination de variables et les « MCMC »  (Markov Chain Monte-Carlo) ; les méthodes employées  pour générer les connaissances  exigées par les composants de prise de décision : l es algorithmes de boosting, l’algorithme  « EM » (expectation-minimization), l’apprentissage à base d’exemples et les méthodes à  noyaux (SVM-machines à vecteurs de support) ; les i mplications philosophiques et éthiques  de l’intelligence artificielle. Ces technologies se ront décrites plus loin.  Des ouvrages scientifiques et/ou techniques  doivent aussi être  mentionnés, dont vos rapporteurs ont souvent rencon tré les auteurs dans le  cadre de leurs auditions et déplacements : Jean-Gabriel Ganascia , Le Mythe  de la singularité, L’intelligence artificielle, Les  Sciences cognitives ,  Hugues Bersini , De l’intelligence humaine à l’intelligence artifici elle , Les  fondements de l’informatique , Brèves réflexions d’un informaticien obtus sur la  société à venir , Laurence Devillers , Des Robots et des hommes  : mythes, fantasmes  et réalité , Serge Abiteboul et Gilles Dowek , Le temps des algorithmes ,  Dominique Cardon , A quoi rêvent les algorithmes : nos vies à l’heure des big  data , Alain Bensoussan et Jérémy Bensoussan , Droit des robots , Comparative  Handbook : robotic technolgies law , Alain Bensoussan (et autres), En compagnie  des robots , Alain Bensoussan, Dictionnaire politique d’internet et du numérique,  Code Informatique, fichiers et libertés, Droit de l ’informatique et de la télématique ,  Nathalie Nevejans , Traité de droit et d’éthique de la robotique civile ,  Jean-Yves Girard et Alan Turing , La Machine de  Turing , Nick Bostrom ,  Super-intelligence , Yoshua Bengio, Aaron Courville et Ian Goodfellow,   Deep Learning 1 Michael Jordan , Learning in Graphical Models (Adaptive  Computation and Machine Learning) , Daphne Koller et Nir Friedman ,  Probabilistic  Graphical Models : Principles and Techniques , Jean-Claude Heudin ,  Le Deep learning, Immortalité numérique : Intellige nce artificielle et transcendance,  les 3 Lois de la robotique : Faut-il avoir peur des  robots ?, Robots et avatars : Le rêve  de Pygmalion, Les créatures artificielles : des aut omates aux mondes virtuels,   Jacques Ferber , Les systèmes multi-agents : vers une intelligence c ollective ,  Michael Wooldridge , Introduction to Multi-Agent Systems , Alex Pentland,  Social Physics , Jean-Pierre Changeux , L’Homme neuronal ,  Jean-Michel Besnier, Francis Brunelle et Florence G azeau , Un cerveau très  prometteur : Conversation autour des neurosciences , ou encore un recueil de 150  avis d’experts par John Brockman intitulé What to think about machines that  think . Bruce Buchanan a, quant à lui, rédigé un article très éclairant 2 qui  revient sur l’histoire de l’intelligence artificiel le.                                                    1 Ouvrage disponible en ligne : http://www.deeplearningbook.org/    2 Bruce G. Buchanan « A (Very) Brief History of Artificial Intelligence  » , AI Magazine, 2005. 
- 30  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Le livre blanc d’Inria sur l’intelligence artificielle , coordonné par  Bertrand Braunschweig, a été consulté 1, ainsi que les rapports d’activités et  les contrats d’objectifs de cet institut. La brochure de l’Académie des  technologies  intitulée « Dix Questions sur l’intelligence artif icielle et la  technologie » posées à l’académicien Gérard Sabah a été largement utilisée.  Vos rapporteurs ont également pu consulter des ouvrages axés sur  les enjeux économiques  : Henri Verdier et Nicolas Colin , L’âge de la  multitude : Entreprendre et gouverner après la révo lution numérique , Gilles  Babinet , Transformation digitale : l’avènement des plateform es , big data, penser  l’Homme et le monde autrement et L’ère numérique, un nouvel âge de l’humanité ,  Thibaut Bidet-Mayer , L’industrie du Futur à travers le monde , Dorothée  Kohler et Jean-Daniel Weisz , L’Industrie 4.0 : Les défis de la transformation  numérique du modèle industriel allemand .  Les questions éducatives  ont aussi été explorées à travers différents  ouvrages : Joël Boissière , Simon Fau  et Francesco Pedró , Le Numérique - Une  chance pour l’école , Bruno Devauchelle , Comment le numérique transforme les  lieux de savoirs, Le numérique au service du bien c ommun et de l’accès au savoir  pour tous , Philippe Meirieu , Denis Kambouchner  et Bernard Stiegler ,  L’école, le numérique et la société qui vient , Franck Amadieu  et André Tricot   Apprendre avec le numérique , ainsi que des notes « Quelles priorités éducatives  pour 2017-2027 ?  » de France Stratégie et « L’école sous algorithme  » de la  fondation Terra Nova.  Quelques essais  ont, enfin, retenu leur attention : Serge Tisseron , Le  jour où mon robot m’aimera , Paul Dumouchel  et Luisa Damiano , Vivre avec les  robots, Essai sur l’empathie artificielle , Marc Dugain  et Christophe Labbé ,  L’homme nu : la dictature invisible du numérique , Michel de Pracontal , L’Homme  artificiel, Golems, robots, clones, cyborgs , Pierre Bellanger , La souveraineté  numérique , Éric Sadin , La silicolonisation du monde : l’irrésistible expan sion du  libéralisme numérique, La vie algorithmique : criti que de la raison numérique et   L’humanité augmentée : L’administration numérique d u monde , Luc Ferry , La  Révolution transhumaniste  et Bernard Stiegler , Dans la disruption : Comment ne  pas devenir fou ?                                                         1 Cf. https://www.inria.fr/content/download/103897/152937 0/.../AI_livre-blanc_n01.pdf   
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 31  -         II.  L’HISTOIRE DES TECHNOLOGIES D’INTELLIGENCE  ARTIFICIELLE ET DE LEURS USAGES  A.  DES TECHNOLOGIES NÉES AU MILIEU DU XX E SIÈCLE  1.  La préhistoire de l’intelligence artificielle et sa  présence dans  les œuvres de fiction  Les paragraphes suivants font le point sur les tech niques  d’intelligence artificielle et utilisent notamment les ouvrages cités,  notamment la brochure de l’Académie des technologie s de « dix questions  sur l’intelligence artificielle et la technologie » .  De nombreuses incarnations d’intelligence artificie lle ont jalonné  notre histoire, qu’il s’agisse de mythes ou de proj ets imaginés par les  écrivains et les scientifiques. Comme il a été vu, Jean-Claude Heudin et  Michel de Pracontal leur ont consacré des ouvrages entiers 1. Bruce Buchanan  a, quant à lui, rédigé un article sur l’histoire de  l’intelligence artificielle qui  revient également sur l’ensemble de ses précurseurs2. Comme le relève  Jean-Gabriel Ganascia, que vos rapporteurs ont pu r encontrer à plusieurs  reprises, Homère  a décrit, dans « L’Iliade  », des servantes en or douées de  raison : « Fabriquées par Héphaïstos, le dieu forgeron, elles ont, selon le poète, voix  et force ; elles vaquent aux occupations quotidienn es à la perfection, car les  immortels leur ont appris à travailler. Ce sont don c des robots, au sens étymologique  de travailleurs artificiels ». Ovide  dans ses « Métamorphoses  » crée la figure de  Galatée, statue d’ivoire sculptée par Pygmalion et à laquelle Vénus, déesse  de l’amour, accepte de donner vie. Jean-Gabriel Gan ascia rappelle également  qu’il existait dès l’Égypte ancienne des statues ar ticulées, animées par la  vapeur et par le feu, qui hochaient la tête et boug eaient les bras, véritables  ancêtres des automates. La Bible , par le Psaume 139:16, a fondé le mythe du  Golem, cette créature d’argile humanoïde que l’on r etrouve souvent dans la  tradition cabalistique juive.  En 1495, en vue de festivités organisées à Milan, Léonard de Vinci   imagine puis construit, bien que ce dernier point r este débattu, un  « chevalier mécanique  », sorte de robot automate revêtu d’une armure  médiévale. Sa structure interne en bois, avec quelq ues parties en métal et en  cuir, était actionnée par un système de poulies et de câbles.  Avec ses « animaux-machines », René Descartes  proposa, quant à  lui, dans la première moitié du XVII e siècle, de reproduire artificiellement les  fonctions biologiques, y compris la communication e t la locomotion. Blaise                                                    1 Jean-Claude Heudin, Robots et avatars : Le rêve de Pygmalion  et Les créatures artificielles :  des automates aux mondes virtuels , Michel de Pracontal, L’Homme artificiel, Golems, robots,  clones, cyborgs.   2 Bruce G. Buchanan « A (Very) Brief History of Artificial Intelligence  »,  AI Magazine, 2005. 
- 32  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Pascal  réfléchit à la création d’une machine à calculer. À la fin  du XVII e siècle, Leibniz  imagine ensuite une machine à calculer capable de  raisonner. Il construit un prototype de machine à c alculer en 1694.  Pendant le siècle des Lumières, le philosophe franç ais Julien de la  Mettrie  anticipe le jour où les progrès de la technique pe rmettront de créer  un homme-machine tout entier, à l’âme et au corps a rtificiels. L’abbé Mical et  Kratzenstein imaginent une machine à parler  en 1780, bientôt construite par  le baron Von Kempelen grâce à une cornemuse à tuyau x multiples,  aujourd’hui propriété du « Deutsches Museum »  de Munich.  Dès 1818, Mary Shelley  publie son roman « Frankenstein ou le  Prométhée moderne » , dans lequel elle imagine un savant capable de cré er un  être artificiel, le monstre Frankenstein.  Au milieu du XIX e siècle, George Boole  appelle à mathématiser la  logique, Charles Babbage  conçoit l’ancêtre mécanique des ordinateurs  d’aujourd’hui 1 et l’économiste britannique William Stanley Jevons  imagine  des pianos mécaniques, capables de raisonner.  Jules Verne , dans son roman, La Maison à vapeur , paru en 1880  imagine un éléphant géant à vapeur capable de trave rser l’Inde, sur terre,  comme sur l’eau. Sa machine n’est cependant pas aut onome.  Alors qu’ Isaac Asimov affirmait qu’ « on peut définir la science-fiction  comme la branche de la littérature qui se soucie de s réponses de l’être humain aux  progrès de la science et de la technologie » , force est de constater que  l’intelligence artificielle est un thème de science -fiction particulièrement  fécond pour la littérature , le cinéma  et les jeux vidéo . Laurence Devillers  souligne cette réalité incontestable dans son livre  Des robots et des hommes :  mythes, fantasmes et réalité .  Les ouvrages d’Isaac Asimov lui-même, mais aussi  d’Arthur C. Clarke, de Philip K. Dick ou de William  Gibson l’illustrent, ainsi  que le font, au cinéma, de 1927 à 2017 , les films « Metropolis »,   « 2001, l’Odyssée de l’espace », « Mondwest », « Le s Rescapés du futur », « Le  Cerveau d’acier », « Génération Proteus », « Blade runner », « Tron »,  « Terminator », « Matrix », « A.I. », « I, Robot »,  « Iron Man », « Wall-E »,  « Eva », « The Machine », « Transcendance », « Chap pie », « Her »,  « Ex Machina » , ou, encore, cette année, « Ghost in the Shell » . Les thèmes de  l’hostilité de l’intelligence artificielle  ou des risques que cette dernière  ferait courir à l’espèce humaine  sont souvent au cœur de l’intrigue de ces  œuvres.                                                    1 En 1834, pendant le développement d’une machine à calculer, Charles Babbage imagine le premier  ordinateur sous la forme d’une « machine à différen ces » en utilisant la lecture séquentielle des  cartes du métier à tisser Jacquard afin de donner d es instructions et des données à sa machine. En  cela, il fut le premier à énoncer le principe d’un ordinateur. 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 33  -       Récemment, des séries télévisées  à succès comme  « Person of interest », « Emma », « Westworld » ou, surtout, « Real Humans » et  « Humans »  ont également exploité ce sujet.  2.  Les premières étapes de formation des technologies  d’intelligence artificielle au XX e siècle, la notion d’algorithme et  le débat sur la définition du concept d’intelligenc e artificielle  L’intelligence artificielle a fêté l’année dernière  son  soixantième  anniversaire , puisqu’elle est inventée en tant que discipline e t concept en  1956 dans un contexte que vos rapporteurs vont prés enter dans les pages  suivantes. Elle repose sur l’utilisation d’ algorithmes , dont l’histoire est bien  plus ancienne que celle de leurs usages en informat ique.  Le mot  algorithme est issu de la latinisation du nom du  mathématicien Al-Khawarizmi , dont  le titre d’un des ouvrages (« Abrégé du  calcul par la restauration et la comparaison » ), écrit en arabe entre 813 et 833, et  dont la seule copie est conservée à l’Université d’ Oxford, visitée par vos  rapporteurs, est également à l’origine du mot algèbre . Il est le premier à  proposer des méthodes précises de résolution des éq uations du second  degré, du type « ax² + bx + c =0 ».  La longue histoire des algorithmes est bien décrite  par Serge  Abiteboul et Gilles Dowek, dans leur ouvrage Le temps des algorithmes . Ils ont  tous les deux été auditionnés par vos rapporteurs. Ils rappellent que les  algorithmes sont utilisés depuis des milliers d’années , qu’ Euclide a inventé  en l’an 300 avant notre ère  un algorithme de calcul du plus grand diviseur  commun de deux nombres entiers et que la complexité de certains  algorithmes récents est telle qu’ils peuvent être c omparés à des  cathédrales . Le domaine qui étudie les algorithmes est appelé  l’algorithmique.  De manière résumée, un algorithme est un ensemble d e séquences  d’opérations. Il s’agit, de manière plus précise et  rigoureuse, d’une suite  finie et non ambiguë d’opérations ou d’instructions  permettant, à l’aide  d’entrées, de résoudre un problème ou d’obtenir un résultat, ces sorties  étant réalisées selon un certain rendement 1. De nombreuses applications  sont possibles, à commencer par l’informatique, le fonctionnement des                                                    1 Donald Knuth, pionnier de l’algorithmique moderne ( The Art of Computer Programming ), a  identifié les cinq propriétés suivantes comme étant  les prérequis d’un algorithme : la finitude (« Un  algorithme doit toujours se terminer après un nombr e fini d’étapes  »), une définition précise  (« Chaque étape d’un algorithme doit être définie préc isément, les actions à transposer  doivent être spécifiées rigoureusement et sans ambi guïté pour chaque cas »), l’existence  d’entrées (« des quantités lui sont données avant qu’un algorith me ne commence. Ces  entrées sont prises dans un ensemble d’objets spéci fié  ») et de sorties (« des quantités ayant  une relation spécifiée avec les entrées ») et un rendement (« toutes les opérations que  l’algorithme doit accomplir doivent être suffisamme nt basiques pour pouvoir être en  principe réalisées dans une durée finie par un homm e utilisant un papier et un crayon  »). 
- 34  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        ordinateurs, en particulier leurs systèmes d’exploi tation, reposant sur des  algorithmes. Les algorithmes peuvent, en effet, ser vir, comme le rappellent  Serge Abiteboul et Gilles Dowek, à calculer , mais aussi à gérer des  informations  (comme le font les logiciels d’archivage par exemp le), à  analyser des données  (comme le font les moteurs de recherche), à  communiquer (comme le font les protocoles utilisés pour Interne t par  exemple), à traiter un signal (comme le font les appareils photo et les  microphones numériques par exemple), à commander un robot (comme le  font les systèmes d’analyse des capteurs utilisés p our les voitures autonomes  par exemple), à fabriquer des biens (comme le font les « usines 4.0 »  supervisées par des algorithmes par exemple) ou, en core, à modéliser  simuler et prévoir (comme le font certains outils de météorologie, de  sismologie, d’océanographie ou, encore, de planétol ogie par exemple).  L’informatique constitue un domaine d’application privilégié  pour  les algorithmes. Mais son histoire ne se confond pa s avec celle de ces  derniers. Il en est de même pour l’histoire de l’in telligence artificielle, bien  que ces trois histoires  soient liées. En effet, comme il sera vu plus loin ,  l’informatique traite plutôt de questions résolues par des algorithmes  connus , alors que l’on applique le label d’« intelligence  artificielle » à des  applications permettant de résoudre des problèmes m oins évidents.  Dès 1936, Alan Turing pose les fondements théoriques de  l’informatique et introduit les concepts de program me et de  programmation . Il imagine en effet, à ce moment, un modèle abstr ait du  fonctionnement d’un appareil doté d’une capacité él argie de calcul et de  mémoire, en recourant à l’image d’un ruban infini m uni d’une tête de  lecture/écriture, qui sera appelé « machine de Turing  », précurseur de  l’ordinateur moderne. Puis, dans un article paru en  1950 1, il explore le  problème de l’intelligence artificielle et propose une expérience maintenant  connue sous le nom de « test de Turing » , qui est une tentative de définition  à travers une épreuve d’un critère permettant de qu alifier une machine de  « consciente »2. Il fait alors le pari que « d’ici à cinquante ans, il n’y aura plus  moyen de distinguer les réponses données par un hom me ou un ordinateur, et ce sur  n’importe quel sujet  ». Cette prophétie d’Alan Turing quant aux progrès   connus en l’an 2000 ne s’est pas encore réalisée à ce jour.  De leur côté, les mathématiciens et neurologues Warren McCulloch  et Walter Pitts  écrivent dès 1943 un article intitulé « Un calculateur logique des  idées immanentes dans l’activité nerveuse »3 dans lequel ils posent l’hypothèse  que les neurones avec leurs deux états, activé ou n on activé, pourraint                                                    1 « Computing Machinery and Intelligence » , Mind, octobre 1950.  2 Le test de Turing consiste à mettre en confrontati on verbale un humain avec un ordinateur imitant  la conversation humaine et un autre humain. Dans le  cas où l’homme qui engage les conversations  n’est pas capable de dire lequel de ses interlocute urs est un ordinateur, on peut considérer que le  logiciel de l’ordinateur a passé avec succès le tes t.  3 « A Logical Calculus of Ideas Immanent in Nervous Activity » , 1943, Bulletin of  Mathematical Biophysics 5. 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 35  -       permettre la construction d’une machine capable de procéder à des calculs  logiques. Ils publièrent dès la fin des années 1950  des travaux plus aboutis  sur les réseaux de neurones artificiels . C’est en 1957 que Frank Rosenblatt  développe le Perceptron, première modélisation de r éseau de neurones  artificiels 1, à partir des travaux de McCulloch et Pitts. Ces d erniers publient  un article plus important que les autres en 1959 2 et constituent donc un  modèle simplifié de neurone biologique, communément  appelé neurone  formel . Leurs travaux démontrèrent que des réseaux de neu rones formels  simples pouvaient théoriquement réaliser des foncti ons logiques,  arithmétiques et symboliques complexes. Leur foncti onnement sera expliqué  plus loin.  Trois ans plus tôt,  en 1956, John McCarthy et Marvin Minsky ont  organisé une école d’été à Dartmouth  qui est considérée comme l’acte de  naissance de l’intelligence artificielle , à la fois en tant que discipline et en  tant que concept d’ artificial intelligence .  Le concept a fait l’objet d’un débat et il est dit a posteriori  que le choix  du mot devrait beaucoup à la quête de visibilité de ce nouveau champ de  recherche . Parler d’intelligence artificielle  a pu apparaître comme plus  séduisant que de parler des « sciences et des techn ologies du traitement de  l’information » . L’anthropomorphisme essentialiste 3 qui est exprimé par le  choix du concept d’« intelligence artificielle » n’ a sans doute pas contribué,  selon vos rapporteurs, à apaiser les peurs suscitée s par le projet prométhéen  de construction d’une machine rivalisant avec l’intelligence humaine .  Cette conférence, soutenue par la fondation Rockfel ler, par Nathan  Rochester, alors directeur scientifique d’IBM, et p ar Claude Shannon,  ingénieur, mathématicien et père des théories de l’ information et de la  communication, offre en effet à John McCarthy l’occ asion de convaincre les  participants d’accepter l’expression « intelligence  artificielle »  en tant  qu’intitulé de ce domaine de recherche. La conféren ce affirme donc dès 1956  que « chaque aspect de l’apprentissage ou toute autre car actéristique de  l’intelligence peut être si précisément décrit qu’u ne machine peut être conçue pour le  simuler  ». La rigueur pousse à observer que le projet n’es t pas, en réalité, de  construire une machine rivalisant avec l’homme mais  de simuler telle ou  telle tâche que l’on réserve à l’intelligence humai ne.  Outre John McCarthy et Marvin Minsky, les participants , tels que  Ray Solomonoff, Oliver Selfridge, Trenchard More, A rthur Samuel, Allen                                                    1 « The Perceptron : A Probabilistic Model for Infor mation Storage and Organization in the  Brain ».   2 « What the frog’s eye tells the frog’s brain »  ou « ce que l’œil d’une grenouille dit à son  cerveau » , coécrit avec Jerome Lettvin et Humberto Maturana,  1959, Proceedings of the Institute of  radio engineers.  3 L’anthropomorphisme est l’attribution de caractéri stiques du comportement humain ou de la  morphologie humaine à d’autres entités comme des di eux, des animaux, des objets ou d’autres  phénomènes. L’essentialisme est l’attribution à un être ou à un objet d’une existence propre « par  essence », c’est-à-dire inhérente au sujet en quest ion. 
- 36  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Newell et Herbert Simon, ayant posé comme conjectur e que tout aspect de  l’intelligence humaine peut être décrit de façon as sez précise pour qu’une  machine le reproduise en le simulant, discutent ensuite des possibilités de  créer des programmes d’ordinateur qui se comportent  intelligemment ,  c’est-à-dire qui résolvent des problèmes dont on ne  connaît pas de solution  algorithmique simple.  Dans les années suivantes, soutenus par l’agence am éricaine pour les  projets de recherche avancée de défense du ministèr e de la Défense ( Defense  Advanced Research Projects Agency  ou DARPA), mais aussi par IBM, les  chercheurs mettent au point de nouvelles techniques  informatiques  : le  langage Lisp en 1958, l’un des plus anciens langage s de programmation 1, le  premier programme démontrant des théorèmes d’où est  issue la notion  d’heuristique (règle empirique utile permettant de réduire les chemins  possibles mais sans aboutir nécessairement à une so lution), une première  idée des réseaux de neurones artificiels (le Percep tron, dont Marvin Minsky  souligne les limites théoriques), un programme qui joue aux dames et  apprend par apprentissage à jouer de mieux en mieux … Ces découvertes  rendent les pères fondateurs de l’intelligence arti ficielle très optimistes .  En 1958, Herbert Simon et Allen Newell déclarent ai nsi que « d’ici à  dix ans un ordinateur sera le champion du monde des  échecs »2 et « d’ici à dix ans,  un ordinateur découvrira et résoudra un nouveau thé orème mathématique majeur ».  En 1965, Herbert Simon assure que « des machines seront capables, d’ici  à vingt ans, de faire tout travail que l’homme peut  faire ».  En 1967, Marvin  Minsky estime que « dans une génération [...] le problème de la créat ion d’une  intelligence artificielle sera en grande partie rés olu » , et en 1970 que « dans trois à  huit ans nous aurons une machine avec l’intelligenc e générale d’un être humain  ordinaire »   De même, le premier agent conversationnel  (« chatbot  » ou « bot  »)  est créé en 1966 par Joseph Weizenbaum et simule un  psychothérapeute  grâce à sa technologie de reconnaissance des formes . Il s’appelle « Eliza » et  suscite un grand enthousiasme.  Mais ses capacités restent limitées , puisqu’il est incapable de  vraiment répondre aux questions posées, se contenta nt de continuer à faire  parler son interlocuteur, dans une logique de relan ce.                                                      1 Si l’on met de côté la « machine de Turing » qui r elève de l’informatique théorique, le « système  A-0 » (ou « A-0 System ») est le premier compilateu r (programme qui transforme un code source  écrit dans un langage de programmation ou langage s ource en un autre langage informatique, appelé  langage cible) développé en 1952 ; il est suivi not amment par le Fortran (mot valise issu de l’anglais   « formula translator ») inventé dès 1954, Lisp et A lgol en 1958, COBOL (acronyme de « Common  Business Oriented Language ») en 1959, BASIC (acron yme de « Beginner’s All-purpose Symbolic  Instruction Code ») en 1964, Logo en 1967, Pascal e n 1971, ou, encore, Prolog (mot valise pour  Programmation logique), inventé par des chercheurs français en 1972.  2 Il faudra attendre 1997 pour que le champion d’éch ecs Garry Kasparov s’incline devant le système  Deep Blue d’IBM. 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 37  -       Capture d’écran d’un exemple de conversation avec E liza    Source : Norbert Landsteiner https: //fr.slideshare .net/ashir233/eliza-4615  La représentation des connaissances, le langage obj et, est au cœur de  l’intelligence artificielle des années 1950 et 1960  et elle est ensuite mise au  service de l’informatique, avec des résultats remar quables permettant les  progrès connus vers les ordinateurs modernes. Ainsi  que le remarque  l’académicien des technologies Gérard Sabah, l’informatique classique  traite traditionnellement de questions résolues par  des algorithmes  connus , alors que l’intelligence artificielle s’intéresse plutôt aux problèmes  pour lesquels aucun algorithme satisfaisant n’exist e encore .  Le paradoxe résultant de cette définition est le su ivant : dès que le  problème a été résolu par une technologie dite d’in telligence artificielle,  l’activité correspondante n’est plus considérée com me une preuve  d’intelligence de la machine . Les cas connus de résolutions de problèmes  d’algèbre ou de capacité à jouer à des jeux (des je ux d’échecs par exemple)  illustrent ce phénomène.  Nick Bostrom explique ainsi que « beaucoup  d’intelligence artificielle de pointe a filtré dans  des applications générales, sans y  être officiellement rattachée car dès que quelque c hose devient suffisamment utile et  commun, on lui retire l’étiquette d’intelligence ar tificielle  ».  Les progrès en matière d’intelligence artificielle étant tangibles  depuis les années 1950, les frontières de l’intelligence artificielle sont donc  sans cesse repoussées et ce qui était appelé intell igence artificielle hier  n’est donc plus nécessairement considéré comme tel aujourd’hui . 
- 38  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Vos rapporteurs observent que, dès l’origine, l’intelligence  artificielle est bien une étiquette . Ce label recouvre en réalité des  technologies diverses, dont ils ont voulu retracer la richesse et la diversité  dans le présent rapport.  Vos rapporteurs ont, en effet, relevé dans leurs in vestigations que les  outils d’intelligence artificielle sont très divers , ce qui traduit la variété des  formes d’intelligence en général : elles vont de formes explicites  (systèmes  experts et raisonnements logiques et symboliques) à  des formes plus  implicites  (réseaux de neurones et deep learning ).  3.  « L’âge d’or » des approches symboliques et des rai sonnements  logiques dans les années 1960 a été suivi d’un prem ier « hiver de  l’intelligence artificielle » dans les années 1970  « L’âge d’or » des approches symboliques et des rai sonnements  logiques se produit dans les années 1960 après la n aissance de l’intelligence  artificielle à Dartmouth. Recourant à des connaissances précises, telles que  des logiques diverses ou des grammaires, ces formes  d’intelligence sont  dites explicites .  Il existe, ensuite, les diverses modalités de formalisme logique , soit  sous la forme de logique classique , de logique floue , de logique modale  ou  de logique non monotone .  La logique mathématique peut représenter des connai ssances 1 et  modéliser des raisonnements . Le principe de résolution permet  d’automatiser ces raisonnements : pour démontrer un e propriété, on montre  que son contraire entraîne une contradiction avec c e qu’on sait déjà. La seule  règle utilisée est celle du « détachement » ou modus ponens , figure du  raisonnement logique concernant l’implication (exem ple : « si p implique q et  si p, alors q »). Cette méthode ne s’applique qu’à des cas simples, où la  combinatoire n’est pas excessive. Fondé sur le même  principe, le langage  Prolog (acronyme de PROgrammation LOGique, qui perm et de résoudre les  problèmes par raisonnement à partir de règles de lo gique formelle) lève ces  restrictions en permettant d’aborder des problèmes plus complexes.  Des difficultés subsistent pour traiter des connais sances vagues ou  incomplètes . Devant ces limites, des extensions théoriques ont  donné lieu à  des logiques non classiques permettant d’exprimer p lus d’éléments que dans  la logique classique. Voulant étendre les possibili tés de la logique classique,  les logiques multivaluées gardent les mêmes concept s de base, hormis les  valeurs de vérité, qui, selon les théories, varient  de trois à un nombre infini  de valeurs. La théorie des logiques floues  étend ces logiques en considérant  comme valeurs de vérité le sous-ensemble réel « [0, 1] ». Elles permettent de                                                    1 Des symboles permettent alors de représenter des f aits et des règles permettent d’en déduire de  nouveaux. 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 39  -       traiter des informations incertaines (Jean viendra peut-être demain) ou  imprécises (Anne et Brigitte ont à peu près le même  âge).  Les logiques modales  introduisent des notions comme la possibilité,  la nécessité, l’impossibilité ou la contingence qui  modulent les formules de la  logique classique. La notion de vérité devient relative  à un instant donné ou  à un individu. On distingue ainsi ce qui est accide ntellement vrai  (contingence : Strasbourg est en France) de ce qui ne peut pas être faux  (nécessité : un quadrilatère a quatre côtés). Diver ses interprétations des  modalités donnent lieu à des applications distincte s, dont les plus  importantes sont les logiques épistémiques (savoirs , croyances), déontiques  (modélisant le droit) et temporelles (passé, présen t, futur).  Les connaissances n’étant pas universelles, nous po uvons être  conduit à des hypothèses et suppositions fausses, r emises en cause à la  lumière d’expériences ultérieures. Les logiques non monotones  tiennent  compte du fait que les exceptions sont exceptionnel les et formalisent les  raisonnements où l’on adopte des hypothèses (tous l es oiseaux volent) qui  pourront être modifiées par des connaissances plus précises (mais pas les  autruches). On raisonne avec des règles du type : s i a est vrai et si b n’est pas  incohérent avec ce qu’on sait, on peut déduire c (s i Titi est un oiseau et si  j’ignore que c’est une autruche, il vole). On autorise ainsi la prise de  décision malgré une information incomplète  : des suppositions plausibles  permettent certaines déductions ; si, à la lumière d’informations ultérieures,  ces suppositions se révèlent fausses, on remettra e n question les déductions  précédentes (non-monotonie).  S’agissant des grammaires , le traitement automatique des langues  est un des grands domaines de l’intelligence artifi cielle, qui vise l’application  de ses techniques aux langues humaines. Très plurid isciplinaire, il collabore  avec la linguistique, la logique, la psychologie et  l’anthropologie. Les travaux  en traitement automatique des langues ont donné lie u à la constitution de  divers ensembles de données numériques (dictionnair es de langue, de  traduction, de noms propres, de conjugaison, de syn onymes ; grammaires  sous diverses formes ; données sémantiques), ainsi qu’à divers logiciels  (analyseurs et générateurs morphologiques ou syntax iques, gestionnaires de  dialogue…). Du point de vue conceptuel, ces travaux  ont produit des  théories grammaticales plus compatibles avec les qu estions  d’informatisation, des théories formelles pour la r eprésentation du sens des  mots, des phrases, des textes et des dialogues, ain si que des techniques  informatiques spécifiques pour le traitement de ces  éléments sur ordinateur.  John McCarthy a inventé le langage de programmation « LISP »  dès  1958 1, c’est un mot valise formé à partir de l’anglais list processing  ou  traitement de listes. De grands espoirs sont alors placés dans la                                                    1 « Fonctions Récursives d’expressions symboliques et  leur évaluation par une Machine » ou  « Recursive Functions of Symbolic Expressions and T heir Computation by Machine » ,  Communications of the ACM, Avril 1960. 
- 40  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        compréhension du langage naturel, dans la vision ar tificielle, mais en fin de  compte les résultats sont décevants, largement en r aison des limitations de  puissance du matériel disponible, des données à uti liser mais aussi des  limites intrinsèques des technologies alors disponi bles.  Ainsi le Perceptron , dans lequel Frank Rosenblatt plaçait tant  d’espérance est rapidement critiqué. Le livre Perceptrons  de Marvin Minsky  et Seymour Papert, paru en 1969, démontre les limit es des réseaux de  neurones artificiels de l’époque 1.  Après cet âge d’or, qui court de 1956 au début des années 197 0 , les  financements sont revus à la baisse  en raison de différents rapports assez  critiques  : les prédictions exagérément optimistes des début s ne se réalisent  pas et les techniques ne fonctionnent que dans des cas simples. À l’évidence,  les difficultés fondamentales de l’intelligence art ificielle furent alors  largement sous-estimées en particulier la question de savoir comment  donner des connaissances de sens commun à une machi ne. Les recherches se  recentrent alors sur la programmation logique, les formalismes de  représentation des connaissances et sur les process us qui les utilisent au  mieux.   En dépit de cette réorientation, qui témoigne d’ une certaine cyclicité  des investissements en intelligence artificielle se lon une boucle « espoirsdéceptions » , Marvin Minsky et ses équipes du MIT (Massachusett s Institute  of Technology) développent divers systèmes (Sir, Ba seball, Student..) qui  relancent les recherches sur la compréhension autom atique des langues.   4.  Un enthousiasme renouvelé dans les années 1980 auto ur des  systèmes experts, de leurs usages et de l’ingénieri e des  connaissances précède un second « hiver de l’intell igence  artificielle » dans les années 1990  Au cours des années 1980, de nouveaux financements publics  sont  ouverts avec le projet japonais dit de « cinquième génération », le  programme britannique Alvey, le programme européen Esprit et le soutien  renouvelé de la DARPA aux États-Unis. Les approches  sémantiques sont  alors en plein essor, en lien avec les sciences cog nitives, la représentation des  connaissances mais surtout avec les systèmes expert s et l’ingénierie des  connaissances. Leurs usages dans le monde économiqu e sont des signes de  cette vitalité.  Il s’agit tout d’abord des systèmes experts , appelés aussi systèmes à  base de connaissances. Un système expert est un log iciel qui vise à                                                    1 La critique principale concerne l’incapacité du pe rceptron à résoudre les problèmes non  linéairement séparables, tels que le problème du « X OR » (« OU exclusif »). Il s’en suivra alors, en  réaction à la déception, une période noire d’une vi ngtaine d’années pour les réseaux de neurones  artificiels. 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 41  -       reproduire les raisonnements d’un expert, dans un d omaine particulier. La  connaissance est décrite sous la forme générale de règles :    « SI Condition (s)  »  « ALORS Action (s)  »    Ces systèmes analysent une représentation de la sit uation pour voir  quelles règles sont pertinentes, résolvent les éven tuels conflits si plusieurs  règles s’appliquent et exécutent les actions indiqu ées en modifiant la  situation en conséquence. Ces systèmes sont efficac es dans des domaines  restreints mais deviennent difficiles à gérer quand  ils doivent manipuler  beaucoup de règles ou dans des domaines ouverts.  Destiné au diagnostic des maladies infectieuses du sang sur la base  d’un ensemble de règles déclaratives (si tels faits  – alors effectuer telles  actions), le premier système expert dit « MYCIN » est créé en 19 74 et se  diffuse dans les années 1980 . Il s’agit alors d’extraire des connaissances à  partir du savoir des experts humains.  Les succès de cette approche restent relatifs car e lle ne fonctionne  bien que dans des domaines restreints et spécialisé s. L’incapacité de  l’étendre à des problèmes plus vastes renforce alor s le désintérêt pour  l’intelligence artificielle.  Après ce court regain d’intérêt, la recherche subit  à nouveau un  déclin des investissements. L’enthousiasme renouvel é dans les années 1980  autour des systèmes experts, de leurs usages et de l’ingénierie des  connaissances  précède donc un second « hiver de l’intelligence artificielle »  dans les années 1990 .  Pour autant, des découvertes scientifiques sont réa lisées dans la  période. Après la renaissance de l’intérêt pour les  réseaux de neurones   artificiels  avec de nouveaux modèles théoriques de calculs, le s années 1990  voient se développer la programmation génétique  ainsi que les systèmes  multi -agents  ou l’intelligence artificielle distribuée . La nécessité de  méta-connaissances 1 émerge également.  Les usages des systèmes experts et de l’ingénierie des connaissances  persistent jusqu’à aujourd’hui ainsi que l’a expliq ué Alain Berger, directeur  général d’Ardans, dans son intervention lors de la journée « Entreprises  françaises et intelligence artificielle » organisée  par le MEDEF et l’AFIA le  23 janvier 2017 . Il a ainsi rappelé qu’il reste  essentiel de faire coopérer et  interopérer les connaissances et les données ; en cela, le développement  d’outils précis revêt une importance capitale pour faire parvenir cette  intelligence vers l’utilisateur, l’humain demeurant  par son expertise la clé de  validation de la connaissance. Depuis 1956, de nomb reux progrès ont été  accomplis, à l’instar du développement des systèmes  experts, de la                                                    1 Il s’agit de connaissances à propos des connaissan ces elles-mêmes. 
- 42  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        production et du recueil de volumes importants de d onnées mais également  de solutions coopératives. Au fil des siècles, le t erme « connaissance » a  évolué ; cependant, l’attachement à la compréhensio n d’une vérité et à sa  construction a demeuré. Ce terme pourrait aujourd’h ui être défini comme le  fait de comprendre, de connaître les propriétés, le s caractéristiques et les  traits spécifiques d’une chose. Selon Alain Berger,  l’ingénierie de la  connaissance s’articule donc autour d’une approche de type cognitiviste, qui  postule que la pensée est un processus de traitemen t de l’information. Le  cognitivisme dans l’ingénierie de la connaissance c onsiste ainsi à coupler  représentation et computation . La connaissance, d’un point de vue  technique, vise à être structurée efficacement pour  l’expert comme pour  l’utilisateur ; d’un point de vue stratégique, il e st essentiel de rendre  explicites les savoirs tacites, de capitaliser les expériences singulières et de  capitaliser les connaissances pour les préserver, l es exploiter, les enrichir et  les amplifier. En ce sens, l’approche cognitiviste consiste en trois clés : une  structuration d’une intelligence humaine, une justi fication du contenu par  la validation d’un expert, et l’interopérabilité av ec d’autres systèmes .  L’ingénierie de la connaissance fait donc figure, p our Alain Berger, de  véritable tremplin de l’innovation, c’est  une compétence clé pour  l’organisation, en ce qu’elle permet la maîtrise de  ses savoirs et la  performance de ses systèmes . Il peut exister, dans le cadre de sujets  exploratoires un besoin de modéliser des phénomènes , des interactions, des  acteurs qui permettront de construire des scénarios  et de construire de  nouvelles connaissances. L’ingénierie de la connais sance a pour points forts :  - la formation des acteurs ;  - l’amélioration des compétences des acteurs d’un ser vice ;  - la résolution de problèmes ;  - la pérennisation de l’expertise, qui est liée à un homme, à une  technologie ou à un projet, la pérennisation des co nnaissances  d’une technologie ou d’un projet.  5.  Les autres domaines et technologies d’intelligence artificielle :  robotique, systèmes multi-agents, machines à vecteu r de  support (SVM), réseaux bayésiens, apprentissage mac hine dont  apprentissage par renforcement, programmation par c ontraintes,  raisonnements à partir de cas, ontologies, logiques  de  description, algorithmes génétiques…  De très nombreux autres domaines et technologies d’ intelligence  artificielle peuvent être ajoutés à ceux déjà menti onnés précédemment.  Certains vont être abordés au présent chapitre sans  que cette liste ne soit en  rien exhaustive : il ne s’agit que de quelques exemples visant à illustrer la  variété et la richesse qui se cache derrière le lab el d’intelligence  artificielle . 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 43  -       Le tableau académique des domaines de l’intelligenc e artificielle  (IJCAI) retient cinq domaines  : traitement du langage naturel, vision (ou  traitement du signal), apprentissage automatique, s ystèmes multi-agents,  robotique.  Mais les technologies d’intelligence artificielle sont  quasi-innombrables , surtout que les chercheurs, tels des artisans,  hybrident des solutions inédites au cas par cas, en  fonction d’un tour de  main souvent très personnel . Il s’agit d’une caractéristique propre à la  recherche en intelligence artificielle, souvent peu  connue à l’extérieur du  cercle des spécialistes et à laquelle ont été sensi bilisés vos rapporteurs.      Les domaines de l’intelligence artificielle    Source : Gouvernement (les pourcentages indiquent l a répartition estimée de manière approximative des  chercheurs français entre les différents domaines d e l’intelligence artificielle)    L’un des premiers domaines qui peut être pris pour exemple est  celui de la robotique , qui a toujours entretenu des liens très étroits a vec celui  de l’intelligence artificielle sans se confondre av ec elle, un champ de la  robotique étant hors de l’IA (les simples automates , par exemple). Pour Raja  Chatila, directeur de l’Institut des systèmes intel ligents et de robotique  (ISIR), la problématique de l’intelligence artifici elle telle que posée par Alan 
- 44  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Turing 1 était de savoir si les ordinateurs pouvaient être capables de  « pensée » ( Can Machines Think? ) et il l’a traduite par la question de  l’imitation de l’homme. Or les fondateurs de « l’in telligence artificielle »  dans les années 1950 ont orienté la problématique v ers celle de  l’« intelligence », ou de « mécanismes de haut nive au ».  Cette manière de poser la question néglige un const at pourtant  simple : au fil des ères (de la reptation à la bipé die, de la cueillette à  l’agriculture, de la chasse à l’élevage par exemple ), le cerveau humain a  évolué  vers ce qu’il est grâce au développement des capacités de  perception, d’interprétation, d’apprentissage et de  communication  en vue  d’une action plus efficace, de plus en plus détermi née par la volonté et des  choix rationnels. Or la problématique de la robotiq ue pose l’ensemble de ces  questions. Le robot-machine est soumis à la complex ité du monde réel dans  lequel il évolue et dont il doit respecter la dynam ique. La notion  d’intelligence doit alors être posée de manière à r endre compte globalement  des processus sensori-moteurs, perceptuels et décis ionnels permettant  l’interaction en temps réel avec le monde en tenant  compte des contraintes  d’incomplétude et d’incertitude de perception ou d’ action. C’est le sens de la  définition de la robotique donnée par Mike Brady (O xford) dans les années  1980 : « La robotique est le lien intelligent entre la per ception et l’action. »  Dans ce  sens on peut dire que le robot est le paradigme de l’intelligence artificielle  « encorporée », c’est-à-dire une intelligence matér ialisée dans un  environnement qu’elle découvre et dans lequel elle agit.  Il est nécessaire, selon Raja Chatila, d’adopter un e vision d’ensemble  du robot, en tant que système  intégrant ses différentes capacités  (perception/interprétation, mouvement/action, raiso nnement/planification,  apprentissage, interaction) et permettant à la fois  la réactivité et la prise de  décision sur le long terme. Ces fonctions doivent ê tre intégrées de manière  cohérente dans une architecture de contrôle globale  (architecture cognitive) ;  leur étude de manière séparée risque d’aboutir à de s solutions  inappropriées.   De nombreuses avancées ont été réalisées dans chacu ne des  fonctions fondamentales du robot : perception, action, apprentissage . Dans  les années 1985-2000, la problématique de la locali sation et de la cartographie  simultanées a connu un développement formidable qui  a permis de bien en  cerner les fondements et de produire des systèmes e fficaces, le point faible  important restant le manque d’interprétations plus sémantiques de  l’environnement et des objets qui le composent.   Un autre domaine est celui des systèmes multi-agents  ou  l’intelligence artificielle distribuée , inspirée des comportements sociaux et  notamment de certaines familles d’insectes, permett ant la mise en œuvre de  systèmes qui s’auto-organisent. Ces comportements s ociaux peuvent être                                                    1 A. M. Turing (1950) Computing Machinery and Intelligence . Mind 49: 433-460.  
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 45  -       programmés de manière plus ou moins complexe et int égrer des croyances,  des désirs et des intentions.  Vos rapporteurs ont expérimenté ces systèmes lors d ’une rencontre  avec les chercheurs du laboratoire de robotique et d’intelligence artificielle  de l’Université Libre de Bruxelles dirigé par le pr ofesseur Hugues Bersini.  Une colonie de petits robots peu intelligents trava illent ensemble,  développent une coopération puis des stratégies plu s complexes que ce que  leur permet leur intelligence individuelle et démon trent ainsi la pertinence  de l’intelligence collective. Les travaux de Michae l Wooldridge sur les  systèmes multi-agents, chercheur également rencontr é par vos rapporteurs,  illustrent les résultats de ces méthodes d’intellig ence artificielle distribuée.  Les systèmes multi-agents  et l’intelligence artificielle distribuée renvoient  donc à des formes collectives de décision . Le développement de systèmes  de plus en plus complexes implique l’utilisation de  connaissances expertes,  hétérogènes, plus ou moins indépendantes les unes d es autres. Différents  experts n’aboutissant pas toujours au même résultat , il faut confronter leurs  décisions pour prendre une décision. Les architectu res classiques (des  modules qui s’enchaînent dans un ordre prédéfini) o nt alors été remises en  cause au profit d’architectures multi-agents. Alors qu’un agent est un  logiciel autonome percevant son environnement et ag issant dessus, un  système multi-agent est constitué d’un ensemble de tels agents, partageant  des ressources communes et communiquant entre eux .  On trouve principalement des agents peu complexes, n’utilisant ni  buts ni plans (et qui sont généralement en grand no mbre) ou des agents  disposant de buts, de plans, de croyances et de con naissances (ces agents  plus élaborés sont souvent peu nombreux). Le point crucial de tels systèmes  concerne la coordination entre les agents . Pour ce faire, différents modes de  communication entre agents sont possibles :  - soit chaque agent analyse les données contenues d ans une zone  commune et, s’il en trouve qu’il peut utiliser, il les traite et écrit de nouvelles  données à utiliser par d’autres agents ;  - soit l’agent concerné quand il rencontre un probl ème envoie un  message à d’autres agents afin de trouver qui peut l’aider à le résoudre. Le  système adapte ainsi de manière dynamique son compo rtement à la situation  à traiter.  La coordination est un aspect important, mais des s ystèmes  multi-agents peuvent mettre l’accent sur d’autres c aractéristiques, à l’instar  du modèle Voyelles développé par Yves Demazeau en 1 995 et qui insiste sur  les relations entre les agents, l’environnement, le s interactions et  l’organisation. 
- 46  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        L’évolution artificielle et la programmation génétique 1 donnent  lieu à l’élaboration d’algorithmes génétiques ou al gorithmes évolutifs, qui  imitent la façon dont la vie biologique a évolué su r terre. En effet, il est  loisible d’interpréter le monde d’aujourd’hui comme  une succession de  stratégies gagnantes. Les espèces qui ont survécu à  la sélection naturelle sont  autant d’exemples de réussite. La nature a, par tât onnement, créé un grand  nombre de combinaisons de codes génétiques qu’elle a ensuite sélectionnés  dans la mesure où ils fonctionnent, survivent et pa rviennent à dominer leur  environnement. Les algorithmes génétiques appliquent les mécanismes  fondamentaux de l’évolution et de la sélection natu relle pour  cartographier des espaces de paramètres et surtout répondre à des  problèmes d’optimisation . On code les caractéristiques des objets manipulés   et on définit une fonction qui évalue la valeur att ribuée à chaque objet. On  fait évoluer une population initiale en créant de n ouveaux objets à partir des  anciens et en permettant diverses mutations. La sélection permet d’éliminer  les objets les moins efficaces . Ce type de processus donne de bons résultats  dans divers domaines, la difficulté résidant dans l e choix du codage (c’est-àdire les paramètres pertinents des objets considéré s) et les types de  mutations autorisées.  Les réseaux bayésiens , qui se situent à l’intersection de  l’informatique et des statistiques 2, donnent de bons résultats parmi les  technologies d’intelligence artificielle. Un  réseau bayésien est un outil  mathématique de modélisation graphique probabiliste  et d’analyse de  données. La modélisation est graphique en ce qu’ell e représente les variables  aléatoires sous la forme d’un graphe orienté 3. Judea Pearl, prix Turing 4 2011  pour « ses contributions fondamentales à l’intelligence ar tificielle par le  développement de l’analyse probabiliste et du raiso nnement causal  », est l’un des  inventeurs de ces modèles. Ils sont particulièremen t adaptés à la prise en  compte de l’incertitude et peuvent être décrits man uellement par des experts  ou produits automatiquement par apprentissage. Un r éseau bayésien permet  de représenter la connaissance acquise (modèle de r eprésentation des                                                    1 Il s’agit d’une technique de programmation inspiré e des mécanismes d’évolution et de sélection  génétique des organismes vivants.  2 Les modèles de régression linéaire sont aussi util isés comme méthode d’apprentissage supervisé  pour prédire une variable quantitative. Ils peuvent  aider à prédire un phénomène ou chercher à  l’expliquer. L’inventeur de la notion en 1886, Fran cis Galton, mettait en évidence, dans un article  fondateur, un phénomène de « régression vers la moy enne » en analysant la taille des fils en fonction  de la taille de leurs pères. Avant cela, Carl Fried rich Gauss avait démontré, dès 1821, un théorème  relatif à l’estimateur linéaire selon la méthode de s moindres carrés, connu aujourd’hui sous le nom  de « théorème de Gauss-Markov », car redécouvert et  complété en 1900 par Andrei Markov. Ce  dernier a ainsi mis en évidence les processus aléat oires dans le calcul des probabilités. Ces aléas, o u  « chaînes de Markov » sont les fondements théorique s du calcul stochastique.  3 Pour un domaine donné, on décrit les relations cau sales entre variables d’intérêt par un graphe.  Dans ce graphe, les relations de cause à effet entr e les variables ne sont pas déterministes, mais  probabilisées. Ainsi, l’observation d’une cause ou de plusieurs causes n’entraîne pas  systématiquement l’effet ou les effets qui en dépen dent, mais modifie seulement la probabilité de les  observer.  4 Ce prix est la plus haute distinction en informati que. 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 47  -       connaissances) ou de découvrir la connaissance dans  un contexte par  l’analyse de données (c’est une machine à calculer les probabilités  conditionnelles), afin de mener des opérations de p rise de décisions, de  diagnostic, de simulation et de contrôle d’un systè me. L’intérêt particulier  des réseaux bayésiens est de tenir compte simultané ment de connaissances a  priori d’experts (dans le graphe) et de l’expérience conte nue dans les  données, ce qui est très pertinent pour l’aide à la  décision.  Les réseaux bayésiens sont donc souvent utilisés po ur des solutions  décisionnelles  qui correspondent souvent aux défis lancés aux tec hnologies  d’intelligence artificielle.   Michael Jordan, professeur à l’Université de Berkel ey, que vos  rapporteurs ont rencontré, identifie quatre pistes sur lesquelles il fait  particulièrement travailler ses équipes, qui s’insc rivent dans le prolongement  des modèles graphiques probabilistes et en particul ier des réseaux bayésiens,  dont il est une des figures avec Judea Pearl et Dap hne Koller. Il décrit ainsi  quatre axes de recherche pertinents : les variables latentes, les modèles  topiques, les modèles de causalité et les séries te mporelles .  Deux autres outils d’intelligence artificielle sont  rappelés ici. La  programmation par contraintes , qui se rapproche de certains raisonnements  humains, et les raisonnements à partir de cas , qui se fondent sur la notion  d’analogie mais tend à devenir plus marginal.  Dans certains problèmes, on connaît les valeurs pos sibles que  peuvent prendre certaines des variables – on parle alors de contraintes.  Résoudre le problème consiste alors à affecter à ch aque variable une valeur  satisfaisant ces contraintes. L’évolution de Prolog  système, évoqué plus haut,  a été fondée sur cet aspect. Cette technique de programmation par  contraintes , d’origine française, permet des raisonnements locaux, en  simplifiant le problème global en sous-problèmes pa rtiels, puis une  propagation des contraintes sur l’ensemble du probl ème . Elle est largement  utilisée en biologie moléculaire, en conception de produits industriels, en  planification de production, en gestion du trafic d ans les villes et les  aéroports. Ses limites sont patentes dans les probl èmes dynamiques (où les  contraintes varient dans le temps) ou dans les prob lèmes « sur-contraints »  (dans les cas où il n’existe pas de solution qui vé rifie toutes les contraintes).  Le fait de savoir quelles contraintes négliger ou p rivilégier reste un problème  ouvert.  Le raisonnement à partir de cas se fonde sur des an alogies entre  des expériences passées et un problème actuel . On mémorise un certain  nombre de situations spécifiques dans un domaine do nné (les « cas ») et,  devant un nouveau problème, on essaye de trouver le  ou les cas les plus  proches, puis on transpose les solutions déjà renco ntrées au nouveau  problème. C’est typiquement le raisonnement utilisé par la justice pour  adapter la jurisprudence à une nouvelle situation . Deux étapes sont  nécessaires pour ce type de raisonnement : l’indexa tion, qui sert à trouver les 
- 48  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        cas pertinents pour le problème actuel, et l’adapta tion, pour modifier un ou  plusieurs cas et les rendre applicables au problème  actuel. Les métriques  permettant l’indexation calculent une mesure de sim ilarité entre cas. La  difficulté essentielle de ce type de raisonnement é tant de trouver le chemin  qui va de la solution du cas connu au problème en c ours, sachant que les  métriques les plus élaborées tentent d’en tenir com pte.  Pour comprendre l’ apprentissage automatique  ou machine learning ,  il est loisible d’introduire, comme le préconise Je an-Claude Heudin, les  concepts de  « prédicteur  » et de « classifieur  ». Ce dernier est une machine  capable d’approximer un processus 1 dont on ne connaît pas a priori le  modèle. Le calcul de la sortie en fonction des donn ées présentées en entrée  est appelé une régression. Un classifieur est une m achine qui va plus loin  qu’un simple prédicteur, c’est aussi une fonction l inéaire, mais elle permet  de différencier des éléments appartenant à des caté gories différentes lorsque  ces catégories sont clairement séparables.  Le mot algorithme est issu, comme il a été vu, de l a latinisation du  nom du mathématicien Al-Khawarizmi  et correspond à une suite finie et  non ambiguë d’opérations ou d’instructions permetta nt de résoudre un  problème ou d’obtenir un résultat . La difficulté liée aux algorithmes  classiques réside dans le fait que l’ensemble de to us les comportements  possibles, compte tenu de toutes les entrées possib les, devient rapidement  trop complexe à décrire. Cette explosion combinatoire justifie de confier à  des programmes le soin d’ajuster un modèle adaptati f permettant de  simplifier cette complexité  et de l’utiliser de manière opérationnelle en  prenant en compte l’évolution de la base des inform ations pour lesquelles les  comportements en réponse ont été validés. C’est ce que l’on appelle  l’apprentissage automatique  ou machine learning , qui permet donc au  programme d’apprendre  et d’améliorer le système d’analyse et/ou de  réponse. En ce sens, on peut dire que ces types particuliers  d’algorithmes  apprennent .  Un apprentissage est dit « supervisé » lorsque l’algorithme définit  des règles à partir d’exemples qui sont autant de c as validés . Ces exemples   sont appelés bases de données d’apprentissage. Jean -Claude Heudin parle  ainsi de méthode itérative, autrement dit un algori thme, visant à ajuster les  paramètres d’un classifieur linéaire en fonction de  l’erreur qu’il commet  entre la sortie souhaitée et la sortie obtenue grâc e aux exemples que sont les  données d’apprentissage. La correction à apporter à  chaque étape au  paramètre du classifieur peut être calculée simplem ent en faisant le rapport  de l’erreur sur la valeur d’entrée. Une meilleure p erformance est obtenue en  modérant les ajusements par un taux d’apprentissage . Le classifieur peut  aussi être non linéaire en vue de séparer des donné es qui ne sont pas                                                    1 Le comportement du processus est approximé grâce à  un modèle qui comprend un ensemble de  paramètres ajustables. Une bonne approche pour ajus ter les paramètres est de les modifier  progressivement de façon à minimiser l’erreur que l e prédicteur produit lorsqu’on lui présente des  données dont on connaît la sortie correspondante. 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 49  -       elles-mêmes régies par un processus linéaire 1. Les réseaux de neurones  artificiels, analysés plus loin, représentent une multiplication de classifieurs  non linéaires dotés de paramètres d’ajustement  (il s’agit de coefficients qui  sont appelés de manière métaphorique les « poids sy naptiques »).  À l’inverse de l’apprentissage supervisé, lors d’un  apprentissage  « non supervisé » , le modèle est laissé libre d’évoluer vers n’importe quel  état final  lorsqu’un motif ou un élément lui est présenté.  Entre ces deux formes d’apprentissage, l’apprentiss age automatique  ou machine learning  peut-être semi-supervisé ou partiellement supervisé .  L’apprentissage automatique peut lui-même reposer s ur plusieurs  méthodes : l’apprentissage par renforcement , l’apprentissage par transfert,  ou, encore,  l’apprentissage profond , qui sera vu plus loin.  L’apprentissage par renforcement conduit l’algorith me à apprendre,  à partir d’expériences ou d’observations, un comportement optimal  ou  stratégie, selon une logique itérative de recherche de récompenses , un peu  comme dans le cas du dressage d’un animal. L’action  de l’algorithme sur un  environnement donné produit une valeur de retour qu i guide son  apprentissage dans la mesure où l’algorithme cherch e dans ce cadre  d’apprentissage par renforcement à optimiser sa fon ction de récompense  quantitative au cours des expériences. Par exemple,  l’algorithme de  « Q-learning », qui optimise les actions accessible s sans même avoir de  connaissance initiale de l’environnement par une co mparaison de  récompenses probables, est un cas d’apprentissage p ar renforcement.  L’apprentissage par transfert peut être vu comme la  capacité d’un  système à reconnaître à partir de tâches antérieures  apprises des  connaissances et des compétences, puis à appliquer ces dernières sur de  nouvelles tâches  partageant des similitudes.  L’apprentissage supervisé permet, de plus, des méth odes prédictives  utiles en reconnaissance de formes, selon plusieurs  approches : les arbres de  décision , les réseaux bayésiens  ou, encore, les machines à vecteurs de  support .  Avec les arbres de décision 2, les algorithmes d’apprentissage  supervisés peuvent calculer automatiquement à parti r de bases de données,  en sélectionnant automatiquement les variables disc riminantes à partir de  données peu structurées et potentiellement volumine uses. Ils peuvent ainsi  permettre d’extraire des règles logiques de cause à effet  (des  déterminismes) ou, au moins, des corrélations , qui n’apparaissaient pas  immédiatement dans les données brutes .                                                    1 L’exemple le plus connu est celui des opérateurs b ooléens (du nom du mathématicien George Boole)  « Ou - Exclusif » (en anglais « X-OR »). Un classif ieur linéaire peut traiter des opérations « Et » ou   « Ou » mais bute sur le « Ou - Exclusif ». Les opér ateurs booléens recourent à la solution  « Non - Et » (en anglais « Nand »).  2 Un arbre de décision est un outil d’aide à la déci sion représentant un ensemble de choix sous la  forme graphique d’un arbre. 
- 50  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Avec les réseaux bayésiens , qui ont été mentionnés plus hauts,  l’apprentissage automatique peut être utilisé de de ux façons : pour estimer la  structure d’un réseau, ou pour estimer les tables d e probabilités d’un réseau,  dans les deux cas à partir de données. L’intérêt pa rticulier des réseaux  bayésiens est de tenir compte simultanément de connaissances a priori   d’experts et de l’expérience contenue dans les donn ées .  Les machines à vecteurs de support  (en anglais support vector  machines  ou SVM), parfois appelées séparateurs à vaste marg e sont des  techniques d’apprentissage supervisé reposant sur l es notions de marge  maximale et de fonction noyau, destinées à résoudre des problèmes de  discrimination et de régression . Il s’agit de classifieurs linéaires 1 dont les  excellentes capacités de généralisation leur ont pe rmis d’être l’une des  technologies dominantes en intelligence artificiell e dans les années 1990 et  2000.  La méthode Monte-Carlo 2 et la méthode du recuit simulé 3,  techniques plus anciennes, sont d’autres méthodes d ont le but est de trouver  une solution optimale pour un problème donné et qui  peuvent se combiner  avec les technologies d’apprentissage automatique.  Les réseaux de neurones  artificiels  prennent en compte  l’apprentissage de manière dite « implicite » ou, e n tout état de cause, plus  implicite que l’ensemble des méthodes qui viennent d’être présentées.  Un réseau de neurones artificiels  est constitué d’un ensemble  d’éléments interconnectés, chacun ayant des entrées  et des sorties  numériques . Le comportement d’un neurone artificiel dépend de  la somme  pondérée de ses valeurs d’entrée et d’une fonction de transfert. Si cette  somme dépasse un certain seuil, la sortie prend une  valeur positive, sinon  elle reste nulle . Ainsi que l’explique Jean-Claude Heudin, ces rése aux sont  des « automates à seuil qui réalisent la somme pondérée d e leurs entrées. Les  coefficients synaptiques et le seuil d’activation p ermettent d’ajuster leur  comportement  ». Le neurone formel peut être amélioré en utilisa nt des valeurs  numériques au lieu d’un comportement binaire. Pour ce faire, la fonction à  seuil est remplacée par une fonction sigmoïde 4, les calculs restent néanmoins                                                    1 Algorithmes de classement statistique, les classif ieurs permettent de classer dans des groupes des  échantillons qui ont des propriétés similaires, mes urées par des observations. Un classifieur linéaire   en est un type particulier, qui calcule la décision  par combinaison linéaire des échantillons.  2 Il s’agit de méthodes algorithmiques visant à calc uler une valeur numérique approchée en utilisant  des techniques probabilistes ou aléatoires. Nichola s Metropolis a utilisé le nom de méthode  Monte-Carlo en 1947 en faisant allusion aux jeux de  hasard pratiqués au casino de Monte-Carlo.  3 Adapté par des chercheurs d’IBM en 1983, le recuit  simulé est une méthode empirique ou  méta-heuristique cherchant à optimiser les chances de découvertes des extrêmes d’une fonction. Elle  est inspirée d’un processus traditionnel utilisé en  métallurgie, qui consiste à alterner des cycles de   refroidissement lent et de réchauffage dans le but de minimiser l’énergie du matériau. Elle a été  théorisée en 1985 par S. Kirkpatrick, C.D. Gelatt e t M.P. Vecchi, et indépendamment par V. Černy.  4 La fonction sigmoïde a globalement la même forme q ue la fonction à seuil, mais les changements de  valeur entre 0 et 1 sont plus progressifs : la cour be est plus douce et moins abrupte. L’équation de l a  fonction sigmoïde est la suivante : y = 1 / (1 + e -x). 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 51  -       élémentaires. Un réseau de neurones artificiels com porte une couche  d’entrée (les données), une couche de sortie (les résultats), et peut comporter  une ou plusieurs couches intermédiaires , avec ou sans boucles.  Le principe de fonctionnement consiste, dans une pr emière phase, à  présenter en entrée les valeurs correspondant à de nombreux exemples, et en  sortie les valeurs respectives des résultats souhai tés.  Cet apprentissage permet d’ajuster les poids synapt iques , qui sont  donc des coefficients capables de s’auto-ajuster,  afin que les  correspondances entre les entrées et les sorties so ient les meilleures  possible .  Après un nombre statistiquement pertinent d’exemple s,  l’apprentissage (implicite) est terminé et le résea u peut être utilisé, dans une  seconde phase, pour la reconnaissance. Comme il pro duit toujours une  sortie, même pour des entrées non rencontrées aupar avant, il a le plus  souvent une bonne capacité de généralisation, qui d épend du corpus  d’apprentissage .  Il s’agit donc de combiner de nombreuses fonctions simples pour  former des fonctions complexes et d’ apprendre les liens entre ces fonctions  simples à partir d’exemples étiquetés .  L’analogie avec le fonctionnement du cerveau humain  repose sur le  fait que les fonctions simples rappellent le rôle j oué par les neurones, tandis  que les connexions rappellent les synapses.  Il ne s’agit en aucun cas de réseaux de neurones de  synthèse , ce  n’est qu’une image. Cette métaphore biologique est sans doute malheureuse  selon vos rapporteurs, car elle entretient une form e de confusion , en lien  avec celle produite également par la notion d’ intelligence artificielle .   
- 52  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Schéma d’un réseau de neurones artificiels     Source  : Académie des technologies    Les applications nécessitent des structures aux cou ches de plus en  plus conséquentes, malheureusement comme l’explique  Jean-Claude  Heudin, plus le nombre de couches augmente et plus les problèmes de  surajustement ( overfitting ) et de disparition des gradients ( vanishing gradient )  deviennent gênants, sans même parler des temps de c alcul qui explosent.  D’autres technologies peuvent encore être citées co mme la recherche  dans les espaces d’états, la planification (très ef ficace au jeu d’échecs), les  ontologies, les logiques de description… Les domain es de l’intelligence  artificielle, comme le traitement du langage nature l ou la vision artificielle  utilisent plusieurs des technologies disponibles, q ui, comme il sera vu plus  loin, peuvent de plus se combiner entre elles .  Dans la période récente, un système d’intelligence artificielle nommé  Libratus , créé par le professeur Tuomas Sandholm et son doc torant Noam  Brown, tous deux chercheurs de l’Université Carnegi e Mellon de Pittsburgh,  a affronté et battu en janvier 2017 quatre joueurs de poker profe ssionnels   dans un casino de Pennsylvanie, au cours d’une part ie de poker 1 de  120 000 mains successives sur 20 jours, intitulée « Cerveau contre Intelligence  Artificielle : on monte la mise » (« Brains Vs. Artificial Intelligence : Upping the                                                    1 Il s’agit de parties de poker « Texas Hold’em  », en face à face ou heads-up  et sans limite de mise  ou no limit . 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 53  -       Ante »). Sa victoire sans appel, avec un gain de 1,8 mil lion de dollars (contre  des pertes pour tous les autres joueurs), marque à son tour l’histoire des  progrès des systèmes d’intelligence artificielle , surtout que le poker  requiert une forme de raisonnement particulièrement  difficile à imiter  pour une machine . Libratus  a utilisé les capacités de calcul du  superordinateur de l’Université Carnegie Mellon et combiné des algorithmes  de Public Chance Sampling (PCS, à ce stade non trad uit en français et qui  signifie « Échantillonnage de hasard public »), var iante de la « réduction des  regrets contrefactuels »1 (Counterfactual Regret Minimization ou CFR), avec  la méthode d’Oskari Tammelin introduite en 2014, pe rmettant l’optimisation  des résultats dans un contexte d’informations impar faites 2. Un article  collectif paru dans la revue Science  en 2015 présentait déjà les évolutions  théoriques nécessaires à cette victoire 3.  En effet, un joueur de poker ne connaît pas les res sources (cartes) et  les stratégies (sincérité ou pas) de son adversaire  et doit donc agir sans  informations certaines et sans écarter la possibili té d’un bluff. La réflexion de  la machine au poker doit donc prendre en compte des données incomplètes  ou dissimulées ce qui distingue le poker d’autres j eux comme le Go ou les  échecs , dans lesquels l’intelligence artificielle avait d éjà démontré sa  supériorité sur l’homme. Le poker fait intervenir l es notions de hasard, de  piège et de bluff, alors que les jeux où dominaient  l’intelligence artificielle  jusqu’en janvier 2017 étaient fondés sur des straté gies relevant de l’analyse  combinatoire : les deux adversaires s’y affrontaien t en continu en visualisant  l’ensemble du jeu et des pions.  Cette victoire de Libratus  en 2017 n’a reposé que sur des duels, la  machine jouant contre un seul joueur à la fois. La prochaine étape pour les  développeurs sera d’assurer la victoire d’une intel ligence artificielle dans des  parties à plusieurs. Tuomas Sandholm et Noam Brown travaillent à ce  nouveau projet.  De manière caricaturale, on pourrait résumer les te chnologies  d’intelligence artificielle à un champ de recherche  où s’opposent deux  grands types d’approches : les approches symboliques  et les approches  connexionnistes . Comme il a été vu à travers la description des no mbreuses  technologies développées, la réalité est souvent pl us complexe que cette  opposition, puisqu’il existe une multitude de techn ologies, qui, de plus,  peuvent se conjuguer. Parmi les approches connexion nistes, voire parmi  toutes les familles d’approches en intelligence art ificielle, l’apprentissage  profond ou « deep learning  » est devenu dominant au cours des dernières  décennies, en particulier au cours des quatre derni ères années.                                                    1 Cf. https://www.quora.com/What-is-an-intuitive-explanat ion-of-counterfactual-regretminimization    2 Cf. https://arxiv.org/abs/1407.5042    3 Cf. http://science.sciencemag.org/content/347/6218/145   
- 54  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Pour la DARPA, dont vos rapporteurs ont rencontré l es  responsables, ces deux grands types d’approches peu vent se voir donner le  nom de « savoirs artisanaux » (ou faits à la main, en anglais handcrafted  knowledges ) pour la première et d’apprentissages statistiques  ( statistical  learning ) pour la deuxième, sachant qu’une troisième généra tion d’approche  de l’intelligence artificielle devrait bientôt adve nir : celle de l’adaptation  contextuelle  (contextual adaptation ).  B.  L’ACCÉLÉRATION RÉCENTE DE L’USAGE DES TECHNOLOGIES  D’INTELLIGENCE ARTIFICIELLE GRÂCE AUX PROGRÈS EN  APPRENTISSAGE AUTOMATIQUE (« MACHINE LEARNING »)  1.  Les découvertes en apprentissage profond (« deep learning  »)  remontent surtout aux années 1980, par un recours a ux « réseaux  de neurones artificiels » imaginés dès les années 1 940  Les technologies d’apprentissage profond ou « deep learning  »  rencontrent un succès particulièrement remarquable dans les années  2010 ,  pourtant elles sont anciennes. Leur essor doit beau coup à l’émergence  récente de la disponibilité de données massives (« big data  ») et à  l’accélération de la vitesse de calcul des processe urs, mais leur histoire  remonte aux années 1940, ce que vos rapporteurs ont  évoqué précédemment  mais jugent nécessaire de rappeler de façon plus dé taillée ici : comme il a été  vu les « réseaux de neurones artificiels » sont imaginés d ès les années 1940 1  et aboutissent au Perceptron  à la fin des années 1950. En 1957, au laboratoire  d’aéronautique de l’Université Cornell, Frank Rosen blatt invente ce dernier à  partir des travaux de McCulloch et Pitts, ce qui co nstitue la première  modélisation d’un réseau de neurones artificiels , dans sa forme la plus  simple, à savoir un classifieur linéaire 2. Marvin Minsky ayant pointé,  comme il a été, vu les défauts de ce système, des perceptrons multicouches   ont ensuite été proposés en 1986, parallèlement, pa r David Rumelhart et  Yann LeCun.  Les réseaux de neurones artificiels peuvent être à apprentissage  supervisé ou non  (ils sont le plus souvent supervisés, comme dans l e cas du  Perceptron), avec ou sans rétropropagation (back propagation ).  Outre les réseaux multicouches, d’importantes décou vertes en  apprentissage profond (« deep learning  ») remontent aux années 1980, telles  que la rétropropagation du gradient . Les pionniers de ces découvertes sont  Paul Werbos, David Parker, et le Français Yann LeCu n rencontré plusieurs                                                    1 Les mathématiciens et neurologues Warren McCulloch  et Walter Pitts posent dès 1943 l’hypothèse  que les neurones avec leurs deux états, activé ou n on activé, pourrait permettre la construction  d’une machine capable de procéder à des calculs log iques. Ils publièrent dès la fin des années 1950  des travaux plus aboutis sur les réseaux de neurone s artificiels.  2 Cf. « The Perceptron : A Probabilistic Model for Inform ation Storage and Organization in  the Brain ».  
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 55  -       fois par vos rapporteurs. David Rumelhart, Geoffrey  Hinton  et Ronald  Williams théorisent cette découverte en 1986 dans u n fameux article intitulé  Learning representations by back-propagating errors1. L’idée générale de la  rétropropagation consiste à rétropropager l’erreur commise par un neurone à  ses synapses et aux neurones qui y sont reliés.  Le principe de rétropropagation du gradient fonde l es méthodes  d’optimisation utilisées dans les réseaux de neuron es multicouches ,  comme les perceptrons multicouches. Il s’agit en ef fet de faire converger  l’algorithme de manière itérative vers une configur ation optimisée des  poids synaptiques . L’algorithme étant itératif, la correction s’appl ique  autant de fois que nécessaire pour obtenir une bonn e prédiction. Une  vigilance est requise face aux problèmes de surappr entissage liés à un  mauvais dimensionnement du réseau ou un apprentissa ge trop poussé.  La correction des erreurs peut aussi se faire selon  d’autres méthodes,  en particulier le calcul de la dérivée seconde .  L’apprentissage profond  ou deep learning  regroupe donc des  méthodes plus récentes d’apprentissage automatique , ou machine learning   dont elles sont une sous-catégorie .  Ces méthodes, parfois qualifiées de  révolution dans le domaine de  l’intelligence artificielle , ont pour spécificité d’utiliser  des modèles de  données issus d’architectures articulées en différe ntes couches d’unité de  traitement non linéaire, qui sont autant de niveaux  d’abstraction des  données . La façon de rétropropager l’erreur au sein de plu sieurs couches  cachées permet de généraliser plus efficacement, ce  qui permet des  représentations de plus haut niveau et une capacité  à traiter des données  plus complexes.  Selon Yann LeCun « Les cerveaux humain et animal sont "profonds",  dans le sens où chaque action est le résultat d’une  longue chaîne de communications  synaptiques (de nombreuses couches de traitement). Nous recherchons des  algorithmes d’apprentissage correspondants à ces "a rchitectures profondes". Nous  pensons que comprendre l’apprentissage profond ne n ous servira pas uniquement à  construire des machines plus intelligentes, mais no us aidera également à mieux  comprendre l’intelligence humaine et ses mécanismes  d’apprentissages ».   L’apprentissage profond a récemment fait une incurs ion  considérable en robotique , contestant la place dominante de l’apprentissage  bayésien, à la fois pour la perception et pour la s ynthèse d’actions.  Mais, comme le remarque Raja Chatila, la perception  en robotique  nécessite une interaction  du robot avec son environnement et non une simple  observation de celui-ci . L’apprentissage par renforcement est particulièreme nt  pertinent ici (le cas échéant en complément de l’ap prentissage profond) car il  est un apprentissage souvent non supervisé qui perm et au robot de  découvrir à la fois les effets de ses actions, cara ctérisés par une                                                    1 http://www.nature.com/nature/journal/v323/n6088/abs /323533a0.html   
- 56  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        « récompense » obtenue comme conséquence de l’actio n, et l’incertitude de  ses actions qui n’ont pas toujours les mêmes effets . Le lien entre perception  et apprentissage - en particulier avec l’apprentiss age par renforcement - est  essentiel pour extraire la notion d’ affordance  qui rend compte des propriétés  des objets en ce qu’elles représentent pour l’agent , et qui associe les  représentations perceptuelles aux capacités d’actio n. C’est cela qui sert de  base au robot pour exprimer le sens du monde qui l’ entoure.  L’affordance , courante en ergonomie et en design , évoque la  potentialité ou la capacité d’un système à suggérer  sa propre utilisation ,  sans qu’il soit nécessaire de lui fournir un mode d ’emploi. Issue de la  psychologie 1, la notion renvoie d’abord à toutes les possibilit és d’actions sur  un objet puis a évolué vers les seules possibilités  dont l’acteur est conscient.  Cette utilisation intuitive est importante en robot ique.  2.  L’apprentissage profond connaît un essor inédit dan s les années  2010 avec l’émergence de la disponibilité de donnée s massives  (« big data ») et l’accélération de la vitesse de calcul des  processeurs    En deep learning , toute chose étant égale par ailleurs, les algorithmes  donnent des résultats d’autant plus performants que  les données sont  massives, variées, rapides et pertinentes  : ce sont les quatre V du big data , à  savoir un volume  croissant de données, issues d’une large variété  de  sources, qui circulent à une vitesse  élevée et dont la véracité  assure la  cohérence.                                                                      1 Elle apparait pour la première fois en 1977 dans l ’ouvrage The Theory of Affordances  puis en  1979 dans Approche écologique de la perception visuelle, écrits par le psychologue  James J. Gibson. Il s’agit, selon lui, de combinais ons invariantes de variables qui dépendent du  contexte de l’action : les affordances  ne sont donc pas des propriétés à part entière de l’objet dans  ses travaux. La perception dépendant de la culture,  de l’expérience et de l’apprentissage, une  affordance dissimulée peut devenir perceptible par l’apprentis sage. En outre, les normes peuvent  contribuer à la perception des affordances . Le sens du concept a évolué et s’est élargi aux c apacités  d’un objet ou d’un être à suggérer sa propre utilis ation. 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 57  -           Les « Quatre V » du big data     Source : Thierry Lombry, http://www.astrosurf.com/l uxorion/big-data-mining.htm    S’agissant du volume de données, il a eu pour condi tion la capacité  croissante en matière de stockage de ces dernières . Les supports de  stockage des données ont rapidement évolués ces der nières décennies et sont  de plus en plus divers.                             
- 58  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE            Supports de stockage des données    Source : Thomas Hauet, maître de conférences à l’Un iversité de Lorraine      Les disques durs des ordinateurs ont vu leur capacité de stockage   suivre une croissance exponentielle, dans le même t emps où le coût du  stockage  des données a, quant à lui, chuté très rapidement,  surtout au cours  des 25 dernières années. Le graphique suivant illus tre la conjugaison de ces  deux processus.   
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 59  -       Progrès technologique dans la capacité de stockage des données     Source : Thomas Hauet, maître de conférences à l’Un iversité de Lorraine    Selon Thomas Hauet, maître de conférences à l’Unive rsité de  Lorraine, le stockage des données a énormément évol ué depuis le premier  disque dur dans les années 1950 (le RAMAC d’IBM en 1956 était une boîte  volumineuse de cinquante disques qui faisaient jusq u’à 60 centimètres de  large). On n’avait alors que seulement 5 mégabytes d’information avec un  coût considérable du gigabyte (10 9 informations) de l’ordre de 10 millions de  dollars . En 1981, l’objet disque dur fait 30 à 40 centimèt res de large avec des  coûts moindres (100 000 dollars du gigabyte), des v itesses un peu plus  grandes d’accès à l’information (20 Mbit/s). En 199 4, la structure du disque  rejoint celle que nous connaissons aujourd’hui, ave c un coût de 100 dollars  par gigabyte. En 2015, les disques durs permettaien t de stocker  4 000 gigabytes  d’information avec des densités nettement plus gra ndes  (500 Gbit/inch carré) et des coûts de 0,04 dollar le gigabyte . Nous sommes  donc passés en 50 ans d’un coût de 10 millions de d ollars à 0,04 dollar le  gigabyte.  Avec la vitesse de calcul des processeurs, dont il sera question plus  loin, les données massives (« big data ») ont conduit dans la période récente à  d’importantes améliorations dans l’efficacité des a lgorithmes . Mais ces  données massives n’ont pas été par elles-mêmes le s eul facteur de  progression des algorithmes dans les années 2000 et  2010, mais la 
- 60  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        constitution de grandes bases de données labellisées  a souvent constitué un  préalable 1.  En 1998, MNIST a fait figure de pionnier en utilisa nt les images des  données postales manuscrites de la poste américaine . Deux autres bases de  données labellisées ont plus récemment permis aux d éveloppeurs  d’entraîner, de faire progresser et de comparer leu rs algorithmes. En 2009,  l’Institut canadien de recherche avancée, basé à To ronto, a créé les bases de  données CIFAR-10 et CIFAR-100 du nom de l’acronyme anglais de l’Institut,  Canadian Institute for Advanced Research  ou CIFAR. La distinction entre les  deux bases de données, vient du nombre de classes u tilisées pour  l’apprentissage : 10 classes de données pour CIFAR- 10 ou 100 classes de  données pour CIFAR-100.  En 2010, le projet ImageNet a été lancé aux États-Unis2 avec l’idée  d’organiser un concours annuel sur les programmes m is en place pour traiter  la base de données éponyme. Ce concours s’intitule ImageNet Large Scale  Visual Recognition Challenge  (ILSVRC) et rassemble plus de 50 organisations  participant chaque année (universités, centres de r echerche, entreprises…).  En 2016, la base de données avait annoté un total d e dix millions d’images  disponibles sur Internet .  Dans un article de 2014, Geoffrey Hinton indiquait que la base de  données d’apprentissage de Google comprenait alors environ 100 millions  d’images annotées et plus de 18 000 classes. En d’a utres termes, selon  Jean-Claude Heudin prenant l’exemple de la reconnai sance d’un chat, « il  vaut mieux avoir des images avec le chat dans tous ses états, plutôt que d’appliquer  des prétraitements pour repositionner le chat dans une position idéale  », de même  pour améliorer les performances d’une application, il vaut donc mieux  augmenter le volume des données d’apprentissage que  chercher à tout prix  un meilleur algorithme, d’où l’aphorisme : « ce n’est pas forcément celui qui a  meilleur algorithme qui gagne, c’est celui qui a le  plus de données  ».  Les données sont donc essentielles car l’apprentissage des  algorithmes repose sur celles-ci . L’acquisition de données annotées  représente un enjeu stratégique pour les États et u n enjeu industriel pour les  entreprises.  Ces dernières, telles Google ou Facebook, donnent d ’ailleurs  maintenant assez largement accès à leurs logiciels en open source , mais - à  ce stade - pas à leurs données. La réflexion sur l’open source  est importante  mais doit aller jusqu’à poser la question de l’accès aux données . Pour  Stéphane Mallat, professeur à l’École normale supér ieure et rencontré par  vos rapporteurs, pour donner des résultats satisfai sants, « ces algorithmes (de                                                    1 Une liste de ces nombreuses bases de données peut être consultée ici :  https://en.wikipedia.org/wiki/List_of_datasets_for_ machine_learning_research  2 Avec des chercheurs tels que Olga Russakovsky, Jia  Deng, Hao Su, Jonathan Krause, Sanjeev  Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein,  Alexander C. Berg ou Fei-Fei Li. Site : http://image-net.org/   
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 61  -       deep learning) doivent tout d’abord être alimentés par des quantités de données  gargantuesques. C’est pour cela que DeepMind, le pr ojet de Google, possède  aujourd’hui une telle longueur d’avance ». Les grandes firmes américaines  disposent en effet de données personnelles massives , qu’elles peuvent  utiliser librement dans leurs projets de recherche internes. Mais l’étendue  des corpus de données ne fait pas tout  : « pour les applications médicales, il ne  suffit pas d’avoir à disposition un grand nombre de  mesures par patients : encore  faut-il qu’elles portent sur beaucoup de personnes différentes. Sinon, la règle  construite par l’algorithme fonctionnera peut-être très bien pour une personne  donnée... mais sera difficilement généralisable à t oute la population. La médecine  serait le champ de recherche le plus propre à bénéf icier des big data... mais c’est celui  qui est le plus entravé par les problématiques de c onfidentialité des données ».  Volume, variété, vélocité et véracité sont bien les  quatre V complémentaires  du big data  selon la formule consacrée déjà rappelée par vos r apporteurs.   Les techniques d’apprentissage automatique , ou machine learning ,  se renforcent au cours des quinze dernières années,  surtout au cours des  cinq dernières années en bénéficiant du concours de  données massives  ou  big data . Sans que d’importantes nouveautés théoriques n’ai ent émergé, à  l’exception de l’apprentissage profond ou deep learning , les outils de  l’intelligence artificielle se sont largement diffu sés, aussi bien dans la vie  quotidienne que dans des applications industrielles  ou militaires. Il convient  de relever que nous ne disposons d’aucune explicati on théorique des raisons  pour lesquelles les réseaux de neurones fonctionnen t, c’est-à-dire donnent,  dans un certain nombre de domaines, d’excellents ré sultats. Sans disposer  d’une démonstration générale, il est cependant poss ible, selon Bertrand  Braunschweig, de comprendre pourquoi ces technologi es sont  mathématiquement efficaces, et ce grâce à des appro ximateurs universels  parcimonieux ou par la théorie de la dimension de V apnik et Chervonenkis  (dite « VC-dimension »).  En apprentissage profond, qui repose donc sur des r éseaux de  neurones profonds ( deep neural networks ), on peut distinguer les  technologies  selon la manière particulière d’organiser les neurones en  réseau  : les réseaux peuvent être en couches , tel le Perceptron, les  Perceptrons multicouches et les  architectures profondes (plusieurs dizaines  ou centaines de couches), dans lesquels chaque neur one d’une couche est  connecté à tous les neurones des couches précédente s et suivantes (c’est la  structure la plus fréquente), les réseaux totalement interconnectés , dans  lesquels tous les neurones sont connectés les uns a ux autres (cas rare des  « réseaux de Hopfield » et des « machines de Boltzm ann »), les réseaux  neuronaux récurrents et les réseaux neuronaux  à convolution .  Ces deux dernières technologies, imaginées à la fin  des années 1980  et au début des années 1990, font l’objet d’investi gations particulièrement  poussées et d’applications de plus en plus riches d epuis trois ans.   Les réseaux neuronaux récurrents  (RNR ou recurrent neural networksRNN  en anglais) permettent de prendre en compte le contexte  et de relever 
- 62  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        le défi de traiter des séquences avec des réseaux d e neurones (il existe, au  moins, un cycle dans la structure du réseau). Au se in de ces RNR, on relève  les architectures MARNN (pour Memory-Augmented Recurrent Neural  Networks  ou réseaux neuronaux récurrents à mémoire augmenté e), les  architectures LSTM (pour Long Short Term Memory ), les architectures BLSTM  (pour Bidirectionnal Long Short Term Memory ), les architectures BPTT (pour  BackProp Through Time ), les architectures RTRL (pour Real Time Recurrent  Learning ) et les architectures combinées, avec par exemple des modèles de  Markov 1 à états cachés (MMC, ou Hidden Markov Model, HMM  en anglais).  Ces RNR, notamment les LSTM et les MARNN, forment u n chantier de  recherche prioritaire pour les chercheurs de Google  (DeepMind en  particulier), Baidu, Apple, Microsoft et Facebook. Leur utilisation pour la  traduction, la production de légendes pour les imag es et les systèmes de  dialogues vise à répondre à la question de la capac ité à apprendre des tâches  qui impliquent non seulement d’apprendre à se repré senter le monde, mais  aussi à se remémorer, à raisonner, à prédire et à p lanifier. L’apprentissage  par renforcement recourt de plus en plus à ces RNR,  notamment en  combinaison avec des algorithmes génétiques qui per mettent de mieux les  entraîner. Les LSTM peuvent aussi faire l’objet d’a méliorations avec les SVM.  Les réseaux neuronaux à convolution  (RNC) appelés aussi réseaux  de neurones profonds convolutifs ( convolutional deep neural networks  ou  CNN) sont inspirés des processus biologiques du cortex visuel  des  animaux . En effet, les neurones de cette région du cerveau  sont arrangés de  sorte qu’ils correspondent à des régions qui se che vauchent lors du pavage 2  du champ visuel et transforment un problème global à résoudre en une  succession d’étapes plus petites et plus faciles à résoudre : le motif de  connexion entre ces réseaux de neurones artificiels  à convolution repose sur  un procédé similaire. Les réseaux neuronaux sont ic i soumis à un mécanisme  de poids synaptiques partagés, qui offre l’intérêt d’une plus grande capacité  de généralisation pour moins de paramètres. Destiné es en priorité à traiter  les images, et trouvant leurs principales applicati ons en reconnaissance  d’images et de vidéos, leurs applications sont et s eront de plus en plus  diversifiées, du traitement du langage naturel aux systèmes de  recommandation. L’architecture des RNC comprend des  couches de  traitement indépendantes dédiées qui vont apprendre  les prétraitements de                                                    1 En mathématiques, un processus de Markov (la théor ie des probabilités parle plutôt de « processus  de décision markovien ») est une chaîne stochastiqu e possédant la propriété de Markov qui réside  dans le fait que la prédiction du futur à partir du  présent n’est pas rendue plus précise par des  éléments d’information concernant le passé. L’agent  prend dans ce cas des décisions avec un résultat  aléatoire de ses actions. Claude Shannon s’en est i nspiré en 1948 pour fonder sa théorie de  l’information et l’algorithme de classement par pop ularité de Google repose notamment sur un  modèle de ce type. L’apprentissage par renforcement  permet de résoudre le problème des processus  markoviens.  2 « Paver » l’image de départ revient à la découper en petites zones appelées tuiles. En informatique,  chaque tuile est traitée individuellement par un ne urone artificiel, qui effectue une opération de  filtrage classique en associant un poids à chaque p ixel de la tuile. Tous les neurones ont donc les  mêmes paramètres, ce qui permet d’obtenir le même t raitement pour tous les pixels de la tuile. 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 63  -       l’image au lieu de les coder 1, afin d’extraire ses caractéristiques et de les  transmettre à un réseau neuronal plus classique qui  effectue la phase de  reconnaissance finale, comme l’illustre le graphiqu e suivant.    Architecture d’un réseau de neurones à convolution    Source : Jean-Claude Heudin, Comprendre le deep lea rning.    Une autre façon de décrire l’approche par RNC est d e la voir comme  une décomposition hiérarchisée du processus de reconnai ssance , où chaque  couche participe à la création de représentations d e plus en plus abstraites et  conceptuelles.                                                    1 Le fait de coder les pixels est une approche plus traditionnelle de la reconnaissance d’images, dans  laquelle l’ensemble des pixels d’une image (exemple  262 544 entrées pour une images de 512x512  pixels)  est codé et vectorisé en une couche d’entr ée du réseau de neurones. 
- 64  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Visualisation des caractéristiques extraites par ch aque couche d’un  réseau de neurones à convolution    Source : Jean-Claude Heudin, Comprendre le deep lea rning.    En outre, il convient de relever qu’au mois de janv ier 2017, plusieurs  chercheurs travaillant pour le projet de recherche de deep learning  « Google  Brain » ont publié un article 1 présentant les résultats de leurs travaux sur un  nouveau modèle de réseau de neurones multicouches  (appelé « MoE » pour   « Mixture of Experts Layer  »). La capacité d’un réseau neuronal monocouche à  absorber les données massives étant limitée par son  nombre de paramètres  calculables, le modèle « MoE » représente un réseau  neuronal géant,  composé de plusieurs sous-réseaux neuronaux disposé s en couches,  permettant de traiter les quantités massives de don nées dont disposent les  grandes entreprises du secteur. Accumuler les capac ités de plusieurs  systèmes experts à travers des réseaux neuronaux, p ermet de muscler la  mémoire du modèle, réduisant ainsi le temps de form ation du système et  améliorant de manière considérable sa performance e t sa capacité de calcul  conventionnel, avec une architecture de modèle comp renant jusqu’à  137 milliards de paramètres . Si, à ce stade, le modèle « MoE » est appliqué  aux tâches de modélisation des langues et de traduc tion automatique, cette  avancée présentée permet d’entrevoir des progrès ex ponentiels en matière  d’intelligence artificielle, et selon les chercheur s du projet Google Brain le                                                    1 Geoffrey Hinton, Noam Shazeer, Azalia Mirhoseini, K rzysztof Maziarz, Andy Davis, Quoc Le  et Jeff Dean, « Outrageously large neural networks : the sparsely-gated mixture-of-experts  layer »,  janvier 2017, cf.  https://arxiv.org/abs/1701.06538  
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 65  -       possible avènement d’une intelligence artificielle générale composée de  milliers de sous-réseaux et traitant toutes sortes de données. Il s’agit aussi de  réduire le nombre de processeurs (GPU) nécessaires à l’apprentissage et  donc d’accélérer la capacité du système d’intellige nce artificielle à processeur  égal 1.  En mars 2017, la publication d’un autre article 2 de James Kirkpatrick  basé sur l’apprentissage de plusieurs jeux Atari pa r un système d’IA trace la  voie de futurs progrès dans la capacité des réseaux de neurones artificiels à  se souvenir de leurs tâches et de leurs expériences  précédentes  et, donc, à  se doter progressivement des éléments constitutifs d’une mémoire. En avril  2017, en utilisant aussi plusieurs jeux Atari, des chercheurs de  Google-Deep Mind ont conceptualisé l’apprentissage profond par  renforcement 3 qui pourrait être selon eux la méthode d’apprentis sage la  plus rapide , avec l’idée de pouvoir transposer le processus d’ apprentissage  du système d’IA dans l’environnement réel . Les équipes de cette entreprise  sont donc largement mobilisées pour construire des systèmes capables  d’approcher l’apprentissage humain 4.  L’essor de l’intelligence artificielle avec le deep learning  est, par  ailleurs, facilité par  la croissance exponentielle des avancées  technologiques matérielles dans ce secteur , en particulier les vitesses de  calcul des processeurs, appelée aussi « loi de Moor e ».   La « loi de Moore » est une conjecture , et donc en réalité une  supposition, concernant l’évolution de la puissance de calcul de s  ordinateurs  et, plus généralement, la complexité du matériel i nformatique.  En 1965, Gordon Moore, ingénieur chez Fairchild Sem iconductor, un des  trois fondateurs d’Intel, constate que depuis 1959 la complexité des  semi-conducteurs d’entrée de gamme a doublé tous le s ans à coût constant.  Il s’agit donc d’une loi relative au développement exponentiel des  capacités de traitement de l’information en vertu d ’un doublement  constaté pour le même coût, depuis une quarantaine d’année, du nombre  de transistors des microprocesseurs sur une puce de  silicium . L’observation  empirique, ainsi que l’illustre le graphique suivan t, démontre que ce  doublement a en fait lieu tous les dix-huit mois .                                                    1 Cf les explications données à ce sujet par le jeun e chercheur Théo Szymkowiak, président de la  société pour l’IA de l’université Mc Gill : https://medium.com/@thoszymkowiak/google-brains-new super-fast-and-highly-accurate-ai-the-mixture-of-ex perts-layer-dd3972c25663    2 Revue de l’Académie américaine des sciences, PNAS,  volume 114, issue 13, march 2017  « Overcoming catastrophic forgetting in neural networ ks  »,  cf. http://m.pnas.org/content/114/13/3521.abstract    3 Todd Hester, Matej Vecerik, Olivier Pietquin, Marc  Lanctot, Tom Schaul, Bilal Piot, Andrew  Sendonaris, Gabriel Dulac-Arnold, Ian Osband, John Agapiou, Joel Z. Leibo et Audrunas Gruslys  « Learning from demonstrations for Real World Reinfor cement Learning  »,  cf. https://arxiv.org/abs/1704.03732    4 Un article du complément scientifique du Guardian va dans ce sens :  https://www.theguardian.com/global/2017/mar/14/goog les-deepmind-makes-ai-program-that-canlearn-like-a-human   
- 66  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE          La loi de Moore rapportée à l’évolution réelle  du nombre de transistors dans les microprocesseurs    Source  : contributeur « QcRef87 », licence de documentati on libre  Cette conjecture, connue sous le nom de loi de Moor e, est le  fondement sur lequel se reposent certains spécialis tes pour fixer l’avènement  de l’intelligence artificielle forte en 2030. Or, v os rapporteurs rappellent que  la conjecture n’a trait qu’aux capacités de calcul et de stockage de données  informatiques , elle n’est donc pas de nature à garantir ou à permettre une  prévision de la future date de naissance d’une inte lligence artificielle  égale à celle de l’homme, contrairement à ce que ce rtains font valoir .  Ils notent, par ailleurs, que le deep learning  a largement profité des  processeurs graphiques  dédiés (GPU), souvent issus des exigences des  joueurs de jeux vidéo. À la différence des processe urs principaux  traditionnels (CPU) aux fréquences d’horloge élevée s, les GPU possèdent de  nombreux cœurs (unités de calcul), composants parfa itement adaptés aux  traitements parallélisables de données de grande di mension .  L’intelligence artificielle, dont certaines des tec hnologies recourent à  des analyses qui multiplient les matrices et les co nvolutions (cas des RNC et  des RNR), a donc profité, au cours des dernières an nées, de ces processeurs  graphiques plus efficaces. 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 67  -       La loi de Moore devrait, à technologie égale, attei ndre les limites  des capacités des puces en silicium . Il semble en effet difficile d’écrire à  terme sur des surfaces plus petites que la taille d e l’atome . L’avenir de  l’accélération des vitesses des processeurs pourrai t donc dépendre des  innovations futures en informatique quantique  ou, encore, des inventions  en matière de processeurs fondés sur l’optique . La start-up française  LightOn  créée par Igor Carron, co-fondateur du Paris Machine Learning  Meetup , poursuit ses recherches dans ce sens.  À ce stade du rapport, il semble utile de récapitul er par une  chronologie les principales étapes et découvertes e n intelligence artificielle.           
- 68  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Chronologie des principales étapes et découvertes  en intelligence artificielle    330 avant J.-C. : Invention par Euclide de l’algori thme de calcul du plus grand  diviseur commun de deux nombres entiers ;  833 :   Le mathématicien Al-Khawarizmi, dont les tr avaux fondent l’algèbre,  invente des méthodes précises de résolution des équ ations du second degré, qui seront  appelées algorithmes. Son nom latinisé est à l’orig ine du mot « algorithme » ;  1694 :  Leibniz construit la première machine à cal culer ;  1780 :  Invention d’une machine à parler par l’abbé  Mical et Christian Gottlieb  Kratzenstein ;  1834 :  Invention par Charles Babbage du premier « ordinateur », sous la forme  d’une « machine à différences » inspirée des machin es à tisser ;  1847 et 1854 :  Premières mathématisations de la lo gique par Georges Boole ;  1869 :  Création de pianos mécaniques capables de r aisonner par William Stanley  Jevons ;  1936 :  Formulation des fondements théoriques de l’ informatique par Alan Turing  (son appareil sera plus tard appelé « machine de Tu ring ») par l’introduction des  concepts de programme et de programmation ;  1943 :  Premier article sur le potentiel des réseau x de neurones artificiels par  Warren McCulloch et Walter Pitts ;  1950 :  Invention du « test de Turing » en vue d’év aluer l’intelligence d’un  ordinateur par rapport à celle d’un être humain ;  1956 :  Invention, en tant que discipline et en tan t que concept, de l’intelligence  artificielle lors de la conférence de Dartmouth par  John McCarthy et Marvin Minsky ;  1957 : Invention du perceptron, première utilisatio n de réseaux de neurones  artificiels modélisés, par Frank Rosenblatt ;  1958 :  Invention du langage de programmation Lisp ;  1965 :  Formulation par Gordon Moore de la loi qui porte son nom concernant le  doublement de la vitesse de calcul des ordinateurs tous les 18 mois à coût constant ;  1966 :  Invention par Joseph Weizenbaum du premier agent conversationnel  « Eliza » ;  1974 :  Invention du premier système expert, dit « Mycin » ;  1986 :  Invention des perceptrons multicouches par Yann LeCun et David  Rumelhart et de la rétropropagation du gradient par  David Rumelhart, Geoffrey  Hinton  et Ronald Williams ;  1997 :  Victoire du système Deep Blue aux échecs fa ce à Garry Kasparov ;  Années 2000 et 2010 :  Conjugaison efficace des tec hnologies de deep learning  avec  l’émergence des données massives et l’accélération marquée de la vitesse de calcul des  processeurs ; 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 69  -       Années 2010 : Les réseaux neuronaux récurrents (RNR ) et les réseaux neuronaux à  convolutions (RNC), imaginés dès la fin des années 1980, font l’objet d’usages  particulièrement remarqués ;  2011 :  Victoire du système Watson  au jeu télévisé Jeopardy  en 2011 ;  2016 :  Victoire du système AlphaGo  au jeu de Go face au champion Lee Sedol.  2017 :  Victoire du système Libratus  au cours d’une partie de poker de 20 jours face  à quatre joueurs professionnels    Source : OPECST    3.  Les technologies d’intelligence artificielle condui sent, d’ores et  déjà, à des applications dans de nombreux secteurs  Les applications sectorielles présentes ou futures sont d’envergure  considérable, que l’on pense par exemple aux transports, à l’aéronautique, à  l’énergie, à l’environnement, à l’agriculture, au  commerce 1, à la finance, à  la défense , à la sécurité, à la sécurité informatique, à la co mmunication, à  l’éducation, aux loisirs, à la santé, à la dépendan ce ou au handicap .  Souvent, la capacité prédictive de ces technologies  se trouve mobilisée.  Il s’agit d’autant de jalons d’applications sectori elles. Car en réalité,  derrière le concept d’intelligence artificielle, ce  sont des technologies très  variées, en constante évolution, qui donnent lieu à  des applications  spécifiques pour des tâches toujours très spécialis ées .                                                        1 Le « yield management »,  qui consiste à faire varier les prix en vue de l’o ptimisation du  remplissage (transport aérien et ferroviaire ou hôt ellerie) et/ou du chiffre d’affaires, est déjà conn u de  chacun de nous. En 2013, à titre d’exemple, Amazon changeait ses prix en moyenne plus de  2,5 millions de fois par jour. 
- 70  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE          Applications des technologies d’intelligence artifi cielle en France    Source : Gouvernement    Les applications dans le secteur financier, en part iculier les banques  et les assurances , sont nombreuses. La moitié du volume des  transactions  financières et 90 % des ordres résultent de l’activ ité d’algorithmes . Du tiers  des échanges boursiers en Europe en 2010, ce taux a  dépassé les 90 % depuis  2012.  Depuis 2012, IBM détient un brevet l’autorisant à p rocéder à une  estimation de la volatilité des transactions à haut e fréquence.  Le sujet du « high frequency trading »  (HFT) ou trading à haute  fréquence (THF) constitue un questionnement en soi,  sur lequel la  commission des Finances du Sénat a commencé à trava iller 1.                                                        1 Cf. Par exemple son rapport n° 369 (2011-2012) sur  la proposition de résolution sur la régulation  des marchés financiers. Cette proposition, devenue une résolution du Sénat le 21 février 2012, estime  « nécessaire de renforcer l’encadrement des pratiques  mettant en péril l’intégrité des  marchés financiers et notamment les transactions su r base d’algorithmes (trading  algorithmique ou trading haute fréquence)  », cf. https://www.senat.fr/leg/tas11-079.html  
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 71  -       L’intelligence artificielle et les technologies fin ancières (« Fintech  »)  Le renouveau de l’intelligence artificielle est per mis par une accélération spectaculaire  des investissements, notamment de la part des grand s acteurs industriels et du capitalrisque, ainsi que par les progrès conséquents des p erformances d’intelligence artificielle  visibles, notamment, dans le développement de la re connaissance d’images, de la parole et  de la traduction.  Les technologies d’intelligence artificielle sont s ouvent produites à l’extérieur des  entreprises : la compétence primordiale que doivent  acquérir les entreprises est d’intégrer le  flux permanent de ces technologies quand elles n’en  sont pas directement productrices.  Plus précisément, les technologies financières ( Fintech ) permettent par exemple d’utiliser  l’intelligence artificielle pour des applications d ’interaction avec les clients, de tri dans la  proposition de contrats et de détection de fraude d ans le traitement des demandes.  L’intelligence artificielle développée par de nombr euses entreprises émergentes est  tournée vers le client. Ces systèmes d’intelligence  artificielle visent à toucher toutes les  difficultés relationnelles que peuvent avoir les en treprises. Les technologies modernes de  chatbot  sont mises au service du client. Les algorithmes p euvent être connus car souvent en  open source, cependant, c’est le savoir-faire des ingénieurs et des développeurs qui leur  donnent leur complexité.  Source : Intervention de M. Yves Caseau, animateur du groupe de travail sur l’IA de l’Académie des  Technologies, lors de la journée « Entreprises françaises et intelligence artificiel le » organisée par le  MEDEF et l’AFIA le 23 janvier 2017      Source : groupe de travail sur l’IA de l’Académie d es Technologies animé par Yves Caseau 
- 72  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE          Concernant le secteur automobile , le logiciel n’a, pendant  longtemps, représenté qu’une fraction très réduite de la valeur d’un  véhicule, il s’agissait, il y a dix ans, de 3 %, au jourd’hui, il s’agit de 10 % et il  pourrait s’agir de l’ordre de 15 % ou 30 % demain. Tesla annonce qu’il  produira 500 000 voitures autonomes d’ici à 2020.  Les constructeurs français se sont eux aussi engagés dans la voiture  autonome, à l’image de PSA  qui a présenté son prototype « Peugeot  Instinct » au salon de Genève en mars 2017 et qui a  signé de nombreux  partenariats à ce sujet, ainsi que l’a fait son con current Renault , qui  accompagne ce développement industriel d’une démarc he éthique  intéressante sur la protection des données selon un e approche Privacy by  design  (respect de la vie privée dès le stade de la conce ption) et a à cette fin  élaboré un pack de conformité avec la CNIL. L’entre prise a ainsi joué un rôle  moteur dans la charte de constructeurs élaborée au sein de l’association des  constructeurs européens d’automobiles.  On peut relever qu’Uber dispose d’un centre de rech erche à  Pittsburgh, fondé en partenariat avec l’Université Carnegie-Mellon, consacré  aux véhicules sans conducteurs. Quatre prototypes y  sont testés par Uber  depuis septembre 2016. Les quinze employés de Geome tric Intelligence,  racheté par Uber, qui sont des universitaires et de s scientifiques, se trouvent  désormais affectés à ces recherches.   
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 73  -       L’intelligence artificielle, levier de progrès pour  l’industrie automobile   L’industrie automobile est mobilisée pour réussir t rois révolutions, chacune  d’elles suffisant pour la transformer en profondeur  : la voiture électrique (ce qui  impliquera des réseaux électriques intelligents ou smart grids ),  la voiture connectée   (l’intelligence artificielle permet ici de gérer et  d’exploiter les données, ou de mettre à  disposition des consommateurs des assistants virtue ls) et la voiture autonome . Ces trois  révolutions sont concomitantes et doivent être géré es par l’industrie. Elles nécessitent que  l’industrie automobile maîtrise des technologies qu i ne la concernaient pas jusqu’il y a peu.  Pour être davantage autonome, la voiture développe son intelligence. L’aide à la conduite  et l’autonomisation de la conduite d’un véhicule su ivent trois étapes :   • Percevoir l’environnement grâce à des systèmes de  caméra, de radar et de  technologies à ultra-sons.  • Analyser et décider, le véhicule étant doté d’un calculateur et du traitement de  l’image et du son. L’objectif est de fusionner l’im age et le son captés par le radar et de  permettre au système de réagir à une situation de m anière adéquate.  • Prévenir et/ou agir dans l’utilisation de la dire ction, des freins et du moteur,  cette utilisation étant couplée avec une interactio n homme-machine.   Ces étapes sont celles qui guident la conduite huma ine.  Percevoir l’environnement est complexe et dépend de  la photographie renvoyée  par ce que perçoit une caméra automobile. Il faut a ssurer un équilibre entre la performance  du système et la robustesse de ce système. D’un poi nt de vue de l’analyse d’image, la  perception est complexe pour un système autonome.  Il existe une véritable rupture entre une aide à la  conduite dans laquelle le  conducteur reste maître et une voiture autonome où la conduite est déléguée. Cette rupture  technologique implique la fabrication de très nombr eux scénarios. L’intelligence artificielle  permet de gérer des scénarios très diversifiés et d ’entrer dans une phase d’apprentissage.  L’intelligence artificielle contribuera à la transf ormation de l’industrie  automobile. L’ensemble des constructeurs investisse nt dans l’intelligence artificielle, soit en  créant leurs propres laboratoires de recherche, soi t en établissant des contrats avec des  laboratoires existants. L’intégration de l’intellig ence artificielle dans l’industrie automobile  impliquera un changement des modèles d’affaires des  entreprises du secteur. Le caractère  crucial de l’intelligence artificielle pour le sect eur automobile réside dans le fait que sa  maîtrise permettra de développer des applications d ’un bout à l’autre de la chaîne de  production , de la conception des logiciels et des véhicules j usqu’au service après-vente. La  maîtrise de l’intelligence artificielle représente donc un enjeu essentiel pour les  constructeurs automobiles.  Source : intervention de Patrick Bastard, directeur  de l’ingénierie et des technologies électroniques chez  Renault, lors de la journée « Entreprises françaises et intelligence artificiel le » organisée par le MEDEF et  l’AFIA le 23 janvier 2017    En lien avec l’intelligence artificielle, la roboti que va connaître un  essor inédit. Selon certaines prévisions récentes, le marché de la robotique  devrait ainsi atteindre 35 millions de robots vendus d’ici à 2018 1, sachant  qu’environ 1,5 million sont aujourd’hui en fonction nement. Le syndicat de la  robotique (SYROBO) établit des prévisions du même o rdre, puisqu’il estime                                                    1 Cf. www.worldrobotics.org/uploads/tx_zeifr/Executive_Su mmary__WR_2015.pdf   
- 74  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        que 31 millions de robots - industriels et personne ls - pourraient être vendus  dans le monde entre 2014 et 2017. La croissance mon diale de ce marché serait  d’environ 10 % par an en moyenne sur dix ans à part ir de 2016, selon le  Boston Consulting Group (BCG), au lieu de 2 % par a n jusqu’en 2014. La  seule robotique de service  représente à elle seule un énorme gisement de  croissance : le marché est estimé à environ 100 mil liards d’euros à l’horizon  2020 par la Commission européenne, soit une multipl ication par 30 en dix  ans. La  France  se place au troisième rang mondial  dans la recherche  fondamentale en robotique  derrière les États-Unis et le Japon, ce qui  témoigne d’un avantage comparatif à consolider. Nao, Pepper ou Romeo  ont  été conçus par Aldebaran, entreprise française basé e à Issy-les-Moulineaux,  rachetée en 2012 par SoftBank Robotics, leader mond ial de la robotique  humanoïde. Buddy  est un autre robot de service créé par l’entrepris e  française Bluefrog et dont la commercialisation en 2017 a été annoncée  l’année dernière pour moins de 1 000 euros. La soci été française Robosoft a  annoncé en 2016 le lancement de la seconde version de son robot Kompaï ,  conçu pour assister les personnes âgées au quotidie n. D’autres robots  existent sur le marché mondial et peuvent être ment ionnés comme Paro,  Jibo, Asimo, Amazon Echo, Otto, Floka …  Les capacités des agents conversationnels  dits chatbots  ou même bots   sont, il est vrai, encore limitées mais ces dernier s vont rendre de plus en  plus de services à leurs utilisateurs . Le cabinet d’études Forrester estime,  d’ailleurs, que les bots  ne sont pas encore à la hauteur des attentes des  usagers. Laurence Devillers explique ainsi qu’ils n ’ont pas de mémoire,  qu’ils se contentent de suivre des scénarios de que stions-réponses et qu’ils ne  savent pas répondre aux utilisateurs qui se plaigne nt de dépression ou de  maladies physiques. Vos rapporteurs ont constaté qu ’en dépit de leur  absence de mémoire, les bots font déjà un excellent travail en matière de  prévention du suicide  en réagissant à certains mots clés, ainsi que l’a  expliqué et démontré in vivo à vos rapporteurs Alex Acero, directeur du  projet Siri chez Apple. Siri reçoit par exemple 5 0 00 propos suicidaires par  jour qu’il traite en rassurant le propriétaire du t éléphone et en orientant vers  des services spécialisés. Cortana de Microsoft gère  ce type de conversations  avec la même efficacité. Ces exemples sont un premi er niveau de gestion de  la dépression ne nécessitant pas de mémoire dans le s systèmes d’IA.  Vos rapporteurs ont pu tester en situation ces usages bénéfiques  pour la société des agents conversationnels . Il ne s’agit que d’un exemple,  leur utilité sera bien plus diverse en pratique, su rtout quand les machines  amélioreront leurs capacités en termes de mémoire. Au salon professionnel  E-commerce One To One  2017 1, Google a invité à s’extraire du modèle du  moteur de recherche tel que nous le connaissons enc ore aujourd’hui pour                                                    1 Cf.  https://www.ecommerce1to1.com/   
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 75  -       entrer dans l’ère de l’assistance, « The age of assistance » était ainsi le nom de  sa présentation 1.  En matière d’ éducation , les perspectives pour l’intelligence  artificielle sont riches mais les applications rest ent encore rares. Ce point est  développé plus loin dans le rapport.  Dans le secteur des loisirs , tels que les jeux vidéos ou le cinéma,  l’intelligence artificielle est utilisée assez mass ivement. Il peut par exemple  s’agir de simuler des foules grâce à des systèmes m ulti-agents, comme dans  les trilogies Le Seigneur des anneaux  et Le Hobbit . Les jeux sérieux 2, ou s erious  games en anglais, tout commes les visites virtuelles 3 pourront de plus en plus  mobiliser des technologies d’IA.  Les secteurs de l’énergie  et de l’environnement  commencent à  recourir à des solutions fondées sur l’intelligence  artificielle. Les compteurs  intelligents  sont une des pistes visibles de cette évolution en  cours, sur  laquelle travaille l’OPECST. L’IA permet de modélis er et de simuler et est  donc utilisée en météorologie, sismologie, océanogr aphie, planétologie ou,  encore en urbanisme. Le GIEC a recours à ces techno logies pour analyser les  changements climatiques.  L’agriculture peut aussi être citée , car ce secteur présente des  usages divers et des possibilités nombreuses. Les a pplications concernent la  gestion des exploitations mais vont bien au-delà. L e graphique suivant décrit  ainsi les cycles de traitement des données dans l’a griculture. À chaque étape,  l’intelligence artificielle peut jouer un rôle de p lus en plus grand.                                                      1 Cette économie de l’assistance repose sur trois dé terminants principaux : la personnalisation de la  relation avec le mobinaute (plus encore que l’inter naute), le web sémantique (la question donne lieu  à une réponse directement, voire la machine anticip e vos questions) et, enfin, le web vocal (20 % des  requêtes formulées aujourd’hui sur Google via un mo bile Android sont vocales et ce chiffre devrait  dépasser les 50% en 2020). Cf. http://www.frenchweb.fr/google-annonce-la-mort-du-m oteur-derecherche-et-lavenement-de-lage-de-lassistance/2860 43    2 Pour Julian Alvarez et Olivier Rampnoux, cinq type s de jeux sérieux peuvent être distingués : les  advergamings  (jeux publicitaires), les edutainments  (à vocation éducative), les edumarket  games  (utilisés pour la communication d’entreprise), les  jeux engagés (ou détournés) et les jeux  d’entraînement et de simulation.  3 Outre l’accès à la culture (visites de musées et d e sites archéologiques par exemple), il pourrait  s’agir de visites interactives dans des environneme nts historiques différents, permettant des sortes d e  voyages dans le temps. 
- 76  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Les processus de traitement des données dans l’agri culture    Source : INRA    De manière opérationnelle, de nombreuses applications sont  possibles dans le secteur agricole , pour l’exploitant (dans le suivi ou la  régulation), la filière agricole concernée (en mati ère de progrès génétiques  par exemple) mais aussi l’ensemble de la société (a vec le cas des réseaux  d’épidémio-surveillance). Le graphique suivant l’il lustre.    Exemples d’utilisations des données dans l’agricult ure    Source : INRA   
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 77  -       Il peut être donné l’exemple d’une entreprise qui a  ainsi mis au  point un système de conteneurs agricoles intelligen ts, en partenariat avec le  MIT Media Lab . À l’intérieur, l’intelligence artificielle contrô le la lumière,  l’humidité, la température, mais aussi les nutrimen ts apportés aux plantes,  supervisant leur croissance en temps réel. La techn ologie permet ici  d’améliorer l’efficacité du cycle de production, et  ce sans avoir recours aux  OGM.  Dans le secteur de la défense , les drones autonomes sont de plus en  plus utilisés, à l’image de l’expérience des armées  australiennes, israéliennes  ou, encore, saoudiennes. Ce n’est pas le secteur où  le développement de  l’intelligence artificielle est le plus souhaitable .  La sécurité  est, d’ores et déjà, améliorée avec une intelligen ce  artificielle qui peut détecter les situations anorm ales (par exemple sur les  flux vidéo des caméras de surveillance) et alerter les services compétents.  En matière de  sécurité numérique , ce sont les fraudes et les  cyberattaques qui peuvent être prévues et gérées de  manière plus efficace.  La  cybersécurité  peut être révolutionnée par l’intelligence artific ielle. La  DARPA a ainsi consacré son grand concours 2016 à ce  sujet.  Dans l’ assistance au diagnostic  ou dans les services de maintenance  prédictive  dans l’industrie et l’électroménager, l’intelligen ce artificielle  optimise et détecte les défaillances en amont, de m ême qu’elle prévoit les  étapes de réparation.   Les usages de l’intelligence artificielle en matièr e de  technologies  médicales , de gestion de la  dépendance ou de  handicap seront  considérables mais ils  n’ont pas été  au cœur du travail de vos rapporteurs, le  sujet a déjà  été traité à plusieurs reprises par l’OPECST et con tinuera à l’être,  autour de rapports spécifiques. Le dernier exemple remonte à 2015 avec un  rapport consacré au thème « Le numérique au service de la santé »1. Il est certain  que l’intelligence artificielle est et sera de plus  en plus utile à la médecine,  notamment et y compris à court terme en matière de diagnostic et de  dépistage des maladies. Les systèmes recourant à l’ IA font de plus en plus  souvent aussi bien, voire mieux, que les médecins d ans le dépistage du  cancer 2.   Quelques cas emblématiques peuvent être mentionnés.  En  génomique , par exemple pour la validation et la critique des  thérapies, outre  le deep learning , peuvent être utilisés des systèmes non logiques o u  partiellement logiques, des réseaux bayésiens, des systèmes de règles et  d’arbres de décision, des systèmes experts… En mati ère de prédiction du                                                    1 • Le numérique au service de la santé , Catherine Procaccia et Gérard Bapt, rapporteurs, Sénat  n° 465 (2014-2015).   2 Un exemple récent concerne le dépistage du cancer du sein :  http://www.numerama.com/sciences/176579-une-ia-sait -detecter-le-cancer-du-sein-presque-aussibien-quun-medecin.html 
- 78  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        repliage de protéines 1 ou de segmentation des IRM du cerveau  en vue  d’identifier certaines zones, des projets de recher che sont menés avec  l’utilisation de l’apprentissage automatique ( machine learning ) et de systèmes  multi-agents collaboratifs pour découvrir les règle s qui régulent la géométrie  spatiale de structures complexes (exemple d’un proj et associant l’Université  de Grenoble, Inria et l’INSERM). L’utilisation de s ystèmes multi-agents est  également possible pour analyser les courbes de rép onse d’assistants  respiratoires et détecter les anomalies.  Le Dr Lionel Jouffe, président de Bayesia, s’est sp écialisé dans  l’utilisation des  réseaux bayésiens pour l’aide à la décision médicale . Il  s’agit d’une modélisation des connaissances par app rentissage automatique  à partir des données. Le réseau bayésien peut être utilisé pour des  applications de différentes natures. Il faut rappel ler qu’un réseau bayésien  peut ainsi permettre à une entreprise de calculer l a probabilité qu’un client  soit intéressé par un produit, à une banque ou un business angel de calculer la  probabilité de faillite d’une start-up, tout comme il peut être appliqué à la  thérapie endovasculaire. Ainsi, les applications di verses d’un réseau  bayésien lui permettent d’être utilisé pour de nomb reuses tâches, comme  l’analyse de leviers d’optimisation, le calcul de s cores, l’analyse de défauts  par l’optimisation de processus, l’analyse opératio nnelle, le diagnostic et le  dépannage ou encore l’analyse de risques et la main tenance préventive.  L’exemple de Watson est également instructif, pour le secteur  médical et l’aide au diagnostic mais même au-delà. Dévoilé au grand public  par IBM en 2011, ce système a affronté, avec succès , des candidats humains  au jeu télévisé américain « Jeopardy ! ». En 1996 e t 1997, IBM avait déjà  prouvé les capacités de son superordinateur Deep Bl ue en organisant des  parties d’échecs contre Garry Kasparov. Nicolas Sek kaki, responsable d’IBM  France, assure que sa société est aujourd’hui engag ée dans une dizaine de  projets faisant appel à Watson sur notre territoire , mais les retours  d’expérience dignes de ce nom sur le sujet restent encore peu nombreux. Le  Crédit Mutuel teste avec IBM l’utilisation de l’int elligence artificielle et des  technologies cognitives depuis juin 2015 et a intég ré certaines technologies  dans la gestion de sa relation client  depuis 2016. Watson est ainsi utilisé  pour l’assistance des conseillers dans le traitemen t des courriels d’une part,  et sur les produits d’assurance et d’épargne d’autr e part. Une assistance  informatisée qui vise à optimiser la productivité d u conseiller et améliorer la  pertinence des réponses fournies aux clients finaux . Pour l’instant, il ne  s’agirait pas de laisser l’intelligence artificiell e interagir directement avec le  client.   Les progrès dans les domaines de l’intelligence art ificielle et de la  robotique, en matière de vision par ordinateur , de traitement automatique                                                    1 Ce processus physique, par lequel un polypeptide s e replie dans sa structure tridimensionnelle  caractéristique dans laquelle il est fonctionnel, e st important en ce que de nombreuses maladies, en  particulioer les maladies « neurodégénératives », s ont considérées comme résultant d'une  accumulation de protéines « mal repliées ». 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 79  -       du langage naturel , de reconnaissance automatique de la parole , ou, encore  de bioinformatique , à travers par exemple l’étude de l’ADN, ouvrent e ncore  toute une série de perspectives d’ applications fécondes .  Vos rapporteurs relèvent une  part d’effet de mode dans  l’écosystème entrepreneurial , visible dans le recours à certains concepts, tels   que l’intelligence artificielle, le big data , le cloud , l’IoT  (Internet des objets), le  blockchain . Pour le journaliste Olivier Ezratty, le stéréotyp e de la start-up en  intelligence artificielle serait, de manière carica turale, une « solution d’agent  conversationnel en cloud  faisant du big data sur des données issues de l’ IoT  en  sécurisant les transactions  via des blockchains  ».  Les entreprises de l’intelligence artificielle se d iversifient, se  reconfigurent et s’absorbent les unes les autres, d isparaissent parfois et  d’autres entreprises, issues d’autres secteurs, par fois plus traditionnels,  tentent de les rejoindre dans une course propre à l’économie des  plateformes , que vos rapporteurs décriront plus loin.  4.  Par leurs combinaisons en évolution constante, ces technologies  offrent un immense potentiel et ouvrent un espace  d’opportunités transversal inédit  Le potentiel de ces technologies est immense  et ouvre de manière  transversale un espace d’opportunités inédit  : nos économies peuvent en  bénéficier car les champs d’application sont et ser ont de plus en plus  nombreux. Ces technologies sont non seulement en év olution constante, mais  leurs combinaisons ouvrent de nouvelles perspectives .  Avec l’explosion des données massives ou big data  et  l’augmentation des vitesses de calcul  (vue plus haut avec la loi de Moore),  ces techniques d’intelligence artificielle devienne nt de plus en plus  puissantes et efficaces , grâce aux combinaisons de compétences et de  technologies en particulier.  Les combinaisons et les hybridations  entre technologies mises au  point par Google Deep Mind vont dans ce sens, en ut ilisant tant des outils  traditionnels comme la méthode Monte-Carlo que des systèmes plus récents  comme l’apprentissage profond. L’entreprise fait fi gure de structure à  l’avant-garde de la recherche mondiale en intellige nce artificielle. Les  combinaisons de technologies d’intelligence artific ielle ouvrent un champ de  recherche fécond et elle en a fait sa spécialité. L e programme AlphaGo a  ainsi appris à jouer au jeu de Go par une méthode de deep learning  couplée à  un apprentissage par renforcement et à une optimisation selon la  méthode  Monte-Carlo . 
- 80  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Dans les faits , et comme l’illustrent les cas déjà évoqués de Pro log 1,  des réseaux de neurones profonds 2 ou du programme AlphaGo 3,  l’intelligence artificielle combine très souvent pl usieurs techniques .   De plus en plus, les outils d’intelligence artificielle sont  systématiquement utilisés conjointement .  Par exemple, les systèmes experts  sont utilisés avec le raisonnement  par analogie , éventuellement dans le cadre de systèmes multi-agents .  De même, les SVM  et l’apprentissage par renforcement  se  combinent très efficacement avec l’apprentissage profond des réseaux de  neurones 4. Ce dernier, le deep learning , peut aussi s’enrichir de logiques  floues ou d’algorithmes génétiques et trouve de nom breuses applications  dans le domaine de la reconnaissance de formes (lec ture de caractères,  reconnaissance de signatures, de visages, vérificat ion de billets de banque),  du contrôle de processus et de prédiction.  Selon Stéphane Mallat, professeur à l’École normale  supérieure, le  deep learning  représente en tout cas  « une rupture non seulement technologique,  mais aussi scientifique  : c’est un changement de paradigme pour la science  ».  Traditionnellement, les modèles sont construits par  les chercheurs euxmêmes à partir de données d’observation, en n’utili sant guère plus de dix  variables alors que « les algorithmes d’apprentissage sélectionnent seuls  le modèle  optimal pour décrire un phénomène à partir d’une ma sse de données » et avec une  complexité inatteignable pour nos cerveaux humains,  puisque cela peut  représenter jusqu’à plusieurs millions de variables . Alors que le principe de  base de la méthode scientifique réside dans le fait  que les modèles ou les  théories sont classiquement construits par les cher cheurs à partir des  observations, le deep learning  change la donne en assistant l’expertise  scientifique dans la construction des modèles. Stép hane Mallat  remarque  également que la physique fondamentale et la médeci ne (vision, audition)  voient converger leurs modèles algorithmiques.  Denis Girou, directeur de l’Institut du développeme nt et des  ressources en informatique scientifique au CNRS, es time que « la science a pu  construire des modèles de plus en plus complexes gr âce à l’augmentation de la  puissance de calcul des outils informatiques, au po int que la simulation numérique  est désormais considérée comme le troisième pilier de la science après la théorie et  l’expérience  ». En sciences du climat par exemple, l’approche t raditionnelle  qui consiste à injecter les mesures issues de capte urs, en tant que conditions  initiales des simulations, s’est enrichie : les app roches big data  avec le machine                                                    1 Les raisonnements formels de Prolog ont été enrich is de la méthode de programmation par  contraintes.  2 Les réseaux de neurones artificiels sont dans ce c as couplés aux méthodes d’apprentissage profond.   3 Ce programme a appris à jouer au jeu de Go en comb inant apprentissage profond et apprentissage  par renforcement.  4 L’efficacité est avérée pour le traitement automat ique du langage naturel, la reconnaissance  automatique de la parole, la reconnaissance audio, la bio-informatique ou, encore, la vision par  ordinateur. 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 81  -       learning  et l’analyse statistique des données ouvrent ainsi  une nouvelle voie  :  « ce qu’on appelle « climate analytics »  a permis aux climatologues de découvrir,  grâce au travail de statisticiens, de nouvelles inf ormations dans leurs données  ». Il  s’agit d’outils sur lesquels s’appuie notamment le Groupe d’experts  intergouvernemental sur l’évolution du climat (GIEC ) dans ses prédictions  sur le réchauffement climatique.  Vos rapporteurs appellent à la vigilance à l’égard de l’illusion du  « jamais vu  », il faut en effet relativiser la nouveauté de l’ aide apportée par  l’intelligence artificielle, la découverte d’autres  outils complexes ayant  jalonné l’histoire des civilisations humaines. Dans  un texte intitulé  « L’ordinateur et l’intelligence »1, l’économiste Michel Volle rappelle ainsi que  « des machines remplacent nos jambes (bateau, bicycle tte, automobile, avion), des  prothèses assistent nos sens (lunettes, appareils a coustiques, téléphones, télévision).  L’élevage et l’agriculture pratiquent la manipulati on génétique, depuis le  néolithique, par la sélection des espèces. La bioni que, l’intelligence artificielle ne font  que s’ajouter aujourd’hui au catalogue des prothèse s qui assistent nos activités  physiques ou mentales  ».   Toutefois, quand bien même l’illusion du jamais vu doit être  dénoncée , il convient d’ éviter aussi l’écueil du toujours ainsi . L’intelligence  artificielle représente une série d’outils à l’auto nomie croissante, qui offre de  nouvelles opportunités et qui pose de nombreuses qu estions. La  complémentarité homme-machine est l’une de celles-c i, avec les potentialités  d’amplification de l’action et d’amélioration de l’ efficacité offertes par  l’intelligence artificielle.  5.  L’apprentissage automatique reste encore largement supervisé  et fait face au défi de l’apprentissage non supervi sé  Selon Yann LeCun, le défi scientifique auquel les c hercheurs  doivent s’atteler , au-delà de la redécouverte de ces deux techniques , c’est  celui  de l’apprentissage non supervisé  alors que l’apprentissage machine  reste le plus souvent supervisé : on apprend aux or dinateurs à reconnaître  l’image d’une voiture en leur faisant absorber des milliers d’images et en les  corrigeant quand ils font des erreurs d’interprétat ion. Or les humains  découvrent le monde de façon non supervisée. Un enf ant reconnaît ses  proches très vite et distingue rapidement un lion d ’un chat, sans  apprentissage supervisé etc.  Dans sa leçon inaugurale au Collège de France, Yann  LeCun estime  ainsi que « tant que le problème de l’apprentissage non supervi sé ne sera pas résolu,  nous n’aurons pas de machines vraiment intelligente s. C’est une question  fondamentale scientifique et mathématique, pas une question de technologie.  Résoudre ce problème pourra prendre de nombreuses a nnées ou plusieurs décennies.  À la vérité, nous n’en savons rien ». Selon lui, cette technologie, qui peut                                                    1 Cf. http://www.volle.com/ulb/021116/textes/intelligence .htm   
- 82  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        prendre la forme de l’apprentissage prédictif, devr ait permettre aux  machines d’acquérir ce que l’on appelle le sens com mun.  L’apprentissage non supervisé permettra de faire progresser les  algorithmes sans le coût lié à l’étiquetage et à la  supervision humaine de  l’apprentissage . C’est à l’évidence un défi scientifique , mais vos  rapporteurs notent qu’il n’est pas sûr que l’on y p arvienne et que les moyens  mis en œuvre doivent rester proportionnés, surtout qu’il n’est absolument  pas certain que l’on ainsi puisse parvenir à l’appr entissage non supervisé.  Ils relèvent que les travaux en robotique développementale et  sociale  de Pierre-Yves Oudeyer, responsable de l’équipe Fl owers d’Inria,  sont particulièrement féconds : il s’agit, en faisa nt appel à de nouvelles  disciplines connexes (neurosciences et psychologie développementale), de  concevoir des algorithmes et des robots capables d’ apprendre des choses  nouvelles sur le long terme sans l’intervention d’u n ingénieur, en combinant  curiosité artificielle et interactions sociales ave c des humains, selon la  maxime « humaniser les machines plutôt que machiniser les ho mmes » et en visant  à reproduire les comportements d’apprentissage des enfants. Vos  rapporteurs ont noté l’influence des travaux de Jean Piaget  dans ces  recherches.  En conclusion de cette partie, vos rapporteurs pren nent acte des  limites des technologies actuelles d’intelligence a rtificielle  et font valoir  que l’intelligence artificielle, qui agit sur la ba se de ce qu’elle sait, devra  relever le défi d’agir sans savoir, puisque comme l ’affirmait le biologiste,  psychologue et épistémologue Jean Piaget « L’intelligence, ça n’est pas ce que  l’on sait, mais ce que l’on fait quand on ne sait p as  ».    III.  CARACTÉRISTIQUES GÉNÉRALES DE LA RECHERCHE EN  INTELLIGENCE ARTIFICIELLE ET ORGANISATION NATIONALE   EN LA MATIÈRE  A.  LES CARACTÉRISTIQUES DE LA RECHERCHE EN INTELLIGENC E  ARTIFICIELLE  1.  La place prépondérante de la recherche privée, domi née par les  entreprises américaines et, potentiellement, chinoi ses   La place prépondérante de la recherche privée a été  particulièrement ressentie par vos rapporteurs, y c ompris sur le plan de la  recherche fondamentale . Cette recherche est, de plus, dominée par les  entreprises américaines et pourrait, potentiellement, être dominée demain  par les entreprises chinoises .  Ainsi plusieurs enseignants-chercheurs, souvent les  plus brillants,  ont été recrutés par ces grandes entreprises, comme  en témoigne la liste  suivante qui n’est pas exhaustive : Yann LeCun (Facebook), Andrew Ng 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 83  -       (Baidu, ex-Google), Geoffrey Hinton et Fei Fei Li (Google), Vladimir  Vapnik  et Rob Fergus (Facebook), Nando de Freitas (Google), Zoubin  Ghahramani  (Uber), même Yoshua Bengio,  qui a longtemps refusé de  travailler dans le secteur privé, a créé la platefo rme « Element AI » avec un  investissement de Microsoft et a rejoint Intel à la  fin de l’année 2016 au  Conseil d’administration de Intel Nervana AI.  En 2010, Demis Hassabis  a inventé, avec Mustafa Suleyman et  Shane Legg, une start-up londonienne qui se donnait  pour objectif de faire ce  qui se fait de mieux en intelligence artificielle, de « résoudre l’intelligence ».  Il a rapidement vu sa structure, Deepmind, être rac hetée pour 628 millions  de dollars par Google (en 2014).  Vos rapporteurs ont identifié plusieurs cas de cher cheurs français  recrutés par ces entreprises américaines, dites « G AFA » ou « GAFAMI »,  même s’il serait plus juste de parler des « GAFAMIT IS »1, ou par leurs  équivalentes chinoises dites « BATX »2. Il est à noter que certains de ces  chercheurs ont refusé de rencontrer vos rapporteurs .  Laurent Massoulié, directeur du Centre de recherche  commun InriaMicrosoft explique que « les frontières public/privé sont de plus en plus  perméables  ». L’enjeu affiché est de réunir le meilleur des d eux mondes et de  favoriser la mobilité des chercheurs, mais il faut observer que ce phénomène  concourt aussi à la concentration des compétences a u sein des entreprises  privées américaines.   Comme il a été vu, les technologies d’apprentissage  machine tel que  le deep learning  recourent à des méthodes plus ou moins statistique s qui  nécessitent des données massives pour être efficace s, or ces entreprises  disposent d’un avantage comparatif difficile à ratt raper : des jeux de données  massives, continuellement enrichis par leurs client s et usagers.  Les entreprises américaines font de plus en plus de  recherche  fondamentale en intelligence artificielle, ouvrent une partie de leurs résultats  et communiquent sur leurs travaux et leur fonctionn ement. C’est en  particulier visible pour Google, Facebook, IBM ou m ême pour le chinois  Baidu. Apple, longtemps discrète, a décidé, en 2016 , d’offrir à ses chercheurs  la possibilité de publier dans des revues scientifi ques 3. Six chercheurs de  l’entreprise ont ainsi publié un article sur l’appr entissage machine à partir  d’images de synthèse.                                                    1 Google, Apple, Facebook, Amazon, Microsoft, IBM, Tw itter, Intel et Salesforce. Ces entreprises  américaines représentent la pointe de la recherche et des applications de l’IA .  2 L’expression désigne les géants chinois du numériqu e : Baidu, Alibaba, Tencent et Xiaomi.  3 Cette évolution doit beaucoup à Russ Salakhutdinov , directeur de l’intelligence artificielle chez  Apple et professeur à l’Université Carnegie-Mellon,  rencontré par vos rapporteurs. Cette  communication de plus en plus scientifique d’Apple est visible aussi dans cet article qui met  notamment à l’honneur Alex Acero, directeur du proj et Siri, également rencontré par vos  rapporteurs : https://backchannel.com/an-exclusive-look-at-how-ai -and-machine-learning-work-atapple-8dbfb131932b#.6oxrqyd5g   
- 84  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        De plus, certains outils d’intelligence artificielle  des entreprises  IBM, Microsoft, Google et Facebook ont été rendus publics en « open  source »  en vue d’encourager la constitution de communautés  de  développeurs.  Ces entreprises entretiennent ainsi un formidable v ivier d’experts et  de chercheurs, aux États-Unis mais aussi dans le re ste du monde, qui leur  permet de perfectionner leurs algorithmes à moindre  coût.  Les entreprises américaines dominent donc pour l’he ure, et certains  parlent de « silicolonisation » du monde ou de l’Eu rope, mais les entreprises  chinoises , qui se sont longtemps contentées d’exploiter et d e répliquer des  technologies élaborées à l’extérieur de leurs front ières peuvent  potentiellement monter en puissance. La recherche c hinoise indique  d’ailleurs cette tendance. La Chine a ainsi pris la  tête des publications en deep  learning  depuis trois ans.  Même si les progrès visibles reposent encore sur des archit ectures  conçues initialement par des scientifiques occident aux , les atouts chinois  sont réels, comme l’a indiqué à vos rapporteurs le service scientifique de  l’Ambassade de France en Chine : elle dispose en ef fet « des deux  supercalculateurs les plus puissants du monde, d’un  marché intérieur très  important et friand des avancées potentielles du se cteur, d’une collusion féconde  entre État, instituts de recherche, universités, gé ants de l’Internet et de  l’informatique, start-up  ». Ainsi, le 13 e plan quinquennal chinois comprend  une liste de 15 « nouveaux grands projets – innovat ion 2030 » qui structurent  les priorités scientifiques du pays et corresponden t chacun à des  investissements de plusieurs milliards d’euros. Par mi ces 15 projets, on en  trouve quatre qui sont consacrés indirectement à l’ IA, pour un montant de  100 milliards de yuans en trois ans  : un projet de « Recherche sur le  cerveau » et des projets d’ingénierie intitulés « M ega données », « Réseaux  intelligents » et « Fabrication intelligente et rob otique ».  Ce plan a été décidé par les autorités chinoises dans le bu t de  dynamiser la recherche en IA en Chine et de relever  le défi de la  concurrence avec les États-Unis . Les investissements seront orientés sur la  robotique, les assistants personnels (domotique), l es voitures autonomes et  les objets connectés.   Les enjeux sont nationaux et les financements suive nt. Mais les  entreprises privées sont aussi des moteurs puissant s du secteur .  On voit dans la période récente les entreprises chinoises monter en  puissance, avec les « BATX »1.   L’entreprise Baidu  a développé le principal moteur de recherche  chinois , site le plus consulté en Chine et 5e site le plus consulté au niveau  mondial , indexant près d’un milliard de pages, 100 million s d’images et  10 millions de fichiers multimédia. Elle communique  beaucoup sur le sujet                                                    1 Baidu, Alibaba, Tencent et Xiaomi . 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 85  -       de l’IA, y consacre une part conséquente de sa rech erche ( Institute of deep  learning , big data lab , …) et, comme les géants américains, dispose d’un flux  de données permettant d’envisager des applications dans de nombreux  domaines.  Le recrutement du chercheur de Stanford Andrew Ng par Baidu en  2014 en tant que responsable de l’intelligence arti ficielle, alors qu’il en  était le responsable chez Google,  est emblématique.  De même, en 2017, Baidu débauche Qi Lu , au poste de numéro  deux, alors qu’il était auparavant vice-président chez Microsoft  et directeur  des projets Bing, Skype et Microsoft Office et, aup aravant, directeur de la  recherche de Yahoo.  L’entreprise considère, comme ses concurrents, que l’IA est son  principal défi  comme solution clé pour des applications en vision , parole,  traitement du langage naturel et sa compréhension, génération de  prédictions et de recommandations, publicité ciblée , planification et prise de  décision en robotique, en conduite autonome, pilota ge de drones,… Elle  travaille en étroite relation avec de nombreuses un iversités et start-up.  Les résultats algorithmiques de Baidu et de son Institu te of Deep  Learning sont impressionnants et du meilleur niveau  mondial , malgré son  existence récente. Il n’est pas évident, selon le s ervice scientifique de  l’Ambassade de France en Chine, d’évaluer la maîtri se théorique des  ingénieurs mais l’entreprise montre une incontestab le efficacité pour  implémenter rapidement les dernières innovations du  secteur.   Le système de reconnaissance d’image de Baidu a ainsi battu celui  de Google depuis 2015 . Son logiciel a décrit 100 000 images avec une  précision de 95,42 % contre 95,20 % pour celui de G oogle. Baidu représente à  lui seul plus de 80 % du marché chinois de la reche rche en ligne (contre 9 %  pour Google). La capacité de ses algorithmes à retr ouver une image dans une  base de données de 10 milliards d’images est de moi ns d’une seconde. Ils ont  aussi de bonnes performances sur les benchmarks  ICDAR, où ils se placent 1er   sur cinq des huit évaluations conduites parmi quatr e tâches.  Sur FDDB 1 (Face Detection Data Set and Benchmark ) et sur la base de  données de visages LFW, ce système progresse vite :  8 % d’erreurs en  décembre 2015, 2,3 % en septembre 2016 et bientôt 1  %. L’entreprise annonce  aussi la meilleure précision sur la collection de benchmarks KITTI 2 orientés  pour la conduite de voitures autonomes. Baidu dével oppe aussi des  applications de reconnaissance d’image pour la plat eforme de services Baidu  Nuomi  : une application permet par exemple de reconnaîtr e le restaurant (et  le plat) en prenant une photo de nourriture dans un  restaurant.   Les autres géants chinois du net, comme Alibaba  (distribution) ou  Tencent  (réseaux sociaux), tirent eux aussi dans la même d irection :                                                    1 Voir http://vis-www.cs.umass.edu/fddb/   2 Voir http://www.cvlibs.net/datasets/kitti/  
- 86  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        développement et diffusion grand public d’applicati ons plus ou moins  convaincantes mais manifestement exploitant des tec hniques d’IA un peu  évoluées, même s’ils semblent moins présents dans l a recherche  « fondamentale ».  Créé le 6 avril 2010, Xiaomi a rapidement rejoint l e club des géants  chinois, en devenant l’un des plus gros constructeu rs mondiaux dans les TIC  (smartphones, tablettes, mais aussi bracelets conne ctés, télévisions  intelligentes, équipements pour les maisons connect ées, caméras  miniatures...) sans même devoir s’installer en Occi dent, devenant le  quatrième membre des BATX. Seul Uber présente un dy namisme  comparable. Le recrutement en 2013 de  Hugo Barra  par Xiaomi,  en tant que  vice-président, est significatif. D’abord chercheur  du laboratoire  d’intelligence artificielle et d’informatique du MI T, laboratoire visité par vos  rapporteurs, il est ensuite devenu responsable du d éveloppement du  système d’exploitation Android chez Google entre 20 10 et 2013. En janvier  2017, il a rejoint Facebook, en tant que vice-prési dent de la division Oculus  en charge de la réalité virtuelle. Vos rapporteurs ont été reçus au siège de  Facebook à Menlo Park par les responsables de la re cherche en IA de  Facebook et par différents responsables de sa divis ion Oculus le 26 janvier  2017, au moment de ce transfert de Hugo Barra de Xi aomi vers  Facebook.  Huawei (télécom, téléphones), entreprise qui accorde une g rande  importance à la recherche fondamentale et dont la r echerche  s’internationalise rapidement (pôle mathématique im planté en France il y a  deux ans) a mis en avant début janvier 2017 un conc ept de téléphone  intelligent, dont on ne peut encore savoir s’il ira  effectivement plus loin que  ceux de ses concurrents.   Plus globalement, concernant les données, les pôles universitaires  chinois peuvent aussi compter sur le soutien des in dustriels  comme, par  exemple, National Grid , China Mobile , China Unicom , Shanghai Meteorological  Bureau  ou Environmental Monitoring Center …   La Chine prend aussi position dans les technologies  de cartographie  numérique . Deux entreprises nationales, le chinois NavInfo e t la société de  services Internet Tencent, associées au fonds singa pourien GIC, ont acquis  ensemble une participation de 10 % dans le groupe H ERE, contrôlé par  BMW, Daimler et Volkswagen, qui ont réduit leur par t en proportion. Dans  ce cadre, HERE crée une filiale avec NavInfo pour é tendre son offre à la  Chine. Et Tencent utilisera de son côté les prestat ions de cartographie et de  localisation de la société pour ses propres produit s et services.  2.  Une recherche essentiellement masculine  Vos rapporteurs dressent le constat évident que la recherche en  intelligence artificielle et en robotique est essen tiellement conduite par 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 87  -       des hommes. Cette situation d’extrême masculinisati on est critiquable et  n’est pas souhaitable .  Selon Mady Delvaux, la domination masculine dans ce  secteur serait  de nature à créer des biais, dans la conception des  programmes, l’analyse des  données et l’interprétation des résultats, elle dén ombre de l’ordre de 90 % de  programmeurs et de développeurs masculins .  3.  Une interdisciplinarité indispensable mais encore i nsuffisante  En matière d’intelligence artificielle, l’interdisciplinarité est  particulièrement requise . En effet, il s’agit à la fois d’un secteur de  recherche en informatique et d’un champ de réflexio n bien plus large, qui  mobilise des connaissances provenant de nombreuses disciplines .  L’interdisciplinarité est donc indispensable en int elligence  artificielle. Cette prise en compte du critère de l ’interdisciplinarité est  essentielle et souvent recherchée par les équipes d e chercheurs mais, ellemême sous-domaine de l’informatique, l’intelligence  artificielle demeure  éclatée en une cinquantaine de sous-domaines de recherche  identifiés, qui  parfois s’ignorent les uns les autres ou ne coopère nt pas suffisamment.    L’éclatement de la discipline en une cinquantaine d e domaines     Source : Gouvernement    Non seulement l’interdisciplinarité reste insuffisamment mise en  œuvre  mais l’intelligence artificielle elle-même souffre  de ces découpages  internes, qui tendent à cloisonner les recherches.  Vos rapporteurs ont ainsi relevé que les recherches en intelligence  artificielle empruntent et devront, de plus en plus , emprunter à diverses  autres disciplines et en agréger les démarches et l es connaissances . Elles 
- 88  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        peuvent même aller jusqu’à s’inscrire dans d’autres  espaces disciplinaires  (mathématiques, physique, biologie…).  Issue des mathématiques , de la logique et de l’informatique ,  l’intelligence artificielle fait appel depuis des d écennies, et de plus en plus, à  la psychologie, à la linguistique, à la neurobiolog ie, à la neuropsychologie  et au design . Dans la période plus récente, elle s’ancre encore  davantage  dans les sciences cognitives , et mobilise les outils de la génétique  et des  « Sciences de l’Homme et de la Société » (SHS), en particulier de la  sociologie .  L’intelligence artificielle se nourrit de plus en p lus des recherches  issues des mathématiques, des statistiques, de la p hysique, de la biologie, en  particulier pour ses méthodes de recherche et ses champs d’application .  Elle doit également, et de plus en plus, s’alimente r auprès des SHS, plutôt  sur les usages mais aussi sur les questionnements éthiq ues en matière de  conception.  Les humanités numériques  sont un exemple de démarches à  l’intersection de l’intelligence artificielle et de s SHS. Comme l’a expliqué  Jean-Gabriel Ganascia à vos rapporteurs, les discip lines relevant des  humanités, à savoir dont l’objet d’étude porte sur les œuvres humaines,  comme l’histoire, l’archéologie, la littérature, et c., tirent, depuis environ  quinze ans, avantage de la numérisation des sources  et de l’utilisation des  techniques d’intelligence artificielle et d’apprent issage machine pour  concevoir de nouveaux opérateurs d’interprétation. Aujourd’hui, ce courant  scientifique situé à la frontière de l’informatique  et des « sciences de la  culture » est désigné sous le vocable d’« humanités  numériques ». Cela fait  l’objet de nombreuses recherches dans tous les pays  du monde, en particulier  aux États-Unis, dans les États européens, dont la F rance. On peut, par  exemple, citer l’école polytechnique fédérale de La usanne en Suisse, visitée  par vos rapporteurs, ou le Labex OBVIL entre la Sor bonne et l’UPMC.  Par ailleurs, les liens entre intelligence artificielle et robotique  ont  longtemps été très étroits mais dans le dernier qua rt du XX e siècle une  distance s’est créée sous le double effet de la spé cialisation de la robotique  industrielle sur des automates pas ou peu autonomes  et du moindre coût  de la recherche sur des systèmes logiciels d’intell igence artificielle  (le coût  relatif d’un robot intelligent étant plus élevé). D ’après Raja Chatila, cette  distance devrait maintenant se réduire car les robo ts deviennent de plus en  plus des intelligences artificielles « encorporées » (embodied ), le terme étant  plus pertinent que celui « d’incorporées » car elle s s’incarnent dans des corps  physiques plus qu’elles n’y seraient simplement pla cées. Selon lui, au-delà  du traitement du langage naturel, les problèmes d’i nteraction et d’action  conjointe homme-robot posent des questions d’interd isciplinarité : la mise en  œuvre de « prises de perspective » est une probléma tique fondamentale pour  permettre une interaction efficace et naturelle ent re l’humain et le robot. Ce  sujet demande un développement qui associe des rech erches en robotique et  en SHS, en particulier, en sociologie, philosophie,  psychologie, linguistique... 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 89  -       Le rôle des émotions dans l’interaction  est à explorer, bien au-delà de  travaux actuels qui se contentent de classer a priori  des expressions faciales  ou de produire des expressions d’émotions artificie lles par le robot.  L’expression d’émotions par un robot pose des questionnements  scientifiques et éthiques sur l’authenticité de ces  émotions et sur  l’anthropomorphisation  qui peut en résulter, sujet sur lequel s’est  spécialisée Laurence Devillers, professeure à l’Uni versité Paris IV Sorbonne  et directrice de recherche au Laboratoire d’informa tique pour la mécanique  et les sciences de l’ingénieur (Limsi de Saclay) qu i plaide elle aussi pour une  plus grande interdisciplinarité, totalement nécessa ire selon elle.  La recherche en robotique pose en effet des questio ns proches des  sciences cognitives, des neurosciences et de plusie urs domaines des SHS,  comme la sociologie, la psychologie et la philosoph ie. Des programmes  interdisciplinaires sont probablement le bon moyen d’aborder les différentes  facettes des questions fondamentales posées par l’i ntelligence artificielle et la  robotique.  En plus des aspects technologiques, les chercheurs appellent à plus  de transversalité  en vue de croiser leurs approches, une pluricompét ence  dans les équipes, indispensable au progrès dans ce domaine où se  télescopent les disciplines. Selon Bertrand Braunsc hweig, directeur du centre  de d’Inria de Saclay, « nous avons besoin de doubles, voire de triplescompétences  ».  Comprendre l’intelligence sous toutes ses formes re ste une des  grandes questions scientifiques de notre temps, au- delà même des progrès  et des limites de l’intelligence artificielle  et, comme le souligne Yann  LeCun, « aucune organisation, si puissante soit-elle, ne peu t résoudre ce problème  en isolation. La conception de machines intelligent es nécessitera la collaboration  ouverte de la communauté de la recherche entière  ».  L’interdisciplinarité doit, en outre, se conjuguer avec une meilleure   prise en compte du long terme , qui représente un autre défi en matière de  recherche scientifique 1, notamment en matière d’intelligence artificielle.  Pour  Jean-Gabriel Ganascia, cela résulte notamment des m odes de financement :  les logiques de court terme des projets n’offrent p as la pérennité et la vision  de long terme souvent souhaitables et rendent diffi ciles le développement de  grandes ambitions. Il note toutefois que les LabEx,  ou Laboratoires  d’excellence, lauréats d’appels à projets lancés da ns le cadre du Programme  investissements d’avenir (Grand emprunt) ont moins présenté ce défaut.  Selon Gérard Sabah, membre de l’Académie des techno logies, c’est la  structure de la recherche française qui gênerait la  recherche en intelligence  artificielle parce que, selon lui, à l’exception du  cas des chercheurs du CNRS                                                    1 Pierre-Gilles de Gènes alerte ainsi : « l’avenir de la recherche est dorénavant aux mains d e  gens qui ne voient que leur intérêt à trois ans (…) . Le mot d’ordre semble être de supprimer  tous les investissements à moyen et long termes, en  postes de chercheurs comme en moyens  de laboratoires. Or une bonne recherche suppose un horizon à dix ans sinon trente ans et  les moyens adéquats ». 
- 90  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        (eux-mêmes souvent envahis par les tâches administr atives), seuls les  doctorants pourraient se consacrer à plein temps à la recherche en  intelligence artificielle qui demande beaucoup d’in vestissement en temps,  d’expérimentation et en retours d’expériences : « La contrainte d’une thèse en  trois ans maximum et le fait qu’après leur soutenan ce ils se voient généralement  obligés de continuer ailleurs (au mieux comme maîtr e de conférences, chargé de  nombreuses tâches autres que de recherche pure) fon t que des projets à long terme  ont du mal à se développer. À mon sens, c’est une d es raisons pour lesquelles la  recherche fondamentale en intelligence artificielle  a peu avancé (en France). Comme  elle est également proche des sciences cognitives e t fait donc appel à diverses  disciplines, la difficulté de mener des carrières i nterdisciplinaires dans le cadre  académique est également un frein à son développeme nt. Or, la fréquentation  d’autres disciplines demande une culture à la fois très vaste et très profonde, qui  n’est pas toujours dispensée par les formations act uelles : la plupart des systèmes  d’enseignement européens fonctionnent selon des str uctures anciennes, qui ont  conduit à la spécialisation  ».  Pour votre rapporteure Dominique Gillot le point év oqué d’une  surcharge administrative des chercheurs constitue u ne appréciation  controversée : souvent reproduite, elle devrait êtr e évaluée et approfondie.  Par ailleurs, avec un point de vue plus interdiscip linaire il est  possible de supposer que l’intelligence artificiell e permettra aussi de mieux  modéliser le fonctionnement du cerveau et les relations entre le cerveau et  la conscience, ainsi que la mémoire  ou la récupération et la stimulation des  facultés cognitives et/ou motrices.  Ces découvertes, qui profiteront aux neurosciences,  rétroagiront  très probablement avec la recherche en intelligence  artificielle dans un  cercle vertueux.  Les projets de recherche Humain Brain Project (HBP) et Blue Brain  Project  (BBP) que vos rapporteurs sont allés découvrir sur  place  en Suisse  devraient aller dans ce sens. Jean-Pierre Changeux,  partie prenante des  projets, leur en a fait partager l’ambition.  L’équipe du BBP de l’École polytechnique fédérale d e Lausanne  (EPFL) se donne pour objectif depuis mai 2005 de cr éer un cerveau  synthétique par rétroingénierie.   Ce projet pluridisciplinaire permet aussi d’étudier  l’architecture et  les principes fonctionnels du cerveau. Il a été sui vi, en 2013, du HBP, financé  par l’Union européenne, et certains résultats sont déjà tangibles : en octobre  2015, l’équipe est parvenue à assurer la reproduction virtuelle de  microcircuits de neurones de rat .    
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 91  -       Présentation du Human Brain project (HBP)  Le  Human Brain project  (HBP) est un projet scientifique lancé en 2013 qui   s’appuie sur le BBP et qui vise à simuler le foncti onnement du cerveau humain  grâce à un superordinateur d’ici à 2024. Il a été c hoisi pour être l’un des deux « FET  Flagships »  de l’Union européenne 1 et son coût total est estimé à 1,19 milliard  d’euros. Il s’agit ainsi de mieux comprendre le cer veau et ses mécanismes de base,  d’appliquer ces connaissances dans le domaine médic al et de contribuer au progrès  de l’informatique (et en IA). Les résultats obtenus  permettraient par exemple de  développer de nouvelles thérapies médicales plus ef ficaces sur les maladies  neurologiques : en effet le projet vise à créer une  nouvelle plateforme informatique  médicale pour tester des modèles de maladies, améli orer le diagnostic et accélérer  le développement de nouvelles thérapies.  S’agissant des progrès en informatique et en IA, l’ objectif du projet est de  tirer parti d’une meilleure compréhension du foncti onnement du cerveau pour le  développement de technologies de l’information et d e la communication plus  performantes s’inspirant des mécanismes du cerveau humain. Les bénéfices espérés  sont une meilleure efficacité énergétique, une fiab ilité améliorée et la  programmation de systèmes informatiques complexes.  Le projet est mené par une équipe coordonnée par He nry Markram, un  neuroscientifique de l’École polytechnique fédérale  de Lausanne (EPFL) qui,  parallèlement, animait déjà le projet Blue Brain ; et codirigé par le physicien  Karlheinz Meier de l’Université de Heidelberg et le  médecin Richard Frackowiak  du Centre hospitalier universitaire vaudois et l’Un iversité de Lausanne, en  collaboration avec plus de 90 instituts de recherch e européens et internationaux  répartis dans 22 pays différents. Il rassemble au t otal des milliers de chercheurs.  Le projet a été contesté en 2014 et 2015 2, ce qui a conduit à le réorienter en  partie, en accordant notamment plus d’importance au x neurosciences cognitives.  En mai 2015, les ingénieurs du HBP montrent les pre mières simulations en  vue de la réalisation d’une « souris virtuelle » en  plaçant un modèle informatique  simplifié du cerveau d’une souris dans un corps vir tuel soumis à des stimulations.  Ces résultats n’ont cependant pas fait cesser les c ritiques contre le HBP.   La première phase du HBP a débuté fin 2013 et a dur é deux ans et demi.  Un premier bilan est donc à dresser.                                                    1 Il s’agit des « Initiatives-phare des Technologies Futures et Émergentes » de l’Union européenne,  soutenues financièrement à hauteur d’un milliard d’ euros chacune sur dix ans, dont la moitié est  versée par le budget de l’UE (l’autre projet porte sur le graphène).  2 En juillet 2014, une lettre ouverte signée de 130  scientifiques est adressée à la Commission  européenne. Elle critique les orientations prises p ar la direction du HBP et appelle l’UE à prendre  des mesures pour réorienter le projet. L’objet de c ette lettre est surtout la gouvernance du HBP, mais   aussi le manque de réalisme du projet et son coût i mportant. En 2015, Yann LeCun a critiqué l’idée  qu’une IA pourrait émerger simplement d’un ordinate ur, aussi puissant soit-il, en utilisant quelques  algorithmes simples d’apprentissage. Il pense que l es progrès en matière d’IA viendront plutôt de  l’apprentissage machine non supervisé. 
- 92  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Pour simuler le fonctionnement d’un cerveau humain,  la puissance  calculatoire nécessaire est estimée à un exaflops 1. Or un superordinateur atteignant  l’exaflops sera difficile à atteindre avant 2020. S teve Furber de l’Université de  Manchester souligne que les neuroscientifiques ne s avent toujours pas avec  certitude quels détails biologiques sont essentiels  au traitement cérébral de  l’information, et en particulier ceux qu’on peut s’ abstenir de prendre en compte  dans une simulation visant à simplifier ce processu s.    Visant la création de modèles pour étudier les mala dies  neurodégénératives, une équipe française du laborat oire CellTechs de l’école  SupBiotech, en collaboration avec le CEA (Commissar iat à l'énergie  atomique et aux énergies alternatives) travaille su r la « reprogrammation» de  cellules souches sans aucune spécialisation, dites alors « pluripotentes  induites » (ou IPS), afin de les différencier pour devenir, par exemple, des  cellules cérébrales  : Frank Yates, enseignant-chercheur à SupBiotech e t  responsable de cette équipe explique que leurs cult ures d’organoïdes  neuroectodermiques « comptent entre 500.000 et un million de cellules, e t  mesurent environ 2 mm de diamètre  »2.   Les perspectives d’application de ces projets et de  BBP et de HPB en  particulier sont grandes, mais la perspective d’un homme non seulement  réparé mais augmenté qui pourrait à terme se dessin er soulève  d’importantes questions éthiques .  Au sein des projets de grande envergure, le plus so uvent menés aux  États-Unis, en Chine et au Japon (mêmes si les cas du HBP de l’EPFL peut  s’apparenter à cette famille de grands projets plur idisciplinaires), le caractère  pluridisciplinaire est évident : au-delà du matérie l informatique et des  logiciels utilisés, cœur historique de l’intelligen ce artificielle, d’autres savoirfaire et domaines de connaissances sont largement m obilisés : la robotique,  au sein de laquelle les mouvements et les perceptio ns sont essentiels pour  produire de l’intelligence, les sciences de la vie,  à l’image de la physiologie,  des neurosciences et de la génétique, mais aussi le s sciences humaines, avec  la psychologie, la linguistique et la sociologie.  Pour vos rapporteurs, il existe un débat sur la façon de réussir cette  interdisciplinarité dans le cadre existant , contraint par un académisme d’un  autre temps. La remise en cause du cadre existant  pourrait être bienvenue.  La place que le CNRS fait, par exemple, à l’intelli gence artificielle dans son  organisation semble être, pour le moins, insuffisan te. Il faudrait aussi revoir  les modalités de carrière des chercheurs en encoura geant les parcours                                                    1 10 18  soit un milliard de milliards, ou un trillion de f lops (un flop est une unité de mesure de la  vitesse d’un système informatique).  2 Cf. http://www.futura-sciences.com/sante/actualites/cer veau-faire-pousser-mini-cerveau-cestpossible-66821/   
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 93  -       transgressant les frontières disciplinaires et en v alorisant dans les  évaluations les expériences de partenariats, notamm ent public-privé.  4.  Une recherche soumise à une contrainte d’acceptabil ité sociale  assez forte sous l’effet de représentations catastr ophistes de  l’intelligence artificielle  La recherche en intelligence artificielle ainsi que  ses applications  sont soumises à une contrainte d’acceptabilité sociale assez forte ,  notamment sous l’effet de représentations catastrop histes, comme en  témoignent les sondages d’opinion.  Lors du lancement de France IA, le Gouvernement a r appelé que  65 % des Français interrogés se disent inquiets du développement de  l’intelligence artificielle  alors que, comparativement, 36 % des Britanniques  et 22 % des Américains expriment la même crainte.  Selon un autre sondage Odoxa, réalisé en mai 2016 p our Stratégies et  Microsoft, qui posait la question « L’intelligence artificielle, une chance ou  une crainte ? », les Français sont aussi nombreux à voir dans cette forme  d’algorithmes une opportunité (49 %) qu’un motif de  peur (50 %) .  Un troisième sondage, réalisé par Orange et « 01.ne t », réalisé, lui, en  ligne parvient à des résultats plus rassurants : 40 % des sondés disent avoir  peur  de l’intelligence artificielle et 60 % disent ne pas en avoir peur  (le fait  qu’il s’agisse d’un sondage en ligne auprès des int ernautes introduit  forcément plus de biais qu’un sondage par échantill on représentatif, les  réponses étant issues de personnes déjà familières des TIC).  Les chiffres annoncés par le Gouvernement en janvie r 2017 sont en  fait les résultats d’une enquête de l’IFOP  sur le sujet. Ces résultats  traduisent, sur un plan statistique, la prise de conscience assez élevée de  l’essor de l’intelligence artificielle et de ses op portunités .  Cet enthousiasme majoritaire doit être nuancé par les craintes –  elles aussi majoritaires – que cette technologie s uscite dans le même  temps . Une majorité de sondés (67 %) voit en effet tout autant l’intérêt de  l’intelligence artificielle pour améliorer le bien- être individuel et collectif,  qu’il s’inquiète (à 65 %) de l’autonomie croissante  des machines.  On se retrouve donc devant une logique d’appréciation contrastée   qui n’est sans doute pas sans lien avec l’accent mi s sur les risques de l’IA  dans la culture populaire (littérature et surtout c inéma de science-fiction en  particulier) et dans le débat public. 
- 94  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Enquête d’opinion conduite en 2016 sur l’intelligen ce artificielle    Source : IFOP  D’après Bernard Stiegler, directeur de l’Institut d e recherche et  d’innovation (IRI) du centre Georges Pompidou et pr ofesseur à l’Université  de Londres, l’enseignement de ce sondage est le sui vant : « la population est  consciente dans son ensemble de l’importance des en jeux liés à la nouvelle  intelligence artificielle qui émerge (…), de ses pr omesses potentielles, mais aussi et  surtout de ses dangers. C’est assez rassurant : qua nd on sait que des personnalités  aussi bien informées que Stephen Hawking ou Bill Ga tes ont elles-mêmes manifesté  leur très grande préoccupation avec des dizaines de  scientifiques de grand renom  face à ce qui se met en place, il est heureux de co nstater que les personnes  interrogées reflètent une conscience de la dimensio n pharmacologique du numérique,  c’est à dire le fait qu’il constitue autant un remè de qu’un poison – et que dans  l’immédiat, le coût toxique semble s’imposer plutôt  que les dimensions curatives  ».  Vos rapporteurs, s’ils y sont sensibles, ne partage nt pas cette analyse  selon laquelle les inconvénients de l’intelligence artificielle seraient, à ce  stade, supérieurs à ses avantages pour nos sociétés . Rien ne permet de le  démontrer et la vigilance qui se met en œuvre sur u n plan national et  international devrait en être garante.  Un autre sondage, mené par l’IFOP pour la CNIL  en janvier 2017,  peut être cité 1. Il est consacré au cas plus général des algorithm es et montre  que la majorité des personnes interrogées (64 %) consid èrent que les  algorithmes représentent plutôt une menace , en raison de l’accumulation de  données personnelles sur les choix, les goûts et le s comportements. Cette  perception varie fortement en fonction de l’âge : p our les 18-24 ans, les  algorithmes représentent d’abord une opportunité (à  51 %).                                                    1 Cf. https://www.cnil.fr/sites/default/files/atoms/files /presentation_ifop_-_presentation.pdf   
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 95  -         Les Français et les algorithmes : notoriété et perc eption  D’après un sondage mené par l’IFOP pour la CNIL en janvier 2017, les  algorithmes sont présents dans l’esprit des Françai s mais de façon assez confuse. Si  83 % des Français ont déjà entendu parler des algor ithmes, ils sont plus de la moitié  à ne pas savoir précisément de quoi il s’agit (52 % ). Leur présence est déjà jugée  massive dans la vie de tous les jours par 80 % des Français qui considèrent, à 65 %,  que cette dynamique va encore s’accentuer dans les années qui viennent.  Concernant l’opinion sur les algorithmes, une court e majorité (53 %) estime  qu’ils sont plutôt sources d’erreur contre 47 % qui  pensent qu’ils sont fiables. Mais,  la confiance s’élève à mesure que le niveau de conn aissance sur les algorithmes  progresse. Un effort de pédagogie et de transparenc e peut donc contribuer à  renforcer la confiance.   Sous un angle marketing, 57 % des Français pensent que les algorithmes limitent  l’étendue des choix proposés. Chez les plus jeunes,  la tendance s’inverse, puisque  53 % des moins de 35 ans et 56 % des 18-24 ans mett ent plutôt en avant le fait que  les algorithmes proposent plus de choix.  Enfin, c’est sous l’angle de la perception citoyenn e que l’opinion est la plus  tranchée en fonction de l’âge. Si les 2/3 des Franç ais (64 %) considèrent que les  algorithmes représentent plutôt une menace en raiso n de l’accumulation de  données personnelles sur les choix, les goûts et le s comportements, les 18-24 ans  inversent cette tendance nettement affirmée puisque  51 % estiment au contraire que  les algorithmes représentent une opportunité.  Source : CNIL    Enfin, deux études parues en avril 2017 au sujet de  l’utilisation de  l’intelligence artificielle à des fins commerciales  vont dans le même sens 1 : la  première montre que 72 % des 6 000 internautes sondés dans six pays  déclarent en avoir peur 2 et la seconde montre que 42 %  des 2 000 personnes  interrogées ne font pas confiance  à l’intelligence artificielle 3.  Vos rapporteurs, qui ont la mémoire des quarante de rnières années,  n’oublient pas que la popularisation d’Internet dan s les années 1990 s’est elle  aussi accompagnée, comme auparavant avec la télémat ique, de l’expression  de craintes : peur de l’affaiblissement des relations sociales 4, des pannes                                                    1 Cf. une synthèse dans l’article suivant : http://www.zdnet.fr/blogs/watch-it/intelligence-art ificielleles-consommateurs-restent-craintifs-39851386.htm    2 https://www.pega.com/ai-survey   3 https://uk.insidesales.com/research-paper/state-art ificial-intelligence-uk-2017-public-perceptionsdisruptive-technology/   4 Il existe, depuis une trentaine d’années et surtou t depuis dix ans, une peur de la perte d’une  sociabilité authentique et de son remplacement par une sociabilité virtuelle, moins durable et plus  égocentrique. Les travaux du sociologue Dominique C ardon, spécialiste de l’usage de l’IA, des TIC et  des comportements sur Internet et les réseaux socia ux, démontrent plutôt une corrélation en sens  inverse : les jeunes adeptes des réseaux sociaux en richissent leur vie sociale physique plus qu’ils ne  
- 96  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        informatiques 1, du piratage , de l’escroquerie  commerciale , d’un  nivellement intellectuel par le bas 2 ou, encore, de l’exploitation non  contrôlée et non autorisée des données personnelles … Certaines de ces  peurs se sont avérées en partie légitimes et vos ra pporteurs n’entonnent pas  le refrain d’un scientisme optimiste et naïf devant  les mutations issues des  technologies numériques. Ils ne souscrivent pas, po ur autant, à une  application stérilisante du principe de précaution qui empêcherait la  recherche en intelligence artificielle : le présent  rapport le démontre,  notamment dans les propositions qui seront développ ées plus loin.  L’actualité, au-delà de la victoire médiatisée à ju ste titre d’AlphaGo  de DeepMind déjà évoquée et des résultats de plus e n plus significatifs  obtenus en intelligence artificielle, pourrait semb ler mettre l’accent sur les  risques liés à l’intelligence artificielle  :  - le premier accident mortel  lors d’un trajet en voiture autonome, a  eu lieu en Floride dans un véhicule Tesla le 7 mai 2016, alimentant la peur  des véhicules autonomes. Le rapport d’expertise de l’agence fédérale  américaine de sécurité routière (NHTSA) a dédouané Tesla et a invoqué des  facteurs humains, dans la mesure où « le conducteur  de la Tesla, censé  garder ses mains à tout moment sur le volant, a eu sept secondes pour voir le  semi-remorque en travers de la route ». Il s’agissa it en mai 2016 du premier  décès sur plus de 209 millions de kilomètres parcou rus par des voitures  Tesla avec le pilote automatique activé, or parmi t ous les véhicules circulant  aux États-Unis, il y a un décès tous les 152 millio ns de kilomètres ;   - le premier accident responsable , mais sans victime, de la voiture  autonome construite par Google, la « Google Car », a eu lieu le 14 février  2016 sur une route de Mountain View ;  - « Tay » , un avatar algorithmique d’intelligence artificiel le créé par  Microsoft dans le but de conduire des conversations  sur Twitter, est devenu                                                                                                                                                  l’appauvrissent. En la matière, le virtuel ne se su bstitue donc pas au réel.  Rodolphe Gélin et Olivier  Guilhem, respectivement directeur scientifique et d irecteur juridique d’Aldebaran puis de SoftBank  Robotics, ne croient pas que l’intelligence artific ielle puisse être un fossoyeur des relations social es et  rappellent que « lorsque nos enfants jouaient des heures, seuls, sur  leur console de jeux ou  leur ordinateur, nous redoutions qu’ils deviennent des êtres désociabilisés n’interagissant  plus qu’avec leur machine. Ils ont aujourd’hui beau  jeu de nous dire que, grâce aux réseaux  sociaux et aux jeux en réseau, ils sont bien plus e n relation avec le monde que nous, perdus  dans nos livres en papier pendant des heures sans p arler à personne !  ».  1 La peur infondée du « bug de l’an 2000 » dans les années 1990 avec son cortège de commentaires  médiatiques excessifs devrait être un exemple à méd iter.  2 « Est-ce que Google nous rend idiots ?  » s’interrogeait Nicholas Carr en juin 2008 dans l a  revue The Atlantic  (traduction du nom anglais de l’article « Is Google making us stupid ? » ). La  consommation de plus en plus rapide et superficiell e d’informations au travers des outils numériques  est patente et remet en question nos capacités inte llectuelles traditionnelles, nos relations sociales  et  nos habitudes de travail. Une étude canadienne publ iée en février 2016 démontre que les réseaux  sociaux encourageraient une pensée rapide et superf icielle pouvant, à terme, entraîner une  superficialité cognitive et morale (cf. Logan Annis ette et Kathryn Lafreniere, « Social media,  texting, and personality : a test of the shallowing  hypothesis »  Department of Psychology,  University of Windsor). 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 97  -       raciste en miroir de ses interlocuteurs 1 quelques heures après son activation  le 23 mars 2016 ;  - une association française contre l’intelligence a rtificielle (AFCIA) a  déposé ses statuts le 18 juillet 2015 2. Son président Cédric Sauviat a été  rencontré par vos rapporteurs, qui ont jugé à la fo is son discours bien  construit et ses analyses excessives voire infondée s, révélatrices d’un certain  climat d’angoisse puisque la France serait le seul pays où une telle  association existerait 3. L’AFCIA juge « illégitime et dangereuse la recherche  scientifique visant à créer des organismes à intell igence artificielle suprahumaine »  et considère que le seul moyen « d’éviter un avenir funeste pour l’humanité est  d’obtenir l’interdiction légale de la recherche en intelligence artificielle à l’échelle  mondiale  ». Se définissant comme association de lobbying, e lle vise à obtenir  cette interdiction auprès des pouvoirs publics  ;  - et plusieurs interventions médiatiques, pétitions  et lettres ouvertes,  ont cherché en 2015 à interpeler l’opinion à propos  des risques qui seraient  inhérents à l’intelligence artificielle 4.  Des figures médiatiques ont par ailleurs tenu des d iscours  catastrophistes. Ainsi, Stephen Hawking, professeur  de mathématiques  connu pour ses contributions dans les domaines de l a cosmologie et la  gravité quantique, a déclaré l’année dernière dans une interview à la BBC  que « les formes d’intelligences que nous avons déjà se s ont montrées très utiles.  Mais je pense que le développement d’une intelligen ce artificielle complète pourrait  mettre fin à la race humaine. Les humains, limités par une lente évolution  biologique, ne pourraient pas rivaliser et seraient  dépassés  ».  Bill Gates, le fondateur de Microsoft, s’est aussi inquiété en 2015 des  progrès de la superintelligence : « dans quelques décennies, l’intelligence sera  suffisamment puissante pour poser des problèmes  ».  Jacques Attali s’est, à son tour, expliqué sur les priorités souhaitables  en matière d’intelligence artificielle et s’est pro noncé à la fin de l’année 2016  pour un moratoire sur les technologies d’intelligen ce artificielle, ce qui a  surpris votre rapporteur Claude de Ganay.                                                    1 Cette évolution de Tay s’est faite au contact d’in ternautes cherchant délibérément à tester les  limites du système en le faisant déraper d’un point  de vue politique et moral.  2 La lecture de son site, qui utilise en fond d’écra n des images extraites des films Metropolis et  Matrix, est édifiante : http://afcia-association.fr/    3 Ce constat est renforcé par l’existence d’autres a ssociations technophobes, inspirées par John  Zerzan, Jacques Ellul, Ivan Illich ou Georges Berna nos et parfois par le néo-luddisme, à l’instar du  collectif « Pièces et main-d’œuvre » (souvent abrég é en PMO) :  http://www.piecesetmaindoeuvre.com/    4 À l’image en janvier 2015 de la lettre d’avertisse ment sur les dangers potentiels de l’intelligence  artificielle signée par 700 personnalités (le plus souvent des scientifiques et des chefs d’entreprise ,  rejoints par plus de 5000 signataires en un an) et,  en juillet 2015 pour l’ouverture de la Conférence  internationale sur l’intelligence artificielle qui s’est tenue à Buenos Aires, de la lettre signée par  plus  de mille personnalités, demandant l’interdiction de s robots tueurs, lettres évoquées dans  l’introduction du présent rapport. 
- 98  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        5.  Une recherche en intelligence artificielle qui s’ac compagne de  plus en plus d’interrogations et de démarches éthiq ues  Vos rapporteurs ont observé une multiplication des initiatives  visant la prise en compte de principes éthiques dan s la recherche et les  usages de l’intelligence artificielle . Cela vaut pour la recherche publique,  comme pour la recherche privée, en Europe comme en Amérique. Il s’agit  d’une caractéristique qui singularise la recherche en intelligence artificielle,  particulièrement en France où les préoccupations en  matière de sécurité et de  données personnelles sont fortes et font régulièrem ent débat.  Ils décrivent les détails de cette réalité de plus en plus tangible plus  loin dans le rapport, dans la partie consacrée à la  prise en compte  grandissante des enjeux éthiques.  B.  TABLEAU DE LA RECHERCHE FRANÇAISE EN INTELLIGENCE  ARTIFICIELLE  1.  De nombreux organismes publics interviennent dans l a  recherche en intelligence artificielle   Notre pays dispose, en matière de recherche en inte lligence  artificielle, d’ importants atouts à faire valoir, riches de la compétence de ses  enseignants, de ses chercheurs et de ses étudiants,  même si la communauté  française de l’intelligence artificielle est encore  insuffisamment organisée,  connue et visible. La reconnaissance internationale des travaux des  chercheurs français doit beaucoup à nos universités , au CNRS, à nos  grandes écoles (Polytechnique, ENS, Mines-Télécom…) mais aussi plus  spécifiquement à deux organismes  : le Commissariat à l’énergie atomique  et aux énergies alternatives (CEA)  et ses nombreux centres de recherche (à  l’image de l’institut Carnot « CEA-List » spécialis é dans les systèmes  numériques intelligents pour l’industrie), et l’ Institut national de recherche  en informatique et en automatique (Inria), créé dès janvier 1967 dans le  cadre du Plan Calcul sous le statut d’établissement  public à caractère  scientifique et technologique.  Les centres de recherche de l’ Institut Mines-Télécom , qui regroupe  les écoles des mines et les écoles des télécommunic ations françaises, méritent  aussi d’être signalés, notamment le centre de reche rche en informatique  (CRI), le centre de Bio-informatique (CBIO) et le c entre de Robotique  (CAOR).  Au total, Inria, le CNRS, le CEA, différentes unive rsités et grandes  écoles sont les principaux organismes de recherche publique en  intelligence artificielle et produisent des travaux  à visibilité  internationale .  
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 99  -       Cette excellence est reconnue à l’international com me ont pu le  constater vos rapporteurs lors de leurs déplacement s. Le bon niveau des  étudiants et des enseignants est également souvent cité. Il leur a même été  demandé à San Francisco de former en France plus d’ étudiants pour  alimenter en ressources la Silicon Valley .    Les principaux organismes de recherche publique en intelligence  artificielle (à visibilité internationale)    Source : ISAI/Paul Strachman    L’excellence de l’école mathématique française contribue à nos  succès, avec un nombre de 13 médaillés Fields, soit  une place de numéro 2,  juste derrière les États-Unis avec 14 médaillés Fie lds. L’ENS, avec ses  11 médailles, figure en tête de la liste des instit utions au niveau mondial.  Cinq de nos universités figurent dans le top 30 des  universités de  mathématiques et une dans le top 5. Nous disposons de plus de 200 écoles  d’ingénieurs qui forment chaque année 38 000 nouvea ux diplômés. Plusieurs  de ces écoles disposent de cursus ou de formations en intelligence artificielle  ou en robotique.  L’histoire montre que la recherche française en mat ière d’intelligence  artificielle a toujours été assez forte  et s’est placée à une place enviable par  rapport à ses concurrents en recherche fondamentale , même si elle court le  risque d’un décrochage face aux pays les plus avanc és  dans la course  mondiale en intelligence artificielle, États-Unis, Chine et Royaume-Uni en  tête.   Au tournant des années 1970 et 1980, la recherche e n intelligence  artificielle en France a connu une certaine accélér ation , avec notamment le  groupe de recherche parisien animé par Claude-Franç ois Picard appelé  « GR 22 ». Jacques Pitrat, Jean-Louis Laurière, Jea n-François Perrot et JeanCharles Pomerol y ont, par exemple, travaillé. En 1 987, il a pris le nom de  LAboratoire FORmes et Intelligence Artificielle (LA FORIA) puis a rejoint en 
- 100  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        1989 l’Institut Blaise Pascal (IBP) avant de fusion ner en 1997 au sein du  Laboratoire d’Informatique de l’Université Paris 6 dit « LIP6 ». D’autres  laboratoires investis dans la recherche en intellig ence artificielle ont  également marqué les années 1980-1990 en France 1. Beaucoup sont rappelés  sous leur nom actuel au paragraphe suivant.  Un inventaire des douze principaux laboratoires du CNRS en  matière d’intelligence artificielle  ayant été dressé par Gérard Sabah 2, vos  rapporteurs ont souhaité les rappeler ici (le nombr e de chercheurs par  laboratoire n’a pas été actualisé et a pu connaître  des variations depuis cet  inventaire) :  - le groupe de recherche en informatique, image, au tomatique et  instrumentation (GREYC), spécialisé dans le traitem ent automatique des  langues, la sémantique, et la fouille de données, b asé à Caen, compte 20  permanents ;  - l’Institut de recherche en informatique de Toulou se (IRIT) est  spécialisé dans la communication, les agents intell igents, l’ingénierie des  connaissances, l’aide au handicap, et le traitement  automatique des langues.  Il compte 40 collaborateurs ;  - le laboratoire d’architecture et d’analyse des sy stèmes (LAAS),  situé à Toulouse, dédié au logiciel, à la communica tion et à la robotique,  compte 40 permanents ;  - le laboratoire d’analyse et modélisation de systè mes pour l’aide à la  décision (LAMSADE) basé à l’Université Paris-Dauphi ne, spécialisé dans les  agents intelligents et modèles coopératifs ainsi qu e dans la gestion des  connaissances, est composé de 15 chercheurs ;  - le laboratoire des langues, textes, traitements i nformatique et  cognition (LATTICE), établi à Paris, est spécialisé  dans le traitement  automatique des langues avec 5 permanents ;   - le laboratoire d’informatique fondamentale (LIF),  établi à Marseille,  est spécialisé dans l’apprentissage et le traitemen t automatique des langues  et regroupe 17 agents ;  - le laboratoire d’informatique de Grenoble (LIG) e st spécialisé dans  l’environnement pour apprentissage, la traduction a utomatique, la réalité  virtuelle et les agents intelligents, il est compos é de 35 permanents ;   - le laboratoire d’informatique pour la mécanique e t les sciences de  l’ingénieur (LIMSI) basé à Orsay et spécialisé en a gents communicants, le  traitement automatique des langues et de la parole,  ainsi qu’en réalité  virtuelle, regroupe 15 chercheurs ;                                                    1 Le Laboratoire d’Informatique pour la Mécanique et  les Sciences de l’Ingénieur (LIMSI) à Orsay,  l’Institut de recherche en informatique et en autom atique (IRIA) et en particulier le Laboria (autour  de Gérard Huet) à Rocquencourt, le GIA (autour d’Al ain Colmerauer) à Marseille, le CRIN à Nancy  ou, encore, le CERFIA à Toulouse.  2 Cet inventaire est présenté dans la brochure de l’ Académie des Sciences déjà citée. 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 101  -       - le laboratoire d’informatique de Paris-Nord (LIPN ) spécialisé dans  l’apprentissage, la logique, le calcul, le raisonne ment, la représentation des  connaissances et le traitement automatique des lang ues. On y dénombre 25  collaborateurs ;  - le laboratoire d’informatique, de robotique et de  microélectronique  de Montpellier (LIRMM) spécialisé dans l’apprentiss age, les contraintes, la  représentation des connaissances, les systèmes mult i-agents, le traitement  automatique des langues, la visualisation, le web  sémantique. Il est composé  de 17 permanents ;  - le laboratoire lorrain de recherche en informatiq ue et ses  applications (LORIA) situé à Nancy, est spécialisé dans la communication  multimodale, la représentation et la gestion des co nnaissances, la  reconnaissance de l’écriture, le traitement automat ique des langues et de la  parole. Il regroupe 30 agents ;  - le laboratoire de recherche en informatique (LRI)  établi en région  parisienne, est spécialisé dans l’apprentissage et l’optimisation, les systèmes  d’inférence. Il compte 24 permanents ;  - le laboratoire « techniques de l’ingénierie médic ale et de la  complexité » (TIMC) basé à Grenoble, est spécialisé  dans l’apprentissage, la  sémantique, la gestion et le traitement des connais sances. Il est composé de  12 collaborateurs.  En plus de ces laboratoires publics, de nombreuses entreprises  françaises ont établi des laboratoires en partenari at avec des organismes  publics de recherche. Il peut être cité les cas des  entreprises Thalès, EDF,  Engie, PSA, Total ou encore Solvay (entreprise belg e mais cotée à la bourse  de Paris et faisant partie de l’indice CAC 40). Les  entreprises étrangères font  aussi de la recherche fondamentale en IA sur le ter ritoire national, à l’instar  de Facebook, IBM, Microsoft ou encore Huawei.  Votre rapporteure Dominique Gillot souligne la volo nté des  organismes de recherche de développer des partenari ats avec les entreprises  pour soutenir la fécondité des initiatives de type start-up (dont il sera  question aux pages suivantes) et surtout d’offrir u n cadre de recherche  stabilisé au-delà du rythme contractuel souvent dén oncé, soit trois ans.  2.  Quelques exemples de centres, de laboratoires et de  projets de  recherche   Les start-up profitent également des atouts des centres  de  recherche français en intelligence artificielle . Ainsi, Heuritech  s’appuie sur  les travaux de recherche de deux laboratoires publi cs le LIP6 (CNRS) et  l’ISIR de l’UPMC (Paris VI) pour proposer sa soluti on logicielle Hakken  d’analyse sémantique, de tagging et classement auto matiques de textes, 
- 102  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        images et vidéos 1, en s’appuyant sur des technologies de machine learning  et  en particulier de deep learning . Les avancées en matière de robotique en  France ont permis à des innovations d’essaimer. Bon  exemple, la start-up  Angus.AI , créée par d’anciens ingénieurs de l’entreprise Aldebaran  ayant  développé la partie logicielle des robots Nao et Pe pper, a ainsi développé  une solution logicielle embarquée dans les robots l eur apportant des  fonctions de base de reconnaissance vocale et facia le et de détection  d’obstacles, qui sont fournies sous la forme d’un k it de développement et  d’interfaces de programmation applicative (souvent désignée par le terme  API  pour Application Programming Interface ), en recourant largement à des  solutions open source . Cette entreprise est déjà sous contrat avec la SN CF.  Le Laboratoire d’informatique pour la mécanique et les  sciences de  l’ingénieur  (LIMSI-CNRS), situé à Orsay, sur le campus de l’Un iversité  Paris-Sud, au sein de l’Université Paris-Saclay, mè ne des recherches sur deux  grands thèmes : la mécanique et l’énergétique, d’un e part, et la  communication homme-machine d’autre part. Les reche rches en interaction  homme-machine portent sur : l’analyse, la compréhen sion et la modélisation  des interactions entre humains et systèmes artifici els dans des contextes et  selon des modalités les plus variées, les interacti ons haptiques, tangibles,  gestuelles et ambiantes, la psychologie des interac tions affectives non  verbales et collectives chez l’humain ainsi que sur  la conception d’interfaces  homme-machine les faisant intervenir, ou, enfin, su r les dispositifs de réalité  virtuelle et augmentée.  Le Laboratoire lorrain de recherche en informatique et  ses  applications  (LORIA-CNRS et Université de Lorraine), basé à Nan cy est un  autre exemple de centre qui mérite d’être cité. Un grand nombre de projets  de recherche fondamentale en intelligence artificie lle référencés sur son site  font appel aux technologies de l’intelligence artif icielle, même s’ils ne sont  pas forcément labellisés intelligence artificielle,  machine learning  ou réseaux  neuronaux. C’est ainsi le cas du projet Orpailleur 2 mené à Nancy en lien avec                                                    1 Ils proposent aussi HeuritechDIP qui permet d’amél iorer sa connaissance des clients et d’anticiper  leurs besoins, évidemment, surtout dans les applica tions de commerce en ligne.  2 Le projet vise la découverte de connaissances dans  les bases de données (KDD pour Knowledge  Discovery in Databases) et utilise l’ingénierie des  connaissances (KE pour Knowledge Engineering).  Le processus de KDD consiste à traiter de grands vo lumes de données pour y découvrir des motifs  qui sont signifiants et réutilisables. En considéra nt les motifs comme des pépites d’or et les bases d e  données comme des régions à explorer, le processus de KDD peut être comparé à la recherche d’or.  Cette analogie explique le nom de l’équipe, où l’or pailleur désigne le chercheur d’or. Le processus de   KDD est interactif et itératif et s’appuie sur troi s opérations principales : la préparation des donné es,  la fouille de données et l’interprétation des motif s extraits. Les connaissances du domaine peuvent  être prises en compte pour guide et améliorer le pr ocessus de KDD, conduisant à la découverte de  connaissances guidée par les connaissances du domai ne (KDDK pour Knowledge Discovery guided  by Domain Knowledge). Les motifs découverts peuvent  être représentés comme des éléments de  connaissances en utilisant un langage de représenta tion des connaissances et servir en résolution de  problèmes. La découverte de connaissances et l’ingé nierie des connaissances sont deux processus  complémentaires qui servent de support aux recherch es menées dans l’EPI Orpailleur. Les domaines  d’application traités par l’EPI Orpailleur sont lié s aux sciences de la vie et comprennent  l’agronomie, la biologie, la chimie et la médecine.  La cuisine, la culture et l’héritage culturel , la  
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 103  -       Inria et dédié à la représentation des connaissance s et au raisonnement.  L’équipe travaille sur l’extraction de données dans  les bases de  connaissances non structurées, et notamment dans le  domaine de la santé, le  même que celui qui est investi par IBM Watson et de  nombreuses start-up.  3.  Une reconnaissance internationale de la recherche f rançaise et  qui s’accompagne d’un phénomène de rachat de start- up et de  fuite des cerveaux lié aux conditions attractives o ffertes à  l’étranger   Outre le départ de Yann LeCun, pour l’Université de  New York puis  pour Facebook, vos rapporteurs ont constaté un phén omène de rachat de  start-up et de « fuite des cerveaux »  lié aux conditions attractives offertes à  l’étranger. Lors de son audition, Stéphane Mallat a  fait valoir que depuis  plusieurs années la quasi-totalité des étudiants issus des masters  spécialisés de l’ENS  quittaient la France aussitôt effectuée leur forma tion.  La reconnaissance des talents français est donc cer taine. Mais cela  conduit à un pillage de nos talents  qui résulte de conditions attractives , à  commencer par les salaires, qui conduisent à une as piration des jeunes  diplômés français spécialisés par les entreprises, le plus souvent des  entreprises américaines. Le mirage de la Silicon Va lley fait sans doute rêver  beaucoup de jeunes esprits brillants mais cette car actéristique n’est pas  propre à la France.  Votre rapporteure Dominique Gillot relève que les s alaires sont  beaucoup plus élevés à San Francisco qu’à Paris, ma is les conditions de vie  n’y sont pas toujours meilleures même avec un salai re bien supérieur (vie  plus chère, infrastructures de transports, de santé , présence d’écoles pour les  enfants etc.) : l’équilibre avantages/inconvénients  est donc plus complexe  qu’il n’y paraît à première vue, surtout que la Fra nce - et Paris en  particulier – représente un écosystème de qualité, avec une vie sociale et  culturelle très riche, un environnement intellectue l stimulant, des lieux de  formation performants et des chercheurs de très bon  niveau.  Il faut permettre à ces jeunes génies, qui sont aut ant d’entrepreneurs  en devenir, de disposer d’opportunités en France et permettre aux start-up  de se développer sans être rachetées par les géants  américains, chinois ou  japonais  dès qu’elles présentent un profil viable. Le cas d ’Aldebaran, racheté  par le japonais SoftBank, illustre le fait que nos talents ne sont pas chassés  que par les firmes américaines du numérique mais au ssi par les géants  chinois ou japonais.                                                                                                                                                  sécurité et la qualité des réseaux de télécommunica tions sont aussi des domaines d’intérêt pour  l’équipe. https://www.inria.fr/equipes/orpailleur   
- 104  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        4.  Une communauté française de l’intelligence artifici elle encore  insuffisamment organisée et visible   La communauté française de l’intelligence artificie lle se constitue  surtout en dehors des institutions - de l’ association française pour  l’intelligence artificielle  (AFIA) en particulier -  à travers les meetups . Le  principal d’entre eux, le « Paris Machine learning Meetup »1, auquel ont été  invités vos rapporteurs, représentent 5 205 membres  au 1 er  mars 2017.  Ses animateurs Igor Carron, Franck Bardol, Frédéric  Dembak et  Isabelle Guyon jouent maintenant un rôle clé dans l a communauté française  de l’intelligence artificielle. Les réunions sont e n général mensuelles et  réunissent des centaines de participants. Il peut, par exemple, s’agir  d’échanges entre développeurs utilisant TensorFlow,  la technologie de  Google mise en open source.   D’autres meetups  peuvent être cités : « Paris.AI Meetup », « Big Data  Paris Meetup », « Deep Learning Meetup Paris », « B ig Data et Machine learning  Paris Meetup » .   D’après les chiffres provisoires du Gouvernement da ns le cadre de la  cartographie réalisée pour France IA il existerait 230 équipes de recherche  publique réparties sur toute la France, dont 50 en région parisienne, ce qui  représenterait 5 300 chercheurs en France , ce nombre de chercheurs  travaillant sur l’intelligence artificielle pouvant  varier de façon significative  selon qu’on y inclut ou pas la recherche SHS portan t sur l’intelligence  artificielle. La compétence de nos chercheurs est r econnue.  Vos rapporteurs ont relevé, par ailleurs, l’existen ce d’une  association française pour l’intelligence artificie lle  (AFIA). Société savante  composée d’environ 300 membres , l’AFIA semble souffrir d’une certaine  fermeture sur elle-même. Elle a été créée en 1993 e n vue de l’organisation de  la conférence internationale en intelligence artifi cielle, ce qui était une  nécessité pour gérer l’organisation, mais c’est don c sous l’effet de la  structuration internationale de ce champ de recherc he plus que de la  mobilisation des chercheurs français que l’AFIA a é té créée. L’association  s’assume comme société savante d’un sous-secteur de  l’informatique. Elle  aurait tout intérêt à transcender ses propres limites pour relever le déf i  d’une intelligence artificielle française ouverte, visible et conquérante .                                                      1 Voir le site https://www.meetup.com/fr-FR/Paris-Machine-learning -applications-group/  et le site  d’Igor Carron http://nuit-blanche.blogspot.fr/   
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 105  -       Tableau de la  communauté française de l’intelligence artificielle   à la fin de l’année 2016    Source : ISAI/Paul Strachman      La communauté française de l’intelligence artificie lle reste encore  insuffisamment organisée et visible. Et la question  du lien avec les  institutions publiques doit être posée.  Votre rapporteure Dominique Gillot fait état de l’expérience des  groupements de recherche interdisciplinaires  dans lesquels il y a aussi des  entrepreneurs. Les groupements de recherche (GdR) o nt pour missions  l’animation de la diffusion des connaissances dans une communauté  thématique , l’effort de rapprochement entre plusieurs types de partenaires  (institutionnels, industriels ou prestataires), le développement d’échanges de  chercheurs, de doctorants ainsi que de faciliter la  mise en place de bourses  doctorales ou postdoctorales. Les GdR poursuivent l ’objectif d’accompagner  la recherche  dans un domaine spécifique et ses applications, de  fédérer une  communauté pluridisciplinaire  et de diffuser les fruits des réflexions  menées , des avancées tant théoriques que technologiques e t des résultats  opérationnels obtenus. Un GdR est une structure originale mise en place par  le CNRS afin d’encourager la coopération des chercheurs des  laboratoires  qu’il rassemble avec des industriels et des organis mes de R&D sur des  objectifs fixés à l’avance. Son rôle consiste à coo rdonner, rapprocher et  évaluer les travaux des équipes concernées. 
- 106  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        5.  La sous-estimation des atouts considérables de la F rance et le  risque de « décrochage » par rapport à la recherche   internationale en intelligence artificielle   La France se situe à un stade intermédiaire en matière de  publications  dans le domaine de l’intelligence artificielle tou t en disposant  d’un réseau de chercheurs très compétents et d’un tissu de start-up très  dynamique . Les atouts considérables du système d’enseignemen t supérieur  et de recherche français sont connus : excellence d e l’école mathématique  française, qualité de la recherche et des dipômés…  On dénombre un total de 240 start-up spécialisées en intelligence  artificielle  (comme, en France, Partnering Robotics, Bayes Impa ct, Yseop,  Prestashop, Adomik, Gorgias, Owkin, Search’XPR, Pla cemeter, Otosense,  Wit.ai, Wca Robotics, Rhythm, Intuitive surgical, L ore.ai, ou au RoyaumeUni BigRobots et en Russie Brainify).  Le tissu de start-up, que l’initiative French Tech vise à renforcer, est  très riche et, selon l’investisseur en intelligence  artificielle, Paul Strachman,  que vos rapporteurs ont auditionné : « La France est l’un des écosystèmes les  plus vibrants en ce qui concerne l’intelligence art ificielle. Malheureusement, cela  n’est pas très su en dehors de la France. Et parfoi s même en-dedans  ». Il convient  de noter qu’il a tenu ces propos lors d’une confére nce « France is AI » qu’il a  organisée à Paris du 16 au 18 septembre 2016. Depui s, cette connaissance  s’est améliorée, la prise en compte de cet atout es t notamment visible du côté  des pouvoirs publics dans la stratégie « France IA ».   
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 107  -       Les start-up françaises en intelligence artificiell e et robotique    Source : ISAI/Paul Strachman    Plusieurs signes positifs peuvent être relevés, don t le succès et  l’ambition internationale d’entreprises françaises,  comme  BlaBlaCar,  Criteo ou Drivy,  et l’ouverture de formations « alternatives » dans  le secteur  du numérique (l’école 42 de Xavier Niel par exemple ).  Selon les données de Stack Overflow, l’Europe compt e désormais  4,7 millions de développeurs  (contre 4,1 millions aux États-Unis). Et Paris  est l’une des capitales européennes qui comptent le  plus grand nombre de  ces profils  très recherchés sur le marché.  Pour Mark Zuckerberg, le Président de Facebook, « la France dispose  de l’une des communautés de chercheurs en intellige nce artificielle la plus forte du  monde  ». De même Mike Schroepfer, le directeur technique  de Facebook,  estimait en 2015 que Paris avait « la plus grande concentration de toute l’Europe  en matière d’intelligence artificielle  ».  Une déclaration qui s’est accompagnée de l’ouvertur e en juin 2015  d’un laboratoire de recherche consacrée à l’intelli gence artificielle à Paris,  justement préférée à Londres, sachant que les trava ux de Facebook dans ce  domaine sont, au niveau mondial, pilotés par le che rcheur Yann LeCun,  rencontré à plusieurs reprises par vos rapporteurs.  
- 108  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Niklas Zennström, P-DG d’Atomico et cofondateur de Skype,  explique dans une tribune au journal Les Échos  que la capitale française  pourrait devenir « le creuset des grands leaders qui révolutionneront le secteur  high-tech dans les dix ans qui viennent  ».  Mais, comme le précise un article de Venture Beat 1, utilisant des  données collectées par Paul Strachman, entre janvie r 2014 et mi-octobre 2016,  une trentaine de start-up françaises spécialisées e n intelligence artificielle  levaient 108 millions de dollars (98 millions d’eur os), quand dans le même  temps, outre-Manche, huit start-up amassaient à ell es seules 900 millions de  dollars (814 millions d’euros). Londres possède don c une avance indéniable  sur Paris  en la matière.  La France, qui est à ce stade encore distancée par le Royaume-Uni,  serait par ailleurs très en avance par rapport aux autres États europée ns . Le  niveau de financement reste encore en-deçà des beso ins.  Selon votre rapporteure Dominique Gillot, la dispon ibilité des  données et des articles auxquels se référer ne rend  pas réellement compte de  la réalité nationale dans une démarche où les chose s évoluent très vite :  chaque jour des start-up naissent de la rencontre e t de la volonté de jeunes  (ou de moins jeunes) diplômés qui découvrent les op portunités de lier  l’emploi et la valeur. Même si tous ces créateurs d e start-up ne rêvent pas  d’être cotés en bourse et d’être rachetés par de gr ands groupes, l’intérêt de  ces derniers existe : ils voient dans cette efferve scence un moyen  d’expérimenter de nouvelles pratiques, des découver tes qui pourront se  révéler fructueuses, dans un cadre beaucoup plus so uple et réactif que celui  contraint par des règles du droit du travail et de la législation vécue comme  un carcan. Les structures qui investissent dans des  secteurs peu identifiés  garantissent la plasticité et la réactivité de ces initiatives dont il faudra  analyser la longévité.                                                    1 http://venturebeat.com/2016/11/06/france-makes-its -bid-to-be-recognized-as-a-global-ai-hub/ 
PREMIÈRE  PARTIE  :   ÉLÉMENTS DE CONTEXTE   - 109  -       Les start-up françaises en intelligence artificiell e par domaine  d’application    Source : Gouvernement    L’exemple de Snips  Snips.ai  est une start-up connue du secteur de l’intelligen ce artificielle,  créée en 2013, par Rand Hindi (prix du MIT 30 en 20 15), Mael Primet et Michael  Fester. Leur dernière levée de fonds de 5,7 million s d’euros en juin 2015 présente la  particularité d’associer Bpifrance avec des investi sseurs américains, en plus de  business angels  tels que Brent Hoberman et Xavier Niel. L’équipe c omprend  35 personnes : des data-scientists, des développeur s, designers et quelques  marketeurs. Leur positionnement est large et un peu  vague : rendre la technologie  invisible et les usages intuitifs via  de l’intelligence artificielle.  À ce titre, la start-up a développé des application s expérimentales telles  que : snips (un ensemble d’applications de recherch e pour iOS dont un clavier  virtuel intelligent pour la recherche d’adresses), Tranquilien (qui prédit les places  disponibles dans les trains de banlieue), Parkr (la  même chose pour prédire les  places de parking), Flux (qui identifie le trafic m obile en s’appuyant sur les données  des smartphones), RiskContext et SafeSignal (identi fication de risques d’accidents  sur la route). Elle travaille aussi sur des applica tions verticales : pour les véhicules  connectés, dans l’hôtellerie, la maison connectée e t les loisirs numériques. Elle  s’appuie sur du deep learning , des modèles probabilistiques, du traitement du  langage, de la gestion de graphes et du cryptage de  données pour garantir le  respect de la vie privée. 
- 110  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        CardioLogs Technologies  a été créée en 2014 une solution  d’interprétation automatique des électrocardiogramm es (ECG) en temps réel  s’appuyant sur du machine learning . Il ne s’agit pas à ce stade d’une  « ubérisation » des actes des cardiologues mais bie n de permettre un suivi  plus régulier des patients à risques ou atteints de  maladies chroniques.  L’attractivité française peut également être relevé e avec les cas des  entreprises étrangères ayant fait le choix de condu ire une part de leur  recherche en intelligence artificielle en France.    Exemples d’entreprises étrangères ayant fait le cho ix de  conduire une part de leur recherche en intelligence  artificielle en France      Source : ISAI/Paul Strachman    Il convient en outre de relever l’existence à l’étr anger d’une  importante diaspora des chercheurs français en inte lligence artificielle .  Elle pourrait sans doute être davantage connue, ani mée, considérée et mise à  contribution.  Au final, vos rapporteurs déplorent la sous-estimation des atouts  considérables de la France  mais ils appellent l’attention sur la nécessité  d’une vigilance forte sur le risque de « décrochage »  par rapport à la  recherche internationale en intelligence artificiel le. 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 111  -         DEUXIÈME PARTIE :   LES ENJEUX DE L’INTELLIGENCE ARTIFICIELLE    I.  LES CONSÉQUENCES ÉCONOMIQUES ET SOCIALES DE  L’INTELLIGENCE ARTIFICIELLE  A.  D’IMPORTANTES TRANSFORMATIONS ÉCONOMIQUES EN COURS  OU À VENIR  1.  L’évolution vers une économie globalisée dominée pa r des  « plateformes »  Ces technologies, leurs usages et leurs artisans ay ant été décrits, il  importe d’identifier leurs impacts sociaux et économiques potentiels , pour  en relever ensuite les enjeux éthiques et juridique s.  Alors qu’Isaac Asimov affirmait qu’« il est une chose dont nous avons  maintenant la certitude : les robots changent la fa ce du monde et nous mènent vers  un avenir que nous ne pouvons encore clairement déf inir  » (Le Cycle des robots ), les  transformations que nous connaissons d’un point de vue économique et  technologique semblent être les signes avant-coureurs de l’évolution vers  une économie globalisée de « plateformes » . Vos rapporteurs ont eu  confirmation de cette intuition lors de leur déplac ement aux États-Unis.  D’après Brian Krzanich, P-DG d’Intel, premier fabri cant mondial de  microprocesseurs, « l’intelligence artificielle n’est pas seulement le prochain raz de  marée de l’informatique, c’est aussi le prochain to urnant majeur dans l’histoire de  l’humanité  ». Il est vrai qu’elle peut devenir l’un des fonde ments de la société  et de l’économie de demain.  On parle des « GAFA » , parfois des « GAFAMI » , mais il serait plus  juste de parler des « GAFAMITIS »1, « NATU »2 et « BATX »3. Ces exemples  emblématiques des bouleversements en cours sont les  prémisses de la place  dominante et monopolistique occupée par quelques en treprises  dans un  contexte d’économie globalisée de « plateformes ». Un accroissement  significatif des investissements dans la recherche en intelligence artificielle  est constaté. Chacune de ces entreprises est entrée  dans une course pour  acquérir une position de pointe dans les technologi es d’intelligence  artificielle afin de tirer profit de la situation d ominante qui en résultera .  Comme l’affirme Guillaume Devauchelle, directeur de  la R&D de Valeo  « dans la ruée vers l’or en Amérique, ceux qui ont fa it fortune, ce sont surtout les                                                    1 Google, Apple, Facebook, Amazon, Microsoft, IBM, Tw itter, Intel et Salesforce. Ces entreprises  américaines représentent la pointe de la recherche et des applications de l’IA.  2 Netflix, Airbnb, Tesla et Uber.  3 L’expression désigne les géants chinois du numériq ue : Baidu, Alibaba, Tencent et Xiaomi. 
- 112  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        vendeurs de pioches et de pelles. C’est exactement ce que nous sommes : nous  fournissons des technologies  ». Grâce à leurs efforts en R&D et aux rachats de  start-up, les grands équipementiers sont bien posit ionnés dans la chaîne de  valeur automobile. Valeo fait la course en tête et,  avec la voiture autonome,  se positionne d’ores et déjà comme la future principale plateforme de  fourniture de technologies  innovantes aux constructeurs automobiles .  En effet, les technologies d’intelligence artificielle renfor cent le  modèle « the winner takes it all  », ou au moins « the winner takes it most  »,  ce qui pourrait bien conduire à une concentration horizontale  progressive  des grandes entreprises, conduisant au monopole de « plateformes »  dominant une économie globalisée.  On assiste à une montée en puissance significative du nombre des  acquisitions , après 140 start-up en intelligence artificielle a chetées de 2011 à  2016, on a vu, en 2016, 40 start-up en intelligence  artificielle être achetées par  des grandes entreprises, pour des valeurs allant de  30 millions à 400 millions  de dollars.    Le mouvement de concentration autour de l’intellige nce artificielle  visible dans les stratégies d’acquisitions     Source : Gouvernement                  Légende :          En mars 2017, un partenariat entre IBM et Salesforce , premier  employeur de San Francisco (dont vos rapporteurs on t rencontré des  responsables en son siège), a été conclu sous l’app ellation : « Watson meets 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 113  -       Einstein » , du nom de chacun des systèmes d’intelligence arti ficielle mis en  place par ces deux entreprises. Il s’agit d’une exp loitation des technologies  de manière associée, à travers une interface de pro grammation applicative  (souvent désignée par le terme API, soit Application Programming Interface ).  Vos rapporteurs observent qu’Intel développe sa pla teforme de  solutions en intelligence artificielle Nervana. L’e ntreprise Intel représente, à  elle seule, 97 % des serveurs de data centers  opérant dans le domaine de  l’intelligence artificielle. Ils relèvent qu’une alliance stratégique a été nouée  entre Google et Intel  afin de fournir une infrastructure multiple sur le  cloud ,  ouverte, flexible et sécurisée.  Dans le secteur médical, des « Uber » de la santé  pourraient gagner  une place de premier plan, le site « mondocteur.fr » constituant un exemple  de plateforme à fort potentiel marquée par la conve rgence NBIC.  L’analyse de données et les outils de prédiction so nt devenus des  incontournables des offres informatiques pour les e ntreprises, avec  l’hébergement dans le cloud . IBM, Amazon, Baidu, Microsoft et Google y  travaillent depuis plusieurs années. Des sociétés s pécialisées dans les  services professionnels, comme Oracle, Salesforce o u SAP, s’y déploient.  Mais, là où ses concurrents se concentrent sur un s ecteur ou un produit en  particulier, IBM imagine Watson comme une plateform e capable de  s’adapter à tous les besoins d’une entreprise.   Au début de l’année 2014, IBM avait annoncé consacr er un milliard  de dollars pour transformer Watson en division indé pendante. Deux ans  plus tard, il ajoutait 3 milliards de dollars dans la balance, cette fois-ci  consacrés à l’Internet des objets, puis 200 million s de dollars pour achever le  centre de recherche de Munich. IBM a aussi investi des milliards de dollars  dans des entreprises et start-up spécialisées pour nourrir Watson de données  diverses : dans la météorologie, la reconnaissance d’image, le domaine  médical, etc. Le nombre d’employés affectés à Watson frôle désormais les  10 000 personnes , dont 800 en France. Selon l’entreprise, aujourd’h ui, « à l’ère  des systèmes cognitifs, les systèmes peuvent appren dre après des expériences,  détecter des corrélations, créer des hypothèses, et  aussi mémoriser les résultats et en  tirer des enseignements ».  Uber a créé un laboratoire de recherche sur l’intel ligence artificielle à  San Francisco. L’entreprise a en effet racheté la s tart-up « Geometric  Intelligence » pour créer ce laboratoire nommé « Ub er AI Labs ». Les  applications potentielles sont innombrables. Mais à  ce stade, le laboratoire  aurait pour mission de se concentrer sur deux innov ations en particulier :  améliorer l’algorithme d’Uber pour faciliter la ren contre entre un chauffeur  et un passager et trouver de nouvelles techniques p our construire un  véhicule autonome performant. En août 2016, Uber aj outait Otto à son actif,  une jeune pousse qui développe des kits pour rendre  les camions autonomes,  un contrat de 680 millions de dollars.  
- 114  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Il convient d’observer que Google a également rache té, en 2013,  Waze, la start-up israélienne à l’origine du fameux  service d’information en  matière de trafic routier en temps réel, pour 1 mil liard de dollars.  Les  entreprises du secteur automobile achètent des entr eprises du  numérique ou nouent des partenariats  (Google-Fiat-Chrysler, GoogleHonda, Amazon-Ford, BMW-IBM, BMW-Mobileye, Volvo-Ub er, Tesla-Uber,  Renault-Nissan-Microsoft). BMW se rapproche d’IBM p our travailler sur le  système cognitif de Watson, les deux entreprises on t ainsi annoncé un  partenariat au travers duquel elles travailleront s ur le système cognitif de  Watson pour améliorer la personnalisation de l’expé rience de conduite.  Après le rapprochement entre Google et le groupe Fi at-Chrysler depuis mai  2016, c’est le constructeur japonais Honda qui s’es t rapproché de  Google-Waymo. Honda est déjà partenaire du service asiatique Grab qui  teste des solutions similaires. Grab travaille sur des voitures autonomes  capables d’évoluer seules sur les routes dès 2020 m ais requérant la présence  d’un conducteur, alors que Waymo veut se dispenser totalement du  chauffeur.  Amazon a réussi à intégrer son système de domotique  Alexa dans  les voitures de Ford, ce qui permettra au propriéta ire de contrôler les objets  connectés de sa maison depuis sa voiture et vice ve rsa. Quant à Microsoft, il  apporte les conférences audio de Skype dans les voi tures Volvo, son assistant  vocal Cortana chez BMW et Nissan. Les algorithmes e t caméras intelligentes  de Mobileye sont utilisés par BMW pour déployer une  flotte de 40 véhicules  autonomes cette année.  Pour conclure en ce qui concerne le secteur automob ile, Rémi  Cornubert, d’AT Kearney, explique qu’avant le monde  automobile était  « simple, très pyramidal : le constructeur était le d onneur d’ordres qui travaillait  avec des fournisseurs. Aujourd’hui, avec la révolut ion de la connectivité, de la  voiture autonome et des services à la mobilité, les  cloisons sautent, il est impossible  pour un constructeur de tout maîtriser  ». Carlos Ghosn, président de RenaultNissan reconnaît qu’« on ne peut pas tout faire  ».  Vos rapporteurs relèvent que le patronat français s’inscrit dans la  démarche de transformation en cours . Le MEDEF a ainsi préparé en 2017 le  projet « Métamorphose », qui vise à définir une pyr amide de changement sur  quatre niveaux : un socle de mobilisation sur la révolution numérique , des  big data  et des NBIC, un socle de formation , un socle d’accompagnement ,  avec les incubateurs et les écosystèmes du numériqu e et, enfin, la pointe du  financement , permettant la transformation des PME.   
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 115  -       Le projet « Métamorphose » du MEDEF  L’enjeu des objets connectés permet de capter de no mbreuses données, qui  deviennent les ressources fondamentales de nombreux  domaines en devenir , à l’instar de  l’intelligence artificielle ou de la chaîne de bloc s ( Blockchain ).  À ce titre, l’intelligence  artificielle était très présente au Consumer Electronics Show  de Las Vegas en 2016.  L’intelligence artificielle se niche dans des appli cations utilisées au quotidien , telles que  les correcteurs orthographiques. L’enjeu essentiel de l’intelligence artificielle est d’alimenter  l’apprentissage profond ( deep learning ) et l’apprentissage automatique ( machine learning ),  auxquels les « GAFAMI » s’attellent.  Le MEDEF est actuellement en pleine préparation du projet « Métamorphose ». Ce  projet vise à définir une pyramide de la métamorpho se bâtie sur quatre niveaux. Tout  d’abord, cette pyramide repose sur un socle de mobilisation sur la révolution numérique ,  des big data  et des NBIC. Ensuite s’ajoute un socle de formation , notamment avec le travail  mené sur les campus numérique qui fournissent des o utils d’évaluation de numérisation  des entreprises. Au-dessus, se trouve le socle d’accompagnement : incubateurs,  écosystèmes de start-up du numérique, pour accompag ner les petites et moyennes  entreprises (PME) qui ont besoin de se transformer.  Enfin, au sommet se trouve la pointe  du financement , qui a pour objectif la création de fonds de finan cement permettant la  transformation des PME.   Ce projet vise deux cibles : les cent mille PME qui  doivent se transformer, et les  start-up françaises . Il est impératif, selon le MEDEF, que les jeunes pousses se transforment  et mutent en PME, voire en grands groupes internati onaux. Ces entreprises émergentes  regorgent de talents et de chercheurs de haut nivea u ; il serait dommage que la France se  fasse piller ses talents. Il est donc indispensable  d’aider les start-up à se transformer grâce à  un financement français. Cela implique de garder le s expertises et centres de décision en  France, malgré la mondialisation de ce domaine, et que certaines réformes se fassent.  Un second niveau, au niveau européen, est également  nécessaire, au travers de la  coopération avec des partenaires tels que l’Allemag ne.  Source : Intervention de Pierre Gattaz, président d u MEDEF, lors de la journée « Entreprises française s et  intelligence artificielle » organisée par le MEDEF et l’AFIA le 23 janvier 2017  2.  Un risque de redéfinition, sous l’effet de ce nouve au contexte  économique, des rapports de force politiques à l’éc helle  mondiale   Dans ce nouveau contexte économique, les rapports de force  politiques pourraient être progressivement boulever sés  à une échelle  mondiale. Le poids pris par les grandes entreprises  privées plateformistes,  GAFAMITIS 1, NATU 2 et BATX 3 fait courir d’importants risques au principe  traditionnel de souveraineté ainsi qu’aux systèmes démocratiques que nous  connaissons.                                                    1 Google, Apple, Facebook, Amazon, Microsoft, IBM, T witter, Intel et Salesforce.  2 Netflix, Airbnb, Tesla et Uber.  3 L’expression désigne les géants chinois du numériq ue : Baidu, Alibaba, Tencent et Xiaomi. 
- 116  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        La question  dépasse le sujet de la colonisation numérique et ce lui  de la domination américaine, voire chinoise, ou de pays émergents comme  l’Inde . Ces questions devront faire l’objet d’une grande attention de la part  des pouvoirs publics, car les mouvements de concent ration capitalistique qui  sont en cours vont dans le sens décrit précédemment , à savoir celui d’une  économie globalisée dominée par des « plateformes » , situées au-dessus des  nations. Les monopoles résultant d’une concentratio n horizontale puis  verticale pourraient disposer d’une puissance à l’échelle mondiale sans  équivalent historique connu.   3.  Des bouleversements annoncés dans le marché du trav ail :  perspectives de créations, d’évolutions et de dispa ritions  d’emplois  La résolution relative aux règles de droit civil sur l a robotique   adoptée le 16 février 2017 par le Parlement europée n, qui fait suite au  rapport de la députée européenne Mady Delvaux, esti me, dans l’un de ses  considérants, « que l’utilisation généralisée de robots pourrait ne  pas entraîner  automatiquement une destruction d’emplois, mais que  des emplois moins qualifiés  dans les secteurs à forte intensité de main-d’œuvre  risquent d’être plus vulnérables à  l’automatisation  ». Animé par la même préoccupation, le réseau de l ’European  Parliamentary Technology Assessment  (EPTA), auquel appartient l’OPECST, a  consacré en 2016 sa conférence annuelle au thème de  l’impact des nouvelles  technologies numériques et robotiques sur le marché  du travail. L’ensemble  des contributions présentées par les dix-sept organ es d’évaluation  scientifique membres de l’EPTA ont été regroupées s ous le titre « L’avenir du  travail à l’ère numérique  »1.  Sur cette question hautement sensible, vos rapporte urs ont  entendu des pronostics très contrastés lors de leur s auditions.  Selon Cédric  Sauviat, président de l’association française contr e l’intelligence artificielle  (AFCIA), «  ce ne sont pas seulement les emplois de la classe moyenne et des  ouvriers qui sont menacés, mais également des emplo is d’expertise, comme les  emplois de médecins ou d’avocats. L’intelligence ar tificielle touche des domaines de  plus en plus vastes ; de fait, toutes les couches d u marché du travail seront  concernées par l’intelligence artificielle ». En sens inverse, Marie-Claire CarrèreGée, présidente du Conseil d’orientation pour l’emp loi (COE) estime que le  rôle de cette instance est « d’anticiper, autant que faire se peut, les conséque nces  du progrès technologique en cours sur l’emploi, dan s un contexte où le débat public  est marqué par des études donnant au pourcentage pr ès le nombre d’emplois  détruits. La situation est très anxiogène. Certes, la crainte du chômage est un grand  classique à chaque vague d’innovation technologique . Keynes lui-même avait prédit  un chômage massif. Pourtant, l’histoire montre que depuis toujours le progrès  technologique a créé des emplois  ».                                                     1 Pour consulter les actes de la conférence annuelle  2016 de l’EPTA :  http://epub.oeaw.ac.at/ita/ita-projektberichte/EPTA -2016-Digital-Labour.pdf  
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 117  -       Ces divergences d’analyses s’expliquent dans une la rge mesure par  des différences d’approches méthodologiques et par la difficulté inhérente  à toute démarche prospective dans ce domaine éminem ment mouvant :  finalement, ce sont les convictions personnelles qu i l’emportent lorsqu’il  s’agit d’apprécier globalement l’incidence future d e l’intelligence artificielle  sur le marché du travail.  Pourtant, l’impact des innovations technologiques s ur le volume et  la nature des emplois est loin d’être un sujet d’ét ude nouveau pour la science  économique. Depuis les débuts de la révolution indu strielle, le débat  académique oppose les « techno-optimistes » et les « techno-pessimistes ».   La littérature économique n’aboutit pas à des concl usions univoques quant  aux effets des évolutions technologiques sur l’empl oi. Une première  distinction est à faire entre les approches micro-é conomique, sectorielle et  macro-économique. Les préoccupations en termes de gains de productivi té  et de réduction de la masse salariale sont prédomin antes au niveau de  chaque entreprise prise isolément, mais les suppres sions d’emplois qui en  résultent peuvent être, au moins, compensées au niv eau global de la branche  ou de l’économie nationale, grâce à des effets de b aisse des prix et de hausse  de la demande. Une seconde distinction est à faire selon la nature  des  innovations technologiques. Une innovation de production  va permettre de  produire davantage avec moins de travail. Mais une  innovation de produit  ou de service peut créer des emplois, en étant à l’origine d’un n ouveau  marché.  La théorie économique ne tranchant pas ce débat vie ux de plus de  deux siècles, il est instructif d’examiner les prin cipales conclusions  empiriques des études rétrospectives  qui ont tenté d’évaluer les effets des  vagues d’innovation successives au cours des trente  dernières années. Le  récent rapport du Conseil d’orientation pour l’empl oi (COE) intitulé  « Automatisation, numérisation et emploi  »1 recense et analyse ainsi seize études  rétrospectives parues sur ce sujet entre 2009 et 20 16. Celles-ci font apparaître  très nettement un double processus de destruction et de création d’em ploi .  Elles soulignent également l’importance des effets indirects positifs sur  l’emploi des innovations de produits, qui viennent plus que contrebalancer  les effets directs négatifs des innovations de proc édés.  Ces études rétrospectives se heurtent à une question de  méthodologie délicate  : comment apprécier les effets distincts des  technologies numériques et robotiques sur l’emploi,  par rapport à d’autres  progrès technologiques ou à d’autres facteurs d’évo lution du marché du  travail ? Les données statistiques de base qui le p ermettraient ne sont pas  toujours disponibles et ce genre d’appréciation com porte inévitablement une  part de convention. L’OCDE a publié en 2016 une étu de de M. Arntz,                                                    1 Pour consulter le rapport du Conseil d’orientation  pour l’emploi :  http://www.coe.gouv.fr/IMG/pdf/COE_170110_Rapport_A utomatisation_numerisation_et_emploi_  Tome_1.pdf  
- 118  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        T. Gregory et U. Zierahn sur « Les risques de l’automatisation pour l’emploi »1,  analysant comparativement 18 États membres, dont la  France, sur la période  1990-2012. Elle parvient à la conclusion que les in vestissements en  technologies de l’information et de la communicatio n n’ont pas d’effets  négatifs sur l’emploi dans ces pays, au niveau agré gé, compte tenu des  phénomènes de compensations. Pour l’avenir, cette étude de l’OCDE estime  qu’en moyenne 9 % des emplois au sein de ces pays m embres sont  menacés par l’automatisation.   D’autres études prospectives parues ces dernières a nnées sur le  même sujet se sont focalisées sur le risque de dest ruction d’emplois lié aux  avancées de la numérisation et de l’automatisation.  Une étude originale et  fondatrice de la Oxford Martin School , conduite par Carl Benedikt Frey et  Michael A. Osborne 2, a suscité en 2013 une forte inquiétude en avançan t que  l’automatisation représentait un risque pour 47 % des emplois aux  États-Unis . En 2014, une étude du cabinet de conseil McKinsey  estime que  60 % de tous les métiers pourraient voir automatise r 30 % de leurs  activités .  En 2014 également, une étude du cabinet Roland Berg er 3 estime,  pour la France, que 42 % des métiers présentent une probabilité  d’automatisation forte du fait de la numérisation de l’économie, et que  3 millions d’emplois pourraient être détruits par l a numérisation à l’horizon  2025. Cette étude relève que, désormais, les métier s manuels ne sont pas les  seuls à être automatisables mais que des tâches int ellectuelles de plus en plus  nombreuses pourront faire l’objet d’une prise en ch arge par les outils  numériques.  Lors de sa réunion à Davos en janvier 2017, le Foru m économique  mondial a également rendu public un pronostic inqui étant, en considérant  que la « quatrième révolution industrielle  », celle de l’intelligence artificielle,  des objets connectés et de l’impression 3D, suscite  de nouveaux risques  mondiaux et tend à détruire plus d’emplois qu’elle n’en crée. Ce qui se  traduirait par une perte nette de 5,1 millions d’emplois dans 15 écono mies  nationales , dont la France, d’ici à 2020.  Vos rapporteurs invitent à ne pas céder au « techno -pessimisme »  devant cette succession de rapports alarmistes. Ces  prévisions leur  paraissent trop axées sur le seul aspect des destru ctions d’emplois, qui est  le plus facile à évaluer, et insuffisamment sur cel ui des créations  d’emplois, que les études rétrospectives invitent à  ne pas négliger, même                                                    1 Pour consulter le rapport de l’OCDE : http://www.oecd-ilibrary.org/social-issues-migratio nhealth/the-risk-of-automation-for-jobs-in-oecd-coun tries_5jlz9h56dvq7-en   2 Pour consulter l’étude de la Oxford Martin School :  http://www.oxfordmartin.ox.ac.uk/downloads/academic /The_Future_of_Employment.pdf   3Pour consulter l’étude du cabinet de conseil Roland  Berger :  https://www.rolandberger.com/publications/publicati on_pdf/les_classes_moyennes_face___la_transf  ormation_digitale___roland_berger.pdf    
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 119  -       si leur caractère indirect les rend plus difficile à quantifier.  À cet égard,  une variable essentielle pour l’ampleur et le sens positif ou négatif des effets  sur l’emploi de cette « quatrième révolution industrielle  » est le décalage  toujours possible entre le rythme de diffusion des innovations liées à  l’automatisation, la numérisation et l’intelligence  artificielle au sein de  l’économie et de la société, et la temporalité des réactions d’adaptation sur le  marché de l’emploi. Même si les phases de transition peuvent être  délicates, vos rapporteurs sont convaincus qu’à ter me ces innovations  multiples, qui se renforcent mutuellement, auront g lobalement un effet  positif sur le volume total des emplois, comme sur l’intérêt des tâches  professionnelles et la qualification des métiers.  Dans le cas de la France, l’étude prospective que l e Conseil  d’orientation pour l’emploi a présentée en janvier 2017, précédemment  évoquée, a vocation à devenir une référence par son  ampleur et sa précision  méthodologique. Cette étude conclut que l’automatisation et la  numérisation devraient avoir un impact relativement  limité en termes de  créations ou suppressions d’emplois, mais probablem ent important sur la  structure des emplois et le contenu des métiers.   Depuis les années 1980, l’évolution de la structure  des emplois en  France a profité surtout aux plus qualifiés. Les no uvelles technologies sont  plus facilement substituables aux emplois auxquels sont associés des tâches  manuelles et cognitives routinières , correspondant à des niveaux de  qualification intermédiaires. Le mouvement de complexification des  métiers  existants,  sous l’effet des technologies nouvelles, est marqu é par un  essor des compétences analytiques et relationnelles . L’évolution des  compétences demandées sur le marché du travail est aussi induite par  l’émergence de nouveaux métiers dans le domaine du numérique, qui  recouvrent des tâches nouvelles et plus complexes.  La situation actuelle du marché de l’emploi au rega rd des nouvelles  technologies place la France dans une position inte rmédiaire en Europe.  Selon les données d’Eurostat 1, environ 8 millions de personnes étaient  employées comme spécialistes des technologies de l’ information et de la  communication dans l’Union européenne, soit 3,5 % d e l’emploi total.  Toutefois, ce taux moyen recouvre des disparités im portantes entre les pays,  le secteur des TIC représentant plus de 6 % de l’em ploi en Finlande et en  Suède, mais seulement 1,2 % en Grèce. La France se situe légèrement  au-dessus de la moyenne européenne, avec un taux de  3,6  %. Le secteur de  la robotique est encore très marginal en termes d’e mplois. Selon les chiffres  de la Fédération internationale de robotique, il re présenterait environ  300 000 emplois directs dans le monde. En France, l a filière robotique  regroupait en 2012 un peu plus de 7 000 emplois, se lon les chiffres du Syntec  numérique.                                                    1 « Les compétences numériques »,  Communiqué de presse d’Eurostat n° 207/2016, octob re 2016. 
- 120  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        La méthodologie retenue par le COE dans son étude r epose sur une  approche qualitative et sectorielle, fondée sur les  données issues de l’enquête  « Conditions de travail » de la DARES, et est décom posée par tâche et par  métier. Cette étude vise à affiner les approches pu rement macroéconomiques, et montre que :  - moins de 10 % des emplois existants présentent un c umul de  vulnérabilités susceptibles de menacer leur existen ce  dans un contexte de  numérisation et d’automatisation ;  - la moitié des emplois existants est susceptible d’é voluer dans  leur contenu de manière significative ou très impor tante  ;  - le progrès technologique devrait continuer à favoriser plutôt  l’emploi qualifié et très qualifié .  Vos rapporteurs relèvent que des emplois très quali fiés, du type  statisticiens, analystes et conseillers financiers ou bancaires, médecins,  notamment radiologues, etc., sont d’ores et déjà im pactés par le recours à  des applications intelligentes, agiles, interconnec tées et ultra rapides.  Il en  va de même pour les métiers recourant à des techniq ues de simulation ou de  projection dans les domaines de l’environnement, de  l’urbanisme, de la  gestion des flux, des transports et, d’une manière générale, de tous les  systèmes complexes.  L’étude prospective du COE tente également d’antici per les effets  possibles de l’automatisation et de la numérisation  sur la localisation des  emplois.  Ces effets apparaissent eux aussi diversifiés. En abaissant le coût de  la distance géographique, les technologies de l’inf ormation et de la  communication ont jusqu’à présent favorisé la déloc alisation de certaines  activités routinières industrielles et de services vers des pays à faibles coûts  de main-d’œuvre. En sens inverse, l’automatisation pourrait atténuer cette  tendance, voire l’inverser en incitant à des relocalisations d’activités  précédemment déplacées vers les pays émergents. Tou tefois, même si  certaines prémisses de ce phénomène de relocalisati on sont perceptibles,  celui-ci est encore loin de constituer un mouvement  de grande ampleur.  Enfin, toujours dans une approche en termes de loca lisation des  emplois, l’étude du COE estime que ces nouvelles te chnologies devraient  avoir un impact différencié sur la répartition géographique des emplois  sur le territoire national . Les régions du territoire national dans lesquelle s  les secteurs industriels traditionnels faiblement i ntensifs en technologie  représentent une grande part de l’emploi, et caract érisées par une forte  densité en travailleurs peu qualifiés, sont les plu s exposées au risque des  destructions d’emplois sous l’effet de l’automatisa tion. Inversement, les aires  urbaines, et notamment les métropoles, pourraient b énéficier de certains  « effets d’économies d’agglomération », ainsi que d e leurs réserves en emploi  pour les compétences complémentaires des nouvelles technologies.   
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 121  -       Vos rapporteurs soulignent que le débat sur l’impac t du  numérique en matière d’emploi n’est pas propre à l’ intelligence  artificielle :  la question se pose beaucoup plus largement, puisq ue les  conséquences du progrès technologique sur le marché  du travail sont  particulièrement visibles depuis la révolution indu strielle, et n’ont d’ailleurs  pas débuté avec celle-ci... Le développement de l’i nformatique et de la  robotique implique la disparition de certains emplo is, souvent peu qualifiés,  mais en crée aussi de nouveau, plus qualifiés.  Les études disponibles ne s’intéressent souvent qu’ aux destructions  brutes d’emplois, alors qu’il y aura très probablem ent d’importantes  créations d’emplois,  non identifiées à ce jour. Dès 1964, un manifeste  alarmiste adressé au Président des États-Unis, Lynd on B. Johnson, et signé  de plusieurs prix Nobel et chercheurs avait dénoncé  une « large vague de  chômage technologique  » causée par « la combinaison d’ordinateurs et de machines  automatiques et autonomes  ».  En 1981, Alfred Sauvy, dans son livre « Informatisation et emploi  »  affirmait : « Ne vous plaignez pas que le progrès technique détru ise des emplois, il  est fait pour ça !  ». Vos rapporteurs jugent la formule un peu provoc atrice  dans un contexte de chômage élevé mais l’estiment p ertinente en période de  plein emploi.  La robotisation pousse les travailleurs vers des mé tiers de plus  en plus intéressants, dès lors que des emplois nouv eaux apparaissent et que  les premiers ont les compétences nécessaires pour l es occuper, ou sont aptes  à les acquérir. Vos rapporteurs estiment donc indispensable et urge nt  d’adapter le système éducatif à ces nouveaux métier s et de développer une  offre de formation professionnelle adéquate, afin d e garantir aux  travailleurs la souplesse de reconversion dont ils ont besoin.   Il y aura aussi d’importantes évolutions en contenu des emplois et  des tâches  et, au-delà de la stricte robotisation, il exister a de plus en plus de  coopération hommes-machines , à travers des interfaces hommes-machines  multimodales, enrichies et transparentes. Cette coo pération devrait être  heureuse.  Votre rapporteure Dominique Gillot propose de réfléchir à un  nouveau mode de financement du système de protectio n sociale, qui serait  un complément des cotisations existantes et qui pou rrait consister en un  prélèvement additionnel aux cotisations sociales, a ssis sur les agents  autonomes et les robots, dans la mesure où ces disp ositifs remplacent des  emplois précédemment occupés par des êtres humains . Elle juge une telle  proposition plus précise que celle de taxe sur les robots qui circule à la suite  de la première version du rapport de Mady Delvaux 1. Selon votre  rapporteure, il faut que le produit de cette imposi tion n’aille pas au budget  de l’État et finance plutôt les régimes sociaux, en  particulier les assurances  chômage, maladie et vieillesse.                                                     1 Bill Gates a fait cette proposition plus récemment  https://www.weforum.org/agenda/2017/02/billgates-this-is-why-we-should-tax-robots   
- 122  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Votre rapporteur Claude de Ganay se déclare, quant à lui, opposé à  toute taxe spécifique sur les activités automatisée s, intelligence artificielle  comme robots, remplaçant des emplois occupés par de s êtres humains, y  compris un prélèvement assis sur les cotisations so ciales. Un mécanisme de  ce type constituerait, selon lui, un mauvais signal, pouvant avoir comme  effet pervers de décourager la recherche, l’innovat ion et l’activité  économique . La TVA et l’IS s’appliquent déjà à ces activités.  Quand ils ne le  font pas parfaitement, il est toujours possible d’y  veiller en étendant  l’assiette de ces impôts. Il n’y a donc pas lieu de les taxer davantage en  instaurant un nouveau prélèvement qui leur serait s pécifique.  B.  LA SOCIÉTÉ EN MUTATION SOUS L’EFFET DE L’INTELLIGEN CE  ARTIFICIELLE  1.  Les défis lancés par l’intelligence artificielle au x politiques  d’éducation et de formation continue  Paul Dumouchel et Luisa Damiano, dans Vivre avec les robots, Essai  sur l’empathie artificielle,  estimaient en 2016 que « vivre avec les robots peut être  l’occasion d’un avenir meilleur, non pas économique ment mais moralement et  humainement  ». L’éducation peut en effet être un facteur à la fois  levier et  bénéficiaire des avancées en intelligence artificie lle .  Intel a, par exemple, noué un partenariat avec Cour sera, une vaste  plateforme d’enseignement en ligne, pour justement y proposer des cours en  intelligence artificielle dès 2017. L’approche de l ’entreprise consiste à offrir  une offre allant du logiciel au matériel (processeu r), en passant par la  formation.  La relation émetteur-récepteur est transformée  et modifie tant la  pédagogie que les principes d’évaluation . Les moyens de prédire la  réussite  des élèves  et d’optimiser les enseignements  seront précisés par les  systèmes d’intelligence artificielle. Ces derniers permettront la  différenciation des méthodes d’apprentissages, voir e des contenus enseignés,  la personnalisation  devant être adaptée à la diversité des élèves. Jea n-Marc  Merriaux, directeur général de Canopé, a donné l’ex emple du projet e-fran ,  qui liera aussi bien des pédagogues que des cherche urs et des start-uppers .  Matador, qui était à la base un jeu de plateau tran sformé dans un  environnement numérique, a ainsi été développé. Le projet repose sur un  monitoring individuel d’apprentissage du calcul men tal par chaque élève.  Plus l’élève jouera en classe et à la maison et mie ux l’enseignant connaîtra  ses compétences acquises et non acquises. Il s’agit  de travailler sur le  parcours d’un élève qui sera mis en rapport avec to us les autres élèves de  son niveau scolaire. L’interaction et l’horizontali té constituent par  conséquent des éléments importants de ce type de pr ojet. E-fran  reposera sur  mille cinq cents élèves pendant une année scolaire,  avec l’objectif d’analyser  plus de sept cent mille opérations chaque année. Se lon les profils, des 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 123  -       parcours de jeu spécifiques seront proposés à chaqu e élève. L’ensemble  s’appuie sur des chercheurs, aussi bien statisticie ns que didacticiens et  cognitivistes.  Jean-Marc Merriaux a également indiqué à vos rappor teurs qu’un  continuum  pédagogique entre le temps scolaire et le hors tem ps scolaire   devrait émerger, à travers la présence future de sy stèmes d’intelligence  artificielle, de robots ou de bots  aussi bien à l’école qu’au sein de la maison, il  s’agira d’ « accompagner d’outils et d’interfaces pour assurer l es usages au sein et  en « « dehors de la classe. Sur ce point, l’intelli gence artificielle peut sûrement  apporter un certain nombre de réponses  ».  Selon vos rapporteurs les nouvelles technologies ne seront pas en  compétition avec les enseignants  mais elles leur seront complémentaires ,  car venant en soutien de l’effort pédagogique. Jean -Marc Merriaux lors de  son audition a également insisté sur la mutation en  cours de la place et du  rôle de l’enseignant sous l’effet de l’ensemble des  évolutions évoquées, ainsi  que sur la nécessité de l’accompagner dès lors que les nouvelles technologies  seront parties intégrantes de son enseignement. L’i ntelligence artificielle  intervient pour compléter le savoir-faire de l’enseignant, en le re ndant plus  accessible et mieux informé .  Les cours en ligne ouverts et massifs , ou MOOC ( massive open online  courses  en anglais) seront, de ce point de vue, des ressou rces utilisables pour  appliquer ces nouvelles méthodes pédagogiques innov antes. Ces ressources  en ligne permettront aux apprenants (en formation initiale o u continue)  d’accéder dans des conditions optimales à la connai ssance , ce dont se  félicitent vos rapporteurs.  2.  Une révolution potentielle de notre cadre de vie et  de l’aide aux  personnes   Vos rapporteurs sont convaincus de l’ imminence de la  possibilité  d’une révolution de notre cadre de vie et de l’aide  aux personnes . Des  changements profonds sont à venir dans la connaissa nce et dans le contrôle  de notre environnement et de la santé des populatio ns. Les smart grids   (réseaux de fourniture d’énergie permettant une con sommation optimisée  grâce à l’IA) et les smart cities  (villes intelligentes) seront les expressions des  bénéfices que nous pouvons tirer de l’intelligence artificielle. Et cela se  traduira en matière de transports, de sécurité, de santé, de dépassement de la  dépendance et du handicap. Notre cadre de vie, la q ualité de nos vies seront  améliorés par l’usage massif de technologies d’inte lligence artificielle.  Il sera également possible de demander de plus en plus de choses à  nos assistants personnels , ils pourront répondre à beaucoup de questions  que nous nous posons dans notre vie quotidienne. Il s pourront de mieux en  mieux comprendre, organiser et hiérarchiser l’infor mation et la connaissance.  Le cabinet d’études Gartner prévoit que 50 % des ap plications analytiques 
- 124  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        embarqueront des fonctions d’intelligence artificie lle d’ici trois à cinq ans et  qu’une large part des analyses sortant de ces appli cations sera glanée via des  interactions vocales (chiffre annoncé lors du sympo sium annuel du cabinet  en octobre 2016).  S’agissant des économies d’énergie , Google a ainsi l’objectif  d’optimiser la consommation de ses data-centers  et de la réduire  drastiquement grâce à l’intelligence artificielle, tout en encourageant la  production d’énergies renouvelables. En partenariat  avec EDF, Kawartech  développe à Toulouse un contrôle intelligent et aut onome de l’éclairage  public.  Le calendrier de déploiement des voitures autonomes  reste  incertain (5, 10, 15, 20, 30 ans ?) mais il est plu s que probable que la conduite  automobile sera dans le futur une activité réservée  à des passionnés  nostalgiques. La recherche avance en la matière, ma is moins vite que la  confiance dans les technologies. Ce n’est pas tant pour des raisons  techniques que pour des raisons d’acceptabilité soc iale, notamment en  France, que le passage aux voitures autonomes risqu e de se voir retarder.  Pourtant, les tests réalisés par Google-Waymo (3,5 millions de kilomètres  parcourus, principalement en zone urbaine) illustre nt la fiabilité croissante  de ces véhicules. Les constructeurs automobiles dép loient de plus en plus de  projets en la matière (en particulier Renault, PSA,  Volkswagen, Audi, BMW,  Daimler-Benz, Honda, Toyota, GM, Ford, Chrysler, Fi at, Volvo…). Il peut  être constaté que les véhicules collectifs autonome s, tels que les bus et  navettes, sont mieux acceptés et sont d’ailleurs dé jà en service.   Votre rapporteur Claude de Ganay a été étonné par d es propos tenus  par le grand maître de la confrérie « bérouettes et  traditions » de Cernoy-enBerry qui a expliqué, lors d’une réunion, tous les bienfaits que les robots et  les systèmes d’intelligence artificielle pourraient  avoir pour la ruralité, en  particulier pour les personnes âgées, isolées ou dé pendantes . Le cas des  voitures autonomes a été d’abord évoqué, mais d’aut res applications utiles  vont émerger au profit du monde rural et des senior s.  En matière de handicap , la start-up américaine BrainRobotics a  présenté au salon d’électronique CES de Las Vegas u ne prothèse de main  capable d’interpréter les signaux envoyés par les m uscles résiduels de  l’utilisateur : le système d’intelligence artificie lle repère certaines  caractéristiques de ces signaux musculaires, comme leur ampleur par  exemple, et les transmet à travers un algorithme de  classification qui sépare  les différents types de geste (poing fermé, index l evé, etc.). Il transmet  ensuite celui qu’il a identifié et son intensité au  moteur de l’appareil.  L’intelligence artificielle peut aussi venir en aid e aux malvoyants .  Facebook et Microsoft, notamment, ont dévoilé l’an passé des systèmes  capables de voir des images et d’en décrire le cont enu pour les aveugles. 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 125  -       Hyundai ambitionne de son côté de s’attaquer à la paralysie  avec  des exosquelettes robotisés. Un prototype montré au  Consumer Electronics  Show (CES) à Las Vegas s’adresse plus particulièrem ent aux paraplégiques,  auxquels il rend la capacité de se lever, marcher o u monter des escaliers.  L’appareil, baptisé H-MEX, longe le bas de la colon ne vertébrale et tout  l’arrière des jambes, avec des attaches au niveau d e la taille, des cuisses, des  genoux et des pieds. Un système de motorisation per met de déclencher des  mouvements de rotation au niveau des articulations,  depuis des boutons de  commande placés sur les béquilles et par l’interméd iaire d’une connexion  sans fil. Hyundai n’a pas encore de plan pour produ ire des appareils grand  public mais conduit des études cliniques dans des h ôpitaux.  La start-up Japet de Lille a mis au point un exosquelette lombaire   Atlas, destiné au milieu médical, et plus particuli èrement aux centres de  rééducation. Le dispositif repose sur quatre colonn es motorisées qui s’étirent  pour décompresser la colonne verticale et soulager les douleurs lombaires.  La commercialisation est visée pour la fin de l’ann ée 2017 ou début 2018, et  l’entreprise n’exclut pas de le décliner par la sui te pour les problèmes au  niveau des cervicales, ou pour les myopathies.  Au-delà de l’automobile et de la santé, d’autres se cteurs  amélioreront leurs offres au profit de toute la soc iété : le contrôle de la  qualité de l’air, avec les robots d’analyse de l’at mosphère, la domotique et  l’électroménager etc.  3.  Le défi de la cohabitation progressive avec des sys tèmes  d’intelligence artificielle dans la vie quotidienne    Les agents conversationnels, chatbots ou bots , les robots de service,  les agents d’assistance, d’accompagnement, d’aide à  la mobilité vont  progressivement cohabiter avec les humains. Cela né cessitera une grande  vigilance . Une adaptation réelle sera aussi requise.  Au quotidien, nos smartphones avec des logiciels tels que « Siri »,  « Cortana » ou « Google Now », font d’ores et déjà cohabiter leurs  utilisateurs avec des algorithmes puissants, qui co nnaissent beaucoup  d’aspects de la vie de chacun d’entre nous.  À ce stade, les bots  restent encore davantage des systèmes de  questions-réponses , ils n’ont pas encore la mémoire des échanges et n e  savent pas prendre en compte les aspects émotionnel s, comme le souligne  Laurence Devillers. Les bots devront savoir prendre en compte ces deux  aspects et, demain, fonctionner sans connexion à In ternet – souvent pour  plus de sécurité et d’autonomie - ainsi que l’a exp liqué à vos rapporteurs  Alex Acero, directeur du projet Siri chez Apple. Au jourd’hui, les bots   dépendent de l’existence d’une connexion au réseau,  cette dépendance les  rendant encore assez peu souples dans leur fonction nement, ce qui peut  contribuer à susciter de la méfiance. 
- 126  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Alors que la robotique industrielle connaît des app lications selon le  respect de la règle d’évitement des 4 D : « dangerous, dull, dirty, dumb  »  (dangereux, ennuyeux, sale, idiot), la robotique de  service suit, comme le  rappelle Laurence  Devillers, la règle des 4 E : « everyday, e-health,  education, entertainment  » (accompagnement au quotidien, santé, éducation,  loisirs).  L’éducation et la prévention  sont indispensables dans ce contexte  de cohabitation croissante entre les bots et les humains. Il convient de  consacrer une grande attention aux logiques d’empat hie et aux aspects  émotionnels qui ne manqueront de se développer.  Yann LeCun se déclare convaincu que « les machines intelligentes du  futur auront des sentiments, des plaisirs, des peur s, et des valeurs morales (et que)  ces valeurs seront une combinaison de comportements , d’instincts et de pulsions  programmées avec des comportements appris  ». Cette perspective mérite de s’y  attarder car, comme l’indiquent Rodolphe Gélin et O livier Guilhem,  respectivement directeur scientifique et directeur juridique d’Aldebaran puis  de SoftBank Robotics, « la modélisation des émotions est une tâche presque plus  facile que l’ensemble des problèmes que les robotic iens ont eu à régler (…), le robot  qui utilisera les techniques de perception des émot ions pourra quasiment lire à livre  ouvert les émotions de son interlocuteur. Elles s’a jouteront aux programmes qui, dès  aujourd’hui, sont capables de détecter la joie, la tristesse, la colère, voire le sarcasme,  dans la voix du locuteur. La perception d’émotions n’est donc pas ce qui  différenciera longtemps l’homme du robot. Quant à l ’expression d’émotions, les  règles de la politesse élémentaires suffiront large ment à en faire un compagnon  suffisamment empathique et à le rendre aussi sympat hique qu’un bon commerçant  sachant jouer au moment opportun la joie, la triste sse, l’excitation ou l’abattement  pour s’accorder à son client même si son émotion pe rsonnelle est à l’opposé de ce  qu’il doit exprimer pour respecter la bienséance. L e robot n’ayant pas d’émotion  personnelle, il lui est encore plus facile d’exprim er celle que son interlocuteur attend  (…) cette façon de jouer sur les émotions pourrait se rapprocher d’une forme de  manipulation. Un programmeur doté de quelques conna issances en psychologie, et  ils seront de plus en plus nombreux à y être formés , pourra jouer sur l’état  émotionnel d’une personne pour la convaincre de pre ndre ses médicaments, de ne  pas boire un verre de plus ou d’aller se coucher qu and il est très tard  ».  Pour le psychanalyste Serge Tisseron, spécialisé en  intelligence  artificielle et en robotique 1, utiliser ces techniques pour faire croire que les  robots seront capables de sentiments serait malhonn ête  car la  reconnaissance des émotions présente avant tout pou r eux l’intérêt de  permettre de s’adapter à l’état d’esprit de l’utili sateur et, partant, à le  tromper. En donnant l’impression que le robot a des  émotions (puisqu’il en  exprime), son programmeur trompe l’interlocuteur et  peut encourager la  création d’un lien affectif disproportionné entre l ’homme et la machine ou  tromper sur les intentions de la machine.                                                    1 « Le jour où mon robot m’aimera », 2015. 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 127  -       En outre, la cohabitation avec des machines pose la  question de la  « vallée de l’étrange  » ou  Uncanny Valley (littéralement : vallée dérangeante).  Ce champ de recherche scientifique, initié par le r oboticien japonais  Masahiro Mori en 1970, plaide pour les reproduction s de certaines  caractéristiques du vivant sans chercher une trop g rande ressemblance,  source de trouble et de gêne, encore difficiles à e xpliquer.  Cette expression imagée peut être représentée graph iquement,  comme l’illustre le document suivant, cette vallée étant symbolisée par la  zone de perception négative ressentie par un observ ateur humain face à un  robot humanoïde ou un zombie. Cette représentation graphique de la théorie  de la vallée de l’étrange pose en abscisse le degré  d’apparence humaine (de  zéro à 100 %) et en ordonnée le degré de familiarit é et/ou d’acceptation.    Représentation graphique de la théorie de la vallée  de l’étrange     Source : creativecommons.org/licenses/by-sa/3.0/      Votre rapporteur Claude de Ganay rappelle que dans la nouvelle de  science-fiction « L’histoire du robot et du bébé  » de John McCarthy, l’un des  pères fondateurs de l’intelligence artificielle, co -organisateur en 1956 avec  Marvin Minsky de l’école d’été de Dartmouth, il est  imaginé qu’après  l’émergence de l’intelligence artificielle forte et  avec la vaste pénétration des  robots dans la vie quotidienne, des robots d’assist ance maternelle, pourtant  conçus en conformité avec le principe éthique de « non-figuration humaine »,  devenu un des articles du code des robots, prennent  une place de plus en  plus grande : « de nombreux enfants devinrent plus attachés à leur robot nounou  qu’à leurs vrais parents. On y remédia en rendant l es robots nounous plus durs et 
- 128  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        en aidant les parents à rivaliser avec eux pour cap ter l’amour de leurs enfants.  Quelquefois, ça marchait. Dans un deuxième temps, l es robots furent programmés de  telle sorte que plus les parents étaient sympas, pl us le robot l’était, tout en laissant  les parents gagner la compétition pour obtenir l’af fection de leurs enfants. Le plus  souvent, ça marchait ».   Au-delà de l’exemple tiré de cette fiction 1, les enjeux de la  cohabitation quotidienne avec des intelligences art ificielles, de leur  acceptation et de leur régulation doivent et devron t être appréhendés .    II.  LES QUESTIONS ÉTHIQUES ET JURIDIQUES POSÉES PAR LES   PROGRÈS EN INTELLIGENCE ARTIFICIELLE  A.  LES ANALYSES PRÉSENTÉES PAR D’AUTRES INSTANCES POLI TIQUES  1.  Les deux rapports issus des institutions de l’Union  européenne :  Parlement européen et Comité économique et social e uropéen  (CESE)  Du côté des institutions de l’Union européenne, il convient tout  d’abord de relever l’initiative conduite par Mady D elvaux, présidente d’un  groupe de travail sur la robotique et l’intelligenc e artificielle au sein de la  Commission des affaires juridiques du Parlement eur opéen. Elle a ainsi  rendu public, le 31 mai 2016, un projet de rapport contenant des  recommandations à la Commission européenne concerna nt des règles de  droit civil sur la robotique et une motion portant résolution du Parlement  européen . Ce document, sous la forme d’une résolution du Pa rlement  européen a été adopté le 16 février 2017 2, dans une version « allégée » à  l’issue de sa discussion (plus de 500 amendements o nt été déposés). La  Commission n’est pas contrainte de suivre les recom mandations du  Parlement mais elle doit exposer ses raisons en cas  de refus.  L’idée de taxer les robots ou celle de mettre en pl ace un revenu  universel font partie des propositions qui ont été écartées lors du vote des  amendements . Par ce texte, les députés européens demandent à l a  Commission européenne de proposer des règles sur la  robotique et  l’intelligence artificielle, en vue d’exploiter ple inement leur potentiel  économique et de garantir un niveau standard de sûr eté, de sécurité et de  transparence. Ils y soulignent que des normes commu nautaires pour les  robots devraient être envisagées afin que l’Union e uropéenne prenne  l’initiative pour fixer ces normes sans être contra inte de suivre celles édictées  par des États tiers.                                                    1 L’évocation de cette nouvelle science-fiction perm et aussi de replacer la réflexion dans les objectif s  réellement poursuivis, qui ne sont ni l’IA forte, n i les robots d’assistance maternelle remplaçant les   mères.  2 La résolution a été adoptée par 451 voix pour, 138  voix contre et 20 abstentions.  
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 129  -       Il est proposé de clarifier les questions de respon sabilité, en  particulier pour les voitures autonomes, et de mett re en place un système  d’assurance obligatoire ainsi qu’un fonds de garant ie permettant le  dédommagement des victimes en cas d’accidents causé s par ce type de  voitures. Il est également proposé un code de condu ite éthique pour la  robotique, à destination notamment des chercheurs e t des concepteurs.   Par ailleurs, les parlementaires européens demanden t à la  Commission d’envisager, à long terme, la possibilit é de créer un statut  juridique spécial pour les robots, sous la forme de  l’octroi d’une personnalité  juridique afin de clarifier la responsabilité en ca s de dommages.  En outre, la création d’une agence européenne pour la robotique et  l’intelligence artificielle, afin de fournir aux au torités publiques une  expertise technique, éthique et réglementaire, est préconisée.  Une consultation publique sur cette résolution du P arlement  européen a été ouverte le 16 février 2017  Vos rapporteurs jugent nécessaires de distinguer cl airement les  robots « physiques » des robots « virtuels », ce qu e ne fait pas la résolution  du Parlement européen. Ils pensent que la confusion  doit être levée et le  terme de robot réservé à des objets matériels auton omes.  Vos rapporteurs désapprouvent également l’octroi d’ une  personnalité juridique pour les robots, qui leur pa raît soit dépourvue de  fondement, soit totalement prématurée.  Le Comité économique et social européen (CESE), l’a ssemblée  consultative des partenaires économiques et sociaux  européens, rend des  avis qui sont publiés au Journal officiel de l’Unio n européenne, à raison  d’environ 170 par an en moyenne. Catelijne Muller, que vos rapporteurs ont  rencontrée, est en cours de finalisation d’un rappo rt sur l’intelligence  artificielle en sa qualité de rapporteure pour le C ESE sur l’intelligence  artificielle. L’avis sera rendu public à l’issue de  la réunion de section prévue  le 4 mai 2017. Vos rapporteurs ont pu constater que  Mme Muller partageait  largement leurs points de vue, analyses et proposit ions.  2.  Les trois rapports de la Maison Blanche   La Présidence des États-Unis s’est emparée du sujet  de l’intelligence  artificielle et a rendu différents rapports dans la  période récente, dont trois  au cours des six derniers mois. Elle avait auparava nt rendu public un  premier rapport en mai 2014 sur le big data 1 sous-titré « seizing opportunities,  preserving values », piloté par John Podesta, au sein du bureau exécu tif du                                                    1 https://obamawhitehouse.archives.gov/sites/default/ files/docs/20150204_Big_Data_Seizing_Opport  unities_Preserving_Values_Memo.pdf  et http://www.cfr.org/technology-and-science/white-hou sebig-data---seizing-opportunities-preserving-values/ p32916   
- 130  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        président des États-Unis 1 (en anglais Executive Office of the President , appelé  également « Brain Trust  »). Plus récemment, après avoir mobilisé des exper ts  au sujet de l’intelligence artificielle, en mai 201 6 2, la Présidence des ÉtatsUnis a rendu public, en octobre 2016 , un rapport de l’Office de la politique  scientifique et technologique de la Maison Blanche intitulé « Se préparer à  l’avenir de l’intelligence artificielle  »3 (en anglais, Preparing the Future of  Artificial Intelligence ), accompagné d’un autre document intitulé « Plan  stratégique national pour la recherche et le dévelo ppement de l’intelligence  artificielle  »4 (National Artificial Intelligence Research & Develop ment Strategic  Plan ), ces deux rapports sont résumés ci-après. Enfin, en décembre 2016, le  bureau exécutif du président des États-Unis a rendu  un nouveau rapport sur  l’impact économique de l’intelligence artificielle et de la robotisation 5 (il  est intitulé « Artificial Intelligence, Automation, and the Econom y  »).  L’administration Obama a donc produit pas moins de trois rapports sur le  sujet entre octobre et décembre 2016.  Vos rapporteurs ont été marqués par le fait que le Président Barack  Obama ait choisi de consacrer l’une des dernières de ses grandes  apparitions publiques  aux défis technologiques, sociaux, économiques et  éthiques de l’intelligence artificielle, lors d’un entretien avec Joi Ito, directeur  du MIT Media Lab, publié dans le magazine technolog ique le plus lu au  monde 6. Comme leur ont indiqué les fonctionnaires du serv ice scientifique  du consulat de France à San Francisco, il s’agit d’ un bon indicateur du fait  que « cette thématique est le sujet brûlant du moment aux  États-Unis, que ce soit  dans l’expression de politiques publiques, la conso lidation d’une puissance de  recherche inégalée ou le développement rapide et sa ns précédent d’activités  économiques liées à ces technologies  ».  Le premier rapport  intitulé « Se préparer à l’avenir de l’intelligence  artificielle » , assez peu détaillé, a pour objectif de produire u n cadre général  de réflexion , en amorçant un état des lieux de la recherche et des  applications actuelles tout en posant des jalons pr udents quant à la                                                    1 Le « cabinet » est, aux États-Unis, la réunion des  membres les plus importants de l’exécutif du  gouvernement fédéral américain, ce qui est totaleme nt différent d’un cabinet ministériel au sens où  nous l’utilisons en français.  2 Le Président des États-Unis a ainsi lancé un group e de travail et un sous-comité spécifique au sein  du National Science and Technology Council (NSTC), chargés de suivre les évolutions du secteur et  de coordonner les activités fédérales sur le sujet.  En parallèle ont été tenues quatre sessions de  travail publiques entre les mois de mai et juillet 2016, visant à engager la discussion avec le grand  public et surtout à produire une large évaluation d es opportunités, risques, et implications  réglementaires et sociales de l’intelligence artifi cielle et de ses nouveaux développements, cf. :  https://www.whitehouse.gov/blog/2016/05/03/preparin g-future-artificial-intelligence   3 https://obamawhitehouse.archives.gov/sites/default/ files/whitehouse_files/microsites/ostp/NSTC/pr  eparing_for_the_future_of_ai.pdf    4 https://obamawhitehouse.archives.gov/sites/default/ files/whitehouse_files/microsites/ostp/NSTC/na  tional_ai_rd_strategic_plan.pdf    5 https://www.whitehouse.gov/sites/whitehouse.gov/fil es/images/EMBARGOED%20AI%20Econom  y%20Report.pdf    6 ‘Barack Obama, neural nets, self–driving cars and the future of the world’, entretien du 24 août 2016  dans  WIRED. https://www.wired.com/2016/10/president-obam a-mit-joi-ito-interview/  
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 131  -       possibilité et la nature d’une régulation. Il dress e moins un bilan de l’état  actuel de l’intelligence artificielle, de ses appli cations effectives et  potentielles, points rapidement évoqués, qu’il ne s ’intéresse aux questions  posées par les progrès en intelligence artificielle  pour la société et les  politiques publiques, tout en mettant en avant un d iscours mobilisateur  autour du potentiel des avancées en intelligence ar tificielle pour permettre  aux États-Unis de rester à la pointe de l’innovatio n mondiale. La publication  de ce rapport suit une série d’activités publiques menées par l’Office de la  politique scientifique et technologique de la Maiso n Blanche en 2016, qui  comprenait cinq ateliers publics co-animés tenus à travers le pays, ainsi  qu’une demande d’information 1, en juin 2016, à laquelle cent soixante-et-une  réponses ont été apportées. Ces activités ont permi s de faire connaître les  sujets étudiés et les recommandations incluses dans  le rapport.   Ce dernier constate que depuis quelques années, les machines ont  surpassé les humains dans l’accomplissement de cert aines tâches  spécifiques , par exemple dans la reconnaissance d’images. Bien  qu’il soit  peu probable que les machines présentent une intell igence d’application  générale comparable ou excédant celle des humains d ans les vingt  prochaines années, les experts prévoient que les pr ogrès rapides dans le  champ de l’intelligence artificielle spécialisée se  poursuivront, avec des  machines égalant et dépassant les performances huma ines sur de  nombreuses tâches spécialisées.   L’un des plus importants enjeux de l’intelligence a rtificielle est son  impact sur l’emploi et l’économie . Le rapport recommande que la Maison  Blanche organise une étude sur l’impact de l’automa tisation sur l’économie,  ce qui a été fait avec la publication d’un rapport spécifique sur ce sujet en  décembre 2016.   En particulier, ce premier rapport se conclut sur l ’idée que les  technologies d’intelligence artificielle font émerg er un potentiel  d’amélioration de la vie des citoyens en ouvrant de  nouveaux marchés et  de nouvelles opportunités permettant de résoudre ce rtains des grands  enjeux sociétaux  : la santé, les transports, l’éducation, l’énergie ,  l’environnement, la justice, la sécurité ou encore l’efficacité du  gouvernement. Il estime crucial que l’industrie, la  société civile, et le  Gouvernement travaillent ensemble et se mobilisent pour saisir pleinement  ces opportunités.  Au-delà des domaines d’application mis en avant, il  affirme qu’une  réglementation générale de la recherche en intellig ence artificielle semble  inapplicable à l’heure actuelle et que la réglement ation actuelle est pour  l’heure suffisante , dans l’attente d’une expertise plus fouillée 2. Ainsi, les                                                    1 Cette procédure « Request for information »  correspond à une consultation publique formalisée.   2 L’analyse comparée des risques et des bénéfices de vra permettre de justifier les futures évolutions  législatives et réglementaires. En effet, le rappor t insiste sur l’importance d’ajuster les prochains  arbitrages selon le principe suivant : évaluer les risques que l’implémentation de l’IA pourrait  réduire, de même que ceux qu’elle pourrait augmente r. 
- 132  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        éventuelles futures réglementations devront réduire  les coûts et les barrières  à l’innovation sans mettre en danger la sécurité du  public ou la concurrence  équitable sur le marché. Le Gouvernement fédéral pe ut cependant jouer un  rôle de pivot, même sans impulser de nouvelles lois1.  Un second rapport, intitulé plan national pour la recherche sur  l’intelligence artificielle et le développement str atégique , a également été  publié en octobre 2016. Allant de pair avec le prem ier, il pose les lignes  directrices d’une stratégie nationale pour la reche rche et le développement   de l’intelligence artificielle. Il apporte ainsi de s recommandations pour des  actions spécifiques en R&D financées au niveau fédé ral. Il rappelle que le  Gouvernement fédéral des États-Unis a investi dans la recherche sur  l’intelligence artificielle durant de nombreuses an nées, par exemple à travers  la DARPA. Au vu des immenses opportunités qui se pr ésentent, de  nombreux facteurs sont à prendre en considération d ans la définition de la  recherche et du développement (R&D) de l’intelligen ce artificielle financée  au niveau fédéral. Sept priorités ont donc été défi nies :  1. Soutenir, par l’investissement fédéral, la recherch e à long terme   afin de produire des percées scientifiques et techn ologiques dans les dix  prochaines années et demeurer le leader mondial de l’intelligence  artificielle . Il s’agit en particulier des méthodes nécessaires  à la découverte  de savoirs dans de grands volumes de données, l’amé lioration des capacités  de perception des systèmes d’intelligence artificie lle, la compréhension  profonde des capacités théoriques et des limites pr opres au développement  de l’intelligence artificielle, la poursuite des ef forts visant au développement  d’une intelligence artificielle générale par opposi tion aux intelligences  artificielles spécifiques.   2. Développer des méthodes de collaboration entre hommes et  intelligence artificielle . Plutôt que de remplacer les humains, la plupart d es  systèmes d’intelligence artificielle vont collabore r avec eux : la recherche est  nécessaire afin de créer des interactions effective s entre les humains et les  systèmes d’intelligence artificielle.  3. Comprendre et se pencher sur les implications éthiques, légales  et sociétales , dans le but de concevoir des systèmes d’intellige nce artificielle  conformes aux principes éthiques, légaux et sociéta ux des États-Unis. Le  rapport insiste sur l’importance d’assurer la justi ce, la transparence et la  responsabilité des systèmes, dès la phase de concep tion.                                                    1 Il a selon le rapport plusieurs rôles à jouer : un  rôle d’organisateur du débat public et d’arbitre d es  mesures à mettre en place à l’échelle du pays ; un rôle de suivi attentif de la sécurité et de la  neutralité des applications développées ; un rôle d ’accompagnateur de la diffusion de ces technologies   tout en protégeant certains secteurs au besoin afin  d’éviter des contrecoups économiques  dévastateurs ; un rôle de soutien et de financeur d e projets de recherche faisant avancer le domaine ;   et enfin un rôle d’adoption en son sein même de ces  avancées afin d’assurer un service public de  meilleure qualité. Il peut, en outre, veiller à la production d’une main-d’œuvre en nombre suffisant,  ainsi que d’un haut niveau de qualification et de d iversité technique, non seulement d’un point de  vue professionnel, mais également, et de manière pl us large, du point de vue de la formation générale  de la population. 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 133  -       4. Assurer la sécurité et sûreté des systèmes d’intelligence  artificielle , en particulier dans l’adaptation à des environnem ents complexes  et/ou incertains. Avant que les systèmes d’intellig ence artificielle ne soient  utilisés à grande échelle, il faut s’assurer que ce s systèmes vont opérer de  manière sécurisée et fiable. Des progrès plus pouss és dans la recherche sont  nécessaires pour répondre à ce défi.  5. Développer des bases de données publiques partagées  pour  l’analyse, l’apprentissage, l’entraînement et le te st de systèmes d’intelligence  artificielle. La profondeur, la qualité et la préci sion des données  d’apprentissage conditionnent leurs performances. L a mise à disposition de  bases de données fédérales existantes est proposée.   6. Développer des standards  visant à s’assurer que les technologies  émergentes répondent à des objectifs précis en term es de fonctionnalité et  d’interopérabilité, ainsi qu’en termes de sécurité et de performance. Des  recherches additionnelles sont nécessaires pour dév elopper un large spectre  de techniques évaluatives et de plateformes d’essai .  7. Évaluer les besoins en termes de main-d’œuvre . Les avancées en  intelligence artificielle demandent une forte commu nauté de chercheurs et  d’experts en intelligence artificielle, ce qui plai de pour une meilleure  compréhension des besoins actuels et futurs de main -d’œuvre.  Le Plan Stratégique de R&D pour l’intelligence arti ficielle se conclut  avec deux recommandations :  • Développer un cadre de mise en œuvre de la R&D de l ’intelligence  artificielle afin d’identifier les opportunités sci entifiques et technologiques et  soutenir une coordination effective des investissem ents en R&D de  l’intelligence artificielle, en accord avec les str atégies 1 à 6 de ce plan.  • Étudier le paysage professionnel national afin de c réer et  maintenir une main-d’œuvre de bon niveau pour la R& D en intelligence  artificielle, en accord avec la stratégie 7 de ce p lan.   3.  Le rapport de la Chambre des Communes du Royaume-Un i  La commission science et technologie de la Chambre des Communes du  Royaume-Uni a rendu public, en octobre 2016, un rapport sur la robotique  et l’intelligence artificielle , intitulé « Robotics and artificial intelligence  »1. Les  rapporteurs de ce texte affirment le potentiel disr uptif du développement de  l’intelligence artificielle sur les manières de viv re et de travailler.     Selon Tania Mathias, présidente par intérim de la c ommission,  « l’intelligence artificielle a encore du chemin à pa rcourir avant que les systèmes  artificiels et robots ne deviennent comme ceux imag inés dans des œuvres telles que                                                    1 Pour consulter le rapport :  https://www.publications.parliament.uk/pa/cm201617/ cmselect/cmsctech/145/145.pdf  
- 134  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Star Wars . Pour le moment, les “machines à intelligence arti ficielle” se voient  assigner des rôles restreints et spécifiques, comme  la reconnaissance vocale ou être  un adversaire au jeu de Go. Cependant, la science-f iction est doucement en train de  devenir une science factuelle, la robotique et les intelligences artificielles semblent  être destinées à jouer un rôle de plus en plus impo rtant dans nos vies au cours des  prochaines décennies. Il est trop tôt pour établir des régulations sector ielles  pour ce domaine naissant  mais il est vital qu’un examen attentif des implic ations  éthiques, légales et sociétales des systèmes d’inte lligence artificielle débute dès  maintenant  ».     Ce rapport estime que le rôle d’impulsion joué par le Gouvernement   dans le domaine de la robotique et de l’intelligenc e artificielle a été déficient.  Le fait que les structures privées s’interrogent fa ce aux risques et bénéfices  de l’intelligence artificielle ne décharge pas le G ouvernement britannique de  ses responsabilités. Ce rapport incite ainsi le Gou vernement à établir une  « Commission nationale sur l’intelligence artificiell e  » au sein de l’Institut  Alan Turing, afin d’identifier les principes de gou vernance du  développement et de l’utilisation de l’intelligence  artificielle et d’encourager  le débat public.    Ce rapport aborde également la question de l’emploi . Selon ses auteurs,  les progrès en productivité, permis par la robotiqu e et l’intelligence  artificielle, sont largement prévisibles. Bien qu’u ne incertitude plane sur  l’ampleur des destructions d’emploi et la capacité du marché du travail à  résorber un chômage potentiellement massif, il deme ure que, selon les  recommandations de ce rapport, l’accent doit être m is sur l’ajustement des  systèmes d’éducation et de formation  britanniques afin de délivrer les  compétences qui permettront à la population de s’ad apter et de profiter des  opportunités ouvertes au moment où les nouvelles te chnologies sont et  seront mises en œuvre.    Selon Tania Mathias, « il est concevable que nous verrons des machines à  intelligence artificielle créer de nouveaux emplois  dans les décennies à venir tout en  en remplaçant d’autres. Comme nous ne pouvons pas e ncore prévoir avec exactitude  comment ces changements vont se concrétiser, nous d evons répondre avec  préparation et réactivité aux besoins de requalific ation et d’amélioration des  compétences  ». Cela implique un engagement de la part du Gouvernement   qui garantisse la flexibilité des systèmes d’éducat ion et de formation leur  permettant de s’adapter à l’évolution des opportuni tés et des exigences  imposées aux travailleurs. Le rapport déplore, en o utre, que le  Gouvernement n’ait pas encore publié sa stratégie n umérique, ni déterminé  ses plans pour doter les futurs travailleurs des co mpétences numériques  essentielles à leur développement professionnel.    
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 135  -       Le Gouvernement britannique a apporté en janvier 20 17 une  réponse 1 au rapport présenté par la Chambre des Communes en  reprenant  explicitement trois recommandations  avancées dans celui-ci sans toutefois  annoncer de décisions nouvelles. Tout d’abord, le G ouvernement semble  bien conscient du bien fondé de développer une stra tégie pour soutenir les  systèmes autonomes et robotiques ( Robotics and Autonomous Systems , RAS en  anglais) et indique sa volonté d’améliorer la coordination stratégique entre  le Gouvernement, les industries et le monde académi que  afin de maximiser  les retombées économiques et sociales permises par ces technologies.  Ensuite, le Gouvernement reconnaît et promeut le rô le de l’Institut  Alan Turing dans la stratégie à développer, en anno nçant la mise en place en  son sein d’une « Commission nationale sur l’intelli gence artificielle ». Les  missions primordiales de l’Institut relatives au dé veloppement de  l’intelligence artificielle seront de répondre aux enjeux éthiques, sociaux et  juridiques, d’assurer que le développement de ces t echnologies soit  pleinement bénéfique à la société, et de bâtir la c onfiance dans les capacités  de développement du Royaume-Uni dans ce secteur.  Enfin, le Gouvernement affirme avoir bien identifié  la nécessité de la  formation aux technologies numériques , cette dimension étant appelée à  être incluse dans l’ensemble des filières de format ion.  Un groupe de travail de la Royal Society , rencontré par vos  rapporteurs, conduit également un projet de recherc he 2 visant à analyser les  opportunités et les défis juridiques, sociaux et ét hiques liés au machine  learning  et à ses applications sur les cinq à dix prochaine s années. Ce groupe  de travail publiera des recommandations à l’attention du Gouvernement  britannique au cours de l’année 2017 .  4.  Les initiatives chinoises et japonaises en intellig ence artificielle  accordent une place contrastée aux questions éthiqu es  La Chine et le Japon ont déployé des stratégies nat ionales pour l’IA  qui accordent une place contrastée aux questions éthiqu es  : alors que la  première les délaisse, le second a mis en place une  réflexion officielle de haut  niveau en la matière.  La Chine se trouve au cœur de l’évolution récente des techniques  et  déploie d’ importants moyens avec pour objectif de devenir leader mondial  dans le domaine 3. Elle a l’ambition d’être la première à disposer, vers  2025-2030, d’une intelligence artificielle générale , comparable à celle du  cerveau humain (« Artifical General Intelligence  » ou AGI ), première étape                                                    1 La réponse du Gouvernement britannique est disponi ble ici :  https://www.publications.parliament.uk/pa/cm201617/ cmselect/cmsctech/896/89602.htm    2 Pour consulter le projet de la Royal Society : https://royalsociety.org/topicspolicy/projects/machine-learning/    3 Une note complète sur le sujet de la place de l’IA  en Chine est annexée au présent rapport. 
- 136  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        dans le but de parvenir ensuite au développement d’ intelligences  suprahumaines, ce qui ne soulève pas de questions é thiques majeures dans  ce pays.  Même si les progrès visibles de la Chine reposent e ncore sur des  architectures conçues par des scientifiques occiden taux, ses atouts propres  sont réels , comme l’a indiqué à vos rapporteurs le service sc ientifique de  l’Ambassade de France à Pékin : elle dispose « des deux supercalculateurs les  plus puissants du monde, d’un marché intérieur très  important et friand des  avancées potentielles du secteur, d’une collusion f éconde entre l’État, les instituts de  recherche, les universités, les géants de l’interne t et de l’informatique et les  start-up  ».   Le 13 e plan quinquennal comprend une liste de 15 « nouvea ux  grands projets – innovation 2030 » qui structurent les priorités scientifiques  du pays et correspondent chacun à des investissemen ts de plusieurs  milliards d’euros. Parmi ces 15 projets, on en trou ve quatre qui sont  consacrés indirectement à l’IA, pour un montant de 100 milliards de yuans  en trois ans : un projet de « Recherche sur le cerv eau » et des projets  d’ingénierie intitulés « Mega données », « Réseaux intelligents » et  « Fabrication intelligente et robotique ».  Les recherches envisagées ne sont pas seulement thé oriques, les  applications multiples sont un moteur important : c ontrôle de drones, de  robots ou d’avatars, interfaces en langage naturel,  interfaces hommemachine, détection des émotions, analyse d’images, automobiles autonomes,  etc. Les systèmes permettront aussi de faire l’anal yse des big data .  L’exemple suivant ne semble pas gêner les chercheur s chinois,  comme l’a précisé à vos rapporteurs le service scie ntifique de l’Ambassade  de France : « Piloté par le Gouvernement et l’organisme central  de planification, le  dispositif de notation de la population devrait réc upérer automatiquement les  informations sur les citoyens d’ici à 2020. Il scru tera les activités en ligne etc, pour  générer un score individuel. Il semble que si un se uil est dépassé, l’individu  concerné se verra privé d’un certain nombre de droi ts et de services  ». Une  expérimentation a commencé dès 2017 à Suining 1. D’autres dispositifs  d’évaluation individuelle des citoyens ou des conso mmateurs sont étudiés,  comme le Sesame Credit  du distributeur en ligne Alibaba 2.  L’opinion publique chinoise semble donc, à ce stade, peu  préoccupée par les questions éthiques et philosophi ques soulevées par ces  applications , ni même par les questions concernant la protectio n des  données et de la vie privée qui sont des enjeux imp ortants pour l’évolution  de la recherche et pour les applications de l’IA. E n effet, les jeux de données                                                    1 Cf. https://www.washingtonpost.com/world/asia_pacific/c hinas-plan-to-organize-its-whole-societyaround-big-data-a-rating-for-everyone/2016/10/20/1c d0dd9c-9516-11e6-ae9d0030ac1899cd_story.html?utm_term=.71ca38d649e1    2 Cf. http://www.bbc.com/news/world-asia-china-34592186   
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 137  -       sont l’une des dimensions majeures des progrès des algorithmes de deep  learning  et d’apprentissage statistique de façon plus génér ale.  L’intelligence artificielle est considérée, par ail leurs, comme  l’élément clé de la révolution numérique au Japon  selon les informations  transmises à vos rapporteurs par le service scienti fique de l’Ambassade de  France au Japon 1. Le gouvernement japonais a fait le choix d’annonc er dès  mai 2015 un grand plan quinquennal pour la robotique et l’intel ligence  artificielle 2, entré en vigueur le 1 er  avril 2016.  Il a fait de ces deux dernières technologies le soc le de sa nouvelle  stratégie en science, technologie et innovation, qu i vise à mettre en place, au  terme de la « 4e révolution industrielle  », une « société 5.0  », société  superintelligente et fer-de-lance à l’échelle mondi ale du dynamisme  japonais. On estime que le marché de l’intelligence  artificielle au Japon  devrait passer de 3,7 milliards de yens en 2015 à 87 milliards en 2030 , dont  30,5 milliards de yens dans le domaine du transport  et 42 milliards en  incluant la production industrielle pour le transpo rt.  Le gouvernement japonais a annoncé une vague d’investissements  massifs  dans le domaine, avec 27 milliards de yens pour la seule année  2016 , à travers la création de centres de recherche et technologies dédiés. Ce  montant est à rapprocher des plus de 300 milliards de yens d’investissement  que les grands groupes japonais ont lancé sur les t rois ans à venir pour  financer des programmes ou des laboratoires dédiés à l’intelligence  artificielle 3. Les partenariats publics-privés entre les centres  publics et les  grands groupes japonais se multiplient, afin d’expl oiter le potentiel de  création de valeur que constitue l’intelligence art ificielle sur des applications  ciblées. L’intelligence artificielle ouvre la voie à des développements très  attendus au Japon, selon le service scientifique de  l’Ambassade, dans le  domaine des transports, de la communication, de la traduction  automatique ou de la robotique , notamment à l’horizon des Jeux  Olympiques et paralympiques de 2020, que le Japon e nvisage comme une  vitrine technologique pour se présenter comme « le pays leader mondial  » en  termes d’innovation.   Il peut être relevé qu’à l’occasion de l’organisati on du sommet 2016  du G7  au Japon, qui s’est tenu à Shima les 26 et 27 mai 2016, le Japon a pris  l’initiative d’organiser une réunion ministérielle du G7 consacrée aux  Sciences et technologies de l’information et de la communication , format  qui n’avait pas été mis en œuvre depuis 20 ans.                                                    1 Une note complète sur le sujet de la place de l’IA  au Japon est annexée au présent rapport.  2 Soutenu par 200 entreprises et universités, le 5e Plan-cadre pour la Science et la technologie  prévoit le triplement des investissements dans ce d omaine d’ici à 2020 en vue d’inciter les  entreprises à répandre l’utilisation de la robotiqu e dans tous les secteurs de l’économie et de la  société afin de surmonter le vieillissement et la b aisse du nombre d’actifs.  3 Plusieurs exemples de projets sont détaillés dans la note sur le sujet de la place de l’IA au Japon  annexée au présent rapport. 
- 138  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Le ministère japonais de l’Éducation, de la culture , des sports, des  sciences et de la technologie a rédigé en 2016 un livre blanc pour la science  et la technologie , intitulé « Vers la société ultra-intelligente mise en œuvre pa r  l’IoT , le big data  et l’IA– pour que le Japon soit un précurseur mond ial  », adopté  en Conseil des ministres le 20 mai 2016. Ce rapport  signale l’insuffisance au  Japon de la formation et de la recherche fondamenta le en informatique, qui  devraient venir soutenir le développement des techn ologies de l’information  et de la communication.  Trois ministères, respectivement en charge de la re cherche, de  l’industrie et des communications se sont mobilisés  avec une vitesse  étonnante pour développer des initiatives pour la r obotique et l’intelligence  artificielle et ont, chacun, annoncé en 2016 la cré ation d’un centre de  recherche spécifique sur l’intelligence artificiell e : un premier centre auprès  du RIKEN (principal centre de recherche japonais, d u type CNRS), portant le  nom de « AIP Center »1 (Advanced Integrated Intelligence Platform Project  Center ), l’AIRC ( Artificial Intelligence Research Center ), hébergé par l’AIST  (Advanced Institute for Science and Technologies ), et, enfin, le NICT ( National  Institue for Information and Communication Technolo gies ).  Le gouvernement japonais a mis en place  deux structures pour le  suivi des stratégies  du grand plan quinquennal pour la robotique et  l’intelligence artificielle  : un Conseil consacré à la stratégie des technolog ies  liées à l’IA (qui a notamment pour but de coordonne r les actions des trois  centres de recherche précités, disposant d’un site web commun et  mutualisant leurs ressources informatiques) et un C omité de délibération sur  l’IA et la société humaine. Ces deux structures rel èvent directement du  gouvernement japonais.  Le Conseil de la stratégie des technologies liées à  l’IA a tenu sa  réunion inaugurale le 18 avril 2016 et sert de « qu artier général de la  recherche et du développement (R&D) des technologie s de l’IA et de leurs  applications industrielles » en regroupant les troi s ministères impliqués dans  l’IA. Il est présidé par Yuichiro Anzai, Président de la JSPS (agence de  financement de la recherche du MEXT dédiée à la rec herche fondamentale),  et composé de deux représentants du Keidanren (synd icat patronal des  entreprises japonaises), des présidents de deux uni versités (Université de  Tokyo et Université d’Osaka) et des présidents de c inq grands instituts de  recherche et agences de financement : le NICT ( National Institute for  Information and Communication Technologies, dépendant du Ministère des  affaires intérieures et communication, MIC), le RIK EN (principal centre de                                                    1 Les activités s’articulent autour de cinq objectif s : développer des technologies pour l’intelligence   artificielle « fondamentale » (basé essentiellement  sur le machine learning) ; contribuer à  l’accélération de la recherche scientifique (analys e et synthèse d’articles scientifiques, d’expérienc es  de brevets…) ; contribuer à des applications concrè tes à fort impact sociétal (problématique des soins   dans le contexte du vieillissement de la population , gestion des infrastructures et des ouvrages de  génie civil, résilience aux catastrophes naturelles ...) ; prise en compte des aspects éthiques, légaux  et  sociaux ; développement des ressources humaines. 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 139  -       recherche japonais), l’AIST ( Advanced Institute for Science and Technologies ,  centre de recherche du Ministère de l’Économie), la  JST (agence de  financement orientée vers les projets de recherche appliquée) et la NEDO  (agence de financement dépendant du Ministère de l’ Économie). Deux souscomités ont été placés sous l’autorité de ce Consei l : le Comité de  collaboration de recherche (conseil des présidents des instituts de recherche  et des agences de financement) et le Comité de coll aboration industrielle qui  se réunissent chacun mensuellement.  Le  Comité de délibération sur l’IA et la société humai ne a tenu sa   première réunion le 30 mai 2016 en présence de Aiko  Shimajiri, ministre  chargée de la politique de la science et de la tech nologie, conformément à  une annonce en Conseil des ministres, le 12 avril 2 016. Il s’agit de la  première structure gouvernementale ayant pour missi on d’étudier les  enjeux liés à l’IA , selon cinq points de vue, à savoir : l’aspect éth ique,  l’aspect légal, l’aspect économique, l’aspect socia l et l’aspect R&D. Ce  Comité, présidé par Yuko Harayama et composé de onz e experts, se réunit à  une fréquence mensuelle pour analyser les activités  nationales et  internationales et a choisi de se baser sur des cas  d’application précis,  mettant en œuvre des technologies qui devraient voi r le jour à court terme :  le véhicule autonome, l’automatisation de l’apparei l de production et la  communication homme-machine. Il souhaite également engager un débat  avec le grand public, par le biais essentiellement de séminaires ouverts et de  questionnaires en ligne.   Le Comité a remis ses conclusions, qui seront prise s en compte dans  la nouvelle Stratégie japonaise globale pour la Sci ence, la technologie et  l’innovation qui sera publiée en juin 2017. Des dis cussions au niveau  international en la matière sont prévues à partir d e 2017. Mme Harayama a  toutefois présenté à Paris le 17 novembre 2016, dan s le cadre du Technology  Foresight Forum 2016 de l’OCDE 1 dédié à l’intelligence artificielle, les  premières pistes de réflexion du Comité :   - Éthique : Le citoyen peut-il accepter d’être mani pulé pour modifier  ses sentiments, convictions ou comportements, et d’ être catégorisé ou évalué,  sans en être informé ? Quel impact aura le développ ement de l’IA sur notre  sens de l’éthique et les relations entre les hommes  et les machines ? Dans la  mesure où elle étend notre temps, notre espace et n os sens, est-ce que l’IA  viendra affecter notre conception de l’humanité, no tamment notre  conception des facultés et des émotions humaines ? Comment évaluer les  actions et la création à partir de l’IA ?   - Légal : comment trouver le juste équilibre entre les bénéfices du  traitement des big data  par l’IA, et la protection des informations  personnelles ? Est-ce que les cadres légaux existan ts pourront s’appliquer  aux nouvelles problématiques soulevées par l’IA ? C omment clarifier la                                                    1 http://www.oecd.org/sti/ieconomy/Yuko%20Harayama%20 %20AI%20Foresight%20Forum%20Nov%202016.pdf   
- 140  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        responsabilité dans le cas d’incidents impliquant d e l’intelligence artificielle  (par exemple dans le cas du véhicule autonome) ? Qu els sont les risques  encourus en utilisant l’IA ou en ne l’utilisant pas  ?  - Économique : comment l’IA va-t-elle changer notre  manière de  travailler ? Quelle politique nationale mettre en p lace pour favoriser  l’utilisation de l’IA ? Comment l’IA va-t-elle modi fier le monde de l’emploi ?   - Sociétal : Comment réduire les divisions liées à l’IA et répartir de  manière équitable le coût social de l’IA ? Y-a-t-il  des pathologies ou des  conflits de société potentiellement engendrés par l ’IA ? Peut-on garantir la  liberté d’utiliser ou non l’IA, et assurer le droit  à l’oubli ?   - Éducation : Quelle politique nationale mettre en place pour faire  face aux inégalités que pourrait provoquer l’utilis ation de l’IA dans le  domaine de l’éducation ? Comment développer notre c apacité à exploiter  l’IA ?   - R&D : Quelle R&D développer pour l’IA en respect de l’éthique, la  sécurité, la protection de la vie privée, la transp arence, la contrôlabilité, la  visibilité, la responsabilité ? Comment rendre disp onible l’information liée à  l’IA de manière à ce qu’un utilisateur puisse prend re la décision d’utiliser ou  non l’IA ?   Le Comité cherche notamment à approfondir trois voi es pour définir  des politiques adaptées : la coévolution de la soci été et de la technologie ; la  recherche d’un équilibre entre les bénéfices (servi ces personnalisés à coût  abordable) et les risques liés à l’IA (discriminati on, perte de protection des  données à caractère privé, perte d’anonymat) ; la d éfinition des limites de la  prise de décision automatisée.  Les questions éthiques occupent donc, au total, une  place contrastée  au sein des initiatives chinoises et japonaises en IA . Autant elles ne  semblent pas être, pour le moins et à ce stade, au cœur des démarches  impulsées par les autorités chinoises , autant le gouvernement japonais les  évoque  très largement à travers la mise en place de son Comité national de  délibération sur l’IA et la société humaine . Le Japon a fait le choix  d’accompagner la transition produite par l’intelligen ce artificielle de  manière très étroite , avec des investissements publics massifs, mais  également par une réflexion publique institutionnalisée sur l’impact de  l’utilisation de l’intelligence artificielle pour l a société .  5.  La stratégie du Gouvernement français pour l’intell igence  artificielle : un plan qui arrive trop tard pour êt re intégré dans  les stratégies nationales destinées au monde de la recherche  Thierry Mandon, secrétaire d’État chargé de l’Ensei gnement  supérieur et de la Recherche et Axelle Lemaire, sec rétaire d’État au  Numérique et à l’Innovation, ont lancé une stratégie nationale en 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 141  -       intelligence artificielle , appelée « France IA », le 20 janvier 2017 dans le s  locaux de l’incubateur Agoranov à Paris. Cette stra tégie, qui consistait à  mobiliser sept groupes de travail  rassemblant des chercheurs et des  entreprises afin de définir les orientations stratégiques  de la France dans ce  domaine, a été suivie le 21 mars 2017 de l’annonce du plan du  Gouvernement à la Cité des sciences et de l’industrie et de la r emise d’un  rapport au Président de la République 1. Ce plan prévoit :   - la mise en place d’un comité stratégique « FranceIA  » rassemblant  les sphères académique, scientifique, économique ai nsi que des  représentants de la société civile, chargé de mettr e en œuvre les  recommandations des groupes de travail ;  - la coordination par la France d’une candidature à u n « projet  phare de technologie émergente » (« FET flagship ») sur l’IA, co-financé par  l’Union européenne (montant estimé d’un milliard d’ euros) ;  - le lancement d’un nouveau programme mobilisant les institutions  de recherche pour identifier, attirer et retenir le s meilleurs talents en IA,  dans le cadre de l’action Programmes prioritaires d e recherche du troisième  volet du plan pour les investissements d’avenir (« PIA 3 ») ;  - le financement d’une infrastructure mutualisée pour  la recherche ;  - la constitution d’un consortium public-privé en vue  de  l’identification ou de la création d’un centre inte rdisciplinaire pour  l’intelligence artificielle ;  - l’inclusion systématique, d’ici fin 2017, de l’IA d ans les priorités de  l’ensemble des dispositifs publics de soutien à l’i nnovation ;  - la mobilisation des ressources publiques (Bpifrance , PIA) et  privées pour atteindre l’objectif d’ici à cinq ans d’investir dans dix start-up  françaises pour plus de 25 millions d’euros chacune  ;  - la mobilisation des filières automobile, relation c lient, finances,  santé et transport ferroviaire pour que chaque fili ère définisse une stratégie  sectorielle en IA d’ici à la fin 2017 ;  - le lancement d’un appel à projets pour des platefor mes sectorielles  de partage de données pour trois à six secteurs, d’ ici à la fin 2017 ;  - la conclusion du débat sur l’éthique des « algorith mes » animé par  la CNIL en octobre 2017 et la remise de recommandat ions au  Gouvernement ;  - le lancement d’ici à l’été 2017 d’une concertation de France  Stratégie sur la question des effets de l’intellige nce artificielle sur l’emploi.                                                    1 Cf. http://www.economie.gouv.fr/files/files/PDF/2017/Ra pport_synthese_France_IA_.pdf   http://www.economie.gouv.fr/files/files/PDF/2017/Co nclusions_Groupes_Travail_France_IA.pdf  et  http://www.economie.gouv.fr/files/files/PDF/2017/Do ssier_presse_France_IA.pdf   
- 142  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Vos rapporteurs jugent regrettable  que l’évolution récente des  connaissances et des technologies ainsi que la pert inence de l’actualité n’ait  pas permis que cette démarche du Gouvernement soit inscrite dans les  différentes stratégies nationales de recherche à di x ans  et le livre blanc de  l’enseignement supérieur et de la recherche 1.  B.  DES « LOIS D’ASIMOV » À LA QUESTION CONTEMPORAINE D E LA  RÉGULATION DES SYSTÈMES D’INTELLIGENCE ARTIFICIELLE    1.  Dépasser les « lois d’Asimov » pour envisager un dr oit de la  robotique  Dès ses premiers romans, l’écrivain Isaac Asimov  a formalisé ses  « trois lois » applicables au comportement des robots . Ces « trois lois », qui  s’apparentent à des règles éthiques,  sont les suiv antes :  - première loi, « un robot ne peut porter atteinte à un être humain n i,  restant passif, laisser cet être humain exposé au d anger  » ;  - deuxième loi, « un robot doit obéir aux ordres donnés par les êtres   humains, sauf si de tels ordres sont en contradicti on avec la première loi  » ;  - troisième loi, « un robot doit protéger son existence dans la mesure  où  cette protection n’entre pas en contradiction avec la première ou la deuxième loi  ».  Au-delà de l’articulation des « trois lois » de la robotique entre elles,  Isaac Asimov a imaginé une quatrième loi, dite « loi zéro », élaborée par les  robots eux-mêmes . Cette invention suit le changement d’échelle de l a sphère  d’influence des robots. Elle consiste en une généra lisation de la première loi,  par le passage d’un individu à l’humanité toute ent ière : « nulle machine ne  peut porter atteinte à l’humanité ni, restant passi ve, laisser l’humanité exposée au  danger  ».  Bien qu’elles puissent avoir l’air infaillibles, ce s règles peuvent  être prises en défaut et atteindre leurs limites . L’œuvre d’Isaac Asimov  montre que l’application et l’articulation entre ce s trois lois ne vont pas de  soi. Ces règles, interprétées par les robots , peuvent même finir par nuire  aux êtres humains .  La Corée du Sud s’est tout de même inspirée de ces « lois » pour  rédiger un projet de charte sur l’éthique des robot s , dans le but « d’éviter les  problèmes de société qui pourraient découler de mes ures sociales et juridiques  inadéquates prises pour encadrer l’existence de rob ots dans la société  ».                                                    1 La loi pour l’enseignement supérieur et la recherc he du 22 juillet 2013 a conduit à la préparation  de deux grandes stratégies à 10 ans : une Stratégie  nationale de l’enseignement supérieur (StraNES)  et une Stratégie nationale de la recherche (S.N.R.) . Cette loi prévoit également, dans son article 17,   la réalisation d’un livre blanc de l’enseignement s upérieur et de la recherche par le Gouvernement au  Parlement tous les cinq ans. 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 143  -       Vos rapporteurs rappellent que les « lois d’Asimov » sont des règles  issues de la fiction et qu’elles posent des problèm es réels de mise en  œuvre . Les experts en robotique rencontrés par vos rappo rteurs ont tous  souligné la difficulté à traduire ces « lois » dans  des systèmes matériels. Au  total, il s’agit davantage de principes éthiques généraux que de prémices à  un droit de la robotique .  Les travaux d’ Andrea Keay  visant à compléter les « lois d’Asimov »  participent aussi de cette logique éthique. Pour mé moire, elle propose que  les robots ne soient pas utilisés comme des armes, qu’ils doivent se  conformer aux lois, notamment celles sur la protect ion de la vie privée, être  sûrs, fiables et donner une image exacte de leurs c apacités, qu’ils ne doivent  pas être utilisés pour tromper les utilisateurs les  plus vulnérables (ce qui  plaide pour éviter les robots humanoïdes trop resse mblants) et qu’il doit être  possible de connaître le responsable de chaque robo t.  Reconnaître une personnalité juridique des robots  est une des  pistes innovantes qui parcourent le débat public su r la robotique.  En France, l’avocat Alain Bensoussan , rencontré à plusieurs reprises  par vos rapporteurs,  milite en faveur de l’adoption d’un droit des robo ts  au  sein de l’association pour le droit des robots qu’i l préside. Il a ainsi rédigé un  projet de charte des droits des robots , qui fait de ces derniers des êtres  artificiels dotés d’une personnalité juridique part iculière et d’un droit à la  dignité 1. Il réfléchit également aux implications en matièr e de responsabilité  et d’assurance. En outre, il demande à ce que tout robot dispose de systèmes  de sécurité permettant un arrêt d’urgence.  Selon Alain Bensoussan, les textes actuellement en vigueur, à l’instar  de la loi du 6 janvier 1978 relative à l’informatiq ue, aux fichiers et aux  libertés 2, n’offrent pas un  cadre juridique suffisant  face aux évolutions en  cours de la robotique, à l’amélioration des capacit és d’apprentissage et de la  liberté décisionnelle du robot et à la question de la confidentialité des  enregistrements et des données que celui-ci peut re cueillir. En particulier,  pour Alain Bensoussan, il serait essentiel d’intégr er aux corpus normatifs  existants un « droit des robots », qui se déclinera it sur trois axes : les règles  générales applicables à tous les types de robots ; les règles spécifiques par  type de robot (véhicule autonome, robot humanoïde…)  ; et les référentiels  robotiques sur les plans éthiques, culturels et nor matifs.  Vos rapporteurs ont sur le sujet de la reconnaissan ce de la  personnalité juridique des robots un avis très rése rvé. Ils ne sont pas  convaincus de l’intérêt de reconnaître une personnalité juridique aux robots                                                     1 Cette charte précise que « les données à caractère personnel conservées par un  robot sont  soumises à la réglementation Informatique et libert és. Un robot a le droit au respect de sa  dignité limitée aux données à caractère personnel c onservées  ».  2 L’intégralité de la loi n° 78-17 du 6 janvier 1978  relative à l’informatique, aux fichiers et aux  libertés est disponible ici :  https://www.legifrance.gouv.fr/affichTexte.do?cidTe xte=JORFTEXT000000886460   
- 144  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        et se demandent à qui il conviendrait d’accorder la personnalité ju ridique ,  au robot dans son ensemble ou à son intelligence ar tificielle ?  Dans la mesure où le système d’intelligence artificielle pourrait  migrer d’un corps robotique à un autre , la partie physique du robot ne  serait qu’un contenant, destiné à recevoir pour un temps donné un système.  Il serait alors opportun d’opérer une discrimination entre la parti e  physique et la partie informatique du robot  en vue de les soumettre à des  régimes juridiques différents, notamment en matière  de responsabilité. Il  faudrait alors pouvoir, tel l’historien Ernst Kanto rowicz distinguant les  deux corps du roi, discerner les deux corps du robo t 1.  Vos rapporteurs estiment qu’il est urgent d’attendre en la matière  et  que le sujet de la personnalité juridique des robot s n’est pas à une question  qui mérite d’être posée à ce stade.    2.  Les questions juridiques en matière de conception ( design), de  propriété intellectuelle et de protection des donné es  personnelles et de la vie privée   S’agissant des autres aspects juridiques de l’intel ligence artificielle et  de la robotique, il sera loisible de conduire une r éflexion et de faire de la  prospective concernant la conception ( design ) et l’autorisation de  commercialisation 2. Pour Rodolphe Gélin et Olivier Guilhem,  respectivement directeur scientifique et directeur juridique d’Aldebaran puis  de Softbank Robotics, il n’existe pas de vide juridique béant . Les rapports  parus sur le sujet, notamment dans le monde anglo-s axon, semblent aller  dans le même sens.  Dans l’état actuel du droit, en cas de commercialisation de robots  entre professionnels , ces derniers disposent d’une certaine liberté  contractuelle qui leur permet de combler les incert itudes législatives et  jurisprudentielles . Ainsi, leur appréciation totale des possibilités et leur  maîtrise des contraintes et limites technologiques leur offrent une approche  technique permettant la distribution de la responsa bilité finale de chaque  partie prenante de cet échange commercial (fabrican t, développeur,  propriétaire et utilisateur).  Concernant la commercialisation de robots à destina tion des  consommateurs, le droit de la consommation  a vocation à s’appliquer.   La propriété intellectuelle pose des questions auxq uelles vos  rapporteurs n’ont pas de réponses définitives. Quel  est le statut de ce qui est  créé par des technologies d’intelligence artificiel le ? Ces œuvres sont-elles la                                                    1 Ernst Kantorowicz, « Les Deux Corps du roi. Essai sur la théologie politique au Moyen Âge »,  Gallimard, 1957.  2 Un régime du type de celui qui est applicable aux médicaments avant autorisation de mise sur le  marché, avec une période de tests et d’observations , pourrait devenir obligatoire pour les systèmes  autonomes d’intelligences artificielles, au stade o ù leur commercialisation massive sera envisagée. 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 145  -       propriété de son acheteur, de son fabricant, de l’é diteur du logiciel ?  En  tout cas elles n’appartiennent pas à la machine  d’après vos rapporteurs.  Plusieurs juristes, tel l’avocat Alain Bensoussan i magine à l’inverse une telle  solution, qui implique de doter les intelligences a rtificielles et les robots  d’une personnalité propre, comme il a été vu cette idée n’emporte pas leur  adhésion.   Dans l’état actuel du droit français, la reconnaiss ance d’une création  pleinement robotique ou issue de technologies d’int elligence artificielle  n’existe pas et  seul un être humain peut bénéficier d’un régime de   propriété intellectuelle pour ses créations . Il existe néanmoins certains  mécanismes juridiques permettant à une œuvre ou à u n ouvrage dont le  processus de création a été partiellement assuré pa r une machine ou un  système d’intelligence artificielle de bénéficier d ’un régime de protection au  titre de la propriété intellectuelle. Ainsi, il est possible d’accorder un brevet  à une création résultant d’un processus industriel impliquant un  ordinateur ou un robot . De même, si les créations produites par des  composants robotiques ne sont pas éligibles à la pr otection assurée par le  code de la propriété intellectuelle, le savoir-fair e, qui représente un ensemble  d’informations non brevetées résultant de l’expérie nce et de  l’expérimentation, peut être utilisé comme un outil  pour protéger la création  robotique, à la suite de la construction jurisprude ntielle et doctrinale  reconnaissant la notion de savoir-faire. Enfin, con formément à la  « Classification de Nice »1, qui est le système de classification des produits  et  des services établi dans le cadre de l’Organisation  mondiale de la propriété  intellectuelle et ratifié par la France, les robots  et technologies d’intelligence  artificielle sont considérés comme des biens et leu rs actions en tant que  fournisseur de services ne sont, de fait, pas prise s en compte.  À titre de comparaison, les robots et les technolog ies d’intelligence  artificielle n’étant pas dotés de personnalité juri dique propre au regard du  droit international, ils demeurent considérés aux y eux de nombreux  systèmes juridiques nationaux comme des objets, et ne sont donc pas  porteurs de droits. Le droit de l’Union européenne ne prévoit pas la création  par un robot ou un ordinateur ; de fait, leurs créations sont exclues du  champ de la protection de la propriété intellectuel le, du brevet, du dépôt  de marque et du droit d’auteur  tel que défini par le droit communautaire.  Ainsi, au-delà de la France et plus généralement de s États membres de  l’Union européenne, de nombreux pays tels que l’Afr ique du Sud, le Brésil,  la Chine, les États-Unis ou le Japon, considèrent q ue la création ne peut être  qu’humaine, et non issue d’une machine ou d’une tec hnologie  d’intelligence artificielle . Dans ce cas, les créations effectuées par le reco urs  à un robot sont éligibles à la protection de la pro priété intellectuelle, la  propriété de la création étant attribuée au proprié taire ou à l’utilisateur de la  machine ou du système.                                                     1 Les 45 classes établies par la « Classification de  Nice » sont disponibles ici :  http://web2.wipo.int/classifications/nice/nicepub/e n/fr/edition-20170101/taxonomy/   
- 146  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        L’avocat Laurent Szuskin propose, quant à lui, une application  distributive de la propriété intellectuelle . Par exemple, une invention dans  un système d’intelligence artificielle pourrait êtr e protégeable par le brevet,  les logiciels sous-jacents par le droit d’auteur, l es bases de données par le  droit spécifique à celles-ci, etc. Sur la question de savoir si le résultat produit  par l’intelligence artificielle appartient au dével oppeur de la solution ou au  fournisseur ou encore à l’entreprise ayant intégré la solution à ses systèmes  de production ou encore à une autre personne telle que celle ayant fourni les  données, Laurent Szuskin plaide, en l’absence de ré gime légal ou de  jurisprudence à ce jour, pour une solution contractuelle . Les clauses  « propriété intellectuelle et savoir-faire » encadr ant le développement  d’intelligence artificielle ou la fourniture de ser vices d’intelligence artificielle  doivent attribuer la propriété ou du moins l’affect ation contractuelle des  résultats qui découlent de l’usage de la solution.  Le développement de la robotique « intelligente » e t des  technologies d’intelligence artificielle soulève ég alement des questions en  matière de protection des données personnelles.  Au quotidien, nos  ordinateurs connectés à Internet et nos smartphones avec des logiciels tels que  « Siri », « Cortana » ou « Google Now », nous font d’ores et déjà cohabiter  avec des algorithmes puissants, qui connaissent bea ucoup de chacun de  nous, le plus souvent avec notre complicité, sans que nous ne connaissions  l’usage qui peut être fait de ces millions d’inform ations à caractère  personnel . Les agents conversationnels étant appelés à jouer  un rôle  croissant dans nos sociétés, ce sujet doit faire l’ objet d’une prise en charge  satisfaisante.   Les activités robotiques sont soumises au respect d e la  loi n°78-17 du 6 janvier 1978  relative à l’informatique, aux fichiers et aux  libertés . Ainsi, les propriétaires de robots gérant le syst ème de traitement  des données doivent respecter les obligations posée s par la Commission  nationale de l’informatique et des libertés (CNIL),  c’est-à-dire la notification  standard sur les utilisations du robot, sur le type  de logiciel utilisé, sur les  systèmes de sécurité installés pour protéger les do nnées d’intrusions tierces  non autorisées, sur les données personnelles stocké es dans le robot, et sur les  informations fournies aux utilisateurs concernant l e traitement de leurs  données personnelles. Tout traitement de données pe rsonnelles doit être  signalé en amont à la CNIL, et l’utilisation de don nées « sensibles », comme  les données médicales, doit être autorisée par la C NIL. En outre, les  propriétaires de systèmes de traitement de données personnelles sont soumis  à une obligation de sécurité et de confidentialité des données.  Un effort d’adaptation du cadre juridique de la pro tection des  données à caractère personnel aux nouvelles réalité s du monde numérique a  été mené récemment à la fois au niveau communautair e et au niveau  national. 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 147  -       Le règlement (UE) 2016/679 du Parlement européen et du Conseil  du 27 avril 2016 relatif à la protection des personnes physiques à l ’égard du  traitement des données à caractère personnel et à l a libre circulation de ces  données 1, également appelé « règlement général européen sur  la protection  des données » et abrogeant la directive 95/46/CE, v ise à doter les États  membres d’une législation uniforme et actualisée en  matière de protection  des données à caractère personnel. Ce « règlement g énéral sur la protection  des données », entré en vigueur le 24 mai 2016 et q ui sera applicable à partir  du 25 mai 2018, est destiné à remplacer l’actuelle loi du 6 janvier 1978  relative à l’informatique, aux fichiers et aux libe rtés.  L’application de ce règlement général européen sur la protection des  données poursuit trois objectifs . Tout d’abord, l’application de ce règlement  vise à « renforcer les droits des personnes, notamment par l a création d’un droit à la  portabilité des données et de dispositions propres aux personnes mineures »2.  Ensuite, ce règlement impose un accroissement de la  transparence et la  responsabilisation des acteurs traitant des données , selon une logique de  conformité dont les acteurs sont responsables, sous  le contrôle et avec  l’accompagnement du régulateur. Enfin, l’applicatio n de ce règlement a pour  objectif de « crédibiliser la régulation grâce à une coopération renforcée entre les  autorités de protection de données, qui pourront no tamment adopter des décisions  communes et des sanctions renforcées dans les cas d e traitements de données  transnationaux »3.   Les dispositions contenues dans le règlement général européen sur  la protection des données  encadrent la collecte et le traitement de données à  caractère personnel par de nombreux droits et respo nsabilités . Ainsi, ce  règlement introduit la définition de « l’expression du consentement renforcé  »,  indiquant que les utilisateurs doivent être informé s de l’usage de leurs  données et doivent donner leur accord, ou s’opposer , au traitement de leurs  données personnelles. De même, le droit à la portab ilité des données est  affirmé, et les responsables de traitements des don nées à caractère personnel  devront assurer des opérations respectant la protec tion des données  personnelles, à la fois dès la conception du produi t ou du service et par  défaut.   Le règlement général européen sur la protection des  données  s’accompagne de l’adoption de la directive (UE) 2016/680 du Parlement  européen et du Conseil du 27 avril 2016  relative à la protection des  personnes physiques à l’égard du traitement des don nées à caractère  personnel  par les autorités compétentes à des fins de préven tion et de  détection des infractions pénales, d’enquêtes et de  poursuites en la matière                                                    1 Le texte intégral du règlement est disponible ici : http://eur-lex.europa.eu/legalcontent/FR/ALL/?uri=CELEX%3A32016R0679    2 La CNIL propose une analyse détaillée et synthétiq ue des dispositions contenues dans le règlement  général européen sur la protection des données, dis ponible ici : https://www.cnil.fr/fr/reglementeuropeen-sur-la-protection-des-donnees-ce-qui-chang e-pour-les-professionnels   3 Ibid.  
- 148  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        ou d’exécution de sanctions pénales, et à la libre circulation de ces données.  Cette directive, entrée en vigueur le 5 mai 2016 et  que les États membres sont  tenus de transposer dans leur ordre juridique inter ne au plus tard le 6 mai  2018, s’applique aux opérations de données effectué es à la fois au niveau  transfrontalier et au niveau national par les autor ités compétentes des États  membres à des fins répressives, comprenant notammen t la prévention et la  détection des infractions pénales et la protection contre les menaces pour la  sécurité publique.   Vos rapporteurs notent que certaines dispositions d e la loi  n° 2016-1321 du 7 octobre 2016 pour une République numérique anticipent  ce règlement européen sur la protection des données  personnelles .  La loi crée, en effet de nouveaux droits informatiq ue et libertés et  permet ainsi aux personnes de mieux maîtriser leurs données personnelles,  par l’affirmation du droit à l’autodétermination in formationnelle , qui  constitue un renforcement des principes énoncés à l ’article 1 er  de la loi du  6 janvier 1978 relative à l’informatique, aux fichi ers et aux libertés. De même,  elle introduit le droit à l’oubli  par les mineurs via  une procédure spécifique  accélérée permettant un effacement des données « pr oblématiques » sur les  plateformes, prévu désormais par l’article 40 de la  loi du 6 janvier 1978  relative à l’informatique, aux fichiers et aux libe rtés. L’article 40-1 de cette  même loi permet désormais aux personnes d’organiser  la conservation,  l’effacement et la communication de leurs données p ersonnelles après leur  décès , notamment en désignant une personne pour exécuter  des directives  générales ou particulières souhaitées par le défunt . En outre, le nouvel article  43 bis de la loi du 6 janvier 1978 relative à l’inf ormatique, aux fichiers et aux  libertés offre la possibilité aux citoyens d’exercer leurs droits par voie  électronique .  La loi du 7 octobre 2016  pour une République numérique élargit  également les pouvoirs de sanctions de la CNIL et l ui confie de nouvelles  missions . Ainsi, le plafond maximal des sanctions de la CNIL est désormais  de trois millions d’euros, cette augmentation antic ipant celle prévue par le  règlement général européen sur la protection des do nnées. La loi introduit la  consultation systématique  de la CNIL afin que celle-ci soit saisie pour avis   dès lors qu’un projet de loi ou une disposition d’u n projet de loi ou de décret  est relatif à la protection et au traitement des do nnées à caractère personnel.  Tous les avis  de la CNIL seront par ailleurs automatiquement rendus  publics . De plus, la loi renforce la CNIL de nouvelles mis sions en matière de  protection des données personnelles. Ainsi, la CNIL  doit assurer la  promotion des technologies de protection de la vie privée , certifier la  conformité des processus d’anonymisation des donnée s à caractère  personnel  lors de leur mise en ligne et de leur utilisation,  et conduire une  réflexion sur les problèmes éthiques et les questio ns de société face à  l’évolution des technologies numériques . Cette dernière mission confiée à  la CNIL l’a ainsi menée à initier un cycle de débat s publics, ateliers ou 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 149  -       rencontres, intitulé « Éthique et numérique : les algorithmes en débat  »1. Ce point  sera abordé plus loin dans la partie consacrée au c adre national de la  réflexion sur les enjeux éthiques de l’intelligence  artificielle  Enfin, la loi du 7 octobre 2016  pour une République numérique  contribue également à une meilleure ouverture des d onnées publiques .  L’article 4 de la loi modifie, en effet, le droit à  la communication des  documents administratifs, et crée l’article L311-3- 1 du Code des relations  entre le public et l’administration, qui dispose qu e « sous réserve de  l’application du 2° de l’article L. 311-5, une déci sion individuelle prise sur le  fondement d’un traitement algorithmique comporte un e mention explicite en  informant l’intéressé. Les règles définissant ce tr aitement ainsi que les principales  caractéristiques de sa mise en œuvre sont communiqu ées par l’administration à  l’intéressé s’il en fait la demande. Les conditions  d’application du présent article  sont fixées par décret en Conseil d’État  »2.  À ce titre, la loi signe le passage d’une logique de la demande  d’un  accès à la logique de l’offre de données publiques,  bien que les critères de  communicabilité de ces données demeurent inchangés.    Néanmoins, vos rapporteurs soulignent le fait que  l’introduction  de ce nouveau droit réinterroge les questions d’exp licabilité et de  responsabilité des algorithmes . En effet, le principe d’explicabilité d’un  algorithme implique que toute décision prise par ce lui-ci doit être accessible  et compréhensible par les personnes concernées par cette décision, afin de  permettre à ces derniers de fournir une meilleure c ontestation des erreurs  constatées ou des données erronées. De même, le pri ncipe de responsabilité  d’un algorithme implique que l’algorithme ou son ut ilisateur rende compte  des effets de leurs procédés et de leurs actions. L es algorithmes étant  souvent caractérisés par leur opacité et qualifiés de boîtes noires  insondables, la collecte et le traitement de données publiques d ésormais  librement accessibles par des algorithmes soulève d e nombreuses  préoccupations sur la transparence des algorithmes .  Vos rapporteurs notent que la loi ne fournit toujours pas de régime  juridique spécifique  de protection des données personnelles dans les ca s de  collecte et de traitement de ces données par des ro bots intelligents ou des  technologies d’intelligence artificielle, c’est le droit commun de la protection  des données à caractère personnel dans les traiteme nts informatiques  qui  continue de s’appliquer.                                                     1La CNIL rendra publique dès l’automne 2017 la synth èse des échanges et des contributions. Comme  elle l’affirme, « il s’agira d’établir une cartographie de l’état du débat public et un panorama  des défis et enjeux. Des pistes ou propositions pou r accompagner le développement des  algorithmes dans un cadre éthique pourraient faire par la suite l’objet d’arbitrages par les  pouvoirs publics  ». La présentation du projet est disponible ici : https://www.cnil.fr/fr/ethique-etnumerique-les-algorithmes-en-debat-0    2 Le droit applicable à la communication des documen ts administratifs est disponible ici :  https://www.legifrance.gouv.fr/affichCode.do;jsessi onid=9D32BEC5092D1A4CC3D228A1256F8AB  A.tpdila23v_2?idSectionTA=LEGISCTA000031367696&cidT exte=LEGITEXT000031366350&date  Texte=20170312   
- 150  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Afin de répondre plus spécifiquement aux préoccupat ions d’explicabilité, de  régulation et de responsabilité des algorithmes, le  Conseil général de  l’économie (CGE) a remis au Gouvernement un rapport  intitulé « Modalités  de régulation des algorithmes de traitement des con tenus »1. Cinq  préconisations ont été formulées en vue de vérifier  la conformité aux lois et  règlements dont la détection de discrimination illi cite. Suite à ce rapport, le  secrétariat d’État à l’économie numérique a confié à l’Institut national de  recherche en informatique et en automatique (Inria)  le rôle d’opérateur de la  plateforme scientifique d’évaluation de la responsa bilité et de la  transparence des algorithmes  avec le soutien de l’IMT et du CNNum. Ce  projet a été placé sous la direction de Nozha Bouje maa, directrice de  recherche chez Inria. Les travaux de la plateforme « TransAlgo »2 ont ainsi  été lancés en janvier 2017 et rassemblent des cherc heurs de plusieurs  établissements (SciencePo, UVSQ, CEA, CNRS, Inria, IMT etc).  La disposition sur l’ouverture des données publique s introduite par  la loi du 7 octobre 2016 pour une République numéri que et la question de la  transparence des algorithmes ont été abordées, le 1 5 novembre 2016, dans le  cadre de débats au Sénat  sur les « inégalités devant l’orientation après le   bac ». Au cours de ce débat, notre collègue sénatri ce Sylvie Robert a abordé  la question de l’algorithme de répartition utilisé par la  plateforme « Admission post-bac » (APB), dont les r ésultats semblaient  refléter des inégalités subies par les candidats, n otamment en fonction de  leur origine sociale, dans l’orientation dans des f ilières d’enseignement  supérieur. L’encadré suivant rappelle l’échange que  notre collègue a eu à ce  sujet en séance publique avec le Gouvernement, repr ésenté par Mme Clotilde  Valter, secrétaire d’État auprès de la ministre du travail, de l’emploi, de la  formation professionnelle et du dialogue social, ch argée de la formation  professionnelle et de l’apprentissage.                                                      1 http://www.economie.gouv.fr/cge/modalites-regulatio n-des-algorithmes-traitementdes-contenus    2 http://www.economie.gouv.fr/files/files/PDF/Inria_P lateforme_TransAlgo2016-12vf.pdf  
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 151  -         Inégalités devant l’orientation après le bac (extra it des débats 1)    Mme Sylvie Robert . Madame la secrétaire d’État, une récente étude me née  par l’INSEE dans l’académie de Toulouse souligne qu e les résultats d’admission  post-bac reposent, dans une large mesure, sur un dé terminisme social évident. À  dossiers équivalents, les élèves issus de milieux f avorisés s’orientent beaucoup plus  vers les filières d’excellence ou les grandes école s. Plusieurs facteurs peuvent  expliquer ce constat : les différences de ressource s financières, la position sociale  des parents, qui influe souvent sur le choix des en fants, l’asymétrie d’information  concernant les établissements d’enseignement supéri eur ou encore les disparités en  matière d’orientation dans les lycées. Cette config uration tend à conférer un poids  déterminant au capital social et culturel détenu pa r l’élève et sa famille. Or le  niveau de diplôme demeure un facteur prépondérant e n matière d’insertion sur le  marché du travail. À preuve, quatre ans après la so rtie de la formation initiale, le  taux de chômage des peu ou non diplômés, qui s’élèv e à 45 %, est quatre fois plus  important que celui des diplômés du supérieur.  Pour remédier à cette situation, il se révèle donc essentiel d’agir en amont,  en garantissant une égalité réelle devant l’orienta tion, laquelle n’est pas seulement  un « processus de répartition des élèves dans diffé rentes voies de formation », mais  aussi « une aide dans le choix de leur avenir scola ire et professionnel », comme le  rappelle le Haut Conseil de l’éducation.  À ce titre, il est reconnu que le système APB, admi ssion post-bac, requiert  un accompagnement et un suivi personnalisés de chaq ue élève. Néanmoins,  l’impossibilité parfois, pour l’élève, d’obtenir da ns le cadre scolaire des  informations pertinentes sur les filières et établi ssements envisagés, ainsi que des  conseils quant aux stratégies à mettre en œuvre pou r formuler ses vœux, constitue  l’une des causes principales d’erreur, voire d’éche c, d’orientation. D’ailleurs, dans  le rapport d’information sénatorial intitulé « Une orientation réussie pour tous les  élèves », il est préconisé d’intégrer le conseil en  orientation dans la formation  initiale et continue des enseignants. Dans cette mê me perspective, les rectorats ont  proposé des améliorations du système APB : ouvrir l e dispositif à l’ensemble des  filières sélectives ; abandonner le tirage au sort utilisé pour certaines formations,  qui est source de frustration, d’injustice et parfo is de contentieux ; associer au  processus, dès la classe de première, l’élève et sa  famille, afin de les familiariser à  l’outil APB et de leur permettre d’anticiper et de réfléchir posément à l’orientation ;  renforcer la transparence du système APB par la pub lication de son code source,  conformément aux dispositions de l’article 2 du pro jet de loi pour une République  numérique, qui crée un droit d’accès aux règles déf inissant le traitement  algorithmique.                                                    1 L’intégralité des débats conduits lors de la séanc e du 15 novembre 2016 après la question n° 1489  adressée à Mme la ministre de l’éducation nationale , de l’enseignement supérieur et de la recherche  au Sénat est disponible ici :   https://www.senat.fr/seances/s201611/s20161115/s201 61115_mono.html#cribkmk_questionorale_14  89_109137   
- 152  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Je souhaiterais connaître la position du Gouverneme nt sur ces quelques  pistes de réflexion. Par ailleurs, madame la secrét aire d’État, envisagez-vous de  prendre d’autres mesures afin que tous les élèves p uissent faire un choix éclairé et  aient des chances égales, avec le système APB, de p oursuivre ses études dans la  filière et l’établissement supérieur de ses vœux ?  Mme Clotilde Valter, secrétaire d’État auprès de la  ministre du travail, de  l’emploi, de la formation professionnelle et du dia logue social, chargée de la  formation professionnelle et de l’apprentissage . Madame la sénatrice Sylvie  Robert, je suis mandatée par Mme la ministre de l’é ducation nationale et par mon  collègue Thierry Mandon pour répondre à votre quest ion. L’orientation des élèves  est un des champs de réflexion et de travail du Gou vernement depuis 2012, dans la  perspective de la lutte que nous menons contre le d écrochage scolaire. C’est dans ce  cadre que le parcours Avenir a été mis en place, à la rentrée 2015, pour délivrer une  information personnalisée à chaque élève, et ainsi favoriser l’élaboration d’une  orientation cohérente. Cet accompagnement personnal isé en lycée, dispensé dès la  classe de seconde, représente d’ores et déjà deux h eures par semaine en moyenne.  Des actions ont également été engagées pour amélior er le continuum de formation  bac-3/bac+3, telles que la généralisation du consei l d’orientation anticipé en classe  de première, le renforcement du rôle de la commissi on académique des formations  post-baccalauréat, l’amélioration de l’articulation  des programmes du second degré  et du supérieur par la rénovation en profondeur des  programmes, le renforcement  des passerelles et l’évolution de l’offre pédagogiq ue.  Je tiens également à rappeler que le dispositif adm ission post-bac n’est,  pour les élèves, qu’un outil d’expression des vœux.  Le choix de l’orientation se fait  bien évidemment en amont de la formulation de ces d erniers sur le portail ; c’est le  fruit d’une réflexion que l’élève mène avec l’aide de l’équipe pédagogique et grâce  aux ressources de l’ONISEP, l’Office national d’inf ormation sur les enseignements  et les professions. Ce portail a fait l’objet d’évo lutions importantes, qui visent à  améliorer l’information et à permettre à chaque élè ve de formaliser un choix  réfléchi, que ce soit en le confortant dans son cho ix ou en lui conseillant une autre  orientation. De plus en plus, ce portail permet en effet aux élèves de recevoir un  conseil. La très grande majorité des universités l’ utilisent désormais pour formuler  des avis : on recense plus de 500 000 avis ainsi dé livrés par les universités au cours  de la dernière année. Les équipes éducatives ont ét é formées à cet effet dans chaque  académie, au niveau des bassins de formation des ét ablissements. Les actions mises  en œuvre sur le terrain, à l’instar des Cordées de la réussite et des parcours  d’excellence, lancés à la rentrée de 2016, doivent aussi être mentionnées.  Ces politiques commencent à porter leurs fruits : n ous enregistrons des  résultats extrêmement positifs, avec une baisse du nombre de jeunes sortis sans  qualification, inférieur cette année à 100 000, le taux de jeunes de 18 à 24 ans non  qualifiés étant désormais, dans notre pays, plus fa ible qu’en Allemagne ou au  Royaume-Uni.  J’ai bien pris note, madame la sénatrice, des quest ions très précises que  vous avez posées sur un certain nombre de points. J e ne suis pas en mesure d’y  répondre, mais je les transmettrai à Mme la ministr e de l’éducation nationale et à  Thierry Mandon. 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 153  -       Mme Sylvie Robert . Madame la secrétaire d’État, je vous remercie  vivement de cette réponse, et j’ai bien noté que me s questions précises obtiendront  des réponses précises. Mon intention n’était vraime nt pas de critiquer le système  APB, qui s’est en effet beaucoup amélioré. Je souha itais simplement souligner la  difficulté que rencontrent certains élèves, et leur s familles avec eux, pour élaborer  de façon libre et éclairée leur parcours profession nel.  3.  Les divers régimes de responsabilité envisageables et ceux  envisagés  Les régimes de responsabilité envisageables ont ten dance à mettre  en cause soit le fabricant, soit le propriétaire, s oit l’utilisateur . Les cas  d’accident risquent en effet de se multiplier à raison de la d iffusion de  systèmes autonomes, notamment de robots.  Vos rapporteurs jugent donc nécessaire de se poser d’autres  questions que celle d’une reconnaissance de la pers onnalité juridique des  robots .  L’association EuRobotics  (« European Robotics Coordination  Action »), en charge du programme de recherche de l ’Union européenne en  robotique avec l’objectif de favoriser le développe ment de la robotique en  Europe, a proposé le 31 décembre 2012 un projet de livre vert sur les aspects  juridiques de la robotique 1. Dans ce projet de livre vert, deux situations son t  distinguées : celles où un robot cause un dommage d u fait d’un défaut de  fabrication et qui justifient une responsabilité du  fait des produits  défectueux 2 et celles où un robot cause un dommage dans le cad re de ses  interactions avec des humains dans un environnement  ouvert. Dans ce  dernier cas, avec des robots de nouvelle génération  dotés de capacité  d’adaptation et d’apprentissage et dont le comporte ment présente un certain  degré d’imprévisibilité, le régime de la responsabi lité du fait des produits  défectueux n’est pas approprié. Le cadre juridique applicable pourrait donc  s’inspirer, selon les auteurs du livre vert, de deu x régimes traditionnels  (responsabilité du fait des animaux  ou responsabilité du fait d’autrui ,  comme celle des parents si l’on choisit d’assimiler  les robots cognitifs aux  enfants) ou, encore, d’un code de conduite éthique applicable aux robots  et  qui reste à rédiger.  Vos rapporteurs notent que quatre régimes de respon sabilité  pourraient en réalité trouver à s’appliquer aux acc idents causés par des                                                    1 Cf. http://www.eu-robotics.net/cms/upload/PDF/euRobotic s_Deliverable_D.3.2.1_Annex_Suggesti  on_GreenPaper_ELS_IssuesInRobotics.pdf    2 La directive n° 85/374/CEE du Conseil du 25 juille t 1985 sur la responsabilité du fait des produits  défectueux établit le principe de la responsabilité  objective (responsabilité sans faute) du fabricant  en  cas de dommages provoqués par un produit défectueux . 
- 154  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        robots : le régime de responsabilité du fait des produits défectueux 1, celui  de la responsabilité du fait des animaux 2, celui de la responsabilité du fait  d’autrui 3, ou, encore, celui, traditionnel 4, de la responsabilité du fait des  choses , mais qui ne s’applique que de façon résiduelle pa r rapport au régime  de responsabilité du fait des produits défectueux.  Le robot est considéré comme une chose dans le droi t civil français.  La responsabilité du fait des choses , en tant que régime de responsabilité  objectif codifié par l’ancien article 1384 du code civil, signifie que pour  qu’elle soit appliquée, la chose doit être impliqué e dans le dommage et  qu’elle joue un rôle actif  (comme le fait d’être en mouvement ou de toucher  la victime) dans l’occurrence dudit dommage. C’est l’individu considéré  comme « gardien » de la chose qui est responsable d e la réparation du  dommage causé. Cependant, si le dommage est causé p ar une faille de  sécurité du robot, le régime de responsabilité pour  le dommage causé par la  chose s’applique au fabricant du robot.  Selon Arnaud Touati et Gary Cohen 5, le régime de responsabilité du  fait des choses laisse planer des incertitudes face  à des biens autonomes .  En effet la jurisprudence requiert, pour appliquer ce régime, d’avoir la garde  de la chose pour en être tenu responsable. Or cette  garde se matérialise par  un pouvoir de contrôle, de direction et d’usage. Ma is alors que l’on conçoit  facilement l’usage d’une intelligence artificielle (utiliser le logiciel, exploiter  ses capacités), en avoir la direction et le contrôl e semblent deux éléments  beaucoup plus difficiles à envisager face à des sys tèmes d’intelligence  artificielle autonomes, de surcroît non matérialisé s physiquement 6.  Concernant ce régime de responsabilité applicable à  l’intelligence  artificielle et aux robots, Rodolphe Gélin et Olivi er Guilhem estiment, quant  à eux, intéressant de noter que la responsabilité d u fait des choses peut  appréhender certaines caractéristiques propres des robots comme  leur  polyvalence, leur capacité d’apprentissage et d’int eraction . En revanche,  l’autonomie décisionnelle semble davantage poser pr oblème. Si le robot agit  de façon autonome, qui est son gardien ? Le concept eur de son intelligence  artificielle ou le propriétaire qui a réalisé son a pprentissage ?                                                    1 Codifié aux articles 1386-1 et suivants du code ci vil, il vise à engager la responsabilité du  producteur de robots dès lors que ces derniers, aya nt causé un dommage, n’offrent pas « la sécurité  à laquelle on peut légitimement s’attendre » . Ce critère de sécurité légitime présente l’intérê t  d’être flexible.  2 Pour les cas où un individu est déclaré responsabl e des actes dommageables commis par un animal  dont il a la garde ou la propriété.  3 Pour les cas où un individu est déclaré responsabl e des actes dommageables commis par un tiers.  4 Issu du fameux ancien article 1384 du code civil.  5 Article « Le droit à l’épreuve de l’intelligence artificielle  » du 28 novembre 2016 paru dans la  revue Village de la Justice.  6 Même en présence d’une application matérielle de l ’intelligence, tel qu’un robot, le problème de la  garde reste posé, de sorte que l’utilisateur ne con trôle pas effectivement le système, il peut  simplement l’allumer ou l’éteindre. 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 155  -       À ce niveau, le fait de mettre en place une responsabilité en cascade   pourrait être envisagée. Dans la mesure où trois ou  quatre acteurs sont en  présence (le producteur de la partie physique du ro bot, le concepteur de  l’intelligence artificielle, l’utilisateur et s’il est distinct de ce dernier, le  propriétaire), il est possible d’imaginer que chacu n puisse supporter une  part de responsabilité selon les circonstances dans  lesquelles est survenu le  dommage. Arnaud Touati et Gary Cohen plaident de mê me pour offrir à  l’intelligence artificielle un statut particulier, différent de celui réservé à la  chose et protecteur en cas d’accident, du type « chaîne de responsabilités  »,  allant du concepteur à l’utilisateur, en passant pa r le fabricant, le fournisseur  et le distributeur.  À l’heure où d’autres juristes, tel Alain Bensoussa n, prônent la  création d’une personnalité juridique autonome pour  les systèmes  d’intelligence artificielle, il est important d’ identifier des pistes qui ne  fassent pas courir le risque de déresponsabiliser l es acteurs du secteur, à  commencer par les industriels de la robotique .  En outre, il conviendrait de réfléchir à la possibi lité d’instituer des  systèmes d’assurance spécifiques, voire des assuran ces obligatoires. La  Fédération Française de l’Assurance a ainsi mis en place dès la fin 2014 une  commission spécialisée dans les questions du numéri que qui a pour objectif  de structurer un écosystème plus favorable au numér ique tout en respectant  les enjeux concurrentiels entre les assureurs. Cett e Commission, composée  de 26 représentants des sociétés d’assurances, est présidée par Virginie  Fauvel, en charge du Digital & Market Management d’ Allianz France. La  commission a notamment pour mission :  - d’analyser les enjeux collectifs attachés à la tran sformation digitale  pour le secteur,  - d’étudier les moyens de consolider la confiance ent re les assureurs  et les assurés dans cette transformation,  - de promouvoir l’innovation et notamment une régleme ntation  adaptée et graduée (principe du bac à sable régleme ntaire).   Cette commission a lancé plusieurs actions concrète s en 2016, dont :   • une initiative pour le Legal Design, qui vise à lutter contre la  surabondance de l’information, grâce à des infograp hies et vidéos  permettant de rendre l’information juridique plus v isuelle et plus facilement  compréhensible par les assurés ;  • une rencontre avec une trentaine de start-up InsurTech  en  décembre 2016, afin de renforcer les liens entre le s assureurs et les « jeunes  pousses » ;  • L’organisation d’une Learning Expedition  en Silicon Valley et au  CES de Las Vegas en janvier 2017. 
- 156  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Pour l’année 2017, plusieurs thématiques ont été dé finies comme  prioritaires par la commission :  • Véhicules connectés/autonomes  : une bonne utilisation des données  des véhicules connectés permettra une meilleure pré vention des risques  d’accidents (ex : localisation de zones accidentogè nes). Par ailleurs, il est  nécessaire d’anticiper l’arrivée des véhicules auto nomes afin de proposer des  produits d’assurance adaptés ;  • Blockchain : cette technologie pourrait permettre de simplifie r  l’identification et la preuve d’assurance, ainsi qu e d’automatiser les  procédures d’indemnisation (l’un des exemples étant  l’indemnisation  automatique des voyageurs en cas de retard d’avion)  ;  • Intelligence artificielle : la puissance de calcul des ordinateurs et  l’augmentation exponentielle du nombre de données v ont permettre à  l’intelligence artificielle d’offrir de très nombre uses applications nouvelles :  reconnaissances vocales, reconnaissances d’images, assistants virtuels,  véhicules autonomes…  Selon la Fédération Française de l’Assurance  (FFA) interrogée par  vos rapporteurs, l’intelligence artificielle est un  sujet naissant sur lequel les  impacts et les solutions ne sont pas encore connus .  En termes de réglementation, il faudra par conséque nt trouver un  équilibre entre un encadrement qui ne bride pas l’i nnovation et le fait  d’apporter suffisamment de protection aux consommat eurs . De nouvelles  questions vont émerger avec ces nouvelles technolog ies, et notamment  certaines concernant l’assurance et ses régimes.  Mais la Fédération Française de l’Assurance estime qu’il est encore  trop tôt pour y répondre  car elle n’a pas aujourd’hui de visibilité suffisa nte  sur les applications futures de ces technologies, e lle assure qu’en tout état de  cause le droit et l’assurance accompagneront les nouveaux  risques , ce dont  se réjouissent vos rapporteurs. Avec l’émergence de  nouvelles formes  d’intelligence artificielle et de robotique, il pou rrait être envisagé de mettre  en place de nouveaux régimes d’assurance , voire de créer une assurance  obligatoire .  Enfin, vos rapporteurs s’interrogent sur la question de la   responsabilité juridique des algorithmes , par exemple le cas d’un moteur  de recherche pour les suggestions qu’il peut propos er à ses utilisateurs.  Dans l’arrêt n° 625 du 19 juin 2013 de la Première chambre civile de  la Cour de cassation 1, la plus haute juridiction judiciaire a en effet c onsidéré  que Google ne pouvait pas être tenu pour responsable de s mots proposés  d’après un algorithme construit par ses soins . L’explication du  raisonnement des juges est le suivant : « la fonctionnalité aboutissant au                                                    1 L’intégralité de l’arrêt rendu par la Cour de la C assation est disponible ici :  https://www.courdecassation.fr/jurisprudence_2/prem iere_chambre_civile_568/625_19_26825.html   
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 157  -       rapprochement critiqué  est le fruit d’un processus purement automatique da ns son  fonctionnement et aléatoire dans ses résultats, de sorte que l’affichage des « mots  clés » qui en résulte est exclusif de toute volonté  de l’exploitant du moteur de  recherche d’émettre les propos en cause ou de leur conférer une signification  autonome au-delà de leur simple juxtaposition et de  leur seule fonction d’aide à la  recherche  ».   Dans la mesure où la saisie semi-automatique de Goo gle fonctionne  uniquement à partir d’algorithmes, la Cour de cassa tion estime qu’il n’est  pas possible d’en déduire que la responsabilité de l’entreprise puisse être  engagée. Pour la Cour de cassation, les algorithmes ne sont donc pas  coupables .  4.  Les différenciations du droit applicable selon le t ype d’agents  autonomes : robots industriels, robots de service, voitures  autonomes et dilemmes éthiques afférents  Le livre blanc « droit de la robotique » que le SYM OP a publié en  2016 contient d’utiles réflexions à ce niveau, nota mment sur les robots  industriels. La question de la sécurité des robots implique, en amont,  l’établissement d’une définition de la collaboratio n et de l’interaction  homme-robot. La norme ISO 8373 : 2012  établit la définition  de certains  termes caractérisant une interaction entre l’homme et le robot 1. Ainsi, à  l’article 2.29 de la norme, l’interaction homme-rob ot est définie comme un  « échange d’information et d’actions entre l’homme et  le robot pour exécuter une  tâche, au moyen d’une interface utilisateur  », notamment au moyen d’échanges  vocaux, visuels ou tactiles.   Le Parlement européen et le Conseil de l’Union euro péenne ont  adopté la directive 2006/42/CE 2, dite directive « Machines », dont l’objectif  est d’assurer « la libre circulation des machines au sein du marché  intérieur tout en  garantissant un haut niveau de protection de la san té et de la sécurité »,  impliquant une harmonisation des exigences de chaque État membre e n  termes de santé et de sécurité  concernant la conception et la production de  machines. Les parties prenantes concernées par la d irective Machines  doivent respecter des obligations directement liées  à leur statut :  - le fabriquant est responsable de la conformité de l a machine aux  exigences de santé et de sécurité. La conformité du  produit est certifiée  par un marquage « CE » sur la machine ;                                                    1 Cette norme ISO définit ainsi les termes de « fonct ionnement collaboratif » (article 2.25), de  « robot de collaboration » (article 2.26), et « [d’ ] interaction homme-robot » (article 2.29).  L’intégralité du texte est disponible ici : https://www.iso.org/obp/ui/#iso:std:iso:8373:ed-2:v 1:fr    2 Directive 2006/42/EC du Parlement européen et du Co nseil du 17 mai 2006 relative aux  machines et modifiant la directive 95/16/CE. L’ense mble des dispositions contenues dans cette  directive est accessible ici : http://eurlex.europa.eu/LexUriServ/LexUriServ.do?uri=OJ:L:200 6:157:0024:0086:fr:PDF   
- 158  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        - l’importateur peut, en plus de transmettre à l’auto rité de surveillance  du marché certaines informations concernant le prod uit, assumer une  responsabilité juridique par rapport au produit imp orté ;  - le distributeur doit veiller à la conformité des pr oduits qu’il met sur le  marché, et l’assembleur et l’installateur doivent v eiller à ce que le  produit demeure conforme.   Le code du travail  contient également de nombreuses dispositions  concernant les exigences de santé et de sécurité . Une partie de la directive   2006/42/CE a ainsi été transposée dans le droit fra nçais aux articles  R. 4311-4 et suivants du code du travail. En outre,  les différentes dispositions  relatives aux exigences de santé et de sécurité pré sentes dans le code du  travail affirment que la sécurité et la protection de la santé des travai lleurs  sont assurées par l’employeur et s’appliquent dans le cadre de l’utilisation  de robots industriels ou de services . L’employeur doit respecter les  exigences de conformité en vigueur et est tenu de p rendre des mesures  adaptées à l’utilisation de robots, telles que des actions de prévention des  risques professionnels, des actions d’information e t de formation, ou encore  assurer des conditions d’utilisation sécurisée des robots.   Il est important de noter, comme le relève le livre  blanc du SYMOP  « Droit de la robotique  », que « la cour de Cassation a déjà retenu la responsabilit é  d’employeurs en cas d’infractions à la législation relative à la sécurité des  travailleurs dans le cadre d’utilisation de robots  », notamment dans le cas du  décès d’un travailleur dans une usine d’emballage 1 ou d’un employeur ayant  fait travailler un salarié sur une ligne de fabrica tion robotisée sans prendre  les mesures de sécurité nécessaires 2.  Les robots de service posent différentes questions juridiques, dont  les développements précédents ont montré que les enjeux en termes de  responsabilité ou de sécurité n’étaient pas insurmo ntables .  En revanche, pour ce qui concerne les voitures autonomes , le besoin  d’essais à grande échelle et en situation réelle ap pelle une clarification du  cadre juridique . Il s’agit à la fois d’ enjeux économiques et de sécurité .   Le cadre légal auquel sont soumises les expérimenta tions des  voitures autonomes peut être examiné sous différent s aspects. Au regard du  droit privé international , certaines dispositions contenues dans la  Convention de Vienne sur la circulation routière du  8 novembre 1968 ,  comme l’obligation de présence d’un conducteur et le cont rôle de celui-ci  sur le véhicule en mouvement , peuvent constituer d’éventuels obstacles  juridiques à la généralisation de voitures autonome s en France. Seuls les  véhicules dotés de systèmes partiellement autonomes  (comme les systèmes  d’aide à la conduite) sont autorisés à la circulati on sur la voie publique, et le                                                    1 Arrêt n°02-87666 du 30 septembre 2003 de la chambre  criminelle de la Cour de cassation.   2 Arrêt n°01-21192 du 16 septembre 2003 de la deuxièm e chambre civile de la Cour de  cassation.  
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 159  -       chauffeur doit avoir le contrôle du véhicule. Cette  convention internationale,  bien qu’encore récemment amendée, nécessitera de no uvelles modifications  du fait de l’intégration croissante de systèmes d’a ide à la conduite, de  systèmes autonomes et de systèmes d’intelligence ar tificielle dans les  véhicules automobiles.  L’état actuel du droit communautaire peut également  constituer un  obstacle juridique à la circulation de véhicules in telligents sur la voie  publique. L’adoption de la directive 2010/40/UE du Parlement européen et  du Conseil du 7 juillet 2010 concernant le cadre po ur le déploiement de  systèmes de transport intelligents dans le domaine du transport routier et  d’interfaces avec d’autres modes de transport  a permis l’instauration d’un  cadre juridique accélérant le déploiement des systè mes de transport  intelligents, qui pourrait servir de modèle pour l’ adoption d’une directive  spécifique aux voitures numériques afin de coordonn er les législations des  États membres sur le déploiement des voitures intel ligentes. Néanmoins,  vos  rapporteurs constatent que  le droit communautaire ne prévoit pour le  moment pas de cadre normatif spécifique permettant l’harmonisation de  l’expérimentation, du déploiement et de l’exploitat ion des véhicules  intelligents au sein de l’espace européen .   Cependant, l’adoption du règlement (UE) 2015/758  du Parlement  européen et du Conseil du 29 avril 2015 concernant les exigences en matière  de réception par type pour le déploiement du systèm e eCall embarqué fondé  sur le service 112 rendant obligatoire l’installation de terminaux  permettant aux véhicules de communiquer entre eux ( V2V) et avec les  infrastructures de transport intelligent (V2I) , permettent de poser les bases  du déploiement des véhicules intelligents en Europe .  Vos rapporteurs notent que les États-Unis disposent  de lois  autorisant l’expérimentation de voitures autonomes sur la voie publique ,  au niveau des États du Nevada depuis juin 2011, de Floride depuis avril  2012, de Californie depuis septembre 2012, du distr ict de Columbia depuis  janvier 2013, et du Michigan depuis fin 2013. D’autres projets de loi  concernant les voitures autonomes sont en cours d’a doption dans une  dizaine d’États . Ces lois  existantes ou en cours d’adoption  fixent les  conditions des tests sur la voie publique ainsi que  les normes de sécurité  applicables. Cependant, aucune harmonisation au niv eau fédéral n’est à ce  jour à l’étude.   En France, l’article R. 412-6-I du code de la route indique qu e tout  véhicule en mouvement doit avoir un conducteur . Dans l’état actuel de la  législation française, le conducteur du véhicule es t responsable en cas  d’accident de la route. Cependant, cette législatio n ne peut être appliquée  telle quelle aux accidents causés par des véhicules  autonomes car le  conducteur n’a pas le contrôle direct du véhicule.   La course à la voiture autonome et la perspective d e ses débouchés  massifs et de ses gains en termes de sécurité ou d’ environnement entre en 
- 160  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        tension avec le risque d’accident et surtout le flo u juridique en matière de  responsabilité. Le Gouvernement s’est vu confier la  tâche de déterminer le  régime juridique applicable et il y a donc lieu pou r vos rapporteurs, et, plus  largement, l’OPECST, de suivre cette mission sans i nterférer avec elle.  La  loi n°2015-992 du 17 août 2015 relative à la transi tion énergétique  pour la croissance verte contient des dispositions introduisant le cadre  expérimental visant à promouvoir l’expérimentation et le déploiement de  véhicules propres, incluant les voitures sans chauf feur .  Cette loi habilite le Gouvernement à agir par ordon nance concernant  l’autorisation d’expérimentation de véhicules à dél égation partielle ou totale  de conduite sur la voie publique. En ce sens, l’ordonnance n° 2016-1057 du  3 août 2016  relative à l’expérimentation de véhicules à déléga tion de  conduite sur les voies publiques autorise l’expérimentation de véhicules  intelligents sur la voie publique  sous condition de la délivrance d’une  autorisation accordée par le ministre chargé des tr ansports, après avis du  ministre de l’intérieur. Pour mémoire, le projet « Nouvelle France  industrielle », annoncé à la fin de l’année 2013 av ec le but de réindustrialiser  les territoires, anticipait l’arrivée des véhicules  à pilotage automatique d’ici à  2020.  Néanmoins, vos rapporteurs rappellent qu’ une mise en circulation  effective de véhicules autonomes sur la voie publiq ue soulève des  questionnements éthiques . Dans l’article « The social dilemma of autonomous  vehicles  »1 paru le 24 juin 2016 dans le magazine Science , Jean-François  Bonnefon, Azim Shariff et Iyad Rahwan affirment que  le choix opéré par  l’algorithme peut représenter de véritables dilemme s. Certains cas peuvent  conduire l’algorithme à prendre une décision basée sur un critère moral qui  lui aura été programmé à l’avance. Deux conceptions  s’affrontent selon les  auteurs : une conception utilitariste , qui postule qu’il faut minimiser les  pertes humaines , et une conception auto-protectrice qui postule que les  systèmes algorithmiques embarqués doivent avant tou t protéger ses  passagers à tout prix .  Au cours des six études qu’ils ont menées, les aute urs ont constaté  que les participants ont largement été en accord av ec le fait qu’il était plus  moral qu’un véhicule autonome sacrifie son passager  si cela permettait de  sauver un grand nombre de vies. Cependant, devant des situations  concrètes, de nombreux participants avaient la tent ation de faire le choix  du « passager clandestin »  en privilégiant les choix des véhicules autonomes  protégeant ses passagers à tout prix. De fait, si d es véhicules autonomes  dotés de codes moraux utilitaristes et des véhicule s étant programmés pour  protéger leurs passagers étaient commercialisés, le s participants  orienteraient davantage leur choix vers les véhicul es les protégeant à tout  prix.                                                     1 Les résultats de l’étude menée par les auteurs son t disponibles sur le site Internet du magazine  Science : http://science.sciencemag.org/content/352/6293/1573 .full   
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 161  -       Le laboratoire du MIT « moral machine  », visité par vos rapporteurs,  travaille notamment sur les dilemmes éthiques concernant les voitures  autonomes . Le dilemme du tramway inventé par Philippa Foot a  été réaffiné  et testé. Les résultats provisoires des tests condu isent cette équipe à  identifier différents facteurs de choix : le nombre  de tués (on préfère la  solution qui réduit le nombre de morts), le fait de  sacrifier en priorité des  personnes qui transgressent les règles (exemple du voleur), le fait de sacrifier  en priorité un animal plutôt qu’un être humain, le fait de sacrifier en priorité  une personne plus âgée plutôt qu’une personne plus jeune et a fortiori  un  enfant, le fait de sacrifier en priorité un homme p lutôt qu’une femme… Ces  hypothèses soulèvent néanmoins la question du cadre  éthique dans lequel  situer les voitures autonomes.  Le 6 février 2017 a été donné le coup d’envoi d’un programme  européen de trois ans baptisé « Autopilot ».  Pour la France, Versailles  fera  partie des cinq lieux d’expérimentation en Europe, avec l’objectif d’améliorer  l’efficacité des véhicules autonomes grâce à l’expl oitation des données  externes, produites par l’infrastructure, les objet s connectés… et les usagers.  On compte 43 acteurs impliqués dans le projet, cons tructeurs automobiles et  sous-traitants, acteurs des télécoms, instituts de recherche... On y trouve  notamment PSA, IBM, Valeo, Continental, TomTom, Stm icro ou Thales. Cinq  territoires ont été choisis pour tester des concept s de communication entre  véhicules autonomes et systèmes d’information exter nes, en France,  Finlande, Espagne, Italie et Pays-Bas. Un projet si milaire sera lancé en Corée.  Plusieurs types de configuration seront testés : co nduite en milieu urbain,  sur autoroute, stationnement autonome. En France, c ’est Versailles qui  accueillera les tests, sous l’impulsion de l’instit ut Vedecom, qui a mis au  point un prototype fonctionnel de véhicule autonome  de niveau 4 (100 %  autonome dans des zones précises).  Par ailleurs, une autre expérimentation de voitures  autonomes est  conduite dans un partenariat franco-allemand , visant la mise en place à  partir de mars 2017 du premier site expérimental transfrontalier  de tests de  voitures autonomes. Il s’agira en effet d’une zone allant de Metz à Merzig  dans la Sarre, avec des tronçons d’autoroutes, de r outes et de zones urbaines.  Il s’agit d’un complexe ouvert à tous les construct eurs, équipementiers ou  entreprises du numérique ou des télécommunications.  La France et  l’Allemagne entendent ainsi rattraper leur retard e n matière  d’expérimentation de voitures autonomes et se place r ensuite à l’avant-garde  de la définition des futures règles applicables (st andards ou réglementation).  Concernant l’assurance applicable aux voitures auto nomes, il  apparaît nécessaire de se doter à terme, sur un pla n global dans tous les États  membres de l’UE (voire au-delà), d’un système d’assurance obligatoire  afin  de garantir le dédommagement total des victimes d’a ccidents causés par ce  type de véhicules. 
- 162  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        C.  LA PRISE EN COMPTE GRANDISSANTE DES ENJEUX ÉTHIQUES   1.  Le cadre national de la réflexion sur les enjeux ét hiques de  l’intelligence artificielle  La place des systèmes d’intelligence artificielle e t des machines  utilisant ces technologies, notre dépendance à leur  égard et la maîtrise que  nous conservons de leur évolution sont des question s qui méritent d’être  débattues dès aujourd’hui .  Il convient d’ anticiper les problèmes posés par l’intelligence  artificielle et d’ accompagner ses usages d’une réflexion éthique .  Comme il a été vu, la science-fiction, avec Isaac A simov, a envisagé  la question et proposé des lois de la robotique, ma is comment garantir, audelà du statut juridique du robot et de ces lois, q ue ces technologies puissent  être maîtrisées, utiles et conformes à nos valeurs ? La réflexion sur les enjeux  éthiques de l’intelligence artificielle doit clarif ier le cadre dans lequel  s’inscrit la recherche en intelligence artificielle , ses usages ainsi que les  limites éventuelles qu’il faut fixer à l’intelligen ce artificielle. Pour Gérard  Sabah, les aspects pertinents sur lesquels l’éthiqu e de l’intelligence  artificielle doit réfléchir et se prononcer sont « les impacts de telles machines sur  la vie privée, sociale, politique et économique, ai nsi que les valeurs qui les soustendent et celles qu’elles impliquent  ». Il poursuit en affirmant que « la société  doit définir clairement les limites acceptables ent re la science et la fiction, le progrès  et les risques encourus, afin de préserver notre id entité et notre liberté  ».  La CERNA d’Allistene, déjà évoquée plusieurs fois, joue en la  matière un rôle majeur, elle a d’ailleurs produit d es rapports, dont il sera  rendu compte plus loin. Sa création est récente et fait suite aux demandes  parallèles en 2009 du Comité d’éthique du CNRS (COM ETS) et d’Inria. Le  rapport du COMETS sur l’éthique des Sciences et tec hnologies de  l’information et de la communication (STIC) a parti culièrement donné  naissance à la CERNA 1. Il convient de relever que le COMETS s’est, à  plusieurs reprises, penché sur les problèmes éthiqu es posés par les STIC 2.   Le rôle de la CERNA en matière de réflexion éthique  sur le  numérique est remis en perspective 3 avec les nouvelles missions dévolues à                                                    1 Rapport du COMETS sur l’éthique des STIC : http://www.cnrs.fr/comets/IMG/pdf/08rapportcomets091112-2.pdf   2 Il est loisible de mentionner l’existence de rappo rts sur le partage des données  (http://www.cnrs.fr/comets/IMG/pdf/2015-05_avis-come ts-partage-donnees-scientifiques-3.pdf ), sur  le contrôle des publications scientifiques avec les  nouveaux médias  (http://www.cnrs.fr/comets/IMG/pdf/mediaaviscometsav ril16-2.pdf ) ou, encore sur les sciences  citoyennes ( http://www.cnrs.fr/comets/IMG/pdf/comets-avis-entie r-sciences_citoyennes25_juin_2015.pdf ).  3 Selon Max Dauchet, président de la CERNA, cette de rnière a « pour mission de mener une  réflexion éthique au titre du monde de la recherche . La proximité dans le numérique étant  grande entre la recherche et les usages, la CERNA a  milité activement pour la création par  la loi pour une République numérique d'un dispositi f traitant plus largement des questions 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 163  -       la CNIL , après la loi du 7 octobre 2016 pour une Républiqu e numérique 1.  Aux termes de cette loi, la CNIL, qui se définit co mme l’autorité française de  contrôle en matière de protection des données perso nnelles 2, a en effet été  chargée de conduire une réflexion sur les questions  d’éthique liées au  numérique et aux algorithmes , ce qui la mène à animer le débat public en la  matière. Une page Internet dédiée a été créée 3. Il s’agit aussi de s’intéresser  aux questions de sociétés soulevées par l’évolution  des technologies  numériques. La CNIL a choisi d’y répondre par l’org anisation de débats  publics, d’ateliers et de rencontres. Selon elle, s on rôle consiste à « initier un  processus de discussion collectif que feront vivre tous ceux – institutions publiques,  société civile, entreprises – qui souhaitent y pren dre part en organisant des débats et  manifestations multiformes  ». Elle a ainsi mis en place une plateforme 4 pour  contacter l’équipe de la mission « éthique et numér ique », afin de permettre à  toute « institution publique, membre de la société civile ou entreprise » de  pouvoir prendre part au débat sur les algorithmes. Elle assurera la  coordination et la cohérence des diverses manifesta tions.   Un cycle de débats publics  intitulé « Les algorithmes en débat »  est  ainsi organisé par la CNIL en 2017. Pour la CNIL, l a réflexion doit porter  cette année sur « les algorithmes à l’heure de l’intelligence artific ielle ». Elle  retient que « ceux-ci occupent dans nos vies une place importante , bien  qu’invisible. Résultats de requêtes sur un moteur d e recherche, ordres financiers  passés par des robots sur les marchés, diagnostics médicaux automatiques,  affectation des étudiants à l’université : dans tou s ces domaines, des algorithmes  sont à l’œuvre. Ces derniers mois, le sujet des alg orithmes s’est invité dans le débat  public et a suscité une forte attention médiatique ». Différentes questions sont  posées 5.                                                                                                                                                  éthiques et sociétales, comme le CCNE le fait dans le secteur de la vie et de la santé. La  création d’un tel dispositif que la CERNA appelait de ses voeux, ayant été confié à la CNIL,  elle doit conduire à conforter la CERNA comme coord inateur du monde de la recherche au  sein du débat de société sur ces questions ». Il ajoute que « le rôle de la CERNA est à  positionner suite aux nouvelles missions dévolues à  la CNIL, sous l’angle des rapports  entre la recherche dans le numérique et la société  ».  1 Loi n° 2016-1321 du 7 octobre 2016 pour une Républ ique numérique.  2 Sa mission historique, conformément à la loi n° 78 -17 du 6 janvier 1978 modifiée à plusieurs  reprises, dont par la loi pour une République numér ique précitée, est de veiller à ce que  l’informatique soit au service du citoyen et qu’ell e ne porte atteinte ni à l’identité humaine, ni aux   droits de l’Homme, ni à la vie privée, ni aux liber tés individuelles ou publiques. Elle assure ainsi l a  protection des données à caractère personnel dans l es traitements informatiques mis en œuvre sur le  territoire français.  3 Cf. https://www.cnil.fr/fr/ethique-et-numerique    4 Cf. https://www.cnil.fr/fr/webform/contacter-lequipe-de -la-mission-ethique-et-numerique    5 S’agit-il d’une nouvelle révolution industrielle, ou d’un simple moyen d’améliorer la productivité ?  Les algorithmes sont-ils les nouveaux décideurs ? O nt-ils pour effet de nous enfermer dans une bulle  informationnelle, mettant en danger ouverture cultu relle et pluralisme démocratique ? Sont-ils au  contraire un moyen d’accéder à des idées, contenus,  données ou personnes inaccessibles ou invisibles  jusqu’alors ? Quelle transparence à l’ère des algor ithmes : comment concilier transparence et  propriété intellectuelle ? Faut-il repenser, face a ux progrès de l’intelligence artificielle, la  responsabilité des acteurs publics et privés ? Comm ent construire le libre-arbitre dans un monde  « algorithmé » ?  
- 164  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        À l’automne 2017, la CNIL rendra publique la synthè se des échanges  et des contributions. Il s’agira d’établir une « cartographie de l’état du débat  public  » et un « panorama des défis et enjeux  ». Des pistes ou des propositions  pour accompagner le développement des algorithmes d ans un cadre  éthique  pourraient faire par la suite l’objet d’arbitrages  par les pouvoirs  publics.  L’articulation et la complémentarité entre le travail de la  CERNA   qui représente le monde de la recherche, et celui d e la CNIL , chargée de la  dimension sociétale de la réflexion éthique, sont nécessaires  et pourraient  être formalisées. À ce stade, vos rapporteurs relèv ent que les manifestations  envisagées 1 sont le plus souvent organisées conjointement par la CNIL avec  la CERNA, le COMETS, l’AFIA, Universcience ou, enco re, le Genotoul de  Toulouse (plateforme éthique et bioscience).  Le Conseil général de l’économie (CGE) a rendu le 1 5 décembre 2016  un rapport au ministre de l’économie et des finance s portant sur les  « Modalités de régulation des algorithmes de traite ment des contenus »2. Ses  auteurs, Jacques Serris et Ilarion Pavel, montrent que les algorithmes de  traitement des contenus sont inséparables des donné es qu’ils traitent et des  plateformes qui les utilisent pour proposer un serv ice. Mais alors qu’il y a de  nombreux travaux sur la protection des données et s ur la loyauté des  plateformes, il y en a encore peu sur les algorithm es eux-mêmes . Ceux-ci  sont pourtant des moteurs d’innovations, avec la ré volution des réseaux  neuronaux et de l’apprentissage profond. Ce rapport  ne propose pas une  nouvelle régulation sectorielle qui s’appliquerait aux algorithmes. En  revanche, il souligne qu’il faut développer la capacité à tester et contrôler  les algorithmes – tout en préservant l’innovation. Ses auteurs prop osent cinq  pistes d’action qui ont pour objet la montée en compétence et le  développement de l’expertise des pouvoirs publics , mais appellent aussi au  développement de bonnes pratiques  dans les différents secteurs  économiques. Ils soulignent par ailleurs qu’il faut  préserver une image  positive des technologies  utilisées pour concevoir ou opérer des  algorithmes. C’est essentiel pour continuer à attir er les jeunes générations de  françaises et de français dans des filières de form ation exigeantes  (mathématiques, ingénieurs ou data scientists ) où la France est aujourd’hui  bien placée.  Vos rapporteurs relèvent que la plateforme scientifique  collaborative  « TransAlgo  »3, lancée en janvier 2017, portée par Inria et  placée sous la direction de Nozha Boujemaa, travail le de manière utile au  développement de pratiques transparentes et respons ables dans le  traitement algorithmique des données 4. Dans la notion de  « responsabilité », sont considérés à la fois le re spect des règles juriques et le                                                    1 Cf. https://www.cnil.fr/fr/les-partenaires-et-evenement s    2 http://www.economie.gouv.fr/cge/modalites-regulatio n-des-algorithmes-traitement-des-contenus    3 http://www.economie.gouv.fr/files/files/PDF/Inria_P lateforme_TransAlgo2016-12vf.pdf    4 https://www.inria.fr/actualite/actualites-inria/tra nsalgo   
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 165  -       respect des règles éthiques. Il s’agit de répondre aux préoccupations  exprimées d’ explicabilité, de loyauté, de neutralité, de non-di scrimination  des algorithmes  mais aussi des biais des données e t des algorithmes . Plus  récemment, un Institut « Convergence i2-DRIVE »  (son nom vient de  « Interdsciplinary Institute for Data Research : In telligence, Value and  Ethics ») porté par l’Université Paris-Saclay et lu i aussi piloté par Nozha  Boujemaa - incluant 14 partenaires académiques et b énéficiant de soutiens  industriels - a été accepté en avril 2017 dans le c adre de l’appel à projet du  PIA 2 et comporte un programme de travail sur dix a ns. Il vise la conjonction  des expertises en sciences du numérique et en scien ces humaines et sociales  pour l’innovation en matière de recherche et de for mation dans le domaine  des sciences des données et de l’intelligence artif icielle avec leurs enjeux  socio-économiques et éthiques. Cette conjonction an nonce aussi des  perspectives fécondes en matière de transfert et d’ innovation par la vision  systémique que proposera i2-DRIVE pour adresser les  défis technologiques  et éthiques de la transformation numérique à l’ère des Big Data et des  systèmes cognitifs.  Pour la CERNA , dans son rapport sur l’éthique de la recherche en  robotique , le respect de la vie privée  doit être une priorité dans la mesure  où les systèmes d’intelligence artificielle et les robots déplacent les frontières  d’utilisation, d’exploitation et d’usage, ce qui po se de nouvelles difficultés 1.  La conception des robots doit donc intégrer l’exigence de confidentialité  des données personnelles qu’ils traitent .  Ce rapport remarque également que les capacités d’a utonomie des  systèmes d’intelligence artificielle et des robots portent surtout actuellement  sur l’autonomie opérationnelle, mais demain leur autonomie sera de plus en  plus décisionnelle , issue de systèmes plus élaborés. Les robots auron t, de  plus, outre les développements en informatique, la possibilité d’une plus  grande ressemblance avec l’être humain , comme tente de le montrer le  chercheur Hiroshi Ishiguro au Japon. Les interrogations éthiques sur les  finalités d’un tel projet d’intelligence artificiel le humanoïde et sur ses  effets s’imposent . La ressemblance avec l’humain renvoie à l’hypothè se de  la « Vallée de l’étrange », introduite par Masahito  Mori en 1970. Cette sorte  de malaise ressenti par les êtres humains face à de s entités presque  semblables à eux, mais pas au point de s’y tromper a été présentée  précédemment de manière plus détaillée par vos rapp orteurs.  La CERNA a formulé neuf préconisations générales, sept sur  l’autonomie, cinq sur l’imitation du vivant et quat re sur l’homme  augmenté . Vos rapporteurs les rappellent ici de manière syn thétique :                                                    1 Ces systèmes ont la capacité de capter des données  personnelles (photos ou vidéos de personnes,  voix, paramètres physiologiques, géolocalisation…),  leur déploiement soulève donc des questions  liées à la protection de la vie privée et des donné es personnelles. 
- 166  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        - lorsque le chercheur s’exprime en public sur une qu estion de société  relative à son activité professionnelle, il doit distinguer son intervention  experte de l’expression de son opinion personnelle  ;  - les établissements de recherche se dotent de comités opérationnels  d’éthique en sciences et technologies du numérique  ;  - les établissements de recherche et les acteurs conc ernés mettent en  place des groupes de travail et des projets de rech erche interdisciplinaires   ouverts à l’international et incluant des chercheurs et des juristes  pour  traiter des aspects juridiques des usages de la rob otique ;  - les établissements de recherche et les acteurs conc ernés mettent en  place des actions de sensibilisation et de soutien  auprès des chercheurs et  des laboratoires de recherche dans le numérique. Lo rs de l’élaboration et  dans la conduite de ses projets le chercheur saisir a, si nécessaire, le comité  opérationnel d’éthique de son établissement ;  - lors de la conception d’un système numérique ayant la capacité de  capter des données personnelles , le chercheur se demandera si ce système  peut être équipé de dispositifs facilitant le contrôle de sa conformité à la  réglementation  lors de sa mise en usage ;  - le chercheur veillera à prendre en compte l’exposit ion potentielle de  ses recherches à des attaques numériques  ;  - si le chercheur considère que le projet vise un dév eloppement  pouvant avoir un impact important sur la vie des utilisateurs , il veillera à  en délibérer  avec les acteurs et les utilisateurs potentiels af in d’éclairer au  mieux les choix scientifiques et technologiques ;  - le chercheur veillera à documenter l’objet ou le système conçu et  à  en exposer les capacités et les limites . Il sera attentif aux retours  d’expérience à tous les niveaux, du développeur à l ’utilisateur ;  - le chercheur veillera à faire une communication mesurée  et  pédagogique  sachant que les capacités des objets et systèmes q u’il conçoit  peuvent susciter des questionnements et des interpr étations hâtives dans  l’opinion publique ;  - concernant l’autonomie, le chercheur doit se poser la question des  reprises en main que l’opérateur ou l’utilisateur p eut effectuer  et étudier la  possibilité ou non laissée à l’humain de « débrayer  » les fonctions  autonomes du robot . Il doit faire en sorte que les décisions du robot  ne  soient pas prises à l’insu de l’opérateur , être conscient des phénomènes de  biais de confiance , et être attentif à expliciter les limites des programmes  de perception, d’interprétation et de prise de déci sion , en particulier les  programmes qui visent à conférer une conduite moral e au robot. Le  chercheur doit évaluer jusqu’à quel point les logiciels d’interprétation d u  robot peuvent caractériser correctement une situati on  et discriminer entre  plusieurs situations qui semblent proches, surtout si la décision d’action est  fondée uniquement sur cette caractérisation . Il faut en particulier évaluer 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 167  -       comment les incertitudes sont prises en compte. Le chercheur doit analyser  la prévisibilité du système humain-robot  considéré dans son ensemble, en  prenant en compte les incertitudes d’interprétation  et d’action, ainsi que les  défaillances possibles du robot et celles de l’opér ateur , et analyser  l’ensemble des états atteignables par ce système. I l doit intégrer des outils de  traçage  dès la conception du robot. Ces outils doivent per mettre d’élaborer  des explications, même limitées, à plusieurs niveau x selon qu’elles  s’adressent à des experts de la robotique, à des op érateurs ou à des  utilisateurs ;  - en matière d’émotions, le chercheur étudiera, au re gard des fonctions  utiles du robot, la pertinence et la nécessité de susciter des émoti ons  et de  recourir à des aspects ou des comportements biomimé tiques , notamment  dans les cas de forte ressemblance visuelle ou comp ortementale entre un  robot et un être vivant. Dans les cas où l’apparenc e ou la voix humaines sont  imitées, le chercheur s’interrogera sur les effets que pourrait avoir cette  imitation . Le chercheur doit avoir conscience que la démarch e biomimétique  peut brouiller la frontière entre un être vivant et un a rtefact . Le chercheur  consultera sur ce brouillage le comité opérationnel  d’éthique de son  établissement ;  - pour les projets de recherche qui ont trait au déve loppement de la  robotique affective, le chercheur s’interrogera sur  les répercussions  éventuelles de son travail sur les capacités de socialisation de l’utilisateur  ;  - pour les projets qui mettent en présence des enfant s et des robots, le  chercheur doit se poser la question de l’impact de l’interaction enfant-robot   sur le développement des capacités émotionnelles de  l’enfant, tout  particulièrement dans la petite enfance ;  - pour les projets de recherche relatifs à des robots  susceptibles d’avoir  des effets sur l’affectivité des utilisateurs et de susciter leur attachement , le  chercheur devra élaborer un protocole de conception et d’évaluation  en  veillant à impliquer les compétences multidisciplin aires nécessaires et des  utilisateurs potentiels ;  - le chercheur doit être prudent dans sa communication sur les  capacités émotionnelles des robots et sur l’imitati on de la nature et du  vivant , notamment parce que l’expression des émotions, au  sens humain, par  un robot, est un leurre , et parce que l’imitation du vivant peut amener,  volontairement ou pas, à prêter à l’artefact des caractéristiques du vivant  ;  - les chercheurs en robotique réparatrice ou d’assist ance doivent  appliquer, en coordination avec les professionnels de santé, les aidants et les  patients, les principes d’éthique en usage dans le secteur mé dical  afin  d’arbitrer entre les exigences d’efficacité et de s écurité des soins, celles  d’autonomie et d’intégrité de la personne et, enfin , de protection de la vie  privée. Ces questions relèvent de l’éthique et non uniquement du droit en  cela qu’elles demandent à être arbitrées dans chaqu e cas particulier et  qu’elles ne reçoivent pas de réponse générale. Pour  en traiter, il faudra 
- 168  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        prendre avis auprès des comités opérationnels d’éth ique des sciences  médicales et veiller à ce que les compétences techn ologiques y soient  étroitement associées. Dans le cas d’organes roboti sés à vocation réparatrice,  le chercheur aura le souci de la préservation de l’autonomie de l’indivi du  équipé , à savoir de la maîtrise qu’il conservera autant q ue faire se peut sur  ses actions, et de la conservation de l’intégrité des fonctions autres qu e  celles concernées par la réparation . Dans le cas des dispositifs robotisés  visant l’augmentation, le chercheur veillera à la réversibilité  de celle-ci : les  dispositifs doivent être amovibles sans dommage s pour la personne,  autrement dit, sans que la personne perde l’usage d e ses fonctions initiales.  En vue de prévenir les discriminations induites par l’augment ation , le  chercheur se posera la question de l’incidence de l ’augmentation des facultés  et des capacités humaines induites par les disposit ifs qu’il développe sur le  comportement social de ceux qui en bénéficient ains i que, symétriquement,  de ceux qui n’en bénéficient pas.  La CERNA a formulé dans son second rapport, intitul é « Éthique en  apprentissage machine » , et rendu public en avril 2017, ses préconisations  sur  le machine learning  structurées autour de six thèmes directeurs : les données  des systèmes d’apprentissage (1-4), l’autonomie des  systèmes apprenants  (5-6), l’explicabilité des méthodes d’apprentissage  et leur évaluation (7-9), les  décisions des systèmes d’apprentissage (10), le con sentement dans le  domaine du numérique (11), la responsabilité dans l es relations  homme-machine (12-13), et l’organisation de la rech erche française sur  l’éthique du numérique (14-17) :  1.  Les concepteurs et entraîneurs des systèmes d’appre ntissages veillent à  la qualité des données d’apprentissage et aux conditions de leur  captation.  2.  Les entraîneurs doivent garantir que les données représentent un  miroir de la diversité culturelle.  3.  Les variables dont les données sont réglementées , les entraîneurs  doivent veiller à ce qu’elles ne soient pas discrim inantes (âge, sexe,  race, etc.), tout en respectant le principe de conf identialité des données.  4.  Le concepteur d’un système d’apprentissage automati que doit prévoir  des dispositifs de traçabilité du système .   5.  La machine ne doit pas introduire de biais de carac térisation et induire  en erreur l’utilisateur sur l’état de son système.  6.  Le concepteur doit maintenir un certain niveau de vigilance dans la  communication sur les capacités d’un système apprenant, afin de n e  laisser aucune place à l’interprétation ni à des fa ntasmes ou craintes  irrationnelles.   7.  Le concepteur doit veiller à l’ explicabilité , la transparence des actions  de son système apprenant, tout en maintenant un niv eau de  performance suffisant.  
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 169  -       8.  Tout en garantissant une meilleure explicabilité du  système, le  concepteur doit décrire les limitations des heuristiques d’explication  du système, en évitant notamment la création de bia is.   9.  Le concepteur d’un système apprenant apporte sa con tribution à  l’élaboration des normes et des protocoles d’évaluation de  l’apprentissage machine.   10.  Le concepteur doit garantir la place de l’humain dans les décisions  assistées par des machines apprenantes , afin d’éviter notamment la  création de biais ou l’installation de dépendance d e l’humain par  rapport aux décisions des machines.  11.  La mémorisation des traces des données personnelles utilisées dans le  processus d’apprentissage devra obtenir le consente ment de  l’utilisateur et en accord avec la législation sur la protection des  données personnelles en vigueur.   12.  Le concepteur du système doit y inclure des mécanismes de contrôle  automatiques ou supervisés.  13.  Le concepteur doit fournir une déclaration des intentions d’usage du  système informatique « de manière sincère, loyale e t complète » au  cours de son apprentissage.   14.  La création d’un réseau national de recherche dénom mé « Initiative  Fédérative de Recherche Numérique, Éthique et Socié té  » permettrait de  faire émerger un positionnement français sur les qu estions d’impact  sociétal et éthique des sciences et technologies du  numérique.   15.  La création de comités d’éthique opérationnels d’établissements en  science et technologie du numérique est conseillée.    16.  Les établissements sont également incités à lancer des initiatives sur  les aspects juridiques des usages des innovations du numérique, au  travers de groupes de travail et projets de recherc hes avec d’autres  acteurs concernés.   17.  Des actions de sensibilisation et soutien du chercheur par les  établissements  doivent être mises en place.  Le rapport produit par la CERNA présente, au total,  des  recommandations plus opérationnelles que celles fou rnies  par les autres  structures ayant rendu public des rapports similair es, telles que l’association  mondiale des ingénieurs électriciens et électronici ens ( Institute of Electrical  and Electronics Engineers  ou IEEE), qui regroupe plus de 400 000 membres, ou   les « 23 points d’Asilomar » issus de la conférence  « Beneficial AI 2017  »  (initiatives qui seront évoquées plus loin dans le présent rapport). La  singularité du rapport de la CERNA s’observe égalem ent par le fait que les  recommandations mises en avant concernent, pour la majeure partie  d’entre elles, des aspects techniques du développem ent de l’apprentissage  automatique , alors que le rapport de l’IEEE et les « 23 points  d’Asilomar » 
- 170  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        abordent des problématiques plus vastes, telles que  la question des  investissements, des relations entre les scientifiq ues et les décideurs, la  course à l’innovation entre les chercheurs, le béné fice collectif, la vie privée,  la défense ou encore les problèmes économiques et h umanitaires.   En outre, les 17 propositions avancées par ce rappo rt de la CERNA  misent davantage sur la pluridisciplinarité , qui est, selon les auteurs,  essentielle à la réflexion sur les considérations é thiques, juridiques et  scientifiques de l’apprentissage automatique .    Le Club informatique des grandes entreprises frança ises (CIGREF),  créé en 1970 à l’initiative de dirigeants de grande s entreprises, a lui aussi  réfléchi aux questions éthiques posées par l’intell igence artificielle et la  robotique. Deux rapports ont ainsi été rendus publi cs, dont vos rapporteurs  ont rencontré les auteurs. Le premier porte sur le thème de « l’éthique du  numérique »1 et a été rédigé par Flora Fischer, chercheuse en p hilosophie des  technologies à la Sorbonne et chargée de recherche au CIGREF, que vos  rapporteurs ont eu le plaisir d’auditionner. Le sec ond, qui se veut livre  blanc, porte sur la « Gouvernance de l’intelligence  artificielle dans les  grandes entreprises », et a été réalisé en partenar iat avec le cabinet Alain  Bensoussan Avocats 2.  Le premier rapport du CIGREF  sur « l’éthique du numérique »  montre que la technologie numérique est à la fois r elationnelle, d’usage et  fabriquée, comme toute technologie. L’éthique du nu mérique est donc à la  fois une éthique des usages et de la conception. Fl ora Fischer aime à rappeler  que le philosophe Gilbert Simondon disait que « toutes les technologies sont des  médiations »  et que le numérique crée un nouveau rapport au mon de, dans  lequel  il faut simplement être attentif à l’éthique des no uveaux usages et à la  démultiplication. Beaucoup d’entreprises qui naisse nt aujourd’hui avec le  numérique, tel que les start-up, mettent déjà en œu vre la privacy by design  et  l’éthique  by design, ce qui suppose d’anticiper les usages et la façon d ont tels  ou tels outils vont adapter les pratiques et de voi r quelles questions éthiques  cela va engendrer. Pour respecter ces objectifs éth iques,  il faut anticiper les  usages des outils dès la conception et prévoir des architectures souples,  suffisamment pour pouvoir agir rétroactivement sur les usages et sur la  conception. Il faut aussi explorer les limites des nouveaux outils et des  nouveaux services. Les GAFA ayant été les pionniers , ils ont imposé leurs  propres règles , ce qui pourra justifier une régulation, par exemp le en matière  de stockage et de traitement des données privées . Les entreprises qui vont  mettre en œuvre des services numériques passeront p ar la privacy by design 3,  et l’éthique  by design 4, ce qui sera plus facile pour des jeunes et petite s                                                    1http://cigref.fr/Publication/2014-CIGREF-Ethique-et -Numerique-une-ethique-a-reinventerRapport-mission-F-FISCHER.pdf   2http://www.cigref.fr/wp/wp-content/uploads/2016/09/ Gouvernance-IA-CIGREF-LEXING-2016.pdf   3 Respect de la vie privée dès le stade de la concep tion du produit.  4 Respect de règles éthiques dès le stade de la conc eption du produit. 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 171  -       entreprises que pour des grandes entreprises plus a nciennes. Cela  nécessitera une révision de l’architecture des plat eformes. Dans ce contexte  général, l’État ne peut et ne pourra qu’agir a posteriori .   Le second rapport du CIGREF, le livre blanc sur la « Gouvernance  de l’intelligence artificielle dans les grandes ent reprises » , apporte une  vision prospective  visant à permettre aux entreprises d’anticiper le passage  de la transition digitale que nous vivons déjà à la  « transition  intelligente »  à venir. Il présente l’intérêt de partir du cadre historique de  l’intelligence artificielle, en passant par ses déf initions (générale et  technique) et de ses modes d’expression (robots, av atar, chatbots …), afin de  montrer que l’intelligence artificielle confronte l e management de  l’entreprise à des situations émergentes multiples,  à la fois culturelles,  humaines (impact sur les manières de travailler), é thiques et juridiques… Les  entreprises devront être en mesure d’anticiper, par  exemple, l’évolution des  compétences, l’évolution de la réglementation, que ce soit sur la robotique  intelligente ou sur les différentes formes de l’int elligence artificielle.  Le livre blanc aborde également la question du droit prospectif  :  l’intelligence artificielle, du fait de son autonom ie, a un degré  d’imprévisibilité dans le cadre de son interaction avec les êtres humains, or,  en l’état actuel du droit, aucune règle ne serait d irectement applicable à la  responsabilité délictuelle de l’intelligence artifi cielle, ce qui peut paraître  discutable. Des craintes liées au développement de l’intelligence artificielle  font débat et posent questions.  Par exemple, la délégation de tâches à haute respon sabilité (décision,  recommandation) à des machines interroge sur le lib re arbitre et la place  laissée à la pertinence de l’interprétation humaine . L’entreprise ne saurait  donc contourner des questions éthiques  de deux ordres : l’éthique des  usages et l’éthique de la conception ( by design )… ». L’enjeu est de « saisir la  complexité du sujet et mieux comprendre les freins et leviers à actionner pour  accompagner au mieux les opportunités à venir » .    Vos rapporteurs ont, en outre, rencontré les animat eurs et des  chercheurs du projet ETHICAA  (Éthique et Agents Autonomes), financé par  l’Agence nationale de la recherche  (ANR) pour la période 2014 – 2017, dont  les rapports techniques et les publications sont di sponibles 1. Coordonné par  Grégory Bonnet (GREYC – Normandie Université), il a ssocie différents  partenaires 2 et chercheurs.  Les objectifs initiaux du projet peuvent être rappelés.  Les machines  et les logiciels (agents) deviennent de plus en plu s autonomes et agissent de  plus en plus sans être contrôlés par des utilisateu rs ou des opérateurs                                                    1 https://ethicaa.org  2 Les responsables scientifiques du projet pour les partenaires sont : Alain Berger (société Ardans) ;  Olivier Boissier (Institut Henry Fayol – ARMINES) ;  Pierre-Antoine Chardel (Institut MinesTélécom) ; Jean-Gabriel Ganascia (LIP6 – Université  Paris 6) ; Catherine Tessier (ONERA). 
- 172  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        humains. C’est pourquoi, la question de doter ces a gents autonomes de  comportements éthiques se pose.  L’objectif du projet ETHICAA est de définir ce que devrait être un  système composé d’un ou plusieurs agents artificiel s capables de gérer des  conflits éthiques, aussi bien au niveau individuel qu’au niveau collectif. Il y a  en effet des verrous scientifiques majeurs.  En premier lieu, les théories éthiques sont diffici les à mettre en  œuvre sous forme de principes éthiques opérationnel s.  En second lieu, ces principes éthiques opérationnel s sont eux-mêmes  difficiles à implanter parce qu’ils sont liés à l’é valuation courante de la  situation, dont l’automatisation rencontre de forte s limites.  En troisième lieu, d’un point de vue philosophique,  il existe de  nombreux principes éthiques et aucun d’eux n’est me illeur que les autres,  rendant ainsi difficile de choisir celui qui doit ê tre mis en œuvre. Enfin, les  systèmes informatisés sont de plus en plus ouverts et décentralisés, c’est-àdire impliquant des agents artificiels autonomes en  interaction avec d’autres  agents, des opérateurs ou des utilisateurs humains.  Dans ces circonstances,  la gestion des conflits éthiques entre différents a gents devient une question  cruciale et des méthodes originales sont nécessaire s pour répondre à cette  problématique.  Un état des lieux des travaux peut être fait en mars 2 017 : les  résultats intermédiaires des travaux du projet ETHI CAA se structurent en  trois points : (1) une réflexion autour des concept s éthiques à employer et des  domaines d’application sensibles ; (2) une producti on de modèles de  décision et de raisonnement éthiques ; (3) une fédé ration d’une communauté  de recherche autour de ces thématiques.  1.  Dans le domaine de la réflexion, deux études ont ét é produites :  • Un état de l’art dans le domaine de la philosophie morale et de  l’intelligence artificielle a permis de formuler de s définitions : agent artificiel  éthique (cadre idéal non réalisable en pratique) ; agent artificiel éthique  compétent (agent capable de justifier ses actes en fonction de critères  explicites) ; situation de conflit éthique.  • Une identification de quatre scénarios-clés intéres sants à des fins de  modélisation et d’expérimentation : un scénario de véhicule autonome, un  scénario de véhicule aérien piloté en tandem par un  agent artificiel et un  agent humain, un scénario d’agent de surveillance m édicale, un scénario  d’organisation et de coopération d’agents de gestio n de portefeuilles.  2.  Dans le domaine de la production, deux approches on t été mises  en œuvre et expérimentées sur une partie des scénar ios  mentionnés précédemment : 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 173  -       • Un travail sur des architectures d’agents se fondan t sur l’utilisation des  logiques d’actions, de logique modale et de logique  argumentative pour  modéliser et expliquer  a priori un raisonnement moral.  • Un travail sur la vérification formelle de propriét és éthiques ayant pour  but de vérifier a posteriori  si la spécification d’un système multi-agents  répond à des critères éthiques.  3.  Dans le domaine de la fédération d’une communauté d e recherche,  le projet s’axe sur deux points :  • Une interaction avec la communauté internationale d e recherche par  l’organisation d’un atelier international ainsi que  la participation au dépôt  d’une action COST Responsible Artificial Intelligence et à la IEEE Global  Initiative on Ethical Considerations in the Design of Autonomous Agents .  • La diffusion grand public au travers d’articles et conférences de  vulgarisation. À cela, s’ajoutent de nombreuses int erventions en séminaires,  journées d’études, tables rondes et interventions r adiophoniques.  Quant aux perspectives du projet ETHICAA , il s’agit de rassembler  les différents modèles de décision produits au sein  d’un même cadre de  conception auquel s’ajoutera la dimension multi-age nt, offrant ainsi une  grille de lecture unifiée pour concevoir des méthod es répondant aux  problématiques de régulation éthiques d’agents auto nomes. D’un point de  vue de développement, le projet ETHICAA envisage de  finaliser un logiciel  de démonstration orchestrant une simulation du scén ario de gestion  éthique d’actifs financiers , il s’agit en effet d’aboutir à une preuve de  concept (« proof of concept  ») à travers l’organisation et la coopération  d’agents de gestion de portefeuilles selon des règl es éthiques.  2.  Les nombreuses expériences anglo-saxonnes de réflex ion sur les  enjeux éthiques de l’intelligence artificielle  Les expériences de réflexion sur les enjeux éthiques de   l’intelligence artificielle, que ce soit aux États- Unis ou au Royaume-Uni ,  sont particulièrement nombreuses  et se sont multipliées de façon  impressionnante  dans la période récente. Ces expériences de réflexion sont  le plus souvent non gouvernementales et sont fréquemment financées par  des donations privées  : on peut relever que cette observation s’inscrit dans le  contexte d’une tradition de mécénat scientifique et technologique  aux  États-Unis, alors qu’en France le mécénat reste lar gement consacré à l’art et à  la culture.  Vos rapporteurs ont, en effet, observé une multipli cation  surprenante d’initiatives anglo-saxonnes, souvent coordonnées , visant la  prise en compte de principes éthiques dans la reche rche et les usages de  l’intelligence artificielle. Ils souhaitent les rap peler. 
- 174  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Il existe tout d’abord une structure plus ancienne que les autres, qui  reste jeune puisqu’elle a été créée en 2000, The International Society for Ethics  and Information Technology  (INSEIT), qui édite aussi sa propre revue. Cette  structure, qui rassemble beaucoup de chercheurs du monde académique, est  de plus en plus éclipsée par la multiplication réce nte des collectifs ou des  instituts se donnant pour rôles d’animer une réflex ion sur les enjeux éthiques  du numérique et plus spécifiquement de l’intelligen ce artificielle. Ces  initiatives plus récentes sont souvent financées pa r des fonds privés issus de  grandes entreprises du secteur et ont recours à des  plans de  communication aboutis .  L’une des principales initiatives est l’ Institut du futur de la vie ou  « Future of Life Institute  » (FLI) 1, fondé en mars 2014, qui est à l’origine en  janvier 2015 de la lettre d’avertissement sur les d angers potentiels de  l’intelligence artificielle, qui affirmait qu’étant  donné le grand potentiel de  l’intelligence artificielle, « il était important d’étudier comment la société peu t  profiter de ses bienfaits, mais aussi comment évite r ses pièges  ». Le FLI s’interroge  ainsi sur les conséquences économiques, légales et éthiques de  l’intelligence artificielle  et de l’automatisation des tâches et promeut le  développement d’une intelligence artificielle bénéf ique et fiable.  Le FLI, visité par vos rapporteurs en janvier 2017,  situé à Cambridge,  près de Boston (avec le MIT et Harvard), est une or ganisation à but non  lucratif, dont le financement repose sur d’importan tes donations privées. Il  se donne pour mission de « catalyser et soutenir la recherche et les initiativ es  visant la sauvegarde de la vie et proposant une vis ion optimiste de l’avenir  ». Il  s’agit de « tirer le meilleur profit des nouvelles technologies  et de prévenir les  risques potentiels pour l’humanité du développement  de l’intelligence artificielle  ».  Il soutient ainsi en 2016 et 2017, après un appel à  projets lancé en 2015, pas  moins de 37 projets de recherche destinés à préveni r les risques liés à  l’intelligence artificielle 2. Selon Max Tegmark, président du FLI, il existerai t  une « course entre le pouvoir grandissant de la technolog ie et le bon sens avec lequel  on la gère » : alors que « jusqu’ici, tous les investissements ont eu pour obj ectif de  rendre les systèmes plus intelligents, c’est la pre mière fois qu’il y a un  investissement sur l’autre aspect  ».  Lors d’un colloque à New York sur les défis posés p ar l’émergence  de l’intelligence artificielle, organisé le 14 octo bre 2015 par l’Institut de  recherche sur la criminalité et la justice des Nati ons Unies (UNICRI), Max  Tegmark était invité avec un autre expert 3 à s’exprimer devant quelques                                                    1 L’Institut a été fondé en mars 2014 par Max Tegmar k cosmologiste au MIT, Jaan Tallinn cofondateur de Skype, Anthony Aguirre physicien à l’U CSC et deux étudiants (Viktoriya Krakovna et  Meia Chita-Tegmark), figurent à son conseil consult atif l’informaticien Stuart J. Russell, le  biologiste George Church, le physicien Frank Wilcze k, les cosmologistes Stephen Hawking et Saul  Perlmutter, ou, encore, l’entrepreneur Elon Musk.  2 Il s’agit, par exemple, de développer une intellig ence artificielle capable d’expliquer ses décisions   ou, encore, de travailler sur l’alignement de l’int elligence artificielle sur les valeurs humaines.  3 Outre Max Tegmark, président du FLI, dont il a déj à été question, le second expert était Nick  Bostrom, philosophe, fondateur du Future of Humanit y Institute (FHI) de l’Université d’Oxford. 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 175  -       130 délégués de 65 États. Ils ont clairement soulig né les risques liés à  l’intelligence artificielle  et appelé à la mise en place d’une réflexion solide  sur l’éthique de l’intelligence artificielle .  Le second expert, Nick Bostrom, philosophe, fondate ur du Future of  Humanity Institute  (FHI) en 2005 au sein de l’Université d’Oxford (un ité de  l’Oxford Martin School ), rencontré par vos rapporteurs, a également fondé ,  dès 2004, un Institute for Ethics and Emerging Technologies (IEET), proche  du mouvement transhumaniste.  De manière similaire au Future of Humanity Institut e, ont été créées  plusieurs structures qui travaillent toutes en rése au les unes avec les autres,  au sein de l’Université de Cambridge, un Centre for the Study of Existential  Risks  (CSER) créé en 2012 et un Leverhulme Centre for the Future of  Intelligence  créé en 2016 (tous les deux visités par vos rapport eurs), au sein  de l’Université de Berkeley, un Machine Intelligence Research Institute   (MIRI), créé lui aussi en 2016 et animé par Stuart Russel 1, rencontré par vos  rapporteurs.  Il peut être relevé que les anciens dirigeants de P aypal, Elon Musk  (actuellement patron de Tesla et SpaceX) et Sam Alt man se sont fixés pour  but de promouvoir et de développer des outils d’int elligence artificielle en  open source . Ils ont ainsi fondé, le 11 décembre 2015, la « fondation  OpenAI  »,  qu’ils président, association à but non lucratif vi sant à réfléchir aux  questions de société que pose l’intelligence artifi cielle. Vos rapporteurs ont  eu la chance de visiter cette association basée dan s la Silicon Valley et d’en  rencontrer des responsables.  Le dernier exemple, peut-être le plus significatif est le « Partnership  on AI  » formé en septembre 2016 par Google, Microsoft, F acebook, IBM et  Amazon afin de réfléchir et de faire avancer de man ière collective les  discussions sur l’intelligence artificielle. Yann L eCun et Demis Hassabis ont  joué un rôle essentiel dans ce partenariat. Vos rap porteurs se sont réjouis du  fait qu’ Apple a rejoint cette initiative le 26 janvier 2017  le jour de leur  visite du siège de l’entreprise 2. La responsable des affaires publiques  d’Apple a alors expliqué à vos rapporteurs que les valeurs spécifiques à                                                    1 Stuart Russell travaille à l’Université de Berkele y, où il est professeur au département  d’informatique et directeur du centre pour l’étude des systèmes intelligents. Ancien membre du  bureau exécutif de l’AAAI (American Association for  Artificial Intelligence), il a reçu de nombreux  prix scientifiques Il est l’auteur de plus de cent articles et de plusieurs best-sellers sur l’intelli gence  artificielle. Il a co-rédigé le principal manuel di sponible sur l’IA avec Peler Norvig, ancien  professeur à l’Université de Californie du Sud, dir ecteur scientifique chez Google, qui auparavant  travaillé pour la NASA sur l’intelligence artificie lle et la robotique, ainsi que pour Junglee sur  l’extraction d’informations par Internet., membre d e l’AAAI et de l’ACM (Association for  Computing Machinery).  2 Lors de la visite de vos rapporteurs au siège appe lé « campus Apple », situé en plein centre de la  Silicon Valley au 1 InfiniteLoop à Cupertino en Cal ifornie, un communiqué de presse leur a été  communiqué par des responsables de l’entreprise. Il  expliquait qu’Apple rejoint ce partenariat en  tant que membre fondateur (« founding partner »). L e communiqué de presse se trouve ici :  https://www.partnershiponai.org/2017/01/partnership -ai-update/  
- 176  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Apple, en particulier la protection des données per sonnelles et de la vie  privée, pourraient être mieux prises en compte .  Apple a donc rejoint officiellement, et en tant que  membre  fondateur, avec Facebook, Google, Microsoft, IBM et  Amazon, les activités  du collectif voué au développement éthique de l’int elligence artificielle, ce  « Partnership on AI  ». Les six « GAFAMI » se sont donc dotés d’un outi l  commun, réputé être ouvert aux entreprises, aux chercheurs et à toute  personne morale intéressée par la démarche . Le « Partnership on AI  » a aussi  intégré dans son conseil d’administration six nouveaux membres provenant  d’ONG et d’universités . De cette manière, son conseil d’administration se   compose désormais de douze membres, six responsable s d’entreprises des  nouvelles technologies (GAFAMI) et de six autres ap partenant aux ONG.  Ces six représentants d’ONG et d’universités sont :  Dario Amodei d’OpenAI,  une organisation fondée par Elon Musk, Deirdre Mull igan de l’Université de  Californie Berkeley, Jason Furman du Peterson Institute of International  Economics , un prestigieux think tank de Washington, Subbarao   Kambhampati de l’ Association for the Advancement of Artificial Intel ligence ,  Carol Rose de l’Union Américaine pour les Libertés Civiles (ACLU) et Eric  Sears de la fondation MacArthur. Le communiqué de p resse de « Partnership  on AI » affirme : « C’est un moment important pour Partnership on AI, a lors que  nous établissons un conseil d’administration divers ifié et équilibré qui étendra et  élargira notre leadership . L’inclusion de perspectives différentes et d’une réflexion  critique constante a été une mission centrale depui s le début, et nous continuerons à  ajouter de nouvelles voix à mesure que nous avançon s ». D’après le collectif, le  conseil d’administration contrôlera les activités g énérales de l’organisation  avec un directeur exécutif (encore inconnu), avec u n Comité exécutif de  direction (inconnu lui aussi) qui jugera et dévelop pera des initiatives selon  les objectifs de l’organisation. Ces initiatives co ncerneront notamment la  résolution « des problématiques importantes, […] sur l’éthique, la sécurité, la  transparence, la vie privée, l’influence, et l’équi té » engendrées par les  intelligences artificielles du futur. La première r éunion du conseil a eu lieu le  vendredi 3 février à San Francisco. L’organisation promet de révéler plus de  détails sur son programme de recherche et d’activit és.  Le rapport « L’Intelligence artificielle et la vie en 2030 »  (Artificial  Intelligence and Life in 2030 1 en anglais) publié en septembre 2016 par  l’Université Stanford, visitée par vos rapporteurs,  dévoile les résultats de  l’étude « One Hundred Year Study of Artificial Intelligence » , un projet  universitaire débuté en 2014 et initié par Eric Hor vitz, chercheur au  laboratoire Microsoft Research. Le rapport a été ré alisé par les membres du  Comité permanent de l’étude, présidé par Barbara J.  Grosz et composé de six  autres membres, dont Eric Horvitz et Russ Altman, e t par un groupe d’étude  rassemblant dix-sept chercheurs spécialisés dans le  sujet de l’intelligence  artificielle.                                                     1 L’intégralité du rapport publié par l’Université S tanford est disponible ici :  https://ai100.stanford.edu/sites/default/files/ai_1 00_report_0831fnl.pdf   
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 177  -       L’étude et les résultats présentés au sein de ce ra pport portent sur  l’analyse, à long terme, des avancées techniques de  l’intelligence  artificielle et de ses implications sur la société  au cours des cent dernières  années. Ce projet reprend les travaux d’une autre é tude menée entre 2008 et  2009, informellement connue sous le titre de « Étude d’Asilomar de  l’Association pour les progrès de l’intelligence ar tificielle »  (AAAI Asilomar  Study , en anglais). Au cours de cette étude, un groupe d ’experts de  l’intelligence artificielle appartenant à des établ issements, institutions et  champs disciplinaires différents ainsi que des spéc ialistes des sciences  cognitives, des juristes et des philosophes, avaien t été mobilisés par Éric  Horvitz, qui était à cette époque le président de l ’AAAI.  Selon les auteurs de ce rapport , les technologies issues de  l’intelligence artificielle , à l’instar de la reconnaissance vocale ou de  l’utilisation de systèmes de recommandations automa tiques, ont déjà et  continueront de bousculer des pans entiers de l’éco nomie mondiale et des  sociétés . L’intelligence artificielle représente en cela un  enjeu considérable,  tant du point de vue économique que politique et so ciétal, et un facteur de  création de valeur pour nos sociétés. Il est , de fait, essentiel que les  pouvoirs publics et les citoyens en saisissent les enjeux , dont la complexité  interdit tout angélisme ou catastrophisme a priori . Les gouvernants sont ainsi  encouragés à produire une législation encourageant l’innovation, la  production et le transfert d’expertise , et promouvant les responsabilités que  doivent endosser le monde de l’entreprise et la soc iété civile afin d’affronter  les défis apportés par l’utilisation de ces technol ogies, notamment sur la  question de la répartition des fruits de la croissa nce numérique.   Les auteurs de ce rapport soumettent de nombreuses  recommandations à l’attention des décideurs, couvra nt un large spectre de  domaines. Des propositions de politiques publiques sont ainsi proposées en  matière de protection de la vie privée, d’innovatio n, de responsabilité civile  et pénale, ou encore de fiscalité. Trois recommanda tions majeures peuvent  être retenues. Tout d’abord, les auteurs recommande nt d’accroître le niveau  d’expertise des gouvernants  en matière d’intelligence artificielle, afin qu’il s  puissent mieux apprécier les impacts de ces technol ogies. Ensuite, ils incitent  à l’élimination des obstacles et des freins à la tran sparence et aux  recherches sur la sécurité, la protection de la vie privée et les répercussions  sociales entraînées par l’utilisation de technologi es douées d’intelligence  artificielle, afin de prévenir les usages abusifs. Enfin, les auteurs de ce  rapport appellent au financement d’études d’impact pluridisciplinaires .  À la suite de ce rapport de septembre 2016  et puisqu’il n’existait  aucun guide commun encadrant le domaine de l’intell igence artificielle ,  édictant notamment de bonnes pratiques en la matièr e, plusieurs spécialistes  de l’intelligence artificielle et de la robotique se s ont réunis lors de la  conférence dénommée « Beneficial AI 2017 » organisé e par le Future of Life  Institute  (le FLI, dont il a été question plus haut). La con férence s’est tenue à 
- 178  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Asilomar, en Californie du 5 au 8 janvier 2017 1, avec le soutien de sponsors  tels que Alexander Tamas, Elon Musk, Jaan Tallinn e t deux associations « The  Center for Brains, Minds, and Machines  » et « The Open Philanthropy Project  ».   Aux termes de la rencontre, les spécialistes ont pr océdé à l’adoption  de vingt-trois principes baptisés « Les 23 principes d’Asilomar » et dont  l’objectif est d’encadrer le développement de l’int elligence artificielle.  D’après les informations recueillies, les principes  ont été signés par 846  chercheurs spécialisés dans l’intelligence artifici elle et la robotique et par  1 270 autres spécialistes dans divers domaines. Ces  « 23 principes d’Asilomar »   constituent un guide de référence d’encadrement éth ique du développement  de l’intelligence artificielle, qui explique que « l’intelligence artificielle a déjà  fourni de nombreux outils utiles qui sont utilisés au quotidien à travers le monde.  Son développement continu, guidé par les principes suivants, offrira des  opportunités extraordinaires pour aider, responsabi liser et rendre plus performants  les humains pour les décennies et les siècles à ven ir  ». Les « 23 principes  d’Asilomar »2 se présentent comme suit :  1) Objectif des recherches : Le développement de l’intelligence  artificielle ne doit pas servir à créer une intelli gence sans contrôle mais une  intelligence bénéfique.  2) Investissements : Les investissements dans l’intelligence  artificielle doivent être orientés vers le financem ent de recherches visant à  s’assurer de son usage bénéfique, qui prend en comp te des questions  épineuses en matière d’informatique, d’économie, de  loi, d’éthique et de  sciences sociales. Parmi ces questions :   - « Comment rendre les futures intelligences artifici elles suffisamment  solides pour qu’elles fassent ce qu’on leur demande  sans  dysfonctionnement ou risque d’être piratées ? »  - « Comment améliorer notre prospérité grâce à cette automatisation tout  en maintenant les effectifs humains ? »  - « Comment adapter le cadre juridique afin d’être pl us juste et efficace,  de suivre le rythme de l’intelligence artificielle et de gérer les risques  qui y sont associés ?  - « Quel ensemble de valeurs l’intelligence artificie lle devra respecter, et  quel statut éthique devrait-elle revêtir ?  3) Relations entre les scientifiques et les législateu rs : Un échange  constructif et sain entre les développeurs d’intell igence artificielle et les  législateurs est souhaitable.  4) Esprit de la recherche : Un esprit de coopération, de confiance et  de transparence devrait être entretenu entre les ch ercheurs et les  scientifiques en charge de l’intelligence artificie lle.                                                    1 Son programme figure ici : https://futureoflife.org/bai-2017/    2 https://futureoflife.org/ai-principles/   
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 179  -       5) Éviter une course : Les équipes qui travaillent sur les intelligences   artificielles sont encouragées à coopérer pour évit er des raccourcis en  matière de standards de sécurité.  6) Sécurité : Les intelligences artificielles devraient être sé curisées  tout au long de leur existence, une caractéristique  vérifiable et applicable.  7) Transparence en cas de problème : Dans le cas d’une blessure  provoquée par une intelligence artificielle, il est  nécessaire d’en trouver la  cause.  8) Transparence judiciaire : Toute implication d’un système  autonome dans une décision judiciaire devrait être accompagnée d’une  explication satisfaisante contrôlable par un humain .  9) Responsabilité : Les concepteurs et les constructeurs  d’intelligence artificielle avancée sont les premie rs concernés par les  conséquences morales de son utilisation et de ses d étournements. Il leur  incombe donc d’assumer la charge de les anticiper.  10) Concordance de valeurs : Les intelligences artificielles  autonomes devraient être conçues de façon à ce que leurs objectifs, leur  comportement et leurs actions s’avèrent conformes a ux valeurs humaines.  11) Valeurs humaines : Les intelligences artificielles doivent être  conçues et fonctionner en accord avec les idéaux de  la dignité, des droits et  des libertés de l’homme, ainsi que de la diversité culturelle.  12) Données personnelles : Chacun devrait avoir le droit d’accéder  et de gérer les données le concernant au vu de la c apacité des intelligences  artificielles à analyser et utiliser ces données.  13) Liberté et vie privée  : L’utilisation d’intelligence artificielle en  matière de données personnelles ne doit pas rogner sur les libertés réelles ou  perçue des citoyens.  14) Bénéfice collectif  : Les intelligences artificielles devraient  bénéficier au plus grand nombre, les valoriser et l es rendre plus performants.  15) Prospérité partagée : La prospérité économique découlant de  l’utilisation de systèmes d’intelligence artificiel le devrait être partagée avec  le plus grand nombre, pour le bien de l’humanité.  16) Contrôle humain : Les humains devraient pouvoir choisir  comment et s’ils veulent déléguer des décisions de leur choix aux  intelligences artificielles.  17) Anti-renversement : Le pouvoir obtenu en contrôlant des  intelligences artificielles très avancées devrait ê tre soumis au respect et à  l’amélioration des processus civiques dont dépend l e bien-être de la société  plutôt qu’à leur détournement à d’autres fins.  18) Course aux IA d’armement : Une course aux intelligences  artificielles d’armement mortelles est à éviter. 
- 180  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        19) Avertissement sur les capacités : En l’absence de consensus sur  le sujet, il est recommandé d’éviter les hypothèses  au sujet des capacités  maximum des futures intelligences artificielles.  20) Importance : Les intelligences artificielles avancées pourraie nt  entraîner un changement drastique dans l’histoire d e la vie sur Terre, et  devront donc être gérées avec un soin et des moyens  considérables.  21) Risques  : Les risques causés par les IA, particulièrement les  risques catastrophiques ou existentiels, sont sujet s à des efforts de  préparation et d’atténuation adaptés à leur impact supposé.  22) Auto-développement infini : Les IA conçues pour  s’auto-développer à l’infini ou s’auto-reproduire, au risque de devenir très  nombreuses ou très avancées rapidement, doivent fai re l’objet d’un contrôle  de sécurité rigoureux.  23) Bien commun : Les intelligences surdéveloppées devraient  seulement être développées pour contribuer à des id éaux éthiques partagés  par le plus grand nombre et pour le bien de l’human ité plutôt que pour un  État ou une entreprise.  Il convient, en outre, d’observer que Microsoft  a lancé en 2017 un  fonds d’investissement en capital-risque consacré à  l’intelligence  artificielle avec un objectif de ciblage sur les in vestissements à impact  positif pour la société . D’après le vice-président de Microsoft Ventures,  Nagraj Kashyap, « l’intelligence artificielle doit être conçue pour a ssister  l’humanité, être transparente, maximiser l’efficaci té sans détruire la dignité  humaine, protéger intelligemment la vie privée et a ssurer la responsabilité de  l’imprévu, et se garder des préjugés. Ce sont ces p rincipes qui guideront l’évolution  de ce fonds  ». Le premier investissement de Microsoft est dest iné à la  plateforme « Element AI » basée à Montréal, cofondée avec Yoshua Bengio,  professeur à l’Université de Montréal. Cet investis sement confirme à vos  rapporteurs le fait que la capitale du Québec se pl ace parmi les principaux  pôles mondiaux de l’intelligence artificielle, alor s que Google y avait  également basé une de ses divisions de recherche en  intelligence artificielle.  De même que Microsoft, avec Pierre Omidyar et Reid Hoffman, les  fondateurs d’eBay et de LinkedIn, ont lancé en 2017 , avec le fondateur de  Raptor Group James Pallotta et les fondations Knigh t et William et Flora  Hewlett, un fonds d’investissement de 27 millions d e dollars, qui porte le  nom de  Ethics and Governance of Artificial Intelligence Fu nd , qui  accompagnera les projets R&D axés sur les problémat iques d’éthique dans le  domaine de l’intelligence artificielle. Le fonds es t piloté par le Media Lab du  MIT et le Berkham Klein Center for Internet and Soc iety de Harvard. Cette  enveloppe sera exploitée pour soutenir les initiati ves repérées dans le monde  académique et orientées vers le développement d’une  intelligence artificielle  éthique, capable de ne pas « reproduire et amplifier les biais humains  ». Dans  cette optique, il s’agira d’impliquer, au-delà des ingénieurs, des sociologues,  des philosophes, des juristes, des économistes… et les régulateurs, au 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 181  -       croisement des sciences informatiques, humaines et sociales. L’Ethics and  Governance of Artificial Intelligence Fund se donne  aussi pour mission de  vulgariser l’intelligence artificielle auprès du gr and public.  Vos rapporteurs s’interrogent sur les objectifs pré cis des GAFAMI et  d’Elon Musk à travers ces nombreuses initiatives. L a volonté de ces  nouveaux géants pourrait-elle être celle de se dédouaner ou de créer un  nuage de fumée pour ne pas parler des vrais problèmes éthiques posés à  court terme par les technologies d’intelligence art ificielle, telles que l’usage  des données ou le respect de la vie privée  ? Vos rapporteurs n’ont pas  tranché et laissent aux auteurs de ces initiatives le bénéfice du doute. Chris  Olah, l’un des auteurs de « Concrete Problems in AI Safety  », travail de  recherche publié par Google  fait valoir qu’« alors que les risques potentiels de  l’IA ont reçu une large attention de la part du pub lic, les discussions autour de ce  sujet sont restées très théoriques et basées sur de s spéculations  » et qu’il faut  développer « des approches pratiques d’ingénierie de systèmes d’intelligence  artificielle opérant de façon sûre et fiable » . Dépassant les débats théoriques  entre pro et anti-IA, ces initiatives permettent d’ aborder avec des experts la  réalité concrète de l’intelligence artificielle, mê me si elles donnent, selon vos  rapporteurs, une place trop grande au risque de l’émergence d’une IA  forte  qui dominerait et pourrait faire s’éteindre l’espèc e humaine .  En mars 2017, la fondation  Future Society  de la  Harvard Kennedy  School a rendu un rapport  « La Révolution de l’intelligence artificielle au  service de tous »  dans le cadre de son initiative pour l’intelligenc e  artificielle 1. Coordonné par Cyrus Hodes et Nicolas Miailhe, il décrit  l’émergence de ces technologies, en souligne les op portunités et les défis en  matière de politiques publiques puis formule quelqu es recommandations.  Vos rapporteurs résument ci-après le contenu des tr ois dernières  parties de ce rapport.  1- Pour ce qui concerne tout d’abord les  opportunités économiques  et sociales offertes par l’intelligence artificiell e , il faut observer que le   développement de l’IA pourrait se traduire par une révolution de la  gouvernance,  à travers  l’efficacité des processus décisionnels  pour les  acteurs publics et privés. La capacité des algorith mes d’apprentissage  machine à exploiter les stocks et les flux croissan ts de données est  susceptible de déclencher une vague d’optimisation  dans de nombreux  domaines, à l’instar de l’énergie et des transports . L’intelligence artificielle  peut être essentiellement utilisée comme une « technologie de prédiction  »,  dont la diffusion pourrait réduire considérablement  le coût du traitement des  données historiques et donc faire des prédictions p our un large éventail de  tâches telles que le profil des risques, la gestion  des stocks ou la prévision de  la demande. Le développement de l’intelligence arti ficielle annonce des  formes de collaboration et de complémentarité  nouvelles et  économiquement plus efficaces entre les humains et les machines .                                                    1 Cf. le site :  http://ai-initiative.org/   
- 182  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        L’intelligence artificielle peut potentiellement êt re considérée comme un  nouveau facteur de production , en améliorant l’efficacité des facteurs  traditionnels du travail et du capital et en créant  un hybride capable de créer  des effectifs entièrement nouveaux. Dans de nombreu x cas, l’intelligence  artificielle sera capable de s’auto-améliorer, et d e surpasser les humains en  termes d’échelle et de vitesse.  Dans le domaine de la santé, les progrès réalisés d ans l’intelligence  artificielle créent ce que beaucoup considèrent com me des technologies  véritablement transformatrices et évolutives  pour aborder et traiter les  maladies et les médicaments. Tous les principaux ac teurs de l’intelligence  artificielle entrent sur le marché de la santé, et l’intelligence artificielle est  perçue par les praticiens comme un facilitateur de la révolution médicale de  précision et de prévention , ainsi que dans le séquençage génomique.  Le  recours à des technologies d’intelligence artificie lle dans le domaine de la  santé peut également inclure la découverte et la cr éation de molécules et de  médicaments, la personnalisation des soins, l’utili sation de « bots »  médicaux, ou encore les soins apportés aux personne s âgées.   L’intelligence artificielle a déjà un impact conséq uent sur le  transport avec l’introduction de capacités de condu ite autonome. Le  développement de réseaux neuronaux profonds est l’u n des principaux  moteurs des progrès impressionnants réalisés dans l es véhicules autonomes  au cours de la dernière décennie. La révolution des formes de mobilité  transformera en profondeur l’industrie automobile , qui pourra muter en  industrie de services, et avoir un impact sur les p aysages urbains et  suburbains, avec la possibilité que cela puisse tra iter la ségrégation spatiale  qui a souvent été accompagnée de la marginalisation  sociale.  Bien que l’éducation soit, à court terme, un secteu r moins impacté  par la substitution de l’emploi à l’intelligence ar tificielle, avec un potentiel  d’automatisation estimé à 27%, les outils que l’int elligence artificielle  apporte aux éducateurs et aux étudiants se révélero nt très précieux en  termes d’efficacité. À mesure que les MOOC ( Massive Open Online Courses ) et  les SPOC ( Small Private Online Courses ) gagnent en popularité en donnant  accès au meilleur contenu de cours pour tous , alors que le crowdsourcing  et  l’apprentissage machine sont développés pour assure r notamment les tâches  d’enseignement et d’évaluation.  En analysant et comprenant les normes et les variat ions des  comportements des utilisateurs, l’intelligence arti ficielle s’est avérée être un  outil efficace adoptant des mesures proactives  (contrer les cyberattaques, le  vol d’identité, la lutte contre le terrorisme…).  A u-delà de la cybersécurité,  l’intelligence artificielle prend de plus en plus d e poids dans la défense et la  sécurité. Elle permet au personnel de sécurité nati onale d’être mieux  informé  grâce à des systèmes de gestion et des outils de s imulation plus  intelligents.  
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 183  -       Dans le domaine de la robotique, les progrès de l’i ntelligence  artificielle influent radicalement sur les tactiques et les capacités de mission  des plates-formes autonomes  qui sont en mesure de façonner et d’influencer  la manière dont les conflits et les opérations de s écurité se déroulent à  l’avenir.  Dans la police, l’intelligence artificielle est uti lisée comme un outil  d’identification puissante , et de plus en plus comme un instrument prédictif  indiquant où et quand les crimes peuvent se produir e. Comme dans la  défense, ces applications devront être très sérieus ement régies pour éviter les  abus, ce qui pourrait avoir des effets dévastateurs .  2- Les défis pour les politiques publiques sont gra nds . En raison de  sa dynamique d’entreprise, la montée en puissance d e l’intelligence  artificielle a été caractérisée par la formation de  ce que l’on pourrait appeler  un « oligopole global dissymétrique » qui soulève des problèmes importants  en termes de répartition de la richesse et de la pu issance, mais pourrait  également étouffer l’innovation en empêchant l’appa rition de nouveaux  acteurs. Le marché de l’intelligence artificielle e st dominé par quelques  multinationales américaines (GAFAMITIS) et chinoise s (BATX), dont la  capitalisation boursière représente aujourd’hui plu s de 3,3 mille milliards de  dollars. Le marché de l’intelligence artificielle p résente de fortes  caractéristiques « the  winner takes most » en raison de la prévalence  particulière d’effets de réseau et d’effets d’échel le. Cet oligopole est  dissymétrique en cela qu’il présente de sérieux déséquilibres entre, d’une  part, les multinationales numériques hautement inno vantes dont les modèles  économiques perturbateurs se déroulent à l’échelle transnationale et, d’autre  part, les États-nations. Cette dissymétrie qui conc erne la révolution  numérique en général est encore aggravée par le dév eloppement de  l’intelligence artificielle puisque les multination ales sont maintenant en  mesure de capturer et de fournir des fonctions clés  de gouvernance.  L’« oligopole global dissymétrique » de l’intelligence artificielle pourrait être  une source de tensions sévères au cours des prochai nes décennies dans les  pays et entre eux. Sans régulation et redistributio n, l’accumulation  déséquilibrée de richesse et de pouvoir  entre les mains de quelques acteurs  privés pourrait favoriser la montée en puissance des populismes  et des  extrémismes à l’échelle mondiale.  Un autre élément crucial des défis politiques assoc iés au  développement de l’intelligence artificielle se rap porte à la délégation  croissante de compétences aux agents autonomes. Le potentiel de  l’intelligence artificielle pour la croissance, le développement et le bien  public exigera l’adoption de normes techniques et d e mécanismes de  gouvernance qui maximisent la libre circulation des  données et des  investissements dans des services à forte intensité  de données.  En outre, il pourrait y avoir des tensions entre la  nécessité d’une  réglementation rigoureuse des données  afin de garantir la protection de la  vie privée, le consentement éclairé et la lutte con tre la discrimination, d’une 
- 184  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        part, et les conditions de marché nécessaires  pour favoriser l’innovation et  développer des bases technoindustrielles  puissantes d’autre part.   Certains chercheurs ont exprimé de graves inquiétud es quant au  risque d’amplification des biais sociaux présenté p ar l’apprentissage  machine, les algorithmes pouvant devenir ainsi sour ce de discrimination,  comme l’a montré l’expérience du bot conversationne l « Tay » développé par  Microsoft.   L’ensemble de défis politiques majeurs associés au développement  de l’intelligence artificielle se réfère à l’impact  de l’automatisation sur les  emplois et les inégalités, certains chercheurs crai gnant un potentiel  «décrochage» des classes moyennes . De nombreux experts estiment que la  vague d’automatisation alimentée par l’intelligence artificielle influencera  profondément les profils d’emplois . Les résultats des études sur l’impact de  l’automatisation du travail menées au cours des cin q dernières années  diffèrent cependant radicalement dans leur évaluati on et leurs projections  (comme il a été vu le rapport de l’OCDE publié en j uin 2016 a conclu qu’une  moyenne modeste de 9 % des tâches est automatisable , alors qu’une étude de  2013 de Frey et Osborne se voulait plus alarmiste a vec sa conclusion  qu’environ 47 % des emplois américains seraient sen sibles à l’automatisation  au cours des deux prochaines décennies).   La capacité des sociétés à façonner la révolution d e l’intelligence  artificielle dans une destruction créatrice  et à diffuser son bénéfice à tous   dépend principalement de la façon dont elle réagit collectivement. Des  réponses politiques systémiques seront nécessaires,  y compris la réforme et  la réinvention éventuelle de la sécurité sociale et  de la taxe de redistribution.  Les systèmes d’éducation et de développement des co mpétences devront  également être réformés pour permettre des transitions professionnelles  viables . Compte tenu de la difficulté à prédire les zones les plus impactées et  de désagréger l’automatisation axée sur l’intellige nce artificielle d’autres  facteurs, les réponses politiques devront d’abord v iser l’ensemble de  l’économie, jusqu’à ce que les stratégies ciblées d eviennent plus efficaces et  que les pratiques de suivi et d’évaluation aient ét é conçues.  3. En matière de  recommandations, le rapport « La Révolution de  l’intelligence artificielle au service de tous » fo rmule huit propositions :  1 : Les institutions privées et publiques devraient ê tre encouragées à  examiner si et comment elles peuvent influencer de manière responsable  l’intelligence artificielle dans un sens bénéfique pour la société .  2 : Les États et les organisations internationales de vraient travailler sur le  développement de mécanismes de coordination mondiale pour surveiller  collectivement l’état de l’intelligence artificiell e.  3 : Les États et les organisations internationales de vraient soutenir  davantage la recherche et la prévoyance sur la dynamique (vitesse et  magnitude) du développement de l’intelligence artif icielle. 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 185  -       4 : Les États et les organisations internationales de vraient soutenir le  développement de modèles prédictifs analysant l’impact des machines  autonomes sur les marchés du travail , les emplois ou tâches futurs, les  mécanismes économiques, le bien-être collectif et l es structures de risque et  les compétences associées.  5 : Les États et les organisations internationales de vraient soutenir  davantage de recherche en sciences sociales sur l’interaction entre la  science, la technologie et la société à l’époque de  l’intelligence artificielle.  6 : Les États et les organisations internationales de vraient soutenir  davantage de recherches sur le renforcement des protections juri diques  contre les biais algorithmiques .  7 : Les États et les organisations internationales de vraient s’efforcer de créer  un cadre politique mondial et des normes harmonisées régissant les flux et  les stocks de données , en particulier les données personnelles, ainsi qu e  l’utilisation d’algorithmes .  8 : Les institutions privées et publiques ainsi que l es organisations  professionnelles devraient être encouragées à diriger de manière proactive  les débats publics  en engageant les experts de l’IA, les praticiens, les parties  prenantes et la société en général sur le thème de la gouvernance de  l’intelligence artificielle.  3.  Le travail en cours sur les enjeux éthiques au sein  de  l’association mondiale des ingénieurs électriciens et  électroniciens (Institute of Electrical and Electro nics Engineers  ou IEEE)   Vos rapporteurs soulignent l’important travail en c ours sur les  enjeux éthiques actuellement au sein de l’associati on mondiale des  ingénieurs électriciens et électroniciens ( Institute of Electrical and Electronics  Engineers  ou IEEE), qui regroupe plus de 400 000 membres.  L’initiative mondiale de l’IEEE pour « les considér ations éthiques  dans l’Intelligence Artificielle et les Systèmes Au tonomes » a en effet pour  principal objectif de proposer un cadre éthique de référence pour le  développement des systèmes d’intelligence artificie lle et des systèmes  autonomes .   Souhaitant dépasser la recherche de la performance technologique  en soi, ou le succès commercial, l’IEEE vise à ce que ces systèmes se  comportent d’une manière bénéfique pour l’humanité  et que leur  développement contribue au bien-être  de celle-ci. L’approche est, d’une  part, de produire un document évolutif rédigé colle ctivement et, d’autre  part, de proposer des standards qui pourraient deve nir des standards  industriels. La première version du document  d’IEEE « Conception conforme à  l’éthique : une vision pour fixer comme priorité le  bien-être humain avec  l’intelligence artificielle et les systèmes autonom es » a été publiée le 
- 186  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        13 décembre 2016 , avec l’idée d’une discussion d’ici à l’été 2017 et la  diffusion d’une deuxième version consolidée prévue à l’automne 2017 .  Plusieurs événements, réunions et téléconférences s ont programmés  afin de discuter du texte, y compris en Europe, par  exemple à Bruxelles le  11 avril 2017, et surtout un événement marquant, qu i se tiendra sous la  forme d’une plénière les 5 et 6 juin à Austin (Texa s), à l’issue duquel sera  réalisée la deuxième version du texte. C’est la com munication de ce texte qui  est prévue à l’automne 2017. Enfin, une troisième p lénière aura lieu en Asie  en 2018 (Japon ou Chine).  Le document publié le 13 décembre 2016 aborde les différents  aspects de la création et du développement d’algori thmes et de  l’intelligence artificielle concernés par des quest ionnements éthiques et  propose des recommandations  pour chacun d’entre eux. Il en formule huit,  que vos rapporteurs récapitulent ci-dessous.  1.  Les  principes généraux de la recherche en intelligence artificielle   Le développement de l’intelligence artificielle doi t être encadré par  un respect des principes fondamentaux des droits hu mains, de  responsabilité, de transparence, d’éducation et de connaissance.   2.  Les  valeurs « programmées » dans les systèmes autonomes    Les valeurs morales à intégrer aux algorithmes des systèmes  autonomes ne peuvent être universelles, et, sans to mber dans le relativisme,  doivent davantage s’adapter aux communautés d’utili sateurs concernées et  aux tâches qui lui sont confiées. Il est important de veiller, dès la conception  des algorithmes, à ce que la multiplicité de valeur s ne les fasse pas entrer en  conflit les unes avec les autres et ne désavantage aucun groupe  d’utilisateurs. Cela implique donc qu’une architect ure de calcul exigeante  des valeurs et normes éthiques doit être respectée.    3.  La  méthodologie de recherche et de conception éthiques   Il est essentiel que la méthodologie de recherche e t de conception  d’algorithmes et de systèmes autonomes comble de no mbreux manques.  Au-delà de son enseignement actuellement absent des  programmes d’études  en ingénierie, l’éthique doit être intégrée dans de  nombreux domaines  d’activité. Les pratiques industrielles doivent êtr e davantage marquées par  une culture éthique et la communauté concernée doit  s’emparer des sujets  idoines et assumer sa responsabilité éthique. Du fa it du mode de  fonctionnement et de prise de décision des algorith mes, il est nécessaire  d’inclure des composants de type « boîtes noires » décryptables a posteriori   afin d’enregistrer les informations aidant à l’anal yse des processus de  décision et d’action des systèmes autonomes.  4.  La  sécurité   Les comportements imprévus ou involontaires de syst èmes  d’intelligence artificielle représentent potentiell ement un danger 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 187  -       grandissant. Il est de fait essentiel de renforcer la sécurité de l’utilisation de  systèmes d’intelligence qui, en devenant de plus en  plus capables, peuvent  devenir dangereux. Les chercheurs et concepteurs de  systèmes de plus en  plus autonomes devront se confronter à un ensemble complexe de défis de  sécurité sur le plan technologique ainsi que sur le  plan éthique.   5.  La protection des données à caractère personnel  L’un des principaux dilemmes éthiques relatif au dé veloppement de  l’intelligence artificielle concerne l’asymétrie de  données ( data asymmetry ),  entre ceux qui les produisent et ceux qui les agrèg ent, les traitent, les  manipulent et les vendent. La protection des donnée s à caractère personnel  doit être organisée en considération de différents facteurs : comment est  défini et est identifié le caractère « personnel » d’une donnée ; comment  définir le consentement d’accès à des données à car actère personnel ; les  conditions d’accès et de traitement de ces données ; etc.   6.  Les  considérations juridiques  L’utilisation de systèmes autonomes soulève de nomb reuses  questions d’un point de vue juridique. Des exigence s de responsabilisation,  de transparence et de vérifiabilité des actions des  robots sont essentielles et  les dispositifs existants doivent être améliorés. À  titre d’exemple, la  transparence des systèmes autonomes permet de garan tir qu’une intelligence  artificielle respecte les droits individuels et, ut ilisée par une administration,  qu’elle ne porte pas atteinte aux droits des citoye ns et peut recueillir leur  confiance. En outre, il est nécessaire d’adapter le  cadre juridique concernant  la responsabilité des préjudices et dommages causés  par un système  autonome, ainsi que concernant l’intégrité et la pr otection des données à  caractère personnel.    7.  La  défense  et les « robots tueurs »  L’utilisation d’armes létales autonomes, également appelées « robots  tueurs », revêt un caractère risqué, en cela que le urs actions pourraient être  altérées et devenir un danger non maîtrisable, en c ela que la surveillance  humaine en est exclue. Ces « robots tueurs », à l’i nstar des drones militaires,  sont critiqués, et la légitimation de leur développ ement pourrait  potentiellement créer des précédents, qui du point de vue géopolitique  pourraient être dangereux à moyen terme, notamment en termes de  prolifération de ces armes, d’abus d’utilisation et  d’escalade rapide des  conflits. En outre, l’absence de standards de conce ption ne permet pas  aujourd’hui d’adopter des règles éthiques clairemen t définies.   8.  Les  problèmes économiques et humanitaires   L’objectif de ce rapport, en matière économique et social, est  d’identifier les principaux moteurs de l’écosystème  mondial des technologies  dans ce domaine et de prendre en compte les ramific ations économiques et  humaines, voire humanitaires, afin de suggérer des opportunités clés de  solutions. Ces dernières pourraient être mises en œ uvre de manière à 
- 188  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        débloquer les points critiques de tension. Les syst èmes autonomes et, plus  largement, l’intelligence artificielle, souffrent d ’une mauvaise image auprès  du grand public, du fait d’une interprétation erron ée par de nombreuses  œuvres de culture populaire alarmistes sur les capa cités d’un système  d’intelligence artificielle « forte », qui n’est pa s encore advenu et n’est pas  une réalité envisageable à court terme.   Le phénomène de robotisation et de développement de  l’intelligence  artificielle n’est généralement pas perçu uniquemen t dans un contexte de  marché. Si toute politique publique sur l’intellige nce artificielle peut  potentiellement ralentir l’innovation, de nombreuse s craintes émergent,  notamment concernant l’emploi, les changements tech nologiques évoluant  trop rapidement pour permettre aux méthodes de form ation de la maind’œuvre de s’adapter. Par ailleurs, l’accès aux tec hnologies d’intelligence  artificielle n’est pas équitablement réparti, entra înant un manque de  compréhension des informations par une partie de la  population ; en cela,  l’avènement de l’intelligence artificielle et des s ystèmes autonomes peut  exacerber les différences économiques et structurel les entre les pays  développés et les pays en développement.  En outre, l’IEEE élabore actuellement des standards , dans une  démarche parallèle à la discussion du document « Conception conforme à  l’éthique : une vision pour fixer comme priorité le  bien-être humain avec  l’intelligence artificielle et les systèmes autonom es ». Trois propositions de  standards industriels  ont ainsi été proposées et d’autres sont à venir. Ils sont  en cours de rédaction dans des groupes de travail o uverts, au sein, de la  IEEE Standard association :  - Standard pour un processus tenant compte des cons idérations  éthiques dans la conception des systèmes.  - Standard sur la prise en compte de la protection de la vie privée  dans les systèmes et logiciels utilisant des donnée s personnelles.  - Standard sur les niveaux de transparence mesurabl es pour le test  de systèmes et l’évaluation de leur niveau de confo rmité.  Une telle rédaction de standards prend du temps, au  moins un an, et  d’autres idées de standard pourraient être proposée s et soumises à la  discussion.  Selon l’animateur du comité d’IEEE ayant produit le  document  « Conception conforme à l’éthique : une vision pour  fixer comme priorité le bien-être  humain avec l’intelligence artificielle et les syst èmes autonomes »  et qui prépare le  second rapport, Raja Chatila, directeur de l’Instit ut des systèmes intelligents  et de robotique (ISIR),  auditionné à plusieurs reprises par vos rapporteurs ,  deux aspects concernant l’éthique devraient être pa rticulièrement abordés :  d’une part, les méthodologies de conception éthique de systèmes  autonomes , de manière à ce que ceux-ci tiennent compte des v aleurs  éthiques humaines (par exemple respect de la vie hu maine, des droits 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 189  -       humains) et de manière à ce que les algorithmes qui  les régissent soient  transparents, explicables, traçables, et, d’autre p art, l’éthique des machines,  c’est-à-dire comment les décisions prises par une m achine peuvent intégrer  un raisonnement éthique .   4.  Une sensibilisation insuffisante du grand public à ces questions  et un besoin de partage en temps réel de la culture  scientifique  et de ses enjeux éthiques  Vos rapporteurs constatent une sensibilisation insuffisante du  grand public aux questions posées par l’intelligenc e artificielle et les  systèmes autonomes . Les traitements médiatiques  de ces questions restent  le plus souvent sensationnalistes, voire alarmistes , alors qu’une information  objective serait souhaitable.  La vision déjà tronquée du grand public , sous l’effet des œuvres de  fiction, et en particulier du cinéma , n’est pas améliorée par la lecture de la  plupart des articles disponibles sur l’intelligence  artificielle dans nos  journaux et magazines.  Vos rapporteurs veulent affirmer avec force le besoin de partage en  temps réel de la culture scientifique et de ses enj eux éthiques .   Votre rapporteure, Dominique Gillot, présidente du Conseil  national de la culture scientifique, technique et i ndustrielle  (CNCSTI),  entend rappeler que ce Conseil, placé auprès du min istre chargé de la  Culture et du ministre chargé de la Recherche, « participe à l’élaboration d’une  politique nationale en matière de développement de la culture scientifique, technique  et industrielle, en cohérence avec les grandes orie ntations de la stratégie nationale de  recherche  ».  Réuni pour la première fois le 24 novembre 2015 1, ses membres,  réfléchissent aux actions à conduire  et sur l’articulation entre le niveau  national et le niveau régional. Parmi les thèmes pr ioritaires de réflexion et de  travail figurent l’utilisation des technologies et notamment du numé rique  dans la médiation scientifique , les entreprises et l’innovation, les filles et la   science, l’appui de la recherche aux décisions publ iques, l’après COP 21.  Votre rapporteure, Dominique Gillot, souligne l’importance de la visibilité  du débat public autour de ces questions .  L’Alliance sciences sociétés (ALLISS) se donne justement pour  première mission d’animer le débat public 2, mais aussi de renforcer les  capacités d’initiatives des acteurs de la société c ivile, de soutenir les  initiatives des institutions de l’enseignement supé rieur et de recherche, de                                                    1 Cette réunion a été suivie par la remise du prix «  Le goût des sciences », prix qui a pour objectif d e  valoriser le travail des chercheurs et des éditeurs , d’encourager les vocations scientifiques et  d’affirmer l’importance de la culture scientifique au sein de la culture générale contemporaine.  2 Cf. la charte de l’Allliance : https://uploads.strikinglycdn.com/files/5d463c19-d1 92-418c-99879d3a62b95a22/CHARTE_ALLISS.pdf   
- 190  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        favoriser le croisement des savoirs académiques, d’ action et d’expérience et,  enfin, d’accompagner les collectivités territoriale s et leurs politiques  publiques. En collaboration avec l’OPECST, l’IHEST et le ministère de  l’Enseignement supérieur et de la recherche, ALLISS  a organisé en novembre  2016 la session inaugurale de lancement de son livr e blanc « Prendre au  sérieux la société de la connaissance »1. Fruit de quatre années de travail,  riche de la participation de plus de 1 500 personne s et de 450 organisations et  de la contributions de plus de 150 organisations de  la société civile, ce livre  blanc a été rendu public en mars 2017 , avec l’idée de mettre en lumière des  expériences exemplaires, de contribuer à un diagnos tic partagé et d’effectuer  des recommandations pour les acteurs publics et les  acteurs impliqués dans  l’enseignement supérieur et la recherche : établiss ements d’enseignement  supérieur et de recherche mais aussi acteurs de la société civile, associations,  syndicats, entreprises… Les recommandations du docu ment portent sur les  interactions entre société civile, enseignement sup érieur et recherche, dans le  but d’aboutir entre autres à une meilleure intégrat ion de la société civile  dans les choix des politiques publiques d’innovatio n.  Les activités d’ éducation populaire ou les ateliers citoyens  sont  d’autres pistes pour sensibiliser le grand public a ux questions posées par  l’intelligence artificielle . Vos rapporteurs ne se satisfont pas des traitemen ts  sensationnalistes ou alarmistes de ces questions pa r les médias. Les  informations contenues dans le présent rapport devr aient être accessibles à  tous et transmises par le biais d’activités d’éduca tion populaire ou par des  ateliers citoyens.  Le rapport « Vers une société apprenante  »2 remis en mars 2017 par  François Taddéi, directeur du Centre de recherches interdisciplinaires (CRI),  à la ministre de l’Éducation nationale, de l’enseig nement supérieur et de la  recherche va dans ce sens et propose une approche s ystémique  interdisciplinaire marquée par « une culture de la confiance, de la liberté et du  mentorat bienveillant  », avec le numérique comme catalyseur des évolutio ns  afin de mobiliser les moyens matériels et humains p our répondre aux défis  éducatifs.  Vos rapporteurs observent, en outre, que non seulem ent le   numérique doit être transformé par l’éthique, mais que  le numérique est,  par lui-même, un facteur d’évolution des règles éth iques appliquées par  les chercheurs , surtout au cours des dernières années. Le contrôle par les  pairs se fait de manière plus décentralisée et collaborative.  L’exemple de pubpeer , site de discussion en ligne d’articles  scientifiques 3, peut être cité de manière significative. Les rése aux sociaux de  chercheurs 4 sont une autre illustration.                                                    1 Le livre blanc est téléchargeable sur le site d’AL LISS : http://www.alliss.org/    2 Cf. http://cache.media.education.gouv.fr/file/03_-_mars /19/0/2017_rapport_taddei_740190.pdf    3 Cf. https://pubpeer.com/    4 Cf. https://www.researchgate.net   
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 191  -         III.  LES QUESTIONS TECHNOLOGIQUES ET SCIENTIFIQUES QUI S E  POSENT EN MATIÈRE D’INTELLIGENCE ARTIFICIELLE  A.  LES SUJETS D’INTERROGATION LIÉS AUX ALGORITHMES UTI LISÉS  PAR LES TECHNOLOGIES D’INTELLIGENCE ARTIFICIELLE  1.  Les questions de sécurité et de robustesse  Concernant la sécurité au sens de la sécurité numérique , l’OPECST  a récemment rendu un rapport sur les risques et la sécurité numérique 1, ce  point fera donc l’objet de courts développements da ns le présent rapport.  Vos rapporteurs renvoient à ce rapport qui traite d ’un point de vue général  de la sécurité numérique.  Un exemple fameux de problématique de sécurité pour  les systèmes  d’intelligence artificielle est celui du risque de piratage d’un drone ou d’une  voiture autonome . Les cas existent et doivent donc être résolus. La sécurité  de ces systèmes emporte des conséquences en termes de vie humaine. Une  piste peut résider dans le fait de ne pas être perp étuellement connecté afin de  prévenir le risque de piratage. Selon John Krafcik,  le président de Waymo,  ex-Google Self-Driving Car Project  (branche d’Alphabet pour la conduite  autonome) une connexion Internet permanente embarqu ée n’est pas  nécessaire pour un véhicule sans chauffeur et, au c ontraire, un accès Internet  discontinu dans une voiture autonome serait un gage  de sécurité. Afin  d’assurer la sécurité des passagers d’une voiture a utonome face au risque de  piratage, il s’agit de ne pas dépendre de la connectivité embarquée , comme  l’accès à Internet. John Krafcik explique ainsi : «  la cybersécurité est  quelque  chose que nous prenons très sérieusement […] quand nous évoquons nos voitures  autonomes, ce n’est pas seulement pour dire qu’il n ’y a pas de conducteur humain,  mais aussi qu’il n’y a pas de connexion cloud en continu depuis le véhicule  ».  Les connexions au réseau seront donc gérées avec pa rcimonie,  lorsque la voiture en a besoin. Ce ne sera pas une connexion en continu,  susceptible d’être piratée pour s’introduire dans l e véhicule. Waymo met  ainsi en circulation des véhicules autonomes Chrysl er Pacifica à Mountain  View (Californie), où se trouve le siège de Google,  visité par vos rapporteurs,  et à Ph œnix (Arizona).  Au-delà du piratage, qui est intentionnel, se pose le problème de la  perte de contrôle des systèmes d’intelligence artif icielle . Des recherches  sont à conduire dans ce sens, pour relever le défi de sécurité et de robustesse  des technologies. Depuis 2016, Thierry Berthier, ch aire de cyberdéfense de  Saint-Cyr à l’Université de Limoges, Jean-Gabriel G anascia, UPMC–LIP6, et  Olivier Kempf, IRIS, conduisent une étude sur un sc énario concret de crise                                                    1 Rapport « Sécurité numérique et risques : enjeux e t chances pour les entreprises », n° 271  (2014-2015). 
- 192  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        militaire en raison d’une dérive de systèmes d’inte lligence artificielle ,  dans le cas d’une hypothèse « faible » de dérive ma lveillante dans le sens ou ̀  l’intelligence artificielle impliquée n’a pas de volonté de nuisance  ni de  « métacompréhension » de son environnement ou de sa  propre activité. Ils  ne font intervenir que des capacités et fonctionnal ités de l’intelligence  artificielle existantes ou en cours de développemen t, notamment dans les  récents programmes initiés par la DARPA, l’agence a méricaine pour les  projets de recherche avancée de défense, visitée pa r vos rapporteurs. La  complexité des systèmes et des processus d’apprenti ssage pourrait conduire  à des situations critiques. Le risque naîtrait ains i de l’association de choix  humains et de mécanismes numériques , une série d’éléments mis bout a ̀  bout pourraient en effet devenir potentiellement da ngereux sans que chacun  de ces mécanismes pris individuellement le soit. Un  article devrait paraître  en 2017 dans la revue de la Défense Nationale à la suite de cette étude.  En robotique il est nécessaire de toujours pouvoir arrêter un  système, la question peut se poser plus généralemen t pour une  intelligence artificielle , qu’il s’agisse d’un système informatique ou de so n  incarnation dans un robot. La réversibilité du fonc tionnement de  l’intelligence artificielle est essentielle, elle é voque le Golem de Prague qui se  tourne vers son maître, le prophète Jérémie, et lui  dit : « défais-moi !  ».  Vos rapporteurs rappellent qu’en 2016, Google a également posé la  question  du manque de contrôle potentiel d’agents apprenant s qui  pourraient apprendre à empêcher leur interruption d ans une tâche. C’est  dans ce sens que la firme développe l’idée d’un « bouton rouge »  permettant la désactivation des intelligences artif icielles 1.  Pour la CERNA, la question  du débrayage de certaines fonctions  autonomes , voire de la mise hors service  du robot par l’utilisateur, est  centrale . Elle se demande ainsi : « Quand et comment l’utilisateur peut-il  éteindre des fonctions du robot, voire le robot lui -même ? Le robot peut-il ou doit-il  empêcher ces extinctions, dans quelles circonstance s et sur quelles bases  objectives ?  »  Des recherches complémentaires sont nécessaires sur  ce sujet. Pour  paraphraser Raymond Aron 2, l’enjeu est donc, face à une paix improbable  avec les machines, de rendre la guerre impossible .  2.  Les biais et les problèmes posés par les données né cessaires aux  algorithmes d’apprentissage automatique   Les biais sont l’un des plus gros problèmes posés par les  algorithmes d’apprentissage automatique , ou pour être plus rigoureux,  posés par les données nécessaires aux algorithmes . La question concerne en                                                    1 Morgane Tual, « Pourquoi Google a conçu un bouton rouge pour désactiver des intelligences  artificielles », Le Monde,   7 juin 2016.  2 Il utilisait l’expression de « Paix impossible, guerre improbable  ». 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 193  -       effet plus les données que les algorithmes eux-même s. Les impacts se font  ressentir après le traitement, mais les biais sont introduits en amont dès le  stade des jeux de données .  En effet, les algorithmes d’apprentissage automatiq ue et en  particulier d’apprentissage profond vont reproduire les biais des données  qu’ils traitent , en particulier toutes les discriminations connues  dans nos  sociétés tant qu’elles ne sont pas corrigées. Les d onnées peuvent inclure  toute sorte de biais. Selon vos rapporteurs, cette difficulté ne doit jamais être  négligée.  Outre relever le défi de l’apprentissage non superv isé, il convient  donc d’ être vigilant sur ces biais,  qui de surcroît sont souvent invisibles   sauf si des efforts de recherche sont entrepris, ai nsi que l’ont expliqué  plusieurs spécialistes à vos rapporteurs. Les algor ithmes ne détectent pas les  biais, ils sont « bêtes », comme a pu le dire un ch ercheur.  Le second rapport de la CERNA, en cours de publicat ion, traite de ce  point.  Ces biais peuvent aussi être mis en relation avec l es problèmes de  loyauté des plateformes , ainsi que de l’utilisation des systèmes  d’intelligence artificielle à des fins non éthiques , partisanes et sans  diversification des choix , comme le précise votre rapporteure Dominique  Gillot.  Vos rapporteurs jugent que la gouvernance des algorithmes et des  prédictions qu’ils opèrent est nécessaire .  3.  Le phénomène de « boîtes noires » des algorithmes d e deep  learning  appelle un effort de recherche fondamentale vers l eur  transparence   Les connaissances existantes  sur les systèmes d’intelligence  artificielle  montrent que nous ne disposons d’ aucune explication théorique  satisfaisante des raisons pour lesquelles les algor ithmes de deep learning , à  travers des réseaux de neurones artificiels en couc hes multiples,  fonctionnent, ou, pour être plus précis, donnent, d ans un certain nombre de  domaines, d’excellents résultats et très rapidement .  Ce problème d’opacité reste entièrement à résoudre . On parle à ce  sujet de phénomènes de « boîtes noires », mais elle s n’ont rien à voir avec les  boîtes noires des avions, qui sont des enregistreur s numériques.  Le défi à relever est donc celui de l’objectif d’ explicabilité des  algorithmes de deep learning . Il s’agit là aussi d’une autre question qui peut  se rattacher à la question générale de la gouvernan ce des algorithmes.  Comme il a été vu, le Conseil général de l’économie  (CGE) a rendu le  15 décembre 2016 un rapport au ministre de l’économ ie et des finances  portant sur les « Modalités de régulation des algor ithmes de traitement des 
- 194  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        contenus »1. Les algorithmes de traitement des contenus sont i nséparables  des données qu’ils traitent et des plateformes qui les utilisent pour proposer  un service. Alors qu’il y a de nombreux travaux sur la protection des  données et sur la loyauté des plateformes, il en ex iste encore peu sur les  algorithmes eux-mêmes . Ce rapport souligne donc qu’il faut développer la  capacité à tester et contrôler les algorithmes 2.  Vos rapporteurs rappellent à nouveau ici qu’Inria a vec sa  plateforme scientifique collaborative « Transalgo » ,  lancée en 2017 et placée  sous la direction de Nozha Boujemaa, développe en 2 017 de manière utile  une plateforme scientifique d’évaluation de la responsa bilité et de la  transparence des algorithmes 3, afin de répondre aux préoccupations  exprimées de régulation  et d’ explicabilité des algorithmes  par l’élaboration  d’outils et de pratiques transparentes et responsab les dans le traitement  algorithmique des données. Une telle démarche, en l ien avec le Data  Transparency Lab  du MIT, Mozzilla et Telefonica, va dans le bon sen s mais  gagnerait à voir sa force de frappe démultipliée par une dynamique de   mobilisation de plusieurs équipes de recherche  autour de challenges  scientifiques nouveaux. Inria ne doit pas être la s eule structure en France à  porter des projets de ce type. Le CNNum, la CERNA e t la CNIL sont associés  à la plateforme « Transalgo » mais il s’agit plus d e partager des expériences  que de conduire des recherches transversales. Inria  explique ainsi : « Le  CNNum joindra ses forces avec celles d’Inria dans T ransAlgo dans le respect des  missions de chacun. Il prendra en charge le recense ment et l’objectivisation de la  situation actuelle de certaines pratiques des plate formes à travers un dispositif  contributif (citoyens et professionnels). Les donné es des différentes sources de  régulation européennes ou internationales viendront  enrichir également le centre de  ressources. Pour faire remonter des cas d’usages bi en réels, nous avons prévu de  collaborer avec des think tank comme la FING (Fonda tion internet nouvelle  génération), ou des associations de consommateurs c omme Que-Choisir, en plus de  la CERNA (Commission de réflexion sur l’éthique de la recherche en sciences et  technologies du numérique d’Allistene). Nous allons  travailler également à partir  des remontées d’expression de besoins qui viendront  du CNNum, de la Direction  Générale de la Concurrence, de la Consommation et d e la Répression des Fraudes  (DGCCRF), de l’Autorité française de contrôle en ma tière de protection des données  personnelles (CNIL), afin d’identifier les problème s les plus observés par le citoyen,  les industriels, les autorités de régulation ».                                                    1 http://www.economie.gouv.fr/cge/modalites-regulatio n-des-algorithmes-traitement-des-contenus    2 Ses auteurs proposent cinq pistes d’action qui ont  pour objet la montée en compétence et le  développement de l’expertise des pouvoirs publics , mais aussi d’appeler au développement de  bonnes pratiques  dans les différents secteurs économiques. Ils préc onisent la création d’une  plateforme collaborative scientifique , destinée à favoriser le développement d’outils lo giciels et  de méthodes de test d’algorithmes, ainsi que de pro mouvoir l’utilisation de ces outils et méthodes. Il s  soulignent aussi qu’il faut préserver une image positive des technologies  utilisées pour  concevoir ou opérer des algorithmes. C’est essentie l pour continuer à attirer les jeunes générations  de françaises et de français dans des filières de f ormation exigeantes (mathématiques, ingénieurs ou  data scientists) où la France est aujourd’hui bien placée.  3 Cf. http://www.economie.gouv.fr/files/files/PDF/Inria_P lateforme_TransAlgo2016-12vf.pdf   
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 195  -       Comme il a été mentionné précédemment, l’Institut C onvergence  i2-DRIVE ( Interdsciplinary Institute for Data Research : Intelligence, Value  and Ethics) s’est donné parmi ses objectifs de se consac rer aux défis  scientifiques des algorithmes d’apprentissage et de  traitement des données  mais aussi à leurs impacts socio-économiques.  4.  La question des bulles d’information dites « bulles  de filtres »  L’information ciblée  tout comme la publicité personnalisée  ou la  logique de construction des « fils d’actualité » de s réseaux sociaux , à  l’instar de celui de Facebook, sont autant d’exempl es de réalités déjà  manifestes  d’usage des systèmes d’intelligence artificielle, q ui sont de nature  à changer notre rapport au monde, aux autres et à l a connaissance en  orientant, voire en manipulant, notre perception de  la réalité .  La réflexion inquiète présentée dans le livre Filter bubbles  par Eli  Pariser, Président de MoveOn et cofondateur de Avaa z, illustre ce fait : les  algorithmes intelligents sélectionnent le contenu d ’informations et créent  par là des « bulles de filtres » qui se multiplient  et transforment le rapport  de l’individu au monde .  Ce sujet mérite une vigilance accrue des pouvoirs publics . Pour vos  rapporteurs, l’enfermement, qu’il soit politique, idéologique ou  cognitif,  doit être combattu .  La question va bien plus loin que les critiques for mulées à l’encontre  des fausses informations,  ou fake news,  amplifiées par les réseaux sociaux.  Sur ce dernier point, la recherche est assez bien a vancée et comme l’a  indiqué à plusieurs reprises Yann LeCun, directeur de la recherche en  intelligence artificielle de Facebook, l’intelligen ce artificielle peut aussi être  utilisée pour limiter les flux de fausses informati ons. Des outils de  vérification  (fact checking ) sont ainsi mis en place par plusieurs plateformes ,  à commencer par Facebook et Google.  B.  LES SUJETS D’INTERROGATION LIÉS À LA « SINGULARITÉ », À LA  « CONVERGENCE NBIC » ET AU « TRANSHUMANISME »   1.  La « singularité », point de passage de l’IA faible  à l’IA forte  peut, à long terme, constituer un risque   La rupture dite de la « singularité technologique »  appelée aussi  simplement singularité , est le nom que des écrivains et des chercheurs en   intelligence artificielle ont donné au passage de l’IA faible à l’IA forte 1. La                                                    1 Dès 1965, Irving John Good a décrit, en précurseur , la singularité, mais sans la nommer, et ce de la  manière suivante : « Mettons qu’une machine supra-intelligente soit une machine capable  dans tous les domaines d’activités intellectuelles de grandement surpasser un humain,  aussi brillant soit-il. Comme la conception de tell es machines est l’une de ces activités 
- 196  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        singularité représente un tournant hypothétique sup érieur dans  l’évolution technologique , dont l’intelligence artificielle serait le ressor t  principal. Vernor Vinge a rédigé un essai remarqué à ce sujet en 1993 1.  De nombreuses œuvres de science-fiction ont décrit ce tournant, qui a  été une source d’inspiration très riche pour le cin éma. Les films  « Terminator », « Matrix », « Transcendance »  sont des exemples de la  « singularité technologique », qui est donc bien pl us qu’une simple hostilité  de l’intelligence artificielle , également souvent au cœur de l’intrigue des  œuvres de science-fiction.  Les progrès en matière d’intelligence artificielle,  en particulier avec le  deep learning , sont parfois interprétés comme de « bons » augure s de la  « singularité » mais rien ne permet de garantir la capacité à créer au cours  des prochaines décennies une super-intelligence dép assant l’ensemble des  capacités humaines. Par exemple, en s’appuyant sur la loi de Moore, Ray  Kurzweil  prédit que les machines rivalisant avec l’intellig ence humaine  arriveront d’ici à 2020 et qu’elles le  dépasseront en 2045 2. D’après Raja  Chatila, directeur de recherche à l’Institut des sy stèmes intelligents et de  robotiques (Isir), nous en sommes, aujourd’hui, enc ore loin car  « pour être  intelligente comme un humain, une machine devra d’a bord avoir la perception  d’elle-même, ressentir son environnement, traiter d es informations à flux continu et  en tirer du sens pour ensuite agir (…) Ce n’est pas  la technique qui fait défaut à la  machine, mais le sens de ses actions, et l’intégrat ion de la notion de concept  ».  Les réflexions de Jean-Gabriel Ganascia et de Max D auchet devant  vos rapporteurs vont également dans ce sens. Cette super-intelligence peut  paraître fondée, mais, ainsi que le soulignent Hube rt et Stuart Dreyfus, « cela  fait un demi-siècle, depuis que les ordinateurs son t apparus au monde, que l’on  promet de bientôt les programmer pour les rendre in telligents et que l’on promet  aussi, ou plutôt que l’on a peur, qu’ils apprennent  bientôt à nous comprendre  nous-mêmes comme des ordinateurs. En 1947, Alan Tur ing prédisait qu’il existerait  un ordinateur intelligent d’ici à la fin du siècle.  Maintenant que le millénaire est  dépassé de trois ans, il est temps de faire une éva luation rétrospective des tentatives  faites pour programmer des ordinateurs intelligents  comme HAL dans le film 2001,                                                                                                                                                  intellectuelles, une machine supra-intelligente pou rrait concevoir des machines encore  meilleures ; il y aurait alors sans conteste une ex plosion d’intelligence, et l’intelligence  humaine serait très vite dépassée. Ainsi, l’inventi on de la première machine supraintelligente est la dernière invention que l’homme ait besoin de réaliser.  » Vernor Vinge a  commencé à parler de la singularité dans les années  1980 et a formulé ses idées dans un premier  article paru en 1993 intitulé « Technological Singularity  ». Il y posait l’hypothèse que dans un  délai de trente ans, l’humanité aurait les moyens d e créer une intelligence surhumaine mettant un  terme à l’ère humaine.  1 Cf. Vernor Vinge, The Coming Technological Singularity .  2 Les prédictions du futurologue peuvent être rappel ées. Les ordinateurs atteindront une capacité de  traitement comparable au cerveau humain en 2020. En  2022 les États-Unis et l’Europe adopteront  des lois réglementant les relations entre les humai ns et le robot, l’activité des robots, leurs droits ,  leurs devoirs et autres restrictions seront fixés. En 2031, l’impression des organes humains par des  imprimantes 3D sera possible. La circulation de véh icules autonomes sur les routes devient la norme  en 2033. Immortalité de l’homme en 2042 et, enfin, la singularité en 2045. 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 197  -       l’Odyssée de l’espace »1. Ce jugement sévère est tempéré par Jean-Gabriel  Ganascia selon lequel on attend toujours l’intelligence artificielle au  tournant parce qu’elle déçoit les espérances qu’ell es suscitent  : « HAL,  l’ordinateur intelligent du film de Stanley Kubrick  2001, l’Odyssée de l’espace , ne  voit pas encore le jour, même si le millénaire est déjà passé. Traduction automatique,  compréhension du langage naturelle, vision, démonst ration de théorème, résolution  de problèmes, robotique… l’histoire récente accumul e les échecs. Rien de vraiment  tangible n’advient dans ce secteur de la technologi e… Autant de lieux communs  bien répandus, que l’on retrouve depuis longtemps  ». L’IA forte est une notion  implicite dès la fondation de l’intelligence artifi cielle, mais elle correspond  surtout à une invention conceptuelle des années 198 0. L’explication donnée  par Marvin Minsky, l’un des pères de l’intelligence  artificielle, est  intéressante et pose la question de la place de la recherche publique :  « pourquoi n’avons-nous pas eu HAL en 2001 ? Parce qu e des problèmes centraux,  comme le raisonnement de culture générale, sont nég ligés, la plupart des chercheurs  se concentrent sur des aspects tels que des applica tions commerciales des réseaux  neuronaux ou des algorithmes génétiques.  »2   Le principal propagateur de ce risque existentiel e st Raymond  Kurzweil, sa fonction de directeur de la recherche de Google laissant  perplexe. L’IA forte n’est a priori  pas pour tout de suite mais d’après Stuart  Armstrong, chercheur au Futur of Humanity Institute , Oxford, dirigé par  Nick Bostrom 3 « il y a des risques pour que cela arrive plus tôt qu e prévu  ».  Il convient de noter qu’une étude publiée en octobr e 2016 par  Google, montre que, programmées pour protéger la co nfidentialité de  communications, deux IA peuvent « découvrir des formes de chiffrement et  déchiffrement, sans qu’on leur ait enseigné des alg orithmes spécifiques pour ce  faire », selon les termes des chercheurs : autrement dit,  des formes de  communication ignorées des concepteurs des algorith mes. Le constat est  d’ailleurs identique avec le système de traduction automatique du même  Google, qui intègre désormais des algorithmes de deep learning . Une autre  étude montre que ce système est capable d’établir d es connexions entre des  concepts et des mots qui ne sont pas formellement l iés. Pour les chercheurs à  l’origine de l’étude, la conséquence de ce constat serait claire : le système a  développé son propre langage interne, une interlingua . Ils précisent toutefois  que « les réseaux neuronaux sont complexes et les interac tions difficiles à décrire  ».  2.  Un prophétisme dystopique indémontrable scientifiqu ement   Nier la possibilité d’une IA forte n’a pas de sens,  toutefois se  prononcer sur son imminence ou sur le calendrier pr écis de son avènement                                                    1 « From Socrates to Expert Systems  : The Limits and Dangers of Calculative Rationality  »,  2004.  2 Marvin Minsky, « It’s 2001. Where Is HAL?  », Dr. Dobb’s Technetcast, 2001.  3 Vos rapporteurs les ont rencontrés tous les deux, le second est auteur de « Superintelligence :  Paths, Dangers, Strategy  », 2014. 
- 198  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        semble tout aussi peu raisonnable, car c’est indémontrable  scientifiquement . Outre le calendrier incertain de la singularité c omme en  témoignent les limites de la loi de Moore, il convi ent d’observer que les  théories de la singularité s’apparentent à un proph étisme dystopique. Pour  le sociologue Dominique Cardon, la tentation de l’I A forte est  anthropomorphiste. Certains sont en effet tentés de  plaquer sur les futures  intelligences artificielles des modes de raisonneme nt spécifiques à  l’intelligence humaine.  Ce catastrophisme oublie également le caractère irréductible de  l’intelligence humaine au calcul . Il évacue la place des émotions, de  l’intelligence corporelle. Non seulement l’avènemen t d’une super-  intelligence à long terme n’est pas certaine mais s a menace à court terme  relève du pur fantasme. Pour Mustafa Suleyman, cofo ndateur de Deep Mind,  qui est à l’origine d’AlphaGo, il est impossible de  prévoir la date d’arrivée de  l’IA forte.   Il s’agit donc de fantasmes, et notamment de fantasmes sur la  capacité des algorithmes à devenir conscients , à savoir dotés de capacités  réflexives leur permettant de se représenter à eux- mêmes. Selon Gérard  Sabah, « la bonne question à se poser ce n’est pas de savoir  si un système peut être  conscient, mais de savoir ce que l’homme attribue à  sa conscience » et pour David  Sadek, directeur de la recherche de l’Institut Mine s-Télécom, prudent, « on ne  sait pas plus se représenter mentalement le fonctio nnement d’une machine inconnue  que celui d’un autre être humain  ».  Au-delà des incertitudes sur la capacité d’une mach ine à avoir une  conscience, qui, selon certains philosophes, serait  une caractéristique  réservée aux êtres vivants, se pose la question d’i dentifier ce que peut faire  une technologie d’intelligence artificielle, à savo ir calculer. La calculabilité  renvoie à la thèse de Church  (du nom du mathématicien Alonzo Church),  qui concerne la définition de la notion de calculab ilité : dans une forme dite  « physique », elle affirme que la notion physique d e la calculabilité , définie  comme étant tout traitement systématique réalisable  par un processus  physique ou mécanique, peut être exprimée par un en semble de règles de  calcul. Cette thèse a exercé une influence puissant e en informatique, on peut  penser à l’article d’Alan Turing de 1936 et à son m odèle mécanique de  calculabilité. Dans le prolongement de cette thèse figure le  « computationnalisme  », qui est une théorie fonctionnaliste en philosop hie  de l’esprit qui, pour des raisons méthodologiques, conçoit l’esprit comme un  système de traitement de l’information et compare l a pensée à un calcul (ou  en anglais, computation ) et, plus précisément, à l’application d’un systèm e de  règles.  À la fin des années 1980, le computationnalisme a é té concurrencé  par un nouveau modèle cognitif, le connexionnisme, qui vise à montrer  qu’on peut expliquer le langage de la pensée sans f aire appel à un  raisonnement gouverné par un système de règles, com me le fait le  computationnalisme. 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 199  -       Le computationnalisme a été la cible de diverses critiques , en  particulier de John Searle, Hubert Dreyfus, ou Roge r Penrose, qui tournaient  toutes autour de la réduction de la pensée et/ou de  la compréhension à la  simple application d’un système de règles. Vos rapp orteurs sont sensibles à  ces critiques et en particulier à l’illusion de com préhension, telle qu’elle  ressort de l’expérience de la chambre chinoise  mise en évidence par John  Searle 1. Cette expérience vise à montrer qu’une intelligence artificielle ne  peut être qu’une intelligence artificielle faible e t ne peut que simuler une  conscience , plutôt que de posséder des authentiques états men taux de  conscience et d’intentionnalité. Elle vise à montre r également que le test de  Turing est insuffisant pour déterminer si une intel ligence artificielle possède  ou non une intelligence comparable à celle de l’hom me.  Vos rapporteurs s’interrogent plus largement sur l’ idée de machines  qui gagnent contre l’homme  : a-t-on raison de dire, que ce soit aux échecs,  au jeu de Go, ou en janvier 2017 au poker, que la m achine a battu l’homme et  qu’elle est plus forte que lui ?  Ils partagent l’opinion de Laurence Devillers, selo n laquelle cette  formulation est excessive et revient à essentialise r la machine . Cette  réification nous fait oublier que l’intelligence des algorithmes c’est aussi et  peut-être avant tout l’intelligence de leurs dévelo ppeurs . Elle affirme ainsi  que cette victoire au jeu de Go invoque « une comparaison nulle et non avenue :  on compare un humain avec une machine ; mais derriè re la machine se trouvent cent  ingénieurs au travail  ».  En effet, AlphaGo est peut-être le meilleur joueur de Go de tous les  temps , mais il n’est pas en mesure de parler  ou de distinguer un chat d’un  chien , ce dont serait, quant à lui, capable n’importe qu el joueur de Go  humain débutant.  L’écrivain futuriste et entrepreneur, Jerry Kaplan,  fait valoir que « le  terme même d’intelligence artificielle est trompeur . Le fait que l’on puisse  programmer une machine pour jouer aux échecs, au Go , à Jeopardy ou pour conduire  une voiture ne signifie pas pour autant qu’elle soi t intelligente ! Autrefois, les  calculs étaient effectués à la main, par des humain s très intelligents et portant une  grande attention au détail. Aujourd’hui, n’importe quelle calculette achetée en  supermarché peut faire bien mieux que ces brillants  cerveaux de jadis. Ces  calculatrices sont-elles pour autant intelligentes ? Je ne le crois pas. Au fil du temps,  nous découvrons de nouvelles techniques permettant de résoudre des problèmes bien  précis, à l’aide de l’automatisation. Cela ne signi fie pas pour autant que nous soyons                                                    1 Il pose l’hypothèse d’une personne qui n’a aucune connaissance du chinois, enfermée dans une  chambre, et disposant d’un catalogue de règles perm ettant de répondre à des phrases en chinois,  selon des règles de syntaxe. Cette personne enfermé e dans la chambre reçoit donc des phrases écrites  en chinois et, en appliquant les règles à sa dispos ition, produit d’autres phrases en chinois qui  constituent en fait des réponses à des questions po sées par un vrai sinophone situé à l’extérieur de l a  chambre. Du point de vue du locuteur qui pose les q uestions, la personne enfermée dans la chambre  se comporte comme un individu qui parlerait vraimen t chinois. Mais, en l’occurrence, cette dernière  n’a aucune compréhension de la signification des ph rases en chinois qu’elle crée. Elle ne fait que  suivre des règles prédéterminées. 
- 200  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        en train de construire une super-intelligence en pa sse de prendre le pouvoir à notre  place  ». Les défis que l’intelligence artificielle devra  relever sont d’un autre  ordre selon David Sadek puisque « l’intelligence artificielle, c’est avant tout la  didactique des machines, c’est-à-dire apprendre aux  machines ce que les humains  savent déjà faire (…) quand on parle de vision arti ficielle, par exemple lorsque  Google apprend à identifier un chat sur des photos,  ce n’est pas parce qu’un  algorithme apprend à repérer un chat qu’il sait ce que c’est. De même, le test de  Turing ne sera peut-être pas le meilleur critère po ur évaluer les IA à l’avenir  ».  Ces observations conduisent à relativiser les récen ts progrès de  l’intelligence artificielle et, en particulier, à c ontester le fantasme de  l’intelligence artificielle forte car elles récusen t la pertinence d’une  comparaison avec l’intelligence humaine.  Selon Raja Chatila, la question initiale de Turing devrait conduire à  l’interrogation suivante : une machine peut-elle av oir une faculté de  conscience d’elle-même ? Car malgré toutes les rech erches en robotique et  intelligence artificielle, les résultats, aussi significatifs soient-ils, restent le  plus souvent applicables dans des contextes restrei nts et bien délimités .  Ainsi, la perception ne permet pas à un robot de co mprendre son  environnement, c’est-à-dire d’élaborer une connaiss ance suffisamment  générale et opératoire sur celui-ci (d’où la nécess ité d’étudier la notion  d’ « affordance 1 »), la prise de décision reste limitée à des probl èmes  relativement simples et bien modélisés. Les principes fondamentaux, qui  permettraient aux robots d’interpréter leur environ nement , restent  largement incompris  : comprendre leurs propres actions et leurs effets ,  prendre des initiatives, exhiber des comportements exploratoires, acquérir  de nouvelles connaissances et de nouvelles capacité s… Les clés pour  permettre la réalisation de ces fonctions cognitive s pourraient être le métaraisonnement  et la capacité d’auto-évaluation , deux mécanismes réflexifs.   Yann LeCun, dans un article de juillet 2016, se dem ande « pourquoi  croire à un moment de rupture où les machines seron t supérieures à l’homme ? Elles  vont simplement devenir de plus en plus intelligent es et de plus en plus faciles à  utiliser. Cela amplifiera notre propre intelligence  ! » et il estime que « beaucoup  des scénarios catastrophes (en intelligence artific ielle) sont élaborés par des  personnes qui ne connaissent pas les limites actuel les du domaine. Or les spécialistes  disent qu’ils sont loin de la réalité  ».  De même Rob High, directeur technique du projet Wat son d’IBM  estime qu’il est « trop tôt pour employer le terme intelligence artifi cielle, mieux  vaut parler d’outils capable d’élargir les capacité s cognitives humaines  ».  Lors de sa rencontre avec vos rapporteurs au siège de Google, Greg  Corrado, directeur de la recherche en intelligence artificielle chez Google, a  lui aussi fait valoir qu’il était plus juste de par ler d’ intelligence augmentée   plutôt que d’intelligence artificielle.                                                    1 En ergonomie ou en informatique, l’affordance est la capacité d’un objet à suggérer sa propre  utilisation. 
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 201  -       Pour Jean-Claude Heudin, l’intelligence artificielle ne remplace pas  l’homme mais augmente son intelligence , en formant une sorte de  « troisième hémisphère ».  Cette idée de complémentarité homme-machine et d’intelligence  augmentée a convaincu vos rapporteurs . Selon François Taddéi, directeur  du Centre de recherche interdisciplinaire, « les intelligences humaine et  artificielle coévoluent. Mais ce sont encore les co mbinaisons homme/machine qui  sont les plus performantes : on le voit aux échecs,  où une équipe homme/machine est  capable de battre et l’homme et la machine  ».  En 1996, puis à nouveau en 1997, le champion d’éche cs Garry  Kasparov était battu par le système d’intelligence artificielle Deep Blue créé  par IBM. De nos jours, n’importe quel programme gratuit d’échecs  téléchargeable sur Internet peut battre non seuleme nt les plus grands  champions d’échecs mais aussi Deep Blue . Mais l’homme et la machine,  l’homme-centaure, sont toujours plus forts que tout es les machines . Les  joueurs d’échecs et de Go l’ont expérimenté.  Ainsi que vos rapporteurs ont eu l’occasion de le r appeler  précédemment dans le présent rapport, une victoire équivalente d’une  intelligence artificielle au jeu de Go semblait imp ossible, tant ce jeu exige une  subtilité et une complexité propres à l’intelligenc e humaine. Pourtant, le  15 mars 2016, le système d’intelligence artificiell e AlphaGo créé par  l’entreprise britannique DeepMind, rachetée en 2014  par Google, a battu le  champion de Go, Lee Sedol, avec un score final de 4  à 1, marquant donc  l’histoire des progrès en intelligence artificielle . Selon l’académicien des  technologies Gérard Sabah, il est difficile et risqué d’établir des prévisions   détaillées sur l’avenir à court, moyen et long term es de l’intelligence  artificielle.  Il a toutefois pu émettre quelques hypothèses génér ales fondées sur  l’observation du passé :  - l’intelligence artificielle continuera à faire émer ger de nouvelles  techniques de calcul  ;  - certaines de ces nouvelles techniques trouveront de s applications  utiles , mais avec des délais variables, pouvant aller jus qu’à deux  décennies ;  - certains de ces nouveaux développements conduiront à la formation et  à la rupture de nouveaux domaines de l’informatique  ;  - la méthodologie des techniques de l’intelligence ar tificielle, maintenant  bien établie par des analyses théoriques et des tes ts empiriques,  permettra d’obtenir des produits robustes et fiables . 
- 202  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        3.  Les questions posées par la « convergence NBIC »   La « convergence NBIC » est un thème issu du rappor t  particulièrement volumineux de Mihail C. Roco and W illiam Sims  Bainbridge à la National Science Foundation (États- Unis) en 2003, intitulé  Converging Technologies for Improving Human Perform ance 1. Il s’agit des  convergences entre les nanotechnologies, les biotec hnologies, les  technologies de l’information et les sciences cogni tives. Ce projet ambitieux  de fertilisation croisée n’a pas produit de grands résultats à ce stade  mais  les progrès en intelligence artificielle, en génomique,  en sciences  cognitives et en neurosciences reposent la question  aujourd’hui .  Ce projet ambitieux d’un enrichissement mutuel de c es champs de  recherche mérite donc que vos rapporteurs le mentio nnent. Notre collègue  Jean-Yves Le Déaut, président de l’OPECST, conduit d’ailleurs un travail à ce  sujet pour l’Assemblée parlementaire du Conseil de l’Europe, en tant que  rapporteur pour la science et la technologie. Son p rojet de rapport sur la  convergence technologique, l’intelligence artificie lle et les droits de  l’homme  contiendra des pistes pour que cette convergence s oit respectueuse  des droits humains.  Il pourrait appeler, en particulier, à la vigilance  en matière de  renforcement de la transparence concernant : les op érations de traitements  automatisés visant à collecter, manier et utiliser les données à caractère  personnel ; l’information du public sur la valeur d es données qu’il produit,  le consentement sur leur utilisation et la fixation  de la durée du temps de  conservation de ces données ; l’information de tout e personne sur le  traitement de données dont elle est la source ainsi  que sur les modèles  mathématiques, statistiques qui permettent le profi lage ; la conception et  l’utilisation de logiciels persuasifs et d’algorith mes respectant pleinement la  dignité et les droits fondamentaux de tous les util isateurs, en particulier les  plus vulnérables, dont les personnes âgées et les p ersonnes handicapées.  4.  La tentation du « transhumanisme »   La crainte d’une intelligence artificielle qui écha pperait au  contrôle de l’homme est une des angoisses majeures devant l’essor de ces  technologies, comme il a été vu. En cela, la prospective en intel ligence  artificielle aboutit souvent à des scénarios de dystopie technologique . Ce  pessimisme n’est cependant pas partagé par l’ensemb le des futurologues  puisque, pour certains, les progrès de l’intelligen ce artificielle permettront de  protéger la vie humaine, par la sécurité routière e t la médecine évidemment,  voire d’offrir une opportunité historique pour concrétiser l’utopie  transhumaniste .                                                    1 http://www.wtec.org/ConvergingTechnologies/Report/N BIC_report.pdf  
DEUXIÈME  PARTIE  :   LES ENJEUX DE L ’INTELLIGENCE ARTIFICIELLE   - 203  -       Le transhumanisme est un mouvement philosophique prédisant et  travaillant à une amélioration de la nature de l’ho mme grâce aux sciences  et aux évolutions technologiques .  Le chercheur et prêtre jésuite Pierre Teilhard de C hardin aurait été,  l’un des premiers à utiliser le terme transhumain, en 1951 1. Julian Huxley 2  crée lui le concept de transhumanisme en 1957. Bien  que le terme soit un  label recouvrant des mouvements très différents, il  renvoie au dépassement  des souffrances humaines grâce aux découvertes scie ntifiques.  L’amélioration de nos capacités par l’intermédiaire  des sciences et des  technologies disponibles est au cœur de ce mouvemen t. Pour les  transhumanistes, le progrès scientifique doit être orienté vers cet objectif. Le  transhumanisme est multidisciplinaire dans la mesur e où il agrège, pour  parvenir à ses fins, l’ensemble des sciences et des  connaissances . Pour les  transhumanistes, l’homme « augmenté » pourrait, dem ain, devenir  virtuellement immortel.   Le transhumanisme s’apparente à une religion. Son p rincipal  prophète est Raymond Kurzweil, déjà cité s’agissant  de la singularité. En  2013, Max More et Natasha Vita-More ont publié un e ssai particulièrement  riche à ce sujet 3.  Le projet transhumaniste de mort de la mort et de f in de la  souffrance n’emporte pas l’adhésion de vos rapporte urs . Il s’apparente à  une négation de la nature humaine. Or pour vos rapp orteurs, l’intelligence  artificielle n’est pas un acte de foi et ne doit pa s le devenir .  Selon Raja Chatila, « derrière ces discours, nous avons des vues de l’esp rit  qui n’ont rien d’opérationnelles, elles sont en réa lité des idéologies, qu’on cherche à  imposer pour gommer les différences entre l’humain et le non-humain  ».  Jean-Gabriel Ganascia relève que ce projet possède un versant cybernétique  et un versant plus biologique. Luc Ferry, dans son essai La Révolution  transhumaniste , souligne ces différentes sensibilités au sein de la « famille »  transhumaniste.  Pour vos rapporteurs, il s’agit de chimères ou d’éc rans de fumée qui  empêchent de se poser les vraies questions pertinen tes. Selon eux, il est  essentiel de savoir anticiper les problèmes potentiels posés par   l’intelligence artificielle . À court terme, ces problèmes risquent d’être  ignorés et pris à tort pour de la science-fiction. Il convient en effet de  distinguer les craintes issues de certaines fiction s cinématographiques,  telles que Terminator , Matrix  ou Transcendance , des problèmes réels qui  risquent de survenir plus ou moins rapidement .                                                    1 Sa première occurrence serait la conclusion d’un a rticle intitulé « Du préhumain à  l’ultra-humain », paru au sein de l’Almanach des Sc iences de 1951.  2 Frère de l’écrivain Aldous Huxley, Julian Huxley e st un biologiste britannique, théoricien de  l’eugénisme, premier directeur de l’UNESCO, fondate ur du WWF et auteur connu pour ses livres de  vulgarisation scientifique.  3 Cf. Max More et Natasha Vita-More, The Transhumanist Reader : Classical and  Contemporary Essays on the Science, Technology, and  Philosophy of the Human Future . 

TROISIÈME  PARTIE  :   LES PROPOSITIONS DE VOS RAPPORTEURS   - 205  -         TROISIÈME PARTIE :   LES PROPOSITIONS DE VOS RAPPORTEURS     Les propositions présentées ici n’ont pas vocation à couvrir  l’ampleur des questions posées par la recherche en intelligence artificielle ,  ainsi que l’affirmait Jean de la Fontaine, « Loin d’épuiser une matière, On n’en  doit prendre que la fleur  ». Il s’agit plus de recommandations sous forme de   contributions à la réflexion collective et vos rapp orteurs n’ont pas entendu  répondre en totalité aux défis posés pour la France  et l’Europe par les enjeux  industriels  de l’intelligence artificielle, par l’automatisation de certaines  tâches et par l’économie globalisée de plateformes  qui se dessine avec  l’émergence d’entreprises privées puissantes basées  aux États-Unis ou en  Chine. Ces dimensions, évoquées dans le rapport, ne  sont pas le cœur de  métier de l’OPECST et ne se traduisent donc que par tiellement dans les  propositions formulées ci-après.    I.   POUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE  Proposition n° 1 : Se garder d’une contrainte jurid ique trop forte  sur la recherche en intelligence artificielle, qui - en tout état de  cause - gagnerait à être, autant que possible, euro péenne, voire  internationale, plutôt que nationale  Vos rapporteurs appellent à ne pas céder à la tentation de proposer  et de mettre en place des mesures  dans un cadre trop étroitement national,  qui décourageraient la recherche en intelligence ar tificielle, mais plutôt à  soutenir une forme de régulation internationale. Il  convient de se garder  d’une contrainte juridique trop forte  sur la recherche dans ce domaine, qui  gagnerait à être, en tout état de cause, instaurée à l’échelle européenne, voire  internationale, mais pas uniquement nationale.  Le professeur de droit Albert De Lapradelle affirma it, de manière  provocatrice, que « ce ne sont pas les philosophes avec leurs théories,  ni les juristes  avec leurs formules, mais les ingénieurs avec leurs  inventions qui font le droit et  surtout le progrès du droit ». Vos rapporteurs estiment que c’est surtout au  législateur de réfléchir au droit souhaitable en ma tière d’intelligence  artificielle et de robotique , au terme d’un débat public éclairé avec toutes  les parties prenantes, du citoyen ordinaire à l’exp ert scientifique, en  passant par l’entrepreneur et le technicien .  Il faudra savoir adapter la législation aux nouveaux risques posés  par l’intelligence artificielle et la robotique, ma is il faudra aussi veiller à ne  pas freiner le développement de ces technologies . Des mesures trop  contraignantes auraient pour effet d’ augmenter les coûts de 
- 206  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        commercialisation et de mise en conformité,  ou de poser de nouveaux  freins légaux à l’innovation et à la rentabilité de  ces secteurs d’activité . Un  équilibre subtil est à trouver et le présent rapport entend contribuer à la  réflexion collective en la matière .  La peur ne doit pas paralyser  : vos rapporteurs ne veulent pas  tomber dans la solution de facilité qui consisterai t à faire un usage extensif  du principe de précaution et donc à limiter, a priori , la recherche en  intelligence artificielle. Une telle démarche serai t contraire à l’esprit  scientifique, que vos rapporteurs revendiquent et p romeuvent. Elle serait  également préjudiciable à l’intérêt national  : sans rivaliser directement avec  les États-Unis, la Chine ou le Japon en la matière,  la France dispose d’ atouts  considérables en matière de recherche en intelligen ce artificielle  et ne doit  pas perdre cet avantage comparatif, au risque de se  placer hors jeu dans la  compétition internationale qui s’est engagée .    Proposition n° 2 : Favoriser des algorithmes et des  robots sûrs,  transparents et justes, et prévoir une charte de l’ intelligence  artificielle et de la robotique  Il faut favoriser des algorithmes et des robots  qui soient à la fois  sûrs, transparents et justes . Il faut aussi prévoir une charte de l’intelligence  artificielle et de la robotique , qui nécessitera du temps et une concertation  internationale .  L’approche européenne , voire internationale  est importante à ce  niveau. L’initiative IEEE présentée précédemment va  dans ce sens, en  particulier en ce qui concerne les problèmes liés a ux standards, normes et  certifications .  Les considérations de sécurité  et de robustesse évoquées dans le  présent rapport amènent à conclure qu’il est pertin ent de poursuivre, en  général, la réflexion sur la sécurité numérique et,  en particulier, de prévoir  des mécanismes d’arrêt d’urgence. L’interruption d’un système  d’intelligence artificielle ou d’un robot doit être  possible . Des « boutons  rouges », réels ou virtuels, doivent permettre la d ésactivation des systèmes.  Une telle sécurité est souhaitable mais elle peut ê tre difficile à mettre en  œuvre, surtout que l’arrêt brutal d’un système peut  avoir des conséquences  graves et imprévisibles 1.  Il faut rechercher la transparence des algorithmes  contre les boîtes  noires, les biais et les discriminations.                                                    1 Dans ce cas, l’opérateur est conduit à faire un ch oix rapide entre deux types de conséquences  négatives, celles liées aux dysfonctionnements du s ystème d’IA ou celles liées aux conséquences de  l’arrêt du système. 
TROISIÈME  PARTIE  :   LES PROPOSITIONS DE VOS RAPPORTEURS   - 207  -       Il convient de prévoir aussi des mécanismes de traç abilité, du type  journaux de bord ou loggings 1, ces « mémoires internes » de type  enregistreurs numériques des avions (appelées aussi  « boîtes noires », mais  qui n’ont rien à voir avec le qualificatif de « boî tes noires » appliqué aux  algorithmes de deep learning ). Pour pouvoir expliquer un éventuel  dysfonctionnement, il faut être en mesure de remonter aux derniers circuits  de décision et à leurs motifs . Comme il a été dit précédemment, la  transparence des algorithmes de deep learning  n’existe pas, à ce stade, et  reste à construire. Il s’agit d’un  axe prioritaire pour la recherche . L’initiative  TransAlgo d’Inria, avec le concours du Conseil nati onal du numérique  (CNNum), va dans ce sens et mérite d’être applaudie . Mais elle doit se  prolonger et prendre davantage d’ampleur, pour dépa sser le strict cadre  d’Inria. La question de la transparence des algorit hmes ne se confond pas  avec la question de leur loyauté, mais elle doit au ssi être posée. Il faut noter  qu’à la différence des méthodes d’apprentissage aut omatique profond tels  que les algorithmes de deep learning , le traitement et l’analyse de données  effectués par les réseaux bayésiens sont des systèm es transparents . Il ne  revient pas aux pouvoirs publics de choisir entre t elle ou telle technologie  mais, à performance égale, les technologies transparentes  doivent être  privilégiées .  Pour Raja Chatila, directeur de l’Institut de Systè mes Intelligents et  de Robotique, « le bouton rouge, c’est bien mais c’est déjà trop ta rd, il faut tout  prévoir pour ne pas en arriver là. L’état du systèm e doit être constamment observé et  il faut pouvoir détecter toute déviance avant l’arr ivée des problèmes  ». Il faut  porter, selon lui, une grande attention aux signes précurseurs,  d’autant plus  que les systèmes régis par des technologies d’intel ligence artificielle peuvent  avoir de vastes implications, qui seront de plus en  plus stratégiques, à  l’image de l’alimentation d’une grande ville en éle ctricité. Il rappelle que  tout robot peut virtuellement être dangereux, puisq ue qu’il s’agit d’un objet  puissant en mouvement : ses mouvements peuvent deve nir violents et son  alimentation électrique peut impliquer des risques d’électrocution. Les  dispositifs de vigilance mis en œuvre doivent perme ttre de relever ce défi.  En face de systèmes complexes, des « systèmes de systèmes  » représentent  des perspectives fondamentales en vue de la maîtris e des machines.  La question de la faisabilité de ces préconisations exigeantes,  visant à disposer d’algorithmes et de robots qui so ient à la fois sûrs,  transparents et justes, se pose. Il n’est pas sûr qu’elles puissent être  satisfaites, mais ce sont des objectifs que nous devons nous fixer , quoi qu’il  en soit.                                                    1 En informatique, ces journaux, historiques des évé nements ou loggings  désignent  « l’enregistrement séquentiel dans un fichier ou un e base de données de tous les événements affectant  un processus particulier (application, activité d’u n réseau informatique…). Le journal (en anglais  log file  ou plus simplement log ), désigne alors le fichier contenant ces enregistr ements.  Généralement datés et classés par ordre chronologiq ue, ces derniers permettent d’analyser pas à pas  l’activité interne du processus et ses interactions  avec son environnement » (source : Wikipédia). 
- 208  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        La charte de l’intelligence artificielle et de la robo tique   proclamerait ces objectifs et viserait à codifier l es bonnes pratiques. Elle  devrait être internationale , dans toute la mesure du possible, ou à défaut  européenne. Elle ne se prononcerait pas en faveur de la création d’une  personnalité morale des robots,  mais proposerait des règles relatives aux  interactions homme-machine et poserait des limites en matière d’imitation  du vivant, pour les robots androïdes comme pour les  agents  conversationnels. Le citoyen devrait toujours savoi r s’il est en présence d’une  machine ou d’un humain.  Cette charte pourrait, en outre, proposer d’interdi re les robots  tueurs. Toutefois, ce débat aurait davantage sa pla ce dans le cadre   international des conventions sur les armes et du tr aité sur la nonprolifération des armes nucléaires (TNP) .    Proposition n° 3 : Former à l’éthique de l’intellig ence artificielle et  de la robotique dans certains cursus spécialisés de  l’enseignement  supérieur  Nous devons offrir de façon systématique des formations à  l’éthique de l’intelligence artificielle et de la r obotique dans les cursus de  l’enseignement supérieur qui traitent des algorithmes, de l’intelligence  artificielle et de la robotique. Google Deep Mind l e propose, d’ailleurs, pour  tous les masters britanniques spécialisés. La CERNA  pourrait être associée à  ce projet.  Les formes de cette offre de formation devront être  innovantes,  mobiliser les étudiants, à travers des ateliers, de s débats et des mises en  situation . Il conviendra d’éviter la forme du module de cour s théorique,  validé après le suivi d’un simple cours magistral.  La diffusion de ces connaissances  sur l’éthique de l’intelligence  artificielle et de la robotique vers les autres étudiants, voire le grand public ,  pourrait être recherchée.    Proposition n° 4 : Confier à un institut national d e l’éthique de  l’intelligence artificielle et de la robotique un r ôle d’animation du  débat public sur les principes éthiques qui doivent  encadrer ces  technologies  Au-delà de la nouvelle mission de la CNIL, il faut confier à un  institut national de l’éthique de l’intelligence ar tificielle et de la robotique  un rôle d’animation du débat public sur les princip es éthiques qui doivent  encadrer ces technologies . Il peut s’agir d’un institut ou d’une commission 
TROISIÈME  PARTIE  :   LES PROPOSITIONS DE VOS RAPPORTEURS   - 209  -       nationale. La création d’un comité national d’éthiq ue de la robotique est  proposée par le SYMOP,  et celle d’un comité national d’éthique de  l’intelligence artificielle a été évoquée devant vo s rapporteurs par Max  Dauchet  et Laurence Devillers .  Les expériences de la CNIL, de la CERNA et du COMET S seront à  considérer. Il n’est pas certain qu’il faille séparer la recherche en  intelligence artificielle de la réflexion éthique s ur l’intelligence  artificielle , mais il est certain que les chercheurs spécialisés en intelligence  artificielle et en robotique ne doivent pas être le s seuls à participer à cette  réflexion . L’Institut pourra se préoccuper de l’acceptabilité individuelle et  sociale  de ces technologies et étudier les effets secondaires  imprévus et/ou  indésirables des différents outils de l’intelligenc e artificielle.  L’institut devra s’ouvrir aux SHS, aux associations  et aux ONG. Les  pouvoirs publics ne devront pas être les seuls à en  assurer le financement.  Les entreprises privées, qui se donnent pour object if d’informer et  d’éduquer dans le domaine des ces technologies et d ’accroître leurs effets  bénéfiques pour la société  (à l’image du « partnership on AI  »), pourraient  participer à son financement.  Cet institut national de l’éthique de l’intelligenc e artificielle et de la  robotique pourra s’intéresser aux problématiques « d’explicabilité »  évoquées plus haut, d’autant plus que le projet Tra ns-algo gagnerait à être  élargi au-delà de l’Inria, comme il a été vu dans l e rapport. La démarche ne  doit pas être réservée à une seule structure de rec herche, mais plusieurs  équipes doivent y travailler parallèlement et un in stitut national pourrait  impulser les projets, coordonner les recherches, an imer le débat public et  faire des propositions aux autorités publiques .    Proposition n° 5 : Accompagner les transformations du marché du  travail sous l’effet de l’intelligence artificielle  et de la robotique en  menant une politique de formation continue ambitieu se visant à  s’adapter aux exigences de requalification et d’amé lioration des  compétences  Les transformations du marché du travail sous l’eff et de  l’intelligence artificielle et de la robotique impo sent de mener une politique  de formation continue ambitieuse  visant à s’adapter aux exigences de  requalification et d’amélioration des compétences. Il s’agit à la fois  d’accompagner les transformations du marché du trav ail, d’adapter le  système éducatif  et de développer les formations professionnelles idoines   pour garantir une souplesse suffisante dans la reco nversion des travailleurs.  Les entreprises devront envoyer plus systématiqueme nt leurs  salariés en formation sur leur temps de travail, de  manière à actualiser leurs  connaissances et leurs compétences, par exemple tou s les cinq ans. Le 
- 210  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Compte personnel d’activité  (CPA) peut être un outil mobilisable à cette fin  et le service « Formation Tout au Long de la Vie  » (FTLV), guichet unique  pour l’usager comme pour l’entreprise, permet de co ncrétiser le droit à la  formation continue, tant pour les démarches d’orien tation, de bilan,  d’accompagnement vers l’emploi, que pour les action s de formation et de  validation des acquis de l’expérience.  Les métiers du futur devront relever les défis tech nologiques posés  par l’intelligence artificielle et la robotique, sa chant que les hommes  bénéficieront de nouvelles activités liées à la dif fusion de ces  technologies  : concevoir, entraîner, éduquer, surveiller, répar er les systèmes  et les machines. De nouveaux métiers deviendront envisageables,  et ils  apporteront autant de nouvelles opportunités d’emplois . Parmi ces métiers  qui vont émerger, certains sont encore inconnus, ma is d’autres peuvent  d’ores et déjà être identifiés : concepteur, entraîneur, éducateur, vérificateur  ou, encore, évaluateur des systèmes d’intelligence artificielle et des robots .    II.  POUR UNE INTELLIGENCE ARTIFICIELLE UTILE, AU SERVIC E DE  L’HOMME ET DES VALEURS HUMANISTES  Proposition n° 6 : Redonner une place essentielle à  la recherche  fondamentale et revaloriser la place de la recherch e publique par  rapport à la recherche privée, tout en encourageant  leur  coopération  Il faut parvenir à redonner une place essentielle à la recherche  fondamentale  et à revaloriser le rôle de la recherche publique par ra pport à  la recherche privée,  tout en encourageant leur coopération.  Seule la recherche fondamentale peut permettre de répondre aux  problèmes d’explicabilité des algorithmes et de bia is dans les données .  Nous en avons besoin car, des enjeux de maîtrise de s technologies à ceux du  du financement de la recherche publique, tout se ti ent.  La recherche fondamentale pose, par ailleurs, la qu estion du mode  de financement des projets : il faut favoriser la recherche transversale et ne  surtout pas reproduire l’hyperspécialisation entre sous-domaines de  l’intelligence artificielle .  Ce serait une erreur de financer d’un côté la perce ption, d’un autre,  la vision, encore d’un autre la prise de décisions,  l’apprentissage machine, la  robotique, la relation homme-machine…  Il faut mobiliser les équipes de chercheurs autour de grand s  projets nationaux structurants  et résister aux sirènes de  l’hyperspécialisation entre sous-domaines de l’inte lligence artificielle.  D’après les informations recueillies par vos rappor teurs, le  Commissariat général à l’investissement (CGI), Bpif rance et l’initiative du 
TROISIÈME  PARTIE  :   LES PROPOSITIONS DE VOS RAPPORTEURS   - 211  -       Gouvernement France IA pourraient orienter le futur  PIA dans le sens de  cette hyperspécialisation, ce qui est de nature à l es inquiéter.  Le mode de financement des projets pourrait de plus  gagner à  s’inscrire dans des temps plus longs que 3, 4 ou 5 ans seulement , de  manière à porter les projets à leur pleine maturati on. C’est ainsi le cas aux  États-Unis pour la plupart des projets soutenus par  la Fondation nationale  pour la science, visitée par vos rapporteurs à Wash ington (National Science  Foundation ou NSF), mais encore du projet Todai Rob ot 1 conduit depuis  2011 pour dix ans à l’Université de Tokyo au Japon,  avec le soutien de  l’Institut national de l’informatique japonais et l ’entreprise Fujitsu.  Des projets de grandes bases de données labellisées , nécessaires à  l’apprentissage machine, pourraient être lancés, pa r exemple autour de la  langue française, du marché de l’emploi ou des donn ées de santé, sous  condition d’anonymisation. Ces initiatives pourraie nt se faire en liaison avec  la CNAM, l’APHP, la BNF, l’INA ou, encore, avec Pôl e emploi. Dans son  intervention lors de la journée « Entreprises franç aises et intelligence  artificielle » organisée par le MEDEF et l’AFIA le 23 janvier 2017, Yves  Caseau, animateur du groupe de travail sur l’IA de l’Académie des  technologies, a fourni les premières recommandation s de son groupe, la  première consistant à la collecte en France de jeux de données massifs 2, car  ces jeux de données sont essentiels au développemen t de l’intelligence  artificielle par l’apprentissage.  Quant au  niveau des investissements requis, vos rapporteurs  ne se  sont pas avancés à réaliser leur propre chiffrage . Selon Bertrand  Braunschweig, directeur du centre Inria de Saclay, l’effort financier  nécessaire serait de l’ordre de 100 millions d’euros par an sur dix ans ,  financements publics et privés compris.  De très nombreuses coopérations public-privé existe nt et  fonctionnent et il est loisible de s’en inspirer (M icrosoft-Inria, CNRS avec  IBM, Rhodia, Thalès, Michelin…)  Jean-Gabriel Ganascia pose la question de l’articul ation entre  recherche publique et recherche privée de la manièr e suivante : «  Depuis une  trentaine d’année, un accent très fort a été mis au  plan européen et au plan national,  sur les projets collaboratifs entre l’université et  l’industrie. Cela a certainement eu  des aspects très bénéfiques, mais ce mode de coopér ation présente aussi des limites.  En effet, le caractère très administratif du montag e des projets qui conduit, en                                                    1 En novembre 2016, ce robot a échoué pour la quatri ème année consécutive à intégrer la prestigieuse  Université de Tokyo. Ses concepteurs tirent à chaqu e rentrée scolaire les leçons de cet échec pour  faire progresser la machine.  2 Les trois autres recommandations sont :  • commencer à utiliser des réseaux neuronaux afin d e résoudre des problèmes de classification  externe (exemple : TensorFlow outil en open source développé par Google) ;  • maîtriser la technologie d’automatisation (roboti c process automation) en augmentant le volume  d’investissement dans la robotique de pointe et de robotique à haute performance ;  • implémenter les premiers chatbots d’assistance cl ient sur des périmètres fonctionnels simples. 
- 212  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        particulier au plan européen, à solliciter des soci étés spécialisées pour le montage des  projets, le taux d’acceptation des projets (moins d e 8 %, parfois de 2 % pour  certaines actions), les procédures d’évaluation trè s rigides, conduisent à une  recherche chère, conventionnelle et peu innovante, tendant à stériliser les équipes. À  cela, il faut ajouter qu’en l’absence de post-évalu ation sérieuse, on n’est pas en  mesure de tirer parti des résultats de projets fina ncés, ce qui conduit à un gaspillage  des ressources. Il faudrait encourager des partenar iats bilatéraux entre une équipe  privée et un laboratoire public, avec des actions p lus légères. Il est à noter que des  actions à plus long terme, comme les Labex, ou des financements de bourses de type  « CIFRE » complétés par des contrats conclus grâce au crédit d’impôt recherche,  peuvent avoir des effets très positifs ».  Il est important de produire de l’intelligence artificielle « à la  française » , en intégrant notamment les sciences humaines et s ociales. Les  réponses possibles à la question de la vulnérabilit é de la société aux  bouleversements des innovations technologiques doit  pouvoir s’appuyer sur  les sciences humaines.    Proposition n° 7 : Encourager la constitution de ch ampions  européens en intelligence artificielle et en roboti que, tout en  poursuivant le soutien aux PME spécialisées, en par ticulier les  start-up  Il faut encourager la constitution de champions européens e n  intelligence artificielle et en robotique , sans retomber dans les erreurs du  projet Quaero 1 mais plutôt en suivant les traces des succès du mo dèle  d’Airbus, ce qui pourra impliquer de poser la quest ion du droit de la  concurrence dans l’Union européenne, très contraign ant en matière de  concentrations. Cette proposition s’ajoute à celle de poursuivre les mesures  de soutien aux PME spécialisées , en particulier les start-up.  Faire émerger des champions européens et soutenir n otre tissu de  PME passe aussi par un écosystème rendu encore plus  favorable grâce à la  mise à dispositions de très grands volumes de donné es (vue au paragraphe  précédent), l’accès facilité à des supercalculateur s, dont les puissances de  traitement pourraient être mises en réseau sur le cloud , l’harmonisation du                                                    1 Le projet, imaginé par la France en 2004 en tant q u’un des cinq premiers PMII (programmes  mobilisateurs pour l’innovation industrielle), lanc é en 2008 avec le soutien de l’Allemagne et  abandonné en 2013, visait à développer des « outils intégrés de gestion des contenus  multimédias  », dont des extensions multimédias pour des moteur s de recherche de nouvelle  génération qui devaient permettre de rechercher par  le contenu non seulement du texte, mais aussi  des images, du son et de la vidéo. L’ambition de co nstituer les fondements technologiques européens  de futurs moteurs de recherche a donc rapidement av orté, l’américain Google demeurant dans un  quasi-monopole (en dépit des qualités éthiques du m oteur de recherche français « Qwant »). Le projet  Quaero s’est donc soldé par un échec mais il n’est pas nécessaire d’espérer pour entreprendre ni de  réussir pour persévérer, cf. http://www.quaero.org/   
TROISIÈME  PARTIE  :   LES PROPOSITIONS DE VOS RAPPORTEURS   - 213  -       droit applicable, par exemple en matière de protect ion des données  personnelles dans l’Union européenne.  Sans verser directement dans le nationalisme indust riel appliqué à  l’intelligence artificielle, il faut réfléchir aux formes de protection qui  pourraient être instituées, car les laboratoires fr ançais sont pillés de leurs  chercheurs par des multinationales nord-américaines  et chinoises.  La  question du soutien à la création, mais aussi à la croissance des entreprises  françaises de ce secteur, en particulier de ses sta rt-up, doit être étudiée ,  afin de faire  émerger une industrie française de l’intelligence artificielle  qui développera des produits innovants compétitifs et exportables. Là aussi,  en plus de l’encouragement et de la facilitation de  l’accès aux dispositifs de  soutiens, des protections pourraient être utiles.  Comme l’affirment justement Thierry de Montbrial et  Thomas  Gomart, dans un ouvrage qu’ils viennent de publier en février 2017, nous  devons défendre « notre intérêt national  » et vos rapporteurs y ajoutent « notre  intérêt européen » .    Proposition n° 8 : Orienter les investissements dan s la recherche  en intelligence artificielle vers l’utilité sociale  des découvertes   Il faut orienter les investissements dans la recher che en intelligence  artificielle vers l’utilité sociale des découvertes , en encourageant les  applications à impact sociétal bénéfique  : bien-être, santé, dépendance,  handicap, infrastructures civiles, gestion des cata strophes … De manière  caricaturale, la recherche appliquée en intelligenc e artificielle ne doit pas  s’intéresser qu’au trading  à haute fréquence (THF).   Il convient de saisir, dans notre intérêt national,  les opportunités  ouvertes par les technologies d’intelligence artifi cielle. Là aussi, les  entreprises privées, qui se donnent pour objectif d ’informer et d’éduquer  dans le domaine de ces technologies et d’accroître leurs effets bénéfiques  pour la société, pourraient participer à l’effort c ollectif nécessaire.    Proposition n° 9 : Élargir l’offre de cursus et de modules de  formation aux technologies d’intelligence artificie lle dans  l’enseignement supérieur et créer, en France, au mo ins un pôle  d’excellence international et interdisciplinaire en  intelligence  artificielle et en robotique  Il est nécessaire d’élargir l’offre de cursus et de modules de  formation aux technologies d’intelligence artificie lle dans l’enseignement  supérieur  et de créer en France au moins un pôle d’excellence inter national 
- 214  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        et interdisciplinaire en intelligence artificielle et en robotique . Il s’agit de  renforcer ces formations, alors que des besoins con sidérables apparaîtront  bientôt pour le développement de l’intelligence art ificielle. Des cycles de  formation longs apparaissent donc nécessaires, mais  des cycles de formation  plus courts et plus professionnalisants le sont aus si, le cas échéant selon un  processus itératif.  Il sera possible de s’appuyer sur l’expérience des 138 cours  spécifiques en intelligence artificielle, ou techni ques en relation avec l’IA,  dispensés dans l’enseignement supérieur français ch aque année et sur les  16 masters existants qui, de près ou de loin, sont spécialisés en intelligence  artificielle en France, à l’image du Master MVA-MAT H de l’ENS Cachan, du  Master en sciences cognitives (Cog master) de l’ENS  Ulm, des Masters  ANDROIDE (AgeNts Distribués, Robotique, Recherche o pérationnelle,  Interaction, Decision) et DAC (Master Données, Appr entissage et  Connaissances de l’Université Pierre-et-Marie-Curie  Paris 6 (UPMC), du  Master en informatique spécialité intelligence arti ficielle de Université ParisDescartes ou, encore du Master « Intelligence Artif icielle et Reconnaissance  des Formes » de l’Université Paul Sabatier de Toulo use.   En outre,  il est nécessaire de créer en France au moins un pôle  d’excellence international et interdisciplinaire  en intelligence artificielle et  en robotique. Jusqu’à deux ou trois pôles pourraien t voir le jour, appuyés sur  l’excellence d’Inria, du LAAS de Toulouse, de l’ENS , de l’Institut  Mines-Télécom… Ils ne seraient pas nécessairement g éographiquement  localisés, mais, à défaut d’une création pure et si mple, il paraît urgent  d’encourager la coordination et d’accroître la cohé rence des instituts et des  centres existants, et de leurs équipes de recherche s à travers des réseaux  d’excellence en IA .   Vos rapporteurs ont visité au Royaume-Uni, en Suiss e et aux ÉtatsUnis des pôles d’excellence à visibilité internatio nale et à vocation  interdisciplinaire. Ils jugent indispensables de s’ inspirer de ces pôles pour  structurer la recherche française, qui est déjà d’e xcellent niveau. Et comme  l’a fait remarquer le jeune chercheur Jill-Jênn Vie  à vos rapporteurs, le cas de  son laboratoire de recherche Riken en intelligence artificielle à Tokyo montre  qu’il est possible de développer l’excellence à l’é chelle de tout un pays, ici le  Japon, et que ce rayonnement est utile à tous les c hercheurs concernés.   
TROISIÈME  PARTIE  :   LES PROPOSITIONS DE VOS RAPPORTEURS   - 215  -       Proposition n° 10 : Structurer et mobiliser la comm unauté  française de la recherche en intelligence artificie lle en organisant  davantage de concours primés à dimension nationale,  destinés à  dynamiser la recherche en intelligence artificielle , par exemple  autour du traitement de grandes bases de données na tionales  labellisées  L’initiative « France IA » est une étape importante  dans la  mobilisation de la communauté française de la reche rche en intelligence  artificielle . Il faut continuer et structurer encore davantage celle-ci, par  exemple en organisant davantage de concours primés à dimension  nationale , destinés à dynamiser la recherche en intelligence  artificielle, par  exemple autour du traitement de grandes bases de do nnées nationales  labellisées.  Les projets de la DARPA , à l’image de celui présenté à vos  rapporteurs au siège de l’organisme en matière de c ybersécurité, reposent  souvent sur ce modèle, qui crée une saine émulation  au sein des équipes. Un  travail avec l’ANR  peut être envisagé pour définir une offre français e de  grands concours primés en IA  et contribuer à l’excellence de la recherche en  France.  Les « hackathons  »1 qui sont à la fois le principe, le moment et le li eu  d’événements dans lesquels des développeurs se réun issent pour faire de la  programmation informatique collaborative, sont des pistes à creuser pour  assurer une telle promotion de la recherche et de l ’innovation en intelligence  artificielle.  Le traitement de grandes bases de données nationale s labellisées  nécessitera de mettre à disposition des jeux de données massifs , ce que le  Gouvernement pourrait favoriser comme il a été vu d ans la proposition n° 6.    Proposition n° 11 : Assurer une meilleure prise en compte de la  diversité et de la place des femmes dans la recherc he en  intelligence artificielle   La place des femmes et la question des minorités da ns la recherche  en intelligence artificielle sont des défis qu’il c onvient de relever.   Diversifier le profil des chercheurs en intelligenc e artificielle et  travailler sur le thème de la diversité dans ce sec teur apparaissent  nécessaires, vos rapporteurs ayant noté la sous-représentation des minorités   dans ce secteur. La réponse qui leur a été faite, s elon laquelle ce serait le cas                                                    1 Ce mot valise a été formé sur la base de « hack » (activité de manipulation d’un système  informatique) et de « marathon ». La référence au «  marathon » provient du fait que le travail des  développeurs est souvent conduit sur plusieurs jour s et sans interruption. 
- 216  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        plus globalement pour tout le secteur de l’informat ique  et  pour les filières  scientifiques en général, ne suffit pas à justifier  la situation présente. Il s’agit  d’ailleurs d’un axe de travail du CNSTI.  Dans le secteur de l’informatique, la vigilance et la prise en compte  des problématiques de biais et de discriminations dans les algorithmes et  les données  seront d’autant plus grandes que les acteurs du do maine seront  issus d’une plus grande diversité.  Ils notent, d’ailleurs, que le Gouvernement a signé , le 31 janvier  2017, un plan sectoriel « mixité dans les métiers d u numérique » avec une  quinzaine de structures telles que Cap digital, le Syndicat national du jeu  vidéo, TECH-IN France ou Syntec numérique. Des plan s similaires ont été  lancés auparavant dans le secteur du bâtiment ou le s transports. Il est vrai  qu’on ne dénombre que 28 % de femmes dans le secteu r du numérique  contre 48 % dans le reste de l’économie, et que der rière ce pourcentage se  cache une réalité encore moins admissible : les fem mes sont surtout  présentes dans les emplois de secrétariat du secteu r du numérique, mais sont  particulièrement sous-représentées dans les métiers  de techniciens,  d’informaticiens ou d’ingénieurs.  Là aussi, les entreprises privées, qui se donnent p our objectif  d’informer et d’éduquer dans le domaine de ces tech nologies ainsi que  d’accroître leurs effets bénéfiques pour la société , pourraient participer à  l’effort collectif nécessaire.    III.  POUR UNE INTELLIGENCE ARTIFICIELLE DÉMYSTIFIÉE   Proposition n° 12 : Organiser des formations à l’in formatique dans  l’enseignement primaire et secondaire faisant une p lace à  l’intelligence artificielle et à la robotique   Toute formation à l’informatique doit s’accompagner  d’une  consolidation de l’apprentissage des mathématiques.  Des formations  spécifiques à l’informatique  sont dispensées dans l’enseignement primaire  et secondaire, mais ces enseignements sont le plus souvent facultatifs 1 et  restent insuffisants . Ils ne font pas toujours, en outre, de place à  l’intelligence artificielle et à la robotique . Il s’agit d’une insuffisance à  laquelle il convient de remédier en urgence. La formation des enseignants   est aussi une priorité.                                                    1 Le programme d’enseignement facultatif d’informati que et création numérique pour les classes de  première des séries générales et les classes termin ales des séries ES et L peut être lu ici :  http://www.education.gouv.fr/pid285/bulletin_offici el.html?cid_bo=104657  . Il peut être rapproché  de celui d’enseignement de spécialité d’informatiqu e et sciences du numérique de la série  scientifique : http://www.education.gouv.fr/pid25535/bulletin_offi ciel.html?cid_bo=57572   
TROISIÈME  PARTIE  :   LES PROPOSITIONS DE VOS RAPPORTEURS   - 217  -       Il peut être noté qu’un plan numérique pour l’éducation  a été lancé  par le Président de la République en mai 2015 1, à l’issue de la concertation  nationale sur le numérique éducatif, et que le Cons eil supérieur des  programmes (CSP) travaille depuis 2015 à un projet de programme pour un  enseignement d’exploration d’informatique et de cré ation numérique 2.     Proposition n° 13 : Former et sensibiliser le grand  public à  l’intelligence artificielle par des campagnes de co mmunication,  l’organisation d’un salon international de l’intell igence artificielle  et de la robotique et la diffusion d’émissions de t élévision  pédagogiques  Il importe de former et de sensibiliser le grand public à  l’intelligence artificielle par des campagnes de co mmunication, par  l’organisation d’un salon international de l’intell igence artificielle et de la  robotique et par la diffusion d’émissions de télévi sion pédagogiques . Le  CNSTI est un organe utile en la matière. Il convien t de faire savoir que les  progrès en intelligence artificielle sont d’abord b énéfiques à la société, et que  les risques éventuels doivent être anticipés et peu vent être maîtrisés. Enfin,  l’avènement d’une intelligence artificielle forte r este peu probable. Nous  nous orientons plus vraisemblablement vers de nouve lles formes  d’intelligence et de nouvelles complémentarités ent re l’homme et la machine,  qui conduiront à une « intelligence augmentée ».                                                    1 Il s’agit de mieux préparer les élèves à être acte ur du monde de demain en développant des  méthodes d’apprentissages innovantes pour favoriser  la réussite scolaire et développer l’autonomie ;  en formant des citoyens responsables et autonomes à  l’ère du numérique ; et en préparant les élèves  aux emplois digitaux de demain. Sa mise en œuvre re pose sur quatre piliers : la formation, les  ressources, l’équipement et l’innovation. Pour aide r les enseignants à faire évoluer leur pratique  pédagogique en intégrant harmonieusement les outils  numériques à leurs cours, un programme de  formation à la fois initiale et continue est mis en  place sur l’ensemble du territoire :  - une formation de trois jours par an dédiée au num érique à destination des enseignants et chefs  d’établissement de collège ;  - des formations mises en place au niveau de l’étab lissement pour une meilleure prise en main des  outils numériques ;  - des formations à distance pour tous les enseignan ts et les professeurs stagiaires  via la plateforme de  formation M@gistère;  - le développement de cours en ligne (Moocs) pour l es enseignants et les professeurs stagiaires sur le   portail France université numérique (FUN-Mooc).  Il s’agit de retenir trois axes de formation : la m aîtrise des outils numériques pour une meilleure  prise en main des outils par les enseignants ; les usages du numérique dans les disciplines pour  développer de nouvelles méthodes d’enseignement ; e t la culture numérique et l’éducation aux  médias et à l’information pour transmettre aux ense ignants les bases essentielles liées à l’usage  d’internet et des réseaux sociaux. Enfin, une plate forme en ligne nationale (Myriaé) est mise à  disposition des enseignants en vue de présenter tou tes les ressources pédagogiques numériques,  gratuites ou payantes, produites par les éditeurs p rivés ou publics. Cf.  http://ecolenumerique.education.gouv.fr/plan-numeri que-pour-l-education/    2 Cf. http://www.education.gouv.fr/cid89179/projet-de-pro gramme-pour-un-enseignement-dexploration-d-informatique-et-de-creation-numerique .html   
- 218  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Un salon international de l’intelligence artificielle et de la  robotique est à organiser en France , en s’inspirant de VivaTech et de  l’initiative Innorobo 1 portée par Catherine Simon, organisatrice du salon   français de la robotique. Il n’existe pas de salon européen du type du   Consumer Electronics Show  (CES) de Las Vegas, qui est un salon consacré à  l’innovation technologique en électronique 2 orienté vers le grand public dès  sa création en 1967, puisqu’il est organisé par la Consumer Technology  Association . Le grand événement professionnel européen en la m atière est,  par défaut, la foire de Hanovre, le plus vaste salo n au monde pour la  technologie industrielle, qui réunit, selon les ann ées, entre 7 et 13 salons  phares internationaux au même endroit : Industrial Automation, MDA  (Motion, Drive & Automation), Digital Factory, ComV ac, Industrial Supply,  Energy, Power Plant Technology, Wind, MobiliTec, Co ilTechnica,  SurfaceTechnology, IndustrialGreenTec, Research & T echnology . Un autre salon  européen est Automatica , salon international qui se tient aussi en Allemag ne,  à Munich, et regroupe tous les professionnels du se cteur de l’automatisme  industriel et de la robotique.  Les réseaux sociaux ou la télévision pourraient êtr e des supports  pour des émissions de partage de la connaissance . Les émissions de  télévision du type de « la faute à l’algo »3, diffusée par la chaîne No Life, ou  de certains épisodes de « data-gueule », diffusés p ar la chaîne France 4, en  sont des exemples intéressants.  Une mobilisation à cette fin de communication des e ntreprises et des  chercheurs est indispensable. Il faut faire preuve de pédagogie, expliquer  que l’intelligence artificielle est complémentaire de l’homme, qu’elle ne le  concurrence pas . En dépit des métaphores anthropomorphiques et de la  réification de l’IA, il s’agit simplement de scienc es et de technologies du                                                    1 Innorobo est une entreprise d’Impact Consulting sp écialisée dans le business développement par  l’innovation et un expert international des marchés  robotiques mondiaux, qui promeut une approche  humaine des technologies robotiques. Les actions d’ Innorobo s’expriment selon 3 axes : son  événement international, ses « Ressources » et sa c ommunauté. Tout au long de l’année, Innorobo  interagit avec un réseau de plus de 3 500 organisat ions robotiques dans le monde et 20 000 leaders et  décideurs, tous acteurs de l’innovation ouverte, qu i voient les technologies, produits et services  robotiques non seulement comme des opportunités de croissance et de compétitivité par l’innovation,  mais aussi comme une source de progrès pour l’Humai n. Innorobo est fermement convaincu que les  objectifs économiques peuvent servir et être aligné s avec une plus grande cause, celle d’une humanité  durable. Cf www.innorobo.com   2 Voir le site officiel du salon : http://www.ces.te ch/  3 L’émission « La Faute à l’algo » est écrite et réa lisée par Michel Blockelet et Jill-Jênn Vie en  collaboration avec la chaîne Nolife, qui en assure la production. Présentée par Frédéric Hosteing, ell e  retrace de façon pédagogique divers moments de nos vies où les algorithmes ont échappé à notre  contrôle, et où des bugs ont eu des répercussions p arfois insolites, parfois désastreuses sur notre  économie ou nos libertés. L’émission, dont la musiq ue est composée par un algorithme, se déroule en  2098, et son synopsis est le suivant : « 2098. Les Algorithmes ont pris le contrôle de notre   société. Mais comment en sommes-nous arrivés là ? V oici quelques vidéos du futur pour  prendre conscience du rôle grandissant des algorith mes dans nos vies, à l’origine de notre  déchéance  ». L’émission a été diffusée d’octobre 2015 à déce mbre 2016, à raison de 23 épisodes de 6  minutes, portant sur des sujets allant de la transp arence des algorithmes jusqu’aux monnaies  virtuelles, en passant par l’ubérisation, cf. http://fautealgo.fr   
TROISIÈME  PARTIE  :   LES PROPOSITIONS DE VOS RAPPORTEURS   - 219  -       traitement automatique de l’information, qui impliq uent davantage de  progrès que de risques, même si ces derniers doiven t être maîtrisés.  Il faut se saisir du partnership on AI  pour associer les GAFAMI voire  les « GAFAMITIS »1 à ce travail pédagogique. Là aussi, le coût du  financement pourrait être partagé avec les entrepri ses privées , qui se  donnent pour objectif d’informer et d’éduquer dans le domaine de ces  technologies. Pour votre rapporteur Claude de Ganay , il est déplorable que  les grand-messes d’Apple ne s’accompagnent jamais d e présentations  pédagogiques sur les technologies d’intelligence ar tificielle.    Proposition n° 14 : Former et sensibiliser le grand  public aux  conséquences pratiques de l’intelligence artificiel le et de la  robotisation  Il s’agit de former et de sensibiliser le grand pub lic aux  conséquences pratiques de l’intelligence artificiel le et de la robotisation.  Avec un effort de formation continue visant l’améli oration continuelle des  compétences, il s’agit de permettre aux travailleurs et au grand public  d’envisager de manière positive les transitions à v enir.   Selon votre rapporteur Claude de Ganay, il ne faut pas uniquement  s’adapter aux exigences de requalification et d’amé lioration des  compétences, mais redéfinir un projet de société pa rtagé en débattant des  conséquences pratiques de l’intelligence artificiel le et de la robotisation.  Là encore, le coût du financement pourrait être partagé  avec les  entreprises privées, qui se donnent pour objectif d ’informer et d’éduquer  dans le domaine de ces technologies.    Proposition n° 15 : Être vigilant sur les usages sp ectaculaires et  alarmistes du concept d’intelligence artificielle e t de  représentation des robots  Vos rapporteurs appellent à la vigilance sur les usages  spectaculaires et alarmistes du concept d’intellige nce artificielle et de  représentation des robots . Il s’agit d’éviter les dérapages, dans le respect  de  la liberté de création et de la liberté d’expressio n. Les pistes à explorer  pourraient s’inspirer de régimes législatifs ou déo ntologiques existants.  La vérification des publicités , en lien avec l’Autorité de régulation  professionnelle de la publicité (ARPP, ex-Bureau de  vérification de la                                                    1 Google, Apple, Facebook, Amazon, Microsoft, IBM, T witter, Intel et  Salesforce. Ces  entreprises américaines représentent la pointe de l a recherche en IA et de ses applications. 
- 220  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        publicité), serait par exemple un premier pas vers une plus grande maîtrise  de la communication médiatique sur le sujet. La référence à l’intelligence  artificielle des produits et des services  offerts sur le marché gagnerait à être  encadrée par un principe déontologique : toute entr eprise étant tentée  d’utiliser l’IA comme un élément de stratégie marke ting, les abus devraient  être évités par de bonnes pratiques ou une charte p rofessionnelle non  contraignante.  Votre rapporteur Claude de Ganay invite, en particu lier, à ne pas  limiter la représentation courante de l’intelligenc e artificielle aux robots qui  nous concurrenceraient ou nous menaceraient en tant  qu’êtres humains. Face  aux scénarios catastrophistes, il faut sensibiliser les écoles de journalisme  à  l’intérêt d’une présentation équilibrée et nuancée de l’intelligence artificielle,  et à leur responsabilité en la matière. La loi pour  une République numérique  est un pas utile dans la direction d’une société qu i perçoit la révolution  numérique de façon positive.   
CONCLUSION  - 221  -         CONCLUSION    Les propositions du présent rapport devront être remises en débat  au fur et à mesure des nouvelles découvertes scient ifiques , de leurs  transferts et de leurs usages. Vos rapporteurs tien nent à ce que le point  d’équilibre qu’ils ont cherché à atteindre dans le présent rapport puisse  évoluer, en fonction des évolutions du contexte rés ultant du jeu de ces  variables.  Vos rapporteurs appellent à la poursuite des travaux de l’OPECST  sur les enjeux de l’intelligence artificielle en 20 17 et 2018 . Ce suivi pourra  prendre la forme d’une veille générale des rapporte urs, d’une incitation à la  reprise de leurs propositions par le Gouvernement, ainsi que d’un  approfondissement de leur travail, le cas échéant e n ciblant leurs  investigations plus particulièrement sur certaines dimensions ou sur certains  secteurs. Le suivi par l’OPECST d’un sujet aussi important et  mouvant  apparaît indispensable.   Ils proposent, en outre, la poursuite du plan national pour  l’intelligence artificielle annoncé en janvier 2017, puis précisé de manière  plus détaillée à la fin du mois de mars 2017.  Ils forment le vœu que ce plan connaisse de francs succès, de  manière moins contrastée que le « Plan Calcul » lan cé en 1966 ou que le plan  « Informatique pour tous » lancé en 1985. Au cours de leurs investigations  sur l’intelligence artificielle, vos rapporteurs on t eu à l’esprit le rapport sur  l’informatisation de la société  publié en 1978 : il préconisait de manière  audacieuse d’associer les télécommunications et l’i nformatique grâce à la  connexion de terminaux informatiques permettant la visualisation et  l’échange, à travers les réseaux de télécommunicati on, de données stockées  dans des ordinateurs. Ce rapport, remis au Présiden t de la République  Valéry Giscard d’Estaing en décembre 1977 par Simon  Nora et Alain Minc, a  inventé le concept de télématique et proposait le l ancement du réseau  Minitel, exactement quinze ans après qu’un chercheu r du Massachusetts  Institute of Technology (MIT) eut rédigé les premie rs textes décrivant les  interactions sociales rendues possibles par l’inter médiaire d’un réseau  d’ordinateurs 1. La popularisation d’Internet dans les années 1990  a éclipsé la  télématique mais les inspirations des deux projets étaient proches. La  stratégie nationale pour l’intelligence artificiell e ne devra pas se tromper                                                    1 En juillet 1962, Joseph Carl Robnett Licklider ent amait en effet cette réflexion en vue de faciliter les  communications entre chercheurs de la Defense Advan ced Research Projects Agency (DARPA) du  ministère américain de la Défense. Quelques mois pl us tard, en octobre 1962, il devint le premier  chef du programme de recherche en informatique de l a DARPA. La rigueur scientifique exige de se  référer également aux travaux de Leonard Kleinrock,  lui aussi chercheur au MIT, et qui publia en  1961 le premier texte théorique sur la « commutation de paquets  ». 
- 222  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        de cible mais bien définir des objectifs réalistes garantissant des résultats  effectifs .  Ni quête vaine ni projet de remplacement de l’homme  par la  machine, l’ intelligence artificielle représente une chance à s aisir pour nos  sociétés et nos économies . La France doit relever ce défi .  Les progrès  en intelligence artificielle sont d’abord et avant  tout  bénéfiques . Ils comportent aussi des risques , qu’il serait malhonnête de  nier. Mais ces risques peuvent et doivent être identifiés, anticipés et  maîtrisés .  L’avènement d’une superintelligence  ne fait pas partie de ces  risques à court et moyen termes. À  long terme , la réalité de cette menace  n’est pas certaine . Quant à son imminence à court ou moyen terme ,  prophétisée par plusieurs figures médiatiques, elle  relève du pur fantasme   aux yeux de vos rapporteurs. Le présent rapport se veut une première  contribution à un travail indispensable d’identific ation, d’anticipation et de  maîtrise des risques réels. Ce travail de démystifi cation et d’objectivation  doit être collectif, interdisciplinaire et international .  Afin de prévenir de futures désillusions, il est né cessaire d’assurer  un suivi continu de ces technologies et de leurs usage s , en sachant que les  cycles d’espoirs et de déceptions qui jalonnent l’h istoire de l’intelligence  artificielle invitent à ne pas avoir d’attentes irr éalistes à l’égard de ces  technologies dans un avenir proche.  Les propositions du présent rapport veulent aller d ans ce sens.  Nous nous prononçons, en fin de compte, pour une intelligence  artificielle maîtrisée, utile et démystifiée : maîtrisée, parce que ces  technologies devront être les plus sûres, les plus transparentes et les plus  justes possibles ; utile parce qu’elles doivent, da ns le respect des valeurs  humanistes, profiter à tous au terme d’un large déb at public ; démystifiée,  enfin, parce que les difficultés d’acceptabilité so ciale de l’intelligence  artificielle résultent largement de visions catastr ophistes sans fondement.  Plutôt qu’une hypothétique confrontation dans le fu tur entre les  hommes et les machines, qui relève de la science-fi ction dystopique, nous  croyons au bel avenir de la complémentarité homme-m achine. La conviction  de vos rapporteurs est que nous allons bien plus vers une  intelligence  humaine augmentée que vers une intelligence artific ielle concurrençant  l’homme.  
SAISINE  DE  L’OFFICE  - 223  -           SAISINE DE L’OFFICE    Lettre de saisine de l’Office par la commission des  affaires économiques  du Sénat.     

RÉUNION  DE  L’OPECST  DU  14  MARS  2017  :  ADOPTION  DU  RAPPORT  - 225  -         RÉUNION DE L’OPECST DU 14 MARS 2017 :  ADOPTION DU RAPPORT    M. Jean-Yves Le Déaut, député, président de l’OPECS T . – Nous  aurons en cette fin de la quatorzième législature e xaminé cinq rapports au  cours des deux mois de février et mars. Le 22 févri er dernier, nous avons  adopté le rapport d’évaluation de la stratégie nati onale de recherche (SNR),  ainsi que son volet spécifique sur l’énergie. Aujou rd’hui même, au déjeuner  de l’Association nationale de la recherche et de la  technologie (ANRT), le  ministre de l’Enseignement supérieur et de la reche rche, devant le Premier  ministre, m’a remercié de la qualité de ce travail – le Comité opérationnel  (ComOp), comme diverses autres instances du ministè re, examinera notre  rapport – et m’a indiqué que nos analyses, pourtant  sévères, seraient une  aide dans les arbitrages du ministère, si bien que nos critiques feront avancer  les choses. Le 8 mars, nous avons examiné le rappor t d’évaluation du  quatrième plan national de gestion des matières et déchets radioactifs ; enfin,  notre collègue Catherine Procaccia et moi rédigeons  actuellement le rapport  sur les nouvelles biotechnologies.   Merci à nos deux rapporteurs pour leur travail d’un e grande qualité,  sur un sujet majeur. La convergence technologique –  nanotechnologies,  biologie, informatique, sciences cognitives (NBIC) – a des conséquences  fortes, avec la numérisation et la robotisation de la société. L’interface entre  l’homme et la machine est transformé, et de l’homme  soigné, réparé par la  machine, on envisage à présent l’homme augmenté ! C ela ne va pas sans  susciter des interrogations pour les droits de l’ho mme. Je rédige  actuellement un rapport pour l’Assemblée parlementa ire du Conseil de  l’Europe sur ce sujet. Il est possible d’espionner,  grâce à l’informatique et à la  puissance de calcul, tout individu et tout comporte ment de la vie en société.  Cela pose question…  Je souhaite rendre hommage à Jean-Claude Étienne, q ui fut député,  puis sénateur, et notre vice-président de l’OPECST.  Il s’est éteint samedi  dernier à l’âge de 75 ans. Il était venu encore l’a n dernier nous rendre visite,  à l’occasion du trentième anniversaire de notre Off ice. Il en fut un membre  éminent, en plus d’être professeur agrégé de rhumat ologie et professeur à  l’Université de Reims.   M. Bruno Sido, sénateur, premier vice-président de l’OPECST . – Je  m’associe à cet hommage, d’autant que je fus son vi ce-président au conseil  général de mon département et que je le connaissais  bien. J’ai eu plaisir à  travailler avec lui. Son parcours fut exceptionnel : d’abord agrégé de  mathématiques, il suivit ensuite les traces de son frère médecin pour pouvoir  - aimait-il à dire – acheter lui aussi une Peugeot 203... C’est ainsi qu’il devint  médecin. Humaniste, il voyait dans la politique, co mme dans la médecine, 
- 226  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        un moyen d’accompagner l’homme dans ses difficultés  et de trouver des  solutions.   J’ai eu l’honneur de lui succéder ici comme vice-pr ésident, comme il  me l’avait proposé. Ses obsèques auront lieu jeudi.    (Mmes et MM les parlementaires se lèvent et observe nt une minute de  silence.)  Mme Dominique Gillot, sénatrice, membre de l’OPECST ,  rapporteure . – Monsieur le président a mentionné nos critiques  sur la SNR.  Nous n’avons certes pas été complaisants sur sa mis e en œuvre. Il est vrai  aussi que le pilotage est difficile en pareille pha se de mutation, quand ce qui  a été décidé il y a trois ans est déjà à revoir… D’ où l’intérêt des focus que  l’OPECST publie.   Je m’associe bien sûr aux propos tenus sur Jean-Cla ude Étienne :  agrégés de sciences ou non, nous cherchons, comme p arlementaires, à  comprendre le monde et à éclairer nos décisions. Ce  qui m’amène  naturellement à la présentation de notre rapport.   L’OPECST a été saisi le 29 février 2016, par la com mission des  affaires économiques du Sénat, d’une étude sur l’in telligence artificielle (IA).  Nous sommes fiers d’en avoir été, M. Claude de Gana y et moi-même, les  rapporteurs. Un bouleversement pourrait transformer  profondément nos  sociétés : les technologies d’intelligence artifici elle. Elles pourront apporter  dans notre futur des progrès dans de nombreux domai nes, or elles ne font  pas l’objet d’une analyse sereine et objective. L’i ntelligence artificielle suscite  en effet enthousiasme, espoir et intérêt mais aussi  méfiance, incrédulité ou  oppositions.  L’irruption de l’intelligence artificielle au cœur du débat public  remonte à un peu plus de deux ans, après la diffusi on d’une lettre  d’avertissement sur les dangers potentiels de l’int elligence artificielle,  publiée en janvier 2015, qui a recueilli plus de 5 000 signatures en un an. Elle  a été lancée pour alerter l’opinion publique et ins ister sur l’urgence de  définir des règles éthiques, afin de cadrer la rech erche.  Aucun argument sérieux ne venait étayer cette premi ère mise en  garde quant au risque présumé de dérive malveillant e ! Pourtant, cette alerte  a contribué à renforcer les peurs et les angoisses face aux technologies  d’intelligence artificielle.  Notons que 2016 a fait figure d’année de l’intellig ence artificielle :  chaire d’informatique du Collège de France attribué e à Yann LeCun, victoire  du système d’intelligence artificielle AlphaGo créé  par DeepMind sur le  champion de Go, Lee Sedol, et ainsi de suite, tout au long de l’année. Les  initiatives en matière d’intelligence artificielle se sont multipliées à un  rythme effréné. Impossible d’en faire l’inventaire !  
RÉUNION  DE  L’OPECST  DU  14  MARS  2017  :  ADOPTION  DU  RAPPORT  - 227  -       Après l’irruption de l’intelligence artificielle da ns le débat public en  2015, 2016 et le premier trimestre 2017 ont été jal onnés de nombreux  rapports sur l’intelligence artificielle, émanant d u Parlement européen, de la  Maison blanche, de la Chambre des communes, de l’As sociation mondiale  des ingénieurs électriciens et électroniciens, de l a Commission de réflexion  sur l’éthique de la recherche en sciences et techno logies du numérique de  l’alliance du numérique (CERNA), d’Inria, de l’Inst itut Mines-Télécom, du  Club informatique des grandes entreprises française s (CIGREF), du Syndicat  des machines et technologies de production (SYMOP),  de l’Association  française pour l’intelligence artificielle (AFIA), de l’Association française  contre l’intelligence artificielle (AFCIA), etc. De s conférences d’envergure  nationale ou internationale ont aussi été organisée s sur le sujet par les  Nations unies, l’OCDE, la Fondation pour le futur d e la vie, le Medef, l’AFIA  entre autres. Enfin, l’initiative « France IA », la ncée par le Gouvernement en  janvier 2017, s’est accompagnée de l’annonce d’un p lan national pour  l’intelligence artificielle, dont nous attendons le  détail d’ici à la fin du mois.  Devant cet emballement, alors que les progrès se fo nt à une vitesse  exponentielle et reposent de plus en plus sur un fi nancement privé aux  moyens considérables, il est indispensable que la r éflexion soit conduite de  manière sereine et rationnelle, afin de mettre en a vant la réalité des  connaissances, les opportunités tout autant que les  risques, afin aussi de  rassurer le public et de démystifier les représenta tions biaisées. Comme le  disait Marie Curie, « dans la vie, rien n’est à craindre, tout est à comp rendre  ».  Les progrès en intelligence artificielle posent des  questions  auxquelles toute la société doit être sensibilisée : quels sont les opportunités  et les risques qui se dessinent ? La France et l’Eu rope sont-elles dans une  position satisfaisante dans la course mondiale ? Qu elles places respectives  pour la recherche publique et la recherche privée ?  Quelle coopération entre  celles-ci ? Quelles priorités pour les investisseme nts dans la recherche en  intelligence artificielle ? Quels principes éthique s, juridiques et politiques  doivent encadrer ces technologies ? La régulation d oit-elle se placer au  niveau national, européen ou international ?  Le débat public ne peut pas s’engager sereinement d ans l’ignorance  des technologies mises en œuvre, des méthodes scien tifiques et des principes  de l’intelligence artificielle. Nous avons donc ent endu faire l’état de la  recherche et des usages des technologies d’intellig ence artificielle, en  constante évolution. Nous nous sommes interrogés su r la façon d’assurer le  respect de règles éthiques dans la recherche en IA et au-delà, parce que  « science sans conscience n’est que ruine de l’âme », ainsi que l’affirmait Rabelais.   À la suite de l’adoption de l’étude de faisabilité le 28 juin 2016, nos  auditions et déplacements ont commencé en septembre  2016 ; tous deux  renouvelables, nous avons dû interrompre nos invest igations le mois  dernier. Soit une période utile d’environ six mois : nous avons donc dû  préciser un champ d’investigations, en ayant le sou ci d’optimiser la  plus-value relative du rapport, répondre à la saisi ne de la commission des 
- 228  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        affaires économiques du Sénat et faire mieux connaî tre l’intelligence  artificielle. Les enjeux sont tout autant scientifi ques et technologiques que  politiques, philosophiques, éthiques, juridiques, é ducatifs, médicaux,  militaires ou, encore, économiques. Nous avons dû c hoisir.  Les aspects scientifiques et technologiques constit uant le cœur de  métier de l’OPECST, c’est la recherche publique et privée en intelligence  artificielle qui a été retenue, tout comme les enje ux philosophiques, éthiques,  politiques, juridiques et éducatifs, car ils soulèv ent des questions essentielles  – y répondre devrait aider à dépasser les peurs et les inquiétudes pour  engager un débat public plus serein et mieux étayé.   Les enjeux financiers, économiques et industriels n ’ont pas été  écartés, mais sont mis au second plan car ils corre spondent moins  directement à la plus-value spécifique de l’OPECST.  Enfin, les usages de  l’intelligence artificielle pour la défense, les te chnologies militaires et la  médecine ont été écartés.  Nous avons mis l’accent sur les enjeux éthiques, ca r ils permettent  d’aborder les sujets de manière transversale. La mé thode de travail a été  fondée sur des auditions et des déplacements en Fra nce et à l’étranger,  présentés en annexe du rapport. Nous avons aussi eu  une journée de tables  rondes.   Le rapport contient une histoire et même une « préh istoire » assez  détaillée de l’intelligence artificielle et des tec hnologies rattachées.  L’intelligence artificielle a fêté l’année dernière  son soixantième anniversaire,  puisqu’elle a été inventée en tant que discipline e t en tant que concept en  1956 lors d’une école d’été à Dartmouth. La confére nce affirme que « chaque  aspect de l’apprentissage ou toute autre caractéris tique de l’intelligence peut être si  précisément décrit qu’une machine peut être conçue pour le simuler ». Le projet  n’est pas de construire une machine rivalisant avec  l’homme mais de simuler  telle ou telle tâche que l’on réserve à l’intellige nce humaine. Devant  l’emballement des prises de position médiatisées, i l n’est pas inutile de le  rappeler…   Le concept a fait l’objet d’un débat. Le choix du n om a sans doute été  motivé par une quête de visibilité de ce nouveau ch amp de recherche.  « Intelligence artificielle » a pu apparaître plus séduisant que « sciences et  technologies du traitement de l’information ». Mais  l’anthropomorphisme  essentialiste qui s’est exprimé dans ce choix n’a s ans doute pas contribué à  apaiser les peurs suscitées par le projet prométhée n de construction d’une  machine rivalisant avec l’intelligence humaine.  L’intelligence artificielle repose sur l’utilisatio n d’algorithmes, suites  finies et non ambiguës d’opérations ou d’instructio ns permettant, à l’aide  d’entrées, de résoudre un problème ou d’obtenir un résultat, ces sorties étant  réalisées selon un certain rendement. Les algorithm es peuvent, en effet,  servir à calculer, à gérer des informations, à anal yser des données, à  communiquer, à commander un robot, à fabriquer des biens ou, encore, à 
RÉUNION  DE  L’OPECST  DU  14  MARS  2017  :  ADOPTION  DU  RAPPORT  - 229  -       modéliser et simuler – comme le font certains outil s de météorologie, de  sismologie, d’océanographie, de planétologie, d’urb anisme…  L’informatique traite plutôt de questions résolues par des  algorithmes connus, alors que l’on applique le labe l d’« intelligence  artificielle » à des applications permettant plutôt  de résoudre des problèmes  moins évidents pour lesquels aucun algorithme satis faisant n’existe encore.  Le paradoxe résultant de cette définition est le su ivant : dès que le  problème a été résolu par une technologie dite d’in telligence artificielle,  l’activité correspondante n’est plus considérée com me une preuve  d’intelligence de la machine. Les cas connus de rés olutions de problèmes  d’algèbre ou de capacité à jouer à des jeux (des je ux d’échecs ou de Go par  exemple) illustrent ce phénomène. Nick Bostrom expl ique ainsi que  « beaucoup d’intelligence artificielle de pointe a filtré dans des applications  générales, sans y être officiellement rattachée car  dès que quelque chose devient  suffisamment utile et commun, on lui retire l’étiqu ette d’intelligence artificielle » .  Les progrès en matière d’intelligence artificielle étant tangibles  depuis les années cinquante, les frontières de l’in telligence artificielle sont  donc sans cesse repoussées et ce qui était appelé i ntelligence artificielle hier  n’est donc plus nécessairement considéré comme tel aujourd’hui.  Dès l’origine, l’intelligence artificielle est une étiquette. Ce label  recouvre en réalité des technologies diverses, qui traduisent la variété des  formes d’intelligence en général : elles vont de fo rmes explicites (systèmes  experts et raisonnements logiques et symboliques) à  des formes plus  implicites (réseaux bayésiens et surtout réseaux de  neurones et deep learning ).  Nous avons voulu retracer dans le rapport, de maniè re inédite, la richesse et  la diversité de ces technologies.  De manière caricaturale, on pourrait résumer les te chnologies  d’intelligence artificielle à un champ de recherche  où cohabitent deux grands  types d’approches : les approches symboliques et le s approches  connexionnistes.  Nous notons que « l’âge d’or de l’IA » qui court de  1956 au début  des années soixante-dix, est marqué par les approch es symboliques et les  raisonnements logiques, qui sont de nombreux types et sont tous décrits  dans le rapport. Cet âge d’or a été suivi d’un prem ier « hiver de l’intelligence  artificielle » dans la décennie soixante-dix : les financements sont revus à la  baisse, après divers rapports assez critiques, les prédictions exagérément  optimistes des débuts ne se réalisant pas et les te chniques ne fonctionnant  que dans des cas simples.   Ce constat témoigne du caractère cyclique des inves tissements en  intelligence artificielle selon une boucle « espoir s-déceptions ».  L’enthousiasme se renouvelle dans les années quatre -vingt autour des  systèmes experts, de leurs usages et de l’ingénieri e des connaissances. Suit  un nouvel hiver de l’intelligence artificielle dans  les années quatre-vingt-dix. 
- 230  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Pour autant, des découvertes scientifiques sont fai tes dans la  période. Après la renaissance de l’intérêt pour les  réseaux de neurones  artificiels avec de nouveaux modèles théoriques de calculs, les années  quatre-vingt-dix voient se développer la programmat ion génétique ainsi que  les systèmes multi-agents ou l’intelligence artific ielle distribuée.  De très nombreux autres domaines et technologies d’ intelligence  artificielle peuvent être ajoutés à ceux déjà menti onnés : les machines à  vecteur de support (SVM), l’apprentissage machine d ont l’apprentissage par  renforcement, la programmation par contraintes, les  raisonnements à partir  de cas, les logiques de description, les algorithme s génétiques, la recherche  dans les espaces d’états, la planification, les ont ologies, les logiques de  description… Tous ces exemples analysés de manière détaillée dans le  rapport visent à illustrer la variété et la richess e qui se cachent derrière le  label « intelligence artificielle » : les technolog ies d’intelligence artificielle  sont en fait quasi-innombrables ; surtout, les cher cheurs, tels des artisans,  hybrident des solutions inédites au cas par cas, en  fonction de leur tour de  main personnel.   Le tableau académique international des domaines de  l’intelligence  artificielle retient cinq domaines : traitement du langage naturel, vision,  apprentissage automatique, systèmes multi-agents, r obotique. Nous  renvoyons au rapport pour plus de détails. C’est un e histoire passionnante !   Faisons un focus sur l’apprentissage machine, au cœ ur des débats  actuels. La difficulté liée aux algorithmes classiq ues réside dans le fait que  l’ensemble des comportements possibles d’un système , compte tenu de  toutes les entrées possibles, devient rapidement tr op complexe à décrire.  Cette explosion combinatoire justifie de confier à des programmes le soin  d’ajuster un modèle adaptatif permettant de gérer c ette complexité et de  l’utiliser de manière opérationnelle en prenant en compte l’évolution de la  base des informations pour lesquelles les comportem ents en réponse ont été  validés. C’est ce que l’on appelle l’apprentissage automatique ou machine  learning , qui permet d’apprendre et d’améliorer le système d’analyse ou de  réponse. En ce sens, on peut dire que ces types par ticuliers d’algorithmes  apprennent.  Un apprentissage est dit « supervisé » lorsque le r éseau est forcé à  converger vers un état final précis, en même temps qu’un motif lui est  présenté. À l’inverse, lors d’un apprentissage « no n supervisé », le réseau est  laissé libre de converger vers n’importe quel état final lorsqu’un motif ou un  élément lui est présenté.  Entre ces deux extrêmes, l’apprentissage automatiqu e ou machine  learning  peut être semi-supervisé ou partiellement supervis é. C’est le cas  dans de nombreuses applications.   L’apprentissage automatique peut lui-même reposer s ur plusieurs  méthodes : l’apprentissage par renforcement, l’appr entissage par transfert,  ou, encore, l’apprentissage profond, qui est le plu s en pointe aujourd’hui. Le 
RÉUNION  DE  L’OPECST  DU  14  MARS  2017  :  ADOPTION  DU  RAPPORT  - 231  -       « deep learning  » rencontre un succès particulièrement remarquable  dans la  présente décennie. Pourtant cette méthode est ancie nne. Son essor doit  beaucoup à l’émergence récente de données massives ou big data , et à  l’accélération de la vitesse de calcul des processe urs, mais son histoire  remonte aux années quarante : les « réseaux de neur ones artificiels » sont  imaginés dès cette époque.  Un réseau de neurones artificiels est la modélisati on d’un ensemble  d’éléments interconnectés, chacun ayant des entrées  et des sorties  numériques. Le comportement d’un neurone artificiel  dépend de la somme  pondérée de ses valeurs d’entrée. Si cette somme dé passe un certain seuil, la  sortie prend une valeur positive, sinon elle reste nulle. Un réseau peut  comporter une couche d’entrée (les données), une de  sortie (les résultats), et  une ou plusieurs couches intermédiaires.  Cet apprentissage permet d’ajuster les poids synapt iques afin que les  correspondances entre les entrées et les sorties so ient les meilleures possible.  Il s’agit donc de combiner de nombreuses fonctions simples pour former des  fonctions complexes et d’apprendre les liens entre ces fonctions simples à  partir d’exemples étiquetés.  Il ne s’agit en aucun cas de réseaux de neurones de  synthèse, ce n’est  qu’une image, sans doute malheureuse car elle entre tient une forme de  confusion, en lien avec la notion d’intelligence ar tificielle. L’analogie avec le  fonctionnement du cerveau humain repose sur le fait  que les fonctions  simples rappellent le rôle joué par les neurones, t andis que les connexions  rappellent les synapses. Certains chercheurs préfèr ent ainsi parler de  neurones électroniques et de synapses électroniques .   Outre les réseaux multicouches, d’importantes décou vertes en  apprentissage profond remontent aux années quatre-v ingt, telles que la  rétropropagation du gradient. L’idée générale de la  rétropropagation  consiste à rétropropager l’erreur commise par un ne urone à ses synapses et  aux neurones qui y sont reliés. Il s’agit en effet de faire converger  l’algorithme de manière itérative vers une configur ation optimisée des poids  synaptiques.  En apprentissage profond, qui repose donc sur des r éseaux de  neurones profonds ( deep neural networks ), les réseaux de neurones artificiels  peuvent donc être à apprentissage supervisé ou non (ils sont le plus souvent  supervisés, comme dans le cas du Perceptron), avec ou sans  rétropropagation ( back propagation)  et on peut distinguer les technologies  selon la manière particulière d’organiser les neuro nes en réseau : les réseaux  peuvent être en couches, telles les architectures p rofondes ou multicouches  (plusieurs dizaines ou centaines de couches), dans lesquelles chaque neurone  d’une couche est connecté à tous les neurones de la  couche précédente et de  la couche suivante (c’est la structure la plus fréq uente) ; les réseaux peuvent  être totalement interconnectés (« réseaux de Hopfie ld » et « machines de  Boltzmann ») ; les réseaux peuvent permettre de pre ndre en compte le 
- 232  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        contexte tel une mémoire, avec le cas des réseaux n euronaux récurrents ;  enfin, les réseaux peuvent se chevaucher, un peu co mme dans le calcul  matriciel, à l’instar des réseaux neuronaux à convo lution.  Nous ne disposons d’aucune explication théorique de s raisons pour  lesquelles les réseaux de neurones fonctionnent aus si bien, c’est-à-dire  donnent, dans un certain nombre de domaines, d’exce llents résultats. La  technologie devance donc la science en la matière :  c’est à la recherche  d’éclaircir ce sujet.  Les technologies disponibles en intelligence artifi cielle peuvent se  combiner entre elles : les combinaisons et les hybr idations sont quasi  systématiques, le programme AlphaGo de Google-DeepM ind a ainsi appris à  jouer au jeu de Go par une méthode de deep learning  couplée à un  apprentissage par renforcement et à une optimisatio n selon la méthode  Monte-Carlo, qui repose sur le hasard.  De plus en plus, les outils d’intelligence artifici elle sont utilisés  conjointement. Par exemple, les systèmes experts so nt utilisés avec le  raisonnement par analogie, éventuellement dans le c adre de systèmes multiagents. De même, les SVM et l’apprentissage par ren forcement se combinent  très efficacement avec l’apprentissage profond des réseaux de neurones. Le  deep learning  peut aussi s’enrichir de logiques floues ou d’algo rithmes  génétiques.  Derrière le concept d’intelligence artificielle, ce  sont des technologies  très variées qui donnent lieu à des applications sp écifiques pour des tâches  toujours très spécialisées. Les applications sector ielles présentes ou futures  sont d’envergure considérable, que l’on pense par e xemple aux transports, à  l’aéronautique, à l’énergie, à l’environnement, à l ’agriculture, au commerce,  à la finance, à la défense, à la sécurité, à la séc urité informatique, à la  communication, à l’éducation, aux loisirs, à la san té, à la dépendance ou au  handicap.  Il s’agit d’autant de jalons d’applications sectori elles, dont le rapport  retrace les possibilités, nous y renvoyons donc. Le  potentiel de ces  technologies est immense et ouvre de manière transv ersale un espace  d’opportunités inédit : nos économies peuvent en bé néficier car les champs  d’application sont et seront de plus en plus nombre ux. Ces technologies sont  non seulement en évolution constante, mais leurs co mbinaisons ouvrent de  nouvelles perspectives.  Selon Stéphane Mallat, professeur à l’École normale  supérieure, il  s’agit d’« une rupture non seulement technologique, mais aussi  scientifique ».  Traditionnellement, les modèles sont construits par  les chercheurs euxmêmes à partir de données d’observation, en n’utili sant guère plus de  dix variables alors que « les algorithmes d’apprentissage sélectionnent seuls  le  modèle optimal pour décrire un phénomène à partir d ’une masse de données » et  avec une complexité inatteignable pour nos cerveaux  humains, puisque cela  peut représenter jusqu’à plusieurs millions de vari ables, contre une dizaine 
RÉUNION  DE  L’OPECST  DU  14  MARS  2017  :  ADOPTION  DU  RAPPORT  - 233  -       pour un laboratoire humain. Alors que le principe d e base de la méthode  scientifique réside dans le fait que les modèles ou  les théories sont  classiquement construits par les chercheurs à parti r des observations, le deep  learning  change la donne en assistant et amplifiant l’exper tise scientifique  dans la construction des modèles.  Denis Girou, directeur de l’Institut du développeme nt et des  ressources en informatique scientifique au CNRS est ime que « la science a pu  construire des modèles de plus en plus complexes gr âce à l’augmentation de la  puissance de calcul des outils informatiques, au po int que la simulation numérique  est désormais considérée comme le troisième pilier de la science après la théorie et  l’expérience ».   Selon Yann LeCun, le défi scientifique auquel les c hercheurs doivent  s’atteler c’est celui de l’apprentissage non superv isé. Dans sa leçon  inaugurale au Collège de France, il estime ainsi qu e « tant que le problème de  l’apprentissage non supervisé ne sera pas résolu, n ous n’aurons pas de machines  vraiment intelligentes. C’est une question fondamen tale scientifique et  mathématique, pas une question de technologie. Réso udre ce problème pourra  prendre de nombreuses années ou plusieurs décennies . À la vérité, nous n’en savons  rien  ».   L’intelligence artificielle, qui agit sur la base d e ce qu’elle sait, devra  donc relever le défi d’agir sans savoir, puisque co mme l’affirmait le  biologiste, psychologue et épistémologue Jean Piage t, « L’intelligence, ça n’est  pas ce que l’on sait, mais ce que l’on fait quand o n ne sait pas » . J’insiste, ce que  sait l’intelligence artificielle, c’est l’homme qui  le lui a appris.  M. Claude de Ganay, député, membre de l’OPECST, rap porteur . – Je vais vous parler quant à moi des caractéristique s et des enjeux de la  recherche en l’intelligence artificielle.   La recherche privée tient une place prépondérante, y compris sur le  plan de la recherche fondamentale. Cette recherche est dominée aujourd’hui  par les entreprises américaines et peut-être, demai n, par les entreprises  chinoises. Des enseignants-chercheurs parmi les plu s brillants ont été  recrutés par ces grandes entreprises : Yann LeCun ( Facebook), Andrew Ng  (Baidu, après Google), Geoffrey Hinton (Google), Fe i Fei Li (Google), Rob  Fergus (Facebook), Nando de Freitas (Google)...  Les entreprises américaines dominent donc, mais la recherche et les  entreprises chinoises montent en puissance. La Chin e a ainsi pris la tête des  publications en deep learning  depuis trois ans. L’entreprise Baidu a développé  le principal moteur de recherche chinois, site le p lus consulté en Chine et le  cinquième plus consulté au niveau mondial : indexan t près d’un milliard de  pages, l’entreprise dispose d’un flux de données pe rmettant d’envisager des  applications dans de nombreux domaines. Ses résulta ts algorithmiques sont  impressionnants, malgré son existence récente. Le s ystème de reconnaissance  d’image de Baidu a ainsi battu celui de Google depu is 2015. Le recrutement  du chercheur de Stanford, Andrew Ng, par Baidu en 2 014 en tant que 
- 234  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        responsable de l’intelligence artificielle alors qu ’il en était le responsable  chez Google est emblématique. De même, en 2017, Bai du débauche Qi Lu, au  poste de numéro deux, alors qu’il était auparavant vice-président chez  Microsoft et directeur des projets Bing, Skype et M icrosoft Office et  auparavant directeur de la recherche de Yahoo.  Le 13 e plan quinquennal chinois comprend une liste de qui nze  « grands projets » qui structurent les priorités sc ientifiques avec des  investissements de plusieurs milliards d’euros. Ce plan vise à dynamiser la  recherche chinoise en IA et à concurrencer les État s-Unis. Parmi ces projets,  ceux en lien avec l’IA représentent un montant de 1 00 milliards de yuans sur  trois ans.  Autre caractéristique, l’interdisciplinarité est in dispensable en  intelligence artificielle, alors que la discipline demeure éclatée en une  cinquantaine de sous-domaines de recherche, un tabl eau les décrit dans  notre rapport.   Par ailleurs, la recherche en intelligence artifici elle est soumise à une  contrainte d’acceptabilité sociale assez forte, not amment sous l’effet de  représentations catastrophistes, comme en témoignen t différents sondages  d’opinion, eux aussi rappelés dans le rapport.  Plusieurs interventions médiatiques et pétitions on t cherché en 2015  à interpeler l’opinion à propos des risques qui ser aient inhérents à  l’intelligence artificielle. L’existence d’une asso ciation française contre  l’intelligence artificielle (AFCIA) est révélatrice  d’un certain climat  d’angoisse puisque la France serait le seul pays où  une telle association  existerait. L’AFCIA juge « illégitime et dangereuse la recherche scientifique visant  à créer des organismes à intelligence artificielle supra-humaine » et considère que  le seul moyen « d’éviter un avenir funeste pour l’h umanité est d’obtenir  l’interdiction légale de la recherche en intelligen ce artificielle à l’échelle  mondiale ». Se définissant comme association de lob bying, elle vise à obtenir  cette interdiction auprès des pouvoirs publics. Jac ques Attali s’est, à la fin de  l’année 2016, prononcé pour un moratoire sur les te chnologies d’intelligence  artificielle, ce qui nous a beaucoup surpris.  Dernière caractéristique : la multiplication des in itiatives visant la  prise en compte de principes éthiques dans la reche rche et les usages de  l’intelligence artificielle. Cela vaut pour la rech erche publique, comme pour  la recherche privée, en Europe comme en Amérique.   Concernant la recherche française en IA, notre pays  dispose  d’importants atouts à faire valoir, même si la comm unauté française de  l’intelligence artificielle est encore insuffisamme nt organisée, connue et  visible. La reconnaissance internationale des trava ux des chercheurs français  doit beaucoup à des organismes comme Inria, le CNRS , le CEA, différentes  universités et grandes écoles, par exemple l’ENS et  Mines-Télécom, qui  produisent des travaux à visibilité internationale.  Nous décrivons dans le  détail ces structures et leurs laboratoires, à l’ex cellence reconnue.  
RÉUNION  DE L’OPECST  DU  14  MARS  2017  :  ADOPTION  DU  RAPPORT  - 235  -       La France dispose d’un réseau de chercheurs très co mpétents et d’un  tissu de start-up très dynamiques : 240 d’entre ell es sont spécialisées en  intelligence artificielle. Ce tissu de start-up, en couragé par l’initiative  French Tech, est très riche. Selon l’investisseur e n IA Paul Strachman, « La  France est l’un des écosystèmes les plus vibrants e n ce qui concerne l’intelligence  artificielle. Malheureusement, cela n’est pas très su en dehors de la France. Et  parfois même en dedans » .  Pour Mark Zuckerberg, le président de Facebook, « la France dispose  de l’une des communautés de chercheurs en intellige nce artificielle la plus forte du  monde ».  De même Mike Schr œpfer, le directeur technique de Facebook,  estimait en 2015 que Paris avait « la plus grande concentration de toute l’Europe  en matière d’intelligence artificielle ». Facebook a préféré Paris à Londres pour  ouvrir en juin 2015 un laboratoire de recherche con sacré à l’intelligence  artificielle ; ces recherches sont pilotées par Yan n LeCun au niveau mondial.   Le bon niveau de nos étudiants a également souvent été cité. Mais  nous nous inquiétons d’un phénomène de rachat de st art-up et de fuite des  cerveaux, voire de pillage de nos talents, lié aux conditions attractives  offertes à l’étranger. Lors de son audition, Stépha ne Mallat a fait valoir que  depuis plusieurs années la totalité des étudiants i ssus des masters spécialisés  de l’ENS quittaient la France aussitôt leur formati on achevée. Il faut  permettre à ces jeunes génies, qui sont autant de c hercheurs et  d’entrepreneurs en devenir, de disposer d’opportuni tés en France et  permettre aux start-up de se développer sans être r achetées par les géants  américains, chinois ou japonais dès qu’elles présen tent un profil viable.  Par ailleurs, nous relevons que la communauté franç aise de  l’intelligence artificielle se constitue surtout en  dehors des institutions, à  travers les meetups . Le principal d’entre eux, le Paris machine learning meetup   regroupe 5 205 membres. Quant à l’AFIA, comprenant environ 300 membres,  elle semble assez fermée sur elle-même. Elle aurait  tout intérêt à transcender  ses propres limites pour relever le défi d’une inte lligence artificielle française  ouverte, visible et conquérante.  Au total, on voit une sous-estimation des atouts co nsidérables de la  France, mais il existe un risque de « décrochage » par rapport à la recherche  internationale la plus avancée en intelligence arti ficielle.  Sur les impacts sociaux et économiques potentiels d e l’IA, et les  enjeux liés à ces questions, nous avons perçu les s ignes avant-coureurs de  l’évolution vers une économie globalisée de « plate formes ».   On parle des « GAFA », parfois des « GAFAMI », mais  il serait plus  juste de parler des « GAFAMITIS » (Google, Apple, F acebook, Amazon,  Microsoft, IBM, Twitter, Intel et Salesforce), des « NATU » (Netflix, Airbnb,  Tesla et Uber) et des « BATX » (l’expression désign ant les géants chinois du  numérique, Baidu, Alibaba, Tencent et Xiaomi). Ces exemples  emblématiques des bouleversements en cours sont les  prémices de la place  dominante et monopolistique occupée par quelques en treprises dans ce futur 
- 236  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        contexte général. Chacune de ces entreprises est en trée, selon un modèle  « the winner takes it all  » (« le vainqueur prend tout »), dans une course p our  acquérir une position de pointe dans les technologi es d’intelligence  artificielle afin de tirer profit de la position do minante qui en résultera :  l’accroissement significatif des investissements da ns la recherche en  intelligence artificielle pourrait bien conduire à une concentration  horizontale progressive des grandes entreprises, vo ire au monopole de ces  plateformes dominant une économie globalisée. On as siste à une montée en  puissance significative dans les acquisitions, un t ableau les décrivant figure  dans le rapport.  S’agissant des bouleversements annoncés dans le mar ché du travail,  les pronostics sont très contrastés, allant de 9 % à 47 % de disparition  d’emplois. Pour le Conseil d’orientation pour l’emp loi, moins de 10 % des  emplois existants français apparaissent menacés par  l’automatisation et la  numérisation et la moitié des emplois existants est  susceptible d’évoluer de  façon significative. Nous pensons, quant à nous, qu e les études  sous-estiment les évolutions de contenu des métiers  et les créations  d’emplois. Le solde global reste inconnu mais nous avons la conviction d’une  future coopération homme-machine heureuse.  L’éducation peut être le levier et le bénéficiaire des avancées en  intelligence artificielle. La relation émetteur-réc epteur est transformée et  modifie tant la pédagogie que les principes d’évalu ation. Les moyens de  prédire la réussite des élèves et d’optimiser les e nseignements seront  précisés par les systèmes d’intelligence artificiel le qui permettront la  différenciation des méthodes et des contenus enseig nés, la personnalisation  devant être adaptée à la diversité des élèves. Les nouvelles technologies ne  seront pas en compétition avec les enseignants, ell es leur seront  complémentaires. Les cours en ligne ouverts et mass ifs, ou MOOC ( massive  open online courses ), seront, de ce point de vue, des ressources utili sables pour  appliquer ces nouvelles méthodes pédagogiques innov antes et permettre aux  jeunes générations d’accéder dans des conditions op timales à la  connaissance.  Nous sommes convaincus de la possibilité imminente d’une  révolution bénéfique de notre cadre de vie et de l’ aide aux personnes. Des  changements profonds sont à venir dans la connaissa nce et dans le contrôle  de notre environnement et de la santé des populatio ns. Les smart grids ,  systèmes d’économie d’énergie par une consommation optimisée, et les smart  cities  (villes intelligentes) seront les expressions des bénéfices que nous  pouvons tirer de l’intelligence artificielle. Et ce la se traduira évidemment en  matière de transports, de sécurité, de santé, de dé pendance et de handicap.  Notre cadre de vie, la qualité de nos vies seront a méliorés par l’usage massif  de technologies d’intelligence artificielle.  J’ai été étonné par les propos d’un de mes concitoy ens, grand-maître  de la confrérie « bérouettes et traditions » de Cer noy-en-Berry, qui m’a  expliqué tous les bienfaits que les robots et les s ystèmes d’intelligence 
RÉUNION  DE  L’OPECST  DU  14  MARS  2017  :  ADOPTION  DU  RAPPORT  - 237  -       artificielle pourraient avoir pour la ruralité, en particulier pour les personnes  âgées, isolées ou dépendantes. Le cas des voitures autonomes a été évoqué  mais d’autres applications utiles vont émerger.  En matière de handicap, nous allons vers des progrè s majeurs, avec  les prothèses intelligentes, des exosquelettes robo tisés ou avec des systèmes  capables de voir des images et d’en décrire le cont enu pour des malvoyants.  Les agents conversationnels ou bots , les robots de service, les agents  d’assistance, d’aide à la mobilité vont progressive ment cohabiter avec nous.  Cela nécessitera une grande vigilance. L’éducation et la prévention sont  indispensables dans ce contexte de cohabitation cro issante. Et il convient  d’apporter une grande attention aux logiques d’empa thie et aux aspects  émotionnels.  J’en viens aux questions éthiques et juridiques pos ées par les progrès  en intelligence artificielle. Nous avons dressé le bilan des initiatives  existantes et présenté toutes les propositions qui sont mises sur la table et je  renvoie sur ce point à notre rapport. Il y a aussi les deux rapports issus des  institutions de l’Union européenne, Parlement europ éen et Comité  économique et social européen (CESE), les trois rap ports de la Maison  blanche, le rapport de la Chambre des communes du R oyaume-Uni, le  groupe de travail de la Royal Society , les initiatives chinoises et japonaises qui  accordent une place contrastée aux questions éthiqu es… La stratégie du  Gouvernement pour l’intelligence artificielle arriv e, hélas !, un peu tard pour  être intégrée dans les stratégies nationales destin ées au monde de la  recherche. Les éléments seront communiqués d’ici au  29 mars par le  Gouvernement, nous enrichirons notre rapport en con séquence.  Nous invitons à dépasser les « lois d’Asimov » pour  faire un point  sur le droit de la robotique. Reconnaître une perso nnalité juridique des  robots est une des pistes innovantes qui parcourent  le débat public sur la  robotique, mais nous ne sommes pas convaincus de l’ intérêt de reconnaître  une personnalité juridique aux robots, ce sujet n’e st pas une question qui  mérite d’être posée à ce stade.   S’agissant des autres aspects juridiques de l’intel ligence artificielle et  de la robotique, il sera loisible de conduire une r éflexion et de faire de la  prospective concernant la conception, la propriété intellectuelle et  l’autorisation de commercialisation. Pour différent s spécialistes, il n’y a pas  d’urgence à combler un vide juridique béant… car il  n’y a pas de vide  juridique béant. Les rapports parus sur le sujet, n otamment dans le monde  anglo-saxon, vont dans le même sens et ne recommand ent pas de mesures  législatives. La protection des données personnelle s et de la vie privée  méritera peut-être, en revanche, d’être renforcée d ans l’avenir, en s’adaptant  aux nouvelles innovations. À ce stade, le droit est  suffisamment protecteur.  S’agissant des voitures autonomes nous avons condui t des analyses  présentées dans le rapport, le laboratoire « Moral machine » du MIT que  nous avons visité travaille notamment sur les dilem mes éthiques. Les 
- 238  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        résultats provisoires des tests conduisent à identi fier différents facteurs de  choix : le nombre de tués (on préfère la solution q ui réduit le nombre de  morts), le fait de sacrifier en priorité des person nes qui transgressent les  règles (exemple du voleur), le fait de sacrifier en  priorité un animal contre un  humain, le fait de sacrifier en priorité une person ne plus âgée face à une  personne plus jeune et a fortiori  un enfant, le fait de sacrifier en priorité un  homme face à une femme… Ce dernier point, soit dit en passant, mériterait  un débat !   Sur les régimes de responsabilité, nous notons que quatre régimes  pourraient trouver à s’appliquer aux accidents caus és par des robots : le  régime de responsabilité du fait des produits défec tueux, celui de la  responsabilité du fait des animaux, celui de la res ponsabilité du fait d’autrui,  ou, encore, celui, traditionnel, de la responsabili té du fait des choses, mais  qui ne s’applique que de façon résiduelle par rappo rt au régime de  responsabilité du fait des produits défectueux.  On pourrait envisager de mettre en place une « chaî ne de  responsabilité », ou responsabilité en cascade. Dan s la mesure où trois ou  quatre acteurs sont en présence (le producteur de l a partie physique du  robot, le concepteur de l’intelligence artificielle , l’utilisateur et, s’il est  distinct de ce dernier, le propriétaire), il est po ssible d’imaginer que chacun  puisse supporter une part de responsabilité selon l es circonstances dans  lesquelles est survenu le dommage. Il sera en tout cas important d’identifier  des pistes d’avenir qui ne fassent pas courir le ri sque de déresponsabiliser  les acteurs du secteur, à commencer par les industr iels de la robotique.  En outre, il conviendrait de réfléchir à la possibi lité d’instituer des  systèmes d’assurance spécifiques. Mais la Fédératio n française de l’assurance  estime qu’il est encore trop tôt pour répondre à la  question.   Le rapport présente le cadre national de la réflexi on sur les enjeux  éthiques de l’intelligence artificielle, avec la CE RNA par exemple, qui joue  en la matière un rôle majeur, elle a d’ailleurs pro duit deux rapports, dont  nous rendons compte.   Comme déjà signalé dans le rapport, le positionneme nt de la  CERNA, qui étudie les questions éthiques du point d e vue de la recherche et  de la technologie, est à mettre en synergie avec ce lui récemment dévolu à la  CNIL en matière d’instruction des questions éthique s dans leur dimension  plus sociétale.  Aux termes de la loi pour une République numérique,  la CNIL,  notre autorité de contrôle en matière de protection  des données personnelles,  est en effet chargée de conduire une réflexion sur les questions d’éthique  liées au numérique et aux algorithmes. La CNIL a ch oisi d’y répondre par  l’organisation en 2017 d’un cycle de débats intitul é « Les algorithmes en  débat ». À l’automne 2017, la CNIL rendra publique la synthèse des échanges  afin d’établir une « cartographie de l’état du déba t public » et un « panorama  des défis et enjeux ». Inria, à travers le projet «  Transalgo », développe en 
RÉUNION  DE  L’OPECST  DU  14  MARS  2017  :  ADOPTION  DU  RAPPORT  - 239  -       2017 de manière utile une plateforme d’évaluation d e la transparence des  algorithmes, afin de répondre aux préoccupations d’ explicabilité des  algorithmes. L’articulation et la complémentarité e ntre le travail de la  CERNA, d’Inria et de la CNIL sont à rechercher.   Nous avons par ailleurs présenté dans le rapport le s expériences de  réflexion non gouvernementales sur les enjeux éthiq ues de l’intelligence  artificielle, aux États-Unis et au Royaume-Uni, qui  sont particulièrement  nombreuses et se sont multipliées de façon impressi onnante dans la période  récente.  L’une des principales initiatives est l’Institut du  futur de la vie ou  « Future of Life Institute  » (FLI), situé près du MIT et de Harvard, fondé en   mars 2014. Il est à l’origine, en janvier 2015, de la lettre d’avertissement sur  les dangers potentiels de l’intelligence artificiel le. Le FLI, que nous avons  visité en janvier 2017, se donne pour mission de « catalyser et soutenir la  recherche et les initiatives visant la sauvegarde d e la vie et proposant une vision  optimiste de l’avenir » . Il s’agit de « tirer le meilleur profit des nouvelles  technologies et de prévenir les risques potentiels pour l’humanité du développement  de l’intelligence artificielle ». Lors d’un colloque à New York sur les défis posé s  par l’émergence de l’intelligence artificielle, org anisé le 14 octobre 2015 par  l’Institut de recherche sur la criminalité et la ju stice des Nations unies  (Unicri), Max Tegmark était invité avec un autre ex pert à s’exprimer devant  quelque 130 délégués. Tous deux ont clairement soul igné les risques liés à  l’intelligence artificielle et appelé à la mise en place d’une réflexion solide  sur l’éthique de l’intelligence artificielle. Le se cond expert était Nick  Bostrom, le fondateur du Future of humanity Institute  (FHI) en 2005 à  l’Université d’Oxford ; il a également fondé, dès 2 004, un Institute for ethics  and emerging technologies  (IEET), proche du mouvement transhumaniste.  De manière similaire au Future of humanity Institute , ont été créées  plusieurs structures qui travaillent ensemble en ré seau, au sein de  l’Université de Cambridge : un Centre for the Study of Existential Risks  (CSER)  créé en 2012, un Leverhulme Centre for the Future of Intelligence  créé en 2016 et,  au sein de l’Université de Berkeley, un Machine Intelligence Research Institute  (MIRI).  Les anciens dirigeants de Paypal, Elon Musk (actuel lement patron de  Tesla et SpaceX) et Sam Altman ont fondé, le 11 déc embre 2015, la fondation  « Open AI  » dans le but de promouvoir l’intelligence artific ielle éthique et  ouverte. Nous avons visité cette fondation basée da ns la Silicon Valley et  rencontré ses responsables. Le dernier exemple, peu t-être le plus significatif,  est le « Partnership on AI  » formé en septembre 2016 par Google, Microsoft,  Facebook, IBM et Amazon afin de réfléchir de manièr e collective. Vos  rapporteurs se sont réjouis du fait qu’Apple a rejo int cette initiative le  26 janvier 2017.   Le rapport « L’intelligence artificielle et la vie en 2030 »  publié en  septembre 2016 par l’Université Stanford dévoile le s résultats de l’étude 
- 240  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        « One Hundred Year Study of Artificial Intelligence » , un projet universitaire  débuté en 2014 et initié par Eric Horvitz, chercheu r au laboratoire Microsoft  Research.   Dans la foulée et puisqu’il n’existait aucun guide commun de bonnes  pratiques dans le domaine de l’intelligence artific ielle, plusieurs spécialistes  de l’intelligence artificielle et de la robotique s e sont réunis lors de la  conférence « Beneficial AI 2017  » organisée par le Future of Life Institute . La  conférence s’est tenue à Asilomar, en Californie du  5 au 8 janvier 2017. Les  participants ont adopté vingt-trois principes bapti sés « Les vingt-trois  principes d’Asilomar », guide de référence pour l’e ncadrement éthique du  développement de l’intelligence artificielle.  Nous nous interrogeons sur les objectifs précis des  GAFAMI et  d’Elon Musk à travers ces nombreuses initiatives, q ui donnent une place trop  grande au risque de l’émergence d’une IA forte qui dominerait et pourrait  faire s’éteindre l’espèce humaine. La volonté de ce s nouveaux géants  pourrait-elle être de se dédouaner ou de créer un n uage de fumée pour ne  pas parler des vrais problèmes éthiques posés à cou rt terme par les  technologies d’intelligence artificielle, telles qu e l’usage des données ou le  respect de la vie privée ? Vos rapporteurs n’ont pa s tranché et laissent aux  auteurs de ces initiatives le bénéfice du doute.  Nous soulignons enfin l’important travail en cours sur les enjeux  éthiques au sein de l’association mondiale des ingé nieurs électriciens et  électroniciens ( Institute of Electrical and Electronics Engineers  ou IEEE), qui  regroupe plus de 400 000 membres. Son initiative mo ndiale pour « les  considérations éthiques dans l’intelligence artific ielle et les systèmes autonomes » a  pour objectif de proposer un cadre éthique pour les  systèmes d’intelligence  artificielle et des systèmes autonomes. Une premièr e version du document a  été publiée en décembre 2016, avec l’idée d’une dis cussion d’ici à l’été 2017  et la diffusion d’une deuxième version consolidée à  l’automne 2017.  Alors que toutes ces initiatives sur l’éthique sont  menées, nous  constatons une sensibilisation insuffisante du gran d public aux questions  posées par l’intelligence artificielle et les systè mes autonomes. Les  traitements médiatiques de ces questions restent le  plus souvent  sensationnalistes voire alarmistes, alors qu’une in formation objective serait  souhaitable. La vision déjà tronquée du grand publi c, sous l’effet des œuvres  de fiction, et en particulier du cinéma, n’est pas améliorée par la lecture de la  plupart des articles disponibles sur l’intelligence  artificielle dans nos  journaux et magazines.  Mme Dominique Gillot, sénatrice, rapporteure . – J’en viens aux  questions technologiques et scientifiques qui se po sent en matière  d’intelligence artificielle. Il y a d’abord les suj ets d’interrogation liés aux  algorithmes utilisés par les technologies d’AI. Le rapport contient des  développements sur les questions de sécurité et de robustesse et conclut sur  la nécessité de toujours pouvoir arrêter un système  d’intelligence artificielle, 
RÉUNION  DE  L’OPECST  DU  14  MARS  2017  :  ADOPTION  DU  RAPPORT  - 241  -       qu’il s’agisse d’un système informatique ou de son incarnation dans un  robot. En 2016, Google a également posé la question  du risque de perte de  contrôle et c’est dans ce sens que la firme dévelop pe l’idée d’un « bouton  rouge » permettant la désactivation des intelligenc es artificielles. La CERNA  a aussi cette recommandation. Des recherches complé mentaires sont  nécessaires car en IA cela peut être compliqué. Pou r paraphraser Raymond  Aron, qui utilisait l’expression de « Paix impossible, guerre improbable  » l’enjeu  est donc, face à une paix improbable avec les machi nes, de rendre la guerre  impossible.  Les biais sont l’un des plus gros problèmes posés p ar les algorithmes  d’apprentissage automatique, ou pour être plus rigo ureux, posés par les  données nécessaires aux algorithmes. La question co ncerne en effet plus les  données que les algorithmes eux-mêmes. Les impacts se font ressortir après  le traitement, mais les biais, eux, sont introduits  en amont dès le stade des  jeux de données. En effet, les algorithmes d’appren tissage automatique et en  particulier d’apprentissage profond vont reproduire , en particulier si les  données ne sont pas corrigées, toutes les discrimin ations connues dans nos  sociétés. Il convient donc d’être vigilant sur ces biais, souvent invisibles sans  recherches. Le second rapport de la CERNA traite no tamment de ce point.  L’initiative « Transalgo » d’Inria porte largement sur ce sujet.  La gouvernance des algorithmes et des prédictions q u’ils opèrent est  nécessaire. Le phénomène de « boîtes noires » des a lgorithmes de deep  learning  appelle un effort de recherche fondamentale pour a ccroître leur  transparence : nous ne disposons d’aucune explicati on théorique  satisfaisante des raisons pour lesquelles les algor ithmes de deep learning   donnent, dans un certain nombre de domaines, d’exce llents résultats. Ce  problème d’opacité reste entièrement à résoudre. On  parle ici de  phénomènes de « boîtes noires », mais elles n’ont r ien à voir avec les boîtes  noires des avions, qui sont des enregistreurs numér iques. Le défi à relever  est donc celui de l’objectif d’explicabilité des al gorithmes de deep learning .  L’initiative Transalgo d’Inria va dans ce sens, afi n de répondre aux  préoccupations exprimées. Une telle démarche va dan s la bonne direction  mais gagnerait à voir sa force de frappe être démul tipliée par la mobilisation  de plusieurs équipes de recherche. Inria ne peut re ster la seule structure en  France à conduire un tel projet.   Enfin, les algorithmes sélectionnent le contenu des  informations  dont nous disposons, ce qui pose la question des bu lles d’information dites  « bulles de filtres » ( filter bubbles)  : l’information ciblée tout comme la  publicité personnalisée ou la logique de constructi on des « fils d’actualité »  des réseaux sociaux, à l’instar de celui de Faceboo k, sont autant d’exemples  de réalités déjà manifestes d’usage des systèmes d’ intelligence artificielle,  qui sont de nature à changer notre rapport au monde , aux autres et à la  connaissance en orientant, voire en manipulant, not re perception de la  réalité. 
- 242  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Ce sujet mérite une vigilance accrue des pouvoirs p ublics. Pour  nous, l’enfermement, qu’il soit politique, idéologi que ou cognitif, doit être  combattu. La question va bien plus loin que les cri tiques formulées à  l’encontre des fausses informations ou fake news . Sur ce dernier point, la  recherche est assez bien avancée et, comme l’a indi qué Yann LeCun,  l’intelligence artificielle peut être utilisée pour  limiter les flux de fausses  informations. Des outils de vérification sont ainsi  mis en place par plusieurs  plateformes, à commencer par Facebook.  J’en viens aux interrogations liées à la singularit é, à la convergence  NBIC et au transhumanisme.   La rupture dite de la « singularité technologique »  appelée aussi  simplement singularité, est le nom que des écrivain s et des chercheurs en  intelligence artificielle ont donné au passage de l ’IA faible à l’IA forte. La  singularité représente un tournant hypothétique dan s l’évolution  technologique, dont l’intelligence artificielle ser ait le ressort principal. De  nombreuses œuvres de science-fiction ont décrit ce tournant, qui a été une  source d’inspiration très riche pour le cinéma. Les  films Terminator, Matrix   ou Transcendance sont des exemples de la singularité technologique q ui, audelà de la simple hostilité de l’intelligence artif icielle, est souvent au cœur de  l’intrigue des œuvres de science-fiction.  Les progrès en matière d’intelligence artificielle,  en particulier avec  le deep learning , sont parfois interprétés comme de « bons » augure s de la  « singularité » mais rien ne permet de garantir la capacité à créer au cours  des prochaines décennies une super-intelligence dép assant l’ensemble des  capacités humaines. Par exemple, en s’appuyant sur la loi de Moore, Ray  Kurzweil prédit dans un prophétisme dystopique que les machines rivalisant  avec l’intelligence humaine arriveraient d’ici à 20 20 et qu’elles la  dépasseraient en 2045.   Nous en sommes aujourd’hui encore très loin et il n ’est pas sûr que  nous y arrivions un jour. AlphaGo est peut-être le meilleur joueur de Go de  tous les temps, mais il n’est pas en mesure de parl er ou de distinguer un chat  d’un chien, ce dont serait capable n’importe quel j oueur de Go humain  débutant. Pour le sociologue Dominique Cardon, la t entation de l’IA forte est  anthropomorphiste. Certains sont en effet tentés de  plaquer sur les futures  intelligences artificielles des modes de raisonneme nt spécifiques à  l’intelligence humaine.  L’écrivain et entrepreneur futuriste Jerry Kaplan f ait valoir que « le  terme même d’intelligence artificielle est trompeur . Le fait que l’on puisse  programmer une machine pour jouer aux échecs, au Go , à Jeopardy ou pour conduire  une voiture ne signifie pas pour autant qu’elle soi t intelligente ! Aujourd’hui,  n’importe quelle calculette achetée en supermarché peut faire bien mieux que les plus  brillants cerveaux. Ces calculatrices sont-elles po ur autant intelligentes ? Je ne le  crois pas. Au fil du temps, nous découvrons de nouv elles techniques permettant de  résoudre des problèmes bien précis, à l’aide de l’a utomatisation. Cela ne signifie pas 
RÉUNION  DE  L’OPECST  DU  14  MARS  2017  :  ADOPTION  DU  RAPPORT  - 243  -       pour autant que nous soyons en train de construire une super-intelligence en passe  de prendre le pouvoir à notre place » .   Ces observations conduisent à relativiser les récen ts progrès de  l’intelligence artificielle et en particulier à con tester le fantasme de  l’intelligence artificielle forte car elles récusen t la pertinence d’une  comparaison avec l’intelligence humaine.  Ce catastrophisme oublie également le caractère irr éductible de  l’intelligence humaine au calcul. Il évacue la plac e des émotions, celle de  l’intelligence corporelle.  Non seulement l’avènement d’une super intelligence à long terme  n’est pas certaine mais la menace à court terme rel ève du pur fantasme. Il  s’agit de fantasmes sur la capacité des algorithmes  à devenir conscients,  autrement dit dotés de capacités réflexives les ren dant capables de se  représenter à eux-mêmes.   Pour nous, nier la possibilité d’une IA forte n’a p as de sens, toutefois  se prononcer sur son imminence ou sur le calendrier  précis de son  avènement semble tout aussi peu raisonnable, car c’ est indémontrable  scientifiquement.   Yann LeCun estime que « beaucoup des scénarios catastrophes (en  intelligence artificielle) sont élaborés par des pe rsonnes qui ne connaissent pas les  limites actuelles du domaine. Or les spécialistes d isent qu’ils sont loin de la réalité » .  De même Rob High, directeur technique du projet Wat son d’IBM,  estime qu’il est « trop tôt pour employer le terme intelligence arti ficielle, mieux  vaut parler d’outils capables d’élargir les capacit és cognitives humaines ».    Greg Corrado, directeur de la recherche en intellig ence artificielle  chez Google, nous a expliqué qu’il était plus juste  de parler d’intelligence  augmentée plutôt que d’intelligence artificielle. P our Jean-Claude Heudin,  l’intelligence artificielle ne remplace pas l’homme  mais augmente son  intelligence, en formant une sorte de « troisième h émisphère ».  Cette idée de complémentarité homme-machine et d’in telligence  augmentée nous a convaincus. François Taddéi expliq ue lui que « les  intelligences humaine et artificielle coévoluent. M ais ce sont encore les combinaisons  homme-machine qui sont les plus performantes : on l e voit aux échecs, où une équipe  homme-machine est capable de battre et l’homme et l a machine » . L’homme et la  machine, les hommes-centaures, sont toujours plus f orts que toutes les  machines.  Pour ce qui concerne la « convergence NBIC », conve rgences entre  les nanotechnologies, les biotechnologies, les tech nologies de l’information et  les sciences cognitives, thème issu du rapport de M M. Roco et Bainbridge à  la National Science Foundation  (États-Unis) en 2003, ce projet ambitieux de  fertilisation croisée n’a pas produit de grands rés ultats à ce stade mais les  progrès en intelligence artificielle, en génomique,  en sciences cognitives et en  neurosciences reposent la question aujourd’hui. 
- 244  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Notre président Jean-Yves Le Déaut conduit un trava il à ce sujet  pour l’Assemblée parlementaire du Conseil de l’Euro pe, en tant que  rapporteur pour la science et la technologie, afin que cette convergence soit  respectueuse des droits humains.  Nous avons vu que la prospective en intelligence ar tificielle aboutit  souvent à des scénarios de dystopie technologique m ais ce pessimisme n’est  pas partagé par l’ensemble des futurologues puisque , pour certains, les  progrès de l’intelligence artificielle permettront de protéger et prolonger la  vie humaine, mais aussi d’offrir une opportunité hi storique pour concrétiser  l’utopie transhumaniste. Le transhumanisme est un m ouvement  philosophique qui s’apparente à une religion, prédi sant et travaillant à une  amélioration de la nature de l’homme grâce aux scie nces et aux évolutions  technologiques. Pour les transhumanistes, l’homme «  augmenté » pourrait  devenir immortel. Inutile de préciser que je n’y cr ois pas du tout…  Ce projet transhumaniste de mort de la mort et de f in de la  souffrance n’emporte pas l’adhésion de vos rapporte urs. Il s’apparente à une  négation de la nature humaine. Pour nous, l’intelli gence artificielle n’est pas  un acte de foi et ne doit pas le devenir.  Selon Raja Chatila, « derrière ces discours, nous avons des vues de l’e sprit  qui n’ont rien d’opérationnelles, elles sont en réa lité des idéologies, qu’on cherche à  imposer pour gommer les différences entre l’humain et le non-humain » .  Il s’agit de chimères qui empêchent de se poser les  vraies questions  pertinentes. Il est essentiel de savoir anticiper l es problèmes potentiels posés  par l’intelligence artificielle. À court terme, ces  problèmes risquent d’être  ignorés et pris à tort pour de la science-fiction. Il convient en effet de  distinguer les craintes issues de certaines fiction s cinématographiques des  problèmes réels qui risquent de survenir plus ou mo ins rapidement.  J’en arrive donc à nos quinze recommandations. Nous  sommes pour  une IA maîtrisée, objet de nos cinq premières propo sitions. Tout d’abord,  proposition n° 1 : se garder d’une contrainte jurid ique trop forte sur la  recherche en intelligence artificielle, qui – en to ut état de cause – gagnerait à  être, autant que possible, européenne, voire intern ationale, plutôt que  nationale.  Proposition n° 2 : favoriser des algorithmes et des  robots sûrs,  transparents et justes et prévoir une charte de l’i ntelligence artificielle et de  la robotique. Il faut rechercher la transparence de s algorithmes contre les  boîtes noires, les biais et les discriminations. Il  convient de prévoir aussi des  mécanismes de traçabilité, de type enregistreurs nu mériques des avions. Une  charte de l’intelligence artificielle et de la robo tique la plus internationale  possible, européenne à défaut, proclamerait ces obj ectifs éthiques et viserait  à codifier les bonnes pratiques. Elle proposerait d es règles sur les  interactions homme-machine, en posant des limites e n matière d’imitation  du vivant, pour les robots androïdes comme pour les  agents  conversationnels.  
RÉUNION  DE  L’OPECST  DU  14  MARS  2017  :  ADOPTION  DU  RAPPORT  - 245  -       Proposition n° 3 : former à l’éthique de l’intellig ence artificielle et de  la robotique dans les cursus spécialisés de l’ensei gnement supérieur qui  traitent de l’intelligence artificielle et de la ro botique.   Proposition n° 4 : confier à un institut national d e l’éthique de  l’intelligence artificielle et de la robotique un r ôle d’animation du débat  public sur les principes éthiques qui doivent encad rer ces technologies. Audelà de la nouvelle mission de la CNIL, cet institu t national de l’éthique de  l’intelligence artificielle et de la robotique pour ra s’intéresser aux  problématiques d’explicabilité vues plus haut. La d émarche ne doit pas être  réservée à une seule structure de recherche, plusie urs équipes doivent y  travailler parallèlement et un institut national po urrait impulser les projets,  coordonner les recherches, animer le débat public e t faire des propositions  aux autorités. Les pouvoirs publics ne devront pas être les seuls à le financer.  Les entreprises privées, qui se donnent pour object if d’informer et d’éduquer  sur ces technologies et d’accroître leurs effets bé néfiques pour la société (à  l’image du « partnership on AI  »), pourraient participer au financement de  l’institut.   Proposition n° 5 : accompagner les transformations du marché du  travail sous l’effet de l’intelligence artificielle  et de la robotique en menant  une politique de formation continue ambitieuse visa nt à s’adapter aux  exigences de requalification et d’amélioration des compétences. Je propose à  titre personnel de réfléchir à un nouveau mode de f inancement de notre  système de protection sociale, qui serait un complé ment des cotisations  existantes et qui pourrait consister en un prélèvem ent de cotisations sociales  sur les agents autonomes, dans la mesure où ils rem placent des emplois  occupés par des êtres  humains. C’est le rapport de Mady Delvaux qui m’a  inspiré cette idée, d’autant que la proposition de taxer les robots a fait son  apparition dans la campagne pour les élections prés identielles. Je précise que  mon co-rapporteur est contre toute taxe spécifique sur l’intelligence  artificielle et les robots.   M. Claude de Ganay, rapporteur . – C’est vrai ! Un mécanisme de ce  type constituerait selon moi un mauvais signal et d écouragerait la recherche,  l’innovation et l’activité économique. La TVA et l’ impôt sur les sociétés (IS)  s’appliquent déjà à ces activités – et quand ils ne  le font pas il faudra y  veiller. C’est notre seul point de désaccord – le m ot est trop fort – et nous  présentons quinze propositions totalement communes.  Dominique Gillot ne  propose pas une telle taxe, elle l’évoque comme suj et de réflexion.   Je poursuis avec notre deuxième série de propositio ns, pour une  intelligence artificielle utile, au service de l’ho mme et des valeurs  humanistes.   Notre proposition n° 6 : redonner une place essenti elle à la recherche  fondamentale et revaloriser la place de la recherch e publique par rapport à la  recherche privée tout en encourageant leur coopérat ion. Seule la recherche  fondamentale peut répondre aux problèmes d’explicab ilité des algorithmes 
- 246  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        et de biais dans les données. Nous en avons besoin.  Des enjeux de maîtrise  des technologies aux enjeux de financement de la re cherche publique, tout se  tient.  La recherche fondamentale pose par ailleurs la ques tion du mode de  financement des projets : il faut favoriser la rech erche transversale et ne  surtout pas reproduire l’hyperspécialisation entre sous-domaines de  l’intelligence artificielle. Il est en cela nécessa ire de mobiliser les équipes de  chercheurs autour de grands projets nationaux struc turants. Des projets de  grandes bases de données labellisées, nécessaires à  l’apprentissage machine,  pourraient être lancés, par exemple autour de la la ngue française, du marché  de l’emploi ou des données de santé, sous condition  d’anonymisation.   Proposition n° 7 : encourager la constitution de ch ampions  européens en intelligence artificielle et en roboti que, un peu sur le modèle  d’Airbus. Sans verser dans le nationalisme industri el, il faut réfléchir aux  protections qui pourraient être instituées. En effe t, les laboratoires français  sont pillés de leurs chercheurs par les multination ales nord-américaines et  chinoises.  Proposition n° 8 : orienter les investissements dan s la recherche en  intelligence artificielle vers l’utilité sociale de s découvertes, à savoir des  applications à impact sociétal bénéfique comme le b ien-être, la santé, la  dépendance, le handicap, les infrastructures civile s, la gestion des  catastrophes…  Proposition n° 9 : élargir l’offre de cursus et de modules de  formation aux technologies d’intelligence artificie lle dans l’enseignement  supérieur français et créer dans notre pays au moin s un pôle d’excellence  international et interdisciplinaire en intelligence  artificielle et en robotique. Il  peut s’agir d’un pôle, de deux ou de trois, en s’ap puyant sur l’excellence  d’Inria, du LAS de Toulouse, de l’ENS, de l’Institu t Mines-Télécom… Mais à  défaut d’une création pure et simple, il sera urgen t d’encourager la  coordination et d’accroître la cohérence des instit uts, des centres et des  équipes de recherches.  Proposition n° 10 : structurer et mobiliser la comm unauté française  de la recherche en intelligence artificielle en org anisant davantage de  concours primés à dimension nationale, destinés à d ynamiser la recherche en  intelligence artificielle. « France IA » est une ét ape importante dans la  mobilisation de la communauté française de la reche rche en intelligence  artificielle. Il faut continuer et la structurer en core davantage, par exemple à  travers l’organisation de concours. Le traitement d e grandes bases de  données nationales labellisées pourrait être l’obje t d’un de ces concours. Un  travail avec l’Agence nationale de recherche (ANR) peut être envisagé pour  définir une offre française de grands concours prim és en IA.  Proposition n° 11 : assurer une meilleure prise en compte de la  diversité et de la place des femmes dans la recherc he en intelligence 
RÉUNION  DE  L’OPECST  DU  14  MARS  2017  :  ADOPTION  DU  RAPPORT  - 247  -       artificielle La place des femmes et la question des  minorités dans la  recherche en intelligence artificielle sont des déf is qu’il convient de relever.   J’en arrive à la troisième et dernière série de pro positions, pour une  intelligence artificielle démystifiée.   Proposition n° 12 : organiser des formations à l’in formatique dans  l’enseignement primaire et secondaire faisant une p lace à l’intelligence  artificielle et à la robotique. Il s’agit d’aller u n peu plus loin que l’offre  actuelle.  Proposition n° 13 : former et sensibiliser le grand  public à  l’intelligence artificielle par des campagnes de co mmunication,  l’organisation d’un salon international de l’intell igence artificielle et de la  robotique et la diffusion d’émissions de télévision  pédagogiques  Un salon international de l’intelligence artificiel le et de la robotique  est à organiser en France, en s’inspirant de VivaTech et de l’initiative Innorobo  portée par Catherine Simon, organisatrice du Salon français de la robotique.  Ce salon pourrait être le pendant européen du CES ( Consumer electronics  Show ) organisé à Las Vegas et sans équivalent en Europe .  Les réseaux sociaux ou la télévision pourraient êtr e des supports  pour des émissions de partage de la connaissance. L es émissions de  télévision du type « la faute à l’algo », diffusées  par la chaîne No Life, et  certains épisodes de « data-gueule », diffusés par la chaîne France 4, sont des  exemples intéressants.  Il faut se saisir du « partnership on AI »  pour associer les entreprises à  ce travail pédagogique. Là aussi, le coût du financ ement pourrait être  partagé avec les entreprises privées, qui se donnen t pour objectif d’informer  et d’éduquer sur ces technologies. Je trouve déplor able que les grand-messes  d’Apple ne s’accompagnent jamais de présentations p édagogiques sur les  technologies d’intelligence artificielle.  Proposition n° 14 : former et sensibiliser le grand  public aux  conséquences pratiques de l’intelligence artificiel le et de la robotisation, il  s’agit, en complément de l’offre de formation conti nue visant l’amélioration  continuelle des compétences, de permettre aux trava illeurs et au grand  public d’envisager de manière positive les transiti ons à venir en termes de  conséquences pratiques de l’intelligence artificiel le et de la robotisation. Là  encore, le coût du financement pourrait être partag é avec les entreprises  privées, qui se donnent pour objectif d’informer et  d’éduquer sur ces  technologies.  Quinzième et dernière proposition : être vigilant s ur les usages  spectaculaires et alarmistes du concept d’intellige nce artificielle et de  représentations des robots. Il s’agit d’éviter les dérapages, mais dans le  respect de la liberté de création et de la liberté d’expression. La vérification  des publicités serait un premier pas vers une plus grande maîtrise de la 
- 248  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        communication médiatique sur le sujet. En réaction aux scénarios  catastrophistes, il faut sensibiliser les écoles de  journalisme.   Pour conclure, j’indique que nos propositions devro nt être remises  en débat à proportion des découvertes scientifiques , de leurs transferts et de  leurs usages. Le point d’équilibre issu du rapport doit pouvoir évoluer, en  fonction du contexte qui résultera du jeu de ces va riables.  Nous faisons une proposition à nos collègues, en pl us de nos  15 propositions, une sorte de proposition zéro comm e aurait dit Asimov : la  poursuite des travaux de l’OPECST sur les enjeux de  l’intelligence artificielle  en 2017 et 2018. Outre une veille générale des rapp orteurs sur le sujet, il  s’agira d’un suivi de la reprise de leurs propositi ons par le Gouvernement  ainsi que d’un approfondissement de leur travail. U n suivi du sujet par  l’OPECST apparaît indispensable.  Nous appelons par ailleurs à la poursuite du plan n ational pour  l’intelligence artificielle, annoncé en janvier 201 7 par le Gouvernement et qui  sera précisé de manière plus détaillé à la fin du m ois.  Ni quête vaine ni projet de remplacement de l’homme  par la  machine, l’intelligence artificielle représente une  chance à saisir pour nos  sociétés et nos économies. La France doit relever c e défi. Les progrès en  intelligence artificielle sont d’abord et avant tou t bénéfiques. Ils comportent  aussi des risques, il serait malhonnête de le nier.  Mais ces risques peuvent et  doivent être identifiés, anticipés et maîtrisés.  L’avènement d’une super-intelligence ne fait pas pa rtie de ces  risques à court et moyen termes. Et, à long terme, la réalité de cette menace  n’est pas certaine, quant à son imminence à court o u moyen terme,  prophétisée par plusieurs figures médiatiques, elle  relève du pur fantasme.  Le présent rapport se veut une première contributio n au travail  indispensable d’identification, d’anticipation et d e maîtrise des risques réels,  travail de démystification et d’objectivation qui d oit être collectif,  interdisciplinaire et international.   Mme Dominique Gillot, sénatrice, rapporteure . – J’insiste à mon  tour sur la nécessité pour notre Office de poursuiv re ces travaux en 2017 et  2018. La meilleure façon de prévenir tout risque de  futures désillusions est  de suivre en continu l’évolution de ces technologie s et de leurs usages,  sachant que les cycles d’espoirs et de déceptions q ui jalonnent l’histoire de  l’intelligence artificielle invitent à ne pas faire  preuve d’attentes irréalistes.  Les propositions du rapport vont dans ce sens. Nous  nous prononçons pour  une intelligence artificielle maîtrisée, utile et d émystifiée. Maîtrisée, parce  que ces technologies devront être les plus sûres, l es plus transparentes et les  plus justes possible. Utile, parce qu’elles doivent , dans le respect des valeurs  humanistes, profiter à tous au terme d’un large déb at public. Et démystifiée,  parce que les difficultés d’acceptabilité sociale d e l’intelligence artificielle  résultent largement de visions catastrophistes erro nées, propagées par des  ignorants. 
RÉUNION  DE  L’OPECST  DU  14  MARS  2017  :  ADOPTION  DU  RAPPORT  - 249  -       Plutôt qu’une hypothétique future confrontation ent re les hommes et  les machines, qui relève de la science-fiction dyst opique, nous croyons au bel  avenir de la complémentarité entre l’homme et la ma chine. C’est, au final,  bien plus vers une intelligence humaine augmentée q ue vers une intelligence  artificielle concurrençant l’homme que nous allons.   M. Jean-Yves Le Déaut, président.  – Merci pour cet excellent  rapport. Avant de poursuivre les travaux durant les  années à venir, il faudra  d’abord être réélus, et que l’Office soit saisi, pu isqu’il ne peut s’autosaisir…  Mme Dominique Gillot, rapporteure . – Bien entendu ! C’est un vœu  que j’exprimais là.   M. Bruno Sido, premier vice-président . – Ce rapport est  passionnant. Je suis d’accord avec toutes vos propo sitions, sauf la cinquième,  qui n’a selon moi pas sa place ici, notre office ne  traitant pas de questions  sociales ou fiscales. Il faudra renvoyer ces points  aux commissions  permanentes concernées. Quant à la proposition n°11 , je ne sache pas qu’en  science, le sexisme ou le refus de la diversité aie nt cours : les Américains par  exemple, prennent les meilleurs dans le monde entie r, et s’en vantent !   M. Claude de Ganay, rapporteur . – Il y a plus d’hommes que de  femmes dans la recherche et dans les formations sci entifiques : il faut que les  femmes rejoignent ces rangs. Comment favoriser ce m ouvement, je ne sais  pas…  Mme Dominique Gillot, rapporteure . – Il y a deux aspects  distincts : assurer la mixité dans ce secteur de la  recherche, mais aussi veiller  à ce que les algorithmes ne comportent pas de biais  liés au genre, à l’origine  ethnique ou socioculturelle.   M. Jean-Yves Le Déaut, président.  – Vous posez la question de la  taxation des robots : mais où se situe la frontière  entre ceux-ci et les  machines ? La disparition du travail humain est une  question pertinente,  dont je ferais mention plutôt dans le corps du rapp ort, non dans les  propositions, en demandant aux commissions compéten tes de s’y pencher.   Quant au choix entre une taxation, des cotisations sociales, ou un  autre moyen…  Mme Dominique Gillot, rapporteure . – Ce n’est pas une  proposition mais une orientation pour la réflexion à venir. Si les tâches à  faible valeur ajoutée doivent dans l’avenir être de  plus en plus fréquemment  assurées par des robots ou « agents autonomes », il  y a lieu de s’interroger  sur l’équilibre des comptes sociaux.   Mme Catherine Procaccia, sénateur, membre de l’OPEC ST . – Mais  ne croyez-vous pas que le système de protection soc iale va évoluer ? La  question doit être posée dans le cadre d’une réflex ion globale sur les comptes  sociaux.  
- 250  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Mme Dominique Gillot, rapporteure . – Le rapport de Mady  Delvaux a suscité un débat autour d’une taxe robots , dans les médias et les  milieux politiques.   Mme Catherine Procaccia . – M. Hamon lui-même…  Mme Dominique Gillot, rapporteure . – Oui, mon candidat la  propose, mais je ne pense pas que ce soit une bonne  solution : ce serait un  signal négatif pour la recherche en IA. On en parle  néanmoins, et France  Inter y a consacré une émission entière, dans On n’arrête pas l’éco .   Mme Fabienne Keller, sénateur, membre de l’OPECST . – Je salue  votre énorme travail. La Chine est un continent, le  nombre de chercheurs en  IA y est considérable. Or vos propositions concerne nt surtout la France.  Toutes devraient être, à tout le moins, à périmètre  européen. Ma chère  professeure de physique disait : « Le nombre de femmes dans les sciences est le  produit de facteurs cumulatifs, tous inférieurs à u n ».  Effectivement, il y a moins  de filles que de garçons au baccalauréat scientifiq ue, encore moins dans les  écoles supérieures, et finalement, elles ne sont qu e 24 % dans la recherche  sur la robotique… On l’observe, plus qu’on ne l’exp lique. Une discrimination  positive serait sans doute utile pour cesser de nou s priver de l’intelligence  féminine… qui n’a rien d’artificiel !    Pourriez-vous revenir sur la différence entre les r obots et l’IA ?  Celle-ci est essentiellement multidisciplinaire. L’ Institut de recherche contre  les cancers de l’appareil digestif (IRCAD) à Strasb ourg travaille sur des  robots chirurgicaux capables de reproduire les meil leures opérations  effectuées dans le monde par les praticiens, en tra itant les données  numérisées des corps mous. On parle à présent d’imp rimer en 3D la prothèse  nécessaire, calquée sur l’organe du patient, produi te en temps réel.   Les applications touchent des domaines très divers,  et pour les  transports, dans le cadre de l’intermodalité, elles  sont très intéressantes : des  propositions de transport pourraient être faites su r le téléphone portable de  l’usager, calculées en fonction des heures, des hab itudes, des besoins,  notamment pour les personnes handicapées.   Comment avez-vous pu traiter de la pluridisciplinar ité de  l’intelligence artificielle, quand les déclinaisons  sont si vastes ?   Mme Delphine Bataille, sénatrice, membre de l’OPECS T . – Au  regard des investissements publics dans les pays do nt vous avez pu étudier  l’effort en IA, quelle est la place de la France, n otamment pour les  infrastructures de calcul intensif ? De nombreux ac teurs industriels sont-ils  équipés ? Les réglementations sont-elles adaptées ?  Les contraintes  juridiques ne sont-elles pas excessives ? Existe-t- il parmi les pays que vous  avez étudiés un modèle d’organisation ? Au Japon, t rois ministères, sciences  et technologies, économie et industrie, intérieur e t communications, ont  chacun un centre de recherche, mais les trois se co ordonnent. Avec quel pays 
RÉUNION  DE  L’OPECST  DU  14  MARS  2017  :  ADOPTION  DU  RAPPORT  - 251  -       la France entretient-elle la collaboration scientif ique la plus aboutie ? Le plan  national pour l’intelligence artificielle s’inspire -t-il d’exemples à l’étranger ?   M. Jean-Yves Le Déaut, président . – Nos rapporteurs disent que ces  sujets sont internationaux, mais leurs propositions  sont plutôt nationales  alors qu’elles gagneraient à être davantage europée nnes. Il existe une  convention internationale en biologie, dite d’Ovied o, dont l’article 13 interdit  par exemple la modification du génome se répercutan t aux descendants. Le  moment n’est-il pas venu d’élargir ce type d’accord , en désignant une  organisation pour le proposer ? Ne faudrait-il pas demander à l’UNESCO de  se charger d’une supervision internationale ? Nous avons par ailleurs un  organisme européen avec lequel l’Office travaille, le European parlementary  technology assessment (EPTA) , qui inclut le Conseil de l’Europe, et, parmi les  pays observateurs, la Russie, les États-Unis le Jap on : il faudrait sans doute  organiser des auditions publiques et contradictoire s des experts de tous les  pays participants, ce serait une manière de commenc er ce travail  international.   La proposition n° 8, qui encourage la recherche au service de la  société, me paraît très bonne, elle s’inscrit bien dans la démarche de la  stratégie nationale de recherche (SNR). Il faudrait  faire un lien avec la SNR  que nous venons d’évaluer et préciser que la questi on du handicap et de  l’atténuation de la frontière entre l’homme et la m achine pourrait être  traitée…  Plutôt que la thèse du robot autonome, je défends l a thèse que toute  machine issue de l’intelligence artificielle, tout robot, doit rester sous le  contrôle de l’homme.   Mme Dominique Gillot, rapporteure . – Oui ! C’est le « bouton  rouge ». Cela figure dans notre rapport. Et c’est l ’esprit de la proposition  n° 2, même si nous n’entrons pas dans le détail.   M. Jean-Yves Le Déaut, président . – Il serait bon de le redire dans la  conclusion.   Mme Dominique Gillot, rapporteure . – D’accord.   Le niveau pertinent est effectivement celui de l’Eu rope. Mais la  France a des atouts majeurs à mettre en avant, son école mathématique,  l’écosystème du développement et de la science, la prise de conscience des  organismes de recherche… En trois ans, la prise de conscience s’est diffusée.  La pluridisciplinarité, plus que la transdisciplina rité, se développe.   L’intelligence artificielle fait intervenir une jux taposition de sciences,  qui se conjuguent, s’hybrident et se renforcent mut uellement, grâce à la  puissance de calcul, les données de masse, la recon naissance d’image de plus  en plus rapide. Le robot - d’observation, ou d’acco mpagnement médical,  etc. – est une machine physique qui comprend une in telligence artificielle  embarquée.  
- 252  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        Mme Fabienne Keller . – Il peut y avoir de l’intelligence artificielle  sans robot.   Mme Dominique Gillot, rapporteure . – Dans un téléphone portable,  par exemple. Quant aux robots, ils vont des plus si mples jusqu’à  l’humanoïde.   Le président Jean-Yves Le Déaut suggère que l’Union  européenne  prenne en charge des missions en matière d’intellig ence artificielle : mais si  les services à Bruxelles sont performants sur les c hartes éthiques, ils le sont  beaucoup moins sur les aspects scientifiques. Lorsq ue nous avons rencontré  les équipes de la Commission européenne, nous avons  été fort déçus : nous  étions mieux informés qu’elles ! Le CESE, qui prépa re un rapport sur l’IA,  fait le même constat. Les experts de la Commission européenne ne se sont  pas emparés du sujet. Ils sont en retard par rappor t aux scientifiques et aux  politiques de notre pays. L’actualité est pourtant intense dans ce domaine !   M. Claude de Ganay, rapporteur . – Pour répondre au président, je  dirai que les propositions n° 1, 2 et 7 ont bien la  vocation européenne qu’il  réclame. Ce rapport était très attendu par la commu nauté scientifique : il  dresse en effet un état des lieux sur le plan scien tifique. Mady Delvaux a  rédigé un rapport de compromis, non de propositions , tenant compte du  cadre européen dans lequel elle intervenait. L’OPEC ST a plus de liberté, il  peut être plus objectif. Je confirme ce qu’a dit Mm e Gillot, nos interlocuteurs  à Bruxelles ignoraient jusqu’à l’existence des rapp orts de la Maison blanche  et de la Chambre des communes britannique. Ce trava il a été passionnant,  nous l’avons abordé sans a priori .   M. Jean-Yves Le Déaut, président . – Je mets aux voix le rapport  sous réserve des corrections rédactionnelles que no us avons mentionnées.    Le rapport est adopté à l’unanimité.  
LISTE  DES  PERSONNES  RENCONTRÉES  - 253  -         LISTE DES PERSONNES RENCONTRÉES    I.  PERSONNES RENCONTRÉES PAR LES RAPPORTEURS EN VUE DE   L’ÉTUDE DE FAISABILITÉ  - M. Raja Chatila, Directeur de recherche au Centre  national de la  recherche scientifique (CNRS), directeur de l’Insti tut des systèmes  intelligents et de robotique (ISIR)  - M. Max Dauchet, Professeur émérite à l’Université  de Lille, Président  de la Commission de Réflexion sur l’Éthique de la R echerche en sciences et  technologies du Numérique (CERNA) d’Allistene 1  - Mme Laurence Devillers, Professeure à l’Universit é Paris IV Sorbonne  et directrice de recherche au Laboratoire d’informa tique pour la mécanique  et les sciences de l’ingénieur (Limsi de Saclay)  - M. Alain Fuchs, Président du Centre national de l a recherche  scientifique (CNRS), Professeur de chimie  - M. Jean-Gabriel Ganascia, Professeur à l’Universi té Paris VI Pierre-etMarie-Curie (UPMC), directeur de l’équipe ACASA (Ag ents Cognitifs et  Apprentissage Symbolique Automatique) au laboratoir e d’informatique de  Paris VI (LIP6), membre du COMETS (Comité d’éthique  du CNRS)  - M. Michael Matlosz, Président-directeur général d e l’Agence nationale  de la recherche (ANR), Professeur de génie des proc édés  - M. Antoine Petit, Président-directeur général de l’Institut national de  recherche en informatique et en automatique (Inria) , Professeur à l’Ecole  normale supérieure de Cachan  - M. François Taddei, Directeur du Centre de recher ches  interdisciplinaires (CRI) de l’Université Paris V R ené Descartes), directeur de  recherche à l’Inserm, ingénieur en chef des Ponts, des Eaux et des Forêts                                                          1 Alliance des sciences et technologies du numérique , cette association regroupe les organismes de  recherche concernés par les différents domaines du numérique, notamment par l’intelligence  artificielle, comme la CDEFI, le CEA, le CNRS, la C PU, Inria et l’Institut Mines-Télécom. Ses  membres associés sont l’INRA, l’INRETS et l’ONERA. 
- 254  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE          II.  PERSONNES RENCONTRÉES PAR LES RAPPORTEURS EN VUE DE   L’ÉTABLISSEMENT DU RAPPORT  A.  EN FRANCE  1.  À Paris (lors de différentes auditions de rapporteu rs)  Mardi 25 octobre 2016  - M. Patrick Albert, entrepreneur (créateur et ancien  directeur de ILOG),  chercheur ;  - M. Stéphane Mallat professeur à l’École normale sup érieure (ENS),  chercheur en mathématiques appliquées.    Mardi 8 novembre 2016  - M. Marc Mézard, directeur de l’École normale supéri eure (ENS) ;  - M. Marc Pouzet directeur des études du département d’informatique de  l’École normale supérieure (ENS) ;  - M. Yves Caseau, directeur du numérique pour le grou pe AXA, membre  de l’Académie des technologies et responsable de sa  commission TIC ;  - M. Grégory Bonnet, GREYC – Normandie Université) ;  - M. Alain Berger, société Ardans ;  - M. Olivier Boissier, Institut Henry Fayol – ARMINES  ;   - M. Pierre-Antoine Chardel, Institut Mines-Télécom ;   - M. Jean-Gabriel Ganascia, LIP6 – Université Paris 6  ;  - Mme Catherine Tessier, ONERA ;  - M. Nicolas Cointe et Mme Fiona Berreby, chercheurs en thèse de  doctorat sur l’éthique de l’intelligence artificiel le ;   - M. Raja Chatila, directeur de recherche au Centre n ational de la  recherche scientifique (CNRS), directeur de l’Insti tut des systèmes  intelligents et de robotique (ISIR) ;  - M. Benoît Girard, directeur de recherche CNRS à l’I SIR ;  - M. Nathanaël Jarrassé, chercheur CNRS à l’ISIR. 
LISTE  DES  PERSONNES  RENCONTRÉES  - 255  -       Mercredi 9 novembre 2016  - M. Pierre-Yves Oudeyer, directeur de recherche Inri a, directeur du  laboratoire Flowers , président du comité technique des systèmes  cognitifs et développementaux de l’IEEE ( Institute of Electrical and  Electronics Engineers , en français Institut des ingénieurs électriciens et  électroniciens) ;   - Me Alain Bensoussan, avocat, président de l’associatio n pour les droits  des robots et M e Marie Soulez, avocate spécialisée sur les TIC dans son  cabinet ;  - M. Laurent Alexandre, président de DNA Vision, fond ateur de  Doctissimo, auteur, chirurgien-urologue et ancien é lève de l’ENA ;  - M. Henri Verdier, entrepreneur et spécialiste du nu mérique français,  directeur interministériel du numérique et du systè me d’information,  adjoint à la secrétaire générale pour la modernisat ion de l’action  publique, administrateur général des données (AGD),  membre du  conseil scientifique de l’Institut Mines-Télécom; d u comité de  prospective de l’ARCEP, du comité de prospective de  la CNIL et de la  Commission innovation 2030, ex-président de Cap Dig ital, pôle de  compétitivité et de transformation numérique.    Jeudi 24 novembre 2016  - M. Max Dauchet, Professeur émérite à l’Université d e Lille, Président  de la Commission de Réflexion sur l’Éthique de la R echerche en  sciences et technologies du Numérique (CERNA) d’All istene ;   - M. Cédric Sauviat, ingénieur, président de l’associ ation française contre  l’intelligence artificielle (AFCIA) et Marie David,  ingénieur, éditrice,  membre du bureau de l’association ;   - Mme Flora Fischer, chargée de programme de recherch e au Cigref,  réseau de grandes entreprises, pilote du groupe de travail sur  l’intelligence artificielle en entreprise.    Lundi 28 novembre 2016  - M. Nicolas Cointe et Mme Fiona Berreby, chercheurs en thèse de  doctorat sur l’éthique de l’intelligence artificiel le ;   - M. Claude Berrou professeur à Télécom Bretagne (Ins titut MinesTélécom), chercheur en électronique et informatique , membre de 
- 256  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        l’Académie des sciences, surtout connu pour ses tra vaux sur les turbocodes, très utilisés en téléphonie mobile 1 ;   - Mme Laurence Devillers 2 professeure d’informatique à l’Université  Paris-Sorbonne et directrice de recherche du CNRS a u Laboratoire  d’informatique pour la mécanique et les sciences de  l’ingénieur  (Limsi de Saclay).    Mercredi 30 novembre 2016  - M. François Taddéi directeur du Centre de recherche s  interdisciplinaires (CRI). (Inserm, Université Pari s Descartes),  biologiste ;   - M. Igor Carron, entrepreneur, organisateur du princ ipal « meet-up »  en  intelligence artificielle en France intitulé « Paris Machine Learning  » ;   - M. Jill-Jen Vie, chercheur en thèse de doctorat à l ’École normale  supérieure Paris-Saclay sur le deep learning 3 ;  - M. Dominique Sciamma directeur de l’école de Design  « Strate » à  Sèvres ;   - M. David Sadek directeur de la recherche de l’Insti tut Mines-Télécom,  spécialiste en intelligence artificielle ;  - Mme Verity Harding, directrice des affaires publiqu es de Deep Mind   (Londres, Royaume-Uni) ;                                                     1 Au début des années 1990, il met au point avec Alai n Glavieux la première classe quasi-optimale de cod es  correcteurs utilisant des codes convolutifs, les tu rbocodes, aujourd’hui très utilisés pour la télépho nie mobile  3G et 4G (plusieurs brevets sur ces systèmes, dont le premier -brevet européen- remonte à 1991 et est détenu en  copropriété par France Télécom, TDF et l’Institut T élécom). Les deux chercheurs, avec d’autres collègu es de  Télécom Bretagne, étendent également le principe tu rbo à des fonctions autres que le codage correcteur   d’erreurs, en particulier l’égalisation. Claude Ber rou fait partie des dix scientifiques français les plus cités dans  les sciences de l’information. En 2003, il reçoit l e Grand Prix France Télécom de l’Académie des scien ces et la  médaille Hamming, puis en 2005 le prix Marconi.  2 Experte en traitement du langage et du signal et e n apprentissage machine, ses recherches portent  principalement sur l’« affective computing », le tr aitement automatique de la langue parlée, la détect ion des  émotions « real-life », l’interaction homme-machine  et la robotique affective et interactive. Laurence  Devillers  anime l’équipe de recherche Dimensions affectives e t sociales dans les interactions parlées. Elle a  participé/participe à de nombreux projets notamment  sur les interactions affectives et sociales humain -robot  (ANR Tecsan Armen, FUI Romeo, BPI Romeo2, Rex EU Hu maine, EU Chistera Joker). Elle travaille sur les  émotions mais aussi sur l’humour et l’empathie dans  les systèmes de dialogue homme-machine. Ses travau x  peuvent être utilisés pour des applications avec de s robots, des objets connectés, des jeux sérieux, d es centres  d’appels pour différents domaines comme par exemple  la santé, le bien-être et la sécurité. Elle anime le pôle coévolution humain-machine de l’Institut de la sociét é numérique (ISN – Paris Saclay), où elle mène des travaux  en collaboration avec des chercheurs en droit et en  sociologie sur mémoire du robot et responsabilité,  et sur la  réflexivité langagière. Elle est également membre d u conseil d’administration de AAAC (emotion-researc h.net),  membre de IEEE, ACL, ISCA and AFCP. Elle est aussi impliquée dans l’association Eurobotics dans les  groupes de travail sur « Natural Interaction with S ocial Robot» et « Socially intelligent robots». Ell e a  participé à la rédaction du premier rapport de la C erna sur l’éthique du chercheur en robotique dont e lle est  membre.  3 Thèse d’informatique à l’ENS et à l’Université Par is-Saclay en 2016. En 2017, il est en postdoctorat au  laboratoire RIKEN à Tokyo, sous la direction de His ashi Kashima. Consultant du ministère de l’Éducatio n  nationale sur le projet PIX de certification des co mpétences numériques, coproducteur de l’émission « La Faute  à l’algo » pour la chaîne Nolife avec Michel Blocke let, sur le rôle grandissant de l’algorithmie dans nos vies. 
LISTE  DES  PERSONNES  RENCONTRÉES  - 257  -       - M. Paul Strachman représentant d’ISAI aux États-Uni s 1, diplômé de  l’École Nationale des Ponts & Chaussées d’un Master  de la London  School of Economics and Political Science  (LSE) et d’un MBA  de Stanford  University.  2.  À Paris (lors de l’audition publique du 19 janvier 2017)  - Mme Axelle Lemaire, secrétaire d’État chargée du nu mérique et de  l’innovation ;  - M. Jean-Gabriel Ganascia, professeur à l’Université  Pierre-et-MarieCurie Paris VI ;  - M. Gérard Sabah, directeur de recherche honoraire a u CNRS ; membre  de l’Académie des technologies ;  - M. Yves Demazeau, président de l’Association frança ise pour  l’intelligence artificielle (AFIA) ;  - M. Bertrand Braunschweig, directeur du Centre Inria  de Saclay ;  - M. David Sadek, directeur de la recherche de l’Inst itut Mines-Télécom ;  - M. Jean-Daniel Kant, maître de conférences à l’Univ ersité Pierre-etMarie-Curie-Paris VI ;  - M. Benoît Le Blanc, directeur-adjoint de l’École na tionale supérieure de  cognitique ;  - M. Jean-Marc Merriaux, directeur général de Canopé ;  - M. François Taddéi, directeur du Centre de recherch e  interdisciplinaire ;  - M. Olivier Esper, responsable des affaires publique s de Google France ;  - Mme Delphine Reyre, directrice Europe des affaires publiques de  Facebook ;  - M. Laurent Massoulié, directeur du Centre de recher che commun InriaMicrosoft ;  - M. Dominique Cardon, professeur de sociologie à l’I nstitut d’études  politiques de Paris/Medialab ;  - M. Gilles Babinet, entrepreneur, digital champion  auprès de la  Commission européenne ;  - M. Henri Verdier, directeur interministériel du num érique ;                                                    1 Basé à New York, il est chargé d’aider les sociétés  du portefeuille d’ISAI à s’établir et se financer  aux Etats-Unis et est également en charge des inves tissements d’ISAI outre-Atlantique. Après un  passage chez PAI Partners puis chez Bain & Company,  il passe 5 ans chez Equinox (centres de fitness  haut de gamme, leader aux Etats-Unis) en tant que D irecteur de la Stratégie. Il combine des activités  de « business angel », de conseil et d’interim-mana gement au sein de l’écosystème américain des  start-up. 
- 258  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        - Mme Marie-Claire Carrère-Gée, présidente du Conseil  d’orientation  pour l’emploi ;  - M. Laurent Alexandre, entrepreneur (DNA vision) ;  - M. Jean-Christophe Baillie, entrepreneur (Novaquark ) ;  - M. Jean-Claude Heudin, directeur de l’Institut de l ’Internet et du  multimédia ;  - M. Gilles Dowek, directeur de recherche Inria et pr ofesseur attaché à  l’ENS de Paris-Saclay ;  - Mme Laurence Devillers, professeur à l’Université P arisSorbonne/LIMSI-CNRS ;  - M. Serge Abiteboul, directeur de recherche Inria ;  - M. Jean Ponce, professeur et directeur du départeme nt d’informatique  de l’École normale supérieure (ENS) ;  - M. Serge Tisseron, psychiatre, chercheur associé à l’Université Paris  Diderot-Paris VII ;  - Mme Isabelle Falque-Pierrotin, présidente de la CNI L ;  - M. Rand Hindi, membre du Conseil national du numéri que, pilote du  groupe de travail sur l’intelligence artificielle ;   - M. Olivier Guilhem, directeur juridique chez SoftBa nk Robotics (exAldebaran) ;  - Me Alain Bensoussan, avocat, président de l’Associa tion du droit des  robots.  3.  À Arcachon (lors d’un colloque du 26 au 30 septembr e 2016, organisé  avec le soutien du CNRS, d'Inria, du CEA et de l'In stitut Mines-Télécom)  - M. Max Dauchet, Professeur émérite, Université de L ille, Président de la  CERNA ;  - Mme Danièle Bourcier, Directeur de recherche émérit e, CNRS, CERSA ;  - Mme Claire Lobet-Maris, Professeur, Université de N amur ;  - M. Alexei Grinbaum, Chercheur, CEA-Saclay, SPEC/LAR SIM ;  - M. Raja Chatila, directeur de recherche CNRS, ISIR ;  - Mme Nozha Boujemaa, directeur de recherche Inria, c onseillère du  président pour le big data  ;  - M. Jean-Gabriel Ganascia, Professeur UPMC et Instit ut de France,  président du COMETS ;  - M. Guillaume Piolle, enseigant chercheur à Supelec Rennes ; 
LISTE  DES  PERSONNES  RENCONTRÉES  - 259  -       - M. François Pellegrini, Professeur et vice-présiden t délégué au  numérique de l’Université de Bordeux, membre de la CNIL ;  - Mme Nicole Dewandre, conseillère pour les questions  sociétales,  directeur général de CONNECT ;  - M. Claude Kirchner, directeur de recherche Inria, p résident du  COERLE ;  - Mme Sophie Vulliet-Tavernier, directrice des relati ons avec les publics  et la recherche, CNIL ;  - M. Nathanaël Jarrassé, chercheur CNRS à l’ISIR ;  - Mme Laurence Devillers, professeur à l’Université d e Paris IV, LIMSI ;  - Mme Christine Balagué, titulaire de la Chaire Résea ux Sociaux de  Télécom École de Management.  4.  À Paris lors d’un colloque sur l’intelligence artif icielle à l’Assemblée  nationale le 14 février 2017 organisé par la Commis sion supérieure du  numérique et des postes (CSNP)  - M. Jean-Yves Le Drian ministre de la Défense ;  - M. Jean Launay, député du Lot et président de la Co mmission  supérieure du numérique et des postes (CSNP) ;  - M. Jean-Yves Le Déaut, député de Meurthe-et-Moselle , président de  l’Office parlementaire d’évaluation des choix scien tifiques et  technologiques (OPECST) ;  - M. Lionel Tardy, député de la Haute-Savoie  - M. Laurent Celerier, capitaine de vaisseau, command ement  opérationnel de cyberdéfense (COMCYBER) ;  - Mme Nozha Boujemaa, directrice de recherche Inria ;   - M. Jean Ponce, professeur et directeur du départeme nt d’informatique  de l’École normale supérieure (ENS) ;  - M. Benjamin Werner, directeur du département d’info rmatique de  l’Ecole Polytechnique  - M. Pierre-Jean Benghozi, professeur à l’Ecole polyt echnique ;  - M. Yves-Alexandre de Montjoye, professeur à l’Imper ial College  London  - M. Nikos Paragios, professeur à CentraleSupélec ;  - M. Yann Bonnet, Secrétaire Général – Conseil Nation al du Numérique ;  - Mme Flora Fischer, chargée de recherche au CIGREF ;   - M. Alain Clot, président de FinTech France ; 
- 260  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        - M. Éric Leandri, président de QWANT ;  - M. David Bessis, président de Tinyclues ;  - M. Konstantinos Voyiatzis, vice-président de CIO – Edenred ;  - Mme Vanessa Heydorff, directrice régionale France, Espagne et  Portugal de Booking.com ;   - M. Olivier Cuny, secrétaire général du groupe ATOS ;  - M. Jean-Philippe Desbiolles, vice-président de Wats on, IBM France ;  - M. Hervé Juvin, président de l’observatoire d’Eurog roup Consulting ;  - M. Antoine Bordes, chercheur chez Facebook ;  - M. Jean Rognetta, directeur de la rédaction de Forb es France ;  - M. Éric Sadin, Ecrivain et Philosophe.  B.  À L’ÉTRANGER  1.  À Genève, Suisse, les 21 et 22 septembre 2016  - Professeur Daniel Schneider, Faculté de psychologie  et des sciences de  l’éducation de l’Université de Genève, spécialiste de l’e-education ;   - Professeur Alexandros Kalousis, professeur à la Hau te école spécialisée  de Suisse occidentale et Université de Genève, spéc ialiste de machine  learning  ;   - Professeur Dominique Boullier, directeur du SocialMedia Lab  de l’École  polytechnique fédérale de Lausanne (EPFL), spéciali ste de sociologie  du numérique ;   - Professeur Didier Grandjean, enseigne la psychologi e cognitive à  l’Université de Genève, spécialiste des relations a ffectives hommesmachines ;   - M. Hervé Bourlard, directeur de l’Idiap (fondation affiliée à l’École  polytechnique fédérale de Lausanne) ;   - M. Andrei Popescu-Belis, chercheur senior à l’Idiap  et enseignant à  l’École polytechnique fédérale de Lausanne ;   - Professeur Felix Schürmann, directeur adjoint du Blue Brain project .  Professeur adjoint à l’École polytechnique fédérale  de Lausanne  (EPFL) ;  - Professeur Sean Hill, co-directeur du Blue Brain project  (BBP) et codirecteur neuro informatique du Humain brain project  (HBP) ;  - Professeur John Richard Walker, économiste, cherche ur sénior sur le  Blue Brain Project  ; 
LISTE  DES  PERSONNES  RENCONTRÉES  - 261  -       - M. Johann Christoph Ebell, directeur exécutif du pr ojet HBP ;  - M. Jean-Pierre Changeux, chercheur au HBP, École no rmale supérieure,  Collège de France, Institut Pasteur ;  - M. Bernd Stahl, directeur de l’éthique du HBP, dire cteur du centre de  calcul et responsabilités sociales. Professeur à l’ Université De  Montfort (Royaume-Uni) ;  - Mme Christine Aircardi, chercheur associé au Human Brain Project ,  ingénieur de l’École nationale des ponts et chaussé es.  2.  À Londres, Royaume-Uni, les 14, 15 et 16 décembre 2 016  - Madame l’Ambassadeur de France au Royaume-Uni, Son Excellence  Sylvie Bermann ;  - Mme Natasha McCarthy, responsable de la stratégie, à la Royal Society   sur le “Machine Learning Project” ;   - Mme Jessica Montgomery, conseillère stratégie (seni or policy adviser), à  la Royal Society  sur le “Machine Learning Project” ;   - Mme Laura Wilton, conseillère stratégie (senior pol icy adviser), à la  Royal Society  sur le “Machine Learning Project” ;   - M. Paul Mason, directeur des technologies numérique s et habilitantes  (Head of Digital and Enabling Technologies ), Innovate UK ;   - M. Phil Williams, responsable du groupe d’intérêt s ur la robotique et  les systèmes autonomes ( Robotics and Autonomous Systems Special  Interest Group), Knowledge Transfer Network  ;  - M. Noel Sharkey, Université de Sheffield, Professeu r de robotique et  systèmes autonomes, co-fondateur de la Foundation for Responsible  Robotics  (Fondation pour une robotique responsable) ;  - M. Stephen Metcalfe, membre du Parlement, Président  de la  Commission pour la Science et la Technologie de la Chambre des  Communes ;  - Dr Nico Guernion, responsable des partenariats (Fra nçais), Alan Turing  Institute ;  - Dr Sandra Wachter, chercheuse en régulation et éthi que des données,  Alan Turing Institute ;   - Professeur Rose Luckin, éducation et nouvelles tech nologies, spécialiste  en intelligence Artificielle, UCL Knowledge Lab, University College  London ;   - Dr Kedar Pandya, Directeur associé, Engineering and Physical Sciences  Research Council (EPSRC) ; 
- 262  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        - Professeur Alan Winfield, Professeur de robotique, spécialiste des  questions éthiques et sociétales, University of the West of England  Bristol  ;  - Professeur Murray Shanahan, Professeur de robotique  cognitive,  Imperial College London ;   - M. Arnaud Schenk, entrepreneur avec First , incubateur en deep learning ;   - M. Bruno Marnette, entrepreneur, président de prodo.ai ;   - M. Jacqueline I. Forien, fondatrice du salon du Machine Learning ,  professeur de mathématiques, master de Machine Learning ;  - M. Alexandre Flamant, entrepreneur Venture Capital ;  - M. Stéphane Chretien, chercheur au National Physical Laboratory ;  - M. Gautier Marti, doctorant X-ENS, en contrat chez Hellebore Capital  Management.   3.  À Oxford, Royaume-Uni, le 15 décembre 2016  - Professeur Michael Wooldridge, Directeur du départe ment de sciences  informatiques, Université d’Oxford ;  - Professeur Doyne Farmer, Co-Directeur, économies co mplexes, The  Institute for New Economic Thinking (INET), Oxford Martin School ;  - Dr François Lafond, Postdoctorant ;  - Dr Rupert Way, Postdoctorant, INET ;  - Dr Anders Sandberg, chercheur, Oxford Martin School Senior Fellow  et  Future of Humanity Institute  (FHI) ;  - Dr Stuart Armstrong, chercheur en intelligence arti ficielle et machine  learning , Future of Humanity Institute  (FHI) ;  - M. Miles Brundage, chercheur, Strategic Artificial Intelligence Centre ,  Future of Humanity Institute  (FHI) ;  4.  À Cambridge, Royaume-Uni, le 16 décembre 2016  - Dr Stephen Cave, Directeur exécutif du Leverhulme Centre for the Future  of Intelligence  ;  - Dr Huw Price, Directeur académique du Centre for the Study of  Existential Risk (CSER), et du Leverhulme Centre for the Future of  Intelligence  ;  - M. Jens Steffersen, Administrateur, Centre for the Study of Existential  Risks (CSER)  ; 
LISTE  DES  PERSONNES  RENCONTRÉES  - 263  -       - Mme Susan Gowans, Administrateur, Leverhulme Centre for the Future of  Intelligence ;   - Professeur Steve Young, Professeur en ingénierie de  l’information  (information engineering), Université de Cambridge,  et membre de  l’équipe de recherche d’Apple sur le logiciel Siri ; président de la startup de reconnaissance vocale VocalIQ ;   - Dr Sean Holden, chercheur, Artificial Intelligence Group , Université de  Cambridge ; représentant du machine learning group.   5.  À Washington, D.C., États-Unis, le 23 janvier 2017  - Sénateur Ted Cruz, président de la sous-commission du Sénat  américain sur l’espace, la science et la compétitiv ité (« Chairman of the  Senate Commerce Committee’s Subcommittee on Space, Science and  Competitiveness ») ;  - Représentant John Delaney (D-Maryland), président d u comité sur l’IA  du Congrès des États-Unis (« Chairman of the House AI Caucus ») ;  - M. Jason Matheny, directeur de l’agence, Intelligen ce Advanced  Research Projects Activity (IARPA) ;  - M. Andrew Borene, Intelligence Advanced Research Pr ojects Activity  (IARPA) Partner Engagement Lead ;  - Dr. Brian Pierce, directeur adjoint de l’innovation , Defense Advanced  Research Projects Agency (DARPA) ;  - Mme Amanda Lloyd, chargée de l’international, Defen se Advanced  Research Projects Agency (DARPA)  - Mme Rebecca Keiser, directrice, Office of Internati onal Science &  Engineering (OISE), National Science Foundation (NS F) ;  - M. Jim Kurose, directeur adjoint, Computer and Info rmation Science  and Engineering (CISE), National Science Foundation  (NSF) ;  - M. Erwin Gianchandani, adjoint du Directeur de l’In formatique et de  l’Ingénierie du Computer and Information Science an d Engineering  (CISE), National Science Foundation (NSF) ;  - Mme Lynne Parker, Directrice de la Division Informa tion and  Intelligent Systems (IIS), Computer and Information  Science and  Engineering (CISE), National Science Foundation (NS F).  Personnel de l’Ambassade de France aux États-Unis :   - M. Gérard Araud, Ambassadeur de France aux États-Un is ;  - Mme Minh-Hà Pham, conseillère pour la science et la  technologie à  l’Ambassade de France ; 
- 264  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        - M. Renaud Lassus, Ministre Conseiller pour les affa ires économiques à  l’Ambassade de France ;  - M. Bernhard Hechenberger, Conseiller commercial, Se rvice économique  régional ;  - M. Cameron Griffith, chargé de mission à l’Ambassad e de France  (Congressional Affairs Liaison) ;  - M. Hervé Martin, attaché pour la science et la tech nologie à  l’Ambassade de France ;  - M. Xavier Morise, Directeur du bureau du CNRS à l’A mbassade de  France ;  - Mme Mireille Guyader, Directrice du bureau Inserm à  l’Ambassade de  France ;  - M. Norbert Paluch, Conseiller Spatial et Représenta nt du CNES à  l’Ambassade de France ;  - M. Christophe Barre, Attaché pour la Technologie et  l’Innovation au  Service économique régional à l’Ambassade de France .  6.  À Boston, États-Unis, les 24 et 25 janvier 2017  - Professeur Alex "Sandy" Pentland, professeur d’info rmatique, chaire  Marvin Minsky, MIT Media Lab ;  - Professeur David H. Autor, co-director of the Schoo l Effectiveness and  Inequality Initiative economist and professor of ec onomics, MIT ;  - Professeur Iyad Rahwan, professeur d’informatique, MIT ;  - M. Richard Stallman, Free Software Foundation, MIT ;  - Mme Latanya Arvette Sweeney, Professor of Governmen t and  Technology Harvard Data Privacy Lab, , Formerly Chi ef Technology  officer at SEC ;  - M. David Parkes, professeur d’informatique et respo nsable du  département d’informatique, Harvard University, Sch ool of  Engineering and Applied Science ;  - M. Nicolas Miailhes co-fondateur du projet “The Fut ure Society”,  Harvard Kennedy School, fondateur de la “AI Initiat ive” ;  - M. Richard Mallah, director of AI projects, Future of Life Institute (FLI),  Cambridge Innovation Center, MIT ;  - M. Joseph Aoun, Président de North-Eastern Universi ty (Boston) ;  - Professeur Thomas A. Kochan, professor of industria l relations, work  and employment, MIT Sloan School of Management ; 
LISTE  DES  PERSONNES  RENCONTRÉES  - 265  -       - Mme Chloé Hecketsweiler, journaliste au journal Le Monde, Fellow au  MIT ;  - M. Jean-François Guillous, chercheur chez IBM pour le projet Watson ;  - M. Valery Freland, Consul Général de France, et son  conjoint,  M. Laurent Colomines ;  - M. Jean-Jacques Yarmoff, attaché pour la Science et  la Technologie ayu  Consulat de Boston.  7.  À San Francisco, États-Unis, du 25 au 28 janvier 20 17  - M. Philippe Perez, attaché pour la Science et la Te chnologie au consulat  de France à San Francisco.  a)  À San Francisco  - M. Alex Dayon, directeur des produits Salesforce ;  - M. John Ball, directeur du département Einstein de Salesforce ;  - M. Thierry Donneau-Golencer, directeur de la recher che en intelligence  artificielle chez Salesforce (projet Einstein) ;  - M. Gregory Renard, entrepreneur (XBrain), ambassade ur de la  Fondation Sigfox et expert pour la NASA ;  - M. Akli Adjaoute, entrepreneur (Brighterion) ;  - M. Michel Morvan, entrepreneur (Cosmo) ;  - M. Ben Levy, fondateur de BootstrapLabs ;  - M. Nicolas Pinto (ex-startup Perceptio), chercheur en intelligence  artificielle chez Apple ;  - M. François Chollet, chercheur chez Google et créat eur de Keras et de  « AI-ON » (Artificial Intelligence Open Network) ;  - M. Fabien Beckers, entrepreneur (Arterys) ;  - M. Johan Mathé (ex-Google X), chercheur chez Bay La bs ;  - M. Nicolas Poilvert (ex-startup Perceptio), cherche ur chez Bay Labs ;   - M. Reza Malekzadeh (Partech Ventures).  b)  À l’Université de Berkeley  - M. Michael Jordan, professeur d’informatique à l’Un iversité de  Berkeley ;  - M. Stuart Russell, professeur d’informatique à l’Un iversité de Berkeley ;  - M. Russ Salakhutdinov, professeur d’informatique à l’Université  Carnegie Mellon, directeur de la recherche en intel ligence artificielle  chez Apple ; 
- 266  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        - Mme Marion Fourcade, professeur de sociologie à l’U niversité de  Berkeley, chercheuse en sociologie de l’innovation et en économie  numérique ;  - Mme Valérie Issarny, directrice de recherches Inria , basée à l’Université  de Berkeley et chargée des relations Inria - États- Unis ;  - M. Ahmed El Alaoui, chercheur en doctorat sous la d irection de  Michael Jordan, professeur d’informatique à l’Unive rsité de Berkeley.  c)  À l’Université de Stanford et dans la Silicon Valle y  - M. Oussama Khatib, directeur du centre de robotique , Université de  Stanford ;  - Mme Fei-Fei Li, directrice du centre d’intelligence  artificielle, Université  de Stanford ;  - M. Greg Corrado, directeur de la recherche en intel ligence artificielle  chez Google, co-fondateur de l’équipe Google Brain ;  - M. Alex Acero, directeur du projet Siri chez Apple ;  - Mme Catherine H. Foster, directrice des affaires pu bliques chez Apple ;  - M. Larry Zitnick, directeur de la recherche en inte lligence artificielle au  centre Menlo Park de Facebook ;  - M. Michael Kirkland, directeur de la communication technologique de  Facebook ;  - Mme Molly Jackman, directrice des affaires publique s chez Facebook ;  - Mme Brenda Tierney, responsable des relations avec les pouvoirs  publics chez Facebook ;  - M. Jack Clark, responsable de la stratégie et de la  communication,  fondation « Open AI » créée par Elon Musk ;  - Mme Cathy Olsson, directrice de recherche à la fond ation « Open AI ».  8.  À Bruxelles, Belgique, 8 et 9 février 2017  - Mme Juha Heikkila chef de l’unité robotique et inte lligence artificielle,  Commission européenne, et Mme Cécile Huet, son adjo inte ;  - M. Jean Arthuis, eurodéputé et président de la comm ission des Budgets  du Parlement européen ;  - Mme Mady Delvaux, eurodéputée, rapporteure sur l’in telligence  artificielle et la robotique ;  - Professeur Hugues Bersini, Université libre de Brux elles-ULB ;  - M. Erastos Filos, de l’unité RTD.D2 « Systèmes de p roduction avancés  et Biotechnologies » ; 
LISTE  DES  PERSONNES  RENCONTRÉES  - 267  -       - M. Pascal Rogard, conseiller technologie à la RP ;  - Mme Catelijne Muller, rapporteure du Conseil économ ique et social  européen (CESE) sur l’intelligence artificielle ;  - M. Pegado Liz, président du groupe d’étude du CESE sur l’intelligence  artificielle ;  - Mme Marie-Laurence Drillon, administratrice à la se ction « Marché  intérieur, production et consommation » du CESE.     

BIBLIOGRAPHIE  - 269  -         BIBLIOGRAPHIE    • Panorama de l’intelligence artificielle, ses bases méthodologiques, ses  développements 1, dirigé par Pierre Maquis, Odile Papini  et Henri Prade ,  Cépaduès éditions, 2014.  • Intelligence artificielle : problèmes et méthodes , Gérard Tisseau  et  Jacques Pitrat , Presses universitaires de France, 1996.  • De l’intelligence humaine à l’intelligence artifici elle , Hugues Bersini ,  Ellipses, 2006.  • Les fondements de l’informatique , Hugues Bersini et Marie-Paule  Spinette-Rose , Vuibert, 2014.  • Brèves réflexions d’un informaticien obtus sur la s ociété à venir ,  Hugues Bersini, Académie royale de Belgique, 2017.  • Les Sciences cognitives , Jean-Gabriel Ganascia, Flammarion, 1998.  • L’intelligence artificielle , Jean-Gabriel Ganascia, Le Cavalier Bleu,  2007.  • Le mythe de la Singularité , Jean-Gabriel Ganascia, Le  Seuil, 2017.  • Des robots et des hommes : mythes, fantasmes et réa lité , Laurence  Devillers, Plon, 2017.  • Le temps des algorithmes , Serge Abiteboul et Gilles Dowek, Le  Pommier, 2017.  • À quoi rêvent les algorithmes : nos vies à l’heure des big data ,  Dominique Cardon, Le Seuil, 2015.  • Droit des robots, Comparative Handbook : robotic te chnolgies law , Alain  Bensoussan et Jérémy Bensoussan , éditions Larcier, 2016.   • En compagnie des robots , Alain Bensoussan , Jean-Gabriel  Ganascia, Yannis Constantinidès, Kate Darling, John  McCarthy et Olivier  Tesquet, Premier Parallèle, 2016.  • Dictionnaire politique d’internet et du numérique , Christophe Stener,  Books on Demand, 2016.  • Code Informatique, fichiers et libertés , Alain Bensoussan, éditions  Larcier, 2014.  • Droit de l’informatique et de la télématique , Alain Bensoussan ,  Berger-Levrault, 1985.                                                    1 Préfacé par Paul Braffort, le livre est édité par Cépaduès. Le volume 1 traite de la représentation  des connaissances et de la formalisation des raison nements, le volume 2 des algorithmes pour  l’intelligence artificielle et le volume 3 des fron tières et des applications de l’intelligence artifi cielle. 
- 270  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        • Traité de droit et d’éthique de la robotique civile , Nathalie Nevejans ,  Les Études Hospitalières édition, 2017.  • La Machine de Turing , Jean-Yves Girard et Alan Turing, Le Seuil,  Collections Points Sciences, 1999.   • La révolution transhumaniste, Luc Ferry, Plon, 2016 .  • Superintelligence , Nick Bostrom , OUP Oxford, 2016.   • Deep Learning 1, Yoshua Bengio, Aaron Courville  et Ian Goodfellow,  The MIT Press, 2016.   • Learning in Graphical Models (Adaptive Computation and Machine  Learning , Michael Jordan , A Bradford Book, 1998.   • Probabilistic Graphical Models : Principles and Tec hniques , Daphne  Koller et Nir Friedman , The MIT Press, 2009.   • Comprendre le Deep Learning : Une introduction aux réseaux de  neurones , Jean-Claude Heudin, Science eBook, 2016.  • Immortalité numérique : Intelligence artificielle e t transcendance ,  Jean-Claude Heudin , Science eBook, 2016.  • Les 3 Lois de la robotique : Faut-il avoir peur des  robots ? ,  Jean-Claude Heudin , Science eBook, 2015.  • Robots et avatars : Le rêve de Pygmalion , Jean-Claude Heudin , Odile  Jacob, 2009.  • Les créatures artificielles : des automates aux mon des virtuels ,  Jean-Claude Heudin, Odile Jacob, 2008.   • L’Homme neuronal , Jean-Pierre Changeux, Fayard, 1983.  • Un cerveau très prometteur : Conversation autour de s neurosciences,   Jean-Michel Besnier, Francis Brunelle et Florence G azeau, Le Pommier,  2015 .  • Les systèmes multi-agents : vers une intelligence c ollective ,  Jacques Ferber , InterEditions, 1997.   • L’âge de la multitude : Entreprendre et gouverner a près la révolution  numérique,  Henri Verdier et Nicolas Colin , Éditions Armand Colin, 2015.  • Transformation digitale : l’avènement des plateform es , Gilles Babinet ,  éditions Le Passeur, 2016.  • Big Data, penser l’Homme et le monde autrement , Gilles Babinet ,  éditions Le Passeur, 2015.  • L’ère numérique, un nouvel âge de l’humanité , Gilles Babinet ,  éditions Le Passeur, 2014.                                                    1 Ouvrage disponible en ligne : http://www.deeplearningbook.org/   
BIBLIOGRAPHIE  - 271  -       • L’industrie du Futur à travers le monde , Thibaut Bidet-Mayer , fiche  à télécharger sur le site http://www.la-fabrique.fr /fr/publication/lindustrie-du-futur-a-travers-le-monde  • L’Industrie 4.0 : Les défis de la transformation nu mérique du modèle  industriel allemand , Dorothée Kohler et Jean-Daniel Weisz , La  Documentation Française, 2016  • Le Numérique – Une chance pour l’école , Joël Boissière , Simon Fau  et  Francesco Pedró , Éditions Armand Colin, 2013.  • Comment le numérique transforme les lieux de savoir  : Le numérique au  service du bien commun et de l’accès au savoir pour  tous , Bruno Devauchelle ,  FYP éditions, 2012.  • L’école, le numérique et la société qui vient , Philippe Meirieu , Denis  Kambouchner  et Bernard Stiegler , Fayard, 2012.  • Dans la disruption : Comment ne pas devenir fou ?,  Bernard Stiegler ,  Les liens qui libèrent Éditions, 2016.  • Apprendre avec le numérique , Franck Amadieu  et André Tricot,  Retz, 2014.  • Le jour où mon robot m’aimera , Serge Tisseron , Albin Michel, 2015.  • Vivre avec les robots, Essai sur l’empathie artific ielle , Paul Dumouchel   et Luisa Damiano , Le Seuil, 2016.  • L’homme nu : la dictature invisible du numérique , Marc Dugain  et  Christophe Labbé , Plon, 2016.  • L’Homme artificiel, Golems, robots, clones, cyborgs , Michel de  Pracontal , Denoël, 2002.  • La souveraineté numérique , Pierre Bellanger , Stock, 2014.  • La silicolonisation du monde : l’irrésistible expan sion du libéralisme  numérique , Éric Sadin , L'échappée Éditions, 2016.  • La vie algorithmique : critique de la raison numéri que , Éric Sadin ,  L'échappée Éditions, 2015.  • L’humanité augmentée : L’administration numérique d u monde ,  L'échappée Éditions, 2015.  • La Révolution  transhumaniste , Luc Ferry , Plon, 2016.  • Le livre blanc d’Inria sur l’intelligence artificie lle, coordonné par  Bertrand Braunschweig 1  • Dix Questions sur l’intelligence artificielle et la  technologie, posées à  l’académicien Gérard Sabah, dans une brochure de l’ Académie des  technologies.                                                    1 https://www.inria.fr/content/download/103897/152937 0/.../AI_livre-blanc_n01.pdf  
- 272  - P OUR UNE INTELLIGENCE ARTIFICIELLE MAÎTRISÉE , UTILE ET DÉMYSTIFIÉE        • Quelles priorités éducatives pour 2017-2027 ? , note de France  Stratégie , mai 2016.  • Les risques de l’automatisation pour l’emploi, M. Arntz, T. Gregory et  U. Zierahn , rapport OCDE, 2016.   • Automatisation, numérisation et emploi, rapport du Conseil  d’orientation pour l’emploi (COE), 2016.  • L’école sous algorithme , note de la fondation Terra Nova , mars 2016.  • La déconnexion des élites. Comment Internet dérange  l’ordre établi ?   Laure Belot , Les Arènes, 2015.  • Intelligence artificielle et robotique : Confluence s de l’Homme et des  STIC, cahier de l’Agence nationale de la recherche (ANR),  mars 2012.  • Is Google making us stupid ?, article de Nicholas Carr  dans la revue  The Atlantic, juin 2008.   • Social media, texting, and personality: A test of t he shallowing  hypothesis, Logan E. Annisette, Dr. Kathryn Lafreniere , Elsevier, 2016.   • It’s 2001. Where Is HAL?  », Marvin Minsky , Dr. Dobb’s  Technetcast, 2001.   • Introduction to Multi-Agent Systems, Michael Wooldridge, John  Wiley & Sons, 2002.   • Social Physics , Alex Pentland , Penguin Press, 2014.   • Logical Foundations of Artificial Intelligence , Michael R. Genesereth   et Nils J. Nilsson , Stanford University, Morgan Kaufmann Publishers, 1988  • What to think about machines that think , John Brockman , Harper  Perennial, 2015.   • A (Very) Brief History of Artificial Intelligence , Bruce G. Buchanan ,  AI Magazine, 2005.  • The Perceptron: A Probabilistic Model For Informati on Storage And  Organization in the Brain, Frank Rosenblatt, Psychological Review, 1958.   • What the Frog's Eye Tells the Frog's Brain , J.Y. Lettvin, H. R.  Maturanat, S. Mc Culloch, W. H. Pitts , Proceedings of the Institute of Radio  Engineers (IRE), 1959.  • Artificial Intelligence: A Modern Approach , Stuart Russell et Peter  Norvig, Prentice Hall, 1995. 
BIBLIOGRAPHIE  - 273  -       LES RAPPORTS DU SÉNAT    • Les robots et la loi , Jean-Yves Le Deaut et Bruno Sido , rapporteurs,  OPECST, Sénat n° 570 (2015-2016).  • Projet de loi pour une République numérique , Christophe-André  Frassa , rapporteur, Sénat n° 534 (2015-2016).  • Le numérique au service de la santé, Catherine Procaccia  et Gérard  Bapt , rapporteurs, OPECST, Sénat n° 465 (2014-2015).  • Sécurité numérique et risques : enjeux et chances p our les entreprises ,  Anne-Yvonne Le Dain  et Bruno Sido , rapporteurs, OPECST, Sénat n° 271  (2014-2015).  • La place du traitement massif des données (big data ) dans l’agriculture :  situation et perspectives , Jean-Yves Le Deaut, Anne-Yvonne Le Dain  et Bruno  Sido , rapporteurs, OPECST,  Sénat n° 614 (2014-2015).  • Les drones et la sécurité des installations nucléai res , Jean-Yves Le  Deaut et Bruno Sido , rapporteurs, OPECST,  Sénat n° 267 (2014-2015).  • Les nouvelles mobilités sereines et durables , Denis Baupin  et  Fabienne Keller , rapporteurs, OPECST,  Sénat n° 293 (2013-2014).  • Les enjeux des nouvelles technologies d'exploration  et de traitement du  cerveau, Alain Claeys  et Jean-Sébastien Vialatte , rapporteurs, OPECST,  Sénat n° 476 (2011-2012).  • Proposition de résolution sur la régulation des mar chés financiers ,  Nicole Bricq , rapporteur, Sénat n° 369 (2011-2012).  • La gouvernance mondiale de l'Internet, Claude Birraux  et Jean-Yves  Le Deaut, rapporteurs,  OPECST, Sénat n° 219 (2005-2006).  • Les conséquences de l'évolution scientifique et tec hnique dans le  secteur des télécommunications, Pierre Laffitte et  René Tregouet,  rapporteurs,  OPECST,  Sénat n° 159 (2001-2002).  • Images de synthèse et monde virtuel : techniques et  enjeux de  société, Claude Huriet , rapporteur, OPECST, Sénat n° 169 (1997-1998).  • Les techniques des apprentissages essentiels pour u ne bonne  insertion dans la société de l’information, Franck Sérusclat , rapporteur,  OPECST, Sénat n° 383 (1996-1997).  • La France et la société de l’information : un cri d ’alarme et une  croisade nécessaire, Pierre Laffitte , rapporteur, OPECST, Sénat n° 213 (19961997).  • Les nouvelles techniques d’information et de commun ication : l’Homme  cybernétique , Franck Sérusclat , rapporteur, OPECST, Sénat n° 232 (19941995). 
