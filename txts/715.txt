EXECUTIVE OFFICE OF THE PRESIDENT  OFFICE OF MANAGEMENT AND BUDGET  WASHINGTON, D.C. 20503  November 17, 2020  THE DIRECTOR  M-21-06  MEMORANDUM FOR THE HEADS OF EXECUTIVE DEPARTMENTS AND AGENCIES  FROM: Russell T. Vought ,Ii___, G\__ \j ·  Director ~--\ SUBJECT: Guidance for Regulation of Artificial Intelligence Applications  Introduction  Executive Order 13859, "Maintaining American Leadership in Artificial Intelligence," 1  requires the Director of the Office of Management and Budget (0MB), in coordination with the  Director of the Office of Science and Technology Policy, the Director of the Domestic Policy  Council, and the Director of the National Economic Council, to issue a memorandum that  provides guidance to all Federal agencies to inform the development of regulatory and non­ regulatory approaches regarding technologies and industrial sectors that are empowered or  enabled by artificial intelligence (AI) and consider ways to reduce barriers to the development  and adoption of AI technologies. Consistent with Executive Order 13859, 0MB guidance on  these matters seeks to support the U.S. approach to free markets, federalism, and good regulatory  practices (GRPs), which has led to a robust innovation ecosystem. When considering regulations  or policies related to AI applications, agencies should continue to promote advancements in  technology and innovation, while protecting American technology, economic and national  security, privacy, civil liberties, and other American values, including the principles of freedom,  human rights, the rule of law, and respect for intellectual property.  This Memorandum sets out policy considerations that should guide, to the extent  permitted by law, regulatory and non-regulatory approaches to AI applications developed and  deployed outside of the Federal government. Although Federal agencies currently use AI in  many ways to perform their missions, government use of AI is outside the scope of this  Memorandum. While this Memorandum uses the definition of AI recently codified in statute,2 it  1 Exec. Order No. 13,859 of Feb. 11, 2019, Maintaining American Leadership in Artificial Intelligence, 84 Fed. Reg.  3967 (Feb. 14, 2019), available at https://www.whitehouse .gov/presidential-actions /executive-order-maintaining­ american-leadership-artificial-intelligence /.  2 Section 238(g) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019, Pub. L. No. 115232, 132 Stat. 1636, 1695 (Aug. 13, 2018) (codified at 10 U.S.C. § 2358, note), defines AI to include the following:  
focuses on "narrow" ( also known as "weak") AI, which goes beyond advanced conventional  computing to learn and perform domain-specific or specialized tasks by extracting information  from data sets, or other structured or unstructured sources of information.  This Memorandum is directed to the heads of all Executive Branch departments and  agencies, including independent regulatory agencies.  Encouraging Innovation and Growth in AI  As stated in Executive Order 13859, "the policy of the United States Government [is] to  sustain and enhance the scientific, technological, and economic leadership position of the United  States in AI."3 The deployment of AI holds the promise to improve efficiency, effectiveness,  safety, fairness, welfare, transparency, and other economic and social goals, and America's  continued status as a global leader in AI development is important to preserving our economic  and national security. The importance of developing and deploying AI requires a regulatory  approach that fosters innovation and growth and engenders trust, while protecting core American  values, through both regulatory and non-regulatory actions and reducing unnecessary barriers to  the development and deployment of AL  To that end, Federal agencies must avoid regulatory or non-regulatory actions that  needlessly hamper AI innovation and growth. Where permitted by law, when deciding whether  and how to regulate in an area that may affect AI applications, agencies should assess the effect  of the potential regulation on Al innovation and growth. While narrowly tailored and evidence­ based regulations that address specific and identifiable risks could provide an enabling  environment for U.S. companies to maintain global competitiveness, agencies must avoid a  precautionary approach that holds AI systems to an impossibly high standard such that society  cannot enjoy their benefits and that could undermine America's position as the global leader in  AI innovation. Where AI entails risk, agencies should consider the potential benefits and costs  of employing AI, as compared to the systems AI has been designed to complement or replace.  Furthermore, in the context of AI, as in other settings, agencies must consider the effect  of Federal regulation on existing or potential actions by State and local governments. In some  circumstances, agencies may use their authority to address inconsistent, burdensome, and  duplicative State laws that prevent the emergence of a national market. Where a uniform  (1) Any artificial system that performs tasks under varying and unpredictable circumstances without  significant human oversight, or that can learn from experience and improve performance when exposed to  data sets.  (2) An artificial system developed in computer software, physical hardware, or another context that solves  tasks requiring human-like perception, cognition, planning, learning, communication, or physical action.  (3) An artificial system designed to think or act like a human, including cognitive architectures and neural  networks.  (4) A set of techniques, including machine learning, that is designed to approximate a cognitive task.  (5) An artificial system designed to act rationally, including an intelligent software agent or embodied robot  that achieves goals using perception, planning, reasoning, learning, communicating, decision-making, and  acting.  3 See Exec. OrderNo. 13,859, § 1, 84 Fed. Reg. at 3967.  2  
national standard for a specific aspect of AI is not essential, however, agencies should consider  forgoing regulatory action.  Principles for the Stewardship of AI Applications  Consistent with law, agencies should take into consideration the following principles  when formulating regulatory and non-regulatory approaches to the design, development,  deployment, and operation of AI applications, both general and sector-specific. These principles,  many of which are interrelated, reflect the goals and principles in Executive Order 13859.  Agencies should calibrate approaches concerning these principles and consider case-specific  factors to optimize net benefits.  Given that many AI applications do not necessarily raise novel issues, the following  principles also reflect longstanding Federal regulatory principles and practices that are relevant  to promoting the innovative use of AI. Promoting innovation and growth of AI is a high priority  of the U.S. government. Fostering AI innovation and growth through forbearing from new  regulation may be appropriate in some cases. Agencies should consider new regulation only  after they have decided, in light of the foregoing section and other considerations, that Federal  regulation is necessary.  1. Public Trust in AI  AI is expected to have a positive impact across many sectors of social and economic life,  including employment, transportation, education, finance, healthcare, personal security, and  manufacturing. At the same time, AI applications could pose risks to privacy, individual rights,  personal choice, civil liberties, public health, safety, and security that must be carefully assessed  and appropriately addressed. Since the continued adoption and acceptance of AI will depend  significantly on public trust and validation, the government's regulatory and non-regulatory  approaches to AI should contribute to public trust in AI by promoting reliable, robust, and  trustworthy AI applications. For example, an appropriate regulatory approach that reduces  accidents can increase public trust and thereby support the development of industries powered by  AI. Regulatory approaches may also be needed to protect reasonable expectations of privacy on  the part of individuals who interact with AI and to ensure that AI does not compromise the  ability of individuals to make their own informed decisions. The appropriate regulatory or non­ regulatory response to privacy and other risks must necessarily depend on the nature of the risk  presented and the tools available to mitigate those risks.  2. Public Participation  In accordance with Executive Order 13563, "Improving Regulation and Regulatory  Review," regulations "shall be adopted through a process that involves public participation."4  Public participation, especially in those instances where AI uses information about individuals,  will improve agency accountability and regulatory outcomes, as well as increase public trust and  4 Exec. Order No. 13,563 of Jan. 18, 2011, Improving Regulation and Regulatory Review,§ 2(a), 76 Fed. Reg. 3821  (Jan. 21, 2011 ), available at  https://www.whitehouse.gov /sites/whitehouse.gov /files/omb/inforeg/inforeg/eo 12866/eo 13563 01182011.pdf .  3  
confidence. Agencies must provide ample opportunities for the public to provide information  and participate in all stages of the rulemaking process, to the extent feasible and consistent with  legal requirements (including legal constraints on participation to, for example, protect national  security and address imminent threats or respond to emergencies). Agencies are also  encouraged, to the extent practicable, to inform the public and promote awareness and  widespread availability of voluntary frameworks or standards and the creation of other  informative documents.  3. Scientific Integrity and Information Quality  The government's regulatory and non-regulatory approaches to AI applications should  leverage scientific and technical information and processes. Agencies should hold information,  whether produced by the government or acquired by the government from third parties, that is  likely to have a clear and substantial influence on important public policy or private sector  decisions (including those made by consumers) to a high standard of quality and transparency. 5  Consistent with the principles of scientific integrity in the rulemaking and guidance processes,  agencies should articulate a clear public policy need when proposing a regulatory approach to AI  and develop such approaches in a manner that both informs policy decisions and fosters public  trust in AI. When an agency regulates AI applications, it should, as relevant, transparently  articulate the strengths and weaknesses of the applications; intended optimizations or outcomes;  bias and risk mitigations; potential impacts on competition, privacy and personal decision­ making; any national security implications; and appropriate uses of the AI application's results.  4. Risk Assessment and Management  Regulatory and non-regulatory approaches to AI should be based on a consistent  application of risk assessment and risk management across various agencies and various  technologies. It is not necessary to mitigate every foreseeable risk; in fact, a foundational  principle ofregulatory policy is that all activities involve tradeoffs. Instead, a risk-based  approach should be used to determine which risks are acceptable and which risks present the  possibility of unacceptable harm, or harm that has expected costs greater than expected benefits.  Agencies should be transparent about their evaluations of risk and re-evaluate their assumptions  and conclusions at appropriate intervals so as to foster accountability. Correspondingly, the  magnitude and nature of the consequences should an AI tool fail, or for that matter succeed, can  help inform the level and type of regulatory effort that is appropriate to identify and mitigate  risks. Specifically, agencies should follow the direction in Executive Order 12866, "Regulatory  Planning and Review," 6 to consider the degree and nature of the risks posed by various activities  within their jurisdiction. Such an approach will, where appropriate, avoid hazard-based and  unnecessarily precautionary approaches to regulation that could unjustifiably create  5 To further ensure that agencies collect, use, and disseminate information that is fit for its intended purpose, 0MB  issued 0MB M-19-15, Improving Implementation of the Information Quality Act (Apr. 24, 2019), available at  https://www.whitehouse.gov /wp-content/uploads /20 l 9/04/M-19-15 .pdf. 0MB M-19-15 clarified that Information  Quality Act guidelines apply to current and future forms of AI if they are used-for example, to support a regulatory  impact analysis-to create information disseminated by the Federal government.  6 Exec. Order No. 12,866 of Sept. 30, 1993, Regulatory Planning and Review, 58 Fed. Reg. 51,735 (Oct. 4, 1993),  available at https://www.reginfo.gov /public/jsp/Utilities /EO 12866.pdf .  4  
anticompetitive effects or inhibit innovation. 7 Whenever practical and consistent with applicable  law, agencies should seek to apply consistent risk assessment and risk management frameworks  and approaches to similar AI functionalities across sectors. Any assessment of risk should  compare that risk to risk presented by the situation that would obtain absent the AI application at  issue; if an AI application lessens risk that would otherwise obtain, any relevant regulations  presumably should permit that application.  5. Benefits and Costs  When developing regulatory and non-regulatory approaches, agencies will often  consider the application and deployment of AI into already-regulated industries. Presumably,  such significant investments would not occur unless they offered significant economic potential.  As in all technological transitions of this nature, the introduction of AI may also create unique  challenges. For example, while the broader legal environment already applies to AI applications,  the application of existing law to questions of responsibility and liability for decisions made by  AI could be unclear in some instances, leading to the need for agencies, consistent with their  authorities, to evaluate the benefits, costs, and distributional effects associated with any  identified or expected method for accountability. Executive Order 12866 calls on agencies to  "select those approaches that maximize net benefits (including potential economic,  environmental, public health and safety, and other advantages; distributive impacts; and  equity)." 8 Agencies should, when consistent with law, carefully consider the full societal costs,  benefits, and distributional effects when considering regulations related to the development and  deployment of AI applications. Such consideration will include the potential benefits and costs  of employing AI, when compared to the systems AI has been designed to complement or replace;  whether implementing AI will change the type of errors created by the system; and comparison  to the degree of risk tolerated in other existing systems. In cases where a comparison to a current  system or process is not available, evaluation of risks and costs of not implementing the system  should be evaluated as well.  6. Flexibility  When developing regulatory and non-regulatory approaches, agencies should pursue  performance-based and flexible approaches that are technology neutral and that do not impose  mandates on companies that would harm innovation. Rigid, design-based regulations that  attempt to prescribe the technical specifications of AI applications will in most cases be  impractical and ineffective, given the anticipated pace with which AI will evolve and the  resulting need for agencies to react to new information and evidence. Targeted agency  conformity assessment schemes, to protect health and safety, privacy, and other values, will be  essential to a successful, and flexible, performance-based approach. To advance American  innovation, agencies should keep in mind international uses of AI, ensuring that American  companies are not disadvantaged by the United States' regulatory regime.  7 See Exec. Order No. 12,866, § l(b)(5), 58 Fed. Reg. at 51,736 ("[E]ach agency shall consider incentives for  innovation, consistency, predictability, [and] the cost of enforcement and compliance ... to the government,  regulated entities, and the public .... ").  8 Id § l(a).  5  
7. Fairness and Non-Discrimination  Agencies should consider in a transparent manner the impacts that AI applications may  have on discrimination. AI applications have the potential of reducing present-day  discrimination caused by human subjectivity. At the same time, applications can, in some  instances, introduce real-world bias that produces discriminatory outcomes or decisions that  undermine public trust and confidence in AI or be used in other ways that violate anti­ discrimination statutes. When considering regulations or non-regulatory approaches related to  AI applications, agencies should consider, in accordance with law, issues of fairness and non­ discrimination with respect to outcomes and decisions produced by the AI application at issue, as  well as whether the AI application at issue may reduce levels of unlawful, unfair, or otherwise  unintended discrimination as compared to existing processes.  8. Disclosure and Transparency  In addition to improving the rulemaking process, transparency and disclosure can  increase public trust and confidence in AI applications by allowing (a) non-experts to understand  how an AI application works and (b) technical experts to understand the process by which AI  made a given decision. Such disclosures, when required, should be written in a format that is  easy for the public to understand and may include identifying when AI is in use, for instance, if  appropriate for addressing questions about how the application impacts human end users.  Disclosures may be required to preserve the ability of human end users and other members of the  public to make informed decisions, although agencies should be aware that some applications of  AI could improve or assist human decision-making. Agencies should carefully consider the  sufficiency of existing or evolving legal, policy, and regulatory environments before  contemplating additional measures for disclosure and transparency. What constitutes appropriate  disclosure and transparency is context-specific, depending on assessments of potential harms  (including those resulting from the exploitation of disclosed information), the magnitude of those  harms, the technical state of the art, and the potential benefits of the AI application.  9. Safety and Security  Agencies should promote the development of AI systems that are safe, secure, and  operate as intended, and encourage the consideration of safety and security issues throughout the  AI design, development, deployment, and operation process. Agencies should pay particular  attention to the controls in place to ensure the confidentiality, integrity, and availability of the  information processed, stored, and transmitted by AI systems. Agencies should also consider  methods for providing systemic resilience, and for preventing bad actors from exploiting AI  systems, including cybersecurity risks posed by AI operation, and adversarial use of AI against a  regulated entity. When evaluating or developing regulatory and non-regulatory approaches to AI  applications, agencies should be mindful of any potential safety and security risks and  vulnerabilities, as well as the risk of possible malicious deployment and use of AI applications.  Moreover, agencies should consider, where relevant, any national security implications raised by  the unique characteristics of AI and AI applications and take actions to protect national security  as appropriate for their authorities.  6 
10. Interagency Coordination  A coherent and whole-of-government approach to AI oversight requires interagency  coordination. Interagency coordination will be achieved under the auspices of Executive Order  12866, which governs the Office oflnformation and Regulatory Affairs (OIRA) in its oversight  of Federal regulation and establishes principles of regulation that are relevant to this  Memorandum. Consistent with Executive Order 12866, agencies should coordinate with each  other to share experiences to ensure consistency and predictability of AI-related policies that  advance American innovation and adoption of AI, while appropriately protecting privacy, civil  liberties, national security, and American values and allowing sector-and application-specific  approaches. When OIRA designates AI-related draft regulatory action as "significant" for  purposes of interagency review under Executive Order 12866, OIRA will ensure that all agencies  potentially affected by or interested in a particular action will have an opportunity to provide  input.  Non-Regulatory Approaches to AI9  An agency may determine, after considering a particular AI application, that either  existing regulations are sufficient or that the benefits of a new regulation do not justify its costs,  at that time or in the foreseeable future. In these cases, the agency may consider either not taking  any action or, instead, identifying non-regulatory approaches that may be appropriate to address  the risk posed by certain AI applications. Examples of such non-regulatory approaches include:  • Sector-Specific Policy Guidance or Frameworks. Agencies should consider using any  existing statutory authority to issue non-regulatory policy statements, guidance, or testing  and deployment frameworks, as a means of encouraging AI innovation in that sector.  Agencies should provide guidance where a lack of regulatory clarity may impede  innovation. This may also include work done in collaboration with industry, such as  development of playbooks and voluntary incentive frameworks.  • Pilot Programs and Experiments. Agencies should consider using any authority under  existing law or regulation to grant waivers, deviations, and exemptions from regulations,  or to allow pilot programs that provide safe harbors for specific AI applications. Such  programs may also include events such as hackathons, tech sprints, challenges, and other  types of piloting programs. As part of such programs, agencies may collect data on the  design, development, deployment, operation, or outcomes of AI applications to improve  their understanding of the benefits and risks, which could produce useful data to inform  future rulemaking and non-regulatory approaches. If this information is of significant  public interest, agencies should consider periodically informing the general public about  emerging trends to help coordinate research efforts, new or emerging changes that will  affect particular stakeholders (e.g., consumers), and transparency about how specific AI  applications generate net benefits and, if relevant, distributional effects. Any waivers,  deviations, or exemptions granted by agencies should be consistent with the principles of  this Memorandum.  9 Appendix A provides technical guidance on rulemaking to inform the development ofregulatory approaches to AI  applications.  7  
• Voluntary Consensus Standards. The private sector and other stakeholders may develop  or participate in development of voluntary consensus standards that concern AI  applications, which provide non-regulatory approaches to manage risks associated with  AI applications that are potentially more adaptable to the demands of a rapidly evolving  technology. Agencies must give a preference to voluntary consensus standards consistent  with 0MB Circular A-119, "Federal Participation in the Development and Use of  Voluntary Consensus Standards and in Conformity Assessment Activities." 10 In addition,  agencies should consider relying on private-sector conformity assessment programs,  credentialing, and related activities, before proposing either regulations or compliance  programs. Whenever relying on work done by private sector or other stakeholders or  collaborating with them, agencies must ensure that their actions do not contribute to  entrenchment by market incumbents or erect barriers to entry.  • Voluntary Frameworks: Agencies should consider how to promote, leverage, or develop  datasets, tools, frameworks, credentialing, and guidelines to accelerate understanding,  innovation, and trust in AI. While some approaches may be designed specifically for AI  systems, many existing frameworks-including those specific to safety, cybersecurity  and privacy-have been developed with AI considerations in mind or are otherwise  applicable to AI. Agencies should carefully consider what existing products can be used  for particular AI needs and work with stakeholders if any gaps are identified to update  existing datasets, tools, frameworks, credentialing, and guidelines or develop new ones,  which could include risk management frameworks.  Reducing Barriers to the Deployment and Use of AI  As discussed above, Executive Order 13859 requires 0MB to issue a memorandum to  agencies that shall "consider ways to reduce barriers to the use of AI technologies in order to  promote their innovative application while protecting civil liberties, privacy, American values,  and United States economic and national security." Below are four non-exhaustive examples of  actions agencies can take, outside the rulemaking process, to create an environment that  facilitates the use and acceptance of AI.  Access to Federal Data and Models for AI R&D  . Access to data (and metadata) can facilitate the innovative design, development,  deployment, and operation of specific AI applications. Executive Order 13859 calls on agencies  to increase public access to government data and models where appropriate. Increasing such  access to government data must be done in a manner consistent with the Open, Public,  Electronic, and Necessary Government Data Act; 11 0MB Circular No. A-130 "Managing  10 Office ofMgm't & Budget, Exec. Office of the President, 0MB Circular A-119, Federal Participation in the  Development and Use of Voluntary Consensus Standards and in Conformity Assessment Activities (Jan. 27, 2016),  available at https://www.whitehouse.gov /wp-content/uploads /2020/07 /revised circular a-119 as of I 22.pdf.  11 Pub. L. No. 115-435, tit. II, 132 Stat. 5534 (2019) (Title II of the Foundations for Evidence-Based Policymaking  Act of 2018, also referred to as the "OPEN Government Data Act").  8  
I  Information as a Strategic Resource"; 12 0MB Memorandum M-13-13, "Open Data Policy­ Managing Information as an Asset"; 13 and other relevant authorities that require agencies to  collect and create information in a way that supports public transparency as well as downstream,  secondary information dissemination and processing by third parties, thereby making  government information accessible, discoverable, and usable.  Agencies should also follow 0MB guidance to agencies, pursuant to section 5 of  Executive Order 13859, regarding discovery and usability of Federal data and models for non­ Federal use. Agencies may also review their existing disclosure protocols to determine if it is  appropriate to make more data public, as well as provide more granular data, rather than  aggregate data. In increasing data access, agencies should not lose sight of the legal and policy  requirements regarding the protection of sensitive information and vital public interests, such as  privacy, security, and national economic competitiveness. 14  Communication to the Public  The process by which agencies develop and implement regulatory and non-regulatory  approaches to AI applications will have a significant impact on public perceptions of AI.  Consistent with the principles described in this Memorandum, agencies should communicate  with the public about the benefits and risks of AI in a manner that promotes public trust and  understanding of AI. An important opportunity to do this is when publishing requests for  information (RFis) in the Federal Register that are related to AI. RFis and similar notices can  help ensure that public perceptions of AI are informed by agency risk assessments that are  context-specific and based on sound scientific evidence. Agencies should communicate this  information transparently by describing the underlying assumptions and uncertainties regarding  expected outcomes, both positive and negative. For more specific guidance, agencies should  consult OSTP's 2010 memorandum on scientific integrity when considering regulatory and non­ regulatory approaches to AI. 15 Agencies are also encouraged to promote widespread availability  of guidance documents and voluntary frameworks that may be created.16  12 Office ofMgm't & Budget, Exec. Office of the President, 0MB Circular No. A-130, Managing Information as a  Strategic Resource (2013), available at  https:/ /www.whitehouse .gov/sites/whitehouse . gov/files/omb/circulars/ A 130/a 130revised.pdf.  13 Office ofMgm't & Budget, Exec. Office of the President , 0MB M-13-13, Open Data Policy: Managing  Information as an Asset (2013), available at  https://www.whitehouse.gov /sites/whitehouse.gov /files/omb/memoranda/2013 /m-13-13 .pdf.  14 See, e.g., Privacy Act of 1974 (codified at 5 U.S.C. § 552a); Trade Secrets Act (codified at 18 U.S.C. § 1905);  Federal Information Security Modernization Act of2014 (codified at 44 U.S.C. §§ 3551-3558); Confidential  Information Protection and Statistical Efficiency Act of2018 (codified at 44 U.S.C. § 3561-3853) (Title III of the  Foundations for Evidence-Based Policymaking Act of 2018).  15 John P. Holdren, Office of Sci. & Tech. Pol'y, Scientific Integrity (Dec. 17, 2010), available at  https:/ /obamawhitehouse .archives. gov/sites/default/files /microsites /ostp/scientific-integrity-memo-12172010 .pdf.  16 See Office ofMgm't & Budget, Exec. Office of the President, Final Bulletin for Agency Good Guidance  Practices, 72 Fed. Reg. 3432 (Jan. 25, 2007), available at  https://www.whitehouse.gov /sites/whitehouse .gov/files/omb/assets/regulatory matters pdf/012507 good guidance .  pgf.  9  
Agency Participation in the Development and Use of Voluntary Consensus Standards and  Conformity Assessment Activities  Executive Order 13859 calls for Federal engagement in the development of technical  standards and related tools in support of reliable, robust, and trustworthy systems that use AI  technologies. To promote innovation, use, and adoption of AI applications, standards could  address many technical aspects, such as AI performance, measurement, safety, security, privacy,  interoperability, robustness, trustworthiness, and governance. Moreover, Federal engagement  with the private sector on the development of voluntary consensus standards will help agencies  develop expertise in AI and identify practical standards for use in regulation. As directed by  Executive Order 13859, the National Institute of Standards and Technology (NIST) developed a  plan for Federal engagement in AI standards. 17 Agencies should use this plan to direct their  involvement in AI standards development relevant to their authorities.  When engaging with private sector standard-setting organizations, agencies should  adhere to 0MB Circular A-119. Consistent with Section 12(d)(l) of the National Technology  Transfer and Advancement Act of 1995, all Federal agencies must use voluntary consensus  standards in place of government-unique standards in their procurement and regulatory activities,  except where inconsistent with law or otherwise impractical. 18  When appropriate, agencies may also leverage the work of standards bodies and  independent organizations that have extensive experience in managing conformity assessment  programs and who have conformity assessment or certification programs in AI. Conformity  assessment procedures provide a means of enhancing the confidence that the products, services,  systems, persons, or bodies have specifically required characteristics, and that these  characteristics are consistent from product to product, service to service, system to system, and  in similar scenarios. Agencies should rely on the guidance in NIST publications to understand  conformity assessment concepts 19 and to use conformity assessment in an effective and efficient  mariner that meets agency requirements. 20  International Regulatory Cooperation  Executive Order 13609, "Promoting International Regulatory Cooperation," calls on the  Regulatory Working Group, which was established by Executive Order 12866, to consider  "appropriate strategies for engaging in the development of regulatory approaches through  17 Nat'! Inst. of Standards & Tech., U.S. Dep't of Commerce, U.S. Leadership in AI: A Plan for Federal  Engagement in Developing Technical Standards and Related Tools (Aug. 9, 2019), available at  https://www.nist.gov /topics/artificial-intelligence /plan-federal-engagement-developing-ai-technical-standards-and­ related.  18 See Pub. L. No. 104-113, § 12(d), 110 Stat. 775, 783 (1996) (as codified at 15 U.S.C. § 272, note).  19 Lisa Carnahan & Amy Phelps, Nat'! Inst. of Standards and Tech., U.S. Dep't of Commerce, ABC's of Conformity  Assessment, NIST Special Pub. 2000-01 (Sept. 2018), available at https://doi.org/10.6028/NIST.SP .2000-01 .  20 Lisa Carnahan & Amy Phelps, Nat'! Inst. of Standards and Tech., U.S. Dep't of Commerce, Conformity  Assessment Considerations for Federal Agencies, NIST Special Pub. 2000-02 (Sept. 2018), available at  https:/ /doi.org/10 .6028/NIST .SP .2000-02 .  10  
international regulatory cooperation, particularly in emerging technology areas."21 Accordingly,  agencies should engage in dialogues to promote compatible regulatory approaches to AI and to  promote American AI innovation, while protecting privacy, civil rights, civil liberties, and  American values. Such discussions, including those with the general public, can provide  valuable opportunities to share best practices, data, and lessons learned, and ensure that America  remains at the forefront of AI development. They can also minimize the risk of unnecessary  regulatory divergences from risk-based approaches implemented by key U.S. trading partners.  In addition, agencies should consider existing international frameworks to which the United  States has committed itself and the development ·of strategic plans for coordination and  cooperation with international partners.  Agency Plans to Achieve Consistency with this Memorandum  Executive Order 13859 requires that implementing agencies with regulatory authorities  review their authorities relevant to AI applications and submit plans to 0MB on achieving  consistency with this Memorandum.  The agency plan must identify any statutory authorities specifically governing agency  regulation of AI applications, as well as collections of AI-related information from regulated  entities. For these collections, agencies should describe any statutory restrictions on the  collection or sharing of information ( e.g., confidential business information, personally  identifiable information, protected health information, law enforcement information, and  classified or other national security information). The agency plan must also report on the  outcomes of stakeholder engagements that identify existing regulatory barriers to AI applications  and high-priority AI applications that are within an agency's regulatory authorities. 0MB also  requests agencies to list and describe any planned or considered regulatory actions on AI.  Appendix B provides a template for agency plans.  Agency plans are due on May 17, 2021 and should be submitted to OIRA at the  following email address: Alplans@omb.eop.gov. To inform the public of each agency's  planned and implemented activities, agency plans must be posted on, or be accessed from  (through a URL redirect) the following domain on the agency's website:  www.[agencyname].gov/guidance.  21 Exec. Order 13,609 of May 1, 2012, Promoting International Regulatory Cooperation,§ 2(ii)(A), 77 Fed. Reg.  26,413, 26,413 (May 4, 2012), available at  https://www.whitehouse.gov /sites/whitehouse .gov/files/omb/inforeg/inforeg /eo 13609/eo 13609 05012012.pdf .  11  
Appendix A: Technical Guidance on Rulemaking  Consistent with applicable law and Executive Order 12866, before deciding to regulate,  an agency must first identify the problem it seeks to address and consider whether regulation is  justified or if non-regulatory approaches are appropriate . This process will often begin by  assessing the adequacy of existing regulation at a Federal, State, or local level, as well as  potential actions by private parties.  In considering regulatory and non-regulatory approaches 'to the development and  deployment of AI, it is important to recognize the unique characteristics of AI. For example,  while the rapid emergence of new paradigms can foster innovation that the government should  not hinder, the pace of AI development and application will challenge agencies to develop  regulatory and non-regulatory approaches that are adaptable. In addition, current technical  challenges in creating interpretable AI can make it difficult for agencies to ensure a level of  transparency necessary for humans to understand the decision-making of AI applications . The  following discussion of various technical aspects of the regulatory process will help agencies  address the unique aspects of the rapidly changing AI landscape.  Regulatory Impact Analysis  A regulatory analysis should begin with a clear explanation of the need for the regulatory  action, including a description of the problem that the agency seeks to address. For example,  agencies should explain whether the action is intended to address a market failure (e.g.,  asymmetric information) , clarify uncertainty related to existing regulations , or address another  factor, such as protecting privacy or civil liberties, preventing unlawful discrimination, or  advancing the United States' economic and national security. In the case of AI, a regulatory  impact analysis supporting a proposed regulatory approach should articulate a clear public policy  need for Federal regulation. Often, in order to pursue the larger goals of Executive Order 13859,  agencies should consider whether a change in regulatory policy is needed due to the adoption of  AI applications in an already regulated industry, or due to the development of substantially new  industries facilitated by AI.  In addition, agencies should "consider how best to promote retrospective analysis of rules  that may be outmoded, ineffective, insufficient, or excessively burdensome , and to modify,  streamline, expand, or repeal them in accordance with what has been learned," in accordance  with Executive Order 13563. 22 In conducting such retrospective reviews, agencies can determine  whether regulatory changes are necessary to remove barriers to the adoption of net beneficial AI  systems by identifying and promulgating deregulatory actions, consistent with Executive Orders  13771, "Reducing Regulation and Controlling Regulatory Costs,"23 and 13777, "Enforcing the  Regulatory Reform Agenda. "24 To inform these efforts, agencies should develop mechanisms  22 Exec. Order No. 13,563 of Jan. 18, 2011, Improving Regulation and Regulatory Review,§ 6(a), 76 Fed. Reg.  3821 , 3822 (Jan. 21, 2011), available at  https://www.whitehouse .gov/sites/whitehouse .gov/files/omb/inforeg/inforeg/eo 12866/eo 13563 01182011 .pdf.  23 Exec. Order No. 13,771 of Jan. 13, 2017, Reducing Regulation and Controlling Regulatory Costs, 82 Fed. Reg.  9339 (Feb. 3, 2017), available at https://www.govinfo.gov /content/pkg /FR-2017-02-03 /pdf/2017-02451.pdf.  24 Exec. Order No. 13,777 of Feb. 24, 2017, Enforcing the Regulatory Reform Agenda, 82 Fed. Reg. 12,285 (Mar. 1,  2017), available at https://www.govinfo.gov /content/pkg/FR-2017-03-01 /pdf/2017-04107.pd f.  12  
for industry to seek guidance and/or request clarification about regulations that may be creating  uncertainty around the use of AI. Such mechanisms should enable industry to request  information about how an agency may interpret existing regulations and/or statutory authorities  related to the use of AI.  After identifying a set of potential regulatory approaches, the agency should conduct a  benefit-cost analysis that estimates the benefits and costs associated with each alternative  approach. The benefits and costs should be quantified and monetized to the extent possible and  appropriate, and presented in both physical units (e.g., number of accidents avoided) and  monetary terms. When quantification of a particular benefit or cost is not possible, it should be  described qualitatively. The analysis of these alternatives should also evaluate, where relevant  and appropriate and consistent with Executive Order 13859, impacts to equity, human dignity,  fairness, potential distributive impacts, privacy and civil liberties, personal freedom, and other  American values. The agency's analysis should be based on the best available scientific,  technical, and economic information. Agencies should rely on 0MB Circular A-4, "Regulatory  Analysis," for more technical guidance.25  Public. Consultation  The informal rulemaking process under the Administrative Procedure Act provides  predictable and meaningful opportunities for interested stakeholders to provide input on draft  regulations and scrutinize the evidence and analytic bases of regulatory proposals. In soliciting  public input on Notices of Proposed Rulemaking (NPRMs) that relate to AI applications,  agencies will benefit from the perspectives and expertise of stakeholders engaged in the design,  development, deployment, operation, and impact of AI applications, and facilitate a decision­ making process that is more transparent and accountable.  To the extent feasible, agencies should also provide opportunities for stakeholder  consultation before the NPRM stage, including through the issuance, when appropriate, of RFis  and Advance Notices of Proposed Rulemaking (ANPRMs) to inform decisions about the need to  regulate. Agencies should also consider holding stakeholder and public meetings both prior to  issuing an NPRM and during the public comment period.  Assessing Risk  When humans delegate decision-making and other functions to AI applications, there is a  risk that AI' s pursuit of its defined goals may diverge from the underlying or original human  intent and cause unintended consequences-including those that negatively impact privacy, civil  rights, civil liberties, confidentiality, security, and safety. Because traditional forms of delegated  decision-making are accompanied by risks that present some-although not all-of the dynamics  present in the case of delegation to AI, existing approaches to risk continue to be relevant.  However, the kind of AI adopted and the way it works in decision-making may present new  demands on existing risk frameworks. In addition, because components of AI applications, such  as algorithms or the data they are trained on and use, may be sensitive or subject to legal  25 Office ofMgm't & Budget, Exec. Office of the President, 0MB Circular A-4, Regulatory Analysis (Sept. 17,  2003 ), available at https://www.whitehouse .gov/sites/whitehouse. gov/files/omb/circulars/ A4/a-4.pdf.  13  
protections (e.g., privacy or intellectual property), agencies should consider the risks of  inadequate protections to algorithms and data throughout the design, development, deployment,  and operation of an AI system, given the level of sensitivity of the algorithms and data.  Agencies should also consider that an AI application could be deployed in a manner that yields  anticompetitive effects that favors incumbents at the expense of new market entrants,  competitors, or up-stream or down-stream business partners.  Managing Risk  The management of risks created by AI applications should be appropriate to, and  commensurate with, the degree of risk that an agency determines in its assessment. In general,  as emphasized above, the agencies should also be comparing risks unique to the AI application to  other similar risks associated with not using such applications within a regulatory framework or  risks mitigated by the adoption of AL For AI applications, agencies should adopt a tiered  approach in which the degree of risk and consequences of both success and failure of the  technology determines the regulatory approach, including the option of not regulating. Agencies  should be aware that there is always likely to be at least some risk, including that associated with  not knowing what is currently unknown. For AI applications that pose lower risks, agencies can  rely on less stringent and burdensome regulatory approaches--or non-regulatory approaches­ such as requiring information disclosures or consumer education. For higher risk AI  applications, agencies should consider, for example, the effect on individuals, the environments  in which the applications will be deployed, the necessity or availability of redundant or back-up  systems, the system architecture or capability control methods available when an AI application  makes an error or fails, and how those errors and failures can be detected and remediated.  14 
Appendix B: Template for Agency Plans  Agency  1. Statutory Authorities Directing or Authorizing Agency Regulation of AI  Applications. List and describe any statutes that direct or authorize your agency to  issue regulations specifically on the development and use of AI applications.  Statute Brief Description  2. Active Collections of AI-Related Information. List and describe any of your  agency's collections of information approved by 0MB under the Paperwork Reduction  Act that relate directly to the design, development, deployment, and operation of AI  applications in the private sector, including ifthere are any statutory or regulatory  restrictions on the use or sharing of this information.  Title/OMB Control Brief Description Number  3. AI Use Case Priorities . Informed by stakeholder engagement, list and describe AI  applications that are within your agency's regulatory authorities.  AI use case Brief Description  15  
4. AI Regulatory Barriers. Informed by stakeholder engagement, list and describe  existing processes, policies, or regulations that inhibit development or  commercialization of AI applications within your agency's authority.  Process, policy, or  regulation Brief description  5. Planned Regulatory Actions Concerning AI Applications. List and describe any  planned or considered regulatory actions and provide, to the extent possible,  information about the agency's consideration of the principles and approaches  described in 0MB Memorandum M-21-06.  Regulatory Action Brief description  16  
