DIGITAL INCLUSION CO-CHAIR:POLICY BRIEF W20 ARGENTINA Artiﬁcial Intelligence: open questions about gender inclusion 
2 Abstract + Artificial intelligence (AI) is shaping gender relations, creating new challenges and  opportunities for women. For their personal development and professional growth to be  fully integrated, more women need to participate in the design, implementation, evaluation  and debate on ethics and norms of the next generation of machine learning and  AI-powered technologies. Only the meaningful inclusion of women at all stages will result in policies and technologies that make digital equality a reality. The AI world  is almost entirely dominated by men. We need them to be allies and proactively act  to make AI better for all. CHALLENGE The challenges of artificial intelligence (hereinafter, AI) related to gender are multi-layered.  + The first layer is its design. Women need to have an active role  in shaping the next generation  of technologies, so stereotypes are not reproduced  and diversity is considered.   + The second layer is related to the deployment of such technologies and the direct social economic  and political impact AI will have to reduce or exacerbate gender equality.  + The third layer relates to collateral effects of the digitisation strategies on the future of  work and advancement opportunities for women.  Machine learning and AI systems offer opportunities options to fix the bias and build more gender inclusive  societies. Countries lacking key quality data will be unable to make evidence-based policies and, in turn,  will fail to adopt measures not only to mitigate potentially harmful effects, but also to enhance and take  advantage of these corrective opportunities. AUTHORS   Renata Avila | renata.avila@webfoundation.org  Ana Brandusescu | ana.brandusescu@webfoundation.org Juan Ortiz Freuler | juan.ortiz@webfoundation.org Dhanaraj Thakur | dhanaraj.thakur@webfoundation.org
3PROPOSAL 1 Countries need to take proactive steps towards the inclusion of women  in the coding and the design of machine learning and AI technologies The low involvement and marginal inclusion of women in the coding and design of AI and machine learning  technologies is leading to a variety of problems, including the replication of stereotypes, such as the submissive role of voice-powered virtual assistants, overwhelmingly represented by women. As experts Saran and Mishra point out, AI is replicating the same conceptions of gender roles that are being removed from the real world.   WE RECOMMEND THAT: + G20 governments, in close collaboration with the Education Ministries, Universities and the private sector,  take proactive steps towards the inclusion of more women in the workforce that design AI systems.    + G20 governments require companies to proactively disclose the gender balance of their design teams. + G20 governments require recipients of research grants to disclose the gender balance of the applying  research teams.+ G20 governments engage in better, more inclusive data collection processes that focus not only on quantity  but also on the quality of datasets, which are not being collected at the expense of marginalised groups (e.g.  sometimes data deserts are better off as data deserts -- data collected by governments could end up being used against marginalised groups) + G20 government’s engaged in policy making around AI should ensure that these decision-making spaces  are adequately gender balanced and/or these groups are aware of the reasons behind the significant  gender inequalities facing the sector. + G20 governments should collaborate with industry and other partners to fund women-owned technology  firms working in AI, and to incentivize other firms to have more diverse staff at all levels.  
PROPOSAL 2 States need to implement industry guidelines to protect women from  discriminatory algorithms and embrace openness and transparency for AI  AI systems are only as good as the data they rely on during the training phase. Structural inequality  (including gender inequality) means that the world is full of biased datasets that reinforce such inequality.  Building AI on these biased datasets encourages the systems to learn the values embedded in them, and further cement the patterns of exclusion and discrimination, including racial discrimination currently present in the world. The closed nature of AI systems impedes its comprehensive audit. From recruitment systems, powered by machine learning, that might exclude the profile of women who  the system predicts will become mothers soon, to systems that will advertise jobs with a lower payment to women , AI poses unprecedented threats to the progress towards gender equality if no corrective measures are adopted. A study from the University of Washington showed how machine learning amplified gender bias by associating, for example, women with kitchen appliances.  How can society fight misogyny, sexism and discrimination if the systems are fed with sexist data, and  their algorithms are impossible to audit? Proactive steps can lead to the reduction of gender gaps assisted by machine learning and AI, for instance embracing algorithm affirmative actions that will  ensure that the barriers that generally exclude women are removed from recruitment systems. Governments  need to start auditing the systems to verify that women are not deliberately excluded from jobs or other  opportunities for reasons related to their age, marital status, or motherhood plans. WE RECOMMEND: + G20 countries to embrace regulation promoting transparency in machine learning and AI-powered  systems that can meaningfully affect people’s lives. This should include reliance on open data and open AI  whenever government relies on these technologies for service provision. These requirements can be included in  government procurement guidelines for AI systems that support the delivery of public services. + G20 countries to actively produce needed government open gender disaggregated datasets, so the  machine learning systems can improve their performance. Open data can help us to better understand  sources of bias in AI systems. + G20 countries explore the adoption of algorithmic equitable actions to correct real life biases and barriers  that prevent women from achieving full participation and equal enjoyment of rights. 
5PROPOSAL 3 Countries must assess the  economic, political and social effects of AI and  machine learning technologies on the lives of women The impact of AI and machine learning technologies is still uncertain. Yet, if its potential for social benefit is  to be harnessed, solutions need to be designed to actively reduce gender inequality and increase the  opportunities for women and girls.  There is a lack of research in G20 economies on the impact of AI and machine learning on precarious  jobs, especially those of women. The interim measures regarding AI enhanced technologies to avoid  severe disruptions in the economy and the societal effects on women are yet to be determined, and  they will vary from country to country.  Better data and more debate is urgently needed to understand the potential disruptions for the economy in  general and women in particular if protections are to be set into motion.  WE THEREFORE RECOMMEND THAT:+ G20 countries carry out country level assessments to understand the economic, social and political  impacts of algorithmic decisions and AI on women.+ G20 countries create a common research fund to explore the impacts of AI and machine learning on  women and women. _____
6REFERENCES 1.  The Toronto Declaration: Protecting the rights to equality and non-discrimination in machine learning systems https:/ /www.accessnow.org/cms/assets/uploads/2018/05/Toronto-Declaration-D0V2.pdf2. Samir Saran & Vidishi Misra.  The Economic Times. 17 June 2017. “AI replicating same conceptions of gender roles that are being removed in real world”. 3. For definitions, see: Artificial Intelligence: The Road Ahead in Low and Middle-Income CountriesAvailable at:  http:/ /webfoundation.org/docs/2017/07/AI_Report_WF.pdf&sa=D&ust=1527170130801000&usg=AFQjCNGmoKC0lDzMNhLeH5Prqte6rqpx5Q 4.  Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level ConstraintsJieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, Kai-Wei Chang  https:/ /arxiv.org/abs/1707.09457v1 5.  Anupam Chander, The Racist Algorithm?, 115 Mich. L. Rev. 1023 (2017). Available at: http:/ /repository.law.umich.edu/mlr/vol115/iss6/136.   Pasquale, Frank A., A Rule of Persons, Not Machines: The Limits of Legal Automation (March 6, 2018). George Washington Law Review, Forthcoming; U of Maryland Legal Studies Research Paper No. 20018-08. Available at SSRN:  https:/ /ssrn.com/abstract=3135549 6. Katz, Yarden, Manufacturing an Artificial Intelligence Revolution (November 27, 2017). Available at SSRN:  https:/ /ssrn.com/abstract=3078224 or http:/ /dx.doi.org/10.2139/ssrn.3078224 7. MoJ. Buolamwini and T. Gebru.  Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification   http:/ /proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf6.  An End-To-End Machine Learning Pipeline That Ensures Fairness Policies  8. David Casacuberta. Algorithmic injustice http:/ /lab.cccb.org/en/algorithmic-injustice/  http:/ /opentranscripts.org/transcript/ai-is-hard-to-see-social-ethical-impacts/ 9. Investigating the Impact of Gender on Rank in Resume Search Engines  https:/ /cbw.sh/static/pdf/chen-chi18.pdf http:/ /francescobonchi.com/algorithmic_bias_tutorial.html
