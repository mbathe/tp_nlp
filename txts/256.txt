I (Resolutions, recommendations and opinions) OPINIONS EUR OPEAN ECONOMIC AND SOCIAL COMMITTEE 526TH EESC PLENAR Y SESSION OF 31 MA Y AND 1 JUNE 2017 Opinion of the European Economic and Social Committee on ‘Artificial intelligence — The  consequences of artificial intelligence on the (digita l) single market, production, consumption,  emplo yment and society’ (own-initiativ e opinion) (2017/C 288/01) Rappor teur: Catelijne MULLER Plenar y assembly decision 22/09/2016 Lega l basis Rule 29(2) of the Rules of Procedure Own-initiative opinion Section responsible Sing le Marke t, Production and Consump tion Adopted in section 04/05/2017 Adopted at plenar y 31/05/2017 Plenar y session No 526 Outcome of vote (for/ag ainst/abstent ions)159/3/14 1.Conclusions and recommendations 1.1 Artificial intellig ence (AI) is currently undergoing a number of impor tant developments and is rapidly being applied  in society . The AI marke t amounts to around USD 664 million and is expecte d to grow to USD 38,8 billion by 2025. As AI  can have both a positive and a negative imp act on society , the EESC has under taken to closely monitor developments  surrounding AI, not only from a technical perspective but also specifically from an ethical, safety and societal perspective. 1.2 As the representative of European civil society , the EESC will shape, focus and promot e the public debate on AI in  the coming period, involving all relevant stak eholders: policy-makers, industr y, the social partners, consumers, NGOs,  educational and care institutions, and exper ts and academics from various disciplines (including AI, safety, ethics,  economics, occupational science, law, behavio ural science, psychology and philosophy).31.8.2017 EN Official Jour nal of the European Union C 288/1
1.3 Although imp ortant, the discussion on super intellig ence is currently predominating and this is overshado wing the  debate on the impact of the current applications of AI. Theref ore, the task and objective of this process will, among other  things, be to enhance and broaden kno wledg e of AI and thereby feed into an informed and balanced debate free of wors t-  case scenar ios and extreme relativism. In this connection, the EESC will under take to promot e the development of AI for  the benef it of humanity . Never theless, an impor tant task and objective of this process is also to recognise, identify and  monitor disruptive developments in and around the development of AI, in order to be able to address them adequat ely and  in good time. This will lead to increased social involvement, trust and suppor t with respect to the further sustainable  development and use of AI. 1.4 The impact of AI is of a cross-border nature and theref ore supra-national policy framew orks will also need to be  established. The EESC recommends that the EU take the lead globally in establishing clear global policy framew orks for  AI, in line with European values and fundamental rights. The EESC is able and willing to make a contr ibution to this. 1.5 The EESC currently identifie s 11 areas where AI poses societal challeng es: ethics; safety; privacy ; transparency and  accountability ; work; education and skills; (in)equality and inclusiveness; law and regulations; governance and democracy ;  warfare; super intelligence. The EESC makes the following recommendations. 1.6 The EESC calls for a human-in-command approac h to AI, including the precondition that the development of AI be  responsible, safe and useful, where machi nes remain mac hines and people retain control over these machines at all times. 1.7 The EESC calls for a code of ethics for the development, application and use of AI so that throughout their entire  operational process AI syste ms remain compatible with the principles of human dignity , integr ity, freedom, privacy and  cultural and gender diversity , as well as with fundamental human rights. 1.8 The EESC calls for the development of a standardisation system for verifying, validating and monito ring AI  syste ms, based on a wide rang e of standards in the areas of safety, transparency , comp rehensibility , accountability and  ethical values. 1.9 The EESC calls for a European AI infras tructure consisting of open-source learning environments that respect  privacy , real life test environments and high-quality data sets for developing and training AI syste ms. The EESC highlights  the (comp etitive) advantage the EU can gain on the global market by developing and promoting ‘responsible European AI  syste ms’, complet e with European AI certification and labels. 1.10 The EU, national governments and the social partners should jointly identify which job sectors will be affected by  AI, to what exte nt and on what timescale, and should look for solutions in order to properly address the impact on  emp loyment, the nature of work, social syste ms and (in)equality . Investment should also be made in job marke t sectors  where AI will have little or no impact. 1.11 The EESC recommends that these stak eholders work together on complementar y AI systems and their co-  creation in the workplace, such as human-mac hine teams, where AI complements and impro ves the human being’s  perfo rmance. The stakeholders should also invest in formal and informal lear ning, education and training for all in  order to enable people to work with AI but also to develop the skills that AI will not or should not acquire. 1.12 It is already necessar y to carry out a detailed evaluation of the EU laws and regulations in the six areas  identifie d by STO A (Scientific Foresight Unit) that may need to be revised or adap ted. The EESC is able and willing to play a  role in this evaluation process. The EESC opposes the introduction of a form of lega l personality for robots or AI. This  would hollo w out the preventive remedial effect of liability law; a risk of moral hazard arises in both the development and  use of AI and it creates oppor tunities for abuse. 1.13 The development of AI applications that benef it society , promot e inclusiveness and improve people ’s lives  should be actively suppor ted and promot ed, both publicly and privately . Und er its programmes, the European Commission  should fund research into the societal impact of AI and of EU-funded AI inno vations.C 288/2 EN Official Jour nal of the European Union 31.8.2017
1.14 The EESC suppor ts the call by Human Rights Watch and others for a ban on autonomous weapon systems. The  EESC welcomes the consultation on this issue announced by the UN, but considers that it should also cover the applications  of AI in cyber warfare. 2.Artificial intelligence 2.1 There is no sing le accept ed and rigid definition of AI. AI is a catch- all term for a large number of sub(f ields) such as:  cognitive computing (algor ithms that reason and understand at a higher (more human) level), machi ne learning (algor ithms  that can teac h themselves tasks ), augmented intellig ence (cooperation between human and machine) and AI robotics (AI  imbedded in robots). The central aim of AI research and development is, however , to auto mate intelligent behavio ur such as  reasoning, the gather ing of information, planning, learning, communicating, manipulating, detect ing and even creating,  dreaming and perceiving. 2.2 AI is broadly divided into narrow AI and general AI. Narrow AI is capable of carrying out specific tasks . General AI  is capable of carrying out any mental task that can be carried out by a human being. 2.3 Good progress has recently been made in the field of narrow AI, in particular with the growth of comput er  processing power, the availability of large volumes of data and the development of machine learning (ML). ML refers to  algor ithms that can teac h themselves specif ic tasks without needing to be programmed. This method is based on the  processing of ‘training data’ on the basis of which the algor ithm learns to recognise patt erns and devise rules. Deep learning  (DL), a form of ML, uses structures (neural networks) that are loosely based on the human brain and that learn by means of  training and feedbac k. The result of these developments is that by using algor ithms AI syste ms may now be self-te achi ng,  autonomous and adap tive. 2.4 Research and development in AI have for some time been primar ily focused on reasoning, kno wledge acquisition,  planning, communication and percep tion (visual, auditor y and sensor y). This has led to a large number of AI applications:  virtual assistants, self-dr iving cars, automa tic news aggrega tion, speech recognition, translation software, text-t o-speech  software, automat ed financial trading, lega l eDisco very, etc. 2.5 The EESC notes that there has recently been an exponential increase in the amount of AI applications and  invest ment. The AI marke t currently amounts to around USD 664 million and is expecte d to grow to USD 38,8 billion by  2025. 3.Oppor tunities and threats of AI 3.1 It is virtually undisput ed that AI can have significant advantage s for society : consider applications in sustainable  agriculture, safer transpor t, a safer financ ial system, more environmentally friendly production processes, better medicine,  safer work, more personalised education, better jurisprudence and a safer society . It may even potentially help eradicate  disease and poverty. AI may also make a major contr ibution to boosting industr y and to improving the EU’s  competitive ness. 3.2 As with ever y disruptive technology , AI also entails risks and complex policy challeng es in areas such as safety and  monitoring, socio-economic aspects, ethics and privacy , reliability , etc. 3.3 We are at a crucial point in determi ning the (framew ork) conditions for the ongoing and further development and  use of AI. The benefi ts associate d with AI can only be achieved sustainably if the challeng es surrounding it are also  adequately addressed. Policy choices should be made to this end. a)Ethics 3.4 The development of AI raises many ethical questions. What imp act does autonomous (self-te achi ng) AI have on our  personal integrity, autonom y, dignity , independence, equality , safety and freedom of choice? How do we ensure that our  fundamental norms, values and human rights remain respecte d and safeguarded?31.8.2017 EN Official Jour nal of the European Union C 288/3
3.5 Further more, the development of AI is currently taking place within a homogenous envir onment principally  consisting of young, white men, with the result that (whether intentionally or uninte ntionally) cultural and gender  dispar ities are being embedded in AI, among other things because AI syste ms learn from training data. This data should be  accurate and of good quality , diverse, sufficiently detailed and unbiased. There is a general tendency to believe that data is by  definition objective; however , this is a misconcept ion. Data is easy to manipulate , may be biased, may reflect cultural,  gender and other prejudices and preferences and may contain errors. 3.6 The AI systems now being developed will not have any built-in ethical values. We humans must make provision for  them in AI systems and in the envir onments in which they are used. The development, application and use of AI syste ms  (both public and commercial) must take place within the limits of our fundamental norms, values, freedoms and human  rights. The EESC theref ore calls for the development and establishment of a unif orm global code of ethics for the  development, application and use of AI. b)Safety 3.7 The use of AI in the physica l world undoubtedly gives rise to safety issues. A distinction can be made between  inter nal and exter nal safety. —Inter nal safety: is the AI syste m robust enough to (continue to) function well? Is the algor ithm well programmed? Does it  crash? Is it resistant to hack ing? Is it effective? Is it reliable? —Exter nal safety: is the AI syste m safe when in use in society? Does it operat e safely, not only in normal, but also in  unkno wn, critical or unp redictable situations? What bear ing does the self-te achi ng ability have on safety , including if the  syste m continues to learn after entering into use? 3.8 The EESC believes that AI syste ms may only be used if they meet specific intern al and exte rnal safety requirements.  These requirements should be determi ned by AI and safety specialists, businesses and civil society organisations collectively . c)Transpar ency , compr ehensibility , monitor ability and accountability 3.9 The accep tance and sustainable development and application of AI are linked to the ability to understand, monitor  and certify the operation, actions and decisions of AI systems, including retrospectively . 3.10 The actions and decisions of AI systems (through smar t algor ithms) increasing ly inter vene in peoples’ lives.  Exam ples include the use of AI in information-led policing, when assessing mor tgag e applications or in the procedure for  author ising insurance. The compre hensibility , monito rability and accountability of the decision-making process of an AI  syste m is crucial in this rega rd. 3.11 Currently , many AI syste ms are very difficult for users to understand. This is also increasing ly true for those who  develop the systems. In particular , neural networks are often ‘blac k boxes’, in which the (decision-making) processes taking  place can no longer be understood and for which there are no explanator y mecha nisms. 3.12 The EESC advocat es transparent, comp rehensible and monitorable AI syste ms, the operation of which is  accountable, including retrospectively . In addition, it should be established which decision-making procedures can and  cannot be transferre d to AI systems and when human inter vention is desirable or mandator y. d)Privacy 3.13 The privacy of AI syste ms is an issue of concer n. Man y (consumer) products already have built-in AI: household  appliances, children's toys, cars, health trackers and smar tphones. All of these products transmit (often personal) data to the  cloud-based platf orms of their manufa cturers. Whether or not privacy is sufficiently guaranteed is an issue of concer n,  particularly given that trade in data is now booming, meaning that the data generat ed does not remain with the producer  but is sold on to third parties.C 288/4 EN Official Jour nal of the European Union 31.8.2017
3.14 AI is also able to influence people ’s choices in many areas (from commercial decisions to elections and  refere ndums) by analysing large quantities of (often) personal data. Children are a particularly vulnerable group. The EESC is  concer ned about AI applications that explicitly aim to influence the behavi our and desires of children. 3.15 It is necessar y to prevent the application of AI to personal data from restr icting people’s actual or perceived  freedom. The EU General Data Protection Regulation (GDPR) provides for signifi cant privacy protection for digitally  collected personal information. In the light of the development of AI, it must be properly monitor ed whether people ’s right  to informed consent and freedom of choice when submitting data, as well as their right to access, amend and verify data,  are reasonably assured in practice. e)Nor ms, standar ds and infr astr uctur e 3.16 New standardisation systems based on a broad spectr um of standards should be developed for verifying and  validating AI syste ms, in order to be able to assess and monitor the safety , transparency , compre hensibility , accountability  and ethical responsibility of AI syste ms. 3.17 The EESC calls for the EU to develop its own AI infrastr ucture consisting of open-source learning envir onments  that respect privacy and high-quality data sets for developing and training AI syste ms. The EU could also gain a  (competitive ) advantage on the global market by promoting responsible European AI syste ms. In this connection, the  Committe e recommends explor ing the pote ntial of European AI certification and labels. f)Impact on work, emplo yment, working conditions and social syste ms 3.18 Opinions are divided on the speed with which and the extent to which this will occur; however , it is clear that AI  will have an imp act on employment levels and the nature and character of many jobs, and consequently also on social  syste ms. 3.19 Brynjolfsson and McAfee from MIT refer to the current technological developments (including AI) as the second  machine age. However , there are two impor tant differences: (i) the ‘old’ mac hines predominantly replaced muscular power,  while the new machines are replacing brainp ower and cognitive skills, which affects not only low-skilled (‘blue-collar ’)  workers but also medium and highly skilled (‘white-collar ’) workers and (ii) AI is a general purpose technology which affects  virtually all sectors simultaneously . 3.20 AI can have significant advantages when it is used for dangerous, difficult, tiring, dirty, unpleasant , repetitive or  tedious work. Work that can be ‘routinised’, data processing and analysis or work where planning or prediction plays a  major role — work which is often done highly skilled people — can increasing ly be carried out by AI systems. 3.21 However , the majorit y of jobs compri se a variety of activities. The likelihood that all of an individual’s tasks can be  done by AI or taken over by robots appears to be low. However , most people will be confronted with the auto mation of  parts of their job. The time this frees up can be used for other tasks, provided that public author ities and the social partners  make the necessar y efforts in this regard . In this connection, it is necessar y to bear in mind the impact these developments  may have on prof essionals and manager s and to promote their involvement so that they remain in control of these  developments and are not the victims of them. 3.22 New jobs will also be create d. However , no-one can predict what these will be, how many there will be and how  quickly this will happen. Companies such as Goog le and Facebook manage to generate huge value with a relatively small  number of emp loyees. Moreo ver, these new jobs are not alwa ys quality jobs. The concer n is that with the further  development of AI, soon only low-paid mini-tasks will be left for a growing group of ‘flex work ers’. 3.23 AI will not only affect the quantity of available work but also the nature of existing work. AI syste ms offer more  and more oppor tunities to track and monitor workers, raising concer ns over autonom y and privacy . Work is now often  determined and distr ibut ed by algor ithms without human intervention, which influences the nature of the work as well as  working conditions. There is also the risk of a drop in the quality of jobs and the loss of imp ortant skills through the use of  AI systems.31.8.2017 EN Official Jour nal of the European Union C 288/5
3.24 The fact remains, however , that technology is not something inevitable. Governments and the social partners have  the possibility of determi ning how AI is further developed and applied in the work place and should also seize this  oppor tunity with both hands. In this connection, it is imp ortant to focus not only on what AI is capable of doing, but also  on what people are capable of doing (creativity , empath y, cooperation) and what we want people to keep doing, and to look  for oppor tunities to enable people and mac hines to work together better (comp lementar ity). 3.25 Augment ed intellig ence (comp lementar ity), whereby human and machine work together and suppor t each other , is  the most intere sting application of AI since its involves human with machine, as opposed to human instead of machine.  However , co-creation is of major imp ortance: work ers must be involved in developing these kinds of complement ary AI  syste ms, in order to ensure that the syste ms are useable and that the work er still has suffi cient autonom y and control  (human-in-command), fulfilment and job satisfa ction. g)Education and skills 3.26 The maintenance or acquisition of digital skills is necessar y in order to give people the chance to adap t to the rapid  developments in the field of AI. The European Commission is firmly committ ed to developing digital skills through its  Digital Skills and Jobs Coalition. However , not ever yone will be capable of or interest ed in coding or becoming a  programmer . Policy and financial resources will theref ore need to be directe d at education and skills development in areas  that will not be threatened by AI systems (i.e. tasks in which human interaction is vital, where human and machi ne  cooperate or tasks we would like human beings to continue doing). 3.27 When complementar ity between human and AI is used (augmente d intellig ence), education in dealing and working  with AI syste ms will be required for all, beginning at an early age, in order to ensure that people can retain autono my and  control in their work (human-in-command). Education rega rding ethics and privacy in particular is imp ortant here since AI  has a signif icant imp act in these areas. h)Accessibility , social (in)equality , inclusiv eness and distr ibution 3.28 The vast majorit y of the development of AI and all its associated elements (development platf orms, data,  kno wledg e and exper tise) is in the hands of the ‘big five’ technology companies (Amazon, Facebook , Apple, Goog le and  Microsof t). Although these companies are suppor tive of the open development of AI and some of them make their AI  development platf orms available open-source, this does not guarante e the full accessibility of AI systems. The EU,  inter national policy maker s and civil society organisations have an important role to play here in ensur ing that AI syste ms  are accessible to all, but also that they are developed in an open environment. 3.29 Technological chang es that favour capital, whereby the inno vation primar ily benefits those who own it, weak en the  position of labour relative to capital. Technological changes can also lead to (income) dispar ities between people (both  locally as well as regionally and globally). AI may further reinf orce these trends. 3.30 The imp ortant thing is to closely monitor and appropr iately respond to these trends. There have already been calls  for an AI tax, an AI dividend or shared ownership of AI systems by workers and emplo yers. There is also increasing talk of  the need for an unconditional basic income. 3.31 In a previous opinion (1) the EESC identified the possibility of a digital dividend to be shared equally with the aim of  achi eving positive growth effects. The EESC attache s imp ortance to research on all these solutions; however a fair balance  should be struck between developing AI that benefits people and potential hinder ing effects resulting from the solutions.  Moral hazard, whereby responsibility for AI systems is transferr ed to an entity which cannot be held responsible, should  also be avoided.C 288/6 EN Official Jour nal of the European Union 31.8.2017 (1) OJ C 13, 15.1.2016, p. 161.
i)Laws and regulation 3.32 The implications of AI for existing laws and regulation are considerable. In June 2016, the European Parliament’s  STO A unit published an overview of EU laws and rules that will be affect ed by developments in the areas of robotics, cyber -  physica l syste ms and AI. The STO A set out six areas — transpor t, dual-use syste ms, civil liber ties, safety, health and  energy — within which as many as 39 EU regulations, directives, declarations and communications, as well as the European  Char ter for Fundamental Rights, may need to be revised or adap ted. This assessment should be tackled quickly and  vigorously ; the EESC is able and willing to play a role in this process. 3.33 There is a lot of discussion regarding the issue of who can be held liable when a AI syste m causes damage ,  particularly if the AI system is self-te aching and continues to learn after enter ing into use. The European Parliament has  drawn up recommendations for civil law on robotics, including a proposal to explore an ‘e-personality’ for robots so that  they can incur civil liability for any damage they cause. The EESC is opposed to any form of lega l status for robots or AI  (syste ms), as this entails an unaccept able risk of moral hazard. Liability law is based on a preventive, behaviour -cor recting  function, which may disappear as soon as the maker no longe r bears the liability risk since this is transf erred to the robot  (or the AI syste m). There is also a risk of inappropr iate use and abuse of this kind of lega l status. The compariso n with the  limited liability of companies is misplaced, because in that case a natural person is alwa ys ultimately responsible. In this  regard , it should be examined to what exte nt the current national and EU laws, rules and jurisprudence in the area of  (product and risk) liability and own risk provide an adequat e answer to this question and, failing that, what kind of legal  solutions can be put forward. 3.34 Taking the right approac h to laws and regulations on AI will also require a good understanding of what AI can,  cannot and will be able to do in the shor t, medium and long term. 3.35 AI is not limited by borders. It is theref ore imp ortant to explore the need for global regulations, since regional  legislation will be insuff icient and will even produce undesirable effects. Given its tried and tested system of product and  safety standards, the trend towards prot ectionism on other continents, the high level of knowledge within Europe, the  syste m of European fundamental rights and social values and the social dialogue, the EESC recommends that the EU take a  leading role in establishing unif orm, global policy framew orks for AI, and that it promot e this process at a global level. j)Governance and democr acy 3.36 AI applications can help promot e public involvement in public policy and more transparent administrative  decision-making. The EESC calls on the EU and national governments to use AI for this purpose. 3.37 The EESC is concer ned about the targe ted use of AI systems (in the form of smar t algor ithms) for news aggregation,  for example on social media, which seems to have restr icted information flow and led to the further division of society (e.g.  ‘filter bubbles’ and ‘fake news ’ on Twitt er and Facebook during the US elections). 3.38 The EESC is also concer ned about indications that AI systems have been used to influence people’s (voting)  behavio ur. People’s preferences and behavi our appear to have been predicted and actively influenced using smar t  algor ithms. This is a threat to fair and open democracy . In the current era of polar isation and dismantling of international  institutions, the precision and strength of such propaganda technology may quick ly cause further disruption to society . This  is one of the reasons why standards are needed for the transparency of (smar t) algor ithms and the ability to monitor them. k)Warfare 3.39 The United Nations Convention on Certain Con ventional Weapons has decided to convene exper ts in 2017 to  discuss the implications of autonomous weapons. The EESC welcomes this and suppor ts the call by Human Rights Watch  and others for a ban on autonomous weapon syste ms. The EESC believes that such a ban should be seriously analysed and  considered. However , this is not suffici ent to address adequat ely the possible uses of AI in war and conf lict situations. The  applications of AI in cyber warfare should also be examined in this UN consultation.31.8.2017 EN Official Jour nal of the European Union C 288/7
3.40 In addition, it should be ensured that AI does not fall into the hands of people or regimes that aim to use it for  terrorist activities. l)Super intellig ence 3.41 Finally , the question arises as to the possibilities and risks associate d with the development of super intellig ence.  According to Stephen Hawking, the development of general AI may spell the end for mankind. Haw king predicts that, at  that moment, AI will continue to evolve at a speed people cannot keep pace with. As a result, there are exper ts who opt for  a ‘kill switch ’ or reset-butto n, which we can use to deactivate or reset an out-of-control or super intellig ent AI syste m. 3.42 The EESC calls for a human-in-command approac h including the precondition that the development and  application of AI be responsible and safe, where machines remain mac hines and people will be able to retain control over  these mac hines at all times. The discussion on super intellig ence is impor tant in this connection, but is currently  overshado wing the debate on the impact of the current applications of AI. 4.AI for the benef it of humanity 4.1 Large commercial players have now launc hed various initiatives for the open, safe and socially responsible  development of AI (suc h as OpenAI). However , policy-mak ers cannot leave this to businesses and must play a role here.  Target ed measures and suppor t are needed for research into the societal challenges associated with AI and for the  development of safe and robust AI systems. 4.2 EU programmes, including Hor izon 2020, are well-suit ed to addressing this challeng e. The EESC has noted that  funding, particularly under the Societal Challenge s pillar of Hor izon 2020, is belo w that issued under the two other pillars,  Excellent Science and Industr ial Leadership, and is being scaled back. The EESC calls for researc h on the broad societal  challenges as well as on the social applications of AI to have an imp ortant place under the Societal Challenges pillar . 4.3 Possible cross-cutting effects of AI should also be addressed. In parallel with funding for the development of  disruptive of AI inno vations, there should also be funding for research into the societal impact of these inno vations and  ways of addressing them. 4.4 The research and development of AI that benefits humanity also require a variety of high-quality , publicly available  training and test data and real-life test environments. So far, AI infrastr ucture and a lot of quality data has only been  available from and for a limited number of private operat ors and there are obstacles to testing AI in the public sphere,  preventing AI being from applied in other areas. The development of publicly-available, high-quality data and a European  AI infrastr ucture are essential in order to achieve secure, robust and useful AI. 5.Monit oring and taking necessar y action 5.1 The broad societal impact of AI cannot yet be fully assessed. The fact that the impact will be significant is, however ,  undispute d. Developments in the field of AI are currently happening at a rapid pace, which calls for critical monitoring  from a broad perspective, in order to be able to respond appropr iately and in good time to major and disrupti ve  developments, both technical and societal, (‘game-chang ers’) in and around the area of AI. 5.2 Technical game-c hang ers may include notable or significant leaps in the development of AI capabilities, which may  be precursors to achieving general AI. Societal game-chang ers may include considerable job losses without jobs to replace  them, unsafe situations, syste m failures, unforeseen inter national developments, etc. 5.3 Policy-makers, industr y, the social partners, consumers, NGOs, educational and health institutions, and academics  and specialists from various disciplines (including (applied) AI, ethics, safety , economics, occupational science, law,  behavio ural science, psychology and philosoph y) should work together to closely monitor developments in the area of AI  and to draw up a list of these game-chang ers and keep it up to date, in order to be able to take the right measures at the  right time, be they in the form of policy , law and regulations, self-regulation or social dialogue.C 288/8 EN Official Jour nal of the European Union 31.8.2017
5.4 As the representative of European organised civil society , the EESC will shape, focus and promote this multi-  stak eholder debate on AI in the coming period. Brussels, 31 May 2017 The President   of the European Economic and Social Committee Georges DASSIS 31.8.2017 EN Official Jour nal of the European Union C 288/9
