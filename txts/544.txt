EDITOR IAL Tensimple rules forresponsible bigdata research Matthew Zook1*,Solon Barocas2,danah boyd2,3,Kate Crawford2,4,Emily Keller3,Seeta Peña Gangadharan5,Alyssa Goodman6,Rachelle Hollander7,Barbara A.Koenig8, Jacob Metcalf9,Arvind Narayanan10,Alondra Nelson11,Frank Pasquale12 1Department ofGeograph y,University ofKentucky, Lexington ,Kentucky, United States ofAmerica, 2Microsoft Research, New York, New York, United States ofAmerica, 3Data &Society, New York, New York, United States ofAmerica, 4Informatio nLaw Institute, New York University, New York, New York, United States ofAmerica, 5Departm entofMedia andCommunic ations, London School ofEconomics , London, United Kingdom ,6Harvard- Smithsonia nCenter forAstroph ysics, Harvard University, Camb ridge, Massach usetts, United States ofAmerica, 7Center forEngineeri ngEthics andSociety, National Academy ofEngineeri ng,Washingto n,DC, United States ofAmerica, 8Institute forHealth Aging, University of Californi a-San Francisco, San Francisco, Californi a,United States ofAmerica, 9Ethical Resolve, Santa Cruz, Californi a,United States ofAmerica, 10Department ofComputer Science, Princeton University , Princet on,New Jersey, United States ofAmerica, 11Departm entofSociology ,Columbia University, New York, New York, United States ofAmerica, 12Carey School ofLaw, Univers ityofMaryland ,Baltimore, Maryland ,United States ofAmerica *zook@u ky.edu Introduction The useofbigdata research methods hasgrown tremendously over thepast fiveyears inboth academia and industry. Asthesizeand complexity ofavailable datasets hasgrown, sotoohave theethical questions raised bybigdata research. These questions become increasingly urgent asdata and research agendas move well beyond those typical ofthecomputational and natural sciences, tomore directly address sensitive aspects ofhuman behavior, interaction, and health. The tools ofbigdata research areincreasingly woven into ourdaily lives, including mining digital medical records forscientific and economic insights, mapping relationships viasocial media, capturing individuals' speech and action viasensors, tracking movement across space, shaping police and security policy viaªpredictive policing,º and much more. The beneficial possibilities forbigdata inscience and industry aretempered bynew challenges facing researchers that often lieoutside their training and comfort zone. Social scientists now grapple with data structures and cloud computing, while computer scientists must contend with human subject protocols and institutional review boards (IRBs). While theconnection between individual datum and actual human beings canappear quite abstract, thescope, scale, and complexity ofmany forms ofbigdata creates arich ecosystem inwhich human participants and their communities aredeeply embedded and susceptible toharm. This complexitychallenges anynormative setofrules and makes devising universal guidelines difficult. Nevertheless, theneed fordirection inresponsible bigdata research isevident, and this article provides asetofªten simple rulesº foraddressing thecomplex ethical issues that will inevitably arise. Modeled onPLOSComutaianoliB ynoBogy's ongoing collection ofrules, the recommendations weoutline involve more nuance than thewords ªsimpleº and ªrulesº suggest. This nuance isinevitably tied toourpaper's starting premise: allbigdata research on social, medical, psychological, and economic phenomena engages with human subjects, and researchers have theethical responsibility tominimize potential harm. PLOS Computationa lBiology |https:/ /doi.org/10.13 71/journal.p cbi.1005399 March 30,2017 1/10a1111111111 a1111111111 a1111111111 a1111111111 a1111111111 OPEN ACCESS Citation: Zook M,Barocas S,boyd d,Crawford K, Keller E,Gangadharan SP,etal.(2017) Tensimple rules forresponsibl ebigdataresearch. PLoS Comput Biol13(3): e1005399. https://do i.org/ 10.1371/ journal.pcbi.10 05399 Editor: FranLewitter, Whitehead Institute, UNITED STATES Published: March 30,2017 Copyright: Thisisanopen access article, freeofall copyright, andmaybefreely reproduced, distributed, transmi tted,modifie d,builtupon, or otherwise used byanyone foranylawful purpose. Thework ismade available under theCreative Commons CC0public domain dedication. Funding: Thework forthisarticle wassupported bytheNationa lScience Foundation grant #IIS1413864. Thefunders hadnoroleinthestudy design, datacollection andanalysis, decision to publish, orpreparation ofthemanuscript. Competing interests :Theauthors have declared thatnocompeting interests exist.
The variety indata sources, research topics, and methodological approaches inbigdata belies aone-size-fits-all checklist; asaresult, these rules arelessspecific than some might hope. Rather, weexhort researchers torecognize thehuman participants and complex systems contained within their data and make grappling with ethical questions part oftheir standard workflow. Towards thisend, westructure thefirst fiverules around how toreduce thechance of harm resulting from bigdata research practices; thesecond fiverules focus onways researchers cancontribute tobuilding best practices that fittheir disciplinary and methodological approaches. Atthecore ofthese rules, wechallenge bigdata researchers who consider their data disentangled from theability toharm toreexamine their assumptions. The examples in thispaper show how often even seemingly innocuous and anonymized data have produced unanticipated ethical questions and detrimental impacts. This paper isaresult ofatwo-year National Science Foundation (NSF)-funded project that established theCouncil forBigData, Ethics, andSociety, agroup of20scholars from awide range ofsocial, natural, andcomputational sciences (http://bdes.datasociety.n et/). The Council wascharged with providing guidance totheNSF onhow tobest encourage ethical practices in scientific andengineering research, utilizing bigdata research methods andinfrastructures [1]. 1.Acknowledge that data arepeople and can doharm One ofthemost fundamental rules ofresponsible bigdata research isthesteadfast recognition that most data represent orimpact people. Simply starting with theassumption that alldata arepeople until proven otherwise places thedifficulty ofdisassociating data from specific individuals front and center. This logic isreadily evident forªriskyº datasets, e.g., social media with inflammatory language, buteven seemingly benign data cancontain sensitive and private information, e.g., itispossible toextract data ontheexact heart rates ofpeople from YouTube videos [2].Even data that seemingly have nothing todowith people might impact individuals' lives inunexpected ways, e.g., oceanographic data that change theriskprofiles ofcommunities' and properties' values orExchangeable Image Format (EXIF) records from photos that contain location coordinates and reveal thephotographer's movement oreven home location. Harm canalso result when seemingly innocuous datasets about population-wide effects are used toshape thelives ofindividuals orstigmatize groups, often without procedural recourse [3,4]. Forexample, social network maps forservices such asTwitter candetermine credit-worthiness [5],opaque recidivism scores canshape criminal justice decisions inaracially disparate manner [6],and categorization based onzipcodes resulted inlessaccess toAmazon Prime same-day delivery service forAfrican-Americans inUnited States cities [7].These high-profile cases show that apparently neutral data canyield discriminatory outcomes, thereby compounding social inequities. Other cases show that ªpublicº datasets areeasily adapted forhighly invasive research by incorporating other data, such asHague etal.'s[8]useofproperty records and geographic profiling techniques toallegedly identify thepseudonymous artist Banksy [9].Inparticular, data ungoverned bysubstantive consent practices, whether social media ortheresidual DNA we continually leave behind us,may seem public butcancause unintentional breaches ofprivacy and other harms [9,10]. Start with theassumption that data arepeople (until proven otherwise), and useittoguide your analysis. Noonegets anautomatic pass onethics. 2.Recognize that privacy ismore than abinary value Breaches ofprivacy arekeymeans bywhich bigdata research candoharm, and itisimportant torecognize that privacy iscontextual [11] and situational [12], notreducible toasimple Ten Simple Rules forRespons ibleBigData Researc h PLOS Computationa lBiology |https:/ /doi.org/10.13 71/journal.p cbi.1005399 March 30,2017 2/10
public/private binary. Just because something hasbeen shared publicly does notmean anysubsequent usewould beunproblematic. Looking atasingle Instagram photo byanindividual has different ethical implications than looking atsomeone's fullhistory ofallsocial media posts. Privacy depends onthenature ofthedata, thecontext inwhich they were created and obtained, and theexpectations and norms ofthose who areaffected. Understand that your attitude towards acceptable useand privacy may notcorrespond with those whose data youare using, asprivacy preferences differ across and within societies. Forexample, Tene and Polonetsky [13] explore how pushing past social norms, particularly innovel situations created bynew technologies, isperceived byindividuals asªcreepyº even when they donotviolate data protection regulations orprivacy laws. Social media apps that utilize users' locations topush information, corporate tracking ofindividuals' social media and private communications togain customer intelligence, and marketing based onsearch patterns have been perceived bysome tobeªcreepyº oreven outright breaches ofprivacy. Likewise, distributing health records isanecessary part ofreceiving health care, butthissame sharing brings new ethical concerns when itgoes beyond providers tomarketers. Privacy also goes beyond single individuals and extends togroups [10]. This isparticularly resonant forcommunities who have been onthereceiving end ofdiscriminatory data-driven policies historically, such asthepractice ofredlining [14, 15]. Other examples include community mapsÐmade toidentify problematic properties oranassertion ofland rightsÐbeing reused byothers toidentify opportunities forredevelopment orexploitation [16]. Thus, reusingaseemingly public dataset could runcounter totheoriginal privacy intents ofthose who created itand raise questions about whether itrepresents responsible bigdata research. Situate and contextualize your data toanticipate privacy breaches and minimize harm. The availability orperceived publicness ofdata does notguarantee lack ofharm, nordoes itmean that data creators consent toresearchers using their data. 3.Guard against thereidentification ofyour data Itisproblematic toassume that data cannot bereidentified. There arenumerous examples of researchers with good intentions and seemingly good methods failing toanonymize data sufficiently toprevent thelater identification ofspecific individuals [17]; inother cases, these efforts were extremely superficial [18, 19]. When datasets thought tobeanonymized arecombined with other variables, itmay result inunexpected reidentification, much likeachemical reaction resulting from theaddition ofafinal ingredient. While theidentificatory power ofbirthdate, gender, and zipcode iswell known [20], there areanumber ofother parametersÐparticularly themetadata associated with digital activityÐ that may beasoreven more useful foridentifying individuals [21]. Surprising tomany, unlabeled network graphsÐsuch aslocation and movement, DNA profiles, callrecords from mobile phone data, and even high-resolution satellite images oftheearthÐcan beused to reidentify people [22]. More important than specifying thevariables that allow forreidentification, however, istherealization that itisdifficult torecognize these vulnerable points apriori [23]. Factors discounted today asirrelevant orinherently harmlessÐsuch asbattery usageÐ may very well prove tobeasignificant vector ofpersonal identification tomorrow [24]. For example, theaddition ofspatial location canturn social media posts into ameans ofidentifyinghome location [25], and Google's reverse image search canconnect previously separate personal activitiesÐsuch asdating and professional profilesÐin unanticipated ways [26]. Even data about groupsÐªaggregate statisticsºÐcan have serious implications ifthey reveal that certain communities, forexample, suffer from stigmatized diseases orsocial behavior much more than others [27]. Ten Simple Rules forRespons ibleBigData Researc h PLOS Computationa lBiology |https:/ /doi.org/10.13 71/journal.p cbi.1005399 March 30,2017 3/10
Identify possible vectors ofreidentification inyour data. Work tominimize them inyour published results tothegreatest extent possible. 4.Practice ethical data sharing Forsome projects, sharing data isanexpectation ofthehuman participants involved and thus akeypart ofethical research. Forexample, inrare genetic disease research, biological samples areshared inthehope offinding cures, making dissemination acondition ofparticipation. In other projects, questions ofthelarger public goodÐan admittedly difficult todefine category Ðprovide compelling arguments forsharing data, e.g., theNIH-sponsored database ofGenotypes and Phenotypes (dbGaP), which makes deidentified genomic data widely available to researchers, democratizing access, orthejustice claim made bytheInstitute ofMedicine about thevalue ofmandating that individual-level data from clinical trials beshared among researchers[28]. Asking participants forbroad, asopposed tonarrowly structured consent fordownstream data management makes iteasier toshare data. Careful research design and guidance from IRBs canhelp clarify consent processes. However, wecaution that even when broad consent wasobtained upfront, researchers should consider thebest interests ofthehuman participant, proactively considering thelikelihood ofprivacy breaches and reidentification issues. This isofparticular concern forhuman DNA data, which isuniquely identifiable. These types ofprojects, howeverÐin which rules ofuseand sharing arewell governed by informed consent and right ofwithdrawalÐare increasingly theexception rather than therule forbigdata. Inourdigital society, wearefollowed bydata clouds composed ofthetrace elements ofdaily lifeÐcredit card transactions, medical testresults, closed-circuit television (CCTV) images and video, smart phone apps, etc.Ðcollected under mandatory terms ofservice rather than responsible research design overseen byuniversity compliance officers. While wemight wish tohave thestandards ofinformed consent and right ofwithdrawal, these informal bigdata sources aregathered byagents other than theresearcherÐprivate software companies, state agencies, and telecommunications firms. These data areonly accessible to researchers after their creation, making itimpossible togain informed consent apriori, and contacting thehuman participants retroactively forpermission isoften forbidden bythe owner ofthedata orisimpossible todoatscale. Ofcourse, researchers within software companies and state institutions collecting these data have aspecial responsibility toaddress theterms under which data arecollected; butthat does notexempt theend-user ofshared data. Inshort, theburden ofethical use(see Rules 1to 3)and sharing isplaced ontheresearcher, since theterms ofservice under which thehuman subjects' data were produced canoften beextremely broad with little protection forbreaches ofprivacy. Inthese circumstances, researchers must balance therequirements from funding agencies toshare data [29] with their responsibilities tothehuman beings behind thedata they acquired. Aresearcher needs toinform funding agencies about possible ethical concerns before theresearch begins and guard against reidentification before sharing. Share data asspecified inresearch protocols, butproactively address concerns ofpotential harm from informally collected bigdata. 5.Consider thestrengths and limitations ofyour data; bigdoes not automatically mean better Inorder todoboth accurate and responsible bigdata research, itisimportant toground datasetsintheir proper context including conflicts ofinterests. Context also affects every stage of research: from data acquisition, tocleaning, tointerpretation offindings, and dissemination of theresults. During thestep ofdata acquisition, itiscrucial tounderstand both thesource of Ten Simple Rules forRespons ibleBigData Researc h PLOS Computationa lBiology |https:/ /doi.org/10.13 71/journal.p cbi.1005399 March 30,2017 4/10
thedata and therules and regulations with which they were gathered. This isespecially important incases ofresearch conducted inrelatively loose regulatory environments, inwhich useof answers toresearch questions may conflict with theexpectations ofthose who provided the data. One possible approach might betheethical norms employed totrack theprovenance of artifacts, often incooperation and collaboration with thecommunities from which they come (e.g., archaeologists working inindigenous communities todetermine thedisposition ofmaterialculture). Inasimilar manner, computer scientists usedata lineage techniques totrack the evolution ofadataset and often totrace bugs inthedata. Being mindful ofthedata's context provides thefoundation forclarifying when your data and analysis areworking and when they arenot. While itistempting tointerpret findings based onbigdata asaclear outcome, akeystep within scientific research isclearly articulating what data oranindicator represent and what they donot. Areyour findings asclear-cut if your interpretation ofasocial media posting switches from arecording offacttotheperformance ofasocial identity? Given themessy, almost organic nature ofmany datasets derived from social actions, itisfundamental that researchers besensitive tothepotential multiple meanings ofdata. Forexample, isaFacebook post oranInstagram photo best interpreted asanapproval/disapproval ofaphenomenon, asimple observation, oraneffort toimprove status within afriend network? While anyofthese interpretations arepotentially valid, thelack ofcontext makes it even more difficult tojustify thechoice ofoneunderstanding over another. Reflecting onthe potential multiple meanings ofdata fosters greater clarity inresearch hypotheses and also makes researchers aware oftheother potential uses oftheir data. Again, theactofinterpretation isahuman process, and because thejudgments ofthose (re)using your data may differ from your own, itisessential toclarify both thestrengths and shortcomings ofthedata. Document theprovenance and evolution ofyour data. Donotoverstate clarity; acknowledge messiness and multiple meanings. 6.Debate thetough, ethical choices Research involving human participants atfederally funded institutions isgoverned byIRBs charged with preventing harm through well-established procedures and arefamiliar tomany researchers. IRBs, however, arenotthesole arbiter ofethics; many ethical issues involving big data areoutside oftheir governance mandate. Precisely because bigdata researchers often encounter situations that areforeign tooroutside ofthemandate ofIRBs, weemphasize the importance ofdebating theissues within groups ofpeers. Rather than abug, thelack ofclear-cut solutions and governance protocols should bemore appropriately understood asafeature that researchers should embrace within their own work. Discussion and debate ofethical issues isanessential part ofprofessional developmentÐboth within and between disciplinesÐas itcanestablish amature community ofresponsible practitioners. Bringing these debates into coursework and training canproduce peer reviewers who areparticularly well placed toraise these ethical questions and spur recognition oftheneed for these conversations. Aprecondition ofanyformal ethics rules orregulations isthecapacity tohave such openended debates. Asdigital social scientist and ethicist Annette Markham [30] writes, ªwe can make [data ethics] aneasier topic tobroach byaddressing ethics asbeing about choices we make atcritical junctures; choices that willinvariably have impact.º Given thenature ofbig data, bringing technical, scientific, social, and humanistic researchers together onprojects enables thisdebate toemerge asastrength because, ifdone well, itprovides themeans to understand theethical issues from arange ofperspectives and disrupt thesilos ofdisciplines Ten Simple Rules forRespons ibleBigData Researc h PLOS Computationa lBiology |https:/ /doi.org/10.13 71/journal.p cbi.1005399 March 30,2017 5/10
[31]. There areanumber ofgood models forinterdisciplinary ethics research, such asthe trainings offered bytheScience and Justice research center attheUniversity ofCalifornia, Santa Cruz [32] and Values inDesign curricula [33]. Research ethics consultation services, available atsome universities asaresult oftheClinical and Translational Science Award (CTSA) program oftheNational Institutes ofHealth (NIH), canalso beresources forresearchers[34]. Some ofthebetter-known ªbig dataº ethical casesÐi.e., theFacebook emotional contagion study [35]Ðprovide extremely productive venues forcross-disciplinary discussions. Why might onesetofscholars seethisasarelatively benign approach while other groups seesignificant ethical shortcomings? Where doresearchers differ indrawing thelinebetween responsibleand irresponsible research and why? Understanding thedifferent ways people discuss these challenges and processes provides animportant check forresearchers, especially ifthey come from disciplines notfocused onhuman subject concerns. Moreover, thehigh visibility surrounding these events means that (for better orworse) they represent theªpublicº view ofbigdata research, and becoming anactive member ofthisconversation ensures that researchers cangive voice totheir insights rather than simply being at thereceiving end ofpolicy decisions. Inaneffort tohelp these debates along, theCouncil for BigData, Ethics, and Society hasproduced anumber ofcase studies focused specifically onbig data research and awhite paper with recommendations tostart these important conversations (http://bdes.datasociety.net/o utput/). Engage your colleagues and students about ethical practice forbigdata research. 7.Develop acode ofconduct foryour organization, research community, orindustry The process ofdebating tough choices inserts ethics directly into theworkflow ofresearch, making ªfaking ethicsº asunacceptable asfaking data orresults. Internalizing these debates, rather than treating them asanafterthought oraproblem tooutsource, iskeyforsuccessful research, particularly when using trace data produced bypeople. This isrelevant forallresearch including those within industry who have privileged access tothedata streams ofdigital daily life.Public attention totheethical useofthese data should notbeavoided; after all,these datasets arebased onaninfrastructure that billions ofpeople areusing tolivetheir lives, and there isacompelling public interest that research isdone responsibly. One ofthebest ways tocement thisindaily practice istodevelop codes ofconduct foruse inyour organization orresearch community and forinclusion informal education and ongoingtraining. The codes canprovide guidance inpeer review ofpublications and infunding consideration. Inpractice, ahighly visible case ofunethical research brings problems toan entire field, notjusttothose directly involved. Moreover, designing codes ofconduct makes researchers more successful. Issues that might otherwise beignored until they blow upÐe.g., Areweabiding bytheterms ofservice orusers' expectations? Does thegeneral public consider ourresearch ªcreepyº? [13]Ðcan beaddressed thoughtfully rather than inascramble fordamagecontrol. This isparticularly relevant topublic-facing private businesses interested inavoidingpotentially unfavorable attention. Anadditional and longer-term advantage ofdeveloping codes ofconduct isthat itisclear that change iscoming tobigdata research. The NSF funded theCouncil forBigData, Ethics, and Society asameans ofgetting infront ofadeveloping issue and pending regulatory changes within federal rules fortheprotection ofhuman subjects that arecurrently under review [1]. Actively developing rules forresponsible bigdata research within aresearch community isa keyway researchers canjoin thisongoing process. Ten Simple Rules forRespons ibleBigData Researc h PLOS Computationa lBiology |https:/ /doi.org/10.13 71/journal.p cbi.1005399 March 30,2017 6/10
Establish appropriate codes ofethical conduct within your community. Make industry researchers and representatives ofaffected communities active contributors tothisprocess. 8.Design your data and systems forauditability Although codes ofconduct willvary depending onthetopic and research community, aparticularly important element isdesigning data and systems forauditability. Responsible internal auditing processes flow easily into audit systems and also keep track offactors that might contribute toproblematic outcomes. Developing automated testing processes forassessing problematic outcomes and mechanisms forauditing other's work during review processes canhelp strengthen research asawhole. The goal ofauditability istoclearly document when decisions aremade and, ifnecessary, backtrack toanearlier dataset and address theissue attheroot (e.g., ifstrategies foranonymizing data arecompromised). Designing forauditability also brings direct benefits toresearchers byproviding amechanism fordouble-checking work and forcing oneself tobeexplicit about decisions, increasing understandability and replicability. Forexample, many types ofsocial media and other trace data areunstructured, and answers toeven basic questions such asnetwork ties, location, and randomness depend onthesteps taken tocollect and collate data. Systems ofauditability clarifyhow different datasets (and thesubsequent analysis) differ from each other, aiding understanding and creating better research. Plan forand welcome audits ofyour bigdata practices. 9.Engage with thebroader consequences ofdata and analysis practices Itisalso important forresponsible bigdata researchers tothink beyond thetraditional metrics ofsuccess inbusiness and theacademy. Forexample, theenergy demands fordigital daily life, akeysource ofbigdata forsocial science research, aresignificant inthiseraofclimate change [36]. How might bigdata research lessen theenvironmental impact ofdata analytics work? Forexample, should researchers take thelead inasking cloud storage providers and data processing centers toshift tosustainable and renewable energy sources? Asimportant and publicly visible users ofthecloud, bigdata researchers collectively represent aninterest group that could rally behind such acallforchange. The pursuit ofcitations, reputation, ormoney isakeyincentive forpushing research forward, butitcanalso result inunintended and undesirable outcomes. Incontrast, wemight ask towhat extent isaresearch project focused onenhancing thepublic good ortheunderserved ofsociety? Arequestions about equity orpromoting other public values being addressed in one's data streams, orisabigdata focus rendering them invisible orirrelevant toyour analysis [37]? How canincreasingly vulnerable yetfundamentally important public resourcesÐsuch as state-mandated cancer registriesÐbe protected? How might research aidorinhibit different business and political actors? While allbigdata research need nottake upsocial and cultural questions, afundamental aim ofresearch goes beyond understanding theworld toconsidering ways toimprove it. Recognize that doing bigdata research hassocietal-wide effects. 10.Know when tobreak these rules The final (and counterintuitive) rule isthecharge torecognize when itisappropriate tostray from these rules. Forexample, intimes ofnatural disaster orapublic health emergency, itmay beimportant totemporarily putaside questions ofindividual privacy inorder toserve alarger Ten Simple Rules forRespons ibleBigData Researc h PLOS Computationa lBiology |https:/ /doi.org/10.13 71/journal.p cbi.1005399 March 30,2017 7/10
public good. Likewise, theuseofgenetic orother biological data collected without informed consent might bevital inmanaging anemerging disease epidemic. Moreover, besure toreview theregulatory expectations and legal demands associated with protection ofprivacy within your dataset. After all,thisisanexceedingly slippery slope, so before following thisrule (tobreak others), becautious that theªemergencyº isnotsimply a convenient justification. The best way toensure thisistobuild experience inengaging inthe tough debates (Rule 6),constructing codes ofconduct (Rule 7),and developing systems for auditing (Rule 8).The more mature thecommunity ofresearchers isabout their processes, checks, and balances, thebetter equipped itistoassess when breaking therules isacceptable. It may very well bethat youdonotcome toafinal clear setofpractices. After all,justasprivacy isnotbinary (Rule 2),neither isresponsible research. Ethics isoften about finding agood or better, butnotperfect, answer, and itisimportant toask(and trytoanswer) thechallenging questions. Only through thisengagement canaculture ofresponsible bigdata research emerge. Understand that responsible bigdata research depends onmore than meeting checklists. Conclusion The goal ofthissetoftenrules istohelp researchers dobetter work and ultimately become more successful while avoiding larger complications, including public mistrust. Toachieve this, however, scholars must shift from amindset that isrigorous when focused ontechniques and methodology and naïve when itcomes toethics. Statements totheeffect that ªData is[sic] already publicº [38] areunjustified simplifications ofmuch more complex data ecosystems embedded ineven more complex and contingent social practices. Data arepeople, and to maintain arigorously naïve definition tothecontrary [18] willendupharming research efforts inthelong runaspushback comes from thepeople whose actions and utterances aresubject to analysis. Inshort, responsible bigdata research isnotabout preventing research butmaking sure that thework issound, accurate, and maximizes thegood while minimizing harm. The problems and choices researchers face arereal, complex, and challenging and sotoomust beour response. Wemust treat bigdata research with therespect that itdeserves and recognize that unethical research undermines theproduction ofknowledge. Fantastic opportunities tobetter understand society and ourworld exist, butwith these opportunities also come theresponsibilitytoconsider theethics ofourchoices intheeveryday practices and actions ofourresearch. The Council forBigData, Ethics, and Society (http://bdes.datasociet y.net/) provides aninitial setofcase studies, papers, and even tensimple rules forguiding thisprocess; itisnow incumbent onyoutouseand improve these inyour research. Acknowledgmen ts This article also benefitted from theinput ofGeoff Bowker and Helen Nissenbaum. References 1. Metcalf J,boyd d,Keller E.Perspecti vesonBigData, Ethics, andSociety. Council forBigData, Ethics, andSociety. 2016. http://bdes .datasociety.n et/council-ou tput/perspec tives-on-big- data-eth ics-andsociety/. Accessed 31May 2016. 2. WuHY,Rubinstein M,Shih E,Guttag JV,Durand F,Freeman WT. Eulerian video magnificatio nfor revealing subtle changes intheworld. Eulerian Video Magnificatio nforRevealing Subtle Changes in theWorld. ACM Transact ions onGraphics. 2012; 31(4). Ten Simple Rules forRespons ibleBigData Researc h PLOS Computationa lBiology |https:/ /doi.org/10.13 71/journal.p cbi.1005399 March 30,2017 8/10
3. Crawford K,Schultz J.Bigdata anddueprocess: Toward aframework toredress predictive privacy harms. BCL Rev. 2014; 55:93±128. 4. Barocas S,Selbst AD.Bigdata's disparat eimpact. California Law Review. 2016; 104(3): 671±732. 5. Danyllo WA, Alisson VB,Alexandre ND, Moacir LM,Jansepetr usBP,Oliveira RF.Identifying relevant users andgroups inthecontext ofcredit analysis based ondata from Twitter. InCloud andGreen Computing (CGC), 2013 Third Internat ional Conference on2013 Sep 30(pp. 587±592). IEEE. 6. Angwin J,Larson J,Mattu S,Kirchner L.Machine bias. ProPublica. 23May 2016. https://www . propublica.o rg/article/mac hine-bias-r isk-assessme nts-in- criminal-sente ncing. Accesse d4September 2016. 7. Ingold D,Spencer S.Amazon Doesn't Consider theRace ofItsCustome rs.Should It?Bloomb erg.com 21April 2016. http://www .bloomberg.c om/graphic s/2016-am azon-same- day/. Accessed 12June 2016. 8. Hauge MV, Stevenson MD, Rossmo DK,LeComber SC.Tagging Banksy: using geographic profiling to investigate amodern artmyster y.Journal ofSpatial Science. 2016; 61(1):185± 90. 9. Metcalf J,Crawford K.Where areHuman Subjects inBigData Resea rch? The Emerging Ethics Divide. The Emergi ngEthics Divide. BigData andSociety, 2016. 10. Zwitter A.Bigdata ethics. BigData &Society. 2014; 1(2). 11. Nissenbaum H.Privacy incontext :Technology ,policy, andtheintegrity ofsocial life. Stanfor dUniversityPress; 2009. 12. Marwick AE.boyd d.Networke dprivacy: How teenagers negotiate context insocial media. New Media &Society. 2014:1461444 814543 995. 13. Tene O,Polonets kyJ.Theory ofCreepy: Technolog y,Privacy andShifting Social Norms, A.Yale JL& Tech. 2013; 16:59. 14. Massey DS,Denton NA.American aparth eid:Segregatio nandthemaking oftheundercl ass. Harvard University Press; 1993. 15. Davidow B.Redlining forthe21st Century. The Atlanti c.5March 2014. http://www .theatlantic .com/ business/ar chive/2014 /03/red lining-for-the-2 1st-centur y/284235 /.Accesse d31May 2016. 16. Young JC,Gilmore MP. Subaltern empowermen tintheGeoweb: Tensions between publicity andprivacy. Antipode. 2014; 46(2):574± 91. 17. Barbaro M,Zeller T,Hansell S.Aface isexposed forAOL searcher no.4417749. New York Times. 2006 Aug 9;9. 18. Cox J.70,000 OkCupid Users Just Had Their Data Published .Motherboard. 12May 2016. http:// motherbo ard.vice.com/ read/70000- okcupid-us ers-just-had- their-data- publishe d.Accessed 12June 2016. 19. Pandurang anV.OnTaxis andRainbows :Lessons from NYC's improperly anonymiz edtaxilogs. Medium. 2014. https:// medium.com /@vijayp/of-tax is-and-rain bows-f6bc289 679a1. Accessed 10 Novemb er2015. 20. Sweeney L.k-anonymity: Amodel forprotectin gprivacy. Interna tional Journal ofUncertaint y,Fuzziness andKnowled ge-Based Systems. 2002; 10(05):557 ±70. 21. Zimmer M.ªBut thedata isalready publicº :ontheethics ofresearch inFacebook .Ethics andinformationtechnolog y.2010; 12(4):313± 25. 22. Klouman nIM,Kleinberg JM.Commun itymembership identifi cation from small seed sets. InProceedings ofthe20th ACM SIGKDD internationa lconferen ceonKnowled gediscovery anddata mining 2014 Aug 24(pp. 1366±1375) .ACM. 23. Narayanan A,Huey J,Felten EW. Aprecauti onary approach tobigdata privacy. InData protection on themove 2016 (pp. 357±38 5).Springer Netherlan ds. 24. Michalevs kyY,Schulman A,Veerapand ianGA, Boneh D,Nakibly G.Powerspy: Location tracking using mobile device power analysis. In24th USENIX Security Sympos ium(USENIX Security 15)2015 (pp. 785±800). 25. Shelton T,Poorth uisA,Zook M.Social media andthecity: Rethinking urban socio-spatia linequality using user-g enerated geographic informati on.Landscape andUrban Planning. 2015; 142:198±211 . 26. Acquisti A,Gross R,Stutzman F.Face recognition andprivacy intheageofaugmente dreality. Journal ofPrivacy andConfidenti ality. 2014; 6(2): 1±20. 27. Homer N,Merriman B,Nelson SF.BFAST: analignme nttoolforlarge scale genome resequen cing. PLoS ONE. 2009; 4(11):e776 7.https://doi.or g/10.137 1/journal.po ne.0007767 PMID: 19907642 28. LoB.Sharing clinical trialdata: maximizing benefits, minimizing risk. Jama. 2015; 313(8):793 ±4.https:// doi.org/10.10 01/jama.20 15.292 PMID: 25594500 Ten Simple Rules forRespons ibleBigData Researc h PLOS Computationa lBiology |https:/ /doi.org/10.13 71/journal.p cbi.1005399 March 30,2017 9/10
29. Goodman A,Pepe A,Blocker AW, Borgma nCL,Cranmer K,Crosas M,etal.Ten simple rules forthe care andfeeding ofscientific data. PLoS Compu tBiol.; 10(4). 30. Markham A.OKCup iddata release fiasco: It'stime torethink ethics education. Medium .Points 18May 2016. https://p oints.dataso ciety.net/ok cupid-data-r elease-fias co-ba0388348 cd#.g4ofb pnc6. Accessed 12June 2016. 31. Ford H.BigData andSmall: Collabora tions between ethnographe rsanddata scientists .BigData & Society. 2014; 1(2): 32. Science &Justice Research Center (Collaboratio nsGroup. Experi ments incollaboration :interdisci plinarygraduate education inscience andjustice. PLoS Biol. 2013 Jul30;11(7):e100 1619. 33. Knobel C,Bowker GC. Values indesign. Commun ications oftheACM. 2011; 54(7):26±8 . 34. Cho MK, Tobin SL,Greely HT,McCormi ckJ,Boyce A,Magnus D.Research ethics consultation :The Stanford experien ce.IRB. 2008;(6):1± 6.PMID: 191197 57 35. boyd d.Untangling resear chandpractice: What Facebook 'sªemotion alcontagion ºstudy teaches us. Research Ethics. 2016; 12(1):4±1 3. 36. Cook G,Dowdall T,Pomera ntzD,Wang Y.Clicking clean: how companies arecreating thegreen internet.Greenpea ceInc., Washingto n,DC. 2014. http://w ww.greenpea ce.org/usa/w p-content /uploads/ legacy/Gl obal/usa/p lanet3/PDF s/clickingc lean.pdf 37. Zook MA, Graham M.Mapping DigiPlace: geocode dInternet data andtherepresentat ionofplace. Environment andPlanning B:Planning andDesign. 2007 Jun1;34(3):466± 82. 38. Zimmer M.OkCupid Study Reveals thePerils ofBig-Data Science. Wired. 14May 2016. https:// www. wired.com/ 2016/05/ok cupid-study -reveals-per ils-big-data- science/. Accesse d12June 2016. Ten Simple Rules forRespons ibleBigData Researc h PLOS Computationa lBiology |https:/ /doi.org/10.13 71/journal.p cbi.1005399 March 30,2017 10/10
