The Impact of Artificial  Intelligence on Learning,  Teaching, and Education  Policies for the future  Author: T uomi, Ilkka   Editors: Cabrera, Marcelino; Vuorikari,  Riina; Punie, Yves  EUR 29442 EN
i  This publication is a Science for Policy report by the Joint Research Centre (JRC), the European Commission’s  science and knowledge service. It aims to provide evidence-based scientific support to the European  policymaking process. The scientific output expressed does not imply a policy position of the European  Commission. Neither the European Commission nor any person acting on behalf of the Commission is  responsible for the use that might be made of this publication.  Contact information   Address: Edificio Expo. C/ Inca Garcilaso 3, E-41092 Seville (Spain)  Email: marcelino.cabrera@ec.europa.eu  Tel.: +34 9544 88246  EU Sc ience Hub  https://ec.europa.eu/jrc  JRC113226  EUR 29442 EN  PDF ISBN 978-92-79-97257-7 ISSN 1831-9424 doi:10.2760/12297  Luxembourg: Publications Office of the European Union, 2018  © European Union, 2018   The reuse policy of the European Commission is implemented by Commission Decision 2011/833/EU of 12  December 2011 on the reuse of Commission documents (OJ L 330, 14.12.2011, p. 39). Reuse is authorised,  provided the source of the document is acknowledged and its original meaning or message is not distorted. The  European Commission shall not be liable for any consequence stemming from the reuse. For any use or  reproduction of photos or other material that is not owned by the EU, permission must be sought directly from  the copyright holders.  All images © European Union unless otherwise specified  How to cite this report: Tuomi, I. The Impact of Artificial Intelligence on Learning, Teaching, and Education.  Policies for the future, Eds. Cabrera, M., Vuorikari, R & Punie, Y., EUR 29442 EN, Publications Office of the  European Union , Luxembourg, 2018, ISBN 978-92-79-97257-7, doi:10.2760/12297, JRC113226. Title: The Impact of Artificial Intelligence on Learning, Teaching, and Education  Abstract  This report describes the current state of the art in artificial intelligence (AI) and its potential impact for  learning, teaching, and education. It provides conceptual foundations for well-informed policy-oriented work,  research, and forward-looking activities that address the opportunities and challenges created by recent  developments in AI. The report is aimed for policy developers, but it also makes contributions that are of  interest for AI technology developers and researchers studying the impact of AI on economy, society, and the  future of education and learning. 
i i Contents  Preface ................................................................................................................. 1 Executive summary .................................. ............................................................. 2 1 Introduction ...................................................................................................... 5 2 What is Artificial Intelligence? ............................................................................. 7 2.1 A three-level model of action for analysing AI and its impact ............................. 7 2.2 Three types of AI ....................................................................................... 10 2.2.1  Data-based neural AI ......................................................................... 10 2.2.2  Logic- and knowledge-based AI ........................................................... 12 2.3 Recent and future developments in AI .......................................................... 13 2.3.1  Models of learning in data-based AI ..................................................... 15 2.3.2  Towards the future............................................................................. 16 2.4 AI impact on skill and competence demand ................................................... 17 2.4.1  Skills in economic studies of AI impact ................................................. 18 2.4.2  Skill-biased and task-biased models of technology impact ....................... 20 2.4.3  AI capabilities and task substitution in the three-level model ................... 21 2.4.4  Trends and transitions ........................................................................ 22 2.4.5  Neural AI as data-biased technological change ...................................... 23 2.4.6  Education as a creator of capability platforms ........................................ 23 2.4.7  Direct AI impact on advanced digital skills demand ................................ 25 3 Impact on learning, teaching, and education ....................................................... 27 3.1 Current developments ................................................................................ 27 3.1.1  “No AI without UI” ............................................................................. 28 3.2 The impact of AI on learning ....................................................................... 28 3.2.1  Impact on cognitive development ........................................................ 30 3.3 The impact of AI on teaching ....................................................................... 31 3.3.1  AI-generated student models and new pedagogical opportunities............. 31 3.3.2  The need for future-oriented vision regarding AI .................................... 32 3.4 Re-thinking the role of education in society ................................................... 32 4 Policy challenges ............................................................................................. 34 References ......................................... ................................................................ 37
  1   Preface    Artificial Intelligence (AI) is currently high on t he political and research agendas around the  world. With the emergence of every new technology, there is always both a lot of hype and  scepticism around its implications for society and the economy. Although acknowledging  that the foundations for AI have been already aroun d for several decades, recent  technological breakthroughs are accelerating what A I could do. This study looks at what  this could mean for learning, teaching, and educati on. It aims to provide a critical review  and prospective angle on relevant AI developments a s a basis for well-informed policyoriented discussions about the future of these doma ins.     This report is a contribution to the Digital Educat ion Action Plan 1 which foresees policy  research and guidance on the impact and potential o f digital technologies in education. It is  done on behalf of the Directorate-General for Educa tion, Youth, Sport and Culture,  authored by Ilkka Tuomi and edited by the JRC. Anot her report, appraising AI from  different perspectives, entitled "Artificial Intell igence: A European perspective", will be  released soon under the label of JRC flagship repor ts, providing an overall assessment of  opportunities and challenges of AI from a European outlook, and supporting the  development of European action in the global AI con text.    The JRC has carried out research on Learning and Skills for the Digital Era  since 2005. It  aims to provide evidence-based policy support to th e European Commission and its  Member States on how to harness the potential of di gital technologies to encourage  innovation in education and training practices; imp rove access to lifelong learning; and  impart the new (digital) skills and competences nee ded for employment, personal  development and social inclusion. More than 20 majo r studies have been undertaken on  these issues, resulting in more than 120 different publications.   Recent work has focused on the development of digit al competence frameworks for citizens  (DigComp ), educators ( DigCompEdu ), educational organisations ( DigCompOrg ) and  consumers ( DigCompConsumers ). A framework for opening up higher education  institutions ( OpenEdu ) was also published in 2016, along with a competen ce framework for  entrepreneurship ( EntreComp ). Some of these frameworks are accompanied by (sel f-)  assessment instruments. The JRC is also entrusted t o develop a future framework for  personal and social development, including learning  to learn. Additional research has been  undertaken on Learning Analytics, MOOCs ( MOOCKnowledge , MOOCs4inclusion ),  Computational thinking ( Computhink ) and policies for the integration and innovative u se of  digital technologies in education ( DigEduPol ).   More information on all our studies can be found on  the JRC Science hub:  https://ec.europa.eu/jrc/en/research-topic/learning -and-skills.                                                     1  Communication from the Commission to the European  Parliament, the Council, the European Economic and   Social Committee and the Committee of the Regions o n the Digital Education Action Plan (COM(2018) 237  final). 
  2   Executive summary    At the November 2017 Gothenburg Summit, the Commiss ion presented the  Communication 'Strengthening European Identity thro ugh Education and Culture', that  set out a vision for a European Education Area and announced a dedicated Digital  Education Action Plan 2, which aims to foster digital skills and competenc es for all citizens.  The Action Plan focuses on implementation and the n eed to stimulate, support and scale  up purposeful use of digital and innovative educati on practices. It has three priorities:  making better use of digital technology for teachin g and learning; developing relevant  digital competences and skills for the digital tran sformation; and improving education  through better data analysis and foresight. Artific ial Intelligence (AI) will have an impact  on all these, and in the last priority the Communic ation specifically invites to explore its  impact in education and training through pilots. This policy foresight report suggests  that in the next years AI will change learning, teach ing, and education . The  speed of technological change will be very fast, an d it will create high pressure to  transform educational practices, institutions, and policies. It is therefore important to  understand the potential impact of AI on learning, teaching, and education, as well as on  policy development.     AI is currently high on the political agendas aroun d the world. Several EU Member States  have declared it as a political priority. Influenti al studies now suggest that perhaps one in  two occupations in the industrialized countries is likely to become automated using  already existing AI technologies. Policy makers at the European Parliament have  highlighted the importance of the issue, and the Eu ropean Commission, in its 2018  annual work programme, sets its wish to make the mo st of AI, which will increasingly  play a role in our economies and societies 3. AI is now often called “the next  electricity.”  The transformative impact of general purpose techn ologies, like AI,  however, becomes visible only gradually, when socie ties and economies reinvent  themselves as users of new technologies. Technologi cal change brings social and cultural  change that is reflected in lifestyles, norms, poli cies, social institutions, skills, and the  content and forms of education.    Wide availability of cheap processing power and vas t amounts of data in recent years  have enabled impressive breakthroughs in machine le arning and created extraordinary  commercial and research interest in artificial neur al networks, i.e. computational models  based on the structure and functions of biological neural networks. Neural AI, and  machine learning methods associated with it, are no w used for real-time language  processing and translation, image analysis, driverl ess cars and autonomous vehicles,  automated customer service, fraud detection, proces s control, synthetic art, service  robots, and in many other applications. Although some of this excitement may be  based on unrealistic expectations and limited knowledge o f the complexities of  the underpinning technologies, it is reasonable to exp ect that the recent  advances in AI and machine learning will have profound impacts on future  labour markets, competence requirements, as well as in learning and teaching  practices.  As educational systems tend to adapt to the requir ements of the industrial  age, AI could make some functions of education obso lete and emphasize others. It may  also enable new ways of teaching and learning.                                                2  Communication from the Commission to the European  Parliament, the Council, the European Economic and   Social Committee and the Committee of the Regions o n the Digital Education Action Plan (COM(2018) 237  final).  3  Communication from the Commission to the European  Parliament, the Council, the European Economic and   Social Committee and the Committee of the Regions C ommission Work Programme 2018 - An agenda for a  more united, stronger and more democratic Europe (C OM(2017) 650 final). 
  3   In the European framework programmes for research a nd technological development, AI  technologies have been studied and applied in educa tional contexts in many projects  focusing on technology-enabled learning. These proj ects have used technologies that  have deep ties with AI research, including natural language processing, pattern  recognition, intelligent tutoring, probabilistic AI  planning, intelligent agents, AI game  engines, and adaptive user models in personalized l earning environments (PLE). The  impact of these technologies in practical educational  settings has been  relatively modest until recently. Technical developme nts over the recent years,  however, suggest that the situation may be changing ra pidly.      The main intent of the present report is to help ed ucators and policymakers to make  sense of these potentially very important technical  developments. To understand the  impact of AI, we need to understand what AI is and what it can do. In the current “AI  avalanche” this is not always easy. Deep expertise in AI technology is scarce, and many  educators and policymakers now struggle to get up t o date with basic knowledge in this  area. In the midst of self-driving cars, speaking r obots, and the flood of “AI miracles”, it  may be easy to think that AI is rapidly becoming super  intelligent, and gain all  the good and evil powers awarded to it in popular culture.  This, of course, is not  the case. The current AI systems are severely limit ed, and there are technical,  social, scientific, and conceptual limits to what th ey can do.  Perhaps surprisingly,  well-established research on human learning provide s important tools and concepts that  help us understand the state-of-the-art and future of AI. Many current AI systems use  rather simplified models of learning and biological  intelligence, and learning theories thus  help us gain better understanding of the capabiliti es of current AI systems.     There will be great economic incentives to use AI t o address problems that are currently  perceived as important by educational decision- and  policy-makers. This creates policy  challenges. For educational technology vendors it i s easy to sell products that solve  existing problems, but it is very difficult to sell  products that require changes in  institutions, organizations and current practices. To avoid hard-wiring the past, it would  be important to put AI in the context of the future  of learning. Policy may be needed to  orient development in AI towards socially useful di rections that address the challenges,  opportunities, and needs of the future. As AI scales up, it can effectively routinize  old institutional structures and practices that may no t be relevant for the  future.  Future-oriented work, therefore, is needed to unde rstand the potential impact of  AI technologies. How this potential is realized dep ends on how we understand learning,  teaching and education in the emerging knowledge so ciety and how we implement this  understanding in practice. Future-oriented policy experimentation, as suggested  by the Digital Education Action Plan, may, therefore, be an effective way to  address this challenge.  .    Recent AI breakthroughs are based on supervised mac hine learning. A critical success  factor of these systems is the availability of huge  amounts of pre-categorized training  data. In contrast to logic- and knowledge-based app roaches to AI, we therefore  characterize these as “data-based” AI systems in th is report. Many of these “deeplearning” neural AI systems may well be characteriz ed as “datavores.” At present, the  most important technical bottleneck of AI, therefore,  is the availability of data .  This is a qualitatively new development in the hist ory of computing and information  processing. Without access to vast training dataset s, it is very difficult to develop  successful AI systems. In this report, we put forwa rd an argument that EU policies could  create data platforms that could redefine the compe titive landscape for learning- and  education-oriented AI systems.   
  4   As these supervised AI learning algorithms are based on  historical data, they  can only see the world as a repetition of the past. T his has deep ethical  implications . When, for example, students and their achievement s are assessed using  such AI systems, the assessment is necessarily base d on criteria that reflect cultural  biases and historically salient measures of success . Supervised learning algorithms create  unavoidable biases, and these are currently extensi vely debated. From a more  fundamental ethical point of view, however, the exp ression of human agency requires  capability to make authentic choices that do not on ly repeat the past. Although there are  already AI systems that deal with creative activiti es, AI systems will have great  difficulties in dealing with people who are creativ e, innovative, and not only average  representations of vast collections of historical e xamples.     It is often assumed that AI systems enable new leve ls of personalisation and diversity for  information systems; much of this, however, results  from fine-grained categorization that  puts users into pre-defined classes. Although these  systems may be able to efficiently  simulate personalisation, they do not necessarily s upport deeper levels of diversity. At  present we can say that the use AI systems in educa tional settings will shape the  development of human cognition and self-efficacy, b ut we don’t know how. It is therefore  important to continuously evaluate, for example, ho w the use of AI in educational  contexts constrains and enables human possibilities  for responsible and ethical action. AI  systems can be excellent predictive machines, but t his strength may be an important  weakness in domains where learning and development are important. A contribution of  this report is to show that different types of AI a nd machine learning systems operate on  different layers of human behaviour 4. Most importantly, the level of meaningful  activity —which in socio-cultural theories of learning under pins advanced forms of human  intelligence and learning— remains beyond the current state of the AI art.     One of the most successful application areas in AI has been video processing. There will  be strong economic interests in using video-connect ed AI systems in classrooms and to  complement the collected data with data from social  media and Internet of things (IoT)  platforms. As it becomes technically possible to mo nitor student emotions and attention  in real time and use such data to help teachers and  students, AI privacy and security  become important topics also in education. Similarl y, AI systems are well suited for  collecting informal evidence of skills, experience,  and competence from open data  sources, including social media, learner portfolios , and open badges. This creates both  ethical and regulatory challenges.    Several high-profile econometric studies on the fut ure of work have shown that many  occupations can be automated with current AI techno logies. These studies have relied on  task- and skill-biased models of technical change. In this report, we argue that a databiased model is more appropriate for current AI sys tems. We also explore a similar  methodology to see how the future of the teaching p rofession might look like. The results  suggest that many currently defined high-priority t eacher tasks might be automated.  However, this is based on the assumption that the r ole of teachers is rather mechanical  and purely instructional with summative assessment playing a central role, reflecting  deep beliefs about the functions of education and t he social institutions around it. In  educational systems that emphasize development and,  for example, social competences,  formative assessment might be higher on the list. A s a result, there is a risk that AI  might be used to scale up bad pedagogical practices.  If AI is the new electricity, it  will have a broad impact in society, economy, and e ducation, but it needs to be treated  with care.                                               4  Readers may also be interested in “ HUMAINT ”, an interdisciplinary JRC project aiming to under stand the  impact of machine intelligence on human behaviour, with a focus on cognitive and socio-emotional  capabilities and decision making (see https://ec.europa.eu/jrc/communities/community/huma int).  
  5   1 Introduction    All human actions are based on anticipated futures.  We cannot know the future because  it does not exist yet, but we can use our current k nowledge to imagine futures and make  them happen. The better we understand the present a nd the history that has created it,  the better we can understand the possibilities of t he future. To appreciate the  opportunities and challenges that artificial intell igence (AI) creates, we need both good  understanding of what AI is today and what the futu re may bring when AI is widely used  in the society. AI can enable new ways of learning,  teaching and education, and it may  also change the society in ways that pose new chall enges for educational institutions. It  may amplify skill differences and polarize jobs, or  it may equalize opportunities for  learning. The use of AI in education may generate i nsights on how learning happens, and  it can change the way learning is assessed. It may re-organize classrooms or make them  obsolete, it can increase the efficiency of teachin g, or it may force students to adapt to  the requirements of technology, depriving humans fr om the powers of agency and  possibilities for responsible action. All this is p ossible. Now is a good time to start  thinking about what AI could mean for learning, tea ching, and education. There is a lot of  hype, and the topic is not an easy one. It is, howe ver, both important, interesting, and  worth the effort.   Since 2013, when Frey and Osborne 5 estimated that almost half of U.S. jobs were at a  high risk of becoming automated, AI has been on top  of policymakers’ agendas. Many  studies have replicated and refined this study, and  the general consensus now is that AI  will generate major transformations in the labour m arket. 6 Many skills that were  important in the past are becoming automated, and m any jobs and occupations will  become obsolete or transformed when AI will be incr easingly used. At the same time,  there has been a tremendous demand for people with skills in AI development, leading to  seven figure salaries and sign-up fees. China has a nnounced that it aims to become the  world leader in AI and grow a 150 billion AI ecosys tem by 2030. The U.S. Department of  Defense invested about 2.5 billion USD in AI in 201 7, and the total private investment in  the U.S. is now probably over 20 billion USD per ye ar. In 2017, there were about 1200  AI start-ups in Europe, 7 and the European Commission aims to increase the t otal public  and private investment in AI in the EU to be at lea st 20 billion euros by the end of 2020. 8    In limited tasks, AI already exceeds human capabili ties. Last year, with just about one  month of system development, researchers at Stanfor d were able to use AI to diagnose  14 types of medical conditions using frontal-view X -ray images, exceeding the human  diagnostic accuracy for pneumonia. 9 In 2017, given no domain knowledge except the  game rules, an artificial neural network system, Al phaZero, achieved within 24 hours a  superhuman level of play in the games of chess, sho gi, and Go. 10  In May 2018, Google  CEO Sundar Pichai caused a firestorm when he demons trated in his keynote an AI  system, Duplex, that can autonomously schedule appo intments on the phone, fooling  people to think they are discussing with another hu man. In the midst of self-driving cars,  speaking robots, and the flood of AI miracles, it m ay be easy to think that AI is rapidly  becoming superintelligent, and gain all the good an d evil powers awarded to it in popular  culture. This, of course, is not the case. The curr ent AI systems are severely limited, and  there are technical, social, scientific, and concep tual limits to what they can do. As one                                              5 Frey and Osborne (2013, 2017).  6 E.g., European Political Strategy Centre (EPSC 201 8), United States Government Accountability Office  (GAO 2018), Finnish Steering Group of Artificial In telligence Programme (2017), and UK House of Lords  (2018).   7 Data from the U.K. House of Lords Select Committee  on Artificial Intelligence report (House of Lords 2018,  48).  8 Artificial Intelligence for Europe (EC 2018b).  9 Rajpurkar et al. (2017).  10  Silver et al. (2017). 
  6   recent author noted, AI may be riding a one-trick p ony as almost all AI advances  reported in the media are based on ideas that are m ore than three decades old. 11  A  particular challenge of the currently dominant lear ning models used in AI is that they can  only see the world as a repetition of the past. The  available categories and success  criteria that are used for their training are suppl ied by humans. Personal and cultural  biases, thus, are an inherent element in AI systems . A three-level model of human action  presented in the next section suggests that norms a nd values are often tacit and  expressed through unarticulated emotional reactions . Perhaps surprisingly, the recent  successes in AI also represent the oldest approach to AI and one where almost all the  intelligence comes from humans.    Instead of a beginning of an AI revolution, we coul d be at the end of one. This, of course,  depends on what we mean by revolution. Electricity did not revolutionize the world when  Volta found a way to store it in 1800 or when Ediso n General Electric Company was  incorporated in 1889. The transformative impact of general purpose technologies  becomes visible only gradually, when societies and economies reinvent themselves as  users of new technologies. Technological change req uires cultural change that is reflected  in lifestyles, norms, policies, social institutions , skills, and education. Because of this,  AI—now often called the "new electricity"—may revol utionize many areas of life when it  is taken into use even if it keeps on driving its " one-trick" pony for the foreseeable  future. Many interesting things will happen when al ready existing technologies will be  adopted, adapted, and applied for learning, teachin g, and education. For example, AI  may enable both new learning and teaching practices , and it may generate a new social,  cultural, and economic context for education.    Below we ask simple questions that illustrate the r elevance of AI for educational policies  and practices. Which vocations and occupations will  become obsolete in the near future?  What are the 21st Century skills in a world where A I is widely used? How should AI be  incorporated in the K-12 curriculum? How will AI ch ange teaching? Should real-time  monitoring of student emotions be allowed in classr ooms? Can AI fairly assess students?  Do we need fewer classrooms because of AI? Does AI reduce the impact of dyslexia,  dyscalculia, or other learning difficulties? These questions are simple to ask, and relevant  for understanding the future of learning, teaching,  and education. The answers, of  course, are more complex.     The main aim of this report is to put these and oth er similar questions in a context where  they can be meaningfully addressed. We do not aim t o provide final answers; instead, we  hope to provide background that will facilitate dis cussion on these and other important  questions that need to be asked as AI becomes incre asingly visible in the society and  economy around us. To do this, we have to first ope n the "black box" of AI and peek  inside. There are several things AI can do well, an d many things it cannot do. At present  there is an avalanche of reports and newspaper arti cles on AI, and it is not always easy  to distinguish important messages from noise. It is , however, important to understand  some key characteristics of current AI to be able t o imagine realistic futures. In the next  sections, we put AI in the context of learning, tea ching, and education, and then focus on  the specific form of AI, adaptive artificial neural  networks, that have generated the  recent interest in AI.                                                11  Somers (2017). 
  7   2 What is Artificial Intelligence?    Artificial Intelligence has many different definiti ons. In the headlines of newspaper  articles, AI is a machine that thinks, understands languages, solves problems, diagnoses  medical conditions, keeps cars on the highways, pla ys chess, and paints impressionistic  imitations of van Gogh paintings. AI is often defin ed as a computer system with the  ability to perform tasks commonly associated with i ntelligent beings. As this definition  somewhat problematically requires us to define inte lligence and is inconveniently  tautological, artificial intelligence is now common ly defined as a scientific discipline; as  the activity that creates machines that can functio n appropriately and with foresight in  their environment. 12  The first explicit definition of artificial intell igence was suggested in a  funding proposal to the Rockefeller Foundation in 1 955. It was based on the “conjecture  that every aspect of learning or any other feature of intelligence can in principle be so  precisely described that a machine can be made to s imulate it.” This early definition  rapidly led to deep controversies. In practice, the  early developers of AI interpreted  intelligence and thinking as mechanical processing of logical statements, thus, in effect,  defining human intelligence as computation of truth  values. This interpretation was  historically aligned with logical positivism and at tempts to formalize mathematics using  purely syntactic means, but it also raised importan t questions about the philosophical  foundations of AI. 13    In the following section, we propose a different wa y to understand the nature of AI. It  will help us locate the different capabilities of d ifferent types of AI in the context of  learning. Adaptability, learning, and anticipatory action are commonly viewed as key  characteristics of AI. We therefore use a theory of  human action and learning as a  starting point. For this we use a three-level model , along the lines of cultural-historical  activity theory and a similar model proposed by Har ré, Clarke and Carlo. 14     2.1  A three-level model of action for analysing AI and its impact    Cultural-historical theory of activity distinguishe s three hierarchically linked levels of  human behaviour.15  First, behaviour can be analysed as socially meani ngful activity   directed by culturally and socially constructed mot ives. Activity is realized through goaloriented acts  that essentially are ways of solving problems at h and that need to be  solved to accomplish the activity. Operations , in turn, implement the acts in the present  situation and concrete context, using the tools ava ilable. An important aspect of this  three-level hierarchy is that the levels cannot be reduced to each other. We can explain  the meaning of an activity  only using social, cultural and historical terms t hat do not  make sense at the level of acts  or operations . For example, we can explain the object  and motive of activity  by saying that we are teaching children so that th ey become  citizens, realize their potential as human beings, and get good jobs. The "content" of this  activity—how it is translated into concrete acts —depends on social institutions, norms,  social division of labour and knowing, the ways in which social production is organized,  and many other similar things. Most importantly, we  rarely are explicitly aware of all  those social factors that shape our activities. Cul tural norms, values, expectations, social                                              12  Nilsson (2009).  13  Since the early 1960s, the rather straightforward epistemological views adopted by the early AI devel opers  were criticized mainly in reference to continental phenomenologists, including Husserl, Heidegger and  Merleau-Ponty. See, e.g., Dreyfus (1979), Winograd and Flores (1986), Heinämaa and Tuomi (1989).  14  Socio-cultural activity theory, or more accurately  cultural-historical activity theory, was inspired by the  pedagogic studies of Vygotsky and his colleagues in  the 1920s and 1930s. It became an important  approach to study pedagogic methods and psychologic al theory in the Soviet Union in the subsequent  decades. We use here the activity-theoretic model a s described in Leont’ev (1978) and reinterpret its  three-level structure using terminology from Harré et al. (1985).  15  We follow here the terminology from Leont'ev (1978 ). 
  8   institutions, and other essentially contextual fact ors shape our activities and provide a  tacit normative, emotional, and anticipatory backgr ound that allows the ongoing stream  of activity to go on. This is also the level that p rovides the foundation for ethics of action.    The relation between acts  and activity  is, thus, similar to the relation between words an d  utterances. We need words to express utterances, an d acts  to express activity . It is,  however, impossible to understand the meaning of an  utterance by adding up definitions  of words. On the contrary, the sense of the word de pends on its role in the context of an  utterance. A written sentence needs words, and word s need letters, but the meaning of a  sentence cannot be found by studying letters or wor ds. This, in effect, says that it is not  possible to build models of human activity from bot tom up, simply combining some  elementary behavioural components.16  Activity , properly understood, requires social and  inter-generational learning, and the level of human  activity cannot be accessed simply by  empirical observation of human behaviour. The level  of acts , in contrast, consists of  externally and internally observable behaviour. Whe reas the level of activity  answers a  socially, culturally, and historically meaningful q uestion "why", the level of acts  answers  the question "what". This is also the level where w e think with concepts, plan, and solve  problems. If we call the level of activity  a “cultural” level, the level of acts  could perhaps  be called “cognitive.” A description of teaching at  this level could be, for example, that “I  am authoring course material for the class.” The th ird level of operations  addresses the  question "how." It implements acts  in concrete settings. For example, there are many  ways to assess student skills, many kinds of homewo rk, and many ways to deliver  homework to students. This is the level where techn ology operates as a tool, and where  behaviour can be best understood as routine and hab it. A description of teaching activity  at this level could be, for example, that “I’m inse rting a picture on a slide.”     Psychologists and learning theorists have focused o n different levels of this three-level  hierarchy during the last century. Behaviouristic a nd associationist theories of learning  have addressed mainly the level of operations. Cogn itivist and constructivist theorists  have mainly addressed the cognitive level, with con structionists also emphasizing the  material, affective, and social context. Socio-cult ural theorists, in turn, have often  focused on the social, cultural and materially embe dded dimensions of knowing and  learning.  Figure 1 depicts these three levels and maps some well-known learning  theorists to these levels. 17  Human learning occurs on all three levels of the a ctivity  hierarchy. When habit and routine hits an obstacle,  we become aware of it, operation  ceases, and action replaces it. We start to interpr et the problem, and try to find a  solution. 18  At this level, learning consists of problem solvin g, creative reframing, and  formation of new anticipatory models. New ways of d oing and thinking emerge, can be  internalized, and can become the basis for new habi ts and routines. Lev Vygotsky, the  founder of cultural-historical theory, however, als o pointed to the importance of the  social and cultural level of activities that shape human thinking and learning. Advanced  forms of thought are made possible because they rel y on culturally and historically  developed stocks of knowing. 19  Cognitive level acts, thus, use resources from bot h the  top level of activity and the bottom level of opera tions. Whereas Vygotsky emphasized                                              16  This also means that any straightforward attempt t o build artificial intelligence by combining elemen tary  logical components into more complicated networks f ails. For example, in an influential early contribu tion  to AI, John von Neumann (1951) argued that it is po ssible to describe the human brain by interpreting  neurons as logical switches and the brain as a comp lex network of such logical elements. Although von  Neumann noted that we may need radically new forms of logic to do this, he also believed that the bott omup approach is enough.  17  Such a description is, of course, a simplification . In particular, Papert (1980; 1991) emphasized the   affective and material dimensions of learning, and Piaget also wrote extensively about the social fact ors  that underpin cognitive development, see, e.g. Cole  and Wetsch (1996).  18  This is known as Claparède's law of conscious awar eness. It has informed many theories of learning fr om  Dewey (1991) and Vygotsky (1986) to more recent one s, such as action research and action learning in  organizational development (Lewin 1946).  19  See, e.g., Vygotsky (1986), Vygotsky and Luria (19 92), van der Veer & Valsiner (1994). 
  9   the influence of social and cultural factors in cog nitive development, critical pedagogists  such as Paulo Freire and newer activity theorists s uch as Yrjö Engeström have  emphasized the role of learning in changing existin g social practices. 20  Engeström, in  particular, has highlighted the role of learning in  the creation of new educational  practices. 21     Figure 1 . Three levels of human and machine learning    Source:  Author’s elaboration.    In this conceptual frame, learning at the level of activity can be understood as innovation  and realization of imagined futures. 22  Possibilities that have been figured out at the le vel  of cognition can start to change social practices a nd systems of activities, eventually  leading to new motives and reasons that start to or ganize the society. Much of this  activity-level development, however, is also emerge nt and unintended. 23  Social  structures, practices and institutions get their sh ape as a result of complex ongoing social  interaction and highly diversified interests and in terpretations, and to a large extent  remain unobservable for the members of society.     This three-level model provides a useful entry poin t for understanding artificial  intelligence and its potential impact on human acti vities. When AI enters social practices  at the level of operations , it augments and complements them, increasing the efficiency  and effectiveness of current ways of doing things. When it enters at the level of acts , it  replaces, substitutes, and automates acts that were  previously done by humans. When it                                              20  See, e.g., Freire (1972) and Engeström (1996).  21  Engeström (1987). It should perhaps be noted that the “cognitive” level is in cultural-historical app roaches  understood as inherently social and materially embe dded. Psychology has commonly viewed cognition from   an individualistic point of view. To highlight the inadequacy of such an individualistic construct of cognition,  terms such as “socially shared cognition,” “situate d cognition,” “distributed cognition,” and “extende d  cognition” are now commonly used. See, e.g., (Brown , Collins, and Duguid 1989; Cole 1986; Hutchins  1995; Mace 1977; Norman 1993; Suchman 1987; Salomon  1993).  22  In contrast to many common interpretations, innova tion is here defined as creation of new technologic ally  mediated social practice, see (Tuomi 2002a).  23  This observation underpins both Engels' (1966, cha p. 5) description of the development of human cogni tion  and Hayek's (1945) views on the impossibility to de sign policies that, in general, would produce bette r  outcomes than free markets.  
  10   enters social practice at the level of activity , it transforms the system of motives, making  current activities and specializations redundant an d obsolete. For example, technical and  routine skills emphasize the level of operations . Vocational education has traditionally  focused on this level, teaching students how to use  tools and domain-specific knowledge.  The recent calls for competence-based education, in  turn, emphasize problem solving,  critical thinking, decision-making and analytical s kills, focusing on the cognitive  level.  Entrepreneurial and innovation competences, highlig hted in frameworks for key  competences and 21 st  century skills, mainly address the opportunities f or social and  cultural change at the level of activities .    Consequently, learning at the level of operations  requires data on the current concrete  environment. This data can be generated using perce ption and physical interaction.  Learning at the level of socially motivated activity , in contrast, requires knowledge about  social systems of meaning. To gain such knowledge, communication, language, and  dialogue become necessary. An important indicator o f the current change in the  dynamics of development is that whereas technology in the industrial age focused on  tools for automating and supporting operations, the  focus is now increasingly on  technologies for social change. The three levels of  activity have complex dependencies.  In the course of historical development, what origi nally was a means may become an end  in itself. “Zooming in” to modern social life, ther efore, we may see a rather fractal  structure or activities and acts. Using this three- level model of activity, it becomes,  however, clear that different types of artificial i ntelligence and machine learning systems  operate on different layers of this hierarchy. Most  importantly, the level of meaningful  activity, which according to socio-cultural theorie s of learning underpins advanced forms  of human intelligence and learning, remains beyond the current state of the AI art. This  paradigm is currently being explored in the field o f Child-Robot Interaction and social  robotics 24 . In the next section, we briefly outline the main characteristics of three  different types of AI to locate their capabilities in this hierarchy, and discuss their  potential impact.    2.2  Three types of AI  The history of AI can relatively cleanly be categor ized into three alternative approaches:  data-based, logic-based , and knowledge-based. The first of these is now also called  artificial neural networks and machine learning. Pe rhaps surprisingly, the recent  successes in AI also represent the oldest approach to AI.    2.2.1  Data-based neural AI  Mathematical models of neural networks were first d eveloped by Nicolas Rashevsky in  the early 1930s, 25  and they became famous when his student Walter Pit ts interpreted  biological neural networks in 1942 as networks of l ogical switches. The publication of  these ideas by Warren McCulloch and Pitts 26  occurred at a time when Alan Turing had  shown that formal logic can be mechanized and the f irst digital computers were being  developed. It was therefore quickly recognized that  all formal logical operations could be  simulated by such neural networks. Brain started to  look like a computer, and the  computer became known as the electronic brain. This  two-way metaphor has since then  become widely influential. It underpins cognitive s cience and research in organizational                                              24   See, for instance Vouloutsi, V. et al. 2016. Towa rds a synthetic tutor assistant: the EASEL project and its  architecture. In Conference on Biomimetic and Biohy brid Systems (pp. 353-364). Springer, Cham.  25  Early work on neural network models is reviewed in  Rashevsky (1960). Rashevsky's work is little known   among AI researchers, but his indirect impact is co nsiderable. A collection of classic articles up to late  1980s is Anderson and Rosenfeld (1988).  26  McCulloch and Pitts (1943). 
  11   information processing, and now influences economic s, connectivist models of learning,  and many areas of scientific and popular thinking. 27     The present neural AI is to a large extent based on  neural network models that were  informed by neurobiology. An important early contri bution was made by Frank Rosenblatt  in 1958, when he—inspired by neuropsychologist Dona ld Hebb’s idea that learning occurs  in neural networks through synaptic modifications a nd economist Friedrich Hayek’s work  on distributed learning—suggested that learning in biological neural networks could be  modelled as gradual change in network connections. 28  The multi-layer photo-perceptron  described by Rosenblatt is in many ways identical t o current state-of-the-art image  processing neural networks. 29  Its main difference with today’s neural AI systems  is that  modern systems have very many “neural layers,” and “deep learning” in such multi-layer  networks is done using machines that are about tril lion times faster than the IBM 704  computer that Rosenblatt used for his experiments.    Figure 2 : Organization of a perceptron  Source: Adapted from Rosenblatt, 1958 .    The distinctive characteristics of most neural AI s ystems are their simple behaviouristic  learning models, very high computational needs duri ng learning, and their need for data.  For these systems, the availability of data is the most critical success factor. Using                                              27  Many excellent histories of AI and cognitive scien ce exist that describe the interdependent developme nt of  computers, cognitive psychology, and artificial int elligence. See, e.g., McCorduck (1979), Gardner (19 87)  and Boden (2016).  28  Rosenblatt (1958). Hebb was, in turn, influenced b y Rashevsky’s work on neural networks. Hayek’s  connectionist model of learning is described in Hay ek (1952).  29  Current deep-learning architectures use computatio nal "backpropagation" of output error during learni ng to  adjust network weights. In contrast, Rosenblatt's p erceptron used feedback connections from its output   layer for learning how to separate different input patterns. Although deep-learning networks are essen tially  perceptrons, Rosenblatt used in 1958 a vacuum tube computer that able to do about 12,000 mathematical  additions or multiplications per second (12kFLOPS).  Google's newest tensor processing compute ”pods,”  announced in May 2018, can run more than hundred pe taflops when training a machine learning system.  That is 100,000,000,000,000,000 multiplications per  second. This, in itself, is superhuman: If every p erson  on Earth would make one multiplication every second , about ten million planet Earths would be needed t o  achieve the same computational capability.   
  12   biological terminology, they could be called “datav ores.” Because of this, we call this the  “data-based” approach to AI. 30     2.2.2  Logic- and knowledge-based AI  Neural network models were popular in the 1950s and  1960s. They were also a key area  of study—among learning, language, creativity, and abstraction—in the Dartmouth  summer research project in 1956 that established th e term Artificial Intelligence.  Although work continued on neural networks, researc h on AI soon moved to “symbolic  processing.” As mathematicians and logic-oriented p hilosophers had since Hilbert and  Russell believed that logical truths could be deriv ed by formal manipulation of sentences,  it was apparent that computers could do all those i nferences that are logical. A  pioneering effort in this line of AI was the Logic Theorist, developed by Allen Newell, John  Shaw, and Herbert Simon over the Christmas break in  1955. It was able to manipulate  logical statements and derive proofs for logical th eorems, and its creators were certain  that they had produced a machine that thinks. The L ogic Theorist was soon followed by  the General Problem Solver that was supposed to be able to solve any logically welldefined problem that had a solution. This logic-ori ented approach to AI was the dominant  one from the late 1950s to early 1970s. 31     By the 1970s it was generally acknowledged that hum an thinking cannot be simulated  just by formal manipulation of logical statements. As a result, domain-specific knowledge  and different ways of representing knowledge became  the central focus of AI research.  This led to what is now known as "expert systems" o r, more broadly, knowledge-based  systems. Early examples of these include the SHRDLU  natural language understanding  program and the MYCIN medical diagnostic system tha t recommended antibiotics and  their dosage based on the symptoms and the patient.  Knowledge-based systems typically  consisted of a relatively general "inference engine " and a domain-specific "knowledge  base" that was used to make inferences based on hum an input. In particular, in expert  systems, domain knowledge tried to imitate knowledg e structures used by human  experts. Expert systems were very popular in the 19 80s, with two thirds of Fortune 500  companies using them in the daily activities. Since  then they have been widely used in  various sectors of economy, for example in the fina ncial sector, logistics, semiconductor  chip design, manufacturing planning, and business p rocess automation. Many expert  systems have also been developed for learning and e ducation since the early 1980s.    The interest in knowledge-based AI waned towards th e end of 1980s as it became clear  that the development of domain-specific knowledge b ases required specialized knowledge  engineers, and also because the spread of computer networking and the Internet shifted  the interests towards system integration and automa tion of routine business processes.  Many ideas from stand-alone expert systems are now widely used in standard  programming environments. As the boom of knowledge- based AI decayed at the end of  the 1980s, neural AI research became again popular for a few years. Difficulties  associated with parallel programming and system int egration, however, kept most neural  AI systems in university laboratories, and attentio n moved to new areas such as mobile  computing and the World-Wide Web.                                                 30   It should perhaps be noted that the currently pop ular neural AI models require huge amounts of data  because they use learning models that can easily be  implemented using digital computers and algorithms .  More effective neural models can be implemented usi ng analog computation and measurement-type  computers (Tuomi, 1988). The ”third wave” DARPA AI Next campaign, announced in September 2018, and  many neural chip initiatives aim to address this ch allenge.  31  C.f. McCorduck (1979). 
  13   From a practical point of view, both logic-based an d knowledge-based approaches in AI  focus on the cognitive level of activity hierarchy.  They also interpreted cognition in a  purely individualistic way. Logic-based AI tried to  develop general algorithms for thinking  that manipulate symbols, arguing that this is what also humans do. Whereas logic-based  systems focused on general problem-solving processe s, knowledge-based approaches  used simple models of inference and more elaborate representations of domain-specific  knowledge, arguing that effective decision-making r equires more knowledge than logic.  In contrast, machine learning and artificial neural  networks typically use learning models  that can be characterized as behaviouristic. These systems are typically provided with  vast amounts of data and pre-defined criteria for o ptimal response. In these systems, the  algorithms do not try to imitate human intelligence ; instead, they define strategies for  adapting system output to expected output using ext ensive amounts of what is called  “training data”. In some applications, such as game s, this training data can be  automatically generated; in most currently importan t neural AI systems the data are  provided by humans. For example, the development of  state-of-the-art image recognition  AI systems now, to a large extent, relies on the pu blicly available ImageNet database  that consists of 14 million images. The labelling o f objects in these images was done in  2007-2010 using the Amazon’s Mechanical Turk crowds ourcing platform by 48,940  people in 167 countries.      2.3  Recent and future developments in AI    The recent interest in AI results from three parall el developments. First, increasingly  realistic computer games have required specialized graphics processors. When the PC  graphics card manufacturer Nvidia  published the CUDA  programming interface to its  graphics accelerator cards in 2007, fast parallel p rogramming became possible at low  cost. This allowed researchers to build neural netw ork models that had many connected  layers of artificial neurons and large numbers of p arameters that the network could learn.  Second, huge amounts of data have become available as computers and computer users  have been networked. The digitalization of images, videos, voice and text has created an  environment where machine learning can thrive. This  has allowed AI researchers to  revisit old artificial neural network models, train ing them with very large datasets.    Somewhat surprisingly, these huge data sources have  proven to be enough for some of  the hard problems of AI, including object recogniti on from digital images and machine  translation. Whereas it was earlier believed that c omputers need to understand language  and its structures before they can translate text a nd speech from one language to  another, for many practical uses it is enough to pr ocess millions of sentences to find out  the contexts where words appear. By mapping words i nto high-dimensional  representational spaces, enough of this contextual information is retained so that  translation can be done without linguistic knowledg e. A common approach is to use the  publicly available GloVe  word representations that have been developed usin g text  corpora that contains up to 840 billion word-like t okens found on documents and content  on the Internet, subsequently translated to a vocab ulary of over 2 million words. 32  Using  this dataset and machine learning algorithms, the w ords have been mapped into points in  a 300-dimensional vector space. 33  The location and geometric relations between words  in  this space capture many elements of word use, and c an be also used as a basis for  translation from one language to another. Although such a purely statistical and data                                            32  See Pennington et al. (2014)  33  There exist several versions of GloVe  vectors. Pre-trained GloVe  vectors, trained using different corpora,  can be downloaded from https://nlp.stanford.edu/pro jects/glove/ 
  14   based approach is not able to comprehend new or cre ative uses of language, it works  surprisingly well in practice.    Third, specialized open source machine learning pro gramming environments have  become available that make the creation and testing  of neural networks easy. In most  current neural AI models, learning occurs by the gr adual adjustment of network weights,  based on whether the network makes right prediction s with the training data. A central  task in such learning is to propagate information a bout how important each neuron's  activity is to right and wrong predictions made by the network. When an active neuron is  associated with a wrong prediction, the activity of  the neuron is decreased by decreasing  the weights of its incoming connections. As there c an be very many layers of neurons  and many connections between neurons, this is a tas k that is difficult even for powerful  traditional computers. The influence of each neuron  to the prediction can, however, be  computed using the chain rule of calculus, propagat ing the information from the output  layer of the network layer-by-layer towards the inp ut layer. This is known as  "backpropagation" of error. 34  Although the computation of network weights using this  method may involve hundreds of millions of computat ions in state-of-the-art networks,  current neural AI development environments can do t his with a couple of lines of  program code.    These three trends started to come together around 2012. In that year, a multilayer  network trained using Nvidia 's graphics processor cards showed outstanding perf ormance  in an image recognition competition. The competitio n was based on the ImageNet  database that contains about 14 million human-annot ated digital images. The ImageNet  Large Scale Visual Recognition Challenge (ILSVRC) i s now one of the main benchmarks  for progress in AI. Its object detection and classi fication challenge uses 1.2 million  images for training, with 1,000 different types of objects. In 2017, the best neural  network architectures were able to guess the correc t object category with 97,7 per cent  "top-5" accuracy, meaning that the correct object c lass was among the five most  probable classes as estimated by the network. The r apid improvement in object  recognition can be seen in Figure 3 that gives the top-5 error rates of the winners over  the years.    Figure 3 : Error rates in the ImageNet ILSRC object recognit ion competition    Source: Data compiled from imagenet.org                                              34  This method was first explicitly described by Sepp o Linnainmaa in 1970 in his master’s thesis at the  University of Helsinki, but it became widely known in the mid-80s, as part of the parallel distributed   processing approach to AI (Rumelhart and McClelland  1986). The difficulty of propagating prediction er ror  signals in complex multilayer neural models limited  the use of this methodology until graphics process ors  started to be used for "deep learning."  
  15   The resurrection of neural AI has partly been cause d by the availability of data, such as  digital images, electronic texts, Internet search p atterns, and social network content and  linkages. Recent developments, however, have also b een driven by the fact that these  huge datasets are difficult to analyse and utilize with traditional computing. Machine  learning both requires big data but it also makes l arge quantities of data usable and  valuable. There are therefore large commercial ince ntives in using machine-learned  models for processing data that cannot practically be processed using more traditional  approaches.    2.3.1  Models of learning in data-based AI  Almost all current neural AI systems rely on what i s called a supervised model of  learning. Such “supervised learning” is based on tr aining data that has been labelled,  usually by humans, so that the network weights can be adjusted when the labels for  training data are wrongly predicted. After a suffic ient number of examples are provided,  the error can in most cases be reduced to a level w here the predictions of the network  become useful for practical purposes. For example, if an image detection program tries to  differentiate between cats and dogs, during the tra ining process someone needs to tell  the system whether a picture contains a cat or a do g.    A practically important variant of supervised learn ing is called "transfer learning." A  complex neural network can be trained with large am ounts of data, so that it learns to  discern important features of the data. The trained  network can then be re-used for  different pattern recognition tasks, when the under pinning features are similar enough.  For example, a network can be trained to label huma n faces with millions of images.  When the network has learned to recognize the faces  that have been used for its  training, its deep layers become optimized for face  recognition. The top levels of the  network can then relatively easily be trained to de tect new faces that the system has not  seen before. This drastically reduces the computati onal and data requirements. In effect,  AI developers can buy pre-trained networks from spe cialized vendors, or even get many  state-of-the-art pre-trained networks for free and adapt them to the problem at hand.  For example, the GloVe vectors, available from Stan ford University, are commonly used  as a starting point for natural language processing , and Google’s pre-trained Inception  image processing networks are often used for object  recognition and similar image  processing tasks.    Supervised learning systems can produce statistical  guesses of which of possible pregiven class a specific given input data pattern bel ongs. Supervised learning, thus,  assumes that we already know what categories input patterns can represent. This is the  most frequently used learning model in AI today bec ause for practical purposes it is often  enough to classify patterns into a set of pre-defin ed classes. For example, a self-driving  car needs to know whether an object is a cyclist, t ruck, a train, or a child. Technically,  supervised learning creates machines that map input  patterns into a collection of output  classes. Their intelligence, thus, is similar to si mplest living beings that can associate  environmental conditions with learned behaviours. I n psychology, these learning models  underpin the Pavlovian theory of reflexes and, for example, Skinnerian reinforcement  learning. As Vygotsky pointed out in the 1920s, thi s type of learning represents the  developmentally simplest model of learning, and bot h pigeons and humans are well  capable of it. 35                                                 35  Tuomi (2018). 
  16   A particular challenge of supervised learning model s is that they can only see the world  as a repetition of the past. The available categori es and success criteria that are used for  their training are supplied by humans. Personal and  cultural biases, thus, are an inherent  element in AI systems that use supervised learning.  The three-level model presented  above suggests that norms and values are often taci t and expressed through  unarticulated emotional reactions. It is, therefore , to be expected that supervised  learning models materialise and hardwire cultural b eliefs that often remain otherwise  unexplored. In somewhat provocative terms, supervis ed learning creates machines that  are only able to perceive worlds where humans are p ut in pre-defined boxes. From  ethical and pedagogic points of view this is proble matic as it implies that in interactions  with such machines, humans are deprived of agency p owers that allow them to become  something new and take responsibility of their choi ces.    Many unsupervised or partially supervised neural le arning models have been developed  since the 1960s, some of which are also currently b eing developed and applied.  Increasing computational power has also allowed res earchers to use simple patternmatching networks as components in higher-level arc hitectures. For example, Google's  AlphaZero game AI uses “reinforcement learning” where the sys tem generates game  simulations and adjusts network weights based on su ccess in these games. Inspired by  Skinnerian models of operant conditioning, reinforc ement learning amplifies behaviour  that leads to outcomes that are defined as positive . A variant of reinforcement learning is  known as generative adversarial networks, or GANs, where one network tries to fool  another to believe that the data it generates actua lly comes from the training data set.  This approach has been used, for example, to create  synthetic images of artworks and  human faces that an image recognition system cannot  distinguish from real images 36 . It  is also commercially used for product design, for e xample in the fashion industry. A  variation of GAN is called "Turing learning," where  the system that learns is allowed to  actively interact with the world in trying to guess  whether the data comes from the real  environment or from a machine. 37   2.3.2  Towards the future    As some economists, philosophers, and scientists ha ve made high-profile statements  about the forthcoming emergence of super-intelligen t AI systems that eventually may  replace humans in many areas of human life, it is p erhaps useful to note that most  current AI learning models represent cognitive capa bilities that most closely resemble  biological instincts. Many predictions about the fu ture of AI have been based on  extrapolations of historical technical development,  and in particular estimates of the  continuation of "Moore's Law" in computing, with li ttle concern about differences between  advanced forms of human learning and the more eleme ntary capabilities of association.  Human learning requires many meta-level competences . In particular, for humans it is  important to know what counts as knowledge, how to go on in acquiring, creating, and  learning knowledge, how to regulate cognition, atte ntion and emotion in learning                                              36     https://www.nytimes.com/interactive/2018/01/02/tech nology/ai-generated-photos.html  and  https://www.hs.fi/tiede/art-2000005734015.html    37  This approach is based on a simplified version of the imitation game suggested by Turing in 1950. Tur ing  argued that if a machine is able to fool a human in  this game, the question whether machines can think   becomes redundant. This is now known as the "Turing  test." The original imitation game, however, is mo re  sophisticated than its popular versions and the mod el used in Turing learning. The game tries to disti nguish  a man and a woman, and tries to see if, based on an swers to interrogator's questions, a man makes as  many errors in detecting a man who imitates a woman  than he makes detecting a machine who imitates a  woman. Turing's test, thus, measures whether two ob viously different humans (a man and a woman) are  no more different than a machine and a human when t hey can be observed only using teletype messages.  The philosophical foundation for the test is logica l positivism, which essentially claims that if some thing  walks and talks like a duck, it has to be a duck. I n the imitation game, the duck is in a closed room with a  teletype printer, and the types of ducks that are a llowed in the game are strongly constrained (Heinäm aa  and Tuomi 1989). 
  17   processes, and what the social and practical motiva tion for learning is. As Luckin has  recently well pointed out, at present AI lacks most  of these meta-cognitive and  regulatory capabilities. 38     It is important to note that the future of the curr ent AI boom will to an important extent  be determined by developments in chip design. For a lmost fifty years, developments in  processor and memory chips were driven by rapid con tinuous improvements in  miniaturization of component features on semiconduc tor chips. During the last ten years  it has become increasingly accepted that this devel opment is about to end, and new  approaches are needed to keep the semiconductor ind ustry growing. Neural AI addresses  this "post-Moore" era by shifting development towar ds new computing models, including  analog computing. This represents a major discontin uity in the technological foundations  of knowledge society. 39     In practice, most AI experts work with "narrow AI,"  in contrast with "general AI" that  would have capabilities similar to humans. In setti ng up the first Dartmouth summer  project on artificial intelligence, the leading res earchers believed that computers will soon  be intelligent. Such expectations seem to be unreal istic also today. Although it might be  possible to develop AI systems that have capabiliti es that more closely resemble human  intelligence, current AI systems use rather simplif ied models of learning and biological  intelligence. Most current AI systems rely on essen tially reflexological and behaviouristic  models of learning, popularized by Pavlov and Thorn dike at the beginning of the 20 th   century. They could perhaps therefore better be des cribed as mechanical instincts,  instead of artificial intelligence. 40  Despite these limitations, the potential of AI in  education has been widely recognized during the las t three decades. Although the impact  on classrooms has been relatively minor, the recent  developments suggest that the  situation may change. In particular, AI-based syste ms can become widely used as  systems that support teachers and learners. AI can also rapidly change the economy and  job market, creating new requirements for education  and educational systems.    2.4  AI impact on skill and competence demand  One of the key roles of modern educational system i s that it creates competences that  allow people to participate in the economic sphere of life. The history of educational  systems is closely linked with the development of t he industrial society, and wage labour  is still a central organizing principle in industri al societies and their everyday life. In highlevel policy discussions, education is therefore of ten understood as a source of  employment. Education, in this interpretation, is a  key driver of economic productivity  and competitiveness, and educational policies are f ramed in the context of economic  growth. It is therefore important to ask also in th e context of educational policies how AI  will transform work and employment. For economists,  a central question has been  whether automation and computerization increases un employment. As machines increase                                              38  Luckin (2018).  39   The claims of rapidly approaching ”singularity” a nd ”superintelligence,” therefore, are based on som ewhat  questionable extrapolations of historical trajector ies. For more detailed analysis of these developmen ts, see  Tuomi (2002b, 2009). In particular, the energy cons umption of neural AI systems will be a critical fac tor  for the wide use of AI.  40  Most current AI researchers are rather agnostic co ncerning the future of general AI. Historically, ma ny AI  researchers have thought that Turing's test is impo rtant for AI because it is aligned with the formali st idea  that all truths are statements that at least in pri nciple can be typed on a teletype keyboard. From th is point  of view, it seems irrelevant that the experimenter is prohibited from opening the door and looking ins ide to  check whether there is a human or a machine. It can  also be shown that success in the Turing test does   not mean that a machine would have similar capabili ties for thinking as humans. A finite collection of   Google Duplexes do not make a dialogue in mathemati cal sense. More generally, it can be shown that any   finite collection of simulations cannot generate an  accurate model of biological systems (Rosen 1985; Louie  2009). This, however, requires the use of mathemati cal formalism known as category theory. 
  18   labour productivity, fewer human workers are needed  to maintain production. Unless the  demand for products grows enough, unemployment grow s.    In reality, this simple model is, of course, too si mple. If machines replace some jobs,  people may move to other jobs. In general, this is what happened in the last century  when agricultural and industrial jobs were automate d, and labour moved to services.  There are many influential studies that have verifi ed this pattern. 41  Using historical data,  they typically conclude that more technology and la bour productivity growth have not  increased aggregate unemployment. On the other hand , it is well known that an  important reason why automation has not generated p ersistent unemployment is  population growth that has continuously increased d emand for industrial products and  services. Many other factors, such as education, gl obalization, increased consumption of  non-renewable natural resources, as well as develop ments in science and healthcare  have been involved in the 20 th  century economic growth, and it is, therefore, dif ficult to  make predictions about the future using historical patterns.    Although some influential studies claim that automa tion has not generated  unemployment, it may therefore be useful to recall also the history of industrialization  and its social consequences. Industrialization led to social upheavals and revolutions from  Prussia to Mexico, Russia, and countries around the  world, often with brutal outcomes.  Millions of lives were lost. People flocked into ci ties, and at the turn of the 20th century  authors such as Jack London still described in deta il the dismal conditions of wage-slaves  in the Oakland docks. As the economic system now op erates on a global scale, the  impact of AI cannot easily be studied on a national  scale, where useful econometric data  typically is available. Although country-level data  can be aggregated, for example, for  cross-national comparisons, the global and networke d knowledge economy is not just a  collection of economically integrated national econ omies. 42  In considering the social,  economic and human impact of AI and its relation to  educational policies, a broad view  on social change is necessary.    2.4.1  Skills in economic studies of AI impact  Much of the current economic research on the future  of work and the impact of AI starts  from analysing the impact of computers on skill dem and. It is, therefore, important to  understand how skills and work tasks have been inte rpreted in these studies. Below, we  put these econometric studies in the context of the  three-level model presented above                                              41  These include, for example, Autor, Levy and Murnan e (2003), Acemoglu and Restrepo (2016), and, in a  more pessimistic vein, Brynjolfsson and McAfee (201 2). Autor, in particular, has argued that the main  impact of automation has been in the polarization o f labour markets. He also argues that the use of AI  will  increase the comparative advantage of humans in tas ks that require problem-solving skills, adaptabilit y,  creativity, flexibility, and common sense (Autor 20 15). A recent collection of articles on the economy  of AI  is available from the US National Bureau of Economi cs Research (Agrawal, Gans, and Goldfarb 2018). Man y  of these studies, however, could be put in a somewh at different light by looking time use and hours wo rked  in the economy per capita. For example, in Finland the time used for paid labour has decreased about o ne  fifth per capita in the last forty years.  42  The global and networked character of knowledge ec onomy poses some quite deep methodological  challenges here. We have extensive economic data on  the national level, and it is therefore natural to   assume that we should use those data as a starting point to study the economic impact of computerizati on  and AI. The available data, however, do not necessa rily capture the non-local and functional aspects o f  economy. In biology, the observation that those asp ects of living systems that make them “alive” canno t  be described using data on their constituent compon ents led in the 1950s to “relational biology.” It f ocuses  on the functional organization of biological system s instead of their various material implementations   (Rosen 1958, 1991; Rashevsky 1954, 1972). In partic ular, Robert Rosen argued that dynamic models,  such as those used in physics and economics, are no t able to capture the essence of biology as systems  are  alive because of complex networks of interrelated f unctions. A category theoretic formalism is needed to  model such systems (cf. Louie 2009). 
  19   (see 2.1), showing that different types of AI have capabilities on different levels of this  model.    Many of the influential econometric studies use the  U.S. Occupational Information  Network (O*NET) database as a starting point. 43  O*NET contains now about 1000  occupational definitions to help students, job seek ers, and educators to understand skill  requirements and work content in different occupati ons. An example of the task structure  of one occupation, “Middle School Teachers, Except Special and Career/Technical  Education,” is shown in Figure 4.    Figure 4 : O*NET task and skill structure for Middle School teacher occupation  Source: Based on O*NET (www.onetonline.org )    The path-breaking study by Frey and Osborne asked e xperts in robotics and AI what are  those technical bottlenecks that limit the automati on of work tasks.44  Using these  automation bottlenecks as a starting point, they th en asked the experts to classify a set  of O*NET occupations based on whether automation of  their tasks seemed possible.  Those jobs that didn’t contain hard-to-automate tas ks were classified as having a high  risk of being automated. One important outcome of t he Frey and Osborne study is that it  predicted that about half of U.S. occupations is at  high risk of being automated in the  near future using current technologies. Whether thi s estimate is accurate or not, it still  highlights the point that educational systems will be under considerable pressure to  address this wide-spread change. Traditional educat ional planning has tried to predict the  future demand for different types of education base d on estimated labour market  developments. Frey and Osborne show that AI will ha ve radical impact on the labour  market, and create discontinuities in many trends t hat currently underpin educational  planning and policies. We, therefore, need to recon sider both the content and the  functions of education in this new environment.                                                43  O*NET data can be accessed online at http://www.on etonline.org/.  44  Frey and Osborne (2013).  
  20   2.4.2  Skill-biased and task-biased models of technology i mpact    Many earlier studies on the impact of computers and  automation were based on skillbiased models of technological change. In skill-bia sed models, jobs that do not require  educated, experienced, and skilled workers are susc eptible to automation. In such  models, computers are expected to be used mainly fo r tasks that require limited skill. It  becomes then natural to assume that to avoid unempl oyment people need more and  higher-level education. In contrast, recent studies  on computerization have adopted a  task-biased approach. It assumes that those tasks t hat can be exactly described can be  programmed with a computer. In these studies, occup ations that consist of routine tasks  are susceptible to automation. This has typically l ed researchers to assume that  occupations that require human-like intelligence ar e not susceptible to automation. The  implication for educational policy could be that ed ucation should focus on non-routine  cognitive tasks, often labelled as 21 st  century skills. Frey and Osborne used a task-biase d  model, but they argued for a different approach. In  their view, the impact on AI and  robotics should be studied based on current technol ogical bottlenecks. AI is rapidly  becoming able to perform tasks that have traditiona lly been understood to require  human cognition. According to Frey and Osborne, it is therefore important to ask experts  what computers cannot do. All those tasks where tec hnical bottlenecks do not exist may  be automated, and if an occupation consists of such  tasks, it is susceptible to  automation.   Beyond such an occupation-level analysis, it is int eresting to drill down to specific  occupations and consider how AI could change them. In Table 1 we do this for the O*NET  Middle School Teachers. The table lists some of the  teacher’s tasks, as they are listed in  O*NET, in their order of importance. The potential impact of AI on tasks is based on  author’s estimate, and should be taken as indicativ e.      Table 1 : Potential impact, middle-school teacher tasks      Task  AI impact   1 Adapt teaching methods and instructional materials to meet students ’ varying needs and interests  High   2 Establish and enforce rules for behaviour and procedures for main taining order among students  ?  3 Confer with parents or guardians, other teachers, c ounsellors, and administrators to resolve students’    behavioural and academic problems Low   4 Maintain, accurate, comple te, and correct students records as required by law s, district policies, and  administrative regulations High   5 Prepare, administer, and grade tests and assignment s to evaluate student’s progress  High   6 Prepare material and classrooms for class activitie s  Medium   7 Instruct though lectures, discussions, and demonstr ations in one or more subjects, such as English,  mathematics, or social studies Medium   8 Establish clear objectives for all lessons, units, and projects, and communicate these objectives to  students Medium   9 Assist students who need extra help, such as by tut oring, and preparing and implementing remedial  programs High   10  Assign lessons and correct homework  High   11  Enforce all administration policies and rules gover ning students  Medium   …    15 Meet or correspond with parents or guardians to dis cuss children’s progress and to determine prioritie s  and resource needs Medium     Source: I. Tuomi’s estimate     Looking at this table, one might wonder why many of  the listed tasks seem to be  susceptible to automation. One explanation could be  that technology has now advanced  to a level where also some demanding human cognitiv e activities, such as performing 
  21   tasks related to teaching, administrative and commu nication tasks, can be performed by  computers. A more critical view might be that teach ers are in the current educational  systems burdened with rather mechanical tasks. The list of high-importance tasks also  reflects deep beliefs about the functions of educat ion and the social institutions around it.  For example, comparative high-stakes testing and as sessment of achievement may be  highly important when educational systems are used for social selection. In educational  systems that emphasize development and, for example , social competences, formative  assessment might be higher on the list.    2.4.3  AI capabilities and task substitution in the three- level model    If we use the three-level model of activity (see 2. 1), the econometric studies on future  work and skill demand appear in a new light. First,  as von Neumann argued half a  century ago, if we can exactly and unambiguously de scribe a task, it is possible to  program a computer to perform the task. 45  Von Neumann was talking about the  capability of computers to simulate any system that  can be simulated, although he also  noted that we may need new forms of logic and new f ormalisms to do this. A simple  conclusion from this might be that there are no fun damental technical bottlenecks that  would make automation impossible. Indeed, well-know n authors such as Kurzweil and  Bostrom seem to adopt such a view. 46     In the context of the three-level model of human ac tivity and cognition, the level of  activity  is not directly accessible for individual human co gnition. It provides a tacit  cultural and social background which makes activiti es meaningful. As Polanyi and Hayek,  among others, have emphasized, much of the knowledg e that underpins social activity is  contextual, distributed, embedded in social institu tions and technologies, and enacted in  practice. 47  It seems, therefore, that this social and cultural  layer can, at best, be only  partially articulated and made explicit. If von Neu mann was right, and everything that  can be explicitly described can be computed, it see ms that the level of acts  and cognition   is the level where computing could have it main imp act. This, indeed, is the level where  most logic- and knowledge-based AI work has been do ne. In this view, the important  bottleneck is not technical; instead, it is represe ntational. Although we may convert some  tacit knowledge to explicit knowledge, this require s a context that necessarily remains  unarticulated.    An alternative way to approach the question of task  substitution is to start from the  statement by one of the leading AI experts, Andrew Ng. He summarizes the capabilities  of neural AI and machine learning is a compact way:     “If a typical person can do a mental task with less  than one second of  thought, we can probably automate it using AI eithe r now or in the near  future.”48     This highlights the point that current neural AI an d machine learning systems address  the bottom level of the three-level hierarchy. Task s that require habit formation and  reflex reaction are well suited for supervised lear ning models.                                              45  Von Neumann (1951, 310).  46  Kurzweil (1999), Bostrom (2014).  47  Cf. Polanyi (1967), Hayek (1952).  48  Ng (2016). 
  22     Yet, there is a caveat to Ng’s definition: What cou nts as a “typical” person? Many “lessthan-one-second” human tasks require years of learn ing. Some of these, for example,  learning to walk, are rather behavioural, and can a lso be learned by AI-supported robots.  Many of these tasks, however, also require long per iods of cultural and social  accommodation. It may, therefore, be possible, for example, to use AI to simulate a  concert pianist playing Bach’s Goldberg variations,  and generate music that sounds  similar. Meaningful interpretation of Goldberg vari ations, however, requires extensive  knowledge about cultural history, reflection of the  relation of Bach to other composers,  knowledge about subsequent interpretations, as well  as years of training. It may take  less than a second to play a note, but it may take many years to be able to do that.  Although it is clear that a concert pianist may not  be a “typical” person, many very  typical everyday tasks require similar enculturatio n and learning. Indeed, a central claim  in Vygotsky’s theory of cognitive development in th e early 1930s was that those  advanced cognitive capabilities that distinguish hu mans from other animals are exactly  those capabilities that cannot be described as simp le reflexes, but which require social  and cultural learning. This suggests that Ng is rea lly talking about instinctive behaviour,  instead of intelligence. The fundamental automation  bottleneck, therefore, is not about  technical capability. It is in the qualitative diff erence between observed behaviour and its  meaning. As soon as the meaning of activity is fixe d, we may be able to mechanize the  behaviour and learn to do this using a large number  of examples of such behaviour.  Many forms of human learning and advanced forms of human cognition, however, are  based on creating meaning where it was not before. To address such areas of human  intelligence, AI researchers will need models of in telligence that far exceed those that are  currently used in artificial intelligence.    2.4.4  Trends and transitions    Econometric studies on the effects of automation, c omputerization, and AI are therefore  interesting and important but they do not capture t he future well. In general terms, there  is no obvious reason why historical trends would re main valid in socio-economic  transitions. Econometric models may be important fo r understanding the present in the  light of the past, but they can predict the future only if nothing important changes. This  is simply because these models are based on data, a nd we don't have empirical data  about the future. 49  They are, however, important because they suggest that we can  predict the future in a very specific way: If nothi ng important changes, wide use of  already existing AI technologies will imply a futur e that will be very different from what it  used to be. This somewhat paradoxical result shows that, if for nothing else, this is  because paid labour used to be such a central facto r in shaping the industrial age, its  institutions, and our everyday life.                                                49  More detailed discussion on this problem can be fo und in Tuomi (2012).Productivity is also often diff icult to  measure when quality change and innovation are impo rtant. This will be the case for AI, in particular,  as it  does not only replace existing functions but transf orms existing ones and creates novel productive tas ks.  For example, the impact of computers has been measu red using "quality adjusted prices" that take into  account developments in technical characteristics o f computer equipment, such as processor clock speed ,  memory bandwidth, and number of transistors on chip s. Because of the almost exponential improvements  in many of these technical features, computers have  become important factors in productivity growth. I t is,  however, not clear how such productivity measures c orrelate with common-sense ideas of productivity. F or  example, it is difficult to say how much more produ ctive a person is writing texts with a computer tha t has  a thousand times faster processor than two decades ago. 
  23   2.4.5  Neural AI as data-biased technological change  A recent study by Nedelkoska and Quintini 50  at the OECD provides a good review of  econometric research on the impact of automation, a nd extends the Frey and Osborne  study using the results of the OECD Survey of Adult  Skills (PIAAC). Nedelkoska and  Quintini matched the technical bottlenecks from Fre y and Osborne to PIAAC variables on  job tasks, such as frequency of complex problem sol ving and advising or teaching others.  The variables used by Nedelkoska and Quintini are s hown in Table 2. For the overall  sample of 32 countries, they found that the median job had a 48 per cent probability of  being automated, with large variations across count ries.    Table 2:  Technical bottlenecks for automation   Engineering  bottlenecks  Variable in PIAAC  Description   Perception manipulation  Fingers (dexterity)  How often - using skill or accuracy with your hands or  fingers?  Creative intelligence  Problem solving, simple  How often - relatively simple problems that take no  more than 5 minutes to find a good solution?  Problem solving, complex  Problem solving - complex problems that  take at least  30 minutes thinking time to find a good solution?  Social intelligence  Teaching  How often - instructing, training or teaching people,  individually or in groups?  Advise  How often - advising people?   Plan for others  How often - planning the  activities of others?   Communication  How often - sharing work -related information with co workers?  Negotiate  How often - negotiating with people either inside or  outside your firm or organization?  Influence  How often - persuading or influencing peopl e?   Sell  How often - selling a product or selling a service?   Source: Adapted from Nedelkoska & Quintini, 2018    Economists have used both skill-biased and task-bia sed models to study the impact of  automation, computers and AI. Neural AI and machine  learning, however, do not fit  these models well. The critical bottleneck is not w hether a task is routine or non-routine,  or whether it requires complex problem solving; ins tead, it is whether the task can be  learned by a computer. This, in turn, depends on wh ether there are data that can be  used for learning. The impact of AI on occupations can, therefore, best be understood in  a “data-biased” model. If data are available and hi story repeats itself, current machine  learning algorithms can at least in principle simul ate the past. To the extent that  learning, innovation and knowledge creation is abou t combining existing pieces of  knowledge, machines may also be able to do that. Fr om a technical point of view, such  operations are purely syntactic. There are good rea sons to expect that social, economic,  and cognitive processes, as well as other systems t hat can be called living, cannot be  simulated using such an approach. 51     2.4.6  Education as a creator of capability platforms    As a result, AI will probably have its biggest impa ct when it is used to augment human  cognition, and in supporting human learning and kno wing. This suggests a general  principle of keeping humans in the loop when AI is used for educational purposes and in                                              50  Nedelkoska and Quintini (2018).  51  Sophisticated mathematical formalisms are needed t o appropriately study the possibility of building  computational models of human cognition, and many A I experts remain agnostic whether this will ever be   possible. See, e.g., Rosen (1998), Loiue (2007, 200 9). 
  24   educational settings. Assuming that some occupation s, perhaps such as truck drivers,  data entry keyers or utilities meter readers, will become obsolete in the near future, an  important question for education policy is how peop le in these occupations can move to  new jobs. A recent study by Royal Bank of Canada (R BC) focused on this question,  locating six skill clusters that can be used to gro up occupations in Canada. 52  Also this  study used O*NET data, but focused on skills, inste ad of tasks as was done in the Frey  and Osborne study. The RBC study argued that as man y occupations overlap in their skill  requirements, it is relatively easy to complement s kills within these clusters in ways that  enable people to move to new jobs when their old jo bs become automated. These  clusters are shown in Table 3. This approach, thus,  complements the view that there are  key transversal skills and competences that are nec essary for future.    Table 3:  Skill clusters and probability of disruption in th eir occupations  Skill cluster  Description  Probability of disruption   Technicians High on technical skills Moderate  Crafters Medium in technical skills, low in  management skills Very high  Doers Emphasis on basic skills High  Solvers Emphasis on management skills  and critical thinking Minimal  Facilitators Emphasis on emotional skills Moderate  Providers High in analytical skills Low  Source: Adapted from RBC, 2018      Similar questions may be asked for key competences as defined in the EU Key  Competences for Lifelong Learning, as well as for t he European Framework for Digital  Competence of Educators. 53   Figure 5 lists some example capabilities that cou ld have  impact on the key competence on languages. In gener al, studies on future work and skill  demand suggest that education cannot easily focus o n specific work-related skills in the  future. Instead, education needs to create competen ce platforms that enable effective  life-long learning. Somewhat paradoxically, such a view on “platform education” suggests  that we may be moving back towards the medieval tri vium 54  and quadrivium 55 , with their  seven liberal arts. Business executives have alread y for many years argued that we need  educational systems that teach people grammar, logi c, rhetoric, arithmetic, and  geometry. Although music and astronomy have not bee n high on the list, perhaps this is  because they are now subsumed under terms such as c reativity and science.                                                          52  RBC (2018).  53  European Commission (EC 2018a), Redecker (2017).  54   The lower division of the seven liberal arts and comprises grammar, logic, and rhetoric, see:  https://en.wikipedia.org/wiki/Trivium  55     Consisted of arithmetic, geometry, music, and a stronomy, see: https://en.wikipedia.org/wiki/Quadri vium 
  25   Figure 5: Skills of the languages key competence and some ass ociated AI capabilities            Source: Author’s elaboration. Council recommendatio n on Key Competences for Lifelong Learning    2.4.7  Direct AI impact on advanced digital skills demand  The development of new AI and machine learning mode ls requires very high levels of  competences in several areas. This is one of the re asons why AI experts are now being  paid extreme salaries. The number of neural AI expe rts is perhaps doubling annually, but  the basic knowledge needed for state-of-the-art wor k in this area requires advanced  levels of scientific, mathematical and technical sk ills that are demanding to acquire.  Development of new AI methods requires good underst anding of statistics, linear  algebra, differential equations, as well as compute r architectures and emerging chip  technologies 56 , programming approaches and tools. The required sk ill set is rather  scarce, and recent estimates put the number of peop le with this set at some tens of  thousands. 57  There are some 5,000 persons who have written acad emic articles or  presented at AI conferences in recent years.     It may be expected that the high visibility of AI a nd the current demand will relatively  rapidly direct talent to this area. As an example, since its launch in May 2018, about 90  000 students from over 80 countries have enrolled t o the six-week Elements of AI – course organised as part of the AI Education progra mme of the Finnish Center of AI. 58   This introductory course has been popular among pol icymakers and in private and public  sector organisations who struggle to make sense of developments in AI. High-level skills  in AI, however, cannot be acquired quickly, and the  scarcity of AI-related skills may have  serious indirect implications for teaching and lear ning. In 2017, AI related business                                              56  One key bottleneck for neural AI is its energy con sumption. As a result, many chip designers are now  trying to develop semiconductor chips that can be u sed for specific AI applications, see e.g. (Salvo 2 018).  57  Element AI has recently calculated the number of p eople with the required skill set at 22,000, see (K ahn  2018).  58   https://www.elementsofai.com  Key skills       Ability to  understand  spoken messages   Initiate, sustain  and conclude  conversations   Read, understand  and drafts texts  Real time  translation   Semantic search   Speech-to-text   Grammar and  spelling   Rhetoric impact   Online dictionaries         Culture-aware  machine  translation   Sentiment  analysis   Personalised  messaging 
  26   mergers and acquisitions were about 21.8 billion US D worldwide, and start-ups without  revenue fetched prices that amount to $5-10 million  per AI expert. 59  As highly-qualified  experts can now earn very high annual salaries, uni versities will have great difficulties in  finding competent teachers for this specialty. Some  practical implementation work can be  done by relative novices using openly available dev elopment tools and learning materials,  but the development of mission-critical application s requires quite advanced skills.60     One rather immediate result of this situation is th at high-level AI talent and compute  capability will probably be provided as a service. This would perhaps mean that there is  not going to be massive needs for high-level AI com petences. Due to the high wage  differentials, many current students of statistics,  mathematics, mathematical physics,  computer and chip design, and perhaps neurophysiolo gy may, however, reconsider their  career paths and find new identities as experts in AI. Moreover, in the current informal  learning environment, easy access to state-of-the-a rt technologies and research could  also mean that high-level AI competences may emerge  from unexpected places, for  example, through open software and open hardware co mmunities.                                                59  Data from PitchBook, quoted in (Bass 2018).  60  One key bottleneck for neural AI is its energy con sumption. As a result, many chip designers are now  trying to develop semiconductor chips that can be u sed for specific AI applications, see e.g. (Salvo 2 018). 
  27   3 Impact on learning, teaching, and education    Since the beginning of the 1980s, and until recentl y, educational applications of AI have  mainly focused on the knowledge-based approach. 61  The most prominent line of research  has been concerned with intelligent tutoring system s, or ITS. 62  These systems use a  knowledge-based architecture. A typical ITS archite cture has a domain model  that  describes the area to be learned and a student model  that describes the current state of  student's knowledge and learning. An expert system or pedagogical model  manages the  introduction of learning materials to the student t hrough an adaptive and interactive user  interface.    These systems have traditionally used the knowledge -based approach, now commonly  known as "gofai" (good-old-fashioned-AI). They have  been successful mainly in relatively  limited and unambiguous domains, such as mathematic s and physics.63  As student  behaviour and learning can also be monitored in ITS  environments in great detail,  intelligent tutoring environments have also been an  important source of data for research  on learning. 64  The difficulty in developing ITS for broad learnin g domains has also  switched the focus to the more narrow problem of us ing AI and machine learning to  generate teacher interfaces for student and learnin g monitoring, and learning  diagnostics. This is commonly known as learning ana lytics and educational data mining  (EDM). 65   3.1  Current developments  In special needs education, AI-based approaches hav e shown potential, for example, in  the early detection of dyslexia. 66  A well-published example is the Swedish company  “Lexplore ” that has developed a system that quickly scans fo r students at risk and  detects dyslexia by tracking reader eye movements. The system uses data-based pattern  recognition, and the company is now expanding to th e US and UK, offering school and  school-district wide scanning. 67  AI-based systems have also been successfully devel oped  for the diagnosis of autism spectrum disorder and a ttention deficit hyperactivity disorder  (ADHD). In particular, child-robot interaction seem s to enable new forms of diagnostics  and special needs educational applications. 68     As student testing plays an important role in many educational systems, many projects  are trying to explore the use of AI for automatic t est generation and assessment. Much of  this work is aimed at automating summative assessme nt, with a promise of reducing  teacher workloads. A possible unintended consequenc e of this work is that high-stakes  testing will be increasingly displaced by frequent low-stakes formative assessment, as  the effort and cost required for assessment decreas es. Current AI systems are very good  in combining evidence from complex and varied sourc es of data and using them for realtime pattern recognition. For example, student home work can relatively easily be  checked and diagnosed by an AI system that has data  on both individual student history  and peer responses. Accumulated formative assessmen ts could, therefore, to a large  extent make high-stakes testing redundant. AI is al so beginning to be used to diagnose  student attention, emotion, and conversation dynami cs in computer-supported learning                                              61  For an early example, see Sleeman and Brown (1982) .  62  E.g., Woolf (2009).  63  E.g. Ritter et al. (2007), Graesser et al. (2005).   64  E.g., Porayska-Pomsta (2015).  65  For a compact review of some relatively recent dev elopments, see Luckin et al. (2016) and a JRC repor t on  Learning Analytics by Ferguson et al. (2016)  66  See, e.g., Drigas and Ioannidou (2012).  67  Jakobsson (2017). For English version, see http:// www.lexplore.com/  68  E.g., Scassellati (2012), Boccanfuso et al. (2016) . 
  28   environments, for example for course development an d management, in an attempt to  generate optimal groups for collaborative learning tasks, and to recognize patterns that  predict student drop-out. 69  To do this effectively, large datasets are needed for training  the systems. As was pointed out above, this is a ma jor technical bottleneck. Student  behavior also has to be actively monitored to provi de feedback for learning. This creates  technical needs to unobtrusively monitor students, for example, using video processing  and remote eye tracking, with associated ethical an d regulatory challenges. Ethically less  problematic are systems that use less granular data  to provide recommendations. For  example, at UC Berkeley students can now get course  recommendations using a system  that relies on neural AI technologies originally de veloped for natural language processing  and machine translation. 70   3.1.1  “No AI without UI”    A core idea in intelligent tutoring systems is that  a student interacts with adaptive  interfaces that personalize learning experiences ba sed on the student and her current  level of learning. The core strength of data-based AI systems, on the other hand, is that  they can process very complex data streams in real time. For next-generation ITS this  means that these systems will need user interfaces (UI) that collect real-time input from  learner behaviour and also historical data that can  be used to model the learner. In  informal terms, this can be called the principle of  “no AI without UI.” There will,  therefore, be considerable commercial interest to p ush various kinds of sensor  technologies and user interfaces to classrooms, as well as to gain access to data from  other learner related data sources, such as social media and game platforms.    Although many ITS systems have been developed in th e cognitivist tradition and based  on an instructivist approach to pedagogy, also othe r pedagogical models have frequently  been used. For example, the idea that technology ca n be used to support and scaffold  learning and act as a competent guide and companion  has been influential. Related  research on social learning and knowledge building and construction has also shaped  research in this area. 71   As constructivist and constructionist models have  gained  popularity, the emphasis has shifted from teaching to more student-centric approaches,  including support for peer-to-peer social learning.  It can be expected that, as  conversational natural language systems such as the  Google Duplex are now becoming  commercially available, teachable conversational ag ents will be one area where  educational AI start-ups try to create new business  in the near future.    3.2  The impact of AI on learning    In formal education, AI can have both positive and negative impact on learning. As AI is  now high on the policy agenda, it may appear that A I should be applied in as many  educational settings as possible. When a new promis ing technology emerges, and when  the limitations of technology and the challenges of  applying it are often not perfectly  understood, technology may seem to open radically n ew possibilities for solving old  problems.    This is what happens at the early phases of the lif e-cycle of general-purpose  technologies, and it leads to technology push. Visi onary entrepreneurs and policymakers                                              69  See, e.g., Nkambou et al. (2018), Rosé et al. (201 8).  70  E.g., Pardos et al. (2018).  71  See, e.g., Scardamalia and Bereiter (2006), Paavol a and Hakkarainen (2005), Thomas and Brown (2011). 
  29   realize the potential of new technology and see all  the possibilities of how it could make a  difference. In the domain of learning, this enthusi asm will be mitigated when people  realize that AI will not only make existing educati on more efficient but that it will also  change the context where learning occurs and where it becomes socially relevant. Many  current learning practices address the needs of an industrial society that is currently  being transformed. It is easy to automate things th at merely institutionalize old habits.  In a changing world, this often creates frustration  as the solutions can become obsolete  already before they are implemented.    In the stage of technology push, technology experts  possess scarce knowledge. Because  it is scarce, it often dominates and overrides othe r types of knowledge. In the domain of  education and training, this can become a problem a s technologists easily transfer their  own experiences and beliefs about learning to their  designs. For example, in the field of  machine learning, learning is often understood as s imple association between system  inputs and outputs. For learning scientists, such a  concept of machine learning may be  an oxymoron. Using technology, it may be possible t o revolutionize learning but it is also  possible to automate ideas and replicate practices that have little to do with learning.    For example, the promise of MOOCs has been widely n oted but we still know very little  about their impact on “delivering desired learning outcomes.” As it is possible for one  teacher to teach very many students in online envir onments, 72  but difficult to know what  the students learn, one of the great promises of AI  is to do large-scale learning analytics  in such environments. For example, it is often sugg ested that AI could be used to  objectively assess student learning by scoring test  results without teacher bias. Given  enough human-labelled examples of data, neural AI a nd machine learning can easily  learn to categorize students based on their test re sults. Yet, it is not clear that test  results are accurate indicators of learning. To sup port learning, it may be more important  to measure individual development than average perf ormance in standardized tests. 73   Neural AI, however, strongly prefers large datasets  and standardized testing. Current  neural AI systems are a natural fit with learning m odels that view learning as transfer of  knowledge to student's mind. If learning is underst ood as the development of skills and  competences, AI my need to be incorporated in learn ing processes in different ways.    For example, IBM's Watson Classroom promises cognit ive solutions that help educators  gain insights into the learning styles, preferences , and aptitudes of each student,  "bringing personalized learning to a whole new leve l." 74  It is, however, not obvious that  such objectives would be beneficial or relevant for  learning. As Vygotsky pointed out long  time ago, the development of many cognitive capabil ities that define advanced forms of  thinking are based on their social relevance and ha ve little immediate relevance for an  individual learner. For example, mediated communica tion through written text is  unnatural for a child who is perfectly able to use speech from an early age. 75  Without a  complex system of social interests and practices, a dvanced conceptual systems such as  those used in mathematics would make little sense f or an individual learner. AI may thus  provide exciting new opportunities for adapting lea rning content based on student's  individual characteristics and learning style, even  when large bodies of empirical research  show that the concept of learning style is perhaps best characterized as an urban myth. 76   In short, computer programs scale up very well, and  AI can easily scale up bad  pedagogical ideas.                                                72  See e.g., Tuomi (2013).  73  See, e.g. Mislevy (2018), Gane et al. (2018).  74  https://www.ibm.com/watson/education  75  Vygotsky (1986).  76  E.g., Riener and Willingham (2010). 
  30   3.2.1  Impact on cognitive development    On a more fundamental level, we can ask what is the  impact of AI on the development of  human cognition and human brain 77 . More broadly, this is a question about co-evoluti on  of technology and human mind. Friedrich Engels’ inf luential unfinished essay “The Part  Played by Labour in the Transition from Ape to Man”  emphasized the specialization of  knowledge, division of productive labour, and the r ole of technology, arguing that the  development of human brain and society were intrins ically connected. 78  Labour, states  Engels in the beginning of his essay, “is the prime  basic condition for all human  existence, and this to such an extent that, in a se nse, we have to say that labour created  man himself.”    The idea that new ways to organize production lead to new forms of "consciousness"  became one of the driving forces in the revolutiona ry movements towards the end of the  19th century. The original idea, however, was essen tially a Darwinian explanation about  how human brain has evolved. This idea of linkages between cognitive development and  social division of knowledge and practical labour i s also today influential in the postVygotskian learning theory, and Vygotsky himself wa s highly interested in the role of  material artefacts and tools in thinking. 79     Recent research on neuroplasticity takes this idea one step further, showing that tools  and technology do not only shape the way we think b ut they can also shape the brain  itself. One could, therefore, ask how the use of AI  technologies in learning changes the  structure of human brains. 80  In particular, recent research shows that there ar e critical  phases in the development of the brain. Cognitive t echnologies may, therefore, have  quite fundamental consequences if used during such critical periods. At present, we don't  know whether this is the case. 81     In general, AI can be used in three essentially dif ferent ways that may have different  implications for the development of human cognitive  capabilities both in children and  adults. First, AI can support existing capabilities . When competences are understood as  combinations of domain specific expertise and behav ioural repertoires, 82  AI can reduce  the need for human knowledge, experience, and skill , and emphasize the importance of  behavioural repertoires. As a result, humans do not  necessarily need to learn domain  specific knowledge that earlier was required for co mpetent behaviour. In particular, as                                              77   See for instance: Gómez, E., Castillo, C., Charis i, V., Dahl, V., Deco, G., Delipetrev, et al. (2018 ).  Assessing the impact of machine intelligence on hum an behaviour: an interdisciplinary endeavour. arXiv   preprint arXiv:1806.03192.  78  Engels (1966, chap. 6). A similar historical appro ach is more recently adopted by Morrison and Miller   (2017), who argue that human learning is a species- specific capability that is in many ways built in t o  human biology, culture and social structures.  79  E.g. Bruner (1986), Engeström (1987).  80  There are now large bodies of empirical research o n structural change in the human brain. Often quote d  studies in this area are by Maguire et al. (2000; W oollett and Maguire 2011). They measured the struct ural  changes in the hippocampus of London taxi-drivers, showing changes in this area associated with spatia l  navigation.  81  For example, it has been shown that musical traini ng in infancy leads to an expanded auditory cortica l  representation, but only if practicing begins befor e the age of 9 (Pantev et al. 1998). Whereas the cl assical  studies focused on the period where normal developm ent occurs, abnormal input can have a permanent  deleterious effect also after the period of normal development is over. Lewis and Maurer (2005) called   these the "sensitive periods for damage," and showe d that visual deprivation up to 10 years of age lea ds to  a permanent deficit in visual acuity.  82  This is suggested, for example, by Hoekstra and va n Slujis (2003). In the context of the three-level model  presented here, such a model of competences appears  too narrow, and would need to be augmented by  both cultural and technical elements that make expr essions of competence possible and relevant. 
  31   domain-specific knowledge becomes less important fo r competence, transversal and  domain-independent generic competences may become r elatively more important.    Second, AI can speed-up cognitive development and c reate cognitive capabilities that  would not be possible without technology. The mecha nization or human work has made  possible things that would be impossible without te chnology; similarly, the mechanization  of cognitive work makes possible new activities tha t have not been possible before. This,  of course, is something that already has happened. It would be entirely impossible to  design a modern microprocessor or a neural chip wit hout computer-aided design tools  that use extensive bodies of design knowledge.    Third, AI may reduce the importance of some human c ognitive capabilities, or make  them obsolete. For example, as AI can convert speec h to text and vice versa, dyslexia  may become socially less important than it has been  in the past. However, although in  cases such as dyslexia and dyscalculia AI may have clear benefits for individuals, the  overall impact is not easy to predict. For example,  computers may support people in  adding and multiplying numbers; if they became reli ant on computational machines, it  may, however, become more difficult to develop more  advanced mathematical skills that  require mental arithmetic and number skills. From a  pedagogic point of view, it may  sometimes be more beneficial to use AI to help peop le to develop competences that allow  them to overcome difficulties in reading and counti ng, instead of using AI to make  redundant skills that underpin important cognitive capabilities.    3.3  The impact of AI on teaching    If we think how AI can most effectively be used in the current educational context, we  easily automate things that used to be important in  the past. It is therefore important to  understand the impact of AI in the context of futur e learning and education, instead of in  current systems of education and forms of learning.  The analysis of the impact of AI on  teaching will, therefore, be inherently linked to f oresight-oriented work on the future of  learning.    Yet, there are some educational tasks where AI can have a clear impact. One such task is  assessment in its various forms. In the conventiona l intelligent tutoring systems a central  component is a student model that maintains informa tion about the current state of the  learner and which, based on the student model, trie s to infer possible bottlenecks in  student's way of understanding a domain that she or  he is learning.    3.3.1  AI-generated student models and new pedagogical opp ortunities    In principle, neural AI is well suited for diagnost ic tasks. Traditional knowledge-based  intelligent tutoring systems have struggled with th e challenge of creating student models  partly because there is no obvious way to create re presentations of student models in  complex domains and in realistic context of learnin g. Neural AI, however, may generate  student models if sufficient amounts of data are av ailable. As discussed above, words in  natural languages can often be represented using a 300-dimensional space where  millions of words are located based on billions of examples (see 2.3). Machine learning  can generate such complex representations in ways t hat work in practice, despite all their 
  32   conceptual and technical inadequacies. Given enough  data, machine learning can  probably create student models that are good enough  to be of practical value.    Neural AI can also learn patterns of interaction an d associate these with pedagogically  relevant clusters so that a teacher can have a bett er understanding of the ways in which  students think and where they could be effectively guided. AI systems can also provide  such diagnostic data also to the students so that t hey can reflect on their metacognitive  approaches and possible areas in need of developmen t. Neural AI will therefore have  important potential in learning diagnostics, analyt ics and educational data mining.    The rapid advances in natural language processing a nd AI-based human-machine  interfaces will generate new pedagogical possibilit ies, too. For example, as conversational  robots and learning companions are becoming more an d more available, learning by  teaching robots shows some potential 83 . Affective computing and emotion AI will be  important components of such systems. Additionally,  real-time machine translation opens  up new possibilities in language learning, and AI s ystems can be used, for example to  interpret texts written by students thus helping th em to write texts that communicate  better what the student intended  to communicate.    3.3.2  The need for future-oriented vision regarding AI    It is possible to imagine many exciting possibiliti es for AI in teaching. Without clear  pedagogic principles, it is, however, probable that  AI vendors will provide products and  services that address key decision-makers’ perceive d immediate problems, instead of  more fundamental social and economic challenges. Fo r an AI start-up in the educational  sector, it is difficult to offer products and servi ces that require change in current  educational practices.   Therefore, without clear visions and policies that put emerging technical possibilities in  the broader context of the transformation of educat ion and the future of learning,  educational AI will probably mainly be provided as solutions to existing problems. Instead  of renewing the system and orienting it towards the  needs of a post-industrial economy  and knowledge society, AI may therefore mechanize a nd reinvent outdated teaching  practices and make them increasingly difficult to c hange. It may, therefore, be necessary  to develop appropriate visions and policies by simu ltaneously creating future-oriented  models for education and teaching. Creating concret e experimentations in an authentic  context with teachers and experts in education is i mportant. As AI is now very high on  the policy agenda, it is too easy to generate high- level visions of the future that claim  that AI is the next technical revolution. AI is now  frequently called “the new electricity.”  It is therefore important that teachers, who often struggle with concrete demands of  everyday teaching practice and new initiatives, wil l not be electrocuted by this new  technology.    3.4  Re-thinking the role of education in society    On a more systemic level, AI will have a profound i mpact on education systems. This is  not because of any specific characteristics of AI; Instead, AI is one expression of an  ongoing broader transformation that results from di gitalization, global real-time  networking of communication and production, and aut omation of productive processes.                                              83    E.g. see projects such as http://de-enigma.eu/  and https://www.dream2020.eu/   
  33   This has variously been called the information soci ety, the knowledge economy and the  algorithmic revolution. 84  One of the reasons why AI has emerged as major pol icy topic in  recent years is that it is becoming clear that AI w ill have a radical impact on the world of  work. As the current educational institutions have to a large extent emerged as answers  to problems of the industrial age, many of these an swers are now becoming outdated.    It is possible that those economists are right who argue that automation and AI will not  increase unemployment in the future. In the 20 th  century context, this would be good, as  unemployment was a major economic challenge in indu strialized societies. Such  arguments are supported by economic theories that s tart from the assumption that  economies tend toward equilibrium. They are also su pported by common sense that says  that of course people have to work. Adopting such v iews, one may say that of course  there will be work in the future although we do not  yet know how it will look like and  what the jobs will be. It is also possible that wor k in the future will no longer be what it  used to be. In the history of educational thinking,  there has been a constant battle  between views that see education from an instrument al point of view—as a way of  preparing future workers for future jobs—and a more  developmental view that sees  education as a way of realizing human potential. Wh ether there will be jobs in the future  or not, AI seems to push education towards these mo re developmental models of  education. Assuming that AI will transform the labo ur market, a potentially useful way of  imagining the future of education and educational s ystems is to start from the latter  possibility. If we imagine education in a world whe re work is not a central factor in life or  where jobs, as we knew them, do not exist, what wou ld be the role of education? How  could we organize it? What would be its aims and wh at needs would it address?                                                84  The concept of algorithmic revolution is perhaps t he least known of these. It has been discussed by  Zysman (2006). 
  34   4 Policy challenges    The current excitement about AI easily leads to tec hnology push, where AI is viewed as a  solution to a wide variety of problems in education  and learning. It is probably fair to say  that the potential and challenges of AI in educatio n are still not adequately understood.  AI can be understood as a general-purpose technolog y, and it can be applied in many  different ways. Although the characteristics of tec hnology itself may push development  towards specific directions, it is always possible to use technology in many ways and for  many different purposes, also in education. For pol icy development, it is therefore  probably more important to understand why and for w hat we use technology than how it  is used. The future promises of technology, in this  view, have to be justified by making  explicit the motivation of using the technology, as  well as the key assumptions that  underpin the stated motivation. This lifts technolo gy to a level of policy, and we have to  ask what are the objectives and goals of using it. Only if we have such a birds-eye view  on technical development, we can say where we want to go and how technology can help  us on the way. When the assumptions and motivations  are made explicit, they can also  be critically assessed.    A continuous dialogue on the appropriate and responsibl e uses of AI in  education is therefore needed.  As technology and its uses change, important  contributions to this dialogue may emerge from “out siders” who do not represent current  stakeholder interests. Enabling and funding indepen dent research on, for example, the  politics, ethics, social implications, and economy of AI may be a practical way to create  useful inputs to this dialogue.    In the domain of educational policy, it is important f or educators and  policymakers to understand AI in the broader context of the future of learning.   To a large extent, the debate about AI is now about  the ongoing informationalization,  digitalization, and computer-mediated globalization . The current estimates of the impact  of AI and other digital technologies on the labour market highlight the point that the  demand for skills and competences is changing fast,  and the educational system needs to  adapt, in particular when education aims to create skills for work. AI enables the  automation of many productive tasks that in the pas t have been done by humans. As AI  will be used to automate productive processes, we may  need to reinvent current  educational institutions.  It is, for example, possible that formal education  will play a  diminishing role in creating job-related competence s. This could mean that the future  role of education will increasingly be in supportin g human development.    For example, the current AI systems make almost con tinuous assessment of student  progress possible. Instead of high-stakes testing t hat functions as a social filter, AI  supported assessment can be used to help learners t o develop their skills and  competences and keep students on effective learning  paths. With such ongoing  assessment, high-stakes testing may become redundant, and broader e vidence  may be used for assessing skills and competences . This may be important in  particular for assessing transversal key competence s that are now relatively difficult to  assess. As AI and other information technologies fa cilitate informal learning, it also  becomes important to ask what the division of labou r between formal and informal  learning will be in the future.    In general, the balance may thus shift from the instr umental role of education  towards its more developmental role.  Perhaps more importantly, it is possible that  the industrial age link between work and education is changing. Current institutions of 
  35   education to a large extent address the needs of an  industrial world. As knowledge and  data are now created, used, and learned in ways tha t have not been possible before, it is  important that AI is not understood only as a solut ion to problems in the current  educational systems.    In general, the profound changes in the society and  economy that AI and related  technologies are now making possible will create a world where many social institutions  will change, and people have to adapt. When a simil ar broad change occurred almost two  centuries ago, the social and human costs were high . Although we now with hindsight  often neglect the negative consequences of technica l development and emphasize its  positive consequences, it is important to realize t hat general-purpose technologies can  have fundamental transformative impact on social li fe and human development. The  rather poetic declaration in 1848 that "all that is  solid melts into air," was not just a  vision but it was based on careful empirical observ ation of the everyday consequences of  industrialization. 85  A general policy challenge, thus, is to increase amon g  educators and policymakers awareness of AI technologie s and their potential  impact.  One way of doing this is to participate in process es that generate images of  future, develop concepts that can be used to descri be them, and design scenarios and  experiments where such imagined futures can be test ed. A rather simple proposal for  policy development, thus, is to launch explicitly f uture-oriented processes that generate  understanding of the possibilities of the present.    AI provides new means for research on learning, but  it is also important to rethink the  capabilities of AI systems using existing knowledge  about learning. 86  In particular, almost  all currently developed AI systems rely on associat ive and behaviouristic models of  learning. The long history of neural AI contains ma ny attempts to go beyond these  simple models of learning. Learning sciences could have much to offer to researc h  on AI, and such mutual interaction would enable better understanding about  how to use AI for learning and in educational settings , as well as in other  domains of application.    Data that is needed for machine learning is often h ighly personal. If it is used for  assessing student performance, data security can be come a key bottleneck in using AI,  learning analytics, and educational data mining. As  neural AI systems do not understand  the data they process, it is also easy to forge dat a that fools the decision process. 87  AI  security is an important topic, but it is also chal lenging as neural AI systems typically use  complex internal representations of data that are d ifficult or impossible to interpret.  Because of this there is now considerable interest in creating “explainable AI.” The  current systems, however, lack all the essential re flective and metacognitive capabilities  that would be needed to explain what they do or don ’t do. 88  To rephrase Descartes, it is,  therefore, as futile to ask a clock on the wall why  it just struck seven or eight as it is to  ask a deep learning AI system why it gave a specifi c grade to a student. Clocks are not  built to explain their ticking, and AI systems, as we know them, have no explanatory  capabilities. At best they can support humans in ex plaining what happened and why. As  there may be fundamental theoretical and practical lim its in designing AI  systems that can explain their behaviour and decisio ns, it is important to keep  humans in the decision-making loop.                                               85  The quote is from the Manifesto of the Communist P arty by Marx & Engels, 1848.  86  There have been very few attempts to analyse AI fr om the point of view of learning theories. The lear ning  capabilities of convolutional neural networks have been compared with Vygotsky's model of conceptual  development in Tuomi (2018).  87  Pattern matching systems can be very fragile in th eir decision-making capabilities. It is possible, f or  example, to fool image recognition programs by modi fying image pixels (e.g., Yuan et al. 2017; Kurakin ,  Goodfellow, and Bengio 2016).  88  Luckin (2018). 
  36     As several recent reports have emphasized, ethical considerations become highly  relevant when AI is applied in the society or in ed ucational settings. 89  From a policy  perspective, the ethics of AI is a generic challenge, but it has s pecific relevance  for educational policies.     From the regulatory point of view, ethical consider ations provide the fundamental basis  from which new regulations and laws are created and  justified. From a developmental  point of view, ethics and value judgements underpin  fundamental concepts such as  agency, responsibility, identity, freedoms, and hum an capabilities. In supervised AI  learning models, the possible choice outcomes need to be provided to the system before  it starts to learn. This means that the world becom es described in closed terms, based on  predefined interests and categories. Furthermore, t he categories are based on data that  are collected in the past. Neural AI categorizes pe ople in clusters where data from other  people, considered similar by the system, is used t o predict individual characteristics and  behaviour.    From political and ethical points of view, this is highly problematic. Human agency means  that we can make choices about future acts, and thu s become responsible for them.  When AI systems predict our acts using historical d ata averaged over a large number of  other persons, AI systems cannot understand people who make true choices or who  break out from historical patterns of behaviour. AI can therefore also limit the  domain where humans can express their agency .   As has been emphasized above, the recent successes in AI have to a large extent been  based on the availability of vast amounts of data. AI-based products and services can be  created in the educational sector only if appropria te data is available. At present, some of  the existing datasets can be considered as natural monopolies, and they are often  controlled by few large corporations. An important policy challenge is how such  large datasets that are needed for the development and use  of AI-based  systems could be made more widely available.  One potential solution is to build on  the current General Data Protection Regulation whic h requires that data subjects can  have a copy of their personal data from data contro llers in a commonly used electronic  form. Technically this would make it possible for u sers to access their personal data,  anonymize it locally, and submit it in an appropria te format to platforms that are used for  AI learning and educational purposes. Such function ality might be relatively easily  embedded, for example in commonly used web browsers , if platforms for data  aggregation would be available. One possibility cou ld be to pilot such aggregation  platforms on a suitable scale and, if successful, p rovided at the EU level.                                              89   See, e.g., Demiaux and Si Abddallah (2018). The U .K. House of Lords special committee on AI suggests   that the ethical use of AI could become the differe ntiating factor for AI research in the U.K. (House of Lords  2018). Also commercial actors have highlighted the importance of ethical considerations (Microsoft 201 8).  The European group of ethics in science and technol ogy has well emphasized the importance of agency fo r  understanding ethical and political implications of  AI (EGE 2018). Also the European Commission‘s High Level Expert Group on Artificial Intelligence (AI H LEG) is currently developing AI ethics guidelines. 
  37   References      Acemoglu, Daron, and Pascual Restrepo. 2016. “The R ace Between Machine and Man:  Implications of Technology for Growth, Factor Share s and Employment.” Working  Paper 22252. National Bureau of Economic Research.  https://doi.org/10.3386/w22252.  Agrawal, Ajay, Joshua Gans, and Avi Goldfarb, eds. 2018. “Introduction to : ‘Economics  of Artificial Intelligence.’” In Economics of Artificial Intelligence . Toronto: nber.org.  http://www.nber.org/chapters/c14005.pdf.  Anderson, James, A., and Edward Rosenfeld, eds. 198 8. Neurocomputing: Foundations  for Research . Cambridge, MA: The MIT Press.  Autor, David H. 2015. “Why Are There Still So Many Jobs? The History and Future of  Workplace Automation.” Journal of Economic Perspectives  29 (3): 3–30.  https://doi.org/10.1257/jep.29.3.3.  Autor, David H., Frank Levy, and Richard J. Murnane . 2003. “The Skill Content of Recent  Technological Change: An Empirical Exploration.” The Quarterly Journal of  Economics  118 (4): 1279–1333. https://doi.org/10.1162/003355 303322552801.  Bass, A.S. 2018. “Non-Tech Businesses Are Beginning  to Use Artificial Intelligence.”  Financial Times , March 31, 2018.  Boccanfuso, Laura, Erin Barney, Claire Foster, Yeoj in Amy Ahn, Katarzyna Chawarska,  Brian Scassellati, and Frederick Shic. 2016. “Emoti onal Robot to Examine  Differences in Play Patterns and Affective Response  of Children with and Without  ASD.” In The Eleventh ACM/IEEE International Conference on H uman Robot  Interaction , 19–26. HRI ’16. Piscataway, NJ, USA: IEEE Press.  http://dl.acm.org/citation.cfm?id=2906831.2906837.  Boden, Margaret A. 2016. AI: Its Nature and Future . Oxford, New York: Oxford University  Press.  Bostrom, Nick. 2014. Superintelligence: Paths, Dangers, Strategies . 1 edition. Oxford:  Oxford University Press.  Brown, J.S., A. Collins, and P. Duguid. 1989. “Situ ated Cognition and the Culture of  Learning.” Educational Researcher  18 (1): 32–42.  Bruner, J. 1986. Actual Minds, Possible Worlds . Cambridge, MA: Harvard University  Press.  Brynjolfsson, Erik, and Andrew McAfee. 2012. Race Against the Machine: How the Digital  Revolution Is Accelerating Innovation, Driving Prod uctivity, and Irreversibly  Transforming Employment and the Economy . Brynjolfsson and McAfee.  Cole, M. 1986. Culture in Mind . Cambridge, MA: Harvard University Press.  Cole, M., and J.V. Wertsch. 1996. “Beyond the Indiv idual-Social Antinomy in Discussions  of Piaget and Vygotsky.” Human Development  39 (5): 250–56.  Demiaux, Victor, and Yacine Si Abdallah. “How Can H umans Keep the Upper Hand? The  Ethical Matters Raised by Algorithms and Artificial  Intelligence.” Report on the  public debate led by the French Data Protection Aut hority (CNIL) as part of the  ethical discussion assignment set by the Digital Re public Bill. Paris: CNIL,  December 2017.  Dewey, J. 1991. How We Think . Buffalo, NY: Prometheus Books.  Dreyfus, H.L. 1979. What Computers Can’t Do: A Critique of Artificial I ntelligence . New  York: Harper & Row.  Drigas, Athanasios, and Rodi-Eleni Ioannidou. 2012.  “Artificial Intelligence in Special  Education: A Decade Review.” International Journal of Engineering Education  28  (6): 1366–72.  EC. 2018a. “Proposal for a Council Recommendation o n Key Competences for Lifelong  Learning.” COM(2018) 24 final. Brussels: European C ommission. 
3 8 https://ec.europa.eu/education/sites/education/files/recommendation-keycompetences-lifelong-learning.pdf.  ———. 2018b. “Artificial Intelligence for Europe.” COM(2018) 237 Final. Brussels:  European Commission. https://ec.europa.eu/digital-singlemarket/en/news/communication-artificial-intelligence-europe.  EGE. 2018. “Statement on Artificial Intelligence, Robotics and ‘Autonomous’ Systems.  European Group on Ethics in Science and New Technologies.” Brussels: European  Commission. https://ec.europa.eu/research/ege/pdf/ege_ai_statement_2018.pdf.  Engels, Friedrich. 1966. Dialectics of Nature . Moscow,.  Engeström, Y. 1987. Learning by Expanding: An Activity Theoretical Approach to  Developmental Work Research . Helsinki: Orienta Konsultit.  Engeström, Y., J. Virkkunen, M. Helle, J. Pihlaja, and R. Poikela. 1996. “The Change  Laboratory as a Tool for Transforming Work.” Lifelong Learning in Europe  1 (2):  10–17.  EPSC. 2018. “The Age of Artificial Intelligence: Towards a European Strategy for HumanCentric Machines.” 29. EPSC Strategic Notes. European Political Strategy Centre.  https://ec.europa.eu/epsc/sites/epsc/files/epsc_strategicnote_ai.pdf.  Ferguson, R, Brasher, A., Clow, D., Cooper, A.,Hillaire, G., Mittelmeier, J., Rientes, B.,  Ullmann, T. , Vuorikari, R. 2016. “Research Evidence on the Use of Learning  Analytics: Implications for Education Policy.” JRC Science for Policy Report. JRC.  http://europa.eu/!cB93Gb  Freire, P. 1972. Pedagogy of the Oppressed . Harmondsworth: Penguin.  Frey, Carl Benedikt, and Michael A. Osborne. 2013. “The Future of Employment.”  Working Paper. Oxford: Oxford Martin Programme on Technology and  Employment. https://www.oxfordmartin.ox.ac.uk/downloads/academic/future-ofemployment.pdf.  ———. 2017. “The Future of Employment: How Susceptible Are Jobs to  Computerisation?” Technological Forecasting and Social Change  114 (January):  254–80. https://doi.org/10.1016/j.techfore.2016.08.019.  Gane, Brian D., Sania Z. Zaidi, and James W. Pellegrino. 2018. “Measuring What Matters:  Using Technology to Assess Multidimensional Learning.” European Journal of  Education  53 (2): 176–87. https://doi.org/10.1111/ejed.12269.  Gardner, H. 1987. The Mind’s New Science: A History of Cognitive Revolution . New York:  Basic Books.  Gómez, E., Castillo, C., Charisi, V., Dahl, V., Deco, G., Delipetrev, et al. 2018. Assessing  the impact of machine intelligence on human behaviour: an interdisciplinary  endeavour . arXiv preprint arXiv:1806.03192  Graesser, A. C., P. Chipman, B. C. Haynes, and A. Olney. 2005. “AutoTutor: An  Intelligent Tutoring System with Mixed-Initiative Dialogue.” IEEE Transactions on  Education  48 (4): 612–18. https://doi.org/10.1109/TE.2005.856149.  Harré, Rom, David Clarke, and Nicola De Carlo. 1985. Motives and Mechanisms: An  Introduction to the Psychology of Action . London: Methuen & Co. Ltd.  Hayek, F.A. 1945. “The Use of Knowledge in Society.” American Economic Review 35 (4):  519–30.  ———. 1952. The Sensory Order: An Inquiry into the Foundations of Theoretical  Psychology . Chicago, IL: Chicago University Press.  Heinämaa, S., and I. Tuomi. 1989. Ajatuksia Synnyttävät Koneet: Tekoälyn Unia Ja  Painajaisia (Thought Provoking Machines: Dreams and Nightmares of Artificial  Intelligence; in Finnish) . Porvoo: Werner Söderström Osakeyhtiö.  Hoekstra, H.A., and Van Slujis, E. 2003. Managing Competences: Implementing Human  Resource Management. Assen: Koninklijke Van Gorcum.  House of Lords. 2018. “AI in the UK: Ready, Willing and Able?” HL Paper 100. London:  House of Lords, Select Committee on Artificial Intelligence.  https://publications.parliament.uk/pa/ld201719/ldselect/ldai/100/100.pdf.  Hutchins, E. 1995. Cognition in the Wild . Cambridge, MA: MIT Press. 
  39   Jakobsson, Josefin. 2017. “Nya miljoner ska ta dera s dyslexi-startup till USA.” Di Digital ,  March 29, 2017. https://digital.di.se/artikel/nya-m iljoner-ska-ta-deras-dyslexistartup-till-usa.  Kahn, Jeremy. 2018. “Just How Shallow Is the Artifi cial Intelligence Talent Pool?”  Bloomberg.Com , February 7, 2018.  https://www.bloomberg.com/news/articles/2018-02-07/ just-how-shallow-is-theartificial-intelligence-talent-pool.  Kurakin, Alexey, Ian Goodfellow, and Samy Bengio. 2 016. “Adversarial Examples in the  Physical World.” ArXiv:1607.02533 [Cs, Stat] , July.  http://arxiv.org/abs/1607.02533.  Kurzweil, R. 1999. The Age of Spiritual Machines: When Computers Excee d Human  Intelligence . New York: Viking.  Leont’ev, A.N. 1978. Activity, Consciousness, and Personality . Englewood Cliffs, NJ:  Prentice-Hall.  Lewin, Kurt. 1946. “Action Research and Minority Pr oblems.” Journal of Social Issues  2  (4): 34–46. https://doi.org/10.1111/j.1540-4560.194 6.tb02295.x.  Lewis, Terri L, and Daphne Maurer. 2005. “Multiple Sensitive Periods in Human Visual  Development: Evidence from Visually Deprived Childr en.” Developmental  Psychobiology  46 (3): 163–83. https://doi.org/10.1002/dev.20055.   Louie, A. H. 2007. “A Living System Must Have Nonco mputable Models.” Artificial Life  13  (3): 293–97.  ———. 2009. More than Life Itself: A Synthetic Continuation in Relational Biology .  Frankfurt: Ontos Verlag.  Luckin, Rosemary. 2018. Machine Learning and Human Intelligence: The Future  of  Education for the 21st Century . London: UCL Institute of Education Press.  Luckin, Rosemary, Griffiths, M., and Forcier, L.B. 2016. “Intelligence Unleashed. An  Argument for AI in Education.” London: Pearson.  Luria, A.R., and L. Vygotsky. 1992. Ape, Primitive Man, and Child: Essays in the Histor y  of Behavior . Hemel Hempstead: Harvester Wheatsheaf.  Mace, W.M. 1977. “James J. Gibson’s Strategy for Pe rceiving: Ask No What’s inside Your  Head, but What Your Head’s inside Of.” In Perceiving, Acting and Knowing:  Toward Ecological Psychology , edited by R. Shaw. New York: John Wiley & Sons.  Maguire, Eleanor A., David G. Gadian, Ingrid S. Joh nsrude, Catriona D. Good, John  Ashburner, Richard S. J. Frackowiak, and Christophe r D. Frith. 2000. “NavigationRelated Structural Change in the Hippocampi of Taxi  Drivers.” Proceedings of the  National Academy of Sciences  97 (8): 4398–4403.  https://doi.org/10.1073/pnas.070039597.  McCorduck, P. 1979. Machines Who Think: A Personal Inquiry into the His tory and  Prospects of Artificial Intelligence . San Francisco, CA: W.H. Freeman and  Company.  McCulloch, W.S., and W.H. Pitts. 1943. “A Logical C alculus of the Ideas Immanent in  Nervous Activity.” Bulletin of Mathematical Biophysics  5: 115–33.  Metz, Cade. 2018. “A.I. Researchers Are Making More  Than $1 Million, Even at a  Nonprofit.” The New York Times , May 4, 2018, sec. Technology.  https://www.nytimes.com/2018/04/19/technology/artif icial-intelligence-salariesopenai.html.  Microsoft. 2018. “The Future Computed: Artificial I ntelligence and Its Role in Society.”  Redmond, WA: Microsoft Corporation.  Mislevy, Robert J. 2018. Sociocognitive Foundations of Educational Measureme nt . New  York: Routledge.  Morrison, Donald M., and Kenneth B. Miller. 2017. “ Teaching and Learning in the  Pleistocene: A Biocultural Account of Human Pedagog y and Its Implications for  AIED.” International Journal of Artificial Intelligence in  Education , September, 1– 31. https://doi.org/10.1007/s40593-017-0153-0.  Nedelkoska, L., and G. Quintini. 2018. “Automation,  Skills Use and Training.” 202. OECD  Social, Employment and Migration Working Papers. Pa ris: OECD. 
  40   Neumann, John von. 1951. “The General and Logical T heory of Automata.” In Cerebral  Mechanisms in Behavior; the Hixon Symposium , 1–41. Oxford: Wiley.  Ng, Andrew. 2016. “Andrew Ng: What AI Can and Can’t  Do.” Harvard Business Review.  November 9, 2016. https://hbr.org/2016/11/what-arti ficial-intelligence-can-andcant-do-right-now.  Nilsson, Nils J. 2009. The Quest for Artificial Intelligence: A History of  Ideas and  Achievement . Cambridge: Cambridge University Press.  https://doi.org/10.1017/CBO9780511819346.  Nkambou, Roger, Roger Azevedo, and Julita Vassileva , eds. 2018. Intelligent Tutoring  Systems: 14th International Conference, ITS 2018, M ontreal, QC, Canada, June  11–15, 2018, Proceedings . Programming and Software Engineering. Springer  International Publishing.  Norman, D.A. 1993. “Cognition in the Head and in th e World: An Introduction to the  Special Issue on Situated Action.” Cognitive Science  17: 1–6.  Paavola, Sami, and Kai Hakkarainen. 2005. “The Know ledge Creation Metaphor – An  Emergent Epistemological Approach to Learning.” Science & Education  14 (6):  535–57. https://doi.org/10.1007/s11191-004-5157-0.  Pantev, C, R Oostenveld, A Engelien, B Ross, L E Ro berts, and M Hoke. 1998. “Increased  Auditory Cortical Representation in Musicians.” Nature  392 (6678): 811–14.  https://doi.org/10.1038/33918.  Papert, Seymour. 1980. Mindstorms: Children, Computers, and Powerful Ideas . New  York, NY, USA: Basic Books, Inc.  Papert, Seymour, and Idit Harel. 1991. Constructionism . Ablex.  Pardos, Zachary A., Zihao Fan, and Weijie Jiang. 20 18. “Connectionist Recommendation  in the Wild.” ArXiv:1803.09535 [Cs] , March. http://arxiv.org/abs/1803.09535.  Pennington, Jeffrey, Richard Socher, and Christophe r D. Manning. 2014. “GloVe: Global  Vectors for Word Representation.” In Proceedings of the 2014 Conference on  Empirical Methods in Natural Language Processing (E MNLP) , 1532–43. Doha:  Association for Computational Linguistics.  Polanyi, M. 1967. The Tacit Dimension . New York: Anchor.  Porayska-Pomsta, Kaska. 2015. “AI in Education as a  Methodology for Enabling  Educational Evidence-Based Practice.” In Seventeenth International Conference on  Artificial Intelligence in Education (AIED 2015) , 52–61. Madrid.  Rajpurkar, Pranav, Jeremy Irvin, Kaylie Zhu, Brando n Yang, Hershel Mehta, Tony Duan,  Daisy Ding, et al. 2017. “CheXNet: Radiologist-Leve l Pneumonia Detection on  Chest X-Rays with Deep Learning.” ArXiv:1711.05225 [Cs, Stat] , November.  http://arxiv.org/abs/1711.05225.  Rashevsky, Nicolas. 1954. “Topology and Life: In Se arch of General Mathematical  Principles in Biology and Sociology.” Bulletin of Mathematical Biophysics  16: 317– 48.  ———. 1960. Mathematical Biophysics : Physico-Mathematical Foun dations of Biology . 3rd  rev. ed. Dover.  ———. 1972. Organismic Sets: Some Reflections on the Nature of Life and Society .  Holland, Michigan: Mathematical Biology, Inc.  RBC. 2018. “Humans Wanted: How Canadian Youth Can T hrive in the Age of Disruption.”  Royal Bank of Canada. http://www.rbc.com/humanswant ed.  Redecker, Christine. 2017. “European Framework for the Digital Competence of  Educators.” EUR 28775 EN. JRC Science for Policy Re port. Luxembourg:  Publications Office of the European Union.  Riener, Cedar, and Daniel Willingham. 2010. “The My th of Learning Styles.” Change: The  Magazine of Higher Learning  42 (5): 32–35.  https://doi.org/10.1080/00091383.2010.503139.  Ritter, Steven, John R. Anderson, Kenneth R. Koedin ger, and Albert Corbett. 2007.  “Cognitive Tutor: Applied Research in Mathematics E ducation.” Psychonomic  Bulletin & Review  14 (2): 249–55. https://doi.org/10.3758/BF03194060 .  Rosé, Carolyn Penstein, Roberto Martínez-Maldonado,  Ulrich Hoppe, Rose Luckin, Manolis  Mavrikis, Kaska Porayska-Pomsta, Bruce McLaren, and  Benedict du Boulay, eds. 
4 1 2018. Artificial Intelligence in Education: 19th International Conference, AIED  2018, London, UK, June 27–30, 2018, Proceedings, Part I. Lecture Notes in  Artificial Intelligence. Springer International Publishing.  Rosen, Robert. 1958. “A Relational Theory of Biological Systems.” Bulletin of  Mathematical Biophysics  20: 245–60.  ———. 1985. Anticipatory Systems: Philosophical, Mathematical and Methodological  Foundations . Oxford: Pergamon Press.  ———. 1991. Life Itself: A Comprehensible Inquiry into the Nature, Origin and Fabrication  of Life . New York: Columbia University Press.  ———. 1998. “Causal Structures in Brains and Machines.” International Journal on  General Systems  12: 107–26.  Rosenblatt, Frank. 1958. “The Perceptron: A Probabilistic Model for Information Storage  and Organization in the Brain.” Psychological Review  65: 386–408.  Rumelhart, D.E., and J.L. McClelland. 1986. Parallel Distributed Processing: Explorations  in the Microstructure of Cognition, Vol. 1: Foundations; Vol 2: Psychological and  Biological Models . Cambridge, MA: The MIT Press.  Salomon, G. 1993. Distributed Cognitions: Psychological and Educational Considerations .  Cambridge: Cambridge University Press.  Salvo, B. De. 2018. “Brain-Inspired Technologies: Towards Chips That Think?” In 2018  IEEE International Solid - State Circuits Conference - (ISSCC) , 12–18.  https://doi.org/10.1109/ISSCC.2018.8310165.  Scardamalia, M, and C Bereiter. 2006. “Knowledge Building: Theory, Pedagogy, and  Technology.” In Cambridge Handbook of the Learning Sciences , 97–118. New  York: Cambridge University Press.  Scassellati, Brian, Henny Admoni, and Maja Matarić. 2012. “Robots for Use in Autism  Research.” Annual Review of Biomedical Engineering  14 (1): 275–94.  https://doi.org/10.1146/annurev-bioeng-071811-150036.  Silver, David, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai,  Arthur Guez, Marc Lanctot, et al. 2017. “Mastering Chess and Shogi by Self-Play  with a General Reinforcement Learning Algorithm.” ArXiv:1712.01815 [Cs] ,  December. http://arxiv.org/abs/1712.01815.  Sleeman, D., and J.S. Brown. 1982. Intelligent Tutoring Systems . New York: Academic  Press.  Somers, James. 2017. “Is AI Riding a One-Trick Pony?” MIT Technology Review.  September 29, 2017. https://www.technologyreview.com/s/608911/is-ai-riding-aone-trick-pony/.  Steering Group of the Artificial Intelligence Progamme. 2017. “Finland’s age of artificial  intelligence: Turning Finland into a leading country in the application of artificial  intelligence.” MEAE reports 41/2017. Publications of Ministry of Economic Affairs  and Employment. Helsinki. http://urn.fi/URN:ISBN:978- 952- 327- 24 8- 4.  Suchman, L. 1987. Plans and Situated Actions: The Problem of Human-Machine  Communication.  New York: Cambridge University Press.  Thomas, Douglas, and John Seely Brown. 2011. A New Culture of Learning: Cultivating  the Imagination for a World of Constant Change . CreateSpace Independent  Publishing Platform.  Tuomi, Ilkka. 1988. “Neural Networks as Dynamical Systems: Some Theoretical Reasons  for Non-Algorithmic Information Processing.” Proceedings of the Finnish Artificial  Intelligence Symposium, STeP-88, Vol 2, 593–601.  ———. 2002a. Networks of Innovation . Oxford: Oxford University Press.  ———. 2002b. “The Lives and Death of Moore’s Law.” First Monday  7 (11).  http://www.firstmonday.org/issues/issue7_11/tuomi/.  ———. 2009. “The Future of Semiconductor Intellectual Property Architectural Blocks in  Europe.” EUR 23962 EN. JRC Scientific and Technical Reports. Luxembourg:  European Commission. http://ftp.jrc.es/EURdoc/JRC52422.pdf.  ———. 2012. “Foresight in an Unpredictable World.” Technology Analysis & Strategic  Management  24 (8): 735–51. https://doi.org/10.1080/09537325.2012.715476. 
4 2 ———. 2013. “Open Educational Resources and the Transformation of Education.”  European Journal of Education  48 (1): 58–78.  https://doi.org/10.1111/ejed.12019.  ———. 2018. “Vygotsky Meets Backgpropagation: Artificial Neural Models and the  Development of Higher Forms of Thought.” In Artificial Intelligence in Education.  AIED 2018 . Lecture Notes in Artificial Intelligence, Vol. 10947. Cham: Springer.  https://doi.org/10.1007/978-3-319-93843-1_42.  U.S. GAO. 2018. “Artificial Intelligence: Emerging Opportunities, Challenges, and  Implications.” GAO-18-142SP. United States Government Accountability Office.  Veer, R. van der, and J. Valsiner. 1994. Understanding Vygotsky: A Quest for Synthesis .  Cambridge, MA: Blackwell Publishers.  Vouloutsi, V., Blancas, M., Zucca, R., Omedas, P., Reidsma, D., Davison, D., ... &  Cameron, D. 2016. Towards a synthetic tutor assistant: the EASEL project and its  architecture . In Conference on Biomimetic and Biohybrid Systems (pp. 353-364).  Springer, Cham.  Vygotsky, Lev. 1986. Thought and Language . Cambridge, MA: The MIT Press.  Winograd, T., and F. Flores. 1986. Understanding Computers and Cognition: A New  Foundation for Design . Norwood, NJ: Ablex Publishing Corporation.  Woolf, Beverly Park. 2009. Building Intelligent Interactive Tutors: Student-Centered  Strategies for Revolutionizing e-Learning.  San Francisco, CA: Morgan Kaufmann.  Woollett, and E. A. Maguire. 2011. “Acquiring ‘the Knowledge’ of London’s Layout Drives  Structural Brain Changes.” Current Biology  21 (24): 2109–14.  Yuan, Xiaoyong, Pan He, Qile Zhu, Rajendra Rana Bhat, and Xiaolin Li. 2017. “Adversarial  Examples: Attacks and Defenses for Deep Learning.” ArXiv:1712.07107 [Cs,  Stat], December. http://arxiv.org/abs/1712.07107.  Zysman, John. 2006. “The Algorithmic Revolution---the Fourth Service Transformation.”  Communications of the ACM  49 (7): 48.  
XX-NA-xxxxx -EN-N  GETTING IN TOUCH WITH THE EU   In person   All over  the European Union there are hundreds of Europe Direct information centres. You can find the  address of the centre nearest you at: http://europea.eu/contact   On the phone or by email   Europe  Direct is a service that answers your questions about the European Union. You can contact this  service:   - by freephone: 00 800 6 7 8 9 10 11 (certain operator s may charge for these calls),   - at the following standard number: +32 22999696, or   - by electronic mail via: http://europa.eu/contact   FINDING INFORMATION ABOUT THE EU   Online   Information about the European Union in all the official languages of the EU is available on the Europa  website at: http://europa.eu   EU publications   You can download or order free and priced EU publications from EU Bookshop at:  http://bookshop.europa.eu . Multiple copies of free publications may be obtained by contacting Europe  Direct or your local information centre (see http://europa.eu/contact ). 
43    KJ-NA-29442-EN-N   doi:10.2760/ 12297 ISBN 978-92-79-97257- 7
