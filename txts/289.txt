RR\1215422EN.docx PE650.508v02-00 ENUnited in diversityENEuropean Parliament 2019-2024 Plenary sitting A9-0186/2020 8.10.2020 REPORT with recommendations to the Commission on a framework of ethical aspects of  artificial intelligence, robotics and related technologies  (2020/2012(INL)) Committee on Legal Affairs Rapporteur: Ibán García del Blanco Rapporteurs for the opinion (*): Urmas Paet, Committee on Foreign Affairs Alexandra Geese, Committee on Internal Market and Consumer Protection Valter Flego, Committee on Transport and Tourism Assita Kanko, Committee on Civil Liberties, Justice and Home Affairs (*) Associated committees – Rule 57 of the Rules of Procedure   (Initiative – Rule 47 of the Rules of Procedure) 
PE650.508v02-00 2/130 RR\1215422EN.docx ENPR_INL CONTENTS Page MOTION FOR A EUROPEAN PARLIAMENT RESOLUTION............................................. 3 ANNEX TO THE MOTION FOR A RESOLUTION: DETAILED RECOMMENDATIONS  AS TO THE CONTENT OF THE PROPOSAL REQUESTED.............................................. 33 A. PRINCIPLES AND AIMS OF THE PROPOSAL REQUESTED...................................... 33 B. TEXT OF THE LEGISLATIVE PROPOSAL REQUESTED ............................................ 37 EXPLANATORY STATEMENT ............................................................................................ 62 OPINION OF THE COMMITTEE ON FOREIGN AFFAIRS................................................ 65 OPINION OF THE COMMITTEE ON THE INTERNAL MARKET AND CONSUMER  PROTECTION.......................................................................................................................... 76 OPINION OF THE COMMITTEE ON TRANSPORT AND TOURISM............................... 84 OPINION OF THE COMMITTEE ON CIVIL LIBERTIES, JUSTICE AND HOME  AFFAIRS .................................................................................................................................. 91 OPINION OF THE COMMITTEE ON EMPLOYMENT AND SOCIAL AFFAIRS .......... 100 OPINION OF THE COMMITTEE ON THE ENVIRONMENT, PUBLIC HEALTH AND  FOOD SAFETY ..................................................................................................................... 108 OPINION OF THE COMMITTEE ON CULTURE AND EDUCATION ............................ 123 INFORMATION ON ADOPTION IN COMMITTEE RESPONSIBLE............................... 129 FINAL VOTE BY ROLL CALL IN COMMITTEE RESPONSIBLE .................................. 130
RR\1215422EN.docx 3/130 PE650.508v02-00 ENMOTION FOR A EUROPEAN PARLIAMENT RESOLUTION with recommendations to the Commission on a framework of ethical aspects of artificial  intelligence, robotics and related technologies (2020/2012(INL)) The European Parliament, – having regard to Article 225 of the Treaty on the Functioning of the European Union, – having regard to Article 114 of the Treaty on the Functioning of the European Union, – having regard to the Charter of Fundamental Rights of the European Union,  – having regard to Council Regulation (EU) 2018/1488 of 28 September 2018  establishing the European High Performance Computing Joint Undertaking1, – having regard to Council Directive 2000/43/EC of 29 June 2000 implementing the  principle of equal treatment between persons irrespective of racial or ethnic origin2  (Racial Equality Directive), – having regard to Council Directive 2000/78/EC of 27 November 2000 establishing a  general framework for equal treatment in employment and occupation3 (Equal  Treatment in Employment Directive), – having regard to Regulation (EU) 2016/679 of the European Parliament and of the  Council of 27 April 2016 on the protection of natural persons with regard to the  processing of personal data and on the free movement of such data, and repealing  Directive 95/46/EC (General Data Protection Regulation)4 (GDPR), and to Directive  (EU) 2016/680 of the European Parliament and of the Council of 27 April 2016 on the  protection of natural persons with regard to the processing of personal data by  competent authorities for the purposes of the prevention, investigation, detection or  prosecution of criminal offences or the execution of criminal penalties, and on the free  movement of such data, and repealing Council Framework Decision 2008/977/JHA5, – having regard to the Interinstitutional Agreement of 13 April 2016 on Better LawMaking6, – having regard to the proposal for a regulation of the European Parliament and of the  Council of 6 June 2018 establishing the Digital Europe Programme for the period 20212027 (COM(2018)0434),  – having regard to the Communication from the Commission to the European Parliament,  1 OJ L 252, 8.10.2018, p. 1. 2 OJ L 180, 19.7.2000, p. 22. 3 OJ L 303, 2.12.2000, p. 16. 4 OJ L 119, 4.5.2016, p. 1. 5 OJ L 119, 4.5.2016, p. 89. 6 OJ L 123, 12.5.2016, p. 1.
PE650.508v02-00 4/130 RR\1215422EN.docx ENthe Council, the European Economic and Social Committee and the Committee of the  Regions of 11 December 2019 on The European Green Deal (COM(2019)0640), – having regard to the Communication from the Commission to the European Parliament,  the Council, the European Economic and Social Committee and the Committee of the  Regions of 19 February 2020 on Artificial Intelligence - A European approach to  excellence and trust (COM(2020)0065), – having regard to the Communication from the Commission to the European Parliament,  the Council, the European Economic and Social Committee and the Committee of the  Regions of 19 February 2020 on A European strategy for data (COM(2020)0066), – having regard to the Communication from the Commission to the European Parliament,  the Council, the European Economic and Social Committee and the Committee of the  Regions of 19 February 2020 on Shaping Europe’s digital future (COM(2020)0067), – having regard to the Council of the European Union’s conclusions on Shaping Europe’s  Digital future of June 2020, – having regard to its resolution of 16 February 2017 with recommendations to the  Commission on Civil Law Rules on Robotics7, – having regard to its resolution of 1 June 2017 on digitising European industry8, – having regard to its resolution of 12 September 2018 on autonomous weapon systems9, – having regard to its resolution of 11 September 2018 on language equality in the digital  age10, – having regard to its resolution of 12 February 2019 on a comprehensive European  industrial policy on artificial intelligence and robotics11, – having regard to the report of 8 April 2019 of the High-Level Expert Group on Artificial  Intelligence set up by the Commission entitled ‘Ethics Guidelines for Trustworthy AI’, – having regard to the briefings and studies prepared at the request of the Panel for the  Future of Science and Technology (STOA), managed by the Scientific Foresight Unit  within the European Parliamentary Research Service, entitled “What if algorithms could  abide by ethical principles?”, “Artificial Intelligence ante portas: Legal & ethical  reflections”, “A governance framework for algorithmic accountability and  transparency”, “Should we fear artificial intelligence?” and “The ethics of artificial  intelligence: Issues and initiatives”, – having regard to the Council of Europe’s Framework Convention for the Protection of  National Minorities, Protocol No 12 to the Convention for the Protection of Human  7 OJ C 252, 18.7.2018, p. 239. 8 OJ C 307, 30.8.2018, p. 163. 9 OJ C 433, 23.12.2019, p. 86. 10 Texts adopted, P8_TA(2018)0332. 11 Texts adopted, P8_TA(2019)0081.
RR\1215422EN.docx 5/130 PE650.508v02-00 ENRights and Fundamental Freedoms, and the European Charter for Regional or Minority  Languages, – having regard to the OECD Council Recommendation on Artificial Intelligence adopted  on 22 May 2019, – having regard to Rules 47 and 54 of its Rules of Procedure, – having regard to the opinions of the Committee on Foreign Affairs, the Committee on  the Internal Market and Consumer Protection, the Committee on Transport and  Tourism, the Committee on Civil Liberties, Justice and Home Affairs, the Committee  on Employment and Social Affairs, the Committee on the Environment, Public Health  and Food Safety and the Committee on Culture and Education, – having regard to the report of the Committee on Legal Affairs (A9-0186/2020), Introduction  A. whereas the development, deployment and use of artificial intelligence (also referred to  as ‘AI’), robotics and related technologies is carried out by humans, and their choices  determine the potential of such technologies to benefit society; B. whereas artificial intelligence, robotics and related technologies that have the potential  to generate opportunities for businesses and benefits for citizens and that can directly  impact all aspects of our societies, including fundamental rights and social and  economic principles and values, as well as have a lasting influence on all areas of  activity, are being promoted and developed quickly; C. whereas artificial intelligence, robotics and related technologies will lead to substantial  changes to the labour market and in the workplace; whereas they can potentially replace  workers performing repetitive activities, facilitate human-machine collaborative  working systems, increase competitiveness and prosperity and create new job  opportunities for qualified workers while at the same time posing a serious challenge in  terms of reorganisation of the workforce;  D. whereas the development of artificial intelligence, robotics and related technologies can  also contribute to reaching the sustainability goals of the European Green Deal in many  different sectors; whereas digital technologies can boost the impact of policies as  regards environmental protection; whereas they can also contribute to reducing traffic  congestion and emissions of greenhouse gases and air pollutants; E. whereas, for sectors like public transport, AI-supported intelligent transport systems can  be used to minimise queuing, optimise routing, enable persons with disabilities to be  more independent, and increase energy efficiency thereby enhancing decarbonisation  efforts and reducing the environmental footprint;  F. whereas these technologies bring about new business opportunities which can  contribute to the recovery of Union industry after the current health and economic crisis  if greater use is made of them, for instance, in the transport industry; whereas such  opportunities can create new jobs, as the uptake of these technologies has the potential 
PE650.508v02-00 6/130 RR\1215422EN.docx ENto increase businesses' productivity levels and contribute to efficiency gains; whereas  innovation programs in this area can enable regional clusters to thrive;  G. whereas the Union and its Member States have a particular responsibility to harness,  promote and enhance the added value of artificial intelligence and make sure that AI  technologies are safe and contribute to the well-being and general interest of their  citizens as they can make a huge contribution to reaching the common goal of  improving the lives of citizens and fostering prosperity within the Union by contributing  to the development of better strategies and innovation in a number of areas and sectors;  whereas, in order to exploit the full potential of artificial intelligence and make users  aware of the benefits and challenges that AI technologies bring,  it is necessary to  include AI or digital literacy in education and training, including in terms of promoting  digital inclusion, and to conduct information campaigns at Union level that give an  accurate representation of all aspects of AI development; H. whereas a common Union regulatory framework for the development, deployment and  use of artificial intelligence, robotics and related technologies (‘regulatory framework  for AI’) should allow citizens to share the benefits drawn from their potential, while  protecting citizens from the potential risks of such technologies and promoting the  trustworthiness of such technologies in the Union and elsewhere; whereas that  framework should be based on Union law and values and guided by the principles of  transparency and explainability, fairness, accountability and responsibility; I. whereas such a regulatory framework is of key importance in avoiding the  fragmentation of the Internal Market, resulting from differing national legislation and  will help foster much needed investment, develop data infrastructure and support  research; whereas it should consist of common legal obligations and ethical principles  as set out in the proposal for a Regulation requested in the annex to this resolution;  whereas it should be established according to the better regulation guidelines; J. whereas the Union has a strict legal framework in place to ensure, inter alia, the  protection of personal data and privacy and non-discrimination, to promote gender  equality, environmental protection and consumers’ rights; whereas such a legal  framework consisting of an extensive body of horizontal and sectoral legislation ,  including the existing rules on product safety and liability, will continue to apply in  relation to artificial intelligence, robotics and related technologies, although certain  adjustments of specific legal instruments may be necessary to reflect the digital  transformation and address new challenges posed by the use of artificial intelligence; K. whereas there are concerns that the current Union legal framework, including the  consumer law and employment and social acquis, data protection legislation, product  safety and market surveillance legislation, as well as antidiscrimination legislation may  no longer be fit for purpose to effectively tackle the risks created by artificial  intelligence, robotics and related technologies; L. whereas in addition to adjustments to existing legislation, legal and ethical questions  relating to AI technologies should be addressed through an effective, comprehensive  and future-proof regulatory framework of Union law reflecting the Union’s principles  and values as enshrined in the Treaties and the Charter of Fundamental Rights that 
RR\1215422EN.docx 7/130 PE650.508v02-00 ENshould refrain from over-regulation, by only closing existing legal loopholes, and  increase legal certainty for businesses and citizens alike, namely by including  mandatory measures to prevent practices that would undoubtedly undermine  fundamental rights; M. whereas any new regulatory framework needs to take into consideration all the interests  at stake; whereas careful examination of the consequences of any new regulatory  framework on all actors in an impact assessment should be a prerequisite for further  legislative steps; whereas the crucial role of Small- and Medium sized enterprises  (SMEs) and start-ups especially in the Union economy justifies a strictly proportionate  approach to enable them to develop and innovate;  N. whereas artificial intelligence, robotics and related technologies can have serious  implications for the material and immaterial integrity of individuals, groups, and society  as a whole, and potential individual and collective harm must be addressed with  legislative responses; O. whereas, in order to respect a Union’s regulatory framework for AI, specific rules for  the Union’s transport sector may need to be adopted; P. whereas AI technologies are of strategic importance for the transport sector, including  due to them raising the safety and accessibility of all modes of transport, and creating  new employment opportunities and more sustainable business models; whereas a Union  approach to the development of artificial intelligence, robotics and related technologies  in transport has the potential to increase the global competitiveness and strategic  autonomy of the Union economy;  Q. whereas human error is still involved in about 95% of all road traffic accidents in the  Union; whereas the Union aimed to reduce annual road fatalities in the Union by 50%  by 2020 compared to 2010, but, in view of stagnating progress, renewed its efforts in its  Road Safety Policy Framework 2021 - 2030 - Next steps towards "Vision Zero";  whereas in this regard, AI, automation and other new technologies have great potential  and vital importance for increasing road safety by reducing the possibilities for human  error; R. whereas the Union’s regulatory framework for AI should also reflect the need to ensure  that workers’ rights are respected; whereas regard should be had to  the European Social  Partners Framework Agreement on Digitalisation of June 2020; S. whereas the scope of the Union’s regulatory framework of AI should be adequate,  proportionate and thoroughly assessed; whereas it should cover a wide range of  technologies and their components, including algorithms, software and data used or  produced by them, a targeted risk-based approach is necessary to avoid hampering  future innovation and the creation of unnecessary burdens, especially for SMEs;  whereas the diversity of applications driven by artificial intelligence, robotics and  related technologies complicates finding a single solution suitable for the entire  spectrum of risks; T. whereas data analysis and AI increasingly impact on the information made accessible to  citizens; whereas such technologies, if misused, may endanger fundamental rights to 
PE650.508v02-00 8/130 RR\1215422EN.docx ENfreedom of expression and information as well as media freedom and pluralism; U. whereas the geographical scope of the Union’s regulatory framework for AI should  cover all the components of artificial intelligence, robotics and related technologies  developed, deployed or used in the Union, including in cases where part of the  technologies might be located outside the Union or not have a specific location; V. whereas the Union’s regulatory framework for AI should encompass all relevant stages,  namely the development, the deployment and the use of the relevant technologies and  their components, requiring due consideration of the relevant legal obligations and  ethical principles and should set the conditions to make sure that developers, deployers  and users are fully compliant with such obligations and principles; W. whereas a harmonised approach to ethical principles relating to artificial intelligence,  robotics and related technologies requires a common understanding in the Union of the  concepts that form the basis of the technologies such as algorithms, software, data or  biometric recognition; X. whereas action at Union level is justified by the need to avoid regulatory fragmentation  or a series of national regulatory provisions with no common denominator and to ensure  a homogenous application of common ethical principles enshrined in law when  developing, deploying and using high-risk artificial intelligence, robotics and related  technologies; whereas clear rules are needed where the risks are significant; Y. whereas common ethical principles are only efficient where they are also enshrined in  law, and those responsible for ensuring, assessing and monitoring compliance are  identified; Z. whereas ethical guidance, such as the principles adopted by the High-Level Expert  Group on Artificial Intelligence, provides a good starting point but cannot ensure that  developers, deployers and users act fairly and guarantee the effective protection of  individuals; whereas such guidance is all the more relevant with regard to high-risk  artificial intelligence, robotics and related technologies; AA. whereas each Member State should designate a national supervisory authority  responsible for ensuring, assessing and monitoring the compliance of the development,  deployment and use of high-risk artificial intelligence, robotics and related technologies  with the Union’s regulatory framework for AI; and for allowing discussions and  exchanges of views in close cooperation with relevant stakeholders and civil society;  whereas national supervisory authorities should cooperate with each other; AB. whereas in order to ensure a harmonised approach across the Union and the optimal  functioning of the Digital Single Market, coordination at Union level by the  Commission, and any/or relevant institutions, bodies, offices and agencies of the Union  that may be designated in this context, should be assessed as regards the new  opportunities and challenges, in particular those of a cross-border nature, arising from  ongoing technological developments; whereas, to this end, the Commission should be  tasked with finding an appropriate solution to structure such coordination at Union  level;
RR\1215422EN.docx 9/130 PE650.508v02-00 ENHuman-centric and human-made artificial intelligence 1. Takes the view that, without prejudice to sector-specific legislation, an effective and  harmonised regulatory framework based on Union law, the Charter of fundamental  rights of the European Union (‘Charter’) and international human rights law, and  applicable, in particular, to high-risk technologies, is necessary in order to establish  equal standards throughout the Union and effectively protect Union values; 2. Believes that any new regulatory framework for AI consisting of legal obligations and  ethical principles for the development, deployment and use of artificial intelligence,  robotics and related technologies should fully respect the Charter and thereby respect  human dignity, autonomy and self-determination of the individual, prevent harm,  promote fairness, inclusion and transparency, eliminate biases and discrimination,  including as regards minority groups, and respect and comply with the principles of  limiting the negative externalities of technology used, of ensuring explainability of  technologies, and of guaranteeing that the technologies are there to serve people and not  replace or decide for them, with the ultimate aim of increasing every human being’s  well-being; 3. Emphasises the asymmetry between those who employ AI technologies and those who  interact and are subject to them; in this context, stresses that citizens’ trust in AI can  only be built on an ethics-by-default and ethics-by-design regulatory framework which  ensures that any AI put into operation fully respects and complies with the Treaties, the  Charter and secondary Union law; considers that building on such an approach should  be in line with the precautionary principle that guides Union legislation and should be at  the heart of any regulatory framework for AI; calls, in this regard, for a clear and  coherent governance model that allows companies and innovators to further develop  artificial intelligence, robotics and related technologies;  4. Believes that any legislative action related to artificial intelligence, robotics and related  technologies should be in line with the principles of necessity and proportionality;  5. Considers that such an approach will allow companies to introduce innovative products  onto the market and create new opportunities while ensuring the protection of Union  values by leading to the development of AI systems which incorporate Union ethical  principles by design; considers that such a values-based regulatory framework would  represent added value by providing the Union with a unique competitive advantage and  make a significant contribution to the well-being and prosperity of Union citizens and  businesses by boosting the internal market; underlines that such a regulatory framework  for AI will also represent added value as regards promoting innovation in the internal  market; believes that for example, in the transport sector, this approach presents Union  businesses with the opportunity to become global leaders in this area; 6. Notes that the Union’s legal framework should apply to artificial intelligence, robotics and  related technologies, including software, algorithms and data used or produced by such  technologies;  7. Notes that the opportunities based on artificial intelligence, robotics and related  technologies rely on ‘Big Data’, with a need for a critical mass of data to train algorithms  and refine results; welcomes in this regard the Commission’s proposal for the creation of a 
PE650.508v02-00 10/130 RR\1215422EN.docx ENcommon data space in the Union to strengthen data exchange and support research in full  respect of European data protection rules; 8. Considers that the current Union legal framework, in particular on protection and  privacy and personal data, will need to fully apply to AI, robotics, and related  technologies and needs to be reviewed and scrutinized on a regular basis and updated  where necessary in order to effectively tackle the risks created by these technologies,  and, in this regard, could benefit from being supplemented with robust guiding ethical  principles; points out that, where it would be premature to adopt legal acts, a soft law  framework should be used;  9. Expects the Commission to integrate a strong ethical approach into the legislative  proposal requested in the annex to this resolution as a follow up to the White Paper on  Artificial Intelligence, including on safety, liability, fundamental rights, which  maximises the opportunities and minimises the risks of AI technologies; expects that the  legislative proposal requested will include policy solutions to the major recognised risks  of artificial intelligence including, amongst others, on the ethical collection and use of  Big Data, the issue of algorithmic transparency and algorithmic bias; calls on the  Commission to develop criteria and indicators to label AI technology in order to  stimulate transparency, explainability, and accountability and incentivise the taking of  additional precautions by developers; stresses the need to invest in integrating nontechnical disciplines in AI study and research taking into account the social context; 10. Considers that artificial intelligence, robotics and related technologies must be tailored  to human needs in line with the principle whereby their development, deployment and  use should always be at the service of human beings and never the other way round, and  should seek to enhance well-being and individual freedom, as well as preserve peace,  prevent conflicts and strengthen international security, while at the same time  maximising the benefits offered and preventing and reducing its risks; 11. Declares that the development, deployment and use of high-risk artificial intelligence,  robotics and related technologies, including but not exclusively by human beings,  should always be ethically guided, and designed to respect and allow for human agency  and democratic oversight, as well as allow the retrieval of human control when needed  by implementing appropriate control measures; Risk assessment 12. Stresses that any future regulation should follow a differentiated and future oriented riskbased approach to regulating artificial intelligence, robotics and related technologies,  including technology-neutral standards across all sectors, with sector-specific standards  where appropriate; notes that, in order to ensure uniform implementation of the system of  risk assessment and that there is compliance with related legal obligations to ensure a  level-playing field among the Member States and to prevent fragmentation of the internal  market, an exhaustive and cumulative list of high-risk sectors and high-risk uses or  purposes is needed; stresses that such a list must be the subject of regular re-evaluation  and notes that, given the evolving nature of these technologies, the way in which their risk  assessment is carried out may need to be reassessed in the future; 13. Considers that the determination of whether artificial intelligence, robotics and related 
RR\1215422EN.docx 11/130 PE650.508v02-00 ENtechnologies should be considered high-risk, and thus subject to mandatory compliance  with legal obligations and ethical principles as set out in the regulatory framework for  AI, should always follow from an impartial, regulated and external ex-ante assessment  based on concrete and defined criteria; 14. Considers, in that regard, that artificial intelligence, robotics and related technologies  should be considered high-risk when their development, deployment and use entail a  significant risk of causing injury or harm to individuals or society, in breach of  fundamental rights and safety rules as laid down in Union law; considers that, for the  purposes of assessing whether AI technologies entail such a risk, the sector where they  are developed, deployed or used, their specific use or purpose and the severity of the  injury or harm that can be expected to occur should be taken into account; the first and  two criteria, namely the sector and the specific use or purpose, should be considered  cumulatively; 15. Underlines that the risk assessment of these technologies should be done on the basis of  an exhaustive and cumulative list of high-risk sectors and high-risk uses and purposes;  strongly believes that there should be coherence within the Union when it comes to the  risk assessment of these technologies, especially when they are assessed both in light of  their compliance with the regulatory framework for AI and in accordance with any other  applicable sector-specific legislation;  16. Considers that this risk-based approach should be developed in a way that limits the  administrative burden for companies, and SMEs in particular, as much as possible by  using existing tools; such tools include but are not limited to the Data Protection Impact  Assessment list as provided for in Regulation (EU) 2016/679; Safety features, transparency and accountability 17. Recalls that the right to information of consumers is anchored as a key principle under  Union law and underlines that it therefore should be fully implemented in relation to  artificial intelligence, robotics and related technologies; opines it should especially  encompass transparency regarding interaction with artificial intelligence systems,  including automation processes, and regarding their mode of functioning, capabilities,  for example how information is filtered and presented, accuracy and limitations;  considers that such information should be provided to the national supervisory  authorities and national consumer protection authorities; 18. Underlines that consumer trust is essential for the development and implementation of  these technologies, which can carry inherent risks when they are based on opaque  algorithms and biased data sets; believes that consumers should have the right to be  adequately informed in an understandable, timely, standardised, accurate and accessible  manner about the existence, reasoning, possible outcome and impacts for consumers of  algorithmic systems, about how to reach a human with decision-making powers, and about  how the system’s decisions can be checked, meaningfully contested and corrected;  underlines, in this regard, the need to consider and respect the principles of information  and disclosure on which the consumer acquis has been built; considers it necessary to  provide detailed information to end-users regarding the operation of transport systems and  AI-supported vehicles;
PE650.508v02-00 12/130 RR\1215422EN.docx EN19. Notes that it is essential that the algorithms and data sets used or produced by artificial  intelligence, robotics, and related technologies are explainable and, where strictly  necessary and in full respect of Union legislation on data protection, privacy and  intellectual property rights and trade secrets, accessible by public authorities such as  national supervisory authorities and market surveillance authorities; further notes that, in  accordance with the highest possible and applicable industry standards, documentation  should be stored by those who are involved in the different stages of the development of  high-risk technologies; notes the possibility that market surveillance authorities may have  additional prerogatives in that respect; stresses in this respect the role of lawful reverseengineering; considers that an examination of the current market surveillance legislation  might be necessary to ensure that it responds ethically to the emergence of artificial  intelligence, robotics and related technologies; 20. Calls for a requirement for developers and deployers of high-risk technologies to, where  a risk assessment so indicates, provide public authorities with the relevant  documentation on the use and design and safety instructions, including, when strictly  necessary and in full respect of Union legislation on data protection, privacy,  intellectual property rights and trade secrets, source code, development tools and data  used by the system; notes that such an obligation would allow for the assessment of  their compliance with Union law and ethical principles and notes, in that respect, the  example provided by the legal deposit of publications of a national library; notes the  important distinction between transparency of algorithms and transparency of the use of  algorithms;  21. Further notes that, in order to respect human dignity, autonomy and safety, due  consideration should be given to vital and advanced medical appliances and the need for  independent trusted authorities to retain the means necessary to provide services to  persons carrying these appliances, where the original developer or deployer no longer  provides them; for example; such services would include maintenance, repairs and  enhancements, including software updates that fix malfunctions and vulnerabilities; 22. Maintains that high-risk artificial intelligence, robotics and related technologies,  including the software, algorithms and data used or produced by such technologies,  regardless of the field in which they are developed, deployed and used, should be  developed by design in a secure, traceable, technically robust, reliable, ethical and  legally binding manner and be subject to independent control and oversight; considers  especially that all players throughout the development and supply chains of artificial  intelligence products and services should be legally accountable and highlights the need  for mechanisms to ensure liability and accountability; 23. Underlines that regulation and guidelines concerning explainability, auditability,  traceability, and transparency, as well, where so required by a risk assessment, and  strictly necessary and while fully respecting Union law such as that concerning data  protection, privacy, intellectual property rights and trade secrets, as access by public  authorities to technology, data and computing systems underlying such technologies,  are essential to ensuring citizens’ trust in those technologies, even if the degree of  explainability is relative to the complexity of the technologies; points out that it is not  always possible to explain why a model has led to a particular result or decision, black  box algorithms being a case in point; considers, therefore, that the respect of these 
RR\1215422EN.docx 13/130 PE650.508v02-00 ENprinciples is a precondition to guarantee accountability; 24. Considers that citizens, including consumers, should be informed when interacting with  a system using artificial intelligence in particular to personalise a product or service to  its users, whether and how they can switch off or restrain the personalisation;  25. Points out in this regard that, if they are to be trustworthy, artificial intelligence,  robotics and their related technologies must be technically robust and accurate; 26. Stresses that the protection of networks of interconnected AI and robotics is important  and strong measures must be taken to prevent security breaches, data leaks, data  poisoning, cyber-attacks and the misuse of personal data, and that this will require the  relevant agencies, bodies and institutions both at Union and national level to work  together and in cooperation with end users of these technologies; calls on the  Commission and Member States to ensure that Union values and respect for  fundamental rights are observed at all times when developing and deploying AI  technology in order to ensure the security and resilience of the Union’s digital  infrastructure; Non-bias and non-discrimination  27. Recalls that artificial intelligence, depending on how it is developed and used, has the  potential to create and reinforce biases, including through inherent biases in the  underlying datasets, and therefore, create various forms of automated discrimination,  including indirect discrimination, concerning in particular groups of people with similar  characteristics; calls on the Commission and the Member States to take any possible  measure to avoid such biases and to ensure the full protection of fundamental rights; 28. Is concerned by the risks of biases and discrimination in the development, deployment  and use of high-risk artificial intelligence, robotics and related technologies, including  the software, algorithms and data used or produced by such technologies; recalls that, in  all circumstances, they should respect Union law, as well as human rights and dignity,  and autonomy and self-determination of the individual, and ensure equal treatment and  non-discrimination for all; 29. Stresses that AI technologies should be designed to respect, serve and protect Union  values and physical and mental integrity, uphold the Union’s cultural and linguistic  diversity and help satisfy essential needs; underlines the need to avoid any use that  might lead to inadmissible direct or indirect coercion, threaten to undermine  psychological autonomy and mental health or lead to unjustified surveillance, deception  or inadmissible manipulation; 30. Firmly believes that the fundamental human rights enshrined in the Charter should be  strictly respected so as to ensure that these emerging technologies do not create gaps in  terms of protection; 31. Affirms that possible bias in and discrimination by software, algorithms and data can  cause manifest harm to individuals and to society, therefore they should be addressed by  encouraging the development and sharing of strategies to counter these, such as debiasing datasets in research and development, and by the development of rules on data 
PE650.508v02-00 14/130 RR\1215422EN.docx ENprocessing; considers this approach to have the potential to turn software, algorithms  and data into an asset in fighting bias and discrimination in certain situations, and a  force for equal rights and positive social change; 32. Maintains that ethical values of fairness, accuracy, confidentiality and transparency should  be the basis of these technologies, which in this context entails that their operations should  be such that they do not generate biased outputs; 33. Underlines the importance of the quality of data sets used for artificial intelligence,  robotics and related technologies depending on their context, especially regarding the  representativeness of the training data, on the de-biasing of data sets, on the algorithms  used, and on data and aggregation standards; stresses that those data sets should be  auditable by national supervisory authorities whenever called upon to ensure their  conformity with the previously referenced principles; 34. Highlights that, in the context of the widespread disinformation war, particularly driven  by non-European actors, AI technologies might have ethically adverse effects by  exploiting biases in data and algorithms or by deliberately altering learning data by a  third country, and could be also exposed to other forms of dangerous malign  manipulation in unpredictable ways and with incalculable consequences; there is  therefore an increased need for the Union to continue investment in research, analysis,  innovation and cross-border and cross-sector knowledge transfer in order to develop AI  technologies that would be clearly free of any sort of profiling, bias and discrimination,  and could effectively contribute to combating fake news and disinformation, while at  the same time respecting data privacy and the Union’s legal framework; 35. Recalls the importance of ensuring effective remedies for individuals and calls on the  Member States to ensure that accessible, affordable, independent and effective  procedures and review mechanisms are available to guarantee an impartial human  review of all claims of violations of citizens’ rights, such as consumer or civil rights,  through the use of algorithmic systems, whether stemming from public or private sector  actors; underlines the importance of the draft Directive of the European Parliament and  of the Council on representative actions for the protection of the collective interests of  consumers and repealing Directive 2009/22/EC on which a political agreement was  reached on 22 June 2020, as regards future cases challenging the introduction or ongoing  use of a AI system entailing a risk of violating consumer rights, or seeking remedies for a  violation of rights; asks the Commission and the Member States to ensure that national and  Union consumer organisations have sufficient funding to assist consumers in exercising  their right to a remedy in cases where their rights have been violated; 36. Considers therefore that any natural or legal person should be able to seek redress for a  decision made by artificial intelligence, robotics or related technology to his or her  detriment in breach of Union or national law; 37 Considers that, as a first point of contact in cases of suspected breaches of the Union’s  regulatory framework in this context, national supervisory authorities could equally be  addressed by consumers with requests for redress in view of ensuring the effective  enforcement of the aforementioned framework; Social responsibility and gender balance
RR\1215422EN.docx 15/130 PE650.508v02-00 EN38. Emphasises that socially responsible artificial intelligence, robotics and related  technologies have a role to play in contributing to finding solutions that safeguard and  promote fundamental rights and values of our society such as democracy, the rule of  law, diverse and independent media and objective and freely available information,  health and economic prosperity, equality of opportunity, workers’ and social rights,  quality education, protection of children, cultural and linguistic diversity, gender  equality, digital literacy, innovation and creativity; recalls the need to ensure that the  interests of all citizens, including those who are marginalised or in vulnerable situations,  such as persons with disabilities, are adequately taken into account and represented; 39. Underlines the importance of achieving a high level of overall digital literacy and training  highly skilled professionals in this area as well as ensuring the mutual recognition of such  qualifications throughout the Union; highlights the need of having diverse teams of  developers and engineers working alongside key societal actors to prevent gender and  cultural biases being inadvertently included in AI algorithms, systems and applications;  supports the creation of educational curricula and public-awareness activities concerning  the societal, legal, and ethical impact of artificial intelligence; 40. Stresses the vital importance of guaranteeing freedom of thought and expression, thus  ensuring that these technologies do not promote hate speech or violence  thus considers  hindering or restricting freedom of expression exercised digitally to be unlawful under  the fundamental principles of the Union, except where the exercise of this fundamental  right entails illegal acts; 41. Stresses that artificial intelligence, robotics and related technologies can contribute to  reducing social inequalities and asserts that the European model for their development  must be based on citizens’ trust and greater social cohesion; 42. Stresses that the deployment of any artificial intelligence system should not unduly  restrict users’ access to public services such as social security; therefore calls on the  Commission to assess how this objective can be achieved; 43. Stresses the importance of responsible research and development aiming at maximizing  the full potential of artificial intelligence, robotics and related technologies for citizens  and public good; calls for mobilisation of resources by the Union and its Member States  in order to develop and support responsible innovation; 44. Stresses that technological expertise will be increasingly important and it will therefore  be necessary to update continuously training courses, in particular for future  generations, and to promote the vocational retraining of those already in the labour  market; maintains, in this regard, that innovation and training should be promoted not  only in the private sector but also in the public sector; 45. Insists that the development, deployment and use of these technologies should not cause  injury or harm of any kind to individuals or society or the environment and that,  accordingly, developers, deployers and users of these technologies should be held  responsible for such injury or harm in accordance with the relevant Union and national  liability rules; 46. Calls on Member States to assess whether job losses resulting from the deployment of 
PE650.508v02-00 16/130 RR\1215422EN.docx ENthese technologies should lead to appropriate public policies such as a reduction of  working time; 47. Maintains that a design approach based on Union values and ethical principles is strongly  needed to create the conditions for widespread social acceptance of artificial intelligence,  robotics and related technologies; considers this approach, aimed at developing  trustworthy, ethically responsible and technically robust artificial intelligence, to be an  important enabler for sustainable and smart mobility that is safe and accessible;  48. Draws attention to the high added value provided by autonomous vehicles for persons with  reduced mobility, as such vehicles allow such persons to participate more effectively in  individual road transport and thereby facilitate their daily lives; stresses the importance of  accessibility, especially when designing MaaS-systems (Mobility as a Service); 49. Calls on the Commission to further support the development of trustworthy AI systems in  order to render transport safer, more efficient, accessible, affordable and inclusive,  including for persons with reduced mobility, particularly persons with disabilities, taking  account of Directive (EU) 2019/882 of the European Parliament and of the Council1 and  of Union law on passenger rights; 50. Considers that AI can help to better utilise the skills and competences of people with  disabilities and that the application of AI in the workplace can contribute to inclusive  labour markets and higher employment rates for people with disabilities; Environment and sustainability 51. States that artificial intelligence, robotics and related technologies should be used by  governments and businesses to benefit the people and the planet, contribute to the  achievement of sustainable development, the preservation of the environment, climate  neutrality and circular economy goals; the development, deployment and use of these  technologies should contribute to the green transition, preserve the environment, and  minimise and remedy any harm caused to the environment during their lifecycle and  across their entire supply chain in line with Union law; 52. Given their significant environmental impact, for the purposes of the previous  paragraph, the environmental impact of developing, deploying and using artificial  intelligence, robotics and related technologies could, where relevant and appropriate, be  evaluated throughout their lifetime by sector specific authorities; such evaluation could  include an estimate of the impact of the extraction of the materials needed, and the  energy consumption and the greenhouse gas emissions caused, by their development,  deployment and use; 53. Proposes that for the purpose of developing responsible cutting-edge artificial  intelligence solutions, the potential of artificial intelligence, robotics and related  technologies should be explored, stimulated and maximized through responsible  research and development that requires the mobilisation of resources by the Union and  its Member States; 54. Highlights the fact that the development, deployment and use of these technologies  provide opportunities for promotion of the Sustainable Development Goals outlined by 
RR\1215422EN.docx 17/130 PE650.508v02-00 ENthe United Nations, global energy transition and decarbonisation; 55. Considers that the objectives of social responsibility, gender balance, environmental  protection and sustainability should be without prejudice to existing general and  sectorial obligations within these fields; believes that non-binding implementation  guidelines for developers, deployers and users, especially of high-risk technologies,  regarding the methodology for assessing their compliance with this Regulation and the  achievement of those objectives should be established; 56. Calls on the Union to promote and fund the development of human-centric artificial  intelligence, robotics and related technologies that address environment and climate  challenges and that ensure the respect for fundamental rights through the use of tax,  procurement, or other incentives; 57. Stresses that, despite the current high carbon footprint of development, deployment and  use of artificial intelligence, robotics and related technologies, including automated  decisions and machine learning, those technologies can contribute to the reduction of  the current environmental footprint of the ICT sector; underlines that these and other  properly regulated related technologies should be critical enablers for attaining the goals  of the Green Deal, the UN Sustainable Development Goals and the Paris Agreement in  many different sectors and should boost the impact of policies delivering environmental  protection, for example policies concerning waste reduction and environmental  degradation; 58. Calls on the Commission to carry out a study on the impact of AI technology’s carbon  footprint and the positive and negative impacts of the transition to the use of AI  technology by consumers; 59. Notes that, given the increasing development of AI applications, which require  computational, storage and energy resources, the environmental impact of AI systems  should be considered throughout their lifecycle; 60. Considers that in areas such as health, liability must ultimately lie with a natural or legal  person; emphasises the need for traceable and publicly available training data for  algorithms; 61. Strongly supports the creation of a European Health Data Space12 proposed by the  Commission which aims at promoting health-data exchange and at supporting research in  full respect of data protection, including processing data with AI technology, and which  strengthens and extends the use and re-use of health data; encourages the upscaling of  cross-border exchange of health data, the linking and use of such data through secure,  federated repositories, specific kinds of health information, such as European Health  Records (EHRs), genomic information, and digital health images to facilitate Union-wide  interoperable registers or databases in areas such as research, science and health sectors; 62. Highlights the benefits of AI for disease prevention, treatment and control, exemplified  by AI predicting the COVID19 epidemic before the WHO; urges the Commission to  12 Communication from the Commission to the European Parliament, the Council, the European Economic and  Social Committee and the Committee of the Regions - A European strategy for data, COM(2020)0066
PE650.508v02-00 18/130 RR\1215422EN.docx ENadequately equip ECDC with the regulatory framework and resources for gathering  necessary anonymised real-time global health data independently in conjunction with the  Member States, so as, among other purposes, to address issues revealed by the COVID19  crisis;  Privacy and biometric recognition 63. Observes that data production and use, including personal data such as biometric data,  resulting from the development, deployment and use of artificial intelligence, robotics  and related technologies are rapidly increasing, thereby underlining the need to respect  and enforce the rights of citizens to privacy and protection of personal data in line with  Union law; 64. Points out that the possibility provided by these technologies for using personal and  non-personal data to categorise and micro-target people, identify vulnerabilities of  individuals, or exploit accurate predictive knowledge, has to be counterweighted by  effectively enforced data protection and privacy principles such as data minimisation,  the right to object to profiling and control the use of one’s data, the right to obtain an  explanation of a decision based on automated processing and privacy by design, as well  as those of proportionality, necessity and limitation based on strictly identified purposes  in compliance with GDPR; 65. Emphasises that when remote recognition technologies, such as recognition of biometric  features, notably facial recognition, are used by public authorities, for substantial public  interest purposes, their use should always be disclosed, proportionate, targeted and  limited to specific objectives, restricted in time in accordance with Union law and have  due regard for human dignity and autonomy and the fundamental rights set out in the  Charter. Criteria for and limits to that use should be subject to judicial review and  democratic scrutiny and should take into account its psychological and sociocultural  impact on civil society; 66. Points out that while deploying artificial intelligence, robotics and related technologies  within the framework of public power decisions has benefits, it can result in grave  misuse, such as mass surveillance, predictive policing and breaches of due process  rights; 67. Considers that technologies which can  produce automated decisions, thus replacing  decisions taken by public authorities, should be treated with the utmost precaution ,  notably in the area of justice and law enforcement; 68. Believes that Member States should have recourse to such technologies only if there is  thorough evidence of their trustworthiness and if meaningful human intervention and  review is possible or systematic in cases where fundamental liberties are at stake;  underlines the importance for national authorities to undertake strict fundamental rights  impact assessment for artificial intelligence systems deployed in these cases, especially  following the assessment of those technologies as high-risk; 69. Is of the opinion that any decision taken by artificial intelligence, robotics or related  technologies within the framework of prerogatives of public power should be subject to  meaningful human intervention and due process, especially following the assessment of 
RR\1215422EN.docx 19/130 PE650.508v02-00 ENthose technologies as high-risk; 70. Believes that the technological advancement should not lead to the use of artificial  intelligence, robotics and related technologies to autonomously take public sector  decisions which have a direct and significant impact on citizen’s rights and obligations; 71. Notes that AI, robotics and related technologies in the area of law enforcement and  border control could enhance public safety and security, but also needs extensive and  rigorous public scrutiny and the highest possible level of transparency both with regards  to the risk assessment of individual applications, as well as a general overview of the  use of AI, robotics and related technologies in the area of law enforcement and border  control; considers that such technologies bear significant ethical risks that must be  adequately addressed, considering the possible adverse effects on individuals when it  comes, in particular to their rights to privacy, data protection and non-discrimination;  stresses that their misuse can become a direct threat to democracy and that their  deployment and use must respect the principles of proportionality and necessity, the  Charter of Fundamental Rights, as well as the relevant secondary Union law, such as  data protection rules; stresses that AI should never replace humans in issuing  judgments; considers that decisions, such as getting bail or probation, that are heard in  court, or decisions based solely on automated processing producing a legal effect  concerning the individual or which significantly affect them, must always involve  meaningful assessment and human judgement; Good governance 72. Stresses that appropriate governance of the development, deployment and use of  artificial intelligence, robotics and related technologies, especially high-risk  technologies by having measures in place focusing on accountability and addressing  potential risks of bias and discrimination, can increase citizens’ safety and trust in those  technologies; 73. Considers that a common framework for the governance of these technologies,  coordinated by the Commission and/or any relevant institutions, bodies, offices or  agencies of the that may be designated for this task in this context, to be implemented  by national supervisory authorities in each Member State, would ensure a coherent  European approach and prevent a fragmentation of the single market; 74. Observes that data are used in large volumes in the development of artificial  intelligence, robotics and related technologies and that the processing, sharing of, access  to and use of such data must be governed in accordance with the law and the  requirements of quality, integrity, interoperability, transparency, security, privacy and  control set out therein; 75. Recalls that access to data is an essential component in the growth of the digital  economy; points out in this regard that interoperability of data, by limiting lock-in  effects, plays a key role in ensuring fair market conditions and promoting a level  playing field in the Digital Single Market; 76. Underlines the need to ensure that personal data is protected adequately, especially data  on, or stemming from, vulnerable groups, such as people with disabilities, patients, 
PE650.508v02-00 20/130 RR\1215422EN.docx ENchildren, the elderly, minorities, migrants and other groups at risk of exclusion; 77. Notes that the development, deployment and use of artificial intelligence, robotics and  related technologies by public authorities are often outsourced to private parties;  considers that this should not compromise the protection of public values and  fundamental rights in any way; considers that public procurement terms and conditions  should reflect the ethical standards imposed on public authorities, when applicable; Consumers and the internal market 78. Underlines the importance of a regulatory framework for AI being applicable where  consumers within the Union are users of, subject to, targeted by, or directed towards an  algorithmic system, irrespective of the place of establishment of the entities that develop,  sell or employ the system; furthermore, believes that, in the interest of legal certainty, the  rules set out in such a framework should apply to all developers and across the value chain,  namely the development, deployment and use of the relevant technologies and their  components, and should guarantee a high level of consumer protection;  79. Notes the intrinsic link between artificial intelligence, robotics and related technologies,  including software, algorithms and data used or produced by such technologies, and fields  such as the internet of things, machine learning, rule based systems or automated and  assisted decision making processes; further notes that standardised icons could be  developed to help explain such systems to consumers whenever those systems are  characterised by complexity or are enabled to make decisions that impact the lives of  consumers significantly;  80. Recalls that the Commission should examine the existing legal framework and its  application, including the consumer law acquis, product liability legislation, product  safety legislation and market surveillance legislation, in order to identify legal gaps, as  well as existing regulatory obligations; considers that this is necessary in order to  ascertain whether it is able to respond to the new challenges posed by the emergence of  artificial intelligence, robotics and related technologies and ensure a high level of  consumer protection; 81. Stresses the need to effectively address the challenges created by artificial intelligence,  robotics and related technologies and to ensure that consumers are empowered and properly  protected; underlines the need to look beyond the traditional principles of information and  disclosure on which the consumer acquis has been built, as stronger consumer rights and  clear limitations regarding the development, deployment and use of artificial intelligence,  robotics and related technologies will be necessary to ensure such technology contributes to  making consumers’ lives better and evolves in a way that respects fundamental and  consumer rights and Union values; 82. Points out that the legislative framework introduced by Decision No 768/2008/EC  provides for a harmonised list of obligations for producers, importers and distributors,  encourages the use of standards and provides for several levels of control depending on  the dangerousness of the product; considers that that framework should also apply to AI  embedded products; 83. Notes that for the purpose of analysing the impacts of artificial intelligence, robotics and 
RR\1215422EN.docx 21/130 PE650.508v02-00 ENrelated technologies on consumers, access to data could, when in full respect of Union law,  such as that concerning data protection, privacy and trade secrets, be extended to national  competent authorities ; recalls the importance of educating consumers to be more informed  and skilled when dealing with artificial intelligence, robotics and related technologies, in  order to protect them from potential risks and uphold their rights;   84. Calls on the Commission to propose measures for data traceability, having in mind both  the legality of data acquisition and the protection of consumer rights and fundamental  rights , while fully respecting Union law such as that concerning data protection, privacy,  intellectual property rights and trade secrets;  85. Notes that these technologies should be user-centric and designed in a way that allows  everyone to use AI products or services, regardless of their age, gender, abilities or  characteristics; notes their accessibility for persons with disabilities is of particular  importance; notes that there should not be a one-size-fits-all approach and universal design  principles addressing the widest possible range of users and following relevant  accessibility standards should be considered; stresses that this will enable individuals to  have equitable access to and to actively participate in existing and emerging computermediated human activities and assistive technologies. 86. Stresses that where money originating from public sources significantly contributes to the  development, deployment or use of artificial intelligence, robotics and related  technologies, in addition to open procurement and open contracting standards,  consideration could be given to the possibility of having the code, the generated data -as  far as it is non-personal- and the trained model made public by default upon agreement  with the developer, in order to guarantee transparency, enhance cybersecurity and enable  the reuse thereof so as to foster innovation; stresses that, in this way, the full potential of  the single market can be unlocked, avoiding market fragmentation; 87.  Considers that AI, robotics and related technologies have enormous potential to deliver  opportunities for consumers to have access to several amenities in many aspects of their  lives alongside better products and services, as well as to benefit from better market  surveillance, as long as all applicable principles, conditions, including transparency and  auditability, and regulations continue to apply; Security and defence 88. Highlights that the security and defence policies of the European Union and its Member  States are guided by the principles enshrined in the European Charter of Fundamental  Rights and those of the United Nations Charter, and by a common understanding of the  universal values of respect for the inviolable and inalienable rights of the human person,  human dignity, of freedom, of democracy, of equality and of the rule of law; stresses  that all defence-related efforts within the Union framework must respect those universal  values whilst promoting peace, security and progress in Europe and in the world; 89. Welcomes the endorsement, by the 2019 Meeting of High Contracting Parties to the  United Nations Convention on Certain Conventional Weapons (CCW), of 11 Guiding  Principles for the development and use of autonomous weapons systems; regrets  however the failure to agree on a legally binding instrument regulating lethal  autonomous weapons (LAWS), with an effective enforcement mechanism; welcomes 
PE650.508v02-00 22/130 RR\1215422EN.docx ENand supports the Commission’s High-Level Expert Group on Artificial Intelligence  ‘Ethics Guidelines for Trustworthy AI’ published on 9 April 2019 and its position on  lethal autonomous weapon systems (LAWS); urges Member States to develop national  strategies for the definition and status of lethal autonomous weapons (LAWS) towards a  comprehensive strategy at Union level and to promote, together with the Union’s High  Representative/Vice-President of the Commission (‘HR/VP’) and the Council, the  discussion on LAWS in the UN CCW framework and other relevant fora and the  establishment of international norms regarding the ethical and legal parameters of the  development and use of fully autonomous, semi-autonomous and remotely operated  lethal weapons systems; recalls in this respect its resolution on autonomous weapon  systems of 12 September 2018 and calls once again for the urgent development and  adoption of a common position on lethal autonomous weapon systems, for an  international ban on the development, production and use of lethal autonomous weapon  systems enabling strikes to be carried out without meaningful human control and  without respect for the human-in-the-loop principle, in line with the statement of the  world’s most prominent AI researchers in their open letter from 2015; welcomes the  agreement of Council and Parliament to exclude lethal autonomous weapons ‘without  the possibility for meaningful human control over the selection and engagement  decisions when carrying out strikes’ from actions funded under the European Defence  Fund; believes that ethical aspects of other AI-applications in defence, such as  intelligence, surveillance and reconnaissance (ISR) or cyber operations must not be  overlooked, and special attention must be paid to the development and deployment of  drones in military operations; 90 Underlines that emerging technologies in the defence and security sector not covered by  international law should be judged taking account of the principle of respect for  humanity and the dictates of public conscience; 91. Recommends that any European framework regulating the use of artificial intelligence  (AI)-enabled systems in defence, both in combat and non-combat situations, must  respect all applicable legal regimes, in particular international humanitarian law and  international human rights law, and it must be in compliance with Union law, principles  and values, keeping in mind the disparities in terms of technical and security  infrastructure throughout the Union; 92. Recognises that unlike defence industrial bases, critical AI innovations could come  from small Member States, thus a CSDP-standardized approach should ensure that  smaller Member States and SMEs are not crowded out; stresses that a set of common  EU AI capabilities matched to Member States operating concepts can bridge the  technical gaps that could leave out States lacking the relevant technology, industry  expertise or the ability to implement AI systems in their defence ministries; 93. Considers that current and future security and defence-related activities within the  Union framework will draw on AI, on robotics and autonomy, and on related  technologies and that reliable, robust and trustworthy AI could contribute to a modern  and effective military; the Union must therefore assume a leading role in research and  development of AI systems in the security and defence field; believes that the use of AIenabled applications in security and defence could offer a number of direct benefits to  the operation commander, such as higher quality collected data, greater situational 
RR\1215422EN.docx 23/130 PE650.508v02-00 ENawareness, increased speed for decision-making, reduced risk of collateral damage  thanks to better cabling, protection of forces on the ground, as well as greater reliability  of military equipment and hence reduced risk for humans and human casualties; stresses  that the development of reliable AI in the field of defence is essential for ensuring  European strategic autonomy in capability and operational areas; recalls that AI systems  are also becoming key elements in countering emerging security threats, such as cyber  and hybrid warfare both in the online and offline spheres; underlines at the same time  all the risks and challenges of unregulated use of AI; notes that AI could be exposed to  manipulation, to errors and inaccuracies; 94. Stresses that AI technologies are, in essence, dual use, and the development of AI in  defence-related activities benefits from exchanges between military and civil  technologies; highlights that AI in defence-related activities is a transverse disruptive  technology, the development of which may provide opportunities for the  competitiveness and the strategic autonomy of the Union; 95. Recognises, in the hybrid and advanced warfare context of today, that the volume and  velocity of information during the early phases of a crisis might be overwhelming for  human analysts and that an AI system could process the information to ensure that  human decision-makers are tracking the full spectrum of information within an  appropriate timeframe for a speedy response; 96. Underlines the importance of investing in the development of human capital for  artificial intelligence, fostering the necessary skills and education in the field of security  and defence AI technologies with particular focus on ethics of semi-autonomous and  autonomous operational systems based on human accountability in an AI-enabled  world; stresses in particular the importance of ensuring that ethicists in this field have  appropriate skills and receive proper training ; calls on the Commission to present as  soon as possible its "Reinforcement of the Skills Agenda", announced in the White  Paper on Artificial Intelligence on the 19th February 2020; 97. Stresses that quantum computing could represent the most revolutionary change in  conflict since the advent of atomic weaponry and thus urges that the further  development of quantum computing technologies be a priority for the Union and  Member States; recognises that acts of aggression, including attacks on critical  infrastructure, aided by quantum computing will create a conflict environment in which  the time available to make decisions will be compressed dramatically from days and  hours to minutes and seconds, forcing Member States to develop capabilities that  protect themselves and train both its decision makers and military personnel to respond  effectively within such timeframes; 98. Calls for increased investment in European AI for defence and in the critical  infrastructure that sustains it; 99. Recalls that most of the current military powers worldwide have already engaged in  significant R&D efforts related to the military dimension of artificial intelligence;  considers that the Union must ensure that it does not lag behind in this regard; 100. Calls on the Commission to embed cybersecurity capacity-building in its industrial  policy in order to ensure the development and deployment of safe, resilient and robust 
PE650.508v02-00 24/130 RR\1215422EN.docx ENAI-enabled and robotic systems; calls on the Commission to explore the use of  blockchain-based cybersecurity protocols and applications to improve the resilience,  trustworthiness and robustness of AI infrastructures through disintermediated models of  data encryption; encourages European stakeholders to research and engineer advanced  features that would facilitate the detection of corrupt and malicious AI-enabled &  robotics systems which could undermine the security of the Union and of citizens; 101. Stresses that all AI-systems in defence must have a concrete and well-defined mission  framework, whereby humans retain the agency to detect and disengage or deactivate  deployed systems should they move beyond the mission framework defined and  assigned by a human commander, or should they engage in any escalatory or  unintended action; considers that AI-enabled systems, products and technology intended  for military use should be equipped with a ‘black box’ to record every data transaction  carried out by the machine; 102. Underlines that the entire responsibility and accountability for the decision to design,  develop, deploy and use AI-systems must rest on human operators, as there must be  meaningful human monitoring and control over any weapon system and human intent in  the decision to use force in the execution of any decision of AI-enabled weapons  systems that might have lethal consequences; underlines that human control should  remain effective for the command and control of AI-enabled systems, following the  human-in-the loop, human-on-the loop and human-in-command principles at the  military leadership level; stresses that AI-enabled systems must allow the military  leadership of armies to assume its full responsibility and accountability for the use of  lethal force and exercise the necessary level of judgment, which machines cannot be  endowed with as such judgment must be based on distinction, proportionality and  precaution, for taking lethal or large-scale destructive action by means of such systems;  stresses the need to establish clear and traceable authorisation and accountability  frameworks for the deployment of smart weapons and other AI-enabled systems, using  unique user characteristics like biometric specifications to enable deployment  exclusively by authorised personnel; Transport 103. Highlights the potential of using artificial intelligence, robotics and related technologies  for all autonomous means of road, rail, waterborne and air transport, and also for  boosting the modal shift and intermodality, as such technologies can contribute to  finding the optimal combination of modes of transport for the transport of goods and  passengers; furthermore, stresses their potential to make transport, logistics and traffic  flows more efficient and to make all modes of transport safer, smarter, and more  environmentally friendly; points out that an ethical approach to AI can also be seen as  an early warning system, in particular as regards the safety and efficiency of transport;  104 Highlights the fact that the global competition between companies and economic  regions means that the Union needs to promote investments and strengthen the  international competitiveness of companies operating in the transport sector, by  establishing an environment favourable for the development and application of AI  solutions and further innovations, in which Union-based undertakings can become  world leaders in the development of AI technologies;
RR\1215422EN.docx 25/130 PE650.508v02-00 EN105. Stresses that the Union’s transport sector needs an update of the regulatory framework  concerning such emerging technologies and their use in the transport sector and a clear  ethical framework for achieving trustworthy AI, including safety, security, the respect  of human autonomy, oversight and liability aspects, which will increase benefits that are  shared by all and will be key to boosting investment in research and innovation,  development of skills and the uptake of AI by public services, SMEs, start-ups and  businesses and at the same time ensuring data protection as well as interoperability,  without imposing an unnecessary administrative burden on businesses and consumers;  106. Notes that the development and implementation of AI in the transport sector will not be  possible without modern infrastructure, which is an essential part of intelligent transport  systems; stresses that the persistent divergences in the level of development between  Member States create the risk of depriving the least developed regions and their  inhabitants of the benefits brought by the development of autonomous mobility; calls  for the modernisation of transport infrastructure in the Union, including its integration  into the 5G network, to be adequately funded;  107. Recommends the development of Union-wide trustworthy AI standards for all modes of  transport, including the automotive industry, and for testing of AI-enabled vehicles and  related products and services; 108. Notes that AI systems could help to reduce the number of road fatalities significantly, for  instance through better reaction times and better compliance with rules; considers,  however, that it will be impossible for use of autonomous vehicles to result in the  elimination of all accidents and underlines that this makes the explainability of AI  decisions increasingly important in order to justify shortcomings and unintended  consequences of AI decisions; Employment, workers’ rights, digital skills and the workplace 109. Notes that the application of artificial intelligence, robotics and related technologies at  the workplace can contribute to inclusive labour markets and impact occupational health  and safety, while it can also be used to monitor, evaluate, predict and guide the  performance of workers with direct and indirect consequences for their careers; whereas  AI should have a positive impact on working conditions and be guided by respect for  human rights as well as the fundamental rights and values of the Union; whereas AI  should be human centric, enhance the well-being of people and society and contribute to  a fair and just transition; such technologies should therefore have a positive impact on  working conditions guided by respect for human rights as well as the fundamental rights  and values of the Union; 110. Highlights the need for competence development through training and education for  workers and their representatives with regard to AI in the workplace to better  understand the implications of AI solutions; stresses that applicants and workers should  be duly informed in writing when AI is used in the course of recruitment procedures and  other human resource decisions and how in this case a human review can be requested  in order to have an automated decision reversed; 111. Stresses the need to ensure that productivity gains due to the development and use of AI  and robotics do not only benefit company owners and shareholders, but also profit 
PE650.508v02-00 26/130 RR\1215422EN.docx ENcompanies and the workforce, through better working and employment conditions,  including wages, economic growth and development, and also serve society at large,  especially where such gains come at the expense of jobs; calls on the Member States to  carefully study the potential impact of AI on the labour market and social security  systems and to develop strategies as to how to ensure long-term stability by reforming  taxes and contributions as well as other measures in the event of smaller public  revenues; 112. Underlines the importance of corporate investment in formal and informal training and  life-long learning in order to support the just transition towards the digital economy;  stresses in this context that companies deploying AI have the responsibility of providing  adequate re-skilling and up-skilling for all employees concerned in order for them to  learn how to use digital tools and to work with co-bots and other new technologies,  thereby adapting to changing needs of the labour market and staying in employment; 113. Considers that special attention should be paid to new forms of work, such as gig and  platform work, resulting from the application of new technologies in this context;   stresses that regulating telework conditions across the Union and ensuring decent  working and employment conditions in the digital economy must likewise take the  impact of AI into account; calls on the Commission to consult with social partners, AIdevelopers, researchers and other stakeholders in this regard; 114. Underlines that artificial intelligence, robotics and related technologies must not in any  way affect the exercise of fundamental rights as recognised in the Member States and at  Union level, including the right or freedom to strike or to take other action covered by  the specific industrial relations systems in Member States, in accordance with national  law and/or practice, or affect the right to negotiate, to conclude and enforce collective  agreements, or to take collective action in accordance with national law and/or practice; 115. Reiterates the importance of education and continuous learning to develop the  qualifications necessary in the digital age and to tackle digital exclusion; calls on the  Member States to invest in high quality, responsive and inclusive education, vocational  training and life-long learning systems as well as re-skilling and up-skilling policies for  workers in sectors that are potentially severely affected by AI; highlights the need to  provide the current and future workforce with the necessary literacy, numeracy and  digital skills as well as competences in science, technology, engineering and  mathematics (STEM) and cross-cutting soft skills, such as critical thinking, creativity  and entrepreneurship; underlines that special attention must be paid to the inclusion of  disadvantaged groups in this regard; 116. Recalls that artificial intelligence, robotics and related technologies used at the  workplace must be accessible for all, based on the design for all principle; Education and culture 117. Stresses the need to develop criteria for the development, the deployment and the use of  AI bearing in mind their impact on education, media, youth, research, sports and the  cultural and creative sectors, by developing benchmarks for and defining principles of  ethically responsible and accepted uses of AI technologies that can be appropriately  applied in these areas, including a clear liability regime for products resulting from AI 
RR\1215422EN.docx 27/130 PE650.508v02-00 ENuse; 118. Notes that every child enjoys the right to public education of quality at all levels;  therefore, calls for the development, the deployment and the use of quality AI systems  that facilitate and provide quality educational tools for all at all levels and stresses that  the deployment of new AI systems in schools should not lead to a wider digital gap  being created in society; recognises the enormous potential contribution that AI and  robotics can make to education; notes that AI personalised learning systems should not  replace educational relationships involving teachers and that traditional forms of  education should not be left behind, while at the same time pointing out that financial,  technological and educational support, including specialised training in information and  communications technology must be provided for teachers seeking to acquire  appropriate skills so as to adapt to technological changes and not only harness the  potential of AI but also understand its limitations; calls for a strategy to be developed at  Union level in order to help transform and update our educational systems, prepare our  educational institutions at all levels and equip teachers and pupils with the necessary  skills and abilities; 119. Emphasises that educational institutions should aim to use AI systems for educational  purposes that have received a European certificate of ethical compliance;  120. Emphasises that opportunities provided by digitisation and new technologies must not  result in an overall loss of jobs in the cultural and creative sectors, the neglect of the  conservation of originals  or in the downplaying of traditional access to cultural  heritage, which should equally be encouraged; notes that AI systems developed,  deployed and used in the Union should reflect its cultural diversity and its  multilingualism; 121. Acknowledges the growing potential of AI in the areas of information, media and online  platforms, including as a tool to fight disinformation in accordance with Union law;  underlines that, if not regulated, it might also have ethically adverse effects by  exploiting bias in data and algorithms that may lead to disseminating disinformation and  creating information bubbles; emphasises the importance of transparency and  accountability of algorithms used by video-sharing platforms (VSP) as well as  streaming platforms, in order to ensure access to culturally and linguistically diverse  content; National supervisory authorities 122. Notes the added value of having designated national supervisory authorities in each  Member State, responsible for ensuring, assessing and monitoring compliance with  legal obligations and ethical principles for the development, deployment and use of  high-risk artificial intelligence, robotics and related technologies, thus contributing to  the legal and ethical compliance of these technologies; 123. Believes that these authorities must be required to, without duplicating their tasks,  cooperate with the authorities responsible for implementing sectorial legislation in order  to identify technologies which are high-risk from an ethical perspective and in order to  supervise the implementation of required and appropriate measures where such  technologies are identified;
PE650.508v02-00 28/130 RR\1215422EN.docx EN124. Indicates that such authorities should liaise not only among themselves but also with the  European Commission and other relevant institutions, bodies, offices and agencies of  the Union in order to guarantee coherent cross-border action; 125. Suggests that, in the context of such cooperation, common criteria and an application  process be developed for the granting of a European certificate of ethical compliance,  including following a request by any developer, deployer or user of technologies not  considered as high-risk seeking to certify the positive assessment of compliance carried  out by the respective national supervisory authority; 126. Calls for such authorities to be tasked with promoting regular exchanges with civil  society and innovation within the Union by providing assistance to researchers,  developers, and  other relevant stakeholders, as well as to less digitally-mature  companies, in particular small and medium-sized enterprises or start-ups; in particular  regarding awareness-raising and support for development, deployment, training and  talent acquisition to ensure efficient technology transfer and access to technologies,  projects, results and networks; 127. Calls for sufficient funding by each Member State of their designated national supervisory  authorities and stresses the need for national market surveillance authorities to be  reinforced in terms of capacity, skills and competences, as well as knowledge about the  specific risks of artificial intelligence, robotics and related technologies; Coordination at Union level 128. Underlines the importance of coordination at Union level as carried out by the  Commission and/or any relevant institutions, bodies, offices and agencies of the Union  that may be designated in this context in order to avoid fragmentation, and of ensuring a  harmonised approach across the Union; considers that coordination should focus on the  mandates and actions of the national supervisory authorities in each Member State as  referred to in the previous sub-section, as well as on sharing of best practices among  those authorities and contributing to the cooperation as regards research and  development in the field throughout the Union; calls on the Commission to assess and  find the most appropriate solution to structure such coordination; examples of relevant  existing institutions, bodies, offices and agencies of the Union are ENISA, the EDPS  and the European Ombudsman; 129. Believes that such coordination, as well as a European certification of ethical  compliance, would not only benefit the development of Union industry and innovation  in that context but also increase the awareness of our citizens regarding the  opportunities and risks inherent to these technologies; 130. Suggests a centre of expertise be created, bringing together academia, research,  industry, and individual experts at Union level, to foster exchange of knowledge and  technical expertise, and to facilitate collaboration throughout the Union and beyond;  further calls for this centre of expertise to involve stakeholder organisations, such as  consumer protection organisations, in order to ensure wide consumer representation;  considers that due to the possible disproportionate impact of algorithmic systems on  women and minorities, the decision levels of such a structure should be diverse and ensure  gender equality; emphasises that Member States must develop risk-management strategies 
RR\1215422EN.docx 29/130 PE650.508v02-00 ENfor AI in the context of their national market surveillance strategies;  131. Proposes that the Commission and/or any relevant institutions, bodies, offices and  agencies of the Union that may be designated in this context provide any necessary  assistance to national supervisory authorities concerning their role as first points of  contact in cases of suspected breaches of the legal obligations and ethical principles set  out in the Union’s regulatory framework for AI, including the principle of nondiscrimination; it should also provide any necessary assistance to national supervisory  authorities in cases where the latter carry out compliance assessments in view of  supporting the right of citizens to contest and redress, namely by supporting, when  applicable, the consultation of other competent authorities in the Union, in particular the  Consumer Protection Cooperation Network and national consumer protection bodies,  civil society organisations and social partners located in other Member States; 132. Acknowledges the valuable output of the High-Level Expert Group on Artificial  Intelligence, comprising representatives from academia, civil society and industry, as well  as the European AI Alliance, particularly ‘The Ethics Guidelines for Trustworthy Artificial  Intelligence’, and suggests that it might provide expertise to the Commission and/or any  relevant institutions, bodies, offices and agencies of the Union that may be designated in  this context; 133. Notes the inclusion of AI-related projects under the European Industrial Development  Programme (EDIDP); believes that the future European Defence Fund (EDF) and the  Permanent structured cooperation (PESCO) may also offer  frameworks for future AIrelated projects that could help to better streamline Union efforts in this field, and  promote at the same time the Union’s objective of strengthening human rights,  international law, and multilateral solutions; stresses that AI-related projects should be  synchronized with the wider Union civilian programmes devoted to AI; notes that in  line with the European Commission’s White Paper of 19 February 2020 on AI,  excellence and testing centres concentrating on research and development of AI in the  field of security and defence should be established with rigorous specifications  underpinning the participation of and investment from private stakeholders; 134. Takes note of the Commission's White Paper of 19 February 2020 on Artificial  Intelligence and regrets that military aspects were not taken into account; calls on the  Commission and on the HR/VP to present, also as part of an overall approach, a sectoral  AI strategy for defence-related activities within the Union framework, that ensures both  respect for citizens’ rights and the Union’s strategic interests, and that is based on a  consistent approach spanning from the inception of AI-enabled systems to their military  uses, and to establish a working Group on security and defence within the High-Level  Expert Group on Artificial Intelligence that should specifically deal with policy and  investment questions as well as ethical aspects of AI in the field of security and defence;  calls on the Council, the Commission and on the VP/HR to enter into a structured  dialogue with Parliament to that end; European certification of ethical compliance 135. Suggests that common criteria and an application process relating to the granting of a  European certificate of ethical compliance be developed in the context of coordination 
PE650.508v02-00 30/130 RR\1215422EN.docx ENat Union level, including following a request by any developer, deployer or user of  technologies not considered as high-risk seeking to certify the positive assessment of  compliance carried out by the respective national supervisory authority; 136. Believes that such European certificate of ethical compliance would foster ethics by  design throughout the supply chain of artificial intelligence ecosystems; suggests,  therefore, that this certification could be, in the case of high-risk technologies, a  mandatory prerequisite for eligibility for public procurement procedures on artificial  intelligence, robotics and related technologies; International cooperation 137. Is of the opinion that effective cross-border cooperation and ethical standards can be  achieved only if all stakeholders commit to ensure human agency and oversight,  technical robustness and safety, transparency and accountability, diversity, nondiscrimination and fairness, societal and environmental well-being, and respect the  established principles of privacy, data governance and data protection, specifically those  enshrined in Regulation (EU) 2016/679 of the European Parliament and of the Council; 138. Stresses that the Union’s legal obligations and ethical principles for the development,  deployment and use of these technologies could make Europe a world leader in the  artificial intelligence sector and should therefore be promoted worldwide by  cooperating with international partners while continuing the critical and ethics-based  dialogue with third countries that have alternative models of artificial intelligence  regulation, development and deployment models; 139. Recalls that the opportunities and risks inherent to these technologies have a global  dimension, as the software and data they use are frequently imported into and exported  out of the Union, and therefore there is a need for a consistent cooperation approach at  international level; calls on the Commission to take the initiative to assess which  bilateral and multilateral treaties and agreements should be adjusted to ensure a  consistent approach and promote the European model of ethical compliance globally; 140. Points out the added-value of coordination at Union level as referred to above in this  context as well; 141. Calls for synergies and networks to be established between the various European  research centres on AI as well as other multilateral fora, such as the Council of Europe,  the United Nations Educational Scientific and Cultural Organization (UNESCO), the  Organisation for Economic Co-operation and Development’s (OECD),the World Trade  Organisation and the International Telecommunications Union (ITU), in order to align  their efforts and to better coordinate the development of artificial intelligence, robotics  and related technologies; 142. Underlines that the Union must be at the forefront of supporting multilateral efforts to  discuss in the framework of the UN CCW Governmental Expert Group and other  relevant fora, to discuss an effective international regulatory framework that ensures  meaningful human control over autonomous weapon systems in order to master those  technologies by establishing well defined, benchmark-based processes and adopting  legislation for their ethical use, in consultation with military, industry, law enforcement, 
RR\1215422EN.docx 31/130 PE650.508v02-00 ENacademia and civil society stakeholders, to understand the related ethical aspects and to  mitigate the inherent risks of such technologies and prevent use for malicious purposes;   143. Recognises the role of NATO in promoting Euro-Atlantic security and calls for  cooperation within NATO for the establishment of common standards and  interoperability of AI systems in defence; stresses that the transatlantic relationship is  important for the preservation of shared values and for countering future and emerging  threats; 144. Stresses the importance of the creation of an ethical code of conduct underpinning the  deployment of weaponised AI-enabled systems in military operations, similar to the  existing regulatory framework prohibiting the deployment of chemical and biological  weapons; is of the opinion that the Commission should initiate the creation of standards  on the use of AI-enabled weapons systems in warfare in accordance with international  humanitarian law, and that the Union should pursue the international adoption of such  standards; considers that the Union should engage in AI diplomacy in international fora  with like-minded partners like the G7, the G20, and the OECD; Final aspects 145. Concludes, following the above reflections on aspects related to the ethical dimension  of artificial intelligence, robotics and related technologies, that the legal and ethical  dimensions should be enshrined in an effective, forward looking and comprehensive  regulatory framework at Union level, supported by national competent authorities,  coordinated and enhanced by the Commission and/or any relevant institutions, bodies,  offices and agencies of the Union that may be designated in this context regularly  supported by the possible aforementioned centre of expertise and duly respected and  certified within the internal market; 146. In accordance with the procedure laid down in Article 225 of the Treaty on the  Functioning of the European Union, requests the Commission to submit a proposal for a  Regulation on ethical principles for the development, deployment and use of artificial  intelligence, robotics and related technologies on the basis of Article 114 of the Treaty  on the Functioning of the European Union and based on the detailed recommendations  set out in the annex hereto; points out that the proposal should not undermine sectorspecific legislation but should only cover identified loopholes; 147. Recommends that the European Commission, after consulting with all the relevant  stakeholders, review, if necessary, existing Union law applicable to artificial  intelligence, robotics and related technologies in order to address the rapidity of their  development in line with the recommendations set out in the annex hereto, avoiding  over-regulation, including for SMEs; 148. Believes that a periodical assessment and review, when necessary, of the Union  regulatory framework related to artificial intelligence, robotics and related technologies  will be essential to ensure that the applicable legislation is up to date with the rapid pace  of technological progress; 149. Considers that the legislative proposal requested would have financial implications if  any European body entrusted with the above-mentioned coordination functions to 
PE650.508v02-00 32/130 RR\1215422EN.docx ENensure the necessary technical means and human resources to fulfil its newly attributed  tasks were provided; 150. Instructs its President to forward this resolution and the accompanying detailed  recommendations to the Commission and the Council.
RR\1215422EN.docx 33/130 PE650.508v02-00 ENANNEX TO THE MOTION FOR A RESOLUTION: DETAILED RECOMMENDATIONS AS TO THE CONTENT OF THE PROPOSAL  REQUESTED A. PRINCIPLES AND AIMS OF THE PROPOSAL REQUESTED I. The main principles and aims of the proposal are:  ˗to build trust at all levels of involved stakeholders and of society in artificial  intelligence, robotics and related technologies, especially when they are  considered high-risk;  ˗to support the development of artificial intelligence, robotics and related  technologies in the Union, including by helping businesses, start-ups and small  and medium-sized enterprises to assess and address with certainty current and  future regulatory requirements and risks during the innovation and business  development process, and during the subsequent phase of use by professionals and  private individuals, by minimising burdens and red tape;  ˗to support deployment of artificial intelligence, robotics and related technologies  in the Union by providing the appropriate and proportionate regulatory framework  which should apply without prejudice to existing or future sectorial legislation,  with the aim of encouraging regulatory certainty and innovation while  guaranteeing fundamental rights and consumer protection; ˗to support use of artificial intelligence, robotics and related technologies in the  Union by ensuring that they are developed, deployed and used in a manner that is  compliant with ethical principles;  ˗to require transparency and better information flows among citizens and within  organisations developing, deploying or using artificial intelligence, robotics and  related technologies as a means of ensuring that these technologies are compliant  with Union law, fundamental rights and values, and with the ethical principles of  the proposal for Regulation requested. II. The proposal consists of the following elements:  ˗a “Regulation on ethical principles for the development, deployment and use of  artificial intelligence, robotics and related technologies”;the coordination role at  Union level by the Commission and/or any relevant institutions, bodies, offices  and agencies of the Union that may be designated in this context and a European  certification of ethical compliance;  ˗the support role of the European Commission; ˗the role of the “Supervisory Authority” in each Member State to ensure that ethical  principles are applied to artificial intelligence, robotics and related technologies;   
PE650.508v02-00 34/130 RR\1215422EN.docx EN˗the involvement and consultation of, as well as provision of support to, relevant  research and development projects and concerned stakeholders, including startups, small and medium-sized enterprises, businesses, social partners, and other  representatives of the civic society;  ˗an annex establishing an exhaustive and cumulative list of high-risk sectors and  high-risk uses and purposes; III. The “Regulation on ethical principles for the development, deployment and use of  artificial intelligence, robotics and related technologies” builds on the following  principles:  ˗human-centric, human-made and human-controlled artificial intelligence, robotics  and related technologies;  ˗mandatory compliance assessment of high-risk artificial intelligence, robotics and  related technologies; ˗safety, transparency and accountability; ˗safeguards and remedies against bias and discrimination; ˗right to redress; ˗social responsibility and gender equality in artificial intelligence, robotics and  related technologies; ˗environmentally sustainable artificial intelligence, robotics and related  technologies; ˗respect for privacy and limitations to the use of biometric recognition; ˗good governance relating to artificial intelligence, robotics and related  technologies, including the data used or produced by such technologies. IV. For the purposes of coordination at Union level, the Commission and/or any relevant  institutions, bodies, offices and agencies of the Union that may be designated in this  context should carry out the following main tasks: ˗cooperating in monitoring the implementation of the proposal for a Regulation  requested and relevant sectoral Union law;  ˗cooperating regarding the issuing of guidance concerning the consistent  application of the proposal for a Regulation requested, namely the application of  the criteria for artificial intelligence, robotics and related technologies to be  considered high-risk and the list of high-risk sectors and high-risk uses and  purposes set out in the annex to the Regulation; ˗cooperating with the “Supervisory Authority” in each Member State regarding the  developing of a European certificate of compliance with ethical principles and  legal obligations as laid down in the proposal for a Regulation requested and  relevant Union law, as well as the developing of an application process for any 
RR\1215422EN.docx 35/130 PE650.508v02-00 ENdeveloper, deployer or user of technologies not considered as high-risk seeking to  certify their compliance with the proposal for a Regulation requested; ˗cooperating regarding the supporting of cross-sector and cross-border cooperation  through regular exchanges with concerned stakeholders and the civil society, in  the EU and in the world, notably with businesses, social partners, researchers and  competent authorities, including as regards the development of technical standards  at international level; ˗cooperating with the “Supervisory Authority” in each Member State regarding the  establishing of binding guidelines on the methodology to be followed for the  compliance assessment to be carried out by each “Supervisory Authority”; ˗cooperating regarding the liaising with the “Supervisory Authority” in each  Member State and the coordinating of their mandate and tasks; ˗cooperating on raising awareness, providing information and engaging in  exchanges with developers, deployers and users throughout the Union; ˗cooperating on raising awareness, providing information, promoting digital  literacy, training and skills and engaging in exchanges with designers, developers,  deployers, citizens, users and institutional bodies throughout the Union and  internationally; ˗cooperating regarding the coordination of a common framework for the  governance of the development, deployment and use of artificial intelligence,  robotics and related technologies to be implemented by the “Supervisory  Authority” in each Member State; ˗cooperating regarding serving as a centre for expertise by promoting the exchange  of information and supporting the development of a common understanding in the  Single Market; ˗cooperating regarding the hosting of a Working Group on Security and Defence. V. Additionally, the Commission should carry out the following  tasks: ˗drawing up and subsequently updating, by means of delegated acts, a common list  of high-risk technologies identified within the Union in cooperation with the  “Supervisory Authority” in each Member State; ˗updating, by means of delegated acts, the list provided for in the Annex to the  Regulation. VI. The “Supervisory Authority” in each Member State should carry out the following  main tasks: ˗contributing to the consistent application of the regulatory framework established  in the proposal for a Regulation requested in cooperation with the “Supervisory  Authority” in the other Member States, as well as other authorities responsible for  implementing sectorial legislation, the Commission and and/or any relevant 
PE650.508v02-00 36/130 RR\1215422EN.docx ENinstitutions, bodies, offices and agencies of the Union that may be designated in  this context, namely regarding the application of the risk assessment criteria   provided for in the proposal for a Regulation requested and of the list of high-risk  sectors and of high-risk uses or purposes set out in its annex, and the following  supervision of the implementation of required and appropriate measures where  high-risk technologies are identified as a result of such application; ˗assessing whether artificial intelligence, robotics and related technologies,  including software, algorithms and data used or produced by such technologies,  developed, deployed and used in the Union are to be considered high-risk  technologies in accordance with the risk assessment criteria provided for in the  proposal for a Regulation requested and in the list set out in its annex; ˗issuing a European certificate of compliance with ethical principles and legal  obligations as laid down in the proposal for Regulation requested and relevant  Union law, including when resulting from an application process for any  developer, deployer or user of technologies not considered as high-risk seeking to  certify their compliance with the proposal for a Regulation requested, as  developed by the Commission and/or any relevant institutions, bodies, offices and  agencies of the Union that may be designated in this context; ˗assessing and monitoring their compliance with ethical principles and legal  obligations as laid down in the proposal for a Regulation requested and relevant  Union law; ˗being responsible for establishing and implementing standards for the governance  of artificial intelligence, robotics and related technologies, including by liaising  and sustaining a regular dialogue with all relevant stakeholders and civil society  representatives; to that end, cooperating with the Commission and any relevant  institutions, bodies, offices and agencies of the Union that may be designated in  this context regarding the coordination of a common framework at Union level; ˗raising awareness, providing information on artificial intelligence, robotics and  related technologies to the public, and supporting the training of relevant  professions, including in the judiciary, thereby empowering citizens and workers  with the digital literacy, skills and tools necessary for a fair transition; ˗serving as a first point of contact in cases of suspected breach of the legal  obligations and ethical principles set out in the proposal for a Regulation  requested and carrying out a compliance assessment in such cases; in the context  of this compliance assessment, it may consult and/or inform other competent  authorities in the Union, notably the Consumer Protection Cooperation Network,  national consumer protection bodies, civil society organisations and social  partners. VII. The key role of stakeholders should be to engage with the Commission and/or any  relevant institutions, bodies, offices and agencies of the Union that may designated in  this context and the “Supervisory Authority” in each Member State.
RR\1215422EN.docx 37/130 PE650.508v02-00 ENB. TEXT OF THE LEGISLATIVE PROPOSAL REQUESTED Proposal for a REGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL on ethical principles for the development, deployment and use of artificial intelligence,  robotics and related technologies Having regard to the Treaty on the Functioning of the European Union, and in particular  Article 114 thereof, Having regard to the proposal from the European Commission, After transmission of the draft legislative act to the national parliaments, Having regard to the opinion of the European Economic and Social Committee, Acting in accordance with the ordinary legislative procedure, Whereas:  (1) The development, deployment and use of artificial intelligence, robotics and related  technologies, including the software, algorithms and data used or produced by such  technologies, should be based on a desire to serve society. Such technologies can  entail opportunities and risks, which should be addressed and regulated by a  comprehensive regulatory framework at Union level, reflecting ethical principles, to  be complied with from the moment of the development and deployment of such  technologies to their use. (2) Compliance with such a regulatory framework regarding the development, deployment  and use of artificial intelligence, robotics and related technologies, including the  software, algorithms and data used or produced by such technologies in the Union  should of a level that is equivalent in all Member States, in order to efficiently seize  the opportunities and consistently address the risks of such technologies, as well as  avoid regulatory fragmentation. It should be ensured that the application of the rules  set out in this Regulation throughout the Union is homogenous. (3) In this context, the current diversity of the rules and practices to be followed across the  Union poses a significant risk of fragmentation of the Single Market and to the  protection of the well-being and prosperity of individuals and society alike, as well as  to the coherent exploration of the full potential that artificial intelligence, robotics and  related technologies have for promoting innovation and preserving that well-being and  prosperity. Differences in the degree of consideration on the part of developers, 
PE650.508v02-00 38/130 RR\1215422EN.docx ENdeployers and users of the ethical dimension inherent to these technologies can  prevent them from being freely developed, deployed or used within the Union and  such differences can constitute an obstacle to a level playing field and to the pursuit of  technological progress and economic activities at Union level, distort competition and  impede authorities in the fulfilment of their obligations under Union law. In addition,  the absence of a common regulatory framework, reflecting ethical principles, for the  development, deployment and use of artificial intelligence, robotics and related  technologies results in legal uncertainty for all those involved, namely developers,  deployers and users. (4) Nevertheless, while contributing to a coherent approach at Union level and within the  limits set by it, this Regulation should provide a margin for implementation by  Member States, including with regard to how the mandate of their respective national  supervisory authority is to be carried out, in view of the objective it is to achieve as set  out herein.  (5) This Regulation is without prejudice to existing or future sectorial legislation. It  should be proportionate with regard to its objective so as not to unduly hamper  innovation in the Union and be in accordance with a risk-based approach. (6) The geographical scope of application of such a framework should cover all the  components of artificial intelligence, robotics and related technologies throughout  their development, deployment and use in the Union, including in cases where part of  the technologies might be located outside the Union or not have a specific or single  location, such as in the case of cloud computing services.  (7) A common understanding in the Union of notions such as artificial intelligence,  robotics, related technologies and biometric recognition is required in order to allow  for a unified regulatory approach and thus legal certainty for citizens and companies  alike. They should be technologically neutral and subject to review whenever  necessary. (8) In addition, the fact that there are technologies related to artificial intelligence and  robotics that enable software to control physical or virtual processes, at a varying  degree of autonomy1, needs to be considered. For example, for automated driving of  vehicles, six levels of driving automation have been propose by SAE international  standard J3016. (9) The development, deployment and use of artificial intelligence, robotics and related  technologies, including the software, algorithms and data used or produced by such  technologies, should complement human capabilities, not substitute them and ensure  that their execution does not run against the best interests of citizens and that it  complies with Union law, fundamental rights as set out in the Charter of Fundamental  1 For automated driving of vehicles, six levels of driving automation have been proposed by SAE International  standard J3016, last updated in 2018 to J3016_201806. https://www.sae.org/standards/content/j3016_201806/
RR\1215422EN.docx 39/130 PE650.508v02-00 ENRights of the European Union (the ‘Charter’), settled case-law of the Court of Justice  of the European Union, and other European and international instruments which apply  in the Union. (10) Decisions made or informed by artificial intelligence, robotics and related  technologies should remain subject to meaningful human review, judgment,  intervention and control. The technical and operational complexity of such  technologies should never prevent their deployer or user from being able to, at the  very least, trigger a fail-safe shutdown, alter or halt their operation, or revert to a  previous state restoring safe functionalities in cases where the compliance with Union  law and the ethical principles and legal obligations laid down in this Regulation is at  risk. (11) Artificial intelligence, robotics and related technologies whose development,  deployment and use entail a significant risk of causing injury or harm to individuals or  society in breach of fundamental rights and safety rules as laid down in Union law,  should be considered as high-risk technologies. For the purposes of assessing them as  such, the sector where they are developed, deployed or used, their specific use or  purpose and the severity of the injury or harm that can be expected to occur should be  considered. The degree of severity should be determined based on the extent of the  potential injury or harm, the number of affected persons, the total value of damage  caused and the harm to society as a whole. Severe types of injury and harm are, for  instance, violations of children’s, consumers’ or workers’ rights that, due to their  extent, the number of children, consumers or workers affected or their impact on  society as a whole entail a significant risk to breach fundamental rights and safety  rules as laid down in Union law. This Regulation should provide an exhaustive and  cumulative list of high-risk sectors, and high-risk uses and purposes. (12) The obligations laid down in this Regulation, specifically those regarding high-risk  technologies, should only apply to artificial intelligence, robotics and related  technologies, including software, algorithms and data used or produced by such  technologies, developed, deployed or used in the Union, which, following the risk  assessment provided for in this Regulation, are considered as high-risk. Such  obligations are to be complied with without prejudice to the general obligation that  any artificial intelligence, robotics and related technologies, including software,  algorithms and data used or produced by such technologies, should be developed,  deployed and used in the Union in a human-centric manner and based on the principles  of human autonomy and human safety in accordance with Union law and in full  respect of fundamental rights such as human dignity, right to liberty and security and  right to the integrity of the person. (13) High-risk technologies should respect the principles of safety, transparency,  accountability, non-bias or non-discrimination, social responsibility and gender  equality, right to redress, environmental sustainability, privacy and good governance, 
PE650.508v02-00 40/130 RR\1215422EN.docx ENfollowing an impartial, objective and external risk assessment by the national  supervisory authority in accordance with the criteria provided for in this Regulation  and in the list set out in its annex. This assessment should take into account the views  and any self-assessment made by the developer or deployer.  (14) The Commission and/or any relevant institutions, bodies, offices and agencies of the  Union that may be designated for this purpose should prepare non-binding  implementation guidelines for developers, deployers and users on the methodology for  compliance with this Regulation. In doing so, they should consult relevant  stakeholders. (15) There should be coherence within the Union when it comes to the risk assessment of  these technologies, especially in the event they are assessed both in light of this  Regulation and in accordance with any applicable sector-specific legislation.  Accordingly, national supervisory authorities should inform other authorities carrying  out risk assessments in accordance with any sector-specific legislation when these  technologies are assessed as high-risk following the risk assessment provided for in  this Regulation. (16) To be trustworthy high-risk artificial intelligence, robotics and related technologies,  including the software, algorithms and data used or produced by such technologies  should be developed, deployed and used in a safe, transparent and accountable manner  in accordance with the safety features of robustness, resilience, security, accuracy and  error identification, explainability, interpretability, auditability, transparency and  identifiability, and in a manner that makes it possible to disable the functionalities  concerned or to revert to a previous state restoring safe functionalities, in cases of noncompliance with those features. Transparency should be ensured by allowing access to  public authorities, when strictly necessary, to technology, data and computing systems  underlying such technologies. (17) Developers, deployers and users of artificial intelligence, robotics and related  technologies, especially high-risk technologies, are responsible to varying degrees for  the compliance with safety, transparency and accountability principles to the extent of  their involvement with the technologies concerned, including the software, algorithms  and data used or produced by such technologies. Developers should ensure that the  technologies concerned are designed and built in line with the safety features set out in  this Regulation, whereas deployers and users should deploy and use the concerned  technologies in full observance of those features. To this end, developers of high-risk  technologies should evaluate and anticipate the risks of misuse that can reasonably be  expected regarding of the technologies they develop. They must also ensure that the  systems they develop indicate to the extent possible and through appropriate means,  such as disclaimer messages, the likelihood of errors or inaccuracies. (18) Developers and deployers should make available to users any subsequent updates of  the technologies concerned, namely in terms of software as stipulated by contract or 
RR\1215422EN.docx 41/130 PE650.508v02-00 ENlaid down in Union or national law. In addition where a risk assessment so indicates,  developers and deployers should provide public authorities, with for the relevant  documentation on the use of the technologies concerned and safety instructions in that  regard, including, when strictly necessary and in full respect of Union law on data  protection, privacy and intellectual property rights and trade secrets, the source code,  development tools and data used by the system.  (19) Individuals have a right to expect the technology they use to perform in a reasonable  manner and to respect their trust. The trust placed by citizens in artificial intelligence,  robotics and related technologies, including the software, algorithms and data used or  produced by such technologies, depends on the understanding and comprehension of  the technical processes. The degree of explainability of such processes should depend  on the context of those technical processes, and on the severity of the consequences of  an erroneous or inaccurate output, and needs to be sufficient for challenging them and  for seeking redress. Auditability, traceability, and transparency should address any  possible unintelligibility of such technologies. (20) Society’s trust in artificial intelligence, robotics and related technologies, including the  software, algorithms and data used or produced by such technologies, depends on the  degree to which their assessment, auditability and traceability are enabled in the  technologies concerned. Where the extent of their involvement so requires, developers  should ensure that such technologies are designed and built in a manner that enables  such an assessment, auditing and traceability. Within the limits of what is technically  possible, developers, deployers and users should ensure that artificial intelligence,  robotics and related technologies are deployed and used in full respect of transparency  requirements, and allowing auditing and traceability. (21) In order to ensure transparency and accountability, citizens should be informed when a  system uses artificial intelligence, when artificial intelligence systems personalise a  product or service for its users, whether they can switch off or limit the personalisation  and when they are faced with an automated-decision making technology. Furthermore,  transparency measures should be accompanied, as far as this is technically possible, by  clear and understandable explanations of the data used and of the algorithm, its  purpose, its outcomes and its potential dangers. (22) Bias in and discrimination by software, algorithms and data is unlawful and should be  addressed by regulating the processes through which they are designed and deployed.  Bias can originate both from decisions informed or made by an automated system as  well as from data sets on which such decision making is based or with which the  system is trained. (23) Software, algorithms and data used or produced by artificial intelligence, robotics and  related technologies should be considered biased where, for example, they display  suboptimal results in relation to any person or group of persons, on the basis of a  prejudiced personal or social perception and subsequent processing of data relating to 
PE650.508v02-00 42/130 RR\1215422EN.docx ENtheir traits.  (24) In line with Union law, software, algorithms and data used or produced by artificial  intelligence, robotics and related technologies should be considered discriminatory  where they produce outcomes that have disproportionate negative effects and result in  different treatment of a person or group of persons, including by putting them at a  disadvantage when compared to others, based on grounds such as their personal traits,  without objective or reasonable justification and regardless of any claims of neutrality  of the technologies.  (25) In line with Union law, legitimate aims that could under this Regulation be considered  to objectively justify any differential treatment between persons or group of persons  are the protection of public safety, security and health, the prevention of criminal  offences, the protection of fundamental rights and freedoms, fair representation and  objective requirements for holding a professional occupation.  (26) Artificial intelligence, robotics and related technologies, including software,  algorithms and data used or produced by such technologies, should contribute to  sustainable progress. Such technologies should not run counter to the cause of  preservation of the environment or the green transition. They could play an important  role in achieving the Sustainable Development Goals outlined by the United Nations  with a view to enabling future generations to flourish. Such technologies can support  the monitoring of adequate progress on the basis of sustainability and social cohesion  indicators, and by using responsible research and innovation tools requiring the  mobilisation of resources by the Union and its Member States to support and invest in  projects addressing those goals. (27) The development, deployment and use of artificial intelligence, robotics and related  technologies, including the software, algorithms and data used or produced by such  technologies, should in no way purposefully cause or accept by design injury or harm  of any kind to individuals or society. Accordingly, high-risk technologies in particular  should be developed, deployed and used in a socially responsible manner. (28) Therefore, developers, deployers and users should be held responsible, to the extent of  their involvement in the artificial intelligence, robotics and related technologies  concerned, and in accordance with Union and national liability rules, for any injury or  harm inflicted upon individuals and society. (29) In particular, the developers who take decisions that determine and control the course  or manner of the development of artificial intelligence, robotics and related  technologies, as well as the deployers who are involved in their deployment by taking  decisions regarding such deployment and by exercising control over the associated  risks or benefiting from such deployment, with a controlling or managing function,  should be generally considered responsible for avoiding the occurrence of any such  injury or harm, by putting adequate measures in place during the development process 
RR\1215422EN.docx 43/130 PE650.508v02-00 ENand thoroughly respecting such measures during the deployment phase, respectively.  (30) Socially responsible artificial intelligence, robotics and related technologies, including  the software, algorithms and data used or produced by such technologies, can be  defined as technologies which contribute to find solutions that safeguard and promote  different aims regarding society, most notably democracy, health and economic  prosperity, equality of opportunity, workers’ and social rights, diverse and  independent media and objective and freely available information, allowing for public  debate, quality education, cultural and linguistic diversity, gender balance, digital  literacy, innovation and creativity. They are also those that are developed, deployed  and used having due regard for their ultimate impact on the physical and mental wellbeing of citizens and that do not promote hate speech or violence. Such aims should be  achieved in particular by means of high-risk technologies.  (31) Artificial intelligence, robotics and related technologies should also be developed,  deployed and used with a view to supporting social inclusion, democracy, plurality,  solidarity, fairness, equality and cooperation and their potential in that context should  be maximized and explored through research and innovation projects. The Union and  its Member States should therefore mobilise their communication, administrative and  financial resources for the purpose of supporting and investing in such projects.  (32) Projects relating to the potential of artificial intelligence, robotics and related  technologies to deal with the question of social well-being should be carried out on the  basis of responsible research and innovation tools so as to guarantee the compliance  with ethical principles of those projects from the outset.  (33) The development, deployment and use of artificial intelligence, robotics and related  technologies, including the software, algorithms and data used or produced by such  technologies, should take into consideration their environmental footprint. In line with  obligations laid down in applicable Union law, such technologies should not cause  harm to the environment during their lifecycle and across their entire supply chain and  should be developed, deployed and used in a manner that preserves the environment,  mitigates and remedies their environmental footprint, contributes to the green  transition and supports the achievement of climate neutrality and circular economy  goals.  (34) For the purposes of this Regulation, developers, deployers and users should be held  responsible, to the extent of their respective involvement in the development,  deployment or use of any artificial intelligence, robotics and related technologies  considered as high-risk, for any harm caused to the environment in accordance with  the applicable environmental liability rules.  (35) These technologies should also be developed, deployed and used with a view to  supporting the achievement of environmental goals in line with the obligations laid  down in applicable Union law, such as reducing waste production, diminishing the 
PE650.508v02-00 44/130 RR\1215422EN.docx ENcarbon footprint, combating climate change and preserving the environment, and their  potential in that context should be maximized and explored through research and  innovation projects. The Union and the Member States should therefore mobilise their  communication, administrative and financial resources for the purpose of supporting  and investing in such projects.  (36) Projects relating to the potential of artificial intelligence, robotics and related  technologies in addressing environmental concerns should be carried out on the basis  of responsible research and innovation tools so as to guarantee from the outset the  compliance of those projects with ethical principles.  (37) Any artificial intelligence, robotics and related technologies, including software,  algorithms and data used or produced by such technologies, developed, deployed and  used in the Union should fully respect Union citizens’ rights to privacy and protection  of personal data. In particular, their development, deployment and use should be in  accordance with Regulation (EU) 2016/679 of the European Parliament and of the  Council2 and Directive 2002/58/EC of the European Parliament and of the Council3. (38) In particular, the ethical boundaries of the use of artificial intelligence, robotics and  related technologies, including software, algorithms and data used or produced by  such technologies, should be duly considered when using remote recognition  technologies, such as recognition of biometric features, notably facial recognition, to  automatically identify individuals. When these technologies are used by public  authorities for reasons of substantial public interest, namely to guarantee the security  of individuals and to address national emergencies, and not to guarantee the security of  properties, the use should always be disclosed, proportionate, targeted and limited to  specific objectives and restricted in time in accordance with Union law and having due  regard to human dignity and autonomy and the fundamental rights set out in the  Charter. Criteria for and limits to that use should be subject to judicial review and  submitted to democratic scrutiny and debate involving civil society. (39) Governance that is based on relevant standards enhances safety and promotes the  increase of citizens’ trust in the development, deployment and use of artificial  intelligence, robotics and related technologies including software, algorithms and data  used or produced by such technologies. (40) Public authorities should conduct impact assessments regarding fundamental rights  before deploying high-risk technologies which provide support for decisions that are  taken in the public sector and that have a direct and significant impact on citizen’s  2 Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the  protection of natural persons with regard to the processing of personal data and on the free movement of  such data, and repealing Directive 95/46/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016,  p. 1). 3 Directive 2002/58/EC of the European Parliament and of the Council of 12 July 2002 concerning the  processing of personal data and the protection of privacy in the electronic communications sector  (Directive on privacy and electronic communications) (OJ L 201, 31.7.2002, p. 37).
RR\1215422EN.docx 45/130 PE650.508v02-00 ENrights and obligations.  (41) Among the existing relevant governance standards are, for example, the ‘Ethics  Guidelines for Trustworthy AI’ drafted by the High-Level Expert Group on Artificial  Intelligence set up by the European Commission, and any other technical standards  such as those adopted by the European Committee for Standardization (CEN), the  European Committee for Electrotechnical Standardization (CENELEC), and the  European Telecommunications Standards Institute (ETSI), at European level, the  International Organization for Standardization (ISO) and the Institute of Electrical and  Electronics Engineers (IEEE), at international level. (42) Sharing and use of data by multiple participants is sensitive and therefore the  development, deployment and use of artificial intelligence, robotics and related  technologies should be governed by relevant rules, standards and protocols reflecting  the requirements of quality, integrity, security, reliability, privacy and control. The  data governance strategy should focus on the processing, sharing of and access to such  data, including its proper management, auditability and traceability, and guarantee the  adequate protection of data belonging to vulnerable groups, including people with  disabilities, patients, children, minorities and migrants or other groups at risk of  exclusion. In addition, developers, deployers and users should be able, where relevant,  to rely on key performance indicators in the assessment of the datasets they use for the  purposes of enhancing the trustworthiness of the technologies they develop, deploy  and use. (43) Member States should appoint an independent administrative authority to act as a  supervisory authority. In particular, each national supervisory authority should be  responsible for identifying artificial intelligence, robotics and related technologies  considered as high-risk in the light of the risk assessment criteria provided for in this  Regulation and for assessing and monitoring the compliance of these technologies  with the obligations laid down in this Regulation. (44) Each national supervisory authority should also carry the responsibility of the good  governance of these technologies under the coordination of the Commission and/or  any relevant institutions, bodies, offices or agencies of the Union that may be  designated for this purpose. They therefore have an important role to play in  promoting the trust and safety of Union citizens, as well as in enabling a democratic,  pluralistic and equitable society. (45) For the purposes of assessing technologies which are high-risk in accordance with this  Regulation and monitoring their compliance with it, national supervisory authorities  should, where applicable, cooperate with the authorities responsible for assessing and  monitoring these technologies and enforcing their compliance with sectorial  legislation. (46) National supervisory authorities should engage in substantial and regular cooperation 
PE650.508v02-00 46/130 RR\1215422EN.docx ENwith each other, as well as with the European Commission and other relevant  institutions, bodies, offices and agencies of the Union, in order to guarantee a coherent  cross-border action, and allow for consistent development, deployment and use of  these technologies within the Union in compliance with the ethical principles and legal  obligations laid down in this Regulation.  (47) In the context of such cooperation and in view of achieving full harmonisation at  Union level, national supervisory authorities should assist the Commission regarding  drawing up a common and exhaustive list of high-risk artificial intelligence, robotics  and related technologies in line with the criteria provided for in this Regulation and its  Annex. Furthermore a granting process should be developed for the issuing of a  European certificate of ethical compliance, including a voluntary application process  for any developer, deployer or user of technologies not considered as high-risk seeking  to certify their compliance with this Regulation. (48) National supervisory authorities should ensure the gathering of a maximum number of  stakeholders such as industry, businesses, social partners, researchers, consumers and  civil society organisations, and provide a pluralistic forum for reflection and exchange  of views so as to achieve comprehensible and accurate conclusions for the purpose of  guiding how governance is regulated.  (49) National supervisory authorities should ensure the gathering of a maximum number of  stakeholders such as industry, businesses, social partners, researchers, consumers and  civil society organisations, and provide a pluralistic forum for reflection and exchange  of views, to facilitate cooperation with and collaboration between stakeholders, in  particular from academia, research, industry, civil society and individual experts, so as  to achieve comprehensible and accurate conclusions for the purpose of guiding how  governance is regulated. (50) Additionally, these national supervisory authorities should provide professional  administrative guidance and support to developers, deployers and users, particularly  small and medium-sized enterprises or start-ups, encountering challenges as regards  complying with the ethical principles and legal obligations laid down in this  Regulation.  (51) The Commission and/or any relevant institutions, bodies, offices and agencies of the  Union that may be designated for this purpose should establish binding guidelines on  the methodology to be used by the national supervisory authorities when conducting  their compliance assessment. (52) Whistle-blowing brings potential and actual breaches of Union law to the attention of  authorities with a view to preventing injury, harm or damage that would otherwise  occur. In addition, reporting procedures ameliorate the information flow within  companies and organisations, thus mitigating the risk of flawed or erroneous products  or services being developed. Companies and organisations developing, deploying or 
RR\1215422EN.docx 47/130 PE650.508v02-00 ENusing artificial intelligence, robotics and related technologies, including data used or  produced by those technologies, should set up reporting channels and persons  reporting breaches should be protected from retaliation. (53) The rapid development of artificial intelligence, robotics and related technologies,  including the software, algorithms and data used or produced by such technologies, as  well as of the technical machine learning, reasoning processes and other technologies  underlying that development are unpredictable. As such, it is both appropriate and  necessary to establish a review mechanism in accordance with which, in addition to its  reporting on the application of the Regulation, the Commission is to regularly submit a  report concerning the possible modification of the scope of application of this  Regulation.  (54) Since the objective of this Regulation, namely to establish a common regulatory  framework of ethical principles and legal obligations for the development, deployment  and use of artificial intelligence, robotics and related technologies in the Union, cannot  be sufficiently achieved by the Member States, but can rather, by reason of its scale  and effects, be better achieved at Union level, the Union may adopt measures, in  accordance with the principle of subsidiarity as set out in Article 5 of the Treaty on  European Union. In accordance with the principle of proportionality, as set out in that  Article, this Regulation does not go beyond what is necessary in order to achieve that  objective. (55) Coordination at Union level as set out in this Regulation would be best achieved by  the Commission and/or any relevant institutions, bodies, offices and agencies of the  Union that may be designated in this context in order to avoid fragmentation and  ensure the consistent application of this Regulation. The Commission should therefore  be tasked with finding an appropriate solution to structure such coordination at Union  level in view of  coordinating the mandates and actions of the national supervisory  authorities in each Member State, namely regarding the risk assessment of artificial  intelligence, robotics and related technologies, the establishment of a common  framework for the governance of the development, deployment and use of these  technologies, the developing and issuing of a certification of compliance with the  ethical principles and legal obligations laid down in this Regulation, supporting  regular exchanges with concerned stakeholders and civil society and creating a centre  of expertise, bringing together academia, research, industry, and individual experts at  Union level to foster exchange of knowledge and technical expertise, and promoting  the Union’s approach through international cooperation and ensuring a consistent  reply worldwide to the opportunities and risks inherent in these technologies.
PE650.508v02-00 48/130 RR\1215422EN.docx ENHAVE ADOPTED THIS REGULATION:  Chapter I General provisions Article 1 Purpose  The purpose of this Regulation is to establish a comprehensive and future-proof Union  regulatory framework of ethical principles and legal obligations for the development,  deployment and use of artificial intelligence, robotics and related technologies in the Union. Article 2 Scope This Regulation applies to artificial intelligence, robotics and related technologies, including  software, algorithms and data used or produced by such technologies, developed, deployed or  used in the Union. Article 3 Geographical scope This Regulation applies to artificial intelligence, robotics and related technologies where any  part thereof is developed, deployed or used in the Union, regardless of whether the software,  algorithms or data used or produced by such technologies are located outside of the Union or  do not have a specific geographical location. Article 4 Definitions For the purposes of this Regulation, the following definitions apply: (a) ‘artificial intelligence’ means a system that is either software-based or embedded  in hardware devices, and that displays intelligent behaviour by, inter alia, collecting,  processing, analysing, and interpreting its environment, and by taking action, with  some degree of autonomy, to achieve specific goals4; (b) ‘autonomy’ means an AI-system that operates by interpreting certain input and  using a set of pre-determined instructions, without being limited to such instructions,  despite the system’s behaviour being constrained by and targeted at fulfilling the goal  it was given and other relevant design choices made by its developer; 4 Definition as in the European Commission Communication COM(2018) 237 final, 25.04.2018, page 1,  adapted.
RR\1215422EN.docx 49/130 PE650.508v02-00 EN(c) ‘robotics’ means technologies that enable automatically controlled,  reprogrammable, multi-purpose machines5 to perform actions in the physical world  traditionally performed or initiated by human beings, including by way of artificial  intelligence or related technologies; (d) ‘related technologies’ means technologies that enable software to control with a  partial or full degree of autonomy a physical or virtual process, technologies capable  of detecting biometric, genetic or other data, and technologies that copy or otherwise  make use of human traits; (e) ‘high risk’ means a significant risk entailed by the development, deployment and  use of artificial intelligence, robotics and related technologies to cause injury or harm  to individuals or society in breach of fundamental rights and safety rules as laid down  in Union law, considering their specific use or purpose, the sector where they are  developed, deployed or used and the severity of injury or harm that can be expected to  occur; (f) ‘development’ means the construction and design of algorithms, the writing and  design of software or the collection, storing and management of data for the purpose  of creating or training artificial intelligence, robotics and related technologies or for  the purpose of creating a new application for existing artificial intelligence, robotics  and related technologies;  (g) ‘developer’ means any natural or legal person who takes decisions that determine  and control the course or manner of the development of artificial intelligence, robotics  and related technologies; (h) ‘deployment’ means the operation and management of artificial intelligence,  robotics and related technologies, as well as their placement on the market or  otherwise making them available to users; (i) ‘deployer’ means any natural or legal person who is involved in the  specific  deployment of artificial intelligence, robotics and related technologies with a  controlling or managing function by taking decisions, exercising control over the risk  and benefiting from such deployment; (j) ‘use’ means any action relating to artificial intelligence, robotics and related  technologies other than development or deployment; (k) ‘user’ means any natural or legal person who uses artificial intelligence, robotics  and related technologies other than for the purposes of development or deployment; 5 From the definition for industrial robots in ISO 8373.
PE650.508v02-00 50/130 RR\1215422EN.docx EN(l) ‘bias’ means any prejudiced personal or social perception of a person or group of  persons on the basis of their personal traits; (m) ‘discrimination’ means any differential treatment of a person or group of persons  based on a ground which has no objective or reasonable justification and is therefore  prohibited by Union law; (n) ‘injury or harm’ means, including where caused by hate speech, bias,  discrimination or stigmatization, physical or mental injury, material or immaterial  harm such as financial or economic loss, loss of employment or educational  opportunity, undue restriction of freedom of choice or expression or loss of privacy,  and any infringement of Union law that is detrimental to a person; (o) ‘good governance’ means the manner of ensuring that the appropriate and  reasonable standards and protocols of behaviour are adopted and observed by  developers, deployers and users, based on a formal set of rules, procedures and values,  and which allows them to deal appropriately with ethical matters as or before they  arise. Article 5 Ethical principles of artificial intelligence, robotics and related technologies 1. Any artificial intelligence, robotics and related technologies, including software, algorithms  and data used or produced by such technologies, shall be developed, deployed and used in the  Union in accordance with Union law and in full respect of human dignity, autonomy and  safety and other fundamental rights set out in the Charter.  2. Any processing of personal data carried out in the development, deployment and use of  artificial intelligence, robotics and related technologies, including personal data derived from  non-personal data and biometric data, shall be carried out in accordance with Regulation (EU)  2016/679 and Directive 2002/58/EC. 3. The Union and its Member States shall encourage research projects intended to provide  solutions, based on artificial intelligence, robotics and related technologies, that seek to  promote social inclusion, democracy, plurality, solidarity, fairness, equality and cooperation. Chapter II Obligations for high-risk technologies Article 6 Obligations for high-risk technologies 1. The provisions in this Chapter shall only apply to artificial intelligence, robotics and related  technologies, including software, algorithms and data used or produced by such technologies, 
RR\1215422EN.docx 51/130 PE650.508v02-00 ENdeveloped, deployed or used in the Union which are considered high-risk. 2. Any high-risk artificial intelligence, robotics and related technologies, including software,  algorithms and data used or produced by such technologies shall be developed, deployed and  used in a manner that ensures that they do not breach the ethical principles set out in this  Regulation. Article 7 Human-centric and human-made artificial intelligence  1. Any artificial high-risk technologies, including software, algorithms and data used or  produced by such technologies, shall be developed, deployed and used in a manner that  guarantees full human oversight at any time. 2. The technologies referred to paragraph 1 shall be developed, deployed and used in a  manner that allows full human control to be regained when needed, including through the  altering or halting of those technologies. Article 8 Safety, transparency and accountability 1. Any high-risk artificial intelligence, robotics and related technologies, including software,  algorithms and data used or produced by such technologies shall be developed, deployed and  used in a manner that ensures that they are:  (a) developed, deployed and used in a resilient manner so that they ensure an  adequate level of security by adhering to minimum cybersecurity baselines  proportionate to identified risk, and one that prevents any technical vulnerabilities  from being exploited for malicious or unlawful purposes; (b) developed, deployed and used in a secure manner that ensures there are safeguards  that include a fall-back plan and action in case of a safety or security risk; (c) developed, deployed and used in a manner that ensures a reliable performance as  reasonably expected by the user regarding reaching the aims and carrying out the  activities they have been conceived for, including by ensuring that all operations are  reproducible;  (d) developed, deployed and used in a manner that ensures that the performance of the  aims and activities of the particular technologies is accurate; if occasional inaccuracies  cannot be avoided, the system shall indicate, to the extent possible, the likeliness of  errors and inaccuracies to deployers and users through appropriate means; 
PE650.508v02-00 52/130 RR\1215422EN.docx EN(e) developed, deployed and used in an easily explainable manner so as to ensure that  there can be a review of the technical processes of the technologies; (f) developed, deployed and used in a manner such that they inform users that they are  interacting with artificial intelligence systems, duly and comprehensively disclosing  their capabilities, accuracy and limitations to artificial intelligence developers,  deployers and users;  (g) in accordance with Article 6, developed, deployed and used in a manner that  makes it possible, in the event of non-compliance with the safety features set out in  subparagraphs (a) to (g), for the functionalities concerned to be temporarily disabled  and to revert to a previous state restoring safe functionalities. 2. In accordance with Article 6(1), the technologies mentioned in paragraph 1, including  software, algorithms and data used or produced by such technologies, shall be developed,  deployed and used in transparent and traceable manner so that their elements, processes and  phases are documented to the highest possible and applicable standards, and that it is possible  for the national supervisory authorities referred to in Article 14 to assess the compliance of  such technologies with the obligations set out in this Regulation. In particular, the developer,  deployer or user of those technologies shall be responsible for, and be able to demonstrate,  compliance with the safety features set out in paragraph 1. 3. The developer, deployer or user of the technologies mentioned in paragraph 1 shall ensure  that the measures taken to ensure compliance with the safety features set out in paragraph 1  can be audited by the national supervisory authorities referred to in Article 14 or, where  applicable, other national or European sectorial supervisory bodies.  Article 9 Non-bias and non-discrimination  1. Any software, algorithm or data used or produced by high-risk artificial intelligence,  robotics and related technologies developed, deployed or used in the Union shall be unbiased  and, without prejudice to paragraph 3, shall not discriminate on grounds such as race, gender,  sexual orientation, pregnancy, disability, physical or genetic features, age, national minority,  ethnicity or social origin, language, religion or belief, political views or civic participation,  citizenship, civil or economic status, education, or criminal record.  2. By way of derogation from paragraphs 1 and 2, and without prejudice to Union law  governing unlawful discrimination, any differential treatment between persons or groups of  persons may be justified only where there is an objective, reasonable and legitimate aim that  is both proportionate and necessary insofar as no alternative exists which would cause less  interference with the principle of equal treatment. 
RR\1215422EN.docx 53/130 PE650.508v02-00 ENArticle 10 Social responsibility and gender equality  Any high-risk artificial intelligence, robotics and related technologies, including software,  algorithms and data used or produced by such technologies, developed, deployed and used in  the Union shall be developed, deployed and used in compliance with relevant Union law,  principles and values, in a manner that does not interfere in elections or contribute to the  dissemination of disinformation, respects worker’s rights, promotes quality education and  digital literacy, does not increase the gender gap by preventing equal opportunities for all and  does not disrespect intellectual property rights and any limitations or exceptions thereto. Article 11 Environmental sustainability  Any high-risk artificial intelligence, robotics and related technologies, including software,  algorithms and data used or produced by such technologies, shall be assessed as to their  environmental sustainability by the national supervisory authorities referred to in Article 14  or, where applicable, other national or European sectorial supervisory bodies, ensuring that  measures are put in place to mitigate and remedy their general impact as regards natural  resources, energy consumption, waste production, the carbon footprint, climate change  emergency and environmental degradation in order to ensure compliance with the applicable  Union or national law, as well as any other international environmental commitments the  Union has undertaken.  Article 12 Respect for privacy and protection of personal data  The use and gathering of biometric data for remote identification purposes in public areas, as  biometric or facial recognition, carries specific risks for fundamental rights and shall be  deployed or used only by Member States’ public authorities for substantial public interest  purposes. Those authorities shall ensure that such deployment or use is disclosed to the  public, proportionate, targeted and limited to specific objectives and location and restricted in  time, in accordance with Union and national law, in particular Regulation (EU) 2016/679 and  Directive 2002/58/EC, and with due regard for human dignity and autonomy and the  fundamental rights set out in the Charter, namely the rights to respect for privacy and  protection of personal data. Article 13 Right to redress  Any natural or legal person shall have the right to seek redress for injury or harm caused by  the development, deployment and use of high-risk artificial intelligence, robotics and related  technologies, including software, algorithms and data used or produced by such technologies,  in breach of Union law and the obligations set out in this Regulation
PE650.508v02-00 54/130 RR\1215422EN.docx ENArticle 14 Risk assessment  1. For the purposes of this Regulation, artificial intelligence, robotics and related  technologies, including software, algorithms and data used or produced by such technologies,  shall be considered high-risk technologies when, following a risk assessment based on  objective criteria such as their specific use or purpose, the sector where they are developed,  deployed or used and the severity of the possible injury or harm caused, their development,  deployment or use entail a significant risk to cause injury or harm that can be expected to  occur to individuals or society in breach of fundamental rights and safety rules as laid down in  Union law. 2. Without prejudice to applicable sectorial legislation, the risk assessment of artificial  intelligence, robotics and related technologies, including software, algorithms and data used  or produced by such technologies, shall be carried out, in accordance with the objective  criteria provided for in paragraph 1 of this Article and in the exhaustive and cumulative list  set out in the Annex to this Regulation, by the national supervisory authorities referred to in  Article 14 under the coordination of the Commission and/or any other relevant institutions,  bodies, offices and agencies of the Union that may be designated for this purpose in the  context of their cooperation. 3. In cooperation with the national supervisory authorities referred to in paragraph 2, the  Commission shall, by means of delegated acts in accordance with Article 15a, draw up and  subsequently update a common list of high-risk technologies identified within the Union.  4. The Commission shall also, by means of delegated acts in accordance with Article 15a,  regularly update the list provided for in the Annex to this Regulation. Article 15 Compliance assessment  1. High-risk artificial intelligence, robotics and related technologies shall be subject to an  assessment of compliance with the obligations set out in Articles 6 to 12 of this Regulation, as  well as to subsequent monitoring, both of which shall be carried out by the national supervisory  authorities referred to in Article 17 under the coordination of the Commission and/or any other  relevant institutions, bodies, offices and agencies of the Union that may be designated for this  purpose.  2. The software, algorithms and data used or produced by high-risk technologies which have  been assessed as compliant with the obligations set out in this Regulation pursuant to paragraph  1 shall also be considered to comply with those obligations, unless the relevant national  supervisory authority decides to conduct an assessment on its own initiative or at the request  of the developer, the deployer or the user.   
RR\1215422EN.docx 55/130 PE650.508v02-00 EN3. Without prejudice to sectorial legislation, the Commission and/or any relevant institutions,  bodies, offices and agencies of the Union that may be specifically designated for this purpose  shall prepare binding guidelines on the methodology to be used by the national supervisory  authorities for the compliance assessment referred to in paragraph 1 by the date of the entry  into force of this Regulation.  Article 16 European certificate of ethical compliance 1. Where there has been a positive assessment of compliance of high-risk artificial intelligence,  robotics and related technologies, including software, algorithms and data used or produced by  such technologies, carried out in line with Article 7bis, the respective national supervisory  authority shall issue a European certificate of ethical compliance.   2. Any developer, deployer or user of artificial intelligence, robotics and related technologies,  including software, algorithms and data used or produced by such technologies, that are not  considered as high-risk and that are therefore not subject to the obligations laid down in  Articles 6 to 12 and to the risk assessment and compliance assessment provided for in Articles  13 and 14, may also seek to certify the compliance with the obligations laid down in this  Regulation, or part of them where so justified by the nature of the technology in question as  decided by the national supervisory authorities. A certificate shall only be issued if an  assessment of compliance has been carried out by the relevant national supervisory authority  and that assessment is positive.  3. For the purposes of issuing the certificate referred to in paragraph 2, an application process  shall be developed by the Commission and/or any other relevant institutions, bodies, offices  and agencies of the Union that may be designated for this purpose. Chapter III Institutional oversight  Article 17 Governance standards and implementation guidance 1. Artificial intelligence, robotics and related technologies developed, deployed or used in the  Union shall comply with relevant governance standards established in accordance with Union  law, principles and values by the national supervisory authorities referred to in Article 17 in  accordance with Union law, principles and values, under the coordination of the Commission  and/or relevant institutions, bodies, offices and agencies of the Union that may be designated  for this purpose and in consultation with relevant stakeholders.
PE650.508v02-00 56/130 RR\1215422EN.docx EN2. The standards referred to in paragraph 1 shall include non-binding implementation  guidelines on the methodology for compliance with this Regulation by developers, deployers  and users and shall be published by the date of entry into force of this Regulation.  3. Data used or produced by artificial intelligence, robotics and related technologies  developed, deployed or used in the Union shall be managed by developers, deployers and  users in accordance with relevant national, Union, other European organisations’ and  international rules and standards, as well as with relevant industry and business protocols. In  particular, developers and deployers shall carry out, where feasible, quality checks of the  external sources of data used by artificial intelligence, robotics and related technologies, and  shall put oversight mechanisms in place regarding their collection, storage, processing and  use. 3. Without prejudice to portability rights and rights of persons whose usage of artificial  intelligence, robotics and related technologies has generated data, the collection, storage,  processing, sharing of and access to data used or produced by artificial intelligence, robotics  and related technologies developed, deployed or used in the Union shall comply with the  relevant national, Union, other European organisations’ and international rules and standards,  as well as with relevant industry and business protocols. In particular, developers and  deployers shall ensure those protocols are applied during the development and deployment of  artificial intelligence, robotics and related technologies, by clearly defining the requirements  for processing and granting access to data used or produced by these technologies, as well as  the purpose, scope and addressees of the processing and the granting of access to such data,  all of which shall at all times be auditable and traceable. Article 18 Supervisory authorities 1. Each Member State shall designate an independent public authority to be responsible for  monitoring the application of this Regulation (‘supervisory authority’), and for carrying out  the risk and compliance assessments and the certification provided for in Articles 13, 14 and  15, without prejudice to sectorial legislation.   2. Each national supervisory authority shall contribute to the consistent application of this  Regulation throughout the Union. For that purpose, the supervisory authorities in each  Member State shall cooperate with each other, the Commission and/or other relevant  institutions, bodies, offices and agencies of the Union, that may be designated for this  purpose. 3. Each national supervisory authority shall serve as a first point of contact in cases of  suspected breach of the ethical principles and legal obligations laid down in this Regulation,  including discriminatory treatment or violation of other rights, as a result of the development, 
RR\1215422EN.docx 57/130 PE650.508v02-00 ENdeployment or use of artificial intelligence, robotics and related technologies. In such cases,  the respective national supervisory authority shall carry out a compliance assessment in view  of supporting the right of citizens to contest and redress.  4. Each national supervisory authority shall be responsible for supervising the application of  the relevant national, European and international governance rules and standards referred to in  Article 13 to artificial intelligence, robotics and related technologies, including by liaising  with the maximum possible number of relevant stakeholders. For that purpose, the  supervisory authorities in each Member State shall provide a forum for regular exchange with  and among stakeholders from academia, research, industry and civil society. 5. Each national supervisory authority shall provide professional and administrative guidance  and support concerning the general implementation of Union law applicable to artificial  intelligence, robotics and related technologies and the ethical principles set out in this  Regulation, especially to relevant research and development organisations and small and  medium-sized enterprises or start-ups. 6. Each Member State shall notify to the European Commission the legal provisions which it  adopts pursuant to this Article by [OJ: please enter the date one year after entry into force]  and, without delay, any subsequent amendment affecting them. 7. Member States shall take all measures necessary to ensure the implementation of the  ethical principles and legal obligations laid down in this Regulation. Member States shall  support relevant stakeholders and civil society, at both Union and national level, in their  efforts to ensure a timely, ethical and well-informed response to the new opportunities and  challenges, in particular those of a cross-border nature, arising from technological  developments relating to artificial intelligence, robotics and related technologies. Article 19 Reporting of breaches and protection of reporting persons Directive (EU) 2019/1937 of the European Parliament and of the Council6 shall apply to the  reporting of breaches of this Regulation and the protection of persons reporting such breaches. Article 20 Coordination at Union level 1. The Commission and/or any relevant institutions, bodies, offices and agencies of the Union  that may be designated in this context shall have the following tasks:    6 Directive (EU) 2019/1937 of the European Parliament and of the Council of 23 October 2019 on the  protection of persons who report breaches of Union law (OJ L 305, 26.11.2019, p. 17).
PE650.508v02-00 58/130 RR\1215422EN.docx EN-ensuring a consistent risk assessment of artificial intelligence, robotics and  related technologies referred to in Article 13 to be carried out by the national  supervisory authorities referred to in Article 17 on the basis of the common objective  criteria provided for in Article 7(1) and in the list of high-risk sectors and of high-risk  uses or purposes set out in the Annex to this Regulation;    -taking note of the compliance assessment and subsequent monitoring of highrisk artificial intelligence, robotics and related technologies referred to in Article 14 to  be carried out by the national supervisory authorities referred to in Article 17;  -developing the application process for the certificate referred to in Article 15 to  be issued by the national supervisory authorities referred to in Article 17;  -without prejudice to sectorial legislation, preparing the binding guidelines  referred to in Article 14(3) on the methodology to be used by the national supervisory  authorities referred to in Article 17;    -coordinating the establishment of the relevant governance standards referred to  in Article 16 by the national supervisory authorities referred to in Article 17, including  non-binding implementation guidelines for developers, deployers and users on the  methodology for compliance with this Regulation;    -cooperating with the national supervisory authorities referred to in Article 17  regarding their contribution to the consistent application of this Regulation throughout  the Union pursuant to Article 17(2);    -serving as a centre for expertise by promoting the exchange of information  related to artificial intelligence, robotics and related technologies and supporting the  development of a common understanding in the Single Market, issuing additional  guidance, opinions and expertise to the national supervisory authorities referred to in  Article 17, monitoring the implementation of relevant Union law, identifying standards  for best practice and, where appropriate, making recommendations for regulatory  measures; in doing so, it should liaise with the maximum possible number of relevant  stakeholders and ensure that the composition of its decision levels is diverse and  ensures gender equality;  -hosting a Working Group on Security and Defence aimed at looking into policy  and investment questions specifically related to the ethical use of artificial intelligence,  robotics and related technologies in the field of security and defence.  Article 21 Exercise of delegation 1. The power to adopt delegated acts is conferred on the Commission subject to the conditions 
RR\1215422EN.docx 59/130 PE650.508v02-00 ENlaid down in this Article. 2. The power to adopt delegated acts referred to in Article 7(3) and (4) shall be conferred on  the Commission for a period of 5 years from (date of entry into force of this Regulation). 3. The delegation of power referred to in Article 7(3) and (4) may be revoked at any time  by the European Parliament or by the Council. A decision to revoke shall put an end to the  delegation of the power specified in that decision. It shall take effect the day following the  publication of the decision in the Official Journal of the European Union or a later date  specified therein. It shall not affect the validity of any delegated act already in force. 4. Before adopting a delegated act, the Commission shall consult experts designated by each  Member State in accordance with the principles laid down in the Interinstitutional Agreement  of 13 April 2016 on Better Law Making. 5. As soon as it adopts a delegated act, the Commission shall notify it simultaneously to the  European Parliament and to the Council. 6. A delegated act adopted pursuant to Article 7(3) and (4) shall enter into force only if no  objection has been expressed either by the European Parliament or the Council within a period  of three months of notification of that act to the European Parliament and the Council or, if,  before the expiry of that period, the European Parliament and the Council have both informed  the Commission that they will not object. That period shall be extended by three months at the  initiative of the European Parliament or of the Council. Article 22 Amendment to Directive (EU) No 2019/1937 Directive (EU) No 2019/1937 is amended as follows: (1) In Article 2(1), the following point is added: ‘(xi) development, deployment and use of artificial intelligence, robotics and related  technologies.’ (2) In Part I of the Annex, the following point is added: ‘K. Point (a)(xi) of Article 2(1) - development, deployment and use of artificial intelligence,  robotics and related technologies. “(xxi) Regulation [XXX] of the European Parliament and of the Council on ethical principles  for the development, deployment and use artificial intelligence, robotics and related  technologies”.’
PE650.508v02-00 60/130 RR\1215422EN.docx ENArticle 23 Review  The Commission shall keep under regular review the development of artificial intelligence,  robotics and related technologies, including the software, algorithms and data used or  produced by such technologies, and shall by [OJ: please enter the date three years after entry  into force], and every three years thereafter, submit to the European Parliament, the Council  and the European Economic and Social Committee a report on the application of this  Regulation, including an assessment of the possible modification of the scope of application  of this Regulation. Article 24 Entry into force  1. This Regulation shall enter into force on the twentieth day following that of its publication  in the Official Journal of the Union. It shall apply from XX. 2. This Regulation shall be binding in its entirety and directly applicable in the Member States  in accordance with the Treaty establishing the European Union.  This Regulation shall be binding in its entirety and directly applicable in all Member States.
RR\1215422EN.docx 61/130 PE650.508v02-00 ENANNEX Exhaustive and cumulative list of high-risk sectors and of high-risk uses or purposes that  entail a risk of breach of fundamental rights and safety rules. High-risk sectors Employment Education Healthcare Transport Energy Public sector (asylum, migration,  border controls, judiciary and social  security services) Defence and security Finance, banking, insurance High-risk uses or purposes Recruitment Grading and assessment of  students Allocation of public funds  Granting loans  Trading, brokering, taxation, etc. Medical treatments and  procedures Electoral processes and political  campaigns Public sector decisions that have  a significant and direct impact on  the rights and obligations of  natural or legal persons  Automated driving  Traffic management  Autonomous military systems  Energy production and  distribution Waste management Emissions control    
PE650.508v02-00 62/130 RR\1215422EN.docx ENEXPLANATORY STATEMENT In 1982 film ‘Blade Runner’, Rachael, a ‘replicant’ who works for a company that  manufactures other ‘replicants’ – sentient humanoid robots – says to Deckard, a bounty hunter  who makes his living eliminating rogue replicants: - ‘It seems you feel our work is not a benefit to the public.’ Deckard replies: - ‘Replicants are like any other machine - they’re either a benefit or a hazard. If they’re a  benefit, it’s not my problem.’ Benefits and hazards The mass installation of artificial intelligence in all the machines we interact with in public,  the workplace and society will mean – already does mean – a technological sea change  comparable only with the transformation heralded by the Industrial Revolution in bygone  days. Life will never be the same again, and there will be profound changes in the labour  market, in people’s relationship with public authorities, in personal relationships and even in  our home environment – think about what the ‘internet of things’ in all the devices in our  homes actually means. A technological sea change of such a magnitude places us in the  dilemma evoked by Blade Runner: any technology has benefits and hazards. And when we  broach the issue of artificial intelligence we are talking about benefits and/or risks on a scale  previously unimagined, given its intrinsic power.  The EU’s role in establishing a legal framework When public administrations address this phenomenon we cannot, however, adopt Deckard’s  professional cynicism. For the European Parliament it is just as important to harness these  technologies’ potential benefits for Europe’s well-being and competitiveness as it is to  monitor their inherent risks, or to pre-empt the consequences of the any of those risks actually  manifesting itself. We therefore wish to be pioneers in legally establishing an ethical  threshold which both protects European citizens from possible drawbacks of this  technological shift and provides added value in terms of trust in European artificial  intelligence in the world at large. An ethical threshold that is consistent with our European  principles and values enshrined in the Charter of Fundamental Rights of the European Union  and fully in line with the civilising mission of our project. Our Regulation must be inspired by  a humanistic and human-centred approach to technological development. A set of rules that  applies not only to artificial intelligence developed in Europe, but that also constitutes a  demanding regulatory imperative for anyone intending to operate in the EU. It is crucial that the set of rights and duties thus established is shared across all the Member  States of the European Union. A series of national regulations without a common benchmark  could mean the breakdown of the single market and undermine our collective effort to achieve  technological leadership in the world. Establishing a European agency responsible for  supervising the development of this regulation will lead to the harmonisation of the legal and  technical frameworks developed in each Member State. 
RR\1215422EN.docx 63/130 PE650.508v02-00 ENA flexible and future-oriented Regulation In response to those who advocate abandoning this sector to self-regulation, the initial  dialogue can also serve to illustrate the need for public involvement, with a view to achieving  aims that go beyond mere economic profitability: Europe’s public institutions must strive to  avoid discrimination (regardless of its basis) in the decision-making process and harness these  technologies’ potential for change so as to advance towards a fairer, more environmentally  sustainable society– with special emphasis in eliminating gender-based discrimination –  among other objectives. The text provides Europe’s public authorities with express mandates  to tackle these issues.  This Regulation also aspires to combine a highly ambitious set of requirements with  regulatory simplicity, avoiding imposing complicated regulatory systems and/or heavy  bureaucratic burdens on the agents involved. It also seeks to establish a sufficiently flexible  framework to accommodate progress within an ever-changing reality, while allowing for the  development rules in the sector that will shape ever more concrete realities. A comprehensive approach, including the establishment of national supervisory bodies This Regulation aims to extend supervision to all areas of a highly complex technology. It  includes provisions on development, implementation and the evolution of technology through  machine-learning or deep-learning. Special emphasis is placed on prevention when dealing  with technologies defined as ‘high risk’, i.e. those highly likely to cause negative externalities  and/or those requiring the use of sensitive materials that warrant special protection (which are  also defined in the Regulation). It also regulates the highly sensitive issues of individual rights  and remote recognition techniques, establishing many safeguards for their use. A very strict  temporary material framework for exceptional circumstances is also laid down for possible  use by public authorities in the event of major emergencies.  Another of the Regulation’s objectives is to encourage all citizens, especially the persons and  groups most involved in or affected by these technologies, to participate in the design,  development, control and supervision of this regulatory framework. The text sets out a  mandate – which it expressly states is mandatory – for all national supervisory bodies,  ensuring that the necessary, constant support of civil society. Similarly, it establishes  ambitious requirements in terms of transparency and accountability for the designers,  operators and users of artificial intelligence. It also includes obligations for users to behave  with due civility and the necessary to ensure they use the technologies in good faith. Comprehensibility, transparency, accountability, responsibility and governance We are still a long way from developing an algorithm able to give rise to ‘psychohistory’, the  fictional science in Isaac Asimov’s ‘Foundation’ series. The concept of free will, an  inalienable feature of humanity, does not appear to be in danger at the moment. This remains  the case, even though what is at stake is essentially anticipating the emergence of the great  currents of history. Our democratic authorities will have to ensure that all decisions, large and  small, taken with the assistance of artificial intelligence technologies are not the result of  obscure and inaccessible mathematical formulas. Comprehensibility, transparency,  accountability and responsibility will be indispensable features of the artificial intelligence  that is developed and operated in the European Union.
PE650.508v02-00 64/130 RR\1215422EN.docx ENIn a nutshell, the European Union must be an area which maintains the necessary balance  between safeguarding the rights of citizens and fostering technological development. Our  Regulation and the form it takes as it is developed by the supervisory body or bodies must  constitute an example for the rest of the world and the first step towards ensuring adequate  governance of this phenomenon at global level. 
RR\1215422EN.docx 65/130 PE650.508v02-00 EN24.6.2020 OPINION OF THE COMMITTEE ON FOREIGN AFFAIRS for the Committee on Legal Affairs with recommendations to the Commission on framework of ethical aspects of  artificial intelligence, robotics and related technologies (2020/2012(INL)) Rapporteur for opinion (*): Urmas Paet (*) Associated committee – Rule 57 of the Rules of Procedure (Initiative – Rule 47 of the Rules of Procedure)
PE650.508v02-00 66/130 RR\1215422EN.docx EN
RR\1215422EN.docx 67/130 PE650.508v02-00 ENSUGGESTIONS The Committee on Foreign Affairs calls on the Committee on Legal Affairs, as the committee  responsible: – to incorporate the following suggestions into its motion for a resolution: 1. Highlights that the security and defence policies of the European Union and its Member  States are guided by the principles enshrined in the European Charter of Fundamental  Rights and those of the United Nations Charter, and by a common understanding of the  universal values of respect for the inviolable and inalienable rights of the human person,  human dignity, of freedom, of democracy, of equality and of the rule of law; highlights  that all defence-related efforts within the Union framework must respect those universal  values whilst promoting peace, security and progress in Europe and in the world; is of  the opinion that the use of AI should be based on a common set of ethical principles  according to which the use should be: responsible, equitable, traceable, reliable, and  governable; 2. Welcomes the endorsement, by the 2019 Meeting of High Contracting Parties to the  United Nations Convention on Certain Conventional Weapons (CCW), of 11 Guiding  Principles for the development and use of autonomous weapons systems; regrets  however the failure to agree on a legally binding instrument regulating lethal  autonomous weapons (LAWS), with an effective enforcement mechanism; welcomes  and supports the Commission’s High-Level Expert Group on Artificial Intelligence  ‘Ethics Guidelines for Trustworthy AI’ published on 9 April 2019 and its position on  lethal autonomous weapon systems (LAWS); urges Member States to develop national  strategies for the definition and status of lethal autonomous weapons (LAWS) towards a  comprehensive strategy at Union level and to promote, together with the Union’s High  Representaive/Vice-President of the Commission (‘HR/VP’), and the Council to the  discussion on LAWS in the UN CCW framework and other relevant fora and the  establishment of international norms regarding the ethical and legal parameters of the  development and use of fully autonomous, semi-autonomous and remotely operated  lethal weapons systems; recalls in this respect its resolution on autonomous weapon  systems of 12 September 2018 and calls once again for the urgent development and  adoption of a common position on lethal autonomous weapon systems, for an  international ban on the development, production and use of lethal autonomous weapon  systems enabling strikes to be carried out without meaningful human control and  without respect for the human-in-the-loop principle, in line with the statement of the  world’s most prominent AI researchers in their open letter from 2015; welcomes the  agreement of Council and Parliament to exclude lethal autonomous weapons ‘without  the possibility for meaningful human control over the selection and engagement  decisions when carrying out strikes’ from actions funded under the European Defence  Fund; believes that ethical aspects of other AI-applications in defence, such as  intelligence, surveillance and reconnaissance (ISR) or cyber operations must not be  overlooked, and special attention must be paid to the development and deployment of  drones in military operations; 3. Recommends that any European framework regulating the use of artificial intelligence  (AI)-enabled systems in defence, both in combat and non-combat situations, must 
PE650.508v02-00 68/130 RR\1215422EN.docx ENrespect all applicable legal regimes, in particular international humanitarian law and  international human rights law, and it must be in compliance with Union law, principles  and values; stresses that the Union should play a global role in leading the way towards  a credible and binding AI regulatory framework rooted in democratic values and a  human-centric approach; calls on the Union and its Member States to develop joint  mechanisms to quickly and thoroughly assess the inherent AI-related risks and  opportunities with regard to the application of Union law, inspired by the best practices  of more advanced Member states, and to provide for necessary adjustment and  enforcement where needed, keeping in mind the disparities in terms of technical and  security infrastructures throughout the Union; 4. Recognises that unlike defence industrial bases, critical AI innovations could come  from small Member States, thus a CSDP-standardized approach should ensure that  smaller Member States and SME’s are not crowded out. Stresses that a set of common  EU AI capabilities matched to a Member States operating concepts can bridge the  technical gaps that could leave out states lacking the relevant technology, industry  expertise or the ability to implement AI systems in their defence ministries; 5. Emphasises that the geographical scope of such a framework should cover all the  components of artificial intelligence, robotics and related technologies developed,  deployed or used in the Union, including in cases where part of the technologies might  be located outside the Union or not have a specific location; 6. Underlines that emerging technologies not covered by international law should be  judged by the principle of respect for humanity and the dictates of public conscience;  underlines that the use and the ethics of AI-enabled systems in defence must be  constantly assessed, from the point of view of human rights notably human safety,  health and security, freedom, privacy, integrity and dignity and constantly monitored,  especially from the point of view of its advantages and disadvantages, as well as its  impact on the protection of universal human rights; believes that technological  advantages in the field of AI-enabled systems in defence must go hand in hand with an  ample discussion on the use of AI and its impact on societies and communities and  potential economic and societal benefits, and the risks stemming from the use of AI  must be properly communicated; 7. Considers that current and future security and defence-related activities within the  Union framework will draw on AI, on robotics and autonomy, and on related  technologies and that reliable, robust and trustworthy AI could contribute to a modern  and effective military; the Union must therefore assume a leading role in research and  development of AI systems in the security and defence field; believes that the use of AIenabled applications in security and defence could offer a number of direct benefits to  the operation commander, such as higher quality collected data, greater situational  awareness, increased speed for decision-making, reduced risk of collateral damage  thanks to better cabling, protection of forces on the ground, as well as greater reliability  of military equipment and hence reduced risk for humans and human casualties; stresses  that the development of reliable AI in the field of defence is essential for ensuring  European strategic autonomy in capability and operational areas; recalls that AI systems  are also becoming key elements in countering emerging security threats, such as cyber  and hybrid warfare both in the online and offline spheres; underlines at the same time  all the risks and challenges of unregulated use of AI; notes that AI could be exposed to 
RR\1215422EN.docx 69/130 PE650.508v02-00 ENmanipulation, to errors and inaccuracies; 8. Calls for synergies and networks to be established between the various European  research centres on AI as well as other multilateral fora, such as the Council of Europe,  the United Nations Educational Scientific and Cultural Organization (UNESCO), the  Organisation for Economic Co-operation and Development’s (OECD),the World Trade  Organisation and the International Telecommunications Union (ITU), in order to align  their efforts and to better coordinate the development of the AI technology; 9. Stresses that AI technologies are, in essence, dual use, and the development of AI in  defence-related activities benefits from exchanges between military and civil  technologies; highlights that AI in defence-related activities is a transverse disruptive  technology the development of which may provide opportunities for the  competitiveness sand the strategic autonomy of the Union; 10. Highlights that, based on the Commission’s communication of 8 April 2019 ‘Building  Trust in Human-Centric AI’ , whereby technology fully respects human rights and  humans retain authority over automated decision-making systems, while  complementing and supporting human autonomy and decision making the Union needs  a robust AI regulatory framework focused on security and defence, following a path of  responsibility and transparency, of protecting our citizens and their data, and of  defending our values, that its policies aim at preserving peace, preventing conflicts and  strengthening international security, whilst seizing the opportunities that those  technologies offer, as well as realising that AI- enabled systems will be a key element in  future defence-developments and defensive capabilities; 11. Calls on the Member States and the Commission to ensure that the algorithms used in  defence systems, while keeping the necessary confidentiality, are governed by the  principle of transparency, including a clear liability regime for the results of AI use;  underlines that such algorithms must be constantly adjusted to the progress in AI  technologies; 12. Underlines that the Union must be at the forefront of supporting multilateral efforts in  the framework of the UN CCW Governmental Expert Group and other relevant fora, to  discuss an effective international regulatory framework that ensures meaningful human  control over autonomous weapon systems in order to master those technologies by  establishing well defined, benchmark-based processes and adopting legislation for their  ethical use, in consultation with military, industry, law enforcement, academia and civil  society stakeholders, to understand the related ethical aspects and to contain the inherent  risks of such technologies and prevent use for malicious purposes; those include in  particular unintended harm to persons, be it material or immaterial, such as breach of  fundamental rights or physical harm; the Union working together with the Member  States must determine the appropriate liability regimes applicable to innovations in AI  and other immersive technologies in the field of security and defence, thus establishing  a legal basis for accountability and traceability mechanisms; highlights that Union  legislation and normative frameworks must not be overtaken by any future  technological advances, progress in AI and new methods of warfare and hence must be  supported by meaningful monitoring schemes to be constantly adjusted to prevent legal  loopholes or grey zones; underlines that further AI research and development should  ensure that AI enabled systems are better equipped to understand unique contexts;
PE650.508v02-00 70/130 RR\1215422EN.docx EN13. Endorses the key principle “ethics-by-design”, by which ethical principles are  embedded into AI products and services from the outset of the design process; 14. Recalls that most of the current military powers worldwide have already engaged in  significant R&D efforts related to the military dimension of AI; considers that the  Union must see to it that it does not lag behind in this regard; stresses that for any  defence application of AI enabled systems, the Union should set technical and  organisational standards, in accordance with the principle of “Security by Design”,  allowing for specific human oversight, to ensure the resilience of such systems against  vulnerabilities that can be exploited by external attacks, cyber-attacks and digital  influence targeting the data, the model or the underlying infrastructure, both software  and hardware, as well as their compliance with the highest possible reliability standards,  active monitoring and supervision as regards the collection, storage and exploitation of  operational data throughout a system’s entire lifecycle; emphasises the importance for  transparency and accountability of AI algorithms; notes the important distinction  between transparency of algorithms and transparency of the use of algorithms; stresses  that AI systems and applications intended to extract and synthesise data, and extrapolate  results therefrom to inform decisions for matters relating to defence and national  security, must be specific in scope and comply with the provisions set out in the current  regulatory framework in terms of gathering and processing data; stresses that AI  applications designed to process data for intelligence purposes in defence related  activities should comply with data processing standards to avoid risks of unintended  surveillance or infringement of individual rights; believes that for high-risk applications  of AI-enabled technologies like facial recognition which lack a definitive regulatory  framework at the EU level, the Union must ensure that their development and  deployment is rightful, proportional and respects the rights of individuals; stresses that  competent national law enforcement authorities must respect relevant legislation while  developing and deploying AI-enabled systems and technologies to maintain public  order so as to mitigate the disproportionate risks of predictive policing; recognises that  the primary guarantor of Euro-Atlantic security is NATO and calls for increased  cooperation within the NATO Alliance for the establishment of common standards and  interoperability of AI systems in defence; stresses that the transatlantic relationship is  crucial in preserving shared values and in countering future and emerging threats; 15. Highlights the need to adopt clear reliability, safety and security provisions and  requirements with proper certifications for AI-systems in security and defence, to  introduce transparency criteria in the various phases, namely design, production and  operation, and to carry out constant monitoring, regular tests and verification throughout  the entire life cycle; underlines the necessity of ensuring compliance with applicable  standards and obtained certifications where AI modifies e.g. through machine learning  the functionality and behaviour of systems in which it is integrated, in order to ensure  full traceability, explainability and accountability of decisions made with involvement  of AI and their outcomes, as well as meaningful human control when such systems  could kill humans; 16. Calls on the Commission to embed cybersecurity capacity-building in its industrial  policy in order to ensure the development and deployment of safe, resilient and robust  AI-enabled and robotic systems; calls on the Commission to explore the use of  blockchain-based cybersecurity protocols and applications to improve the resilience,  trust and robustness of AI infrastructures through disintermediated models of data 
RR\1215422EN.docx 71/130 PE650.508v02-00 ENencryption; encourages European stakeholders to research and engineer advanced  features that would facilitate the detection of corrupt and malicious AI-enabled &  robotics systems which could undermine the security of the Union and of citizens; 17. Stresses that all AI-systems in defence must have a concrete and well-defined mission  framework, whereby humans retain the agency to detect and disengage or deactivate  deployed systems should they move beyond the mission framework defined and  assigned by a human commander, or engage in any escalatory or unintended action;  considers that AI-enabled systems, products and technology intended for military use  should be equipped with a ‘black box’ to record every data transaction carried out by  the machine; 18. Underlines that the entire responsibility and accountability for the decision to design,  develop, deploy and use AI-systems must rest on human operators, as there must be  meaningful human monitoring and control over any weapon system and human intent in  the decision to use force in the execution of any decision of AI-enabled weapons  systems that might have lethal consequences; underlines that human control should  remain effective for the command and control of AI-enabled systems, following the  human-in-the loop, human-on-the loop and human-in-command principles at the  military leadership level; stresses that AI-enabled systems must allow the military  leadership of armies to assume its full responsibility and accountability for the use of  lethal force and exercise the necessary level of judgment, which machines cannot be  endowed with as it must be based on distinction, proportionality and precaution, for  taking lethal or large-scale destructive action by means of such systems; stresses the  need to establish clear and traceable authorisation and accountability frameworks for the  deployment of smart weapons and other AI-enabled systems, using unique user  characteristics like biometric specifications to enable deployment exclusively by  authorised personnel; 19. Calls on the Commission to work together with Member States’ national competent  authorities and other stakeholders participating in the development and deployment of  AI-enabled systems, products and technologies to establish a safe, secure and resilient  framework whereby the source code of AI-enabled systems is shared, monitored and  verified to mitigate potential deviations from the governing principles and ethical  framework underpinning AI technology in the field of security and defence; suggests to  the Commission that the Union must retain ownership of the intellectual property of  Union-funded research on AI-enabled systems, products and technologies in security  and defence; 20. Underlines that the Union must promote better understanding of the military  implications, advantages and opportunities and weaknesses of AI, of robotics and of  autonomous functions and features, including the potential for the European defence  industry, by working alongside military officials; considers that the Union needs to  promote the acquisition of the necessary skills and knowledge on technology  development processes and operational methods throughout the supply chain and over  the full lifecycle of AI-enabled military capabilities; underlines the urgent need for  establishing increased European strategic and technological independence in the field of  AI-enabled systems, including the critical infrastructure it relies on; 21. Believes that enhanced cooperation between Member States and the Commission is 
PE650.508v02-00 72/130 RR\1215422EN.docx ENnecessary to guarantee coherent cross-border rules in the Union, to encourage the  collaboration between European industries and allow the development and deployment  of AI-enabled technologies consistent with the prescribed safety and security standards,  and the ethical framework governing the development and deployment of AI  technology; 22. Recognises, in the hybrid and advanced warfare context of today, that the volume and  velocity of information during the early phases of a crisis might be overwhelming for  human analysts and that an AI system could process the information to ensure that  human decision-makers are tracking the full spectrum of information within an  appropriate timeframe for a speedy response; 23. Underlines the importance of investing in the development of human capital for  artificial intelligence, fostering the necessary skills and education in the field of security  and defence AI technologies with particular focus on ethics of semi-autonomous and  autonomous operational systems based on human accountability in an AI-enabled  world; stresses in particular the importance of ensuring that ethicists in this field have  appropriate skills and receive proper training ; calls on the Commission to present as  soon as possible its "Reinforcement of the Skills Agenda", announced in the White  Paper on Artificial Intelligence on the 19th February 2020; 24. Stresses that quantum computing could represent the most revolutionary change in  conflict since the advent of atomic weaponry and thus urges that the further  development of quantum computing technologies be a priority for the Union and  Member States; recognises that acts of aggression, including attacks on critical  infrastructure, aided by quantum computing will create a conflict environment in which  the time to make decisions will be compressed dramatically from days and hours to  minutes and seconds, forcing Member States to develop capabilities that protect  themselves and train both its decision makers and military personnel to respond  effectively within such timeframes; 25. Stresses the need to overcome the current fragmentation within the Union as regards  national AI-related law, research, innovation and expertise in the area of AI, which  endangers the functioning of the internal market and the objective of ensuring that there  is reliable and secure development of AI in Europe; in this respect welcomes the  inclusion of AI-related projects under the European Industrial Development  Programme(EDIDP); believes that the future European Defence Fund (EDF) and the  Permanent structured cooperation (PESCO) also offer well adapted frameworks for  future AI-related projects that would help to better streamline Union efforts in this field,  and promote at the same time the Union’s objective of strengthening human rights,  international law, and multilateral solutions; stresses that AI-related projects should be  synchronized with the wider Union civilian programmes devoted to AI; notes that in  line with the European Commission’s White Paper on AI excellence and testing centres  concentrating on research and development of AI in the field of security and defence  should be established with vigorous specifications underpinning the participation of and  investment from private stakeholders; 26. Highlights that the Union needs to strive for strategic resilience so that it is never again  found unprepared in times of crisis, and underlines that, especially in as far as artificial  intelligence and its application to defence and security are concerned, this is of crucial 
RR\1215422EN.docx 73/130 PE650.508v02-00 ENsignificance; emphasises that supply-chains for AI systems in defence and security that  can lead to technological dependence should be recalibrated and such dependencies  should be phased-out; calls for increased investment in European AI for defence and in  the critical infrastructure that sustains it; 27. Emphasises that the development of AI that respects fundamental rights and supports  the public interest requires the strategic pooling and sharing of data in the Union  between private and public entities, as well as the strengthening of a Union AI  ecosystem, which involves public, private, and civil society stakeholders; calls on the  Commission to foster dialogue, closer cooperation and synergies among Member States,  researchers, academics, civil society actors and the private sector, in particular leading  companies and enterprises, and the military so as to have inclusive policymaking  processes when it comes to defence-related AI regulations, harness the potential of AI  to the fullest, while fostering a better understanding of risks and benefits, as well as  ensuring maximum operational security; 28. Highlights that, in the context of the widespread disinformation war, particularly driven  by non-European actors, AI technologies might have ethically adverse effects by  exploiting biases in data and algorithms or by deliberately alternating learning data by a  third country, and could be also exposed to other forms of dangerous malign  manipulation in unpredictable ways and with incalculable consequences; there is  therefore an increased need for the Union to continue investment in research, analysis,  innovation and cross-border and cross-sector knowledge transfer in order to develop AI  technologies that would be clearly void of any sort of profiling, bias and discrimination,  and could effectively contribute to combating fake news and disinformation, while at  the same time respecting data privacy and the European legal framework; 29. Stresses the importance of the creation of an ethical code of conduct underpinning the  deployment of weaponised AI-enabled systems in military operations, similar to the  existing regulatory framework prohibiting the deployment of chemical and biological  weapons; is of the opinion that the Commission should initiate the creation of standards  on the use of AI-enabled weapons systems in warfare in accordance with international  humanitarian law, and the Union should pursue the international adoption of such  standards; considers that the Union should engage in AI diplomacy in international fora  with like-minded partners like the G7, the G20, and the OECD; 30. Takes note of the Commission's White Paper on Artificial Intelligence of 19 February  2020 and regrets that military aspects were not taken into account; calls on the  Commission and on the HR/VP to present, also as part of an overall approach, a sectoral  AI strategy for defence-related activities within the Union framework, that ensures both  respect for citizens’ rights and the Union’s strategic interests, and that is based on a  consistent approach spanning from the inception of AI-enabled systems to their military  uses, and to establish a Working Group on Security and Defence within the High-Level  Expert Group on Artificial Intelligence that should specifically deal with policy and  investment questions as well as ethical aspects of AI in the field of security and defence;  calls on the Council, the Commission and on the VP/HR to enter in a structured  dialogue with Parliament to that end.
PE650.508v02-00 74/130 RR\1215422EN.docx ENINFORMATION ON ADOPTION IN COMMITTEE ASKED FOR OPINION Date adopted 22.6.2020 Result of final vote +: –: 0:60 7 2 Members present for the final vote Alviina Alametsä, Maria Arena, Petras Auštrevičius, Traian Băsescu,  Lars Patrick Berg, Anna Bonfrisco, Reinhard Bütikofer, Fabio Massimo  Castaldo, Susanna Ceccardi, Włodzimierz Cimoszewicz, Katalin Cseh,  Tanja Fajon, Anna Fotyga, Michael Gahler, Kinga Gál, Sunčana  Glavak, Raphaël Glucksmann, Klemen Grošelj, Bernard Guetta, Márton  Gyöngyösi, Sandra Kalniete, Karol Karski, Dietmar Köster, Stelios  Kouloglou, Andrius Kubilius, Ilhan Kyuchyuk, David Lega, Miriam  Lexmann, Nathalie Loiseau, Antonio López-Istúriz White, Claudiu  Manda, Lukas Mandl, Thierry Mariani, David McAllister, Vangelis  Meimarakis, Sven Mikser, Francisco José Millán Mon, Javier Nart,  Gheorghe-Vlad Nistor, Urmas Paet, Kostas Papadakis, Tonino Picula,  Manu Pineda, Kati Piri, Giuliano Pisapia, Diana Riba i Giner, María  Soraya Rodríguez Ramos, Nacho Sánchez Amor, Isabel Santos, Jacek  Saryusz-Wolski, Andreas Schieder, Radosław Sikorski, Sergei  Stanishev, Tineke Strik, Hermann Tertsch, Hilde Vautmans, Harald  Vilimsky, Idoia Villanueva Ruiz, Thomas Waitz, Witold Jan  Waszczykowski, Charlie Weimers, Isabel Wiseler-Lima, Željana Zovko Substitutes present for the final vote Katarina Barley, Nicolas Bay, Arnaud Danjean, Katrin Langensiepen,  Hannah Neumann, Mick Wallace
RR\1215422EN.docx 75/130 PE650.508v02-00 ENFINAL VOTE BY ROLL CALL IN COMMITTEE ASKED FOR OPINION 60 + EPP Traian Băsescu, Arnaud Danjean, Michael Gahler, Kinga Gál, Sunčana Glavak, Sandra Kalniete, Andrius  Kubilius, David Lega, Miriam Lexmann, Antonio López-Istúriz White, Lukas Mandl, David McAllister,  Vangelis Meimarakis, Francisco José Millán Mon, Gheorghe-Vlad Nistor, Radosław Sikorski, Isabel  Wiseler-Lima, Željana Zovko  S&D Maria Arena, Katarina Barley, Włodzimierz Cimoszewicz, Tanja Fajon, Raphaël Glucksmann, Dietmar  Köster, Claudiu Manda, Sven Mikser, Tonino Picula, Kati Piri, Giuliano Pisapia, Nacho Sánchez Amor,  Isabel Santos, Andreas Schieder, Sergei Stanishev RENEW Petras Auštrevičius, Katalin Cseh, Klemen Grošelj, Bernard Guetta, Ilhan Kyuchyuk, Nathalie Loiseau, Javier  Nart, Urmas Paet, María Soraya Rodríguez Ramos, Hilde Vautmans ID Anna Bonfrisco, Susanna Ceccardi VERTS Alviina Alametsä, Reinhard Bütikofer, Katrin Langensiepen, Hannah Neumann, Diana Riba i Giner, Tineke  Strik, Thomas Waitz  ECR Anna Fotyga, Karol Karski, Jacek Saryusz-Wolski, Hermann Tertsch, Witold Jan Waszczykowski, Charlie  Weimers NI Fabio Massimo Castaldo, Márton Gyöngyösi 7 GUE Stelios Kouloglou, Manu Pineda, Idoia Villanueva Ruiz, Mick Wallace ID Nicolas Bay, Thierry Mariani NI Kostas Papadakis 2 0 ID Lars Patrick Berg, Harald Vilimsky Key to symbols: + : in favour - : against 0 : abstention
PE650.508v02-00 76/130 RR\1215422EN.docx EN8.7.2020 OPINION OF THE COMMITTEE ON THE INTERNAL MARKET AND CONSUMER  PROTECTION for the Committee on Legal Affairs with recommendations to the Commission on the framework of ethical aspects of artificial  intelligence, robotics and related technologies (2020/2012(INL)) Rapporteur for opinion: Alexandra Geese  (Initiative – Rule 47 of the Rules of Procedure) (*) Associated committee – Rule 57 of the Rules of Procedure SUGGESTIONS The Committee on the Internal Market and Consumer Protection calls on the Committee on  Legal Affairs, as the committee responsible:  – to incorporate the following suggestions into its motion for a resolution: A. Whereas ethical guidance, such as the principles adopted by the High-Level Expert Group  on Artificial Intelligence, provides a good starting point, but is not enough to ensure that  businesses act fairly and guarantee effective consumer protection; Scope 1. Underlines the importance of an EU regulatory framework focusing on the ethical aspects  of artificial intelligence (AI), robotics and related technologies being applicable where  consumers within the Union are users of, subject to, targeted by, or directed towards an  algorithmic system, irrespective of the place of establishment of the entities that develop,  sell or employ the system; furthermore, believes that, in the interest of legal certainty, the  rules set out should apply to all developers and across the value chain, namely the  development, deployment and use of the relevant technologies and their components, and  should guarantee a high level of consumer protection; reiterates the importance of Union  values as referred to in the Treaties regarding the importance of the protection of personal  data and of explicit, informed consent and proposes that those rules take into account the 
RR\1215422EN.docx 77/130 PE650.508v02-00 ENlessons drawn from the implementation of Regulation (EU) 2016/6791 (GDPR), which is  considered a global benchmark; considers that a legal representative, established in in the  Union, to whom requests could be addressed, in order, for example, to allow for consumer  redress, is important for the enforcement of a future EU regulatory framework;  2. Notes that the EU regulatory framework should apply to algorithmic systems, including the  fields of AI, the internet of things, machine learning, rule-based systems, automated and  assisted decision-making processes and robotics; further notes that standardised icons could  be developed to help explain such systems to consumers whenever those systems are  characterised by complexity or are enabled to make decisions that impact the lives of  consumers significantly; 3. Stresses that the EU regulatory framework must have a human-centric approach and lead  to the development of systems which incorporate European ethical values by design;  considers that an EU regulatory framework that focuses on Union values as referred to in  the Treaties would represent added value providing Europe with a unique competitive  advantage and would make a significant contribution to the well-being and prosperity of  Union citizens and businesses, as well as boost the internal market; underlines that an  ethical framework for AI also represents added value as regards promoting innovation on  the internal market; 4. Points out that the legislative framework introduced by Decision No 768/2008/EC2  provides for a harmonised list of obligations for producers, importers and distributors,  encourages the use of standards and provides for several levels of control depending on  the dangerousness of the product; considers that that framework should also apply to AI  embedded products; 5. Stresses that any future regulation should follow a differentiated risk-based approach to  enable the development and deployment of secure and trustworthy systems, with clear  criteria and indicators, followed by an impartial legal assessment based on the potential harm  or breaches of rights of the individual, as well as for the whole of society, taking into account  the specific context of use of the algorithmic system; stresses that legal obligations and  certification requirements should gradually increase with the identified risk level; highlights  that in the lowest risk category there should be no additional legal obligations; notes that  algorithmic systems that may harm an individual, or cause potential breaches of an  individual’s rights, or impact an individual’s access to public benefits shall not be deemed  to be in the lowest risk category; notes that the risk-based approach should follow clear and  transparent rules providing enough legal certainty whilst being future-proof; calls for a  uniform implementation of the system of risk classification and related legal obligations to  ensure a level-playing field among the Member States and to prevent a fragmentation of the  internal market; stresses that the risk assessment of a specific system must be subject to  1 Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April  2016 on the protection of natural persons with regard to the processing of personal data  and on the free movement of such data, and repealing Directive 95/46/EC (General Data  Protection Regulation) (OJ L 119, 4.5.2016, p. 1).  2 Decision No 768/2008/EC of the European Parliament and of the Council of 9 July  2008 on a common framework for the marketing of products, and repealing Council  Decision 93/465/EEC (OJ L 218, 13.8.2008, p. 82)
PE650.508v02-00 78/130 RR\1215422EN.docx ENregular re-evaluation; 6. Recalls that the Commission should examine the existing EU legal framework and its  application, including the consumer law acquis, product liability legislation, product  safety legislation and market surveillance legislation, in order to identify legal gaps, as  well as existing regulatory obligations; considers that this is necessary in order to  ascertain whether the existing EU legal framework is able to respond to the emergence of  AI, robotics and related technologies and whether it is able to ensure a high level of  consumer protection; Data Management 7. Underlines the importance of an EU ethical and regulatory framework including in particular  provisions requiring high quality data to train algorithmic systems in relation to the purpose  of their use; in that regard, highlights the necessity of ensuring the representativeness of the  training data used and, where possible, the de-biasing of data sets, as well as of data and  aggregation standards in order to improve the output of algorithmic systems and boost  consumer trust and acceptance; stresses that those data sets should be auditable by the  competent authorities whenever called upon to ensure their conformity with the  previously referenced principles; Consumer protection: transparency and explainability of algorithms 8. Underlines that consumer trust is essential for the development and implementation of AI,  robotics and related technologies which can carry inherent risks when they are based on  opaque algorithms and biased data sets; believes that consumers should have the right to be  adequately informed in an understandable, timely, standardised, accurate and accessible  manner about the existence, reasoning, possible outcome and impacts for consumers of  algorithmic systems, about how to reach a human with decision-making powers, and about  how the system’s decisions can be checked, meaningfully contested and corrected; recalls  that humans must always be able to overrule automated decisions; believes that consumers  should also be protected by the right to switch off or limit an AI system using personalisation  where possible; stresses the importance of proportionality in the development of such a  transparency framework to avoid creating an unnecessary burden on start-ups and small and  medium enterprises (SMEs) operating in low-risk categories; 9. Stresses the need to effectively address the challenges created by algorithmic systems and  to ensure that consumers are empowered and properly protected; underlines the need to look  beyond the traditional principles of information and disclosure on which the consumer  acquis has been built, as stronger consumer rights and clear limitations regarding the  development and use of algorithmic systems will be necessary to ensure technology  contributes to improving consumers’ lives and evolves in a way that respects fundamental  and consumer rights and European values; 10. Considers that a value-sensitive design approach is strongly needed to create the conditions  for widespread social acceptance of AI for consumers; considers that ethical values of  fairness, accuracy, confidentiality and transparency should be the basis of AI, which in this  context entails that the system’s operations should be such that they do not generate unfairly  biased outputs; 11. Recalls the importance of ensuring the availability of effective remedies for consumers and  calls on the Member States and national market surveillance authorities to ensure that 
RR\1215422EN.docx 79/130 PE650.508v02-00 ENaccessible, affordable, independent and effective procedures and review structures are  available in order to guarantee an impartial human review of all claims of violations of  consumer rights through the use of algorithmic systems, whether stemming from public or  private sector actors; urges that dispute resolution and collective redress mechanisms in line  with the Directive of the European Parliament and of the Council on representative actions  for the protection of the collective interests of consumers and repealing Directive  2009/22/EC3 should be made available to challenge the introduction or ongoing use of a  system entailing a risk for consumer rights violations, or to remedy a violation of rights; asks  the Commission to ensure that national and European consumer organisations have  sufficient funding to assist consumers in exercising their right to a remedy in cases where  decisions based on AI applications infringe consumer rights; 12. Stresses that where money originating from public sources significantly contributes to the  development or implementation of an algorithmic system, in addition to open procurement  and open contracting standards, the code, the generated data -as far as it is non-personal- and  the trained model could be public by default upon agreement with the developer, in order to  guarantee transparency, enhance cybersecurity and enable the reuse thereof so as to foster  innovation; stresses that, in this way, the full potential of the single market can be unlocked,  avoiding market fragmentation; Internal market: consumer information and awareness 13. Underlines the importance of ensuring that the interests of all consumers, including  consumers who are marginalised or in vulnerable situations, such as persons with  disabilities, are adequately taken into account and represented in a future EU regulatory  framework; notes that for the purpose of analysing the impacts of algorithmic systems on  consumers, access to data could be extended to appropriate parties, in particular independent  researchers, media and civil society organisations, where possible via Application  Programming Interfaces (APIs), while fully respecting Union data protection and privacy  legislation and trade secret legislation; recalls the importance of educating consumers to be  more informed and skilled when dealing with algorithmic systems, in order to protect them  from potential risks and uphold their rights; considers that AI, the internet of things, and  other emerging technologies have enormous potential to deliver opportunities for consumers  to be able to have access to several amenities which facilitate their daily lives in numerous  ways and allow for better products and services, while also benefitting consumers in terms  of fostering better market surveillance, as long as all applicable principles, conditions  (including transparency and auditability), and regulations continue to apply; 14. Underlines the importance of achieving a high level of overall digital literacy and training  highly skilled professionals in this area as well as ensuring the mutual recognition of such  qualifications throughout the Union; highlights the need of having diverse teams of  developers and engineers working alongside key societal actors to prevent gender and  cultural biases being inadvertently included in AI algorithms, systems and applications;  supports the creation of educational curricula and public-awareness activities concerning the  societal, legal, and ethical impact of AI; 15. Calls on the Commission to promote and fund the development of human-centric AI,  robotics and related technologies that address environment and climate challenges and that  ensure equal access to and enjoyment of fundamental rights through the use of fiscal,  3 COD (2018)0089, under publication.
PE650.508v02-00 80/130 RR\1215422EN.docx ENprocurement, or other incentives; 16. Underlines that AI and algorithmic systems should be legally compliant, robust, reliable and  secure by design; calls on the Commission to ensure that the Union’s regulatory approach  to algorithmic systems includes appropriate measures to make it possible for such systems  to be subject to independent control and oversight; Market surveillance 17. Calls for the establishment of a European centre of expertise strengthening Union capacities  and building as far as possible on existing structures to promote the exchange of information  related to algorithmic systems between the Member States’ authorities and to support the  development of a common understanding in the single market by issuing guidance, opinions  and expertise to Member States’ authorities, monitoring the implementation of relevant  Union legislation, addressing potential consumer protection issues, identifying standards for  best practice, and, where appropriate, making recommendations for regulatory measures;  further calls for this structure to be appropriately advised by stakeholder organisations, such  as consumer protection organisations, in order to ensure wide consumer representation;  considers that due to the disproportionate impact of algorithmic systems on women and  minorities, the decision levels of such a structure should be diverse and gender balanced;  emphasises that Member States must develop risk-management strategies for AI in the  context of their national market surveillance strategies;  18. Calls for the Commission to propose measures for data traceability, having in mind both the  legality of data acquisition and the protection of consumer rights and fundamental rights;  stresses, meanwhile, that the data sets, algorithms and processes used in the development  and deployment of algorithmic systems, including those of data collection and data labelling,  should be documented in accordance with the industry standard; notes that it is essential that  the risk assessment documentation, software documentation, the algorithms and data sets  used or produced by artificial intelligence, robotics, and related technologies be accessible  and explainable to market surveillance authorities, while respecting Union law and trade  secrets; further notes that such documentation should be stored by those who are involved  in the different stages of the development of algorithmic systems; notes that additional  prerogatives should be given to market surveillance authorities in that respect; considers that  an examination of the current market surveillance legislation might be necessary to avoid it  becoming obsolete and ensure that it responds ethically to the emergence of AI, robotics and  related technologies; 19. Calls for the designation, and sufficient funding by each Member State, of a competent  national authority for monitoring the application of the provisions related to algorithmic  systems; stresses the need for national market surveillance authorities to be reinforced in  terms of capacity, skills, and competences in AI as well as knowledge about the specific  risks of AI; 20. Calls for a strong coordination of Member State authorities and the establishment of a  European market surveillance board for algorithmic systems, composed of national  authorities, to ensure effective oversight, a European level playing field and to avoid  fragmentation of the internal market; 21. Acknowledges the valuable output of the High-Level Expert Group on Artificial  Intelligence, particularly ‘The Ethics Guidelines for Trustworthy Artificial Intelligence’; 
RR\1215422EN.docx 81/130 PE650.508v02-00 ENsuggests that that group comprising representatives from academia, civil society and  industry, as well as the European AI Alliance, might provide expertise to the European  market surveillance board for algorithmic systems; 22. Notes that, particularly in business-to-consumer domains, systems should be user-centric  and designed in a way that allows everyone to use AI products or services, regardless of their  age, gender, abilities or characteristics; notes that accessibility to this technology for persons  with disabilities, is of particular importance; notes that AI systems should not have a onesize-fits-all approach and should consider universal design principles addressing the widest  possible range of users, following relevant accessibility standards; stresses that this will  enable individuals to have equitable access to and to actively participate in existing and  emerging computer-mediated human activities and assistive technologies.
PE650.508v02-00 82/130 RR\1215422EN.docx ENINFORMATION ON ADOPTION IN COMMITTEE ASKED FOR OPINION Date adopted 7.7.2020 Result of final vote +: –: 0:39 1 4 Members present for the final vote Alex Agius Saliba, Andrus Ansip, Alessandra Basso, Brando Benifei,  Adam Bielan, Hynek Blaško, Biljana Borzan, Vlad-Marius Botoş,  Markus Buchheit, Dita Charanzová, Deirdre Clune, David Cormand,  Petra De Sutter, Carlo Fidanza, Evelyne Gebhardt, Alexandra Geese,  Sandro Gozi, Maria Grapini, Svenja Hahn, Virginie Joron, Eugen  Jurzyca, Arba Kokalari, Marcel Kolaja, Kateřina Konečná, Andrey  Kovatchev, Jean-Lin Lacapelle, Maria-Manuel Leitão-Marques,  Adriana Maldonado López, Antonius Manders, Beata Mazurek, Leszek  Miller, Kris Peeters, Anne-Sophie Pelletier, Christel Schaldemose,  Andreas Schwab, Tomislav Sokol, Ivan Štefanec, Kim Van Sparrentak,  Marion Walsmann, Marco Zullo Substitutes present for the final vote Pascal Arimont, Maria da Graça Carvalho, Edina Tóth, Stéphanie YonCourtin
RR\1215422EN.docx 83/130 PE650.508v02-00 ENFINAL VOTE BY ROLL CALL IN COMMITTEE ASKED FOR OPINION 39 + EPP S&D RENEW GREENS/EFA ECR EUL/NGL NIPascal Arimont, Maria da Graça Carvalho, Deirdre Clune, Arba Kokalari, Andrey Kovatchev, Antonius  Manders, Kris Peeters, Andreas Schwab, Tomislav Sokol, Ivan Štefanec, Edina Tóth, Marion Walsmann Alex Agius Saliba, Brando Benifei, Biljana Borzan, Evelyne Gebhardt, Maria Grapini, MariaManuel LeitãoMarques, Adriana Maldonado López, Leszek Miller, Christel Schaldemose Andrus Ansip, VladMarius Botoş, Dita Charanzová, Sandro Gozi, Svenja Hahn, Stéphanie YonCourtin David Cormand, Petra De Sutter, Alexandra Geese, Marcel Kolaja, Kimvan Sparrentak  Adam Bielan, Carlo Fidanza, Eugen Jurzyca, Beata Mazurek Kateřina Konečná, AnneSophie Pelletier Marco Zullo 1 ID Hynek Blaško 4 0 ID Alessandra Basso, Markus Buchheit, Virginie Joron, JeanLin Lacapelle Key to symbols: + : in favour - : against 0 : abstention
PE650.508v02-00 84/130 RR\1215422EN.docx EN16.7.2020 OPINION OF THE COMMITTEE ON TRANSPORT AND TOURISM for the Committee on Legal Affairs with recommendations to the Commission on framework of ethical aspects of artificial  intelligence, robotics and related technologies (2020/2012(INL)) Rapporteur for opinion: Valter Flego (*) Associated committee – Rule 57 of the Rules of Procedure (Initiative – Rule 47 of the Rules of Procedure) SUGGESTIONS The Committee on Transport and Tourism calls on the Committee on Legal affairs, as the  committee responsible, to incorporate the following suggestions into its motion for a resolution: A. whereas Artificial Intelligence (AI) is a form of technology that is of strategic  importance for the transport sector, and is expected to benefit citizens and society, by improving  the quality of life, raising the safety level of all modes of transport, and creating new  employment opportunities and more sustainable business models; whereas AI has the potential  to transform society significantly, in particular, if made widely available and accessible;  B. whereas the full potential of AI in the transport sector can only be exploited if users are  aware of the potential benefits and challenges that such technology brings; whereas it is  necessary to address this issue in education and training, including in terms of promoting digital  inclusion, and to conduct information campaigns at Union level that give an  accurate representation of all aspects of AI development; C. whereas a European approach to AI, robotics and related technologies needs to be in  accordance with ethical principles in order to ensure that AI, robotics and related technologies  are human-centric, to enhance human well-being, safety, the well-being of society and the  environment, to address the relevant ethical dilemmas, to fully respect Union fundamental  rights, values and principles, and to be fully in line with Union privacy and data protection  legislation; whereas this approach will also need to address issues regarding the quality of data  sets used in algorithmic systems, as well as the algorithms themselves, and data and aggregation  standards; D. whereas trustworthy AI must be based on four ethical principles: respect for human 
RR\1215422EN.docx 85/130 PE650.508v02-00 ENautonomy, prevention of harm, fairness and explainability; whereas the respect of those ethical  principles necessitates adopting specific rules for the Union’s transport sector; E. whereas human error is still involved in about 95% of all road traffic accidents in the  Union; whereas the Union aimed to reduce annual road fatalities in the Union by 50% by 2020  compared to 2010, but, in view of stagnating progress, renewed its efforts in its Road Safety  Policy Framework 2021 - 2030 - Next steps towards "Vision Zero"; whereas in this regard, AI,  automation and other new technologies have great potential and vital importance for increasing  road safety by reducing the possibilities for human error; F. whereas AI, automation and other new technologies can also contribute to reducing  traffic congestion and emissions of greenhouse gases and air pollutants;  G. whereas the production of ethically responsible, human-centred and technologically  robust AI, robotics and related technologies in the transport sector present Union businesses,  including SMEs, with a business opportunity to become global leaders in this area;  H. whereas such new business opportunities can contribute to the recovery of Union  industry after the current health and economic crisis and to making greater use of AI technology  in the transport industry; whereas such opportunities will create new jobs, as the uptake of AI  and related technologies has the potential to increase businesses' productivity levels and  contribute to efficiency gains; whereas innovation programs in this area can enable regional  clusters to thrive;  I. whereas a European approach to the development of AI, robotics and related  technologies in transport has the potential to increase the global competitiveness and strategic  autonomy of the Union economy; J. whereas for sectors like public transport, AI systems for intelligent transport systems  can be used to minimise queuing, optimise routing, enable persons with disabilities to be more  independent, and increase energy efficiency thereby enhancing decarbonisation efforts and  reducing the environmental footprint;  1. Highlights the potential of using AI, robotics and related technologies for all  autonomous means of road, rail, waterborne and air transport, and also for boosting the modal  shift and intermodality, as such technologies can contribute to finding the optimal combination  of modes of transport for the transport of goods and passengers; furthermore, stresses their  potential to make transport, logistics and traffic flows more efficient and to make all modes of  transport safer, smarter, and more environmentally friendly; points out that an ethical approach  to AI can also be seen as an early warning system, in particular as regards the safety and  efficiency of transport;  2 Highlights the fact that the global competition between companies and economic  regions means that the Union needs to promote investments and strengthen the international  competitiveness of companies operating in the transport sector, by establishing an environment  favourable for the development and application of AI solutions and further innovations, in  which Union-based undertakings can become world leaders in the development of AI  technologies; 3. Stresses that the EU transport sector needs an update of the regulatory framework  concerning such emerging technologies and their use in the transport sector and a clear ethical 
PE650.508v02-00 86/130 RR\1215422EN.docx ENframework for achieving trustworthy AI, including safety, security, the respect of human  autonomy, oversight and liability aspects, which will increase benefits that are shared by all and  will be key to boosting investment in research and innovation, development of skills and the  uptake of AI by public services, SMEs, start-ups and businesses and at the same time ensuring  data protection as well as interoperability, without imposing an unnecessary administrative  burden on businesses and consumers; stresses that it is crucial to ensure that any update of the  regulatory framework concerning these emerging technologies is always based on a real need  and complies with the principle of better regulation and in this regard; a) calls on the Commission to provide for a clear framework of ethical principles for the  development, deployment and use of AI, robotics and related technologies in the transport  sector; any AI, robotics and related technologies in the transport sector must be  developed, deployed and used in accordance with those ethical principles; b) recommends the establishment of guidelines for a harmonised risk classification of AIenabled technologies in all modes of transport, covering vehicle functions allocated to  humans and to AI, and clarifying responsibilities and requirements as regards safety;  c) calls on the Commission to explore the use of the existing European market surveillance  structure for algorithmic systems, including the associated data protection provisions,  issuing guidance, opinions and expertise to Member States’ authorities, including on  interoperability. d) calls on the Commission to set up an AI risk classification scheme for intelligent transport  systems, in line with the High Level Expert Group’s assessments, in order to respond  better to the emerging needs of the transport sector;  e) calls on the Commission to devote particular attention to the situation of SMEs and to  design future legislation in such a way as to improve the opportunities for such  undertakings to develop and use AI technology;  f) considers it necessary to provide detailed information to end-users regarding the  operation of transport systems and AI-based vehicles; 4. Highlights that the European approach to AI technology should secure people’s trust,  serve the public interest, and strengthen shared social responsibility; considers the development  of trustworthy, ethically responsible and technically robust AI to be an important enabler for  sustainable and smart mobility that is safe and accessible; in this regard, calls on the  Commission to continue to promote the uptake of AI in the transport sector and to propose, in  order to ensure that Union fundamental rights are respected, corresponding changes to Union  legislation without delay and in close cooperation with all stakeholders in the transport sector; 5. Stresses that the development and deployment of AI enabling safe and accessible  transport services; 6. Recommends the development of Union-wide trustworthy AI standards for all modes  of transport, including the automotive industry, concerning safety, interoperability, technical  robustness, reparability and recyclability of related hardware, including to deal with concerns  relating to resource efficiency, privacy, data protection and transparency, and for testing of AIenabled vehicles and related products and services;
RR\1215422EN.docx 87/130 PE650.508v02-00 EN7. Calls on the Commission to work closely with Member States on the design,  implementation and enforcement of trustworthy AI standards in the Union; notes that the Union  has the potential to become a global leader in promoting a socially responsible and sustainable  approach to AI technology and its use; 8. Calls on the Commission to explore the possibility of entrusting one or several relevant  existing agencies, institutions or bodies at Union level with monitoring, enforcement and  sanction mechanisms and to explore how the existing instruments of supervision and control in  the transport sector can be equipped and used to take action, in order to ensure that there is  oversight at Union level and enable the Commission to take action if an AI system used in  transport violates fundamental rights or the European ethical and security framework; 9. Calls on the Commission to further support the development of trustworthy AI systems  in order to render transport safer, more efficient, accessible, affordable and inclusive, including  for persons with reduced mobility, particularly persons with disabilities, taking account of  Directive (EU) 2019/882 of the European Parliament and of the Council1 and of Union law on  passenger rights; 10. Draws attention to the high added-value provided by autonomous vehicles for persons  with reduced mobility, as such vehicles allow them to participate more effectively in individual  road transport and thereby facilitate their daily lives; 11. Stresses the importance of accessibility, especially when designing MaaS-systems  (Mobility as a Service); 12. Underlines the critical importance for data science in order to design discriminationfree AI systems and prevent damaged data to be used; furthermore, recommends to follow  procedures for data processing compliant with the GDPR and respecting the principles of  confidentiality and non-discrimination; 13. Notes that AI systems could help to reduce the number of road fatalities significantly,  for instance through better reaction times and better compliance with rules; considers however  that it will be impossible for use of autonomous vehicles to result in the elimination of all  accidents and underlines that this makes the explainability of AI decisions increasingly  important in order to justify shortcomings and unintended consequences of AI decisions; 14. Takes the view that it must always be possible to explain AI decisions, as well as any  relevant data underpinning those decisions, to end-users and other stakeholders in non-technical  terms; 15. Notes that the development and implementation of AI in the transport sector will not be  possible without modern infrastructure, which is an essential part of intelligent transport  systems; stresses that the persistent divergences in the level of development between Member  States create the risk of depriving the least developed regions and their inhabitants of the  benefits brought by the development of autonomous mobility; calls for an assessment of the  challenges for the future of the labour market due to the development of AI technologies in the  transport sector, and for the modernisation of infrastructure in the Union, including its  1 Directive (EU) 2019/882 of the European Parliament and of the Council of 17 April  2019 on the accessibility requirements for products and services (OJ L 151, 7.6.2019, p. 70).
PE650.508v02-00 88/130 RR\1215422EN.docx ENintegration into the 5G network, to be adequately funded. 
RR\1215422EN.docx 89/130 PE650.508v02-00 ENINFORMATION ON ADOPTION IN COMMITTEE ASKED FOR OPINION Date adopted 14.7.2020 Result of final vote +: –: 0:49 0 0 Members present for the final vote Magdalena Adamowicz, Andris Ameriks, José Ramón Bauzá Díaz,  Izaskun Bilbao Barandica, Marco Campomenosi, Ciarán Cuffe, Jakop  G. Dalunde, Johan Danielsson, Andor Deli, Karima Delli, Anna  Deparnay-Grunenberg, Ismail Ertug, Gheorghe Falcă, Giuseppe  Ferrandino, Mario Furore, Søren Gade, Isabel García Muñoz, Jens  Gieseke, Elsi Katainen, Kateřina Konečná, Elena Kountoura, Julie  Lechanteux, Bogusław Liberadzki, Benoît Lutgen, Elżbieta Katarzyna  Łukacijewska, Marian-Jean Marinescu, Tilly Metz, Giuseppe Milazzo,  Cláudia Monteiro de Aguiar, Caroline Nagtegaal, Jan-Christoph Oetjen,  Philippe Olivier, Rovana Plumb, Dominique Riquet, Dorien  Rookmaker, Massimiliano Salini, Barbara Thaler, István Ujhelyi,  Elissavet Vozemberg-Vrionidi, Lucia Vuolo, Roberts Zīle, Kosma  Złotowski Substitutes present for the final vote Leila Chaibi, Angel Dzhambazki, Markus Ferber, Carlo Fidanza, Maria  Grapini, Roman Haider, Alessandra Moretti
PE650.508v02-00 90/130 RR\1215422EN.docx ENFINAL VOTE BY ROLL CALL IN COMMITTEE ASKED FOR OPINION 49 + ECR Group Angel Dzhambazki, Carlo Fidanza, Roberts Zīle, Kosma Złotowski GUE/NGL Group Leila Chaibi, Kateřina Konečná, Elena Kountoura ID Group Marco Campomenosi, Roman Haider, Julie Lechanteux, Philippe Olivier, Lucia Vuolo NI Dorien Rookmaker, Mario Furore,  PPE Group Magdalena Adamowicz, Andor Deli, Gheorghe Falcă, Markus Ferber, Jens Gieseke, Benoît Lutgen,  Marian-Jean Marinescu, Giuseppe Milazzo, Cláudia Monteiro de Aguiar, Massimiliano Salini, Barbara  Thaler, Elissavet Vozemberg-Vrionidi, Elżbieta Katarzyna Łukacijewska Renew Group José Ramón Bauzá Díaz, Izaskun Bilbao Barandica, Søren Gade, Elsi Katainen, Caroline Nagtegaal,  Jan-Christoph Oetjen, Dominique Riquet S&D Group Andris Ameriks, Johan Danielsson, Ismail Ertug, Giuseppe Ferrandino, Isabel García Muñoz, Maria Grapini,  Bogusław Liberadzki, Alessandra Moretti, Rovana Plumb, István Ujhelyi Verts/ALE Group Ciarán Cuffe, Jakop G. Dalunde, Karima Delli, Anna Deparnay-Grunenberg, Tilly Metz 0 0 0 Key to symbols: + : in favour - : against 0 : abstention
RR\1215422EN.docx 91/130 PE650.508v02-00 EN22.9.2020 OPINION OF THE COMMITTEE ON CIVIL LIBERTIES, JUSTICE AND HOME  AFFAIRS for the Committee on Legal Affairs with recommendations to the Commission on the framework of ethical aspects of artificial  intelligence, robotics and related technologies (2020/2012(INL)) Rapporteur for opinion (*): Assita Kanko (*) Associated committee – Rule 57 of the Rules of Procedure (Initiative – Rule 47 of the Rules of Procedure) SUGGESTIONS The Committee on Civil Liberties, Justice and Home Affairs calls on the Committee on Legal  Affairs, as the committee responsible, to incorporate the following suggestions into its motion  for a resolution: – having regard to Articles 2 and 3 of the Treaty on European Union (TEU), – having regard to Articles 10, 19, 21 and 167 of the Treaty on the Functioning of the  European Union (TFEU), – having regard to the right to petition enshrined in Articles 20 and 227 of the TFEU and  Article 44 of the Charter of Fundamental Rights of the European Union (EUCFR), – having regard to Articles 21 and 22 of the EUCFR, – having regard to the preamble to the TEU, – having regard to the Council of Europe’s Framework Convention for the Protection of  National Minorities, Protocol No 12 to the Convention for the Protection of Human  Rights and Fundamental Freedoms, and the European Charter for Regional or Minority  Languages, – having regard to Council Directive 2000/43/EC of 29 June 2000 implementing the  principle of equal treatment between persons irrespective of racial or ethnic origin1  1 OJ L 180, 19.7.2000, p. 22.
PE650.508v02-00 92/130 RR\1215422EN.docx EN(Racial Equality Directive), – having regard to Council Directive 2000/78/EC of 27 November 2000 establishing a  general framework for equal treatment in employment and occupation2 (Equal  Treatment in Employment Directive), – having regard to Regulation (EU) 2016/679 of the European Parliament and of the  Council of 27 April 2016 on the protection of natural persons with regard to the  processing of personal data and on the free movement of such data, and repealing  Directive 95/46/EC (General Data Protection Regulation)3 (GDPR), and to Directive  (EU) 2016/680 of the European Parliament and of the Council of 27 April 2016 on the  protection of natural persons with regard to the processing of personal data by  competent authorities for the purposes of the prevention, investigation, detection or  prosecution of criminal offences or the execution of criminal penalties, and on the free  movement of such data, and repealing Council Framework Decision 2008/977/JHA4, – having regard to the Communication from the Commission to the European Parliament,  the Council, the European Economic and Social Committee and the Committee of the  Regions of 11 December 2019 on The European Green Deal, – having regard to its resolution of 16 February 2017 with recommendations to the  Commission on Civil Law Rules on Robotics5, – having regard to the OECD Council Recommendation on Artificial Intelligence adopted  on 22 May 2019, A. whereas the development and design of so-called ‘artificial intelligence’, robotics and  related technologies is done by humans, and their choices determine the potential of  technology to benefit society; B. whereas algorithmic accountability should mean implementing technical and  operational measures that ensure transparency, clearly assigned chains of responsibility,  non-discrimination through automated decision-making or through calculating of  probabilities of individual behaviour; whereas transparency should give individuals  meaningful information about the logic involved, the significance and the envisaged  consequences; whereas this should include information about the data used for training  AI and allow individuals to understand and monitor the decisions affecting them; C. whereas there are serious concerns that the current EU legal framework, including the  consumer law acquis, product safety and market surveillance legislation, as well as  antidiscrimination legislation is not always fit for purpose to effectively tackle the risks  created by artificial intelligence, robotics and related technologies; D. whereas artificial intelligence, robotics and related technologies can have serious  implications for material and immaterial goods of individuals, groups, and society as a  whole, and these individual and collective harms must be reflected in legislative  2 OJ L 303, 2.12.2000, p. 16. 3 OJ L 119, 4.5.2016, p. 1. 4 OJ L 119, 4.5.2016, p. 89. 5 OJ C 252, 18.7.2018, p. 239
RR\1215422EN.docx 93/130 PE650.508v02-00 ENresponses; E. whereas governance issues with the deployment of AI in the public sector must be duly  considered in terms of its implications for democracy, especially democratic legitimacy,  accountability, meaningful public engagement and oversight; F. whereas data analysis and AI increasingly impact on the information made accessible to  citizens; whereas such technologies, if misused, may endanger fundamental rights to  information as well as media freedom and pluralism; G. whereas ethical guidance, such as the principles adopted by the High-Level Expert  Group on Artificial Intelligence, provides a good starting point but is not enough to  ensure that businesses act fairly and guarantee the effective protection of individuals; 1. Stresses that the prospects and opportunities of artificial intelligence can only be fully  tapped into by citizens, the public and private sectors, academia and the scientific  community when public trust in these technologies is ensured by a strong enforcement  of fundamental rights and compliance with current EU data protection law and legal  certainty for all actors involved; stresses that the processing of personal data can only be  done pursuant to any of the legal bases laid down in Article 6 of Regulation (EU)  2016/679; considers that it is crucial that transparency and the proper provision of  information to the audiences concerned are key to building public trust and to the  protection of individual rights; 2. Underlines that compliance with the existing data protection legislation, together with  strong scientific, ethical and legal standards, and methods for democratic oversight, are  key to establishing trust in, and the reliability of, AI solutions; further emphasises that  information revealed by AI does not offer an impartial overview of any subject matter  and is only as reliable as the underlying data permits; highlights that predictive analysis  based on AI can only offer a statistical probability and therefore cannot always  accurately predict individual behaviour; stresses, therefore, that strong scientific, ethical  and legal standards are vital for managing data collection and judging the results of such  AI analysis; 3. Believes that any framework of ethical principles for the development, deployment and  use of AI, robotics and related technologies should fully respect the EU Charter of  fundamental rights and thereby respect human dignity, autonomy and self-determination  of the individual, prevent harm, promote fairness, inclusion and transparency, eliminate  biases and discrimination, also of minority groups, and respect and comply with the  principles of limiting the negative externalities of technology used, explainability of  technologies, and the guarantee that the technologies are there to serve people and not  replace or decide for them, with the ultimate aim of increasingly human well-being for  everybody; 4. Highlights the asymmetry between those who employ AI technologies and those who  interact and are subject to them; in this context, stresses that citizens’ trust in AI can  only be built on an “ethics-by-default and by design” framework which ensures that any  AI put into operation fully respects and complies with the Charter of Fundamental  Rights of the European Union, Union law and the Treaties; considers that this should be  in line with the precautionary principle that guides EU legislation and should be at the  heart of any framework for AI; calls, in this regard, for a clear and coherent governance 
PE650.508v02-00 94/130 RR\1215422EN.docx ENmodel that allows companies and innovators to further develop artificial intelligence,  robotics and related technologies;  5. Calls on the European Union and on the Member States to promote public awareness of  the risks and opportunities of the use of AI as an ethical requirement; 6. Considers that the current Union legal framework, in particular on protection and  privacy and personal data, will need to fully apply to AI, robotics, and related  technologies and to be reviewed and scrutinized on a regular basis and updated where  necessary in order to effectively tackle the risks created by artificial intelligence,  robotics and related technologies, and, in this regard, could benefit from being  supplemented with robust guiding ethical principles; points out that, where it would be  premature to adopt legal acts, a soft law framework should be used;  7. Expects the Commission to integrate a strong ethical framework into the forthcoming  legislative proposal as a follow up to the White Paper on Artificial Intelligence,  including on safety, liability, fundamental rights, which maximises the opportunities  and minimises the risks of AI technologies; expects that the forthcoming legislative  proposal will include policy solutions to the major recognised risks of Artificial  Intelligence including, amongst others, on the ethical collection and use of Big Data, the  issue of algorithmic transparency and algorithmic bias; calls on the Commission to  develop criteria and indicators to label AI technology in order to stimulate transparency,  explanability, and accountability and incentivise additional precautions by developers;  stresses the need to invest in integrating non-technical disciplines attuned to social  context in AI study and research; 8. Recalls that AI, depending on how it is developed, used and applied, has the potential to  create and reinforce biases, including through inherent biases in the underlying datasets,  and therefore, create various forms of automated discrimination, including indirect  discrimination, concerning in particular groups of people with similar characteristics;  calls on the Commission and the Member States to take any possible measure to avoid  such biases and to ensure the full protection of fundamental rights; 9. Notes that the field of AI, robotics and related technologies is strikingly homogenous  and lacking in diversity; recognises the need to ensure that the teams that design,  develop, test, maintain, deploy and procure these systems reflect the diversity of its uses  and of society in general in order to ensure that bias is not unwittingly ‘built in’ to these  technologies; 10. Is of the opinion that effective cross- border cooperation and ethical standards can be  achieved only if all stakeholders commit to ensure human agency and oversight,  technical robustness and safety, transparency and accountability, diversity, nondiscrimination and fairness, societal and environmental well-being and respect the  established principles of privacy, and data governance and data protection - specifically  those enshrined in Regulation (EU) 2016/679 (GDPR); 11. Calls for a risk-based and future oriented approach to regulating artificial intelligence,  robotics and related technologies, including technology-neutral standards across all  sectors, with sector-specific standards where appropriate ; strongly believes that an EUwide workable ethical framework should apply to anyone intending to develop or  operate AI applications in the Union to avoid fragmentation; calls on the Union to 
RR\1215422EN.docx 95/130 PE650.508v02-00 ENpromote strong and transparent cooperation and knowledge-sharing between the public  and private sectors to create best practice and to identify high-risk applications of AI; 12. Promotes Corporate Digital Responsibility on a voluntary basis; the Union should  support corporations, who by choice use digital technologies and AI ethically within  their companies; the Union should encourage corporations to become proactive by  establishing a platform for companies to share their experiences with ethical  digitalization, as well as coordinating the actions and strategies of participating  companies; 13. Stresses that the protection of networks of interconnected AI and robotics is important  and strong measures must be taken to prevent security breaches, data leaks, data  poisoning, cyber-attacks and the misuse of personal data, and that this will require the  relevant agencies, bodies and institutions both at European and national level to work  together and in cooperation with end users of these technologies; calls on the  Commission and Member States to ensure that Union values and respect for  fundamental rights are observed at all times when developing and deploying AI  technology in order to ensure the security and resilience of the EU’s digital  infrastructure; 14. Notes in this regard the provisions laid down in Regulation 2019/881 of the European  Parliament and of the Council on ENISA and the Cyber Security Act, particularly  ENISA's role in promoting public awareness and education campaigns directed at end  users including on potential cyber threats and criminal activities online, and in  promoting essential data protection measures; acknowledges the added value of this EU  agency in this regard; 15. Stresses that the malicious use of AI can pose a risk to the values of our democracies  and the fundamental rights of the citizens of the European Union. Calls on the  Commission to propose a framework that penalises those who, using this technology,  distort the perception of reality through disinformation campaigns, or who provoke  cyber-attacks in order to violate digital cyber-security. 16. Notes that AI, robotics and related technologies in the area of law enforcement and  border control could enhance public safety and security, but also need extensive and  rigorous public scrutiny and the highest possible level of transparency both with regards  to the risk assessment of individual applications, as well as a general overview of their  use of AI, robotics and related technologies in the area of law enforcement and border  control; considers that these technologies bear significant ethical risks that must be  adequately addressed, considering the possible adverse effects on individuals when it  comes, in particular to their rights to privacy, data protection and non-discrimination;  stresses that their misuse can become a direct threat to democracy and that their  deployment and use must respect the principles of proportionality and necessity, the  Charter of Fundamental Rights, as well as the relevant secondary Union law such as EU  data protection rules; Stresses that AI should never replace humans in issuing  judgments; decisions, such as getting bail or probation, being heard in court, or  decisions based solely on automated processing, producing a legal effect concerning  individuals or which significantly affect them, must always involve meaningful  assessment and the judgement of a human;
PE650.508v02-00 96/130 RR\1215422EN.docx EN17. Warns that, owing to the intrusiveness of the decisions and measures taken by law  enforcement authorities – including by means of data processing and AI – into the lives  and rights of citizens, maximum caution is required in order to prevent unlawful  discrimination and the targeting of certain individuals or groups of people defined by  reference to race, colour, ethnic or social origin, genetic features, language, religion or  belief, political or any other opinion, property, birth, disability, age, gender, gender  expression or identity, sexual orientation, residence status, health or membership of a  national minority which is often the subject of ethnic profiling or more intense law  enforcement policing, as well as individuals who happen to be defined by particular  characteristics; calls for proper training for the frontline collectors of data and users of  intelligence derived from AI; 18. Points out that the possibility provided by these technologies of using personal and nonpersonal data to categorise and micro-target people, identify vulnerabilities of  individuals, or exploit accurate predictive knowledge, has to be counterweighted by  effectively enforced data protection and privacy principles such as data minimisation,  the right to object to profiling and to control one’s data, the right to obtain an  explanation of a decision based on automated processing, and privacy by design, as well  as those of proportionality, necessity and limitation based on strictly identified purpose;  points out that while certain models of predictive policing are more privacy-friendly  than others, such as where probabilistic predictions are made about places or events and  not about individual persons, predictive policing systems have proven to exacerbate  overpolicing on the basis of existing bias such as racial profiling, or on migrant or  working class backgrounds even where this does not correspond to actual crime levels; 19. Stresses that citizens have the right to trust in the technology they use, and trust in the  technology that is used by others; stresses that AI and robotics are not immune from  making mistakes, and therefore emphasizes the importance of the right to an  explanation when persons are subjected to algorithmic decision-making as well as the  need for algorithms to be transparent, since transparency regarding the underlying logic  of an algorithm is highly relevant for those who are affected, in order for their  fundamental rights to be fully protected; considers the need for legislators to reflect  upon the complex issue of liability, and that liability in all AI applications should  always rest with a person, either natural or legal;  20. Underlines that artificial intelligence, robotics and related technologies are global  technologies and that these standards need to be adopted worldwide in order to ensure  their future development is aligned to Union values and ethical standards; calls on the  Commission to engage in AI diplomacy in international fora with likeminded partners  such as the United States, the G7, the G20, and OECD for establishing common ethical  standards and guidelines for developing AI, robotics, and related technologies; 21 Stresses that a clear framework needs to be introduced for the use of AI by social media  platforms, as do transparency requirements for the algorithms used and the calibration  thereof, in order to prevent excessive content-removal and any form of filtering or  censorship of the internet; 22 Notes that AI can be used to manipulate face- and audiovisual characteristics, often  referred to as deepfakes; recalls that this technique can be used to manipulate elections,  to disseminate disinformation and for other undesirable actions; asks the Commission 
RR\1215422EN.docx 97/130 PE650.508v02-00 ENtherefore to use its ethical framework to impose an obligation for all deepfake material  or any other realistically made synthetic videos, to state it's not original and to introduce  a strict limitation when used for electoral purposes; 23. Suggests to create a centre of expertise, bringing together academia, research, industry,  and individual experts at Union level, either as an integral part of or associated with  such Agency, to foster exchange of knowledge and technical expertise, and to facilitate  collaboration throughout the EU and beyond; 24. Recalls the importance of linguistic and cultural diversity; calls therefore on the  Commission to use its ethical framework to not let AI reduce this diversity, but to keep  offer access to a wide variety of content which would not over-represent a single  language and/or cultural model and to condemn any attempts from algorithms which  would restrict this diversity and only offer content corresponding to some already  existing patterns or which could act as an 'echo-chamber' that would prevent access to  more diversity; 25. Recommends that the Commission demonstrates that it has clearly reviewed, assessed  and adjusted its coordinated plan on AI in order to address the severe fundamental  rights implications of AI, and outline how such risks will be mitigated in the EU’s  legislative approach and in the implementation of Member State national strategies;
PE650.508v02-00 98/130 RR\1215422EN.docx ENINFORMATION ON ADOPTION IN COMMITTEE ASKED FOR OPINION Date adopted 22.9.2020 Result of final vote +: –: 0:55 5 7 Members present for the final vote Magdalena Adamowicz, Malik Azmani, Katarina Barley, Pernando  Barrena Arza, Pietro Bartolo, Nicolas Bay, Vladimír Bilčík, Vasile  Blaga, Ioan-Rareş Bogdan, Patrick Breyer, Saskia Bricmont, Joachim  Stanisław Brudziński, Jorge Buxadé Villalba, Damien Carême, Anna  Júlia Donáth, Lena Düpont, Cornelia Ernst, Laura Ferrara, Nicolaus  Fest, Jean-Paul Garraud, Maria Grapini, Sylvie Guillaume, Andrzej  Halicki, Balázs Hidvéghi, Evin Incir, Sophia in ‘t Veld, Patryk Jaki,  Lívia Járóka, Marina Kaljurand, Assita Kanko, Fabienne Keller, Peter  Kofod, Moritz Körner, Alice Kuhnke, Jeroen Lenaers, Juan Fernando  López Aguilar, Nuno Melo, Roberta Metsola, Nadine Morano, Javier  Moreno Sánchez, Maite Pagazaurtundúa, Nicola Procaccini, Paulo  Rangel, Diana Riba i Giner, Ralf Seekatz, Michal Šimečka, Birgit  Sippel, Sylwia Spurek, Tineke Strik, Ramona Strugariu, Annalisa  Tardino, Tomas Tobé, Dragoş Tudorache, Milan Uhrík, Tom  Vandendriessche, Bettina Vollath, Jadwiga Wiśniewska, Elena  Yoncheva Substitutes present for the final vote Delara Burkhardt, Gwendoline Delbos-Corfield, Kostas Papadakis, Kris  Peeters, Anne-Sophie Pelletier, Sira Rego, Rob Rooken, Paul Tang,  Tomáš Zdechovský Substitutes under Rule 209(7) present  for the final voteIsabel Benjumea Benjumea
RR\1215422EN.docx 99/130 PE650.508v02-00 ENFINAL VOTE BY ROLL CALL IN COMMITTEE ASKED FOR OPINION 55 + EPP Magdalena Adamowicz, Isabel Benjumea Benjumea, Vladimír Bilčík, Vasile Blaga, Ioan-Rareş Bogdan, Lena  Düpont, Andrzej Halicki, Balázs Hidvéghi, Lívia Járóka, Jeroen Lenaers, Nuno Melo, Roberta Metsola,  Nadine Morano, Kris Peeters, Paulo Rangel, Ralf Seekatz, Tomas Tobé, Tomáš Zdechovský S&D Katarina Barley, Pietro Bartolo, Delara Burkhardt, Maria Grapini, Sylvie Guillaume, Evin Incir, Marina  Kaljurand, Juan Fernando López Aguilar, Javier Moreno Sánchez, Birgit Sippel, Sylwia Spurek, Paul Tang,  Bettina Vollath, Elena Yoncheva RENEW Malik Azmani, Anna Júlia Donáth, Sophia In 'T Veld, Fabienne Keller, Moritz Körner, Maite  Pagazaurtundúa, Michal Šimečka, Ramona Strugariu, Dragoş Tudorache  ID Peter Kofod GREENS/EFA Patrick Breyer, Saskia Bricmont, Damien Carême, Gwendoline Delbos-Corfield, Alice Kuhnke, Diana Riba I  Giner, Tineke Strik ECR Joachim Stanisław Brudziński, Jorge Buxadé Villalba, Assita Kanko, Nicola Procaccini, Jadwiga Wiśniewska NI Laura Ferrara 5 EUL/NGL Pernando Barrena Arza, Cornelia Ernst, Anne-Sophie Pelletier, Sira Rego NI Kostas Papadakis 7 0 ID Nicolas Bay, Nicolaus Fest, Jean-Paul Garraud, Annalisa Tardino, Tom Vandendriessche ECR Rob Rooken NI Milan Uhrík Key to symbols: + : in favour - : against 0 : abstention
PE650.508v02-00 100/130 RR\1215422EN.docx EN7.9.2020 OPINION OF THE COMMITTEE ON EMPLOYMENT AND SOCIAL AFFAIRS for the Committee on Legal Affairs with recommendations to the Commission on a framework of ethical aspects of artificial  intelligence, robotics and related technologies (2020/2012(INL)) Rapporteur for opinion: Lina Gálvez Muñoz (Initiative – Rule 47 of the Rules of Procedure) SUGGESTIONS The Committee on Employment and Social Affairs calls on the Committee on Legal Affairs,  as the committee responsible, to incorporate the following suggestions into its motion for a  resolution: A. Whereas the application of Artificial Intelligence, robotics and related technologies (AI)  in everyday life and in the workplace is constantly increasing, thereby significantly  transforming current socio-economic structures; whereas AI should benefit citizens and  society by improving the quality of life, creating new employment opportunities and  improving the competitiveness of the Union; whereas AI is an essential part of the  digital economy and has the potential to foster prosperity and facilitate the transition to  a sustainable economy, if harnessed well; B. Whereas AI refers to systems that display intelligent behaviour by analysing their  environment and taking actions, with some degree of autonomy, to achieve specific  goals; whereas AI-based systems can be purely software-based, acting in the virtual  world, for example in the form of voice assistants, image analysis software, search  engines, speech and face recognition systems, or they can be embedded in hardware  devices, for example in the form of advanced robots, autonomous cars, drones or  Internet of Things applications;1 C. Whereas AI constitutes a strategic priority the full potential of which can only be  exploited if users and consumers are aware of the potential benefits and challenges it  brings; whereas enterprises as well as workers and their representatives are often aware  of neither AI applications nor of their underlying functions and data; whereas there are  1 Commission Communication on Artificial Intelligence for Europe, COM(2018) 237 final
RR\1215422EN.docx 101/130 PE650.508v02-00 ENcases of AI applications in breach of existing regulations, such as data protection; D. Whereas AI potentially offers economic and societal benefits as well as new  opportunities for businesses and workers, while at the same time giving rise to a number  of ethical, legal and employment related challenges; whereas the application of AI at the  workplace can contribute to inclusive labour markets and impact occupational health  and safety, while it can also be used to monitor, evaluate, predict and guide the  performance of workers with direct and indirect consequences for their careers; whereas  AI should have a positive impact on working conditions and be guided by respect for  human rights as well as the fundamental rights and values of the Union; whereas AI  should be human centric, enhance the well-being of people and society and contribute to  a fair and just transition; E. Whereas AI has a marked impact on the labour market2; whereas it can potentially  replace workers performing repetitive activities, facilitate human-machine collaborative  working systems, increase competitiveness and prosperity and create new job  opportunities for qualified workers; whereas the employment landscape is rapidly  evolving with an estimated 65% of today´s children expected to work in completely  new types of job and there is a need for re-skilling and up-skilling of workers, in  particular with regard to digital skills, to ensure no one is left behind and there is a  sufficient supply of specialised labour3; F. Whereas according to CEDEFOP, about 43% of Union adult employees have  experienced new technologies at work; whereas about seven in ten Union workers  require at least moderate digital skills to do their job;4 whereas on average, about one  quarter of Union citizens have no or low-level digital skills; whereas the digital divide  has specific socio-economic, gender, age, geographic and accessibility aspects, which  must be addressed; whereas 42% of workers in companies that apply AI in their  business processes believe that such activities lead to ethical issues, which must be  addressed; whereas 28% of the employers believe that the application of AI has not  developed at full scale because of a lack of ethical rules on this issue;5 G. Whereas the COVID-19 pandemic underlined the importance of digital solutions,  including teleworking, as well as its technical and social implications; whereas there are  no common provisions at Union level, as regards the application of AI at the workplace,  which could lead to market distortions and competition disadvantages; whereas AI  should be subject to an appropriate regulatory framework; H. whereas the OECD has drawn up recommendations on AI6; I. whereas the Council of the European Union encourages the promotion of an ethical and  human-centred approach with regard to AI7; J. whereas social partners at Union level concluded a framework agreement on  2 STOA, “The ethics of artificial intelligence: issues and initiatives” March 2020 3 European Parliament, “Encouraging STEM Studies for the labour market” March 2015 4 CEDEFOP, “European Skills and Jobs survey” 5 Capgemini Research Institute, “Why addressing ethical questions in AI will benefit organisations”, July 2019 6 OECD, “Recommendation of the Council on Artificial Intelligence”, 2019,  https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449 7 Council of the European Union “Council Conclusions on Shaping Europe’s Digital future”, June 2020
PE650.508v02-00 102/130 RR\1215422EN.docx ENdigitalisation, which amongst others includes a chapter on “Artificial intelligence and  guaranteeing the human in control principle”8; K. whereas some Member States have already established special bodies to monitor and  assess the influence of AI at the workplace; L. whereas efforts to tackle gender bias and inequality in the digital sector are insufficient;  whereas the gender gap persists across all digital technology domains and especially  with regard to AI, thereby solidifying a male-biased trajectory for the digital sector in  the foreseeable future; 1. Highlights the need to thoroughly assess the opportunities and challenges presented by  AI applications in private and public companies as well as in public administration in  relation to jobs and workers, including their impact on work-life balance, organisation  of work and workflows; considers it indispensable that social dialogue not be bypassed  and workers and their representatives be consulted and receive sufficient information  right from the start of the decision making process; underlines that the deployment of  AI needs to be transparent and that AI systems at the workplace must respect the  privacy and dignity of workers; 2. Points out that a comprehensive risk assessment should come before the development,  deployment and implementation of AI systems, evaluating its impact on fundamental  rights and working conditions, including in terms of occupational health and safety, as  well as its social consequences; assessments should icover risks related to human  decision-making and social discrimination, as well as the evaluation of occupational  risks arising; 3. Points out that AI solutions have the potential to improve working conditions and the  quality of life, including improved work-life balance and better accessibility for people  with disabilities, to predict labour market development and to support human resource  management in preventing human bias, yet they can also raise concerns as regards  privacy and occupational health and safety, such as the right to disconnect, and lead to  disproportionate and illegal surveillance and monitoring of workers, infringing their  dignity and privacy, as well as discriminatory treatment, including in recruitment  processes, due to biased algorithms, including gender or racially and ethnically biased  algorithms9 and algorithms to the detriment of vulnerable groups; is concerned,  furthermore, that AI can undermine the freedom and autonomy of people and contribute  to mental health problems of workers, such as burnout, “techno stress”, psychological  overload and fatigue; stresses that AI solutions in the workplace must be transparent,  fair and avoid any negative implications for the workers; 4. Underlines that competent authorities should have access to all information concerning  the data used for training, statistical models and theoretical principles related to AI  solutions as well as the empirical validity of their outcomes; 5. Considers that AI can help to better utilise the skills and competences of people with  disabilities and that the application of AI in the workplace can contribute to inclusive  8 European Social Partners Framework Agreement on Digitalisation, June 2020 9 European Parliament: “Education and employment of women in science, technology and the digital economy,  including AI and its influence on gender equality”, April 2020.
RR\1215422EN.docx 103/130 PE650.508v02-00 ENlabour markets and higher employment rates for people with disabilities; 6. Stresses that new technological possibilities, such as AI, and the appreciation of work  efficiency must not lead to unequal technologically enhanced capacities, and a  dehumanised digital future; underlines that the ethics of innovation must follow a  humanist approach; 7. Considers that it should be mandatory for users, including workers, and consumers to be  informed when a system uses AI, particularly with regard to personalised products or  services, and to receive meaningful information, in easily understandable and accessible  form, on all ethical aspects of AI applications relevant to them, to take informed  decisions; stresses the importance of understanding how algorithms process and value  data and how this can be limited or stopped; highlights the need for competence  development through training and education for workers and their representatives with  regard to AI in the workplace to better understand the implications of AI solutions; 8. Stresses that applicants and workers must be duly informed in writing when AI is used  in the course of recruitment procedures and other human resource decisions and how in  this case a human review can be requested in order to have an automated decision  reversed; 9. Stresses the need to ensure that productivity gains due to the development and use of AI  and robotics do not only benefit company owners and shareholders, but also profit  companies and the workforce, through better working and employment conditions,  including wages, economic growth and development, and also serve society at large,  especially where such gains come at the expense of jobs; calls on the Member States to  carefully study the potential impact of AI on the labour market and social security  systems and to develop strategies as to how to ensure long-term stability by reforming  taxes and contributions as well as other measures in the event of smaller public  revenues; 10. Underlines the importance of corporate investment in formal and informal training and  life-long learning in order to support the just transition towards the digital economy;  stresses in this context that companies deploying AI have the responsibility of providing  adequate re-skilling and up-skilling for all employees concerned in order for them to  learn how to use digital tools and to work with co-bots and other new technologies,  thereby adapting to changing needs of the labour market and staying in employment; 11. Calls for the application of the precautionary principle with regard to new technologies  based on AI; underlines the fundamental principle that humans must always be in  control of machines and AI and that AI decision making must be accountable and  contestable and where relevant reversible; stresses that safety and security standards for  AI must be respected and highlights the importance of regular checks and controls in  this regard to prevent erroneous AI output; recalls that liability with regard to the use of  AI must be clearly defined, both in the event of occupational accidents and damage  caused to third parties; 12. Underlines that AI has to be human-centric, transparent, safe and secure and must  comply with fundamental rights and applicable laws and regulations, including the  General Data Protection Regulation (GDPR), throughout the system’s entire life cycle,  especially when it is deployed at the workplace; calls for the development of a robust 
PE650.508v02-00 104/130 RR\1215422EN.docx ENcertification system, based on test procedures and guided by the precautionary principle,  which would allow businesses to demonstrate that their AI products comply with  fundamental rights and Union standards; 13. Recalls that the employment and social acquis of the Union fully applies to AI and calls  on the Commission and the Member States to ensure proper enforcement and to address  any potential legislative gaps; notes that the Union can become a global leader in  promoting a socially responsible use of AI; 14. Stresses the importance of a common European approach with regard to the ethical  aspects of AI; underlines, that any regulatory framework in this regard must be adequate  and based on a comprehensive impact assessment in order to avoid hampering future  innovation and job creation; calls in this context for a European regulatory framework  regarding the ethical aspects of AI which is proportionate and has a special focus on the  world of work, including workers’ rights and working conditions; considers that special  attention should be paid to new forms of work, such as gig and platform work, resulting  from the application of new technologies in this context; considers that a legislative  framework that has the aim of regulating telework conditions across the Union and  ensure decent working and employment conditions in the digital economy must likewise  take the impact of AI into account; calls on the Commission to consult with social  partners, AI-developers, researchers and other stakeholders in this regard; 15. Underlines that AI and any related legislation must not in any way affect the exercise of  fundamental rights as recognised in the Member States and at Union level, including the  right or freedom to strike or to take other action covered by the specific industrial  relations systems in Member States, in accordance with national law and/or practice, or  affect the right to negotiate, to conclude and enforce collective agreements, or to take  collective action in accordance with national law and/or practice; 16. Underlines that special attention must be paid to data collected at the workplace with  the help of AI, in particular if it is used for human resources decisions; calls on social  partners at company level to jointly analyse and monitor the deployment of AI; calls on  the Commission and social partners to analyse the need for special provisions on data  protection at the workplace in the context of AI; stresses that workers are the owners of  their data, even after the end of an employment relationship; 17. Considers that the new Skills Agenda for Europe must address the challenges of  adapting and acquiring qualifications and knowledge, in view of the ecological and  digital transition, including ethical aspects of AI; underlines the need to make ethical  aspects of AI and the development of skills for ethical purposes an integral part of any  education and training curricula for developers and people working with AI; recalls that  developers, programmers, decision-makers and companies dealing with AI must be  aware of their ethical responsibility; considers it likewise important to ensure that end  users and consumers are provided with comprehensive information and that there are  regular exchanges between all relevant stakeholders in this regard; 18. Reiterates the importance of education and continuous learning to develop the  qualifications necessary in the digital age and to tackle digital exclusion; calls on the  Member States to invest in high quality, responsive and inclusive education, vocational  training and life-long learning systems as well as re-skilling and up-skilling policies for 
RR\1215422EN.docx 105/130 PE650.508v02-00 ENworkers in sectors that are potentially severely affected by AI; highlights the need to  provide the current and future workforce with the necessary literacy, numeracy and  digital skills as well as competences in science, technology, engineering and  mathematics (STEM) and cross-cutting soft skills, such as critical thinking, creativity  and entrepreneurship; underlines that special attention must be paid to the inclusion of  disadvantaged groups in this regard; 19. Underlines that AI must not reinforce gender inequalities and stereotypes by  transforming analogue biases and prejudices into digital ones through algorithms; 20. Stresses the need to ensure that people from diverse backgrounds, including women,  young people, people of colour and people with disabilities are included in the  development, deployment and use of AI; recalls that AI-based technologies at the  workplace must be accessible for all, based on the design for all principle; 21. Points out that access to AI solutions is closely linked to access to high speed internet  and therefore broadband coverage should be a priority in order to avoid discrimination  and unequal access to these technologies; 22. Notes that the opportunities of AI solutions rely on ‘Big Data’, with a need for a critical  mass of data to train algorithms and refine results; welcomes in this regard the  Commission’s proposal for the creation of a common data space in the Union to  strengthen data exchange and support research in full respect of European data  protection rules.
PE650.508v02-00 106/130 RR\1215422EN.docx ENINFORMATION ON ADOPTION IN COMMITTEE ASKED FOR OPINION Date adopted 7.9.2020 Result of final vote +: –: 0:46 6 1 Members present for the final vote Atidzhe Alieva-Veli, Abir Al-Sahlani, Marc Angel, Dominique Bilde,  Gabriele Bischoff, Vilija Blinkevičiūtė, Andrea Bocskor, Milan Brglez,  Sylvie Brunet, David Casa, Leila Chaibi, Margarita de la Pisa Carrión,  Özlem Demirel, Klára Dobrev, Jarosław Duda, Estrella Durá Ferrandis,  Lucia Ďuriš Nicholsonová, Rosa Estaràs Ferragut, Nicolaus Fest,  Loucas Fourlas, Cindy Franssen, Heléne Fritzon, Elisabetta Gualmini,  France Jamet, Agnes Jongerius, Radan Kanev, Ádám Kósa, Stelios  Kympouropoulos, Katrin Langensiepen, Miriam Lexmann, Elena Lizzi,  Radka Maxová, Kira Marie Peter-Hansen, Dragoș Pîslaru, Manuel  Pizarro, Dennis Radtke, Elżbieta Rafalska, Guido Reil, Daniela  Rondinelli, Mounir Satouri, Monica Semedo, Beata Szydło, Eugen  Tomac, Romana Tomc, Yana Toom, Marie-Pierre Vedrenne, Nikolaj  Villumsen, Marianne Vind, Maria Walsh, Stefania Zambelli, Tomáš  Zdechovský Substitutes present for the final vote Lina Gálvez Muñoz, Eugenia Rodríguez Palop
RR\1215422EN.docx 107/130 PE650.508v02-00 ENFINAL VOTE BY ROLL CALL IN COMMITTEE ASKED FOR OPINION 46 + ECR Lucia Ďuriš Nicholsonová, Elżbieta Rafalska, Beata Szydło, Margarita de la Pisa Carrión GUE/NGL Leila Chaibi, Özlem Demirel, Eugenia Rodríguez Palop, Nikolaj Villumsen NI Daniela Rondinelli PPE Andrea Bocskor, David Casa, Jarosław Duda, Rosa Estaràs Ferragut, Loucas Fourlas, Cindy Franssen, Radan  Kanev, Ádám Kósa, Stelios Kympouropoulos, Miriam Lexmann, Dennis Radtke, Eugen Tomac, Romana  Tomc, Maria Walsh, Tomáš Zdechovský Renew Abir Al-Sahlani, Atidzhe Alieva-Veli, Sylvie Brunet, Dragoș Pîslaru, Monica Semedo, Yana Toom,  Marie-Pierre Vedrenne S&D Marc Angel, Gabriele Bischoff, Vilija Blinkevičiūtė, Milan Brglez, Klára Dobrev, Estrella Durá Ferrandis,  Heléne Fritzon, Lina Gálvez Muñoz, Elisabetta Gualmini, Agnes Jongerius, Manuel Pizarro, Marianne Vind Verts/ALE Katrin Langensiepen, Kira Marie Peter-Hansen, Mounir Satouri 6 ID Dominique Bilde, Nicolaus Fest, France Jamet, Elena Lizzi, Guido Reil, Stefania Zambelli 1 0 Renew Radka Maxová Key to symbols: + : in favour - : against 0 : abstention
PE650.508v02-00 108/130 RR\1215422EN.docx EN16.9.2020 OPINION OF THE COMMITTEE ON THE ENVIRONMENT, PUBLIC HEALTH AND  FOOD SAFETY for the Committee on Legal Affairs with recommendations to the Commission on a framework of ethical aspects of artificial  intelligence, robotics and related technologies (2020/2012(INL)) Rapporteur for opinion: Adam Jarubas (Initiative – Rule 47 of the Rules of Procedure) SUGGESTIONS The Committee on the Environment, Public Health and Food Safety calls on the Committee on  Legal Affairs, as the committee responsible,  – to incorporate the following suggestions into its motion for a resolution: A. Whereas the Union is founded on the values stated in Article 2 of the Treaty on European  Union and in compliance with the precautionary principle stated in Article 191(2) of the  Treaty on the Functioning of the European Union; B. Whereas Article 16 TFEU states that everyone has the right to the protection of their  personal data; whereas Article 22 of the Regulation (EU) 2016/679 of the European  Parliament and of the Council 1refers to the situation where data is only used by  automated processing, and recognises the right of the data subject not to be subject to a  decision based solely on automated processing; C. Whereas the global competition for leadership in the development of artificial  intelligence (AI), which will affect the source of ethical values and standards shaping the  sector worldwide, is picking up pace and the European Union should set an example for  the rest of the world with an appropriate regulatory framework to also prevent a potential  race to the bottom regarding national regulations; D. Whereas this global competition should not be separated from the ethical values and  standards; E.  Whereas rapid advances in research and innovation have raised a number of important  ethical, legal and social issues that affect the relationship between science and society;  1 Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of  natural persons with regard to the processing of personal data and on the free movement of such data, and  repealing Directive 95/46/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1).
RR\1215422EN.docx 109/130 PE650.508v02-00 ENwhereas this research and innovation must comply with ethical principles, and relevant  national, Union and international law, including the Charter of Fundamental Rights of the  European Union and the European Convention for the Protection of Human Rights and  Fundamental Freedoms, according to the provisions of the European Research  Programmes; F. Whereas the integration of big data and AI technologies into public health systems and  other sectors must be accompanied by appropriate rules, standards and legislation that  protect the fundamental rights of individuals and address these new ethical challenges;  G. Whereas there is currently a noticeable gap in terms of patents and investments in the  Union in comparison to other parts of the world; H. Whereas AI and other emerging digital solutions may benefit society in the areas of green  transition, environment and biodiversity protection, increasing the efficiency of  agriculture, waste management, the circular economy, mitigation and adaptation to climate  change, greening of various industrial processes, energy and transport management and  efficiency, water and air quality (e.g. smart grids and electro-mobility), risk management  and earth observation, in which the Union’s Copernicus programme is one of the best,  among others; I. Whereas AI can be applied to almost any field in medicine: biomedical research as,  exemplified by the AI-discovered antibiotic Halicin or AI contributions to cancer  prevention, earlier and more precise diagnosis and new therapies with methods such as  predicative or genomic medicine, medical education, assisting caregivers, supporting  elderly care, monitoring patient conditions, more efficient development of medicines,  more targeted treatment, clinical decision-making, personalised medicine, psychiatric  diagnosis and treatment, in revolutionising robotic prostheses and support systems,  telemedicine, telesurgery and enhancing the overall efficiency and interoperability of the  health systems; J. Whereas digital progress requires appropriate training and preparation for health and  administrative personnel to prevent a digital divide, while bearing in mind our ageing  societies and potential challenges to healthcare systems;  K. Whereas there are serious ethical concerns about the autonomy of machines;  L. Whereas digital health should not dehumanise care and not diminish the doctor-patient  relationship, but should provide doctors with assistance in diagnosing and/or treating  patients more effectively; M. Whereas AI technology will accelerate the digital transformation of industry and play an  essential part in the success of the digital economy in an increasingly connected world;  N. Whereas the current Union legal framework and ethics guidelines have already dealt with  some ethical challenges related to AI applications indicated in the Commission White  Paper on Artificial Intelligence, e.g. risk-assessment processes in place for AI-based health  solutions in the Single Market; whereas other areas are lagging behind ethical challenges  that must be identified and mitigated, since AI has tremendous capacity to threaten patient  preference, safety, and privacy; whereas the boundaries between the roles of medical and  care professionals and machines in patient care need to be outlined, including the principle 
PE650.508v02-00 110/130 RR\1215422EN.docx ENof supervised robot autonomy, whereas education of both healthcare workers and patients  is needed; O. Whereas Union data protection rules should be adapted to take into account the  increasing complexity and interconnectivity of care and medical robots that may handle  highly sensitive personal information and health data and should be consistent with  privacy by design as established by Regulation (EU) 2016/679 on data protection; P. Whereas solutions which stress the need to include scientific research as the basis for  development strategies by creating repositories of medical data (e.g. neurological and  cardiological data) and sharing data from this research can produce tangible social  benefits in the context of public safety and health; Q. Whereas AI solutions may benefit society in the area of food safety, among others by  reducing the use of pesticides, supporting precision farming or more broadly Farming 2.0,  where the Union is among the leaders in AI applications (e.g. for automated machine  adjustments for weather forecasting or disease identification) which will allow more  effective production to be combined with higher environmental standards and better  utilisation of resources, especially in areas where water resources are scarce and climate  change has severe impacts, as it should be in line with the Green Deal priorities; R. Whereas the scope of that framework should be adequate, proportionate and thoroughly  assessed; whereas it should cover a wide range of technologies and their components,  including algorithms, software and data used or produced by AI; whereas a targeted  approach based on the concept of high risk is necessary to avoid hampering future  innovations in delivering the benefits of AI applications e.g. in healthcare, environment  protection and food quality to citizens; S. Whereas it is essential to identify effective means of ensuring trustworthy digital  technologies, making it possible to reap their benefits while protecting fundamental rights  and encouraging the development of informal, open, tolerant and just societies; whereas  this is particularly important in the case of hybrid human/artificial intelligence systems; T. Whereas robotic machines blur the boundaries between human subjects and technological  objects; whereas not only do they have implications for society that need to be ethically  assessed, but they also challenge even the ethical frameworks on the basis of which they  are to be assessed; whereas, as is pointed out in the report by the World Commission on  the Ethics of Scientific Knowledge and Technology (COMEST), particular attention  should be paid to the use of medical robots, nursing robots, care robots for the elderly and  companion robots; U. Whereas the use of social robots and companion robots is spreading rapidly within  healthcare and, in particular, within elderly care; whereas care robots for the elderly and  companion robots may take on a functional and emotional role; whereas those robots may  have a role to play in reducing loneliness among older people, preventing behaviours  associated with dementia, stimulating the cognitive activities of patients with a  neurodegenerative disease or performing particular everyday tasks that are difficult for  elderly persons to carry out; whereas companion robots may thus provoke feelings that  are false, illusory and unreciprocated, deluding and infantilising older people; V. Whereas companion robots may increasingly be used for sexual purposes; whereas the 
RR\1215422EN.docx 111/130 PE650.508v02-00 ENuse of sex robots that look like children or are programmed to be abused has particularly  worrying ethical implications; A legal and ethical framework for AI:  1. Stresses that the Union must undertake all necessary steps to guarantee that its ethical  values, as expressed in the acquis, apply effectively to all AI areas within its territory and  to promote its standards worldwide; emphasises in this regard that technological  developments in AI must always be to the benefit of humankind; 2. Underlines that the Union must undertake all necessary steps to increase the trust of  society in the development and implementation of AI, robotics and related technologies;  in light of the significant impact that these technologies can have on citizens; calls on the  Commission to follow the ethics guidelines on trustworthy AI and propose adequate  measures to make sure that those technologies do not generate unfairly biased outputs for  citizens; 3. Stresses that a law-based Union AI ecosystem of trust, whether regarding environmental  protection, health or food safety applications, extended by the Union AI ethical  framework, will reinforce legal certainty and predictability, encourage stakeholders'  involvement, increase the volume of entrusted data and market up-take, allow for  economies of scale and support an ecosystem of excellence in those sectors; is of the  opinion that this will strengthen the Union AI sector's global competitiveness and the  potential to promote Union values and standards; 4 Notes that, due to the fact that legal regulations respond better to current well-defined  challenges and due to the rapid development of AI resulting in uncertainty as regards  what lies ahead, a common, legally well-anchored, enforceable Union AI ethical  framework will expand an ecosystem of trust for all stakeholders as defined in the  Commission White Paper, in particular in environmental or public health protection, the  creation of healthier environments, better healthcare resources and services or food safety  applications, thus supporting the ecosystem of excellence in legal certainty and  predictability, providing effective response to the challenges not yet defined among  others in courtrooms, management meetings or scientific laboratories;  5. Notes that the definition of AI requires further work; therefore underlines the importance  of a human-centric approach and of regular reviews on AI advances and on the ethical  framework, in order to promote proactive regulation and to guarantee its applicability  through time and new developments; underlines that there are many levels of risk that  evolve over time, through the advancement of AI technologies; stresses the need for a  proportionate legislative framework which should evolve in line with the speed of  technological advancement; points out that the Copernicus programme can serve as a best  practice in developing high quality large datasets as input in AI models; 6. Stresses the need for a regulatory framework stipulating the ethical principles to be  applied to the design, development, implementation and functioning of this technology -  from data access to strict outcome monitoring; 7. Underlines that a balanced approach to regulation must be found, first and foremost  ensuring that our values are not compromised whilst avoiding the creation of unnecessary  administrative burden, especially for SMEs and start-ups; highlights in this regard that 
PE650.508v02-00 112/130 RR\1215422EN.docx ENglobal competition in AI does not always follow the same ethical principles as the Union;  highlights that AI and associated technologies should not be left only to 'light-touch' selfregulation; considers it essential that a proportionate and supportive Union legislative  framework is required; points out that many third countries are working on their ethical  frameworks and that there are multiple proposals at a global level; is aware that the main  difficulty regarding ethical principles may lie in the application of such principles rather  than in their existence; 8. Supports the view that the seven AI requirements identified in the Ethics Guidelines for  Trustworthy AI of the High-Level Expert Group on AI constitute solid building blocks  for a common Union AI ethical framework, with proper legal anchoring, addressing,  among others, ethical aspects of AI applications in environment, health and food  protection; calls for an improvement of the acquis on transparency, traceability and  human oversight, which were indicated as areas in need of further improvement in the  feedback given on the Guidelines by 350 organisations; furthermore, encourages the  creation of the Union AI ethical framework in a spirit of openness to the works of other  international partners that share Union values, e.g. UN, the Council of Europe with its  2019 “Guidelines on Artificial Intelligence and Data Protection”2, European ethical  charter on the use of artificial intelligence in judicial systems and the work of its legal  research centre, the Ad Hoc Committee on Artificial Intelligence (CAHAI), the Principles  on AI3 signed by OECD members in May 2019, the G20 Ministerial Statement of 2019  on Trade and Digital Economy, the annex of which contains the principles for AI, and the  IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems4; 9. Strongly supports the Commission in establishing a common Union AI ethical framework  to counter the shortcomings caused by AI internal market fragmentation, including in  research, innovation and expertise in environmental, public health, healthcare, and food  safety applications, and to prevent AI double standards across Member States for AI  developed in the Union and beyond, inter alia in areas such as consumer data management,  protection and privacy in smart grids, waste management, equal access to services and  technologies, patient-doctor relationship standards, data protection and privacy legislation,  including their interplay with research activities and drug development, civil liability in  AI-assisted public healthcare, civil liability regarding autonomous vehicles or machinery;  notes that on a national level, Member States’ legislation does not contain harmonised  liability rules that are applicable to damage or injury that could result from digital and  behavioural technologies; calls for proper legal anchoring and positioning of such a Union  AI ethical framework; 10. Recalls, in this regard, that the resolution of the European Parliament of 16 February 2017  on Civil Law Rules on Robotics5 asked the Commission to consider the designation of a  European Agency for Artificial Intelligence to ensure among others a harmonised approach  across the Union, to develop common criteria and an application process relating to the  granting of a European certificate of ethical compliance, and to address the new  opportunities and challenges, in particular those of a cross-border nature, arising from  ongoing technological developments; asks the Commission to reflect whether existing  Union bodies and institutions are sufficient for those tasks or a new body for Artificial  2 1https://rm.coe.int/guidelines-on-artificial-intelligence-and-data-protection/168091f9d8 3 2https://legalinstruments.oecd.org/api/print?ids=648⟨=en 4 3https://ethicsinaction.ieee.org 5 OJ C 252, 18.7.2018, p. 239.
RR\1215422EN.docx 113/130 PE650.508v02-00 ENIntelligence needs to be created; 11. Considers that for all AI applications, developed in the Union and outside of it, the same  level of protection must be secured in the Union as is the case with all other technologies,  including effective judicial redress for parties negatively affected by AI systems, whilst  technological innovation needs to be allowed to continue to develop; considers  furthermore that this AI risk area is crucial e.g. for the health services, transport involving  autonomous vehicles and food safety; calls for a clear distribution of obligations, rights  and liabilities among the economic operators involved in AI applications delivery, to  attribute each obligation to the actor(s) who is (are) best placed to address any potential  risks, whether this be the developer, the deployer, the producer, the distributor or  importer, the service provider, or the professional or private user, and in this regard calls  for adequate revision of relevant EU legislation, e.g. of the Product Liability Directive  and for the harmonization of national legislation; supports the Commission position  expressed in the White Paper that, due to the complexity of AI systems, securing an  effective level of protection and redress may require adapting the burden of proof  required by national rules on liability for damage caused by the operation of AI  applications; is of the opinion that clarity as to legal liability in the AI sector will  strengthen enforcement of Union ethical values embodied in its acquis, legal certainty  and predictability, and social acceptance supporting the development of a Union AI  ecosystem of excellence by pooling investors and increasing market uptake; 12. Highlights that many of the proposals by countries which are not members of the Union  and by international organisations revolve around common principles or concepts for AI,  those being: human-centredness, trustworthiness, respect for human autonomy, harm  prevention, equity and "no one left behind" and explainability; is of the opinion that an  international ethical framework around those principles would be highly desirable; is  concerned about AI progress and innovations leading to social inequality if no action is  taken; calls therefore on the Commission and Member States to take the necessary  measures to leave no one behind in the transition to a digital Europe, and to guarantee a  fair, affordable and equal access to these innovations especially in areas such as  healthcare; 13. Recommends supplementing the Risk-Based Approach with an Algorithmic Impact  Assessment drawing information for example from the Regulatory Impact Analysis  (RIA), GDPR Risk Assessment Procedure, Human Rights Impact Assessment (HRIA)  and making the results publicly viewable; 14. Welcomes the fact that the Risk-Based Approach methodology defined in the  Commission White Paper of 19 February 20206 recognises healthcare, transport and  energy as high-risk sectors by default, introducing listed AI requirements beyond existing  Union rules in those sectors, unless the manner in which AI is used does not involve  significant risk; stresses that the Union AI ethical framework should address especially  the above-mentioned high-risk sectors; 15. Calls for clear, objective and transparent procedures at Union level for establishing a  public catalogue of AI high-risk applications involving a periodic review and update  mechanism; calls for consideration of putting the burden of proof in such procedures, for  6 CommissionWhite Paper On Artificial Intelligence - A European approach to excellence and trust,  COM(2020)0065
PE650.508v02-00 114/130 RR\1215422EN.docx ENall AI applications in all domains, on the entity seeking to develop or deploy the AI  system, in order to maintain the catalogue open for innovation and avoid ignoring the risk  of classifying AI applications as being non-high risk; 16. Considers that there are risks of biases and discrimination in the development,  deployment and use of high-risk artificial intelligence, robotics and related technologies,  including the software, algorithms and data used or produced by such technologies;  recalls that, in all circumstances, those technologies should respect human dignity and  ensure equal treatment for all; considers that such possible biases could be addressed by  setting rules on data processing and setting up appropriate safeguards against bias and  discrimination based on social, economic, ethnic, racial, sexual, gender, disability or  other factors; warns of potential misuse of AI diagnostic applications and calls for AI  capability and motivational safeguards; 17 Welcomes the voluntary labelling initiative for non-high risk AI; 18. Recommends measures to encourage the involvement of all AI ethics stakeholders from  the private sector, consumer groups and academia for the formulation of an ethical code  tailored to technological, social and political developments; 19. Points out that, to take decisions, robots use algorithms which play the part of values and  ethical frameworks, and that their introduction has significant ethical implications for  healthcare and social relations; is particularly concerned about the use for paedophilic  and sexual abuse purposes of companion robots; believes that ethical considerations  should be taken into account in the design of robotics technologies; calls, in the  development process for these machines, for a place to be granted to ethics, based on an  approach such as value-sensitive design, particularly with regard to care robots for the  elderly and companion robots; stresses that this approach should also be adjusted to take  account of animal welfare; 20. Underlines that, in addition to clear regulatory requirements on accountability and  liability, there is also a need to ensure algorithmic transparency, so that it is possible to  track the moment when 'things went wrong' and allow for the timely intervention by  experts; considers algorithmic transparency as crucial to prevent situations where medical  decision-making is done in a 'black-box' environment; underlines that black-box  algorithms that make inexplicable decisions are unacceptable in any sector but in a  context where AI decision-making has an impact on life or death decisions, the  consequences of algorithmic failure could be grave; calls on the Commission and  Members States to open dialogue with key stakeholders from the fields of medicine, IT,  mathematics, physics, medical data technology, clinical psychology, bioengineering and  pharmaceutical to establish dialogue-building platforms and assess the impact on the  doctor-patient relationship and the dehumanisation of medical care. 21. Calls for Union guiding initiatives promoting interpretable algorithms, eXplainable AI  (xAI), symbolic reasoning AI, white box AI-testing technics, by showing that those  technologies can be combined with deep neural networks and by showing its legal,  ethical and often business advantages, and also promoting methods to determine risks  connected with different technological options using among others the experience of the  UK’s Information Commissioner's Office (ICO) and The Alan Turing Institute guidelines  “Explaining decisions made with AI”, showing that even highly complex neural AI 
RR\1215422EN.docx 115/130 PE650.508v02-00 ENsystems can be interpreted sufficiently; 22. Calls for transparency, responsibility, auditability, predictability and accountability to be  ensured, as citizens, patients and users should be informed when interacting with a  system using artificial intelligence by clear and understandable explanations of the data  used, of the functioning of the algorithm, of its purpose, of its outcomes, and of its  potential dangers; underlines that transparency and explainability are essential to ensure  trust in these technologies; considers that the explanation should be complemented by  auditability and traceability as respecting such principles is a way of guaranteeing  accountability; points out that AI applications can outperform humans at narrow specific  tasks while failing in overview analysis; calls for human oversight, professional  responsibility and system predictability with ability to override the AI system; 23. Considers that any natural or legal person should be able to seek redress for a decision  issued by high-riskAI, robotics or related technology that is to his or her detriment and  that any decision taken by AI should be subject to strict human verification and due  process; suggests that safeguards related to the use of high-risk artificial intelligence,  robotics and related technologies be introduced within the framework of public power  decisions, including periodic assessment and possible review of the regulatory framework  to keep up with technological development, suggests establishing binding guidelines on  the methodology of the compliance assessment to be followed by the national supervisory  authorities, and establishing non-binding guidelines addressed to the developers, the  deployers and the users; 24. Welcomes a European strategy for data, addressing challenges ahead for the Union in this  area that is key to AI progress, and seeking European opportunities for competitive  advantage in new data economy, especially in the growing sector of decentralised, nonpersonal data coming from industry, business and the public sector and from devices at  the edge of the network, which is expected to constitute 80% of 175 zettabytes in 2025  and reverse current proportions; 25. Calls for sufficient financing to be secured for the Union AI transformation; supports the  ambitions laid out in the Commission White Paper to attract €200 billion of AI public and  private investment in the next 10 years in the Union; welcomes the attention granted to  deficits of AI ecosystems in less-developed regions and to the needs of SMEs and startups; calls on the Commission to identify public infrastructure deficits and facilitate AI  funding in climate change mitigation and adaptation, renewable energies and health and to  facilitate geographically balanced access to all AI funding, including for SMEs and startups; stresses that the new Union objectives must not diminish Union engagement in its  standing priorities, like the CAP, Cohesion Policy, the Green Deal and the Next Generation  EU COVID19 Recovery Plan; 26 Calls on the Commission to promote and fund the development of human-centric  artificial intelligence, robotics and related technologies that address environment and  climate challenges and that ensure equal access to and enjoyment of fundamental rights  through the use of tax, green public procurement, or other incentives; Carbon Footprint of AI: 27. Notes that in the digital package published on 19 February 2020 the Commission states  that ICT today accounts for between 5% and 9% of global electricity consumption and 
PE650.508v02-00 116/130 RR\1215422EN.docx EN2% of CO2 emissions and that the volume of data transferred and stored will continue to  grow exponentially in the years to come and solutions in this regard need to be found;  notes further that the 2018 Joint Research Centre study “Artificial Intelligence/ A  European Perspective” estimates that data centres and data transmission could account for  3 to 4% of all power consumption of the Union; 28. Welcomes the fact that the European digital strategy proposes green transformation  measures for digital sectors; 29. Stresses that despite the current high carbon footprint of deep learning and AI  themselves, those technologies can contribute to the reduction of the current  environmental footprint of the ICT sector and the development of AI, robotics, automated  decisions, machine learning; underlines that those and other properly regulated related  technologies should be critical enablers for attaining the goals of the Green Deal, the UN  Sustainable Development Goals and the Paris Agreement in many different sectors and  should boost the impact of policies delivering environmental protection, e.g. for waste  reduction and environmental degradation; 30. Calls on the Commission to carry out a study on the impact of AI technology’s carbon  footprint and the positive and negative impacts of the transition to the use of AI  technology by consumers; 31. Notes that, given the increasing development of AI applications, which require  computational, storage and energy resources, the environmental impact of AI systems  should be considered throughout their lifecycle; Impact of AI on the health sector and patient rights: 32. Recognises the major role AI can play in health and emphasises that AI applications in  health should always have the aim of maximising the opportunities they can bring, such  as improving the health of individual patients as well as the performance of Member  States’ public health systems, without lowering ethical standards and without threatening  the privacy or safety of citizens;  33. Welcomes the Commission commitment expressed in the White Paper to examine safety  and liability challenges that are distinctive to healthcare, e.g. AI systems providing  specialized medical information to physicians or directly to the patient, AI systems  performing medical tasks themselves directly on a patient; calls for corresponding  examination of the other listed sectors that are by default high-risk ones; 34. Considers that in areas such as health, liability must ultimately lie with a natural or legal  person; emphasises the need for traceable and publicly available training data for  algorithms; 35. Calls on the Commission to initiate an open, transparent sectoral dialogue giving priority  to healthcare in order to then present an action plan to facilitate the development, testing  and introduction of AI in research and innovation and its wide application in public  health services; 36. Warns against attempts to give machines some kind of 'personality', which might result in  the removal of human liability in the event of treatment errors;
RR\1215422EN.docx 117/130 PE650.508v02-00 EN37. Strongly supports the creation of a European Health Data Space7 proposed by the  Commission which aims at promoting health-data exchange and at supporting research in  full respect of data protection, including processing data with AI technology, and which  strengthens and extends the use and re-use of health data; calls for the upscaling of crossborder exchange of health data, their link and use through secure, federated repositories,  specific kinds of health information, such as European Health Records (EHRs), genomic  information, and digital health images to facilitate Union-wide interoperable registers or  databases in areas such as research, science and health sectors; 38. Emphasises that patients should know when and how they are interacting with a human  professional and when they are not; insists that patients should have the freedom to  decide about this interaction and should be offered an alternative of an equal standard; 39. Considers that, particularly in the health sector, mobile applications can help to monitor  diseases and it is useful for robots to be present to support the work of doctors or  healthcare assistants, with a view to improving diagnosis and treatment, while ensuring  that medical practice and patient care practices are not dehumanised; 40. Calls for a Union standardised inter-operability of eHealth applications and the creation  of common European data access for prescriptions, diagnosis and medical reports, simply  accessible for all Union citizens and in all Member States; 41. Reiterates that opportunities and risks inherent to these technologies have a global  dimension that requires a consistent harmonised approach at international level; calls on  the Commission to work in bilateral and multilateral settings to advocate and ensure that  there is ethical compliance; 42. Highlights the benefits of AI for disease prevention, treatment and control, exemplified  by AI predicting the COVID19 epidemic before the WHO; urges the Commission to  adequately equip ECDC with the legal framework and resources for gathering necessary  anonymised real-time global health data independently in conjunction with the Member  States, to among other things address issues revealed by the COVID19 pandemic;  43. Points out that the use of tracking and contact tracing technologies by public authorities  during the COVID 19 pandemic and other potential health emergencies might conflict with  data protection; recalls in this regard the Communication of the Commission of 17 April  2020 on the Guidance on Apps supporting the fight against the COVID 19 pandemic in  relation to data protection8 and the need for proportionality, limitation in time, alignment  with Union values and respect of human dignity and fundamental rights; 44. Considers that AI and robotics can provide considerable improvements in the control of  medical devices and facilitate the everyday work of health professionals; considers that  for critical medical devices, there needs to be a back-up system in place to monitor and  secure the functionality of the device in any possible situation of interference and that  possible cyber threats in the control of such devices need to be taken into consideration  and mitigated; stresses that apart from hackers and outside threats, cyber threats can also  originate from human mistakes or system errors and that it is necessary to have adequate  7 Communication from the Commission to the European Parliament, the Council, the European Economic and  Social Committee and the Committee of the Regions - A European strategy for data, COM(2020)0066 8 OJ C 124I , 17.4.2020, p. 1.
PE650.508v02-00 118/130 RR\1215422EN.docx ENback-up systems in place and operational; considers furthermore that the Union should  create an AI backup development roadmap to address the possible issues of AI system  controls making an error; 45. Points out that the safety standards laid down in the Regulation (EU) 2017/745 of the  European Parliament and of the Council 9 may not be sufficient for the challenges of AI  systems; calls on the Commission to monitor the challenges in this field and to put  forward proposals where necessary; 46. Emphasises the need to ensure that AI-driven medical devices should comply with the  safety and performance requirements of the Regulation (EU) 2017/745; calls on the  Commission and Member States to ensure that the Regulation (EU) 2017/745 is  implemented as regards those technologies; considers new guidelines and specifications  are required for the evaluation of the safety and effectiveness of software, AI and deeplearning powered devices throughout the entire usage cycle; 47. Calls for a clearer legal remit and sufficient financing to be secured for EMA and national  competent authorities responsible for medicines in order to support innovation and public  health aspects related to AI in the medicine lifecycle, in particular to collect and analyse  real world health data that can generate additional evidence on medicinal products to  support R&D and to optimise the safe and effective use of existing medicines in the  interest of patients and of the European healthcare systems; 48. Insists that neither insurance companies nor any other type of service provider should be  authorised to use e-health data to introduce discrimination in the setting of prices, given  that this would run counter to the fundamental right to the highest attainable standard of  health; AI and data protection: 49. Welcomes the Commission’s recently published review10 of Regulation (EU) 2016/679,  notes that Member State legislation follows different approaches when implementing  derogations from the general prohibition for processing special categories of personal  data, as regards the level of specification and safeguards, including for health purposes;  states, therefore, that ultimately, humans should keep the responsibility for decision  making, especially in sectors where there are high stakes and risks such as health; 50. Welcomes the Commission’s intention to monitor the application of the Regulation (EU)  2016/679 to new technologies, including in possible future initiatives in the field of  artificial intelligence and under the Data Strategy, and supports the Commission’s call to  the European Data Protection Board to issue guidelines on the application of the  Regulation (EU) 2016/679 in the area of scientific research, AI, blockchain, and other  possible technological developments; 9 Regulation (EU) 2017/745 of the European Parliament and of the Council of 5 April 2017 on medical devices,  amending Directive 2001/83/EC, Regulation (EC) No 178/2002 and Regulation (EC) No 1223/2009 and  repealing Council Directives 90/385/EEC and 93/42/EEC (OJ L 117 5.5.2017, p. 1) 10 Communication from the Commission to the European Parliament and the Council on Data protection as a  pillar of citizens’ empowerment and the EU’s approach to the digital transition - two years of application of the  General Data Protection Regulation (COM(2020) 264 final)
RR\1215422EN.docx 119/130 PE650.508v02-00 EN51. Calls for citizen and patient empowerment regarding their personal data for securing the  full enforcement and a uniform interpretation of the Union legal framework on data  protection and privacy, especially in healthcare AI applications and other related sensitive  data, to fully respect the “Right to be forgotten” provided for in Article 17 Regulation  (EU) 2016/679 and to strengthen the “Right to an explanation” provided for in Article 22  Regulation (EU) 2016/679and higher interpretability requirements for high-risk AI;  52. Emphasises that the ethical framework on AI should include the right to obtain an  explanation of a decision based on automated processing for persons that are the subject  of such decisions; 53. Calls for the right balance to be struck between privacy and data protection and data  utility; considers that it is important for scientific advancement to ensure that it is  possible to share and process health data in sufficient depth and detail; calls for data  anonymization to be ensured while avoiding excessive data minimization; calls for  interoperable, suitable databases, registers and repositories at Union level to facilitate the  use of health data in health, environment and food safety sectors; 54. Underlines the need to ensure that health data and data belonging to vulnerable groups  are protected and points out that, to the extent that AI applications process health data on  the basis of the data subject's consent, the conditions laid down in Article 7 Regulation  (EU) 2016/679 have to be met;  55. Stresses that by no means, should the data generated contribute to any kind of  discrimination; calls for guarantees that data collection and accessibility is always in line  with the legal framework of the Union;  56. Points out that the risk of malicious data alterations and manipulation, and of possible  hacking or data theft, can be particularly severe in the health sector and can be used to  harm, discredit or profit from individuals; stresses that the highest cybersecurity  standards should be established for the relevant networks; AI impact on labour and social settings: 57. Points out that the OECD's ethical framework takes account of labour market upheaval;  stresses that automation combined with AI will increase productivity and therefore  increase output; points out that, as during previous technological revolutions, some jobs  will be replaced; stresses that increased use of robotics and AI should also reduce human  exposure to harmful and hazardous conditions and should also help to create more quality  and decent jobs and improve productivity; points to the work of the OECD, which  stresses that automation may give society the option to cut the number of hours worked,  thus improving workers' living conditions and health; 58. Draws further attention to the OECD recommendations calling for governments to work  closely with stakeholders to promote the responsible use of AI at work, to enhance the  safety of workers and the quality of jobs, and to aim to ensure that the benefits of AI are  broadly and fairly shared; underlines in this context that diverse teams of developers and  engineers working alongside key actors can contribute to avoiding gender and cultural  bias and ensuring that workers’ physical and mental well-being are respected in AI  algorithms, systems and applications; 
PE650.508v02-00 120/130 RR\1215422EN.docx EN59. Stresses that the development of AI applications might bring down the costs and increase  the volume of services available, e.g. health services, public transport, Farming 2.0,  making them more affordable to a wider spectrum of society; stresses that AI applications  may also result in the rise of unemployment, pressure on social care systems, and an  increase of poverty; emphasises, in accordance with the values enshrined in Article 3 of  the Treaty on European Union, the need to adapt Union AI transformation to socioeconomic capacities, adequate social shielding, education and creation of alternative jobs;  calls for the establishment of a Union AI Adjustment Fund building upon the experience  of The European Globalisation Adjustment Fund (EGF) or the currently developed Just  Transition Fund to be considered; 60. Stresses also the importance of social dialogue to accommodate a fair and inclusive  transition for workers to new work realities affected by AI and the need for companies to  invest in training and re-skilling of their workforce; 61. Calls for the Member States to align education for environment protection, health and  food safety professionals to developments in AI, and to raise awareness of the risks and  ethical challenges associated with AI;  62. Welcomes requirements proposed in the White Paper for high-risk AI training data,  addressing as well safety – sufficiently broad data to cover all relevant scenarios in order  to avoid dangerous situations as discrimination - sufficiently representative data to reflect  well the social environment it will be applied to; 63. Stresses that the public sector should focus on solving social problems rather than  generating AI uptake for its own sake; calls for the improvement of the public  procurement regulations and guidelines of the Union, including Green Public  Procurement of the European Union, so that during relevant evaluation procedures for  tender offers, one takes into account whether a given issue requires an AI system  application, and allows an alternative delivery path to be followed in cases where the  evaluation indicates that such a non-AI solution addresses the social problem better;
RR\1215422EN.docx 121/130 PE650.508v02-00 ENINFORMATION ON ADOPTION IN COMMITTEE ASKED FOR OPINION Date adopted 10.9.2020 Result of final vote +: –: 0:77 2 2 Members present for the final vote Nikos Androulakis, Bartosz Arłukowicz, Margrete Auken, Simona  Baldassarre, Marek Paweł Balt, Traian Băsescu, Aurelia Beigneux,  Monika Beňová, Sergio Berlato, Alexander Bernhuber, Malin Björk,  Simona Bonafè, Delara Burkhardt, Pascal Canfin, Sara Cerdas,  Mohammed Chahim, Tudor Ciuhodaru, Nathalie Colin-Oesterlé,  Miriam Dalli, Esther de Lange, Christian Doleschal, Marco Dreosto,  Bas Eickhout, Eleonora Evi, Agnès Evren, Fredrick Federley, Pietro  Fiocchi, Andreas Glück, Catherine Griset, Jytte Guteland, Teuvo  Hakkarainen, Martin Hojsík, Pär Holmgren, Jan Huitema, Yannick  Jadot, Adam Jarubas, Petros Kokkalis, Athanasios Konstantinou, Ewa  Kopacz, Joanna Kopcińska, Ryszard Antoni Legutko, Peter Liese,  Sylvia Limmer, Javi López, César Luena, Fulvio Martusciello, Liudas  Mažylis, Joëlle Mélin, Tilly Metz, Silvia Modig, Dolors Montserrat,  Alessandra Moretti, Dan-Ștefan Motreanu, Ville Niinistö, Ljudmila  Novak, Jutta Paulus, Stanislav Polčák, Jessica Polfjärd, Luisa  Regimenti, Frédérique Ries, María Soraya Rodríguez Ramos, Sándor  Rónai, Rob Rooken, Silvia Sardone, Christine Schneider, Günther Sidl,  Ivan Vilibor Sinčić, Linea Søgaard-Lidell, Nicolae Ştefănuță, Nils  Torvalds, Edina Tóth, Véronique Trillet-Lenoir, Alexandr Vondra,  Mick Wallace, Pernille Weiss, Michal Wiezik, Tiemo Wölken, Anna  Zalewska Substitutes present for the final vote Michael Bloss, Manuel Bompard, Christel Schaldemose
PE650.508v02-00 122/130 RR\1215422EN.docx ENFINAL VOTE BY ROLL CALL IN COMMITTEE ASKED FOR OPINION 77 + #PPE# Bartosz Arłukowicz, Alexander Bernhuber, Traian Băsescu, Nathalie Colin-Oesterlé, Christian Doleschal,  Agnès Evren, Adam Jarubas, Ewa Kopacz, Peter Liese, Fulvio Martusciello, Liudas Mažylis, Dolors  Montserrat, Dan-Ștefan Motreanu, Ljudmila Novak, Jessica Polfjärd, Stanislav Polčák, Christine Schneider,  Edina Tóth, Pernille Weiss, Michal Wiezik, Esther de Lange S&D Nikos Androulakis, Marek Paweł Balt, Monika Beňová, Simona Bonafè, Delara Burkhardt, Sara Cerdas,  Mohammed Chahim, Tudor Ciuhodaru, Miriam Dalli, Jytte Guteland, César Luena, Javi López, Alessandra  Moretti, Sándor Rónai, Christel Schaldemose, Günther Sidl, Tiemo Wölken Renew Pascal Canfin, Fredrick Federley, Andreas Glück, Martin Hojsík, Jan Huitema, Frédérique Ries, María Soraya  Rodríguez Ramos, Linea Søgaard-Lidell, Nils Torvalds, Véronique Trillet-Lenoir, Nicolae Ştefănuță ID Simona Baldassarre, Aurelia Beigneux, Marco Dreosto, Catherine Griset, Joëlle Mélin, Luisa Regimenti,  Silvia Sardone Verts/ALE Margrete Auken, Michael Bloss, Bas Eickhout, Pär Holmgren, Yannick Jadot, Tilly Metz, Ville Niinistö, Jutta  Paulus ECR Sergio Berlato, Pietro Fiocchi, Joanna Kopcińska, Ryszard Antoni Legutko, Alexandr Vondra, Anna  Zalewska GUE/NGL Malin Björk, Manuel Bompard, Petros Kokkalis, Silvia Modig, Mick Wallace NI Eleonora Evi, Athanasios Konstantinou 2 ID Sylvia Limmer ECR Rob Rooken 2 0 ID Teuvo Hakkarainen NI Ivan Vilibor Sinčić Key to symbols: + : in favour - : against 0 : abstention
RR\1215422EN.docx 123/130 PE650.508v02-00 EN3.9.2020 OPINION OF THE COMMITTEE ON CULTURE AND EDUCATION for the Committee on Legal Affairs with recommendations to the Commission on framework of ethical aspects of artificial  intelligence, robotics and related technologies (2020/2012(INL)) Rapporteur for opinion: Łukasz Kohut (Initiative – Rule 47 of the Rules of Procedure) SUGGESTIONS The Committee on Culture and Education calls on the Committee on Legal Affairs, as the  committee responsible: - to incorporate the following suggestions into its motion for a resolution: 1. Recalls that the development, the deployment and the use of artificial intelligence (AI)  in the cultural and creative sectors, and in the areas of education, media, youth, and  information policy, not only has the potential to raise but also raises and will continue to  raise a wide range of ethical issues that need to be addressed; stresses that the Union  should lead the way towards ethical AI anchored in Union values, ensuring the  protection of human dignity, and fundamental rights within a democratic, fair and  sustainable Union; calls on the EU institutions to engage in long-term thinking about the  impact of AI on our democratic debates, our societies and on the very nature of human  beings, in order to be able to pave the way for AI technology that respects our freedom  and does not disrupt innovation or curtail freedom of expression; 2. Strongly believes that there is a need to examine how human rights frameworks and  obligations can guide actions and policies relating to new and emerging digital  technologies to guarantee their anthropocentric approach and the accessibility of their  benefits to all; recognises the need to ensure that the development, the deployment and  the use of AI is free of discrimination, profiling bias and that it mirrors all essential  elements of society; recognises that AI and automation might have an effect on the  globalised economy which might entrench existing inequalities; 3. Stresses the need to develop tailor-made criteria for the development, the deployment  and the use of AI in education, media, youth, research, and the cultural and creative  sectors, by developing benchmarks for and defining principles of ethically responsible  and accepted uses of AI technologies in these areas, including a clear liability regime 
PE650.508v02-00 124/130 RR\1215422EN.docx ENfor products resulting from AI use; underlines that such criteria must be adaptable and  constantly adjusted to the progress in AI technologies so as to also responsibly help  harness the full potential of AI; highlights in particular the need to address personal user  data collection and privacy concerns as well as liability issues in cases where automated  processes lead to undesirable outcomes; recalls that, to provide for such criteria with a  sound basis, it is necessary to require that the principles of conformity of a system with  its specifications, transparency, good faith and equity be observed, in consultation with  the competent ethics committees responsible for helping to lay the groundwork in line  with European Union cultural values and legal framework provisions; notes that AI  systems are software-based displaying intelligent behaviour based on the analysis of  their environment; stresses that this analysis is based on statistical models of which  errors form an inevitable part; underlines the need to ensure that systems and methods  are in place to allow verification of the algorithm, explainability of the algorithm and  access to remedies; highlights the need to ensure that there are binding rules ensuring  that principles of transparency, accountability and non-discrimination are preserved;  reiterates the 2019 Ethics Guidelines for Trustworthy AI and the seven key  requirements for trustworthiness of AI; 4. Notes that every child enjoys the right to public quality education at all levels; therefore,  calls for the development, the deployment and the use of quality AI systems that  facilitate and provide quality educational tools for all at all levels and stresses that the  deployment of new AI systems in schools should not lead to a wider digital gap being  created in society; 5. Notices that AI personalised learning systems are increasingly being deployed in  schools and universities, which is gradually changing the role of teachers in the learning  process; stresses that this shift should be assessed thoroughly, reflected in curricula  accordingly and be anchored by human-centric values; recognises the enormous  potential contribution that AI and robotics can make to education; notes that AI  personalised learning systems should not replace educational relationships involving  teachers and that traditional forms of education should not be left behind, while at the  same time pointing out that financial, technological and educational support, including  specialised training in information and communications technology must be provided  for teachers seeking to acquire appropriate skills so as to adapt to technological changes  and not only harness the potential of AI but also understand its limitations; 6. Stresses that where machine learning is used in the procedures for selection of potential  students, adequate safeguards must be implemented, including informing applicants of  such procedures and their rights in this regard; notes that the relevant algorithms need to  be trained on broad data sets in order to prevent the algorithms from unfairly  discriminating against certain groups; is of the view that the relevant decisions taken  with the help of automated processes need to be explainable, including, if necessary, to  the rejected students; 7. Calls for an AI, robotics and related technologies strategy to be developed at Union  level in order to help transform and update our educational systems, prepare our  educational institutions at all levels and equip teachers and pupils with the necessary  skills and abilities; considers that there is a necessity for a framework on ethics in  education ; recommends the involvement of civil society, universities, trade unions and  employers associations in the process of drafting such a framework ; notes that AI 
RR\1215422EN.docx 125/130 PE650.508v02-00 ENsystems developed, deployed and used in the Union need to reflect its cultural diversity  and its multilingualism; stresses that special support that should be given to tech  developers and beneficiaries from disadvantaged groups and persons with disabilities; 8. Considers that special attention and protection must be given to upholding the rights of  minors, given the particular influence of education on their future, specifically the right  to privacy and access to quality education, ensuring equal opportunities in every case;  emphasises that educational institutions should only use AI systems for educational  purposes that have been audited and certified as ethical, beneficial and acting  consistently with human rights principles; calls on the Commission and the Member  States to promote cooperation between the public and private sectors and academia in  order to reinforce knowledge-sharing and open sources; 9. Notes that there is a need to clarify the concept of arts and cultural and creative works,  as well as the role of humans as creators and artists; emphasises that opportunities  provided by digitisation and new technologies must not lead to an overall loss of jobs in  the cultural and creative sectors, to neglect the conservation of originals and to  downplay traditional access to cultural heritage, which should equally be encouraged; 10. Acknowledges the growing potential of AI in the areas of information, media and online  platforms, including as a powerful tool to fight disinformation; is concerned, however,  about the potential for AI to be misused in order to manipulate public opinion online;  underlines that, if not regulated, it might also have ethically adverse effects by  exploiting bias in data and algorithms that may lead to disseminating disinformation,  creating information bubbles and exploiting biases incorporated into AI algorithms;  recalls that adequate education is a necessary condition to safeguard citizens’ rights  with regard to the freedom of information, opinion and expression, calls for the ethical  use of AI technologies in the field of media; warns about the risks of technology-driven  censorship and the need for an ethical framework to protect the freedom of speech; 11. Considers that the use of certain types of AI, such as facial recognition, emotion and  behaviour detection systems, might have a damaging effect, notably on the role of  media and journalists as watchdogs of democracy and thus on democratic processes;  underlines therefore, that the use of those systems in public spaces should be restricted  or banned whenever necessary; emphasises the need to continue the fight against fake  news, including techniques such as "deepfakes", against censorship and automated  surveillance; 12. Emphasises the need to raise awareness and understanding in the general public about  the role and impact of AI through formal and non-formal education, including humanity  studies, notably about the use of algorithms and their impact, inter alia, on jobs and  privacy, the understanding of the place occupied by IT systems in selecting,  interpreting, storing and representing data; advocates the establishment of digital  literacy tools at all levels of education and thus calls on the Member States and on the  EU institutions to invest in information and media literacy, education and training;  considers that information and media competences are crucial for all citizens, including  the vulnerable social groups, to be able to critically assess and understand new  developments including an understanding of the functioning of AI and its inherent  biases and thus, to develop new forms of critical thinking; recommends that the  Commission promote AI-, robotics- and technology-related formats of education and 
PE650.508v02-00 126/130 RR\1215422EN.docx ENcontinuous education; 13. Notes the important distinction between transparency of algorithms and transparency of  the use of algorithms; emphasises the importance of transparency and accountability of  algorithms used by video-sharing platforms (VSP) as well as streaming platforms, in  order to ensure access to culturally and linguistically diverse content and avoid  privileging; believes that every user should be properly informed when an algorithm is  used to recommend content, and should be able to optimise them according to his or her  choices, and such algorithms should not restrict a user’s choice; considers that any user  should also be able to disable content recommendation by AI; stresses that such  algorithms should be designed in such a way that they reflect the cultural diversity of  our societies ensuring genuine cultural openness and guaranteeing freedom of creation;  insists that user data collected by AI, such as cultural preferences or educational  performance, must not be transmitted or used without the owner's knowledge; 14. Notes that sport has always embraced technological innovation; considers, nevertheless,  that the use of AI technologies, which is spreading rapidly into sports competitions, is  increasingly raising questions of fair competition in sport whereby those teams with the  most financial resources can acquire the best technology, thus potentially giving them  an unfair advantage; emphasises that these developments have to be closely monitored  and stresses that this area needs a regulatory framework which applies ethical and  human-centric criteria in the development and use of AI technologies; calls for full  transparency on the algorithms and technologies used in sports in order to level the  playing field.
RR\1215422EN.docx 127/130 PE650.508v02-00 ENINFORMATION ON ADOPTION IN COMMITTEE ASKED FOR OPINION Date adopted 31.8.2020 Result of final vote +: –: 0:28 0 2 Members present for the final vote Isabella Adinolfi, Christine Anderson, Ilana Cicurel, Gilbert Collard,  Gianantonio Da Re, Laurence Farreng, Tomasz Frankowski, Romeo  Franz, Hannes Heide, Irena Joveva, Petra Kammerevert, Niyazi  Kizilyürek, Predrag Fred Matić, Dace Melbārde, Victor Negrescu, Peter  Pollák, Marcos Ros Sempere, Andrey Slabakov, Massimiliano  Smeriglio, Michaela Šojdrová, Sabine Verheyen, Salima Yenbou, Milan  Zver Substitutes present for the final vote Isabel Benjumea Benjumea, Christian Ehler, Ibán García Del Blanco,  Bernard Guetta, Marcel Kolaja, Elżbieta Kruk, Martina Michels
PE650.508v02-00 128/130 RR\1215422EN.docx ENFINAL VOTE BY ROLL CALL IN COMMITTEE ASKED FOR OPINION 28 + PPE Isabel Benjumea Benjumea, Christian Ehler, Tomasz Frankowski, Peter  Pollák, Michaela Šojdrová, Sabine Verheyen, Milan Zver S&D Ibán García del Blanco, Hannes Heide, Petra Kammerevert, Predrag Fred  Matić, Victor Negrescu, Marcos Ros Sempere, Massimiliano Smeriglio RENEW Ilana Cicurel, Laurence Farreng, Bernard Guetta, Irena Joveva ID Gilbert Collard VERTS/ALE Romeo Franz, Marcel Kolaja, Salima Yenbou ECR Elżbieta Kruk, Dace Melbārde, Andrey Slabakov GUE/NGL Niyazi Kizilyürek, Martina Michels NI Isabella Adinolfi 0 - 2 0 ID Christine Anderson, Gianantonio Da Re Key to symbols: + : in favour - : against 0 : abstention
RR\1215422EN.docx 129/130 PE650.508v02-00 ENINFORMATION ON ADOPTION IN COMMITTEE RESPONSIBLE Date adopted 1.10.2020 Result of final vote +: –: 0:20 0 4 Members present for the final vote Manon Aubry, Gunnar Beck, Geoffroy Didier, Angel Dzhambazki, Ibán  García Del Blanco, Jean-Paul Garraud, Esteban González Pons, Mislav  Kolakušić, Gilles Lebreton, Karen Melchior, Jiří Pospíšil, Franco  Roberti, Marcos Ros Sempere, Liesje Schreinemacher, Stéphane  Séjourné, Raffaele Stancanelli, József Szájer, Marie Toussaint, Adrián  Vázquez Lázara, Axel Voss, Tiemo Wölken, Javier Zarzalejos Substitutes present for the final vote Patrick Breyer, Evelyne Gebhardt
PE650.508v02-00 130/130 RR\1215422EN.docx ENFINAL VOTE BY ROLL CALL IN COMMITTEE RESPONSIBLE 20 + EPP Geoffroy Didier, Esteban González Pons, Jiří Pospíšil, József Szájer, Axel Voss, Javier Zarzalejos S&D Ibán García Del Blanco, Evelyne Gebhardt, Franco Roberti, Marcos Ros Sempere, Tiemo Wölken RENEW Karen Melchior, Liesje Schreinemacher, Stéphane Séjourné, Adrián Vázquez Lázara VERTS/ALE Patrick Breyer, Marie Toussaint ECR Angel Dzhambazki, Raffaele Stancanelli NI Mislav Kolakušić 0 4 0 ID Gunnar Beck, Jean Paul Garraud, Gilles Lebreton GUE/NGL Manon Aubry Key to symbols: + : in favour - : against 0 : abstention
