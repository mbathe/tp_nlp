1  1  1 The Road to a Human-Centred Digital SocietyAiTH THE ROAD TO A  HUMAN-CENTRED  DIGITAL SOCIETYA  MANIFESTO Opportunities, Challenges and  Responsibilities for Humans in the Age of  MachinesCentre on AI Technology for Hummankind,  NUS Business School
 2 The Road to a Human-Centred Digital SocietyAITH CORE TEAM David De Cremer Devesh Narayanan Andreas Deppeler Mahak Nagpal Jack McGuire Jess ZhangCONTENTS * OVERVIEW                                                                 3 * CONTEXT                                                                    4 * REPEATING HISTORY?                                              6   * A MANIFESTO                                                            8              FOR RESPONSIBLE AND HUMAN-CENTRED AI  * IMPLICATION & RECOMMENDATIONS  9 * JOIN US                                                                     12 
 3 The Road to a Human-Centred Digital SocietyOVERVIEW The growing adoption of intelligent technologies has brought  us to a crossroad. The creators of intelligent technologies are  acquiring the power to influence a wide variety of outcomes  that are important to human end-users. In doing so, those same  intelligent technologies are being used to undermine and even  actively harm the interests of those same end-users. In the  absence of a recalibration, we are almost certainly headed down  a path wherein intelligent technologies will primarily serve the  interests of developers and owners of technology rather than  humankind at large. In an attempt to push for such a recalibra tion, we present parallels between the 2008 financial crisis and  the current state of affairs. Following which, we present a list  of recommendations and implications to be used when in the  pursuit of creating responsible and human-centred AI.
 4 The Road to a Human-Centred Digital SocietyIntelligent  technologies are dramatically trans forming modern societies. The potential eco nomic and social benefits of these technologies  seem unprecedented. Intelligent technologies  are therefore increasingly being involved in a  variety of decision-making contexts: to support,  advise and sometimes even override human  decision-makers. As a result, as organizations  undergo digital transformations, such tech nologies are increasingly used to influence a  wide variety of outcomes that are important to  human end-users. But of course, with greater  power also comes greater responsibility. As  such, it is no surprise that a strong need is  emerging for greater scrutiny about the extent  to which humans are vulnerable to the actions  and decisions of intelligent technologies.   These vulnerabilities materialize in various  ways. For example, intelligent technologies can  undermine or sometimes even actively harm  the interests of their human end-users, leading  to unfavourable or unethical outcomes. Quanti fication and datafication are crucial to the func tioning of AI but may be perceived by users as  depersonalizing and reductionist. More gener ally, as intelligent technologies become part of  our lives, the risks to the stability of our social  fabric and the sanctity of our human autonomy  are becoming increasingly apparent. Growing  concerns about these risks and harms threaten  to undermine many of the benefits that these  technologies could create.  As the Centre on AI Technology for Humankind   (AiTH) director David De Cremer has previously  noted, technology will and can definitely be  used for good. However, current investments  in intelligent technologies and automation are  largely driven by cost-cutting motives: lured by the prospects of growth without having to raise  salaries or hire more people. If these cost-cut ting efforts are not combined with investments  in what we call “human upskilling” – where the  abilities, actions and interests of humans are  cultivated and refined with the support and  assistance of technology – then we fear that  the harms and vulnerabilities listed earlier will  surely materialize. The obsessive search for  technological solutions striving to optimize ef ficiency and maximize productivity will prioritize  investments in innovations that primarily serve  the interests of those designing and distributing  intelligent technologies. Following such a path  will lead to building a technologically-regulated  society that serves the interests of machines  and their developers, rather than humankind at  large.  Even more so, such a society would be drasti cally different from the one imagined in the  past. For example, the British economist John  Maynard Keynes predicted almost a century  ago that technical innovation would improve  labour productivity and overall wealth to such  an extent that working three hours a day would  be “quite enough.” Today, however, people are  working more than ever (further exacerbated by  the COVID-19 pandemic, which made working  from home the new default), salaries in many  professions and regions have been stagnant (in  real terms) since the 1980s, and pension funds  are under threat everywhere – forcing people  to work longer than before. At the same time,  the wealth created by the increasing use of  technology is accumulating in the coffers of a  few large and powerful technology companies  —and in the private accounts of the largest  shareholders. Take, for example, the message of  Jeff Bezos after he took a short trip to “space” CONTEXT
 5 The Road to a Human-Centred Digital Societyin his Blue Origin spacecraft. Upon his return to  earth, he thanked the Amazon employees and  customers, because they paid for his trip. Not  surprisingly, people could not appreciate his  message.  Big Tech companies employ a certain strateg y  accompanied by a specific narrative. This is  the narrative of “techno-solutionism” – that  technology can be used to solve most problems  that we encounter in society and business.  This typical Silicon Valley mindset and narrative  has permeated governments and businesses,  entrenching beliefs that social problems can be  ‘solved’ if one has the right technology. Indeed,  because of this techno-solutionist mindset, we  have come to see most societal problems and  challenges as ones that can easily be optimized  by modifying the properties of a machinelearning algorithm. Take, for example, Google’s  recent announcement of “ethics-as-a-service”,  which conveys to business leaders the idea that  if algorithmically-made decisions are unfair or  biased, this can be ‘fixed’ with certain technical  tweaks to those same algorithms and datasets.  As another example, call-centres have been  recently emphasizing that their employees need  to be trained to act in more empathic ways to  their customers. Tech start-ups, in turn, have  offered a solution: to use algorithms, that have  been trained to imitate and recognize empathy,  to coach the call-centre employees to be more  empathetic. This is a strange logic: this problem  only exists because the call centre model in centivizes workers to be less empathetic, whilst  incentivizing mechanical, output-oriented  behaviours. In other words, this problem only  exists because of the inefficiencies and valuemisalignments embedded in the technology,  but the solution offered to address it is once  again technological.  What do the above examples illustrate? To  us, they show how intelligent technologies –  and the companies that design and develop them – have acquired a position of power that  apparently goes unchallenged. Technology is  the only way forward, and if its use reveals  problems, the solution involves more technol ogy. It sounds like a path is being paved for a  world that is more suited for machines than for  humans.  At AiTH, we are deeply concerned about these  seemingly “machine-centred” approaches to  the design and deployment of AI. The adoption  of reductionist perspectives – where finding  the right incentives and rewards is deemed  sufficient to optimize for the behaviours and  decisions we want to see – is a profound threat  to our humanity. Machine-centred approaches  threaten to box in our complex, authentic social  lives, in their bid to reduce humans to quantifi able and predictable data objects. In contrast,  a human-centred approach to developing and  deploying intelligent technologies appreciates  the complexities and grey zones where human  judgments and intuition will always be needed,  and strives to harness the potential of AI to  serve the needs of, and create benefits for,  humans. 
 6 The Road to a Human-Centred Digital SocietyREPEATING HISTORY? INTELLIGENT TECHNOLOGIES ARE POPULARLY CONSTRUED AS A POWERFUL  EXOGENOUS FORCE – SWEEPING IN TO DISRUPT OUR SOCIAL AND WORK  LIVES AT A RATE THAT MOST HUMANS CANNOT KEEP PACE WITH.   As AiTH director David De Cremer has previously noted, the magical thinking sur rounding AI has caused many businesspeople to worry about finding a place for hu mans in a world run by computers, rather than the other way around. Such thinking,  and the fear of humans being “left behind”, threaten to fragment our social fabric.  Perceived divides – between organizations that are “AI leaders” and those that are  “AI laggards”, between those whose jobs will be “disrupted” and those whose jobs  are “safe”, and between “technophiles” and “luddites”, to name a few – can produce  widespread social anxiety and dissatisfaction among those who feel left out of the  technological future we seem to be hurtling towards.   Continuing on a path of accelerating technological developments without reflection  and critical analysis based on a human-centred perspective will, in our view, lead to  a new economic and social crisis. This upcoming ‘tech crisis’ would draw upon and  reinforce the various social anxieties and fears about intelligent technologies that  we are already starting to see. However, like all previous crises in recent history, its  causes and effects on society and the economy are likely to be much broader. In deed, we believe that there are useful and productive parallels to be drawn between  the potential tech crisis to come and the global financial crisis of 2007-2008. For one, the mindsets shared in the corporate world seem to be surprisingly similar  between then and now. The promotion of calculative and hyper-competitive thinking  and a ‘ticking-the-box’ mentality seem to be characteristic of contemporary techno scientific thinking where reducing everything (including humans; cf. people analytics)  to measurable and predictable data-points is omnipresent. These same practices and  mindsets were also dominant in the wake of the global financial crisis. Indeed, al though financial engineering, and overconfidence in mathematical models and quan titative risk management were not the proximate cause of the global financial crisis,  they provided a false sense of security. Mortgage origination and trading desks at  major investment banks relied on quantitative models and ever more complex finan cial engineering to manage the risks of their holdings. It gave the impression – to se nior management, regulators, investors, rating agencies and the general public – that  risk could be quantified and controlled. An overreliance on models, quantification  and rationalization clouded people’s judgments and prevented them from recogniz ing the looming dangers until it was too late. We have since learned that calculative  and hypercompetitive thinking drives unethical behaviour and the tendency to justify  ambiguous ethical decisions, so it is especially worrying to notice the ascendancy of  such thinking again in today’s tech-dominated corporate world.  
 7 The Road to a Human-Centred Digital Society REPEATING HISTORY? (CONTINUED) Further, in the wake of the global financial crisis, banks were seen as “too big to fail” be cause they own and run most of the financial infrastructure that is essential to the func tioning of the globalized economy. Similar beliefs seem to be held about tech companies  today. A handful of tech companies provide and maintain the digital cloud infrastructure  that supports much of the world’s private and public sector activities. They are, so to  speak, too essential to the modern digital economy to fail. Of course, we now know that  such ways of thinking lull us into a false sense of certainty which leads to complacency.  These institutions are glued together by long, and ultimately fragile chains of trust. When  people – and, in particular, veto players such as powerful monied interests and govern ments – lose trust, the whole system collapses. We believe that such a collapse of trust in  the tech-dominated corporate world is be possible.   The belief in technocratic solutions is part of a broader ideology of instrumental rational ity. We saw it in the early 2000s when banks relied on oversimplified models to manage  complex structured financial products. We have seen it since the crash when central bank ers devised ever more creative ways to engage in what essentially amounts to printing  money. Today we see it in pronouncements of technology firms about ethical and respon sible artificial intelligence. It is the unquestioning belief in the inevitability of technical  progress, along with the assumption that any potential threats or harms arising from such  never-ending progress can be “managed” or “mitigated” with ever more technical solutions.  The result is an epistemic bubble that enwraps all public discourse. Piercing the bubble re quires humility, clarity of mind and a historical perspective. Unfortunately, these traits are  all too rare among today’s leaders in governments and corporations and for that reason  poses a threat to how we design and implement regulatory and policy instruments. Indeed, one final analogue that we observe is the one encapsulating the relationship be tween the corporate world and regulators. The business world, both in the past and today,  looks to regulators as suppliers of norms. Regulators, on the other hand, are often unwill ing or unable to enforce strict regulations on businesses – usually citing concerns about  the adverse effects of blunt regulation on productivity and competitiveness.  Instead, a  culture of self-regulation is emphasized. Companies are the ones who are supposed to en sure that their actions are ethical, while regulators may, at best, provide some frameworks  and guidance to help with this self-regulation. We know now that such self-regulation  was insufficient to stop the devastation of the global financial crisis. Despite this, we see  it being pursued once again in the tech industry. The past few years have seen numerous  frameworks, principles and policy documents, but little in the way of actually enforceable  regulation. High-level ethical standards prove difficult to translate into actual behavioural  actions. We do have doubts that such frameworks will serve any meaningful role in stop ping the impending tech crisis.  
 8 The Road to a Human-Centred Digital SocietyA MANIFESTO  FOR  RESPONSIBLE  AND HUMANCENTRED AI  12,2021 Competence: HCAI augments and enriches  human capabilities and per formance across all domains  in life, rather than automating  away the skills and attributes  that make us human. Belonging:    HCAI designs AI systems with  the understanding that intel ligent technologies are fully  embedded in society. Such  systems can therefore be ex pected to act in line with the  norms and values of a humane  society, including fairness,  justice, ethics, responsibility  and trustworthinessControl:  HCAI preserves human  agency and sense of re sponsibility by designing AI  systems to give users a high  level of understanding of, and  control over, their specific  and unique processes and  outputsThis manifesto emerges from the frustrations and concerns shared among researchers at AiTH:  about the state of discourse on AI ethics and trustworthiness, about the unquestioned dominance  of Big Tech, and about the deficiencies of techno-solutionist and machine-centred approaches to  AI. With this manifesto, we wish to publish a public declaration of AiTH’s thinking and objectives.  In particular, we wish to make clear what we believe is needed (and why) to employ a distinctive  and legitimate human-centred approach to the adoption and integration of intelligent technologies  in our businesses and society. AiTH’s approach to HCAI A Human-Centred approach to AI (HCAI) focuses on designing and deploying AI systems in ways  that serve the needs of, and create benefits for, humans. In line with this purpose, we recognize  that HCAI must contribute to and empower human’s experience of competence, sense of belong ing, control and well-being.    Well-being:   HCAI advances the selfesteem, confidence and happi ness of all humans. The design  and deployment of such AI  systems must be mindful to  the varied dimensions of life  that they stand to impact, as  well as their long-term effects  on overall well-being 
IMPLICATIONS AND RECOMMENDATIONS  9 The Road to a Human-Centred Digital Society Humans first, machines second  The capabilities of intelligent technologies for thought and action should not serve as the standard by which humans  are assessed and compared. Considerations about the well-being and flourishing of humans – especially those sys tematically disadvantaged and disenfranchised – must always be central to any technology deployment. We should  be preparing machines to serve humans, rather than preparing humans to serve machines.  Our recommendations   for businesses and policymakers derive directly from AiTH’s research and thought leadership based  on the four facets of HCAI. The following high-level recommendations aim to provide guidance on the  types of considerations that need to be made while pursuing human-centred AI.01 ‘Digital transformation’ and the adoption of intelligent technologies  should be value-driven rather than solely profit-driven We can use machines for good if we are clear about what our human identity is and what value we want to create  for a humane society. A clear understanding of how to do business and what kind of value ought to be created for  end-users can serve as a lens for evaluating the appropriateness and necessity of technological interventions.  02 Human and machine intelligences should not be treated as inter changeable Automation should not be thought of in terms of its potential to replace or disrupt human labour. Instead, in line  with the ‘augmentation’ paradigm, we should instead evaluate automation in terms of how it complements and en hances our human abilities and ways of working. The future of work should be a collaborative one: where machines  are deployed in ways that respect the autonomy and abilities of workers, and in turn, make work better for everyone.   03
 10 The Road to a Human-Centred Digital Society The ultimate responsibility for technological-augmented decisions must  remain in human hands  Intelligent technologies are not moral agents. The ‘decisions’ they make are situated within contexts and rules set in  place by human choices – by those who develop, deploy and use them. As such, humans must and are obliged to  retain ultimate responsibility for these decisions. 04 Ethical considerations about technology must be embedded in organi zational structures and practices, rather than in abstract frameworks  and principles Current governance frameworks and principles reduce ethics, fairness and trust to technological features and boxes to  be ticked. However, we can only have ‘ethical AI’ when ethics is fully integrated into daily organizational life. Leaders  need to translate principles into specific practices, and moral upskilling is needed for all workers.   05 Embrace value pluralism and respect cultural differences while advanc ing ethical AI Current conversations about ethical AI tend to emphasize perspectives from the West rather than the East, and the  Global North rather than the Global South. This trend is at least partly due to greater attention to the topic in these  regions, which necessitates a call for more thought leadership in this field to emerge from Eastern counterparts (a role  that AiTH proudly takes upon itself). For human-centred AI to serve the needs of all – rather than just a few – humans,  we must be sensitive to how values and interests are displayed differently across diverse cultural and social contexts  and how these differences may impact our thinking about and assessment of fair, trustworthy and ethical intelligent  technologies.   06
 11 The Road to a Human-Centred Digital Society Focus on real AI, rather than imagined AI There are growing tendencies to focus on the anticipated future risks and benefits of certain kinds of ‘superintelligent’  AI that might exist in the future. Such imaginaries tend to distract and obfuscate the real harms and benefits that ‘nar row’ AI systems are already bringing to organizations and society. Fantasies of “superhuman” AI (endlessly repeated by  business writers and self-proclaimed experts) mislead people into overestimating the capabilities of currently available  AI systems. As a result, today’s society runs the risk to be constructed and shaped in correspondence with imaginaries  of AI – a world more suited for machines - that may or may not materialize. We hasten to say that we do not mean to  suggest that superintelligence is strictly impossible. However, the process of building value-aligned and human-centred  AI must begin with a realistic attitude that focuses on the AI systems that we have today, and the actual material  harms and benefits that they presently create. 07
 12 The Road to a Human-Centred Digital SocietyJoin us: Centre on AI Technology for Humankind (AiTH) AiTH@nus.edu.sg https:/ /bschool.nus.edu.sg/aith/
