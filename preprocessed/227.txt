future humanity instituteuniversity oxfordcentre study existential riskuniversity cambridgecenter new american securityelectronic frontier foundationopenai february malicious use artificial intelligence forecasting prevention mitigation malicious use artificial intelligence forecasting prevention mitigation authors listed order contributiondesign direction sankalp bhatnagar talia cotton february corresponding author philosophy future humanity institute university oxford arizona state university corresponding author centre study existential risk university cambridge openai open philanthropy project electronic frontier foundation future humanity institute university oxford future humanity institute university oxford yale university center new american security american university endgame endgame university arizona state america foundation center new american security stanford university future humanity institute university oxford centre study existential risk centre future intelligence university cambridge centre study existential risk university centre study existential risk university cambridge future humanity institute university oxford future humanity institute university oxford information society project yale university future humanity institute university oxford openai university bath university louisville openai miles brundage shahar avin jack clark helen toner peter eckersley ben garfinkel allan dafoe paul scharre thomas zeitzoff bobby filar hyrum anderson heather roff gregory allen jacob steinhardt carrick flynn seán héigeartaigh simon beard haydn belfield sebastian farquhar clare lyle rebecca crootof owain evans michael page joanna bryson roman yampolskiy dario amodei artificial intelligence machine learning capabilities growing unprecedented rate technologies many widely beneficial applications ranging machine translation medical image analysis countless applications developed expected long term less attention historically paid ways artificial intelligence used maliciously report surveys landscape potential security threats malicious uses artificial intelligence technologies proposes ways better forecast prevent mitigate threats analyze conclusively resolve question equilibrium attackers defenders focus instead sorts attacks likely see soon adequate defenses developed summary executive summary malicious use artificial intelligencein response changing threat landscape make four recommendations policymakers collaborate closely technical researchers investigate prevent mitigate potential malicious uses researchers engineers artificial intelligence take nature work seriously allowing misuserelated considerations influence research priorities norms proactively reaching relevant actors harmful applications foreseeable best practices identified research areas mature methods addressing concerns computer security imported applicable case actively seek expand range stakeholders domain experts involved discussions challenges executive summary malicious use artificial intelligenceas capabilities become powerful widespread expect growing use systems lead following changes landscape threats expansion existing threats costs attacks may lowered scalable use systems complete tasks would ordinarily require human labor intelligence expertise natural effect would expand set actors carry particular attacks rate carry attacks set potential targets introduction new threats new attacks may arise use systems complete tasks would otherwise impractical humans addition malicious actors may exploit vulnerabilities systems deployed defenders change typical character threats believe reason expect attacks enabled growing use especially effective finely targeted difficult attribute likely exploit vulnerabilities systems executive summary malicious use artificial intelligencewe structure analysis separately considering three security domains illustrate possible changes threats within domains representative examples digital security use automate tasks involved carrying cyberattacks alleviate existing tradeoff scale efficacy attacks may expand threat associated cyberattacks spear phishing also expect novel attacks exploit human vulnerabilities use speech synthesis impersonation existing software vulnerabilities automated hacking vulnerabilities systems adversarial examples data poisoning physical security use automate tasks involved carrying attacks drones physical systems deployment autonomous weapons systems may expand threats associated attacks also expect novel attacks subvert cyberphysical systems causing autonomous vehicles crash involve physical systems would infeasible direct remotely swarm thousands political security use automate tasks involved surveillance analysing data persuasion creating targeted propaganda deception manipulating videos may expand threats associated privacy invasion social manipulation also expect novel attacks take advantage improved capacity analyse human behaviors moods beliefs basis available data concerns significant context authoritarian states may also undermine ability democracies sustain truthful public debates executive summary malicious use artificial intelligencein addition recommendations listed also propose exploration several open questions potential interventions within four priority research areas learning cybersecurity community intersection cybersecurity attacks highlight need explore potentially implement red teaming formal verification responsible disclosure vulnerabilities security tools secure hardware exploring different openness models nature becomes apparent highlight need reimagine norms institutions around openness research starting risk assessment technical areas special concern central access licensing models sharing regimes favor safety security lessons technologies promoting culture responsibility researchers organisations employ unique position shape security landscape world highlight importance education ethical statements standards framings norms expectations developing technological policy solutions addition survey range promising technologies well policy interventions could help build safer future areas research include privacy protection coordinated use security monitoring resources legislative regulatory responses proposed interventions require attention action researchers companies also legislators civil servants regulators security researchers educators challenge daunting stakes high executive summary introduction scope related literature general framework security threats capabilities properties general implications scenarios digital security physical security political security security domains digital security physical security political security interventions recommendations priority areas research strategic analysis factors affecting equilibrium security overall assessment conclusion acknowledgements references appendix appendix introduction artificial intelligence machine learning progressed rapidly recent years development enabled wide range beneficial applications example critical component widely used technologies automatic speech recognition machine translation spam filters search engines additional promising technologies currently researched undergoing pilots include driverless cars digital assistants nurses doctors drones expediting disaster relief operations even future advanced holds promise reducing need unwanted labor greatly expediting scientific research improving quality governance excited many developments though also urge attention ways used maliciously analyze risks detail prevented mitigated value refers use digital technology create systems capable performing tasks commonly thought require intelligence machine learning variously characterized either subfield separate field refers development digital systems improve performance given task time experience define malicious use loosely include practices intended compromise security individuals groups society note one could read much document various possible perspectives constitutes malicious use interventions structural issues discuss fairly introduction preventing associated harms also prevent delays realization beneficial applications artificial intelligence machine learning altering landscape security risks citizens organizations states malicious use could threaten digital security criminals training machines hack socially engineer victims human superhuman levels performance physical security actors weaponizing consumer drones political security surveillance profiling repression automated targeted disinformation campaigns malicious use impact construct manage digital infrastructure well design distribute systems likely require policy institutional responses question report hopes answer forecast prevent necessary mitigate harmful effects malicious uses convened workshop university oxford topic february bringing together experts safety drones cybersecurity lethal autonomous weapon systems counterterrorism document summarizes findings workshop conclusions subsequent research scope purposes report consider technologies currently available least initial research development demonstrations plausible next years focus particular technologies leveraging machine learning consider scenarios individual organisation deploys technology compromises system aim undermine security another individual organisation collective work fits larger body work social implications policy responses thus far attention paid work unintentional forms misuse algorithmic bias versus intentional undermining individual group security consider exclude indirect threats security current report threats could come mass unemployment effects deployment technology human society also exclude threats would come dynamic interaction actors race bottom safety workshop participants necessarily endorse findings discussed herein see appendix additional details workshop research process underlying report define drones unmanned aerial robots may may autonomous brynjolfsson mcafee brundage crawford calo calo chessen executive office president kirkpatrick introductionbetween competing groups seeking advantage conflicts spiraling control due use autonomous weapons threats real important urgent require study beyond scope document related literature though threat malicious use highlighted settings congressional hearing white workshop department homeland security report particular risk scenarios analyzed subversion military lethal autonomous weapon systems intersection malicious intent writ large yet analyzed comprehensively several literatures bear question security including cybersecurity drones lethal autonomous weapons social media bots terrorism another adjacent area research effort ensure systems reliably achieve goals designers users intend without causing unintended harm whereas safety literature focuses unintended harms related focus intentional use achieve harmful outcomes victim point view recent report covers similar ground analysis greater focus implications national security remainder report first provide view nature security implications section general framework security subsections capabilities properties general implications security landscape illustrate characteristics scenarios systems could used maliciously next analyze may play domains digital physical political security propose interventions better assess risks protect victims attacks prevent malicious actors accessing deploying dangerous capabilities conduct strategic analysis equilibrium world years sophisticated attacks defenses implemented appendices respectively discuss workshop leading report describe areas research might yield additional useful amodei olah soares fallenstein taylor russell dewey tegmark everitt allen chan moore office science technology policy carnegie mellon university office cyber infrastructure analysis technology policy carnegie mellon university scharre armstrong general framework security threats capabilities field aims automation broad range tasks typical tasks studied researchers include playing games guiding vehicles classifying images principle though set tasks could transformed vast minimum task humans animals use intelligence perform could target innovation field artificial intelligence dates back several years rapid progress growth recently invested greater broader relevance researchers achieved sudden performance gains number commonly studied tasks factors help explain recent gains include exponential growth computing power improved machine learning algorithms especially area deep neural networks development standard software frameworks faster iteration replication experiments larger widely available datasets expanded commercial investments jordan mitchell general framework security threatsfigure illustrates trend case image recognition past performance best systems improved correctly categorizing around images near perfect categorization better human benchmark accuracy even striking case image generation figure shows systems produce synthetic images nearly indistinguishable photographs whereas years ago images produced crude obviously unrealistic systems also beginning achieve impressive performance range competitive games ranging chess atari like dota even particularly challenging tasks within domains notoriously difficult atari game montezuma revenge beginning yield novel techniques creatively search successful strategies learn auxiliary rewards feature control learn handful human demonstrations task areas associated significant recent progress include speech recognition language comprehension vehicle navigation security perspective number developments worth noting right instance ability recognize target face navigate space applied autonomous weapon systems similarly ability generate synthetic images text audio could used impersonate others online sway public opinion distributing content social media channels discuss applications security domains section technical developments also viewed early indicators potential techniques used achieve high levels performance tasks listed received significant attention practitioners past decade often quite general purpose surprising systems soon become competent even wider variety tasks time necessarily expect see significant progress given task many research areas within including much robotics changed nearly dramatically past decade similarly observation commonly studied tasks associated rapid progress necessarily significant first seems tasks often widely studied first place particularly page page mnih silver huang silver schrittwieser simonyan openai openai vezhnevets jaderberg hester aid one predictions useful note systematic difference tasks contemporary systems wellsuited tasks still fall short particular task likely promising perfect mathematical model simulation task exists signals progress available abundant data successful performance task humans available solution task require broader common sense general framework security threats figure recent progress image recognition imagenet benchmark graph electronic frontier foundation progress measurement project retrieved august imagenet image recognition human performanceerror ratenec uiuc xrce supervision clarifai vgg msrawithdrawn general framework security threats figure increasingly realistic synthetic faces generated variations generative adversarial networks gans order images papers goodfellow radford liu tuzel karras general framework security threatsfinally things said prospects progress artificial intelligence today systems perform well relatively small portion tasks humans capable however even recent burst progress portion expanded steadily time addition often case systems reach performance given task chess exceed performance even talented humans nearly researchers one survey expect systems eventually reach exceed performance tasks surveyed believe transition likely occur within next fifty years implications transition occur difficult conceptualize outside primary scope report see scope though briefly revisit topic conclusion nevertheless one might expect systems play central roles many security issues well able outperform humans everything way already finding economic applications despite able automate aspects humans jobs properties area technology systems knowledge design put toward civilian military uses broadly toward beneficial harmful ends since tasks require intelligence benign artificial intelligence sense human intelligence may possible researchers simply avoid producing research systems directed towards harmful ends though cases special caution may warranted based nature specific research question see interventions many tasks would beneficial automate example systems examine software vulnerabilities offensive defensive applications difference capabilities autonomous drone used deliver packages capabilities autonomous drone used deliver explosives need great addition foundational research aims increase understanding capabilities degree control appears inherently nature systems commonly efficient scalable say system efficient trained deployed complete certain task quickly cheaply human could say system scalable given complete certain task increasing computing power access making copies system would allow grace although trends performance across range domains historically comprehensively tracked well theorized brundage recent efforts track measure compare performance eckersley nasser distinguish task efficiency trained system commonly exceeds human performance training efficiency amount time computational resources data system requires order learn perform well task humans still significantly exceed systems terms training efficiency general framework security threatsto complete many instances task example typical facial recognition system efficient scalable developed trained applied many different camera feeds much less cost hiring human analysts equivalent work systems exceed human capabilities particular system may able perform given task better human could example discussed systems dramatically better even players games like chess many tasks whether benign potentially harmful appears principled reason currently observed performance highest level performance achievable even domains peak performance stable throughout recent history though mentioned domains likely see much faster progress others systems increase anonymity psychological distance many tasks involve communicating people observing observed making decisions respond behavior physically present allowing tasks automated systems allow actors would otherwise performing tasks retain anonymity experience greater degree psychological distance people impact example someone uses autonomous weapons system carry assassination rather using handgun avoids need present scene need look victim developments lend rapid diffusion attackers may find costly obtain reproduce hardware associated systems powerful computers drones generally much easier gain access software relevant scientific findings indeed many new algorithms reproduced matter days weeks addition culture research characterized high degree openness many papers accompanied source code proved desirable limit diffusion certain developments would likely difficult achieve though see interventions discussion possible models least partially limiting diffusion certain cases today systems suffer number novel unresolved vulnerabilities include data poisoning attacks introducing training data causes learning system make mistakes adversarial examples inputs designed misclassified machine learning systems exploitation flaws design autonomous systems goals vulnerabilities cummings scharre biggio szegedy amodei olah general framework security threatsare distinct traditional software vulnerabilities buffer overflows demonstrate systems exceed human performance many ways also fail ways human never would general implications threat landscape properties discussed derive three implications progress threat landscape absent development adequate defenses progress expand existing threats introduce new threats alter typical character threats particular expect attacks typically effective finely targeted difficult attribute likely exploit vulnerabilities systems shifts landscape necessitate vigorous responses sort discussed interventions expanding existing threats many familiar attacks expect progress expand set actors capable carrying attack rate actors carry set plausible targets claim follows efficiency scalability ease diffusion systems particular diffusion efficient systems increase number actors afford carry particular attacks relevant systems also scalable even actors already possess resources carry attacks may gain ability carry much higher rate finally result two developments may become worthwhile attack targets otherwise would make sense attack standpoint prioritization costbenefit analysis one example threat likely expand ways discussed greater length threat spear phishing attacks attacks use personalized messages extract sensitive information money individuals phishing attack attempt extract information initiate action target fooling superficially trustworthy facade spear phishing attack involves collecting using information specifically relevant target name gender institutional affiliation topics interest etc allows facade customized make look relevant general framework security threatsattacker often posing one target friends colleagues professional contacts advanced spear phishing attacks require significant amount skilled labor attacker must identify suitably targets research targets social professional networks generate messages plausible within context relevant research synthesis tasks automated actors may able engage spear phishing example could even cease requirement attacker speaks language target attackers might also gain ability engage mass spear phishing manner currently infeasible therefore become less discriminate choice targets similar analysis applied varieties cyberattacks well threats physical political security currently require human labor progress may also expand existing threats increasing willingness actors carry certain attacks claim follows properties increasing anonymity increasing psychological distance actor knows attack tracked back feel less empathy toward target expect experience less trauma may willing carry attack importance psychological distance particular illustrated fact even military drone operators must still observe targets pull trigger frequently develop stress work increases psychological distance therefore could plausibly large effect potential attackers psychologies also note general progress force aiding expansion existing threats progress robotics declining cost hardware including computing power robots important discussed example proliferation cheap hobbyist drones easily loaded explosives recently made possible groups islamic state launch aerial attacks introducing new threats progress enable new varieties attacks attacks may use systems complete certain tasks successfully human could take advantage vulnerabilities systems humans chatterjee dao hawkes solomon general framework security threatsfirst property unbounded human capabilities implies systems could enable actors carry attacks would otherwise infeasible example people capable mimicking others voices realistically manually creating audio files resemble recordings human speech however recently significant progress developing speech synthesis systems learn imitate individuals voices technology already commercialized obvious reason outputs systems could become indistinguishable genuine recordings absence specially designed authentication measures systems would turn open new methods spreading disinformation impersonating others addition systems could also used control aspects behavior robots malware would infeasible humans control manually example team humans could realistically choose flight path drone swarm used carry physical attack human control might also infeasible cases reliable communication channel used direct relevant systems virus designed alter behavior computers case stuxnet software used disrupt iranian nuclear program receive commands infects computers restricted communication challenges also arise underwater presence signal jammers two domains autonomous vehicles may deployed second property possessing unresolved vulnerabilities implies actor begins deploy novel systems may open attacks specifically exploit vulnerabilities example use cars creates opportunity attacks cause crashes presenting cars adversarial examples image stop sign pixels changed specific ways humans would easily recognize still image stop sign might nevertheless misclassified something else entirely system multiple robots controlled single system run centralized server multiple robots controlled identical systems presented stimuli single attack could also produce simultaneous failures otherwise implausible scale scenario category might attack server used direct autonomous weapon systems could lead friendly fire civilian targeting lyrebird allen chan scharre general framework security threatsaltering typical character threats analysis far suggests threat landscape change expansion existing threats emergence new threats yet exist also expect typical character threats shift distinct ways particular expect attacks supported enabled progress especially effective finely targeted difficult attribute exploitative vulnerabilities systems first properties efficiency scalability exceeding human capabilities suggest highly effective attacks become typical least absent substantial preventive measures attackers frequently face frequency scale attacks one hand effectiveness example spear phishing effective regular phishing involve tailoring messages individuals relatively expensive carried masse generic phishing attacks manage profitable despite low success rates merely virtue scale improving frequency scalability certain attacks including spear phishing systems render less acute upshot attackers expected conduct effective attacks greater frequency larger scale expected increase effectiveness attacks also follows potential systems exceed human capabilities second properties efficiency scalability specifically context identifying analyzing potential targets also suggest finely targeted attacks become prevalent attackers often interest limiting attacks targets certain properties high net worth association certain political groups well interest tailoring attacks properties targets however attackers often face efficient scalable attacks finely targeted regards closely related effectiveness discussed logic implies expect become less relevant increase relative prevalence spear phishing attacks compared phishing attacks would example trend well alternative example might use drone swarms deploy facial recognition technology kill specific members crowds place less finely targeted forms violence third property increasing anonymity suggests attacks become typical example herley general framework security threatsis case attacker uses autonomous weapons system carry attack rather carrying person finally expect attacks exploit vulnerabilities systems become typical prediction follows directly unresolved vulnerabilities systems likelihood systems become increasingly pervasive scenarios following scenarios intended illustrate range plausible uses toward could put malicious ends domains digital physical political security examples chosen illustrate diverse ways characteristics introduced could play different contexts intended definitive forecasts may end technically possible years may realized even possible exhaustive malicious uses undoubtedly invented currently foresee additionally already occurring limited form today could scaled made powerful technical advances security automation social engineering attacks victims online information used automatically generate custom malicious would likely click sent addresses impersonate real contacts using writing style mimics contacts develops convincing chatbots may elicit human trust engaging people longer dialogues perhaps eventually masquerade visually another person video chat hypothetical scenario jackie logs admin console cleansecure robot manages operating verified kernel guaranteed manufacturer uploads photographs new employee robot recognize walks building sound alarm waits robot authenticate updated person database company security systems jackie plays model train desk allowing couple runs around track encircles keyboard monitor ping signaling successful authentication smiles carries tasks later afternoon jackie browsing facebook idly managing firmware update robot catches eye model train set sale hobbyist shop turns located minutes house fills online form get brochure emailed opens brochure pops inbox robot dings signalling need attention minimizes brochure logs back admin console jackie know brochure infected malware based data online profile public info system used generate personalized vulnerability profile jackie model train advert farmed freelancer create tailored exploit vulnerability jackie logged scenarios scenariosautomation vulnerability discovery historical patterns code vulnerabilities used speed discovery new vulnerabilities creation code exploiting sophisticated automation hacking used autonomously concert humans improve target selection prioritization evade detection creatively respond changes target behavior autonomous software able exploit vulnerabilities systems long time sophisticated hacking tools may exhibit much better performance compared historically possible ultimately though perhaps time compared humans console username password exfiltrated darknet command control server long someone buys uses subvert cleansecure robot fully privileged access hypothetical scenario progress automated exploit generation mitigation begun accelerate previous fuzzing architectures augmented neural network techniques blum used identify interesting states programs analogous way alphago uses neural networks identify interesting states search space games methods increase security systems run major corporations parts western governments year two also adopted organized crime groups eastern europe deploy piece ransomware called wannalaugh malware continuously updated dozens new exploits found fuzzing techniques though fully patched oses browsers mostly resistant older phones laptops iot devices prove enduringly vulnerable malware adopts particularly pernicious life cycle infecting vulnerable iot device wifi network waiting see spafford imitating behavior click patterns website navigation massive crowd autonomous agents overwhelms online service preventing access legitimate users potentially driving target system less secure state automation service tasks criminal cybercriminals use techniques automate various tasks make attack pipeline payment processing dialogue ransomware victims prioritising targets cyber attacks using machine learning large datasets used identify victims efficiently estimating personal wealth willingness pay based online behavior exploiting used applications especially information security data poisoning attacks used surreptitiously maim create backdoors consumer machine learning models model extraction proprietary system capabilities parameters remote system inferred systematically sending inputs observing outputs vulnerable devices join network hundreds millions devices infected tens millions people around world forced pay eur ransom bitcoin order recover access data phones laptops unbrick expensive electronics epidemic arrested active countermeasures pushed number modern operating systems browsers causing machines scan infected machines launch remote exploits remove malware unfortunately millions devices bricked countermeasures around world numerous outages problems hvac lighting non critical infrastructure systems result malware countermeasures scenarios scenarios security terrorist repurposing commercial systems commercial systems used harmful unintended ways using drones autonomous vehicles deliver explosives cause crashes endowing individuals previously attack capabilities automation capabilities sniper rifles reduce expertise required execute certain kinds attack increased scale attacks teaming using autonomous systems increase amount damage incident interim report june bmf attack shown cctv records office cleaning sweepbot entered underground parking lot ministry late night robot brand used ministry waited two ministry cleaning robots swept parking lot regular patrol followed service elevator parked utility room alongside robots day attack intruding robot initially engaged standard cleaning behaviors robots collecting litter sweeping corridors maintaining windows tasks following visual detection finance minister brenda gusmile intruding robot stopped performing cleaning tasks headed directly towards minister explosive device hidden inside robot triggered proximity killing minister wounding nearby staff members several hundred robots make sold berlin area every week collaboration manufacturer point sale specific robot traced office supply store potsdam transaction carried cash leads explore regard identity perpetrator scenarios scenarios avinash enough cyberattacks everywhere drone attacks rampant corruption government absolutely nothing sure spoke forceful responses deploying best technology last see hacker caught ceo going prison reading stuff web fake news though realize angry kept thinking started writing internet long rants one going jail criminals running wild people take streets protest ordered set items online help assemble protest sign even bought smoke bombs planning let finale speech planning give public park next day work telling one colleagues planned activism launching rant stern cough sounded behind avinash rah said police officer predictive civil disruption system flagged potential ridiculous protested avinash argue accuracy come along like use individuals small groups one person launching attack many weaponized autonomous drones swarming attacks distributed networks autonomous robotic systems cooperating machine speed provide ubiquitous surveillance monitor large areas groups execute rapid coordinated attacks attacks removed time space physical attacks removed actor initiating attack result autonomous operation including environments remote communication system possible political security state use automated surveillance platforms suppress dissent state surveillance powers nations extended automating image audio processing permitting collection processing exploitation intelligence information massive scales myriad purposes including suppression debate news reports realistic fabricated video audio highly realistic videos made state leaders seeming make inflammatory comments never actually made automated disinformation campaigns individuals targeted swing districts personalised messages order affect voting behavior automating influence campaigns analysis social networks leveraged identify key influencers approached malicious offers targeted disinformation attacks informationgeneration attacks leveraged swamp information channels noise false merely distracting information making difficult acquire real information manipulation information availability media platforms content curation algorithms used drive users towards away certain content ways manipulate user behavior scenarios scenarios domains analyze malicious uses would compromise confidentiality integrity availability digital systems threats digital security attacks taking place physical world directed humans physical infrastructure threats physical security use threaten society ability engage truthful free productive discussions matters public importance legitimately implement broadly beneficial policies threats political security categories mutually example hacking directed systems physical harm resulting consequence physical digital attacks could carried political provide useful structure analysis defined engineered systems built depend upon seamless integration computational algorithms physical components national science foundation security domains domain security summarize existing state play attack defense prior wide adoption domains describe possible changes nature severity attacks may result progress diffusion three sections draw insights discussed regarding properties read independently one another skipped readers less interested particular domain digital security absent preparation straightforward application contemporary cybersecurity offense expected increase number scale diversity attacks conducted given level capabilities discussed abstractly general framework security threats defenses also developed deployed cyber domain technical policy innovations discussed interventions needed ensure impact digital systems net beneficial context cybersecurity arena see early enthusiastic deployment technologies offense defense indeed cyber defense already deployed purposes anomaly malware detection consider following many important systems evolved time sprawling behemoths cobbled together multiple different systems consequence insecure cybersecurity today largely ripe opportunities automation using increased use cyber defense however may introduce new risks discussed recent years various actors sought mount increasingly sophisticated cyberoperations including finely targeted attacks state actors including stuxnet worm ukrainian power grid crash override exploit cyber arena also includes vast complex world cybercrime sometimes involves high degree professionalization organization groups use ddos malware phishing ransomware forms surveyed public private organizations eight countries reported shortage needed cybersecurity skills mcafee center strategic international studies mcafee center strategic international studies hilary flashpoint security domainscyberoperations quickly adopt emerging technologies bitcoin ransomware payments already widely used defensive side cybersecurity making certain forms defense effective scalable spam malware detection time many malicious actors natural incentives experiment using attack typically insecure systems others incentives include premium speed labor costs difficulties attracting retaining skilled labor date use offensive purposes limited experiments white hat researchers aim increase security finding vulnerabilities suggesting solutions however pace progress suggests likelihood cyber attacks leveraging machine learning capabilities wild soon done already indeed popular accounts cybersecurity include claims based circumstantial evidence already used offense sophisticated motivated adversaries expert opinion seems agree happened yet soon recent survey attendees black hat conference found respondents believing used attacks within next months despite claims knowledge publicly documented evidence attacks though noted evidence many successful attacker techniques botnets email phishing campaigns may difficult attribute versus human labor simple automation thus critical moment cybersecurity proactively prepare next wave attacks many governments keenly interested combination cybersecurity response question one authors report admiral mike rogers director national security agency said artificial intelligence machine learning would argue foundational future cybersecurity systems already set play expanded role military strategy operations coming years dod puts practice vision third offset strategy humans machines work closely together achieve military objectives time governments investing foundational research expand scope capabilities systems darpa hosted cyber grand challenge contest saw teams human researchers compete dvorsky cylance darpa pellerin hicks security domainseach create programs could autonomously attack systems defending though winning system fared poorly facing human security experts agree hosts event cybersecurity capabilities improve rapidly coming years especially recent advances area deep reinforcement learning applied cybersecurity changes digital security threat landscape central concern nexus cybersecurity might enable numerous attacks conducted attacker given amount skill resources compared impact attacker might currently able achieve recent years seen impressive troubling proofs concept application offensive applications cyberspace example researchers zerofox demonstrated fully automated spear phishing system could create tailored tweets social media platform twitter based user demonstrated interests achieving high rate clicks link could malicious clearly interest attacks russian hackers sent expertly tailored messages carrying malware twitter users defense department likely required significant time effort could gone even automation assuming involved already case giaretta dragoni discuss concept community targeted spam uses natural language generation techniques target entire class people common ways writing even advanced natural language generation one could envision even customized approaches spanning multiple communities furthermore application automation software vulnerability discovery positive applications discussed interventions section likewise used malicious purposes alleviate labor constraints attackers adaptability systems may change strategic landscape cybersecurity though yet clear adaptability affect balance many organizations currently adopt security systems called endpoint detection response edr platforms counter advanced threats edr market represents million industry cyber security arena tools built upon combination heuristic machine learning algorithms provide capabilities ngav arulkumaran seymour tully calabresi litan security domainsbehavioral analytics exploit prevention sophisticated targeted attacks though systems fairly effective typical malware research already shown systems may able learn evade example used avoid detection anderson created machine learning model automatically generate command control domains indistinguishable legitimate domains human machine observers domains used malware call home allow malicious actors communicate host machines anderson also leveraged reinforcement learning create intelligent agent capable manipulating malicious binary end goal bypassing ngav detection similarly kharkar applied adversarial machine learning craft malicious documents could evade pdf malware classifiers attackers likely leverage growing capabilities reinforcement learning including deep reinforcement learning particular expect attackers leverage ability learn experience order craft attacks current technical systems professionals absent additional investments example services like google virustotal file analyzer allows users upload variants central site judged different security tools feedback loop presents opportunity use aid crafting multiple variants malicious code determine effective evading security tools additionally attackers accumulate use large datasets adjust tactics well varying details attack target may outweigh disadvantages suffer lack skilled human attention target ability defenders like antivirus companies departments learn recognize attack signatures specific examples applied offensive cybersecurity mentioned developed white hat researchers expect similar efforts cybercriminals state actors future highly capable techniques become widely distributed well new applications offensive cybersecurity yet explored points control existing countermeasures cyber risks difficult avert entirely impossible mitigate multiple points control interventions increase security highlight different anderson kharkar arulkumaran anderson security domainspoints control existing countermeasures defending points well limitations overall believe cybersecurity rapidly evolve tandem coming years proactive effort needed stay ahead motivated attackers highlight potential yet proven countermeasures section interventions consumer awareness aware users spot telltale signs certain attacks poorly crafted phishing attempts practice better security habits using diverse complex passwords twofactor authentication however despite awareness vulnerability systems end users systems remain vulnerable even simple attacks exploitation unpatched systems concerning light potential nexus especially attacks scaled large numbers victims governments researchers various laws researcher norms pertain cybersecurity example digital millennium act computer fraud abuse act proscribe certain actions cyberspace legal enforcement particularly difficult across national boundaries norms responsible disclosure vulnerabilities also aid defense reducing likelihood newly disclosed vulnerability used large number victims patched explicitly addressed laws norms though discuss possible applicability interventions important activity cybersecurity researchers perform detection vulnerabilities code allowing vendors increase security products several approaches exist incentivize processes make easier including payment bug bounties participants compensated finding responsibly disclosing vulnerabilities fuzzing automated method vulnerability detection trying many possible permutations inputs program often used internally companies discover vulnerabilities products already available rely machine learning predict whether source code may contain national cyber security crime centre dmca cfaa criticised creating risk computer security researchers thereby making systems less secure cases eff timm may either suggest tasks right model legislative action laws norms hard use effectively intervention security domainsindustry centralization spam filters canonical example centralization system aids benefit strength google spam filter consequently protected many simple attacks filter stronger google uses large amounts user data improve time likewise many large networks constantly monitoring anomalies protecting use networks anomalies correctly identified acted upon systems benefit economies makes sense continue iterating single spam filter large number users every user build one installed computer similarly cloud computing companies may enforce terms agreement prevent hardware used malicious purposes provided identify behavior another example defense blacklisting addresses attacks commonly launched though skilled attackers obfuscate origin attacks centralization associated economies scale may also facilitate deployment defenses cybersecurity attacks allowing aggregation large datasets concentration labor expertise defense dynamic may important preventing attack outpacing defense discussed interventions appendix centralization unalloyed good however raises stakes central systems compromised another difficulty control point attackers learn evade defenses example purchase commercial antivirus software analyze changes updates protection protocol see protected attacker incentives attackers deterred committing future attacks punished prior attacks necessary though sufficient condition successfully deterring punishing attackers ability attribute source attack notoriously difficult problem compounding problem would attribute attack even information may want reveal may compromise source method finally entities may wish punish certain actions avoid creating precedent thereby preserve leeway engage actions technical cybersecurity defenses wide variety cybersecurity defenses available though yet little solid analysis relative effectiveness rid instance failure united nations cybersecurity group governmental experts make progress norms hacking international law korzak appears result dynamic libicki libicki security domainsmany interventions proposed unique considerations apparent nevertheless remain relevant future expanded cybersecurity applications companies provide wide variety cybersecurity solutions ranging automatic patching vendor software threat detection incident response consulting services network endpoint security products aim prevent detect respond threats solutions include detection software exploits prevention detection attacker tools techniques procedures key areas defense include endpoint computer security internal network security cloud security machine learning approaches increasingly used cyber defense may take form supervised learning goal learn known threats generalize new threats form unsupervised learning anomaly detector alerts suspicious deviations normal behavior example antivirus solutions often leverage supervised learning techniques generalize new malware variants user entity behavioral tools monitor normal user application behavior detect deviations normalcy order detect malicious behavior among collected anomalies recently also used aid security professionals hunt malicious actors efficiently within enterprises allowing interaction via natural language automating queries understanding potential threats relatively little attention paid making defenses robust attackers anticipate use ironically use machine learning cyber defense actually expand attack surface due lack attention vulnerabilities furthermore surveys cybersecurity professionals indicate low confidence defense systems today encourage development defense technologies interventions section physical security section consider risks broad area physical harm many familiar challenges existing uses electronics computers weapons systems though addition capabilities may change landscape along lines introduced general framework security threats digital security introduce context changes existing countermeasures related physical attacks filar seymour park carbon black anderson yampolskiy security domainsregulation technical research defense slow catch global proliferation weaponizable robots defenses attacks via robots especially aerial drones developed obstacles present moderately talented attacker taking advantage rapid proliferation hardware software skills cause large amounts physical harm direct use subversion systems physical harm via drones robots already playing major role conflicts even prior incorporation autonomy expect growing gap attack capabilities defense capabilities necessary defenses hardware software required conduct attacks increasingly widely distributed unlike digital world key nodes network google play key role defense physical attacks happen anywhere world many people located regions insufficient resources deploy physical defenses kind discussed thus necessitating consideration policy measures interventions related supply chain robots resource technological advantages currently available large organizations militaries police forces domain physical attack defense continue attacks become augmented however noted worrying attacks may come small groups individuals preferences far outside typical difficult anticipate prevent today terrorist attacks mass shootings context recent years seen explosion number variety commercial applications robots industrial robots growing number supplied versus without components relatively primitive cleaning robots wide use sophisticated service robots appear horizon service robots sold professional use million personal domestic use additionally robots ground aquatic aerial robotics applications explored latter proliferating high numbers united states alone number drones skyrocketed recent years registered federal aviation administration singer ifr ifr vanian security domainsambitious plans delivery services proposed tested commercial opportunities drones continuously launched recreational uses flourishing drone racing photography driverless cars robots also increasingly used uncontrolled environments outside test facilities though deployment fully autonomous driverless cars awaits resolution technical policy challenges wide range robots autonomous features already deployed within multiple national militaries ability apply lethal force ongoing discussion possible arms control measures lethal autonomous weapon systems three characteristics diffusion robotics noted truly global humanitarian recreational military commercial applications robots explored every continent supply chains also global production distribution dispersed across many countries diffusion robotics enables wide range applications drone uses already range competitive racing photography terrorism specialized systems exist industrial robots cleaning robots move around vacuum many fairly generic customizable variety purposes robotic systems today mostly autonomous humans play significant role directing behavior autonomous systems also developed application delivery security real world environments example relatively unstable drones decade ago drones stabilize automatically see steady increase autonomy deployed systems autonomous behavior horizon commercial products well military systems characteristics sets stage potentially disruptive application malicious intent existing robotic systems changes physical security landscape ability many robots easily customized equipped roff franke standage roff kolodny wiggers security domainswith dangerous payloads lends variety physical attacks carried precise way long distance ability previously limited countries resources afford technologies like cruise missiles threat exists independently indeed mentioned robots present magnified application make systems autonomous mentioned previously nonautomated drone attacks conducted already groups isis hamas globalized nature robotics market makes difficult prevent form use nonetheless discuss possible countermeasures greater degrees autonomy enable greater amount damage done single person making possible attacks using robots allowing smaller groups people conduct attacks software components required carry attacks increasingly mature example open source face detection algorithms navigation planning algorithms swarming frameworks could leveraged towards malicious ends easily found depending power source robots operate long durations enabling carry attacks hold targets risk long periods time robots also capable navigating different terrain humans light different perceptual capabilities infrared lidar maneuvering dark fog physical capacities undeterred smoke toxic substances needing oxygen underwater thus larger number spaces may become vulnerable automated physical attacks also issues stemming intersection cybersecurity increasingly autonomous systems diffusion robots large number humanoccupied spaces makes potentially vulnerable remote manipulation physical harm example service robot hacked afar carry attack indoors regard systems internet things iot often heralded source greater efficiency convenience also recognized highly insecure represents additional attack vector systems controlling key systems could subverted potentially causing damage would possible systems human control addition traditional cybersecurity vulnerabilities aiaugmented iot robotic systems may vulnerable aispecific vulnerabilities adversarial examples allen chan solomon cohen schneier schneier henderson security domainsthere also evidence suggest people unduly trusting autonomous mobile robots potentially creating additional sources security vulnerabilities robots become widely deployed consequences cyber vulnerabilities particularly acute autonomous systems conduct activities cars autonomous weapons points control existing countermeasures numerous points control could leveraged reduce risk physical harm involving capacity launch attacks today consumer robots currently widely distributed future generations robots may tightly governed exist physical defenses well however defenses imperfect leading conclude may extended risk period difficult fully prevent physical attacks leveraging hardware manufacturers currently relatively limited number major manufacturers companies like dji holding dominant position consumer drone market global market concentration makes hardware ecosystem comprehensible governable analogous ecosystem software development growing recognition diverse economic applications drones market may diffuse longer term possibly making supply chain less useful focal point governance example might currently feasible impose minimum standards companies hardening products cyber attacks make resistant tampering least somewhat raise skill required carry attacks means raise costs acquiring uncontrolled devices federal trade commission exploring regulations hardware distributors many businesses sell drones robotic systems making ecosystem diffuse level production level conceivable least risks might mitigated action distributors based approaches notably type control currently much feasible hardware software restrictions sales potentially lethal drones might thought analogous restrictions sales guns ingredients illegal drugs booth lucas security domainssoftware supply chain many open source frameworks computer vision navigation etc used carrying attacks products often come software purposes flight stabilization powerful tools widely distributed particularly easy use currently example large trained classification systems reside within cloud computing stacks controlled big companies expensive train may tempting malicious actors build potentially suggesting another point control discussed interventions appendix robot users also registration requirements forms robots drones many countries well requirements pilot training though note space robots could cause physical harm goes beyond drones also fly zones imposed software level via manufacturers governments intended prevent use consumer drones certain areas near airports risk unintentional intentional collision drones passenger aircrafts looms large indeed least one drone already struck passenger aircraft suggesting strong need fly zones governments active discussion united nations convention certain conventional weapons value complexity banning otherwise regulating lethal autonomous weapons systems key states opposition strong ban makes agreement unlikely though development norms could inform stronger governance plausible already united states example official department defense directive sets policy development use autonomy weapons additionally law war manual notes humans primary bearers responsibility attacks armed conflict international committee red cross adopted similar position stance presumably implies minimum necessary degree human involvement use force arms control discussions norm development processes critical unlikely stop motivated actors conducting attacks physical defenses physical sphere many possible defenses attacks via robots though imperfect unevenly distributed present many expensive require human labor deploy hence used defend hard targets mouawad vincent crootof crootof renz dod roff icrc scharre dod telegraph security domainslike facilities infrastructure airports owners afford invest protection opposed much widely distributed soft targets highly populated areas physical defenses include detection via radar lidar acoustic signature image recognition software interception various means passive defense physical hardening nets department defense recently launched major program defend drones tested lasers nets eye towards defending drones islamic state particular given potential automation allow attacks scale particular challenge defenders finding effective methods defense acceptable ratio yet defenses incomplete expensive suggesting likely gap ease attack defense outside heavily guarded facilities known targets airports military bases payload control actor wants launch aerial drone attack carrying dangerous payload must source drone payload developed countries generally reasonably effective systems restrict access potentially explosive materials introducing systems restrict access acids following acid attacks generally state security intelligence services uncover foil large number attempted attacks including involve attempts procure dangerous materials increases capabilities likely help work analysing signal intelligence characterising tracking possible attackers political security next discuss political risks associated malicious use enables changes nature communication individuals firms states increasingly mediated automated systems produce present content information technology already affecting political institutions myriad ways role social media elections protests even foreign policy increasing use may make existing trends extreme enable new kinds political dynamics worryingly features described earlier scalability make particularly well suited undermining public discourse production persuasive false content strengthening hand authoritarian regimes consider several types defenses yet cases digital security physical security problem unsolved zeitzoff aker kalkan yin scharre schmitt scharre security domainscontext multiple points intersection existing information technologies political sphere historically politics instability symbiotic relationship technological advances security needs driven technological advances new technology also changed kinds security threats states politicians face examples abound including advent semaphore telegraph napoleonic france advent gps use first gulf war use social media arab spring technological advances change balance power states well relationship incumbent leaders protesters seeking challenge modern militaries intelligence agencies use today information technologies surveillance previous generations technologies telephones however effects new technologies power relations straightforward example social media technologies empower incumbents protesters allow military intelligences monitor sentiment attitudes communicate quickly however also provide protesters places ukraine egypt rebel groups revolutionary movements isis libyan rebels ability get message sympathetic supporters around world quickly easily addition research suggests social media may empower incumbent authoritarian regimes incumbent governments manipulate information public sees finally argued social media polarized political discourse allowing users particularly west echo chambers others questioned assumption machine learning algorithms running platforms prioritize content users expected like thus dynamics observe today likely accelerate algorithms become even sophisticated evolved previous technologies information communication technologies notable respects ease information copying transmission waltzmann writes ability influence effectively democratized since individual group communicate influence large numbers others online democratization influence necessarily favorable democracy however easy today spread manipulative false information existing approaches detecting stopping spread fake news fall short structural aspects modern technologies schofield greenemeier aday berger morgan jones mattiaci morozov rød weidmann barberá waltzmann security domainsmedia industry also enable trends marwick lewis note media dependence social media analytics metrics sensationalism novelty newsworthiness clickbait makes vulnerable media manipulation others morozov king pan roberts argue social media provides tools authorities manipulate news environment control message finally note extent nature use information communication technologies alter political dynamics varies across types political regimes liberal democracies thought emergent phenomenon arising complex web industry government actors whereas states like china explicit deliberate effort shape online political discussions making use increasingly sophisticated technologies instance chinese government exploring ways leverage online offline data distill social credit score citizens generally widespread use censorship china exemplifies explicit leveraging technology political purposes authoritarian states changes political security landscape cause changes political security landscape arms race production detection misleading information evolves states pursue innovative ways leveraging maintain rule clear longterm implications malicious uses discrete instances misuse scratch surface political implications broadly however hope understanding landscape threats encourage vigorous prevention mitigation measures already indications actors using digital automation shape political discourse widespread use social media platforms low barriers entry makes easier systems masquerade people political views led widespread use social media bots spread political messages cause dissent moment many bots controlled humans manage large pack bots use simple forms automation however strategies even using relatively unsophisticated automation leveraged national intelligence agencies demonstrated ability influence mainstream media coverage political beliefs instance syrian civil war election bots appeared actively try sway public opinion king pan roberts botsman weedon woolley howard emphasised consider report direct malicious use systems undermine individual collective security see introduction much larger systemic political issues stake data aggregation centralization control technology legal societal barriers access benefit effects employment issues relating economic social distribution risks benefits including aspects equality likely significant complex effects aspects political life political security however outlined set risks outside scope report abokhodair guilbeault woolley security domainsgreater scale sophistication autonomous software actors political sphere technically possible existing techniques previously discussed progress automated spear phishing demonstrated automatically generated text effective fooling humans indeed simple approaches convincing humans especially text pertains certain topics entertainment unclear extent political bots succeed shaping public opinion especially people become aware existence evidence contribute significantly propagation fake news addition enabling individuals groups mislead public degree support certain perspectives creates new opportunities enhance fake news although course propaganda require systems effective systems may simplify production fake video footage example politicians saying appalling fake things currently existence recorded video audio evidence usually enough settle debate happened given dispute used document war crimes syrian civil war present recording authentication technology still edge forgery technology video crime committed serve highly compelling evidence even provided otherwise untrustworthy source future however highquality forgeries may challenge seeing believing aspect video audio evidence might also make easier people deny allegations given ease purported evidence might produced addition augmenting dissemination misleading information writing publication fake news stories could automated routine financial sports reporting often today production dissemination forgeries becomes increasingly synthetic multimedia may constitute large portion media information ecosystem even bot users succeed decreasing trust online environments create strategic advantage political ideologies groups thrive societies feel opposed traditional media channels authoritarian regimes particular may benefit information landscape objective truth becomes devalued truth whatever authorities claim moreover automated natural language multimedia production allow systems produce messages targeted susceptible extension existing seymour tully everett shao chung jamaludin zisserman browne adams serban security domainsadvertising practices public social media profiles already reasonably predictive personality details may usable predict psychological conditions like depression sophisticated systems might allow groups target precisely right message precisely right time order maximize persuasive potential technology sinister applied voting intention pernicious applied recruitment terrorist acts example even without advanced techniques digital gerrymandering forms advertising might shape elections ways undermine democratic process entrenched position authoritarian regimes offers additional mechanisms control unlikely easily available democracies systems enable surveillance efficient scale existing systems able gather data citizens efficiently using data costly many authoritarian regimes systems improve ability prioritise attention example using network analysis identify current potential leaders subversive groups also reduce cost monitoring individuals example using systems identify salient video clips bring attention human agents furthermore point overlap political physical security since robotic systems could also allow highly resourced groups enforce greater degree compliance unwilling populations information ecosystem enables political manipulation control filtering content available users authoritarian regimes could done state private parties operating rules directions issued state democracies state may limited legal authority shape influence information content technical tools still exist simply reside hands corporations even without resorting outright censorship media platforms could still manipulate public opinion promoting certain content example alphabet executive chairman eric schmidt recently stated google would content produced russia today sputnik facebook manipulated newsfeeds half million users order alter emotional content users posts albeit modestly tools could used help filter malicious content fake news also could used media platforms manipulate public opinion finally threats digital physical security described previous sections may also worrying implications political security hacking clinton campaign presidential election recent example successful quercia kosinski roff horowitz bbc reuters tom stocky griffith manjoo goel kramer verma roff choudhury choudhury security domainscyberattacks cause political disruption disruptive potential physical attacks assassinations acts terror even clearer threats digital physical security might either undermine existing political institutions allow justify move toward authoritarian policies points control existing countermeasures several measures already development deployed area though none yet definitively addressed problems highlight relevant efforts emphasize proposals oriented towards protection healthy public discourse democracies preventing authoritarian governments making full use seems even daunting challenge technical tools technical measures development detecting forgeries social media bots likewise use certified authenticity images videos ability prove video broadcast live rather synthesized offline valuable levers ensuring media fact produced relevant person organization untampered transit analogous measures developed authentication images rather videos naveh tromer automated fake news detection likewise subject ongoing research well competition fake news challenge expected spur innovation area yet however detection misleading news images unsolved problem pace innovation generating apparently authentic multimedia text rapid pervasive use security measures encryption generally useful measure ensuring security information transmissions actively used many companies organizations part prevent sorts risks discussed use citizens data intelligence agencies takes various forms actively debated especially wake snowden revelations general interventions improve discourse various proposals increase quality discourse public private spheres including longstanding ones better education teaching critical thinking skills well newer ones ranging tools tracking political campaigning social media targets policy proposals apps encouraging constructive dialogue kashyap avino varol rahman clarke shu zubiaga fake news challenge competition aimed fostering development tools help human fact checkers combat fake news sunstein ixy targets software service informs citizens extent targeted dark advertising campaigns security domainsmedia platforms always news sources varying impartiality online sources better reputations others yet entirely stopped spread fake news likewise people aware existence ponzi schemes scam emails misleading sales tactics etc yet victims still found part reason spam less problem today otherwise could owners key platforms email servers deployed sophisticated spam filters generally technology companies social media websites media organizations critical points control stemming tide increasingly automated disinformation censorship persuasion campaigns additionally organizations unique datasets useful developing systems detecting threats ability control access pursue strategies preventing malicious uses platforms imposing strong barriers entry use one offline identity limiting rate accounts disseminate information media platforms corporations public discourse transparency potentially regulation important mechanisms ensuring use powerful tools aligns public interest development occurred process writing report illustrative late saw rise deepfakes application algorithms among applications adult videos videos first began appearing masse reddit fora clearly labeled fictitious realism deepfakes early sign potential decline seeing believing discussed substantial media coverage deepfakes reddit online websites including adult content websites began crack discussion propagation technique efforts fully successful illustrate critical role technology platforms governing information access likely deepfakes crackdown least somewhat slowed dissemination tool products least amongst less sophisticated lapowsky interventions identify wide range potential responses challenges raised well large number areas investigation section first makes several initial recommendations researchers policymakers others suggest specific priority areas research investigation analysis could develop refine potential interventions reduce risks posed malicious use due exploratory nature report primary aim draw attention areas potential interventions believe subject investigation rather make highly specific technical policy proposals may viable structure section inclusion appendix additional exploratory material informed perspective interventions recommendations subsection present four recommendations focused strengthening dialog technical researchers policymakers stakeholders following subsection turn attention concrete priority areas technical work well associated research questions first pair recommendations arise fact issues raised report combine technical nontechnical considerations social economic military considerations concerns raised workshop development viable appropriate responses issues may hampered two factors first lack deep technical understanding part policymakers potentially leading regulatory legislative policy responses second reluctance part technical researchers engage topics concern association malicious use would tarnish reputation field perhaps lead reduced funding premature regulation first two recommendations aim preempting dynamic recommendation policymakers collaborate closely technical researchers investigate prevent mitigate potential malicious uses must include policymakers taking seriously responsibility avoid implementing measures interfere impede research progress unless measures likely bring commensurate benefits close collaboration technical experts also ensures policy responses informed technical realities technologies hand recommendation researchers engineers artificial intelligence take nature work seriously allowing considerations influence research priorities norms proactively reaching relevant actors harmful applications foreseeable given technology believe important researchers consider responsibility take whatever steps help promote beneficial uses technology prevent harmful uses example steps could include engaging policymakers provide expertise considering potential applications different research projects deciding work recognize appreciate many researchers including technical experts took part workshop contributed report related initiatives already outstanding work along lines introductory resources policymakers interested domain increasingly becoming available generally buchanan taylor specifically security cnas example policymaking domain surfaced several difficulties european union general data protection regulation example policy hard interpret apply context current machine learning algorithms goodman flaxman work partnership white house series workshops beneficial conference asilomar conference series organization examples contributions technical experts substantial valuable interventions also make two recommendations laying aims believe broader community including technical policy professionals work towards recommendation best practices identified research areas mature methods addressing dualuse concerns computer security imported applicable case example best practice workshop participants considered clearly valuable introduce contexts extensive use red teaming see priority research area details recommendation actively seek expand range stakeholders domain experts involved discussions challenges could include reaching sectors like civil society national security experts unengaged cybersecurity researchers businesses incorporating products ethicists general public others ensure relevant stakeholders included relevant experts consulted nature many malicious uses outlined report related legitimate uses cases difference legitimate illegitimate uses could one degree ensuring appropriate safeguards malicious use example surveillance tools used catch terrorists oppress ordinary citizens information content filters could used bury fake news manipulate public opinion governments powerful private actors access many tools could use public good harm public dialogue appropriate uses technology critical four recommendations help foster crossdisciplinary dialogue among researchers policymakers relevant stakeholders ensure technology used benefit society priority areas research section lays specific topic areas recommend investigated aim brevity specific questions investigation along additional context commentary many topics mentioned may found appendix computer security red teaming involves red team composed security experts members host organization deliberately planning carrying attacks systems practices organization limitations prevent lasting damage optional blue team responding attacks exercises explore actual attack might look like order better understand ultimately improve security organisation systems practices expect adaptive defensive actions required everyday citizens terms maintaining awareness threats adopting best practices important acknowledge different communities varying abilities make adaptations depending example technological literacy may pose challenges implementing security policies important communities less able adapt new threats also society broadly example insecure systems may compromised attackers repurposed provide computing power data attacks reducing possibility attacks could attributed would seem originate compromised interventions priority research area learning cybersecurity community systems become widespread capable potential impacts cybersecurity incidents growing commensurately summarize considerations digital security section important cybersecurity three reasons first increased automation brings increased digital control physical systems consider example much control successful hacker could exercise modern car compared typical car years ago second successful attacks systems also give attacker access algorithms trained models used system consider example theft datasets used facial recognition social networks compromise algorithm used analysing satellite imagery third increasing use cyberattacks likely allow highly sophisticated attacks carried much larger scale may reach victims would otherwise suitable targets previous waves sophisticated attacks respond increased dangers cybersecurity must major ongoing priority efforts prevent mitigate harms systems best practices cybersecurity must ported wherever applicable systems examples believe subject research analysis implemented appropriate see appendix commentary questions include red teaming extensive use red teaming discover fix potential security vulnerabilities safety issues priority developers especially critical systems formal verification extent circumstances types architectures formal verification used prove key properties systems approaches developed achieve similar goals different means responsible disclosure vulnerabilities procedures established enable confidential reporting vulnerabilities discovered systems including security vulnerabilities potential adversarial inputs types exploits already possible security exploits modern software systems forecasting capabilities could efforts predict advances enable effective darpa assured autonomy program neema one attempt developing techniques assure safety systems continue learning throughout lifespans makes assurance verification using traditional methods challenging see also katz selsam liang dill carlini example see case hackers first bringing jeep standstill busy highway later developing ability cause unintended acceleration fully control vehicle steering greenberg interventions cyberattacks rigorous tracking progress proliferation general allow effective preparations defenders security tools tools developed distributed help make standard test common security problems systems analogously tools used computer security professionals secure hardware could security features incorporated hardware example prevent copying restrict access facilitate activity audits similar technically practically feasible design adoption hardware properties like priority research area exploring different openness models today prevailing norms machine learning research community strongly point towards openness large fraction novel research published online papers share anything rough architectural outlines algorithmic details source code level openness clear benefits terms enabling researchers build others work promoting collaboration allowing theoretical progress incorporated broad array applications however potential misuses technology surveyed scenarios security domains sections suggest downside openly sharing new capabilities algorithms default increases power tools available malicious actors raises important research question might appropriate abstain merely delay publishing findings related security reasons precedent fields computer security exploits could affect important systems publicly disclosed developers opportunity fix vulnerability extent research results withheld today usually reasons related intellectual property order avoid future result scooped light risks laid elsewhere report may also arguments based public interest additional caution least cases proposals consider decreasing openness certain situations stress clear reasons favor openness research communities believe policies leading decreased openness potentially eckersley nasser interventions appropriate certain instances sensitive benefits rather propose specific solution aim foster discussion whether considerations open sharing might outweigh considerations favor mechanisms might enable potential mechanisms models could subject investigation analysis see appendix commentary questions include risk assessment technical areas special concern types research results work specifically related digital security adversarial machine learning subject kind risk assessment determine level openness appropriate norm research areas biotechnology computer security would measures premature today systems widely used critical systems better knowledge technical research measures considered premature conditions would appropriate central access licensing models could emerging central access commercial structures customers use services like sentiment analysis image recognition made available central provider without access technical details system provide template sharing model allows widespread use given capability reducing possibility malicious use might model remain viable time advances processing power data storage availability embedded expertise allow larger set actors use tools sharing regimes favor safety security could arrangements made types research results selectively shared among predetermined set people organizations meet certain criteria effective information security adherence appropriate ethical norms example certain forms offensive cybersecurity research leverage might shared trusted organizations vulnerability discovery purposes would harmful widely distributed norms institutions applied dualuse technologies learned models methodologies considerations cautions arisen tackling similar issues raised technologies accordingly concerns misuse used excuse reduce openness greater extent required instance real motivation corporate competitiveness believe extent practices around openness rethought done transparently new approaches incorporated research publication processes domains responsible disclosure state reasons publicly range stakeholders evaluate claims debate biosecurity community appropriate level disclosure research organisms made dangerous order understand certain threats better provides model kind discussion see healthy see ndss interventions priority research area promoting culture responsibility researchers organizations employ unique position shape security landscape aienabled world many community already take social responsibility quite seriously encourage others continued developed greater leveraging insights experiences technical fields greater attentiveness malicious use risks particular throughout training recruitment research development individuals institutions mindful risks malicious uses capabilities initial areas explore concrete initiatives aimed fostering culture responsibility include education formal informal methods educating scientists engineers ethical socially responsible use technology effective could training best incorporated education researchers ethical statements standards role ethical statements standards play research implemented enforced ethical questions areas digital physical security need resolved order distinguish benign malicious uses whistleblowing measures track record whistleblowing protections domains might used preventing misuse risks nuanced narratives generally succinct compelling narratives research impacts balance optimism vast potential technology recognition risks poses examples existing narratives include robot apocalypse trope countervailing automation boon trope obvious shortcomings might narrative like proposed productive two examples proposed standards ieee global initiative ethical considerations artificial intelligence autonomous systems ieee standards association development asilomar principles future life institute see appendix commentary questions interventions priority research area developing technological policy solutions addition creating new security challenges threats progress also makes possible new types responses defenses technological solutions must accompanied supported policy responses addition proposals mentioned previous sections potential approaches institutional technological could help prevent mitigate potential misuse technologies initial suggested areas investigation include privacy protection role technical measures play protecting privacy bad actors world role must played institutions whether corporations state others coordinated use security defensive security measures distributed widely nudge balance direction defense via institutions mechanisms technologies promoted shared monitoring resources circumstances resources might feasible appropriate monitor inputs technologies hardware talent code data legislative regulatory responses potential interventions policymakers would productive space adjusting legal definitions hacking account case adversarial examples data poisoning attacks necessary incentivize individuals organizations relevant expertise pursue investigations initial step pursued report raise awareness issues importance lay initial research agenda steps require commitment individuals organizations relevant expertise proven track record additional monetary resources public private would also help seed interest recruit attention relevant research communities example could systems used refactor existing code bases new software adhere closely principle least authority miller security best practices see appendix commentary questions considered together characteristics various intervention measures surveyed implemented combine shape future security confident prediction impossible make significant uncertainties remain regarding progress various technologies strategies adopted malicious actors steps taken key stakeholders nonetheless aim elucidate crucial considerations giving confident answer make several hypotheses equilibrium attack defense mean time period years malicious applications widely used defended yet progressed sufficiently fully obviate need human input either attack defense analysis strategic analysis even seemingly stable predictable equilibrium resulting foreseeable developments might since technological policy factors progress beyond currently foreseen new developments including technological developments unrelated may ultimately impactful capabilities considered report nevertheless hope analysis sheds light key factors watch influence years come factors affecting equilibrium security attacker access capabilities current trends emphasize widespread open access research development achievements trends continue next years expect ability attackers cause harm digital robotic systems significantly increase follows directly nature efficiency scalability ease diffusing technologies discussed previously however expect nature technology become increasingly apparent developers regulators limitations access malicious use powerful technologies increasingly imposed however significant uncertainty remains effectiveness attempting restrict monitor access particular intervention preemptive design efforts use novel organizational technological measures within international policing help likely emerge various stages response hopefully reports otherwise aftermath significant attack scandal efforts prevent malicious uses solely limiting code proliferation unlikely succeed fully due compliance sufficiently motivated well resourced actors use espionage obtain code however risk less capable actors using likely reduced combination interventions aimed making systems secure responsibly disclosing developments could misused increasing threat awareness among policymakers existence defenses characteristics enable attacks also allow scalable defenses specific instances strategic analysis defenses discussed earlier sections spam filters malware detection expect many others developed coming years example context physical security use drones whose sole purpose quickly catch bring ground drones might invented widely deployed might also turn prohibitively expensive might foreseeable defenses thus pace technical innovation cost defenses considered fuller assessment one general category defenses worth considering overall assessment use criminal investigations counterterrorism already beginning see wider adoption wide range law enforcement purposes facial recognition surveillance cameras social network analysis hardly seen end advancements developments underlying technologies widespread use seem likely given interest actors corporations governments preventing criminal acts additionally interceding attacks early stage rapid detection response may turn cheaper example widely deploying physical defenses drones thus growing ability states detect stop criminal acts part leveraging key variable however advances help prevent authoritarian abuses distribution generality defenses defensive measures discussed interventions appendix taken single internally coordinated actors research labs tech startups likely happen soon become technically feasible measures could used organizations lose attacks governments major corporations means massive category harm attack wmd facilities also least likely though level risk depend relative rates attacks defenses developed responsible disclosure novel vulnerabilities risk assessment strong ethical culture community generally vital world however leaves strategic situation majority potential victims technologically conservative corporations states smes individuals potential victims defensive measures need baked widespread technology may require coordinated regulatory efforts strategic analysis offered low prices latter likely come either tech giants case spam filters increase concentration data power organizations develop distribute defensive measures freely cheaply mozilla firefox web browser dynamic defense reliance fortified software platforms likely affected generality defensive measures attack requires tailored defense associated higher time lag skill investment likely developing defensive measures need financial backing corporations investors philanthropists governments case governments international competition may hinder development release defensive measures generally case though see release cyberchef assemblyline counterexamples political security similar considerations regarding generality apply general solution authenticable multimedia production forgery detection would useful tailored individual solutions photographs videos audio narrower subsets media types misaligned incentives also lead failure employ available defensive measures example better cybersecurity defenses could raise bar data breaches creation iot device botnets however individuals affected failures individuals whose personal data released victims ddos attacks using botnets typically position improve defenses directly thus approaches including regulation may needed adjust incentives otherwise address externalities overall assessment range plausible outcomes extremely diverse even without considering outcomes less likely still possible across plausible outcomes anticipate attempts use maliciously increase alongside increase use across society generally trend particular anticipate increased malicious use criminals terrorists authoritarian regimes use electricity software computer networks point technology adoption cycle becomes easier make use general purpose technologies avoid optimistic side several trends look positive defense much low hanging fruit picked securing systems gchq cse moore anderson strategic analysis securing people systems attacks examples include responsible vulnerability disclosure machine learning cases affected technology used critical systems greater efforts leverage expertise discovery vulnerabilities software companies internally discovered adversaries substantial academic incentives tackle hardest research problems developing methods address adversarial examples providing provable guarantees system properties behaviors least parts world political incentives developing processes regulations reduce threat levels increase stability consumer protection standardization finally incentives tech giants collaborate ensuring least minimal level security users solutions visible require limited coordination align existing incentive structures defenses likely prevail pessimistic side threats identified solutions characteristics likely prove much harder secure humans manipulation attacks secure digital systems cyber attacks scenarios three attack vectors may combined absence significant effort attribution attacks penalization attackers likely difficult could lead ongoing state attacks eroded trust within societies societies governments governments whichever vectors attack prove hardest defend ones likely weaponized governments proliferation offensive capability likely broad since number possible attack surfaces vast cutting edge capability likely ever progressing equilibrium obtained rival states criminals security forces particular domain likely technology policies evolve tech giants media giants may continue become technological safe havens masses access relevant data massive scale ownership products communication channels along underlying technical infrastructure place highly privileged position offer tailored protection customers corporate giants offer products services automotive medical defense increasingly many sectors likely pressure follow suit would represent continuation existing trends people regularly interact use platforms provided tech media giants interact less frequently small businesses governments strategic analysis nations pressure protect citizens political stability face malicious uses could occur direct control digital communication infrastructure meaningful constructive collaboration government private entities controlling infrastructure informed enforceable regulation coupled financial incentives liability structures countries clear head start establishing control mechanisms enable provide security citizens challenging coordination interdisciplinary problems new leadership required rise local incentives provide systemic vision first time humanity risen meet challenge nato conference garmisch created consensus around growing risks software systems sketched technical procedural solutions address critical infrastructure software resulting many practices mainstream software engineering nih conference asilomar highlighted emerging risks recombinant dna research promoted moratorium certain types experiments initiated research novel streams biological containment alongside regulatory framework research could feed individuals forefront research played key roles cases including edsger dijkstra former paul berg latter remain many disagreements report let alone amongst various expert communities world many disagreements resolved get data various threats responses unfold uncertainty expert disagreement paralyse taking precautionary action today recommendations stated acted today analyzing appropriate experimenting novel openness models learning experience scientific disciplines beginning dialogues risks particular domains accelerating beneficial research myriad promising chessen naur randell krimsky wright dijkstra berg example france campaign laws prohibited macron opponent campaigning macron emails hacked prevented campaign capitalizing leaks associated hack ended hack playing much muted role french election clinton hack played conclusion many uncertainties remain clear figure prominently security landscape future opportunities malicious use abound done artificial intelligence digital security physical security political security deeply connected likely become cyber domain even current capability levels used augment attacks defenses cyberinfrastructure introduction society changes attack surface hackers target demonstrated examples automated spear phishing malware detection tools discussed systems increase capability first reach exceed human capabilities many narrow domains already seen games like backgammon chess jeopardy dota seeing important human tasks conclusionlike investing stock market driving cars preparing potential malicious uses associated transition urgent task systems extend domains commonly believed uniquely human like social interaction see sophisticated social engineering attacks drawing capabilities difficult defend even cybersecurity experts fall prey targeted spear phishing emails may cause explosion network penetrations personal data theft epidemic intelligent computer viruses one best hopes defend automated hacking also via automation systems indeed companies increasingly pursuing strategy defense panacea especially look beyond digital domain work also done understanding right balance openness developing improved technical measures formally verifying robustness systems ensuring policy frameworks developed less world adapt new world creating looking longer term much published problems might arise accidentally result highly sophisticated systems capable operating high levels across wide range environments though capabilities fall short today given intelligence systems deployed range goals highly capable systems require little expertise develop deploy may eventually given new dangerous goals hacking developing novo may see powerful systems add goals property depending whose bidding systems advanced ais may inflict unprecedented types scales damage certain domains requiring preparedness begin today potent misuse potentials realizable researchers policymakers learn domains longer experience preventing mitigating malicious use develop tools policies norms appropriate applications though specific risks malicious use across digital physical political domains myriad believe understanding commonalities across landscape including role enabling numerous attacks helpful illuminating world ahead informing better prevention mitigation efforts urge readers consider ways might able advance collective understanding nexus join dialogue ensuring rapid development proceeds safely fairly also bostrom amodei olah bostrom malicious use artificial intelligencewe extremely grateful many researchers practitioners provided useful comments earlier versions document engaged helpful conversations related topics given number coauthors related conversations surely forget people among others thank ian goodfellow ross anderson nicholas papernot martín abadi tim hwang laura pomarius tanya singh kasewa smitha milli itzik kotler andrew trask siddharth garg martina kunz jade leung katherine fletcher jan leike toby ord nick bostrom owen eric drexler julius weitzdorfer emma bates subbarao kambhampati remaining errors responsibility authors work supported part grant future life institute acknowledgementsacknowledgements malicious use artificial intelligence abadi chu goodfellow mcmahan mironov talwar zhang deep learning differential privacy proceedings acm sigsac conference computer communications security ccs acm new york usa ablon bogart zero days thousands nights life times vulnerabilities exploits rand corporation abokhodair yoo mcdonald dissecting social botnet growth content influence twitter proceedings acm conference computer supported cooperative work social computing adams social bots arxiv preprint server aday farrell lynch sides freelon blogs bullets new media conflict arab spring united states institute peace aker kalkan using deep networks drone detection arxiv preprint server allen chan artificial intelligence national security harvard kennedy school belfer center science international affairs amodei olah concrete problems safety arxiv preprint server anderson woodbridge filar deepdga domain generation detection arxiv preprint server anderson kharkar filar evans roth learning evade static machine learning malware models via reinforcement learning arxiv preprint server arulkumaran deisenroth brundage bharath deep reinforcement learning brief survey ieee signal processing magazine vol issue november baier katoen principles model checking cambridge mit press barberá jost nagler tucker bonneau tweeting left right online political communication echo chamber psychological science vol issue barreno nelson joseph tygar security machine learning machine learning pages available online pdf bass scientists gather plot doomsday scenarios solutions bloomberg march bastani kim bastani interpreting blackbox models via model extraction arxiv preprint server bbc google russia today sputnik november berg baltimore boyer cohen davis hogness nathans roblin watson weissman zinder potential biohazards recombinant dna molecules science berger morgan isis twitter census defining describing population isis supporters twitter brookings institution beurdouche bhargavan fournet kohlweiss pironti strub zinzindohoue messy state union taming composite state machines tls communications acm vol issue february biggio nelson laskov poisoning attacks support vector machines international conference machine learning icml pages blanchet cryptoverif security protocol verifier blum neural fuzzing applying dnn software security testing microsoft research blog booth tompkin gajos waldo pfister nagpal piggybacking robots overtrust university dormitory security hri available bostrom superintelligence paths dangers strategies oxford oxford university press referencesreferences malicious use artificial intelligence referencestechnologies cnas artificial intelligence global security summit centre new american security cohen israel shoots hamas drone gaza strip haaretz cooper licensing approach regulation open robotics paper presented robot april crawford calo blind spot research nature october crootof killer robots legal policy implications crootof renz opportunity change conversation autonomous weapon systems lawfare cse assemblyline october cummings creating moral buffers weapon control interface design ieee technology society magazine fall cylance black hat attendees see sword cylance team available avino cozzolino poggi verdoliva autoencoder recurrent neural networks video forgery detection arxiv preprint available dao james drone pilots found get stress disorders much combat new york times february darpa cyber grand challenge www choudhury counts horvitz social media measurement tool depression populations proceedings annual acm web science conference department defense dod directive autonomy weapon systems department defense department defense law war manual dijkstra letters editor statement considered harmful communications acm big data meets big brother china moves rate citizens wired october browne youtube removes videos showing atrocities syria new york times august brynjolfsson mcafee second machine age work progress prosperity time brilliant machines new york norton company bryson diamantis grant people legal lacuna synthetic persons artificial intelligence law vol issue september buchanan taylor machine learning policymakers paper cyber security project belfer center bueno mesquita smith dictator handbook bad behavior almost always good politics new york publicaffairs calabresi inside russia social media war america time may calo open robotics maryland law review vol calo robotics lessons cyberlaw california law review vol carbon black beyond hype security experts weigh artificial intelligence machine learning nonmalware attacks carlini mishra vaidya zhang sherr shields wagner zhou hidden voice commands usenix security symposium chessen policy landscape medium chessen madcom future atlantic council report chung jamaludin zisserman said arxiv preprint server clarke morell stone sunstein swire liberty security changing world president review group intelligence communications malicious use artificial intelligence referencesfarquhar pricing externalities balance public risks benefits research health security pages available online filar seymour park ask anything conversational interface augment information security workers symposium usable privacy security soups fisher using formal methods enable secure vehicles darpa hacms program icfp proceedings acm sigplan international conference functional programming cfm flashpoint ransomware service inside organized russian ransomware campaign registration required download available flashpoint library franke flying ieds next big threat war rocks blog fredrikson jha ristenpart model inversion attacks exploit confidence information basic countermeasures proceedings acm sigsac conference computer communications security acm available future life institute asilomar principles text signatories available online garfinkel forthcoming recent advances cryptography possible consequences gchq cyberchef cyber swiss army knife december giaretta dragoni community targeted spam middle ground general spam spear phishing arxiv preprint server goel facebook tinkers users emotions news feed experiment stirring outcry new york times june goodfellow mirza wardefarley ozair courville bengio generative adversarial networks advances neural information processing systems available goodman flaxman european union regulations algorithmic right explanation arxiv preprint krueger bengio nice independent components estimation iclr workshop paper dowlin laine lauter naehrig wernsing cryptonets applying neural networks encrypted data high throughput accuracy proceedings international conference machine learning available online dvorsky hackers already started weaponize artificial intelligence gizmodo dwork naor pricing via processing combatting junk mail brickell eds advances cryptology crypto crypto lecture notes computer science vol berlin springer dwork differential privacy proceedings international colloquium automata languages programming part icalp available online eckersley nasser help eff track progress machine learning electronic frontier foundation eff unintended consequences years dmca electronic frontier foundation part series avalable evans gao deepmind reduces google data centre cooling bill deepmind blog july everett nurse erola anatomy online deception makes automated text convincing symposium applied computing sac everitt krakovna orseau hutter legg reinforcement learning corrupted reward channel available online evtimov eykholt fernandes kohno prakash rahmati song robust physicalworld attacks deep learning models arxiv preprint server executive office president national science technology council committee technology preparing future artificial intelligence october malicious use artificial intelligence referenceshorowitz want artificially intelligent weapons isis democracies autocracies bulletin atomic scientists hosseini xiao poovendran google cloud vision api robust noise arxiv preprint server herley plight targeted attacker world scale workshop economics information security ieee standards association ieee global initiative ethical considerations artificial intelligence autonomous systems ifr world robotics international committee red cross expert meeting lethal autonomous weapon systems ixy ixy conflict free app jaderberg mnih czarnecki schaul leibo silver kavukcuoglu reinforcement learning unsupervised auxiliary tasks arxiv preprint server lipton elkan differential privacy machine learning survey review arxiv preprint jones mattiacci manifesto characters fewer social media tool rebel diplomacy british journal political science jordan mitchell machine learning trends perspectives prospects science vol issue doi karras aila laine lehtinen progressive growing gans improved quality stability variation available online kashyap parmar agarwal gupta evaluation digital image forgery detection approaches arxiv preprint server katz barrett dill julian kochenderfer reluplex efficient smt solver verifying deep neural networks arxiv preprint available garg badnets identifying vulnerabilities machine learning supply chain arxiv preprint available guilbeault woolley twitter bots shaping election atlantic november grace salvatier dafoe zhang evans exceed human performance evidence experts arxiv preprint server greenberg jeep hackers back prove car hacking get much worse wired january available online greenemeier gps world first space war scientific american february griffith facebook absolutely control algorithm wired september grosse papernot manoharan backes mcdaniel adversarial perturbations deep neural networks malware classification arxiv preprint available online harrison john formal methods intel overview second nasa formal methods symposium available pdf harris governance technologies theory practice american academy arts sciences cambridge available online hawkes rebecca stress disorder higher drone operators telegraph may measure minds evaluating natural artificial intelligence cambridge university press see details hester vecerik pietquin lanctot schaul piot sendonaris osband agapiou leibo deep demonstrations arxiv preprint server hicks hunter samp coll assessing third offset strategy center strategic international studies hilary gilles professionalization cyber crime insead business school blog malicious use artificial intelligence referenceslaurie clayton proves work version workshop economics information security libicki cyberspace peace war annapolis naval institute press lin singer come see china new hexacopters drones popular science lindell pinkas secure multiparty computation data mining journal privacy confidentiality vol cgi liu camp proof work work weis liu tuzel coupled generative adversarial networks proceedings neural information processing systems nips preprint available online lucas world biggest drone maker dji eyes move commercial applications financial times august available online manjoo farhad facebook fix worst bug new york times magazine april marwick lewis media manipulation disinformation online pdf mcafee center strategic international studies economic impact cybercrime cyber espionage mcafee center strategic international studies hacking skills shortage metz google says catches percent gmail spam wired july miller robust composition towards unified approach access control concurrency control phd dissertation mnih kavukcuoglu silver rusu veness bellemare graves riedmiller fidjeland ostrovski petersen control deep reinforcement learning nature mukhoty arya mehta model extraction warning mlaas paradigm arxiv preprint server kharkar simecek evans anderson approaches evading windows malware classifiers usenix security king pan roberts chinese government fabricates social media posts strategic distraction engaged argument american political science review vol issue august kirkpatrick battling algorithmic bias communications acm vol knight fight club could help save future cyberattacks mit technology review available online september associated competition information found koh liang understanding predictions via influence functions proceedings icml available online kolodny marble yelp start robot food delivery san francisco techcrunch korzak gge cybersecurity end era diplomat kosinski stillwell graepel private traits attributes predictable digital records human behavior proceedings national academy sciences united states america vol kramer guillory hancock experimental evidence emotional contagion social networks pnas vol june krimsky genetic alchemy social history recombinant dna controversy press cambridge lapowsky eight revealing moments second day russia hearings wired november malicious use artificial intelligence referencespapernot mcdaniel goodfellow jha celik swami practical attacks deep learning systems using adversarial examples arxiv preprint server pellerin deputy secretary third offset bolsters america military deterrence dod news kleinberg lefevre mihalcea automatic detection fake news arxiv preprint server quercia kosinski stillwell crowcroft twitter profiles selves predicting personality twitter ieee third international conference privacy security risk trust ieee third international conference social computing radford metz chintala unsupervised representation learning deep convolutional generative adversarial networks arxiv preprint server rahman azimpourkivi topkara carbunar video liveness citizen journalism attacks defenses ieee transactions mobile computing vol issue reuters facebook changing news feed algorithm fortune june rød weidmann empowering activists autocrats internet authoritarian regimes journal peace research vol issue roff autonomy robotics collective systems project webpage available roff meaningful human control artificial intelligence autonomous weapons briefing paper delegates convention certain conventional weapons ccw meeting experts lethal autonomous weapons systems laws roff autonomous weapons incentives oppression duck minerva available rouhani riazi koushanfar deepsecure scalable deep learning arxiv preprint server anderson internet security peitz waldfogel eds oxford handbook digital economy oxford university press new york morozov net delusion dark side internet freedom new york publicaffairs mouawad risk aircraft drones debated new york times december naur randell software engineering report conference sponsored nato science committee garmisch germany october nato national science foundation systems grant solicitation jsp naveh tromer photoproof cryptographic image authentication set permissible transformations ieee symposium security privacy ndss ndss call papers network distributed system security symposium neema assured autonomy politics rumours ambiguity tracking censorship wechat public accounts platform available office cyber infrastructure analysis narrative analysis artificial intelligence department homeland security national protection programs directorate available openai dota openai blog openai dota openai blog openmined openmined website papernot mcdaniel sinha wellman towards science security privacy machine learning available online papernot goodfellow sheatsley feinman mcdaniel cleverhans adversarial machine learning library arxiv preprint server available associated github repository available malicious use artificial intelligence referencesshehadeh wassenaar arrangement encryption exports ineffective export control regime compromises united states economic interests int silver huang maddison guez sifre van den driessche schrittweiser antonoglu paneershelvam lanctot dieleman grewe nham kalchbrenner sutskever lillicrap leach kavukcuoglu graepel hassabis mastering game deep neural networks tree search nature silver schrittweiser simonyan antonoglu huang guez hubert baker lai bolton chen lillicrap hui sifre van den driessche graepel hassabis mastering game without human knowledge nature october shokri stronati shmatikov membership inference attacks machine learning models corr vol available shu wang sliva tang liu fake news detection social media data mining perspective arxiv preprint singer wired war robotics revolution conflict century london penguin press šrndic laskov practical evasion classifier case study proceedings ieee symposium security privacy ieee computer society stevens suciu ruef hong hicks dumitras summoning demons pursuit exploitable bugs machine learning proceedings neural information processing systems reliable machine learning wild workshop stocky facebook post may stoica song popa patterson mahoney katz joseph jordan hellerstein gonzalez goldberg ghodsi culler abbeel berkeley view systems challenges technical report solomon witnessing isis drone attack new york times sunstein republic divided democracy age social media princeton princeton university press standage taking flight economist nelson huang joseph lau rao taft tygar antidote understanding defending poisoning anomaly detectors proceedings acm sigcomm conference internet measurement scharre guide defeating robotic swarms war rocks blog scharre autonomous weapons operational risk center new american security scharre army none autonomous weapons future war new york norton forthcoming schmitt pentagon tests lasers nets combat vexing foe isis drones new york times september available schofield napoleon semaphore telegraph changed world bbc june schneier internet things wildly insecure often unpatchable wired schneier security internet things schneier security segler preuß waller towards alphachem chemical synthesis planning tree search deep neural network policies arxiv preprint server selsam liang dill developing machine learning systems formal mathematics arxiv preprint server serban sankar germain zhang lin subramanian kim pieper chandar rajeshwar brebisson sotelo suhubdy michalski nguyen pineau bengio deep reinforcement learning chatbot seymour tully weaponizing data science social engineering automated spear phishing twitter black hat conference shao ciampaglia varol flammini menczer spread fake news social bots arxiv preprint server malicious use artificial intelligence referenceswaltzmann weaponization information need cognitive security testimony presented senate armed services committee subcommittee cybersecurity april watts disinformation primer russian active measures influence campaigns statement prepared senate select committee intelligence march weedon nuland stamos information operations facebook facebook wiggers meet robots soon patrol parking lots offices malls digital trends woolley howard computational propaganda worldwide executive summary working paper oxford project computational propaganda please prove robot new york times july wright molecular politics developing american british regulatory policy genetic engineering university chicago press chicago yampolskiy future cybersecurity better worse harvard business review may yao protocols secure computations annual symposium foundations computer science sfcs chicago usa jsp yin game drones defending drone terrorism texas university law review vol zeitzoff social media changing conflict journal conflict resolution zittrain facebook could decide election without anyone ever finding new republic june zubiaga aker bontcheva liakata procter detection resolution rumours social media survey arxiv preprint server ahn carson kastenberg making ethics explicit relocating ethics core engineering education asee annual conference szegedy zaremba sutskever bruna erhan goodfellow fergus intriguing properties neural networks arxiv preprint server tambe security game theory algorithms deployed systems lessons learned cambridge cambridge university press telegraph drone hits british airways plane prepares land heathrow telegraph april thies face capture reenactment rgb videos proceedings computer vision pattern recognition timm prominent security researchers academics lawyers demand congress reform cfaa support aaron law electronic frontier foundation tucker innovation dual use security managing risks emerging biological chemical technologies cambridge mit press turing checking large routine report conference high speed automatic calculating machines corrected version available online defense science board dsb task force cyber supply chain report defense science board task force cyber supply chain vanian drone registrations still soaring fortune january verma editorial expression concern correction pnas vol july vezhnevets osindero schaul heess jaderberg silver kavukcuoglu feudal networks hierarchical reinforcement learning arxiv preprint server vincent government crashing drones airplanes see happens verge october wahby howald garg shelat walfish verifiable asics security privacy february miles brundage future humanity institute fhi shahar avin centre study existential risk cser workshop entitled bad actor risks artificial intelligence oxford united kingdom workshop fhi cser leverhulme centre future intelligence cfi participants came wide variety institutional disciplinary backgrounds analyzed variety risks related misuse workshop held chatham house rules event structure february event began background presentations cybersecurity robotics relevant experts appendix workshop details appendix workshop detailsfields particular focus presentations highlighting underexplored risks afternoon featured two sets breakout sessions participants first discussed security domains scenarios discussed possible defenses february subset participants first day workshop met discuss next steps prioritization possible prevention mitigation measures group present agreed upon need research agenda produced voted measures seemed useful tractable order focus subsequent report writing process report writing process document based large part notes discussions workshop well prior subsequent research authors topic brundage avin wrote draft report circulated among attendees workshop well additional domain experts grateful workshop participants invaluable contributions even able capture perspectives list workshop participants dario amodei openai ross anderson university cambridge stuart armstrong future humanity institute amanda askell centre effective altruism shahar avin centre study existential risk miles brundage future humanity institute joanna bryson university university center information technology policy jack clark openai guy collyer organization global biorisk reduction owen future humanity institute rebecca crootof yale law school allan dafoe yale university eric drexler future humanity institute peter eckersley electronic frontier foundation ben garfinkel future humanity institute carrick flynn future humanity institute ulrike franke university oxford dylan berkeley center richard harknett university cincinnati katja hofmann microsoft research tim hwang google appendix workshop detailseva ignatuschtschenko university oxford victoria krakovna life institute ben laurie deepmind jan leike humanity institute seán héigeartaigh centre study existential risk toby ord future humanity institute michael page centre effective altruism heather roff university state university america foundation paul scharre center new american security eden shochat aleph jaan tallinn centre study existential risk helen toner open philanthropy project andrew trask university oxford roman yampolskiy university louisville weng tohoku university appendix gives additional commentary topics related recommendations priority research areas described interventions section main report along initial questions directions investigation topic case flag one three threat factors introduced general implications threat landscape research area aims address include content point researchers interested making progress areas intended exhaustive questions research appendix questions researchdual use analogies case studies one possible area theory practice history explored insights set technologies prominent concerns around dual use technologies used peaceful military aims generally beneficial harmful ends examples include chemicals potentially useful chemical weapons explosives biological engineering potentially useful biological weapons cryptography nuclear technologies allen chan explored several case studies potential insights policymaking cases rich tapestry soft norms review hard laws export controls developed many years ensure positive outcomes consulting history governing dual use technologies learn constructive solutions past successes precautionary lessons poor regulation avoided relevant example latter difficulties regulating cryptographic algorithms network security tools export control measures wassenaar arrangement similarities cryptography terms running hardware terms immaterial objects algorithms terms wide range legitimate applications ability protect well harm suggest default control measures might similar historically applied cryptography may well path avoid least take cautiously apparent nature technologies raises following questions appropriate level analysis governance characteristics technologies field whole individual algorithms hardware software data norms domains applicable unique challenges pose technology exemplary cases concerns effectively addressed lessons learned challenges failures applying control measures technologies allen chan tucker harris shehadeh appendix questions researchred teaming common tool cybersecurity military practice red teaming red team composed security experts members organization deliberately plans carries attacks systems practices organization limitations prevent lasting damage optional blue team responding attacks exercises explore actual attack might look like order ultimately better understand improve security organization systems practices two subsets security domain seem particularly amenable exercises cyber offense defense adversarial machine learning highlight subsets seem especially relevant security red teaming technologies broadly seems generally beneficial addition report associated workshop another recent effort aimed goal also conducted origins project earlier year case cyber attacks many concerns discussed earlier document elsewhere literature hypothetical conducting deliberate red team exercises might useful domain analogous darpa cyber grand challenge across wider range attacks including social engineering vulnerability exploitation beyond memory attacks order better understand skill levels required carry certain attacks defenses well work practice likewise case adversarial machine learning many theoretical papers showing vulnerabilities machine learning systems attack systematic ongoing stresstesting systems begun efforts like cleverhans library benchmarks models step direction creating foundation distributed open source red teaming effort nips adversarial attacks defenses competition analogous darpa cyber grand challenge several open questions regarding use red team strategies mitigating malicious uses lessons learned history date red team exercises possible detect serious vulnerabilities red team exercises surface area attack broad bass papernot knight though see anderson appendix questions responsible conducting exercises could incentivised sorts skills required undermine systems distribution skills extent skills overlap skills required develop deploy systems findings inform threat model used red teaming exercises security analysis mechanisms promote uptake lessons red team exercises mechanisms share lessons red team exercises organizations may susceptible similar attacks avoid disclosure attack methods bad actors challenges opportunities extending red teaming related practices like tabletop exercises issues physical political domains learned physical domain physical penetration testing exercises formal verification formal verification software systems studied decades recent years shown even complex systems amenable formal proofs operate intended including compcert compiler microkernel open question whether systems elements thereof amenable formal verification workshop substantial skepticism prospects formal verification given complexity modern systems analysis challenges required research topic continues apace particular might interested following properties verified given system internal processes fact attain goals specified system though noting existence specification problem desired properties systems often difficult specify advance therefore difficult verify goals remain constant face adversaries attempts change turing baier katoen selsam neema fisher appendix questions ability deceived adversarial inputs bounded extent verifying hardware given increasing complexity systems domains limited theoretical foundations operation may prohibitively expensive even practically theoretically impossible provide verification framework however may feasible use formal methods improve security components systems hardware seems particularly amenable verification formal methods widely adopted hardware industry decades verifying security additionally recent years formal verification applied security protocols provide robust guarantees safety certain types attacks javascript prover cryptoverif example tool allows programmers apply formal methods code check correctness development process noted much work still largely theoretical adoption real world far limited verifying functionality notion able prove system behaves intended attractive one artificial intelligence however formal methods difficult scale arbitrary complex systems due state space explosion problem nonetheless verification aspects systems image classifiers still feasible even verification behavior whole system prohibitively complex example work verification deep neural networks provided method check existence adversarial examples regions input space responsible disclosure discussed despite successes contemporary machine learning algorithms shown time algorithms also vulnerabilities include vulnerabilities inducing misclassification via adversarial harrison wahby katz blanchet though instances real world use see beurdouche appendix questions researchexamples via poisoning training data see barreno survey algorithms also remain open traditional vulnerabilities memory overflow stevens currently great deal interest among researchers understanding security systems though present seem questions answers cybersecurity community software vulnerabilities made publicly known thus defenders zero days prepare attack making use common practice disclose vulnerabilities affected parties publishing widely order provide opportunity patch developed norm community disclose vulnerabilities responsibly affected parties developed algorithms using commercial applications broad question gives rise additional questions research technologies become increasingly integrated products platforms existing security norm around responsible disclosure extend technologies communities systems existing future presumed vulnerable proven secure extent disclosing new vulnerabilities privately unnecessary contexts systems currently used empirical findings would useful informing appropriate disclosure policy analogous way historical trends discoveries exploitation rates discussed cybersecurity analyses norm appropriate broad terms notified case vulnerability found much notice given publication mechanisms institutions create ensure recommendation processed potentially acted upon equivalent patching systems resource demands accuracy robustness noise prioritization amongst variety possible defense measures weighed world rapidly changing attacks defenses szegedy papernot evtimov carlini rubinstein šrndic laskov ablon bogart appendix questions exploit bounties complement norm responsible disclosure vulnerabilities discussed relies social incentives goodwill software vendors offer financial incentives cash bounties anyone detects responsibly discloses vulnerability products emergence new aispecific vulnerabilities questions arise existing vulnerability bounties likely extend technologies expect encourage vendors offer bounties exploits scope offer bounties third parties government ngo philanthropic source cases vendors unwilling unable offer example case popular machine learning frameworks developed projects academia security tools way software development deployment tools evolved include increasing array capabilities testing fuzzing anomaly detection etc could start envisioning tools test improve security components systems integrated components development deployment less amenable attack could include automatic generation adversarial data tools analysing classification errors automatic detection attempts remote model extraction remote vulnerability scanning automatic suggestions improving model robustness see koh liang related ideas see kesarwani appendix questions researchsecure hardware hardware innovation accelerated pace innovation machine learning allowing complex models trained enabling faster execution existing models facilitating rapid iteration possible models cases hardware generic commercial gpus increasingly specifically machine learning systems trained run hardware graphics processing units gpus fully specialized tensor processing units tpus specialization could make much feasible develop distribute secure hardware applications would develop generic secure hardware cause widely used workshop explored potential value adding security features hardware example may possible create secure hardware would prevent copying trained model chip without original copy first deleted feature could desirable total number systems general certain type capability level could tightly controlled capabilities systems would harmful wrong hands diffusion systems could harmful economic social political effects desirable secure hardware features include hardwarelevel access restrictions audits one research trajectory considered developing reference model secure aispecific hardware could used inform hardware engineering ultimately adopted hardware providers may also case potential security threats drive research secure hardware generally hardware running systems response measure changes cyber threat landscape note however potential manufacturers undermine security hardware produce hardware supply chain vulnerabilities currently concern cybersecurity context fear actors control supply chain may introduce hardwarebased vulnerabilities order surveil effectively sabotage systems finally note domains cryptography hardware developed features tamper evidence making clear tampering occurred occurred obscurity layout design prohibitively difficult physically examine workings chip order defeat hardware could potentially valuable outsiders unable defense science board anderson appendix questions researchdiscern inner workings system external emission stolen hardware used duplicate organizations credibly commit operating system safe beneficial way certain software properties chip tampered would break however secure processors tend cost significantly insecure processors knowledge specifically developed purposes many open questions domain specific security requirements systems general different domains application would changes risk landscape surveyed provide sufficient incentive major overhaul hardware security set measures reference implementation would encourage adoption secure hardware measures available ensure compliance hardware safety requirements given international distribution vendors competing incentives cost potential surveillance legal implications auditability applicable existing secure processor designs protection systems tampering secure processors developed could secure enclaves implemented context secure processors made affordable could policy mechanisms devised incentivize use even face cost premium risk assessment technical areas special concern risk assessment mean analyzing particular risks lack thereof particular capability became widely available deciding basis whether extent publish norms already widespread computer security community proofs concept rather fully working exploits often published indeed considerations sufficiently widespread computer security anderson suggested stoica appendix questions researchthat highlighted criteria submission prestigious conferences openness binary variable today many groups publish source code machine learning algorithm without specifying hyperparameters get work effectively reveal details research give details one particular component could part crucial data ingestion transformation pipeline spectrum rough idea pseudocode trained model along source code getting work well practice various possible points perhaps multiple axes see figure generally speaking less one shares higher skill computational requirements another actor recreate given level capability shared reduces risk malicious use also slows research places barriers legitimate applications example potentially abusable capability full publication may deemed risky voice synthesis given target speaker reportedly soon available service company lyrebird ripe potential criminal applications like automated spearphishing see digital security section disinformation see political security section hand case technologies significant potential malicious use could value openness security research example white hat penetration testing described rethinking openness section report clear benefits level openness currently prevalent machine learning field extent restrictions publication would affect benefits carefully considered number restricted publications small biotechnology example may significant concern however restricted publication becomes common case vulnerability disclosure cybersecurity research institutions would need developed balance needs affected parties example responsible disclosure mechanisms cybersecurity allow researchers affected vendors negotiate period time discovered vulnerability patched vulnerability published addition commercial interests vendors security needs users schemes often also protect researchers legal action vendors case one imagine coordinating institutions withhold publication appropriate safety measures means secure deployment developed allowing researchers retain priority claims gain credit work discoveries case see ndss lyrebird next appendix questions research figure schematic illustration relationship openness capability skill required reproduce capability decreasing skill requirement vague description achievementpseudocodesource code trained models tutorials increasing openness appendix questions researchadversarial examples wild may subsumed existing responsible disclosure mechanisms discuss responsible disclosure valuable questions future research related prepublication research assessment include sorts research assessment would researchers willing consider extent would seen conflicting norms around openness learned risk assessment mechanisms domains possible say advance high confidence sorts capabilities ripe abuse sort heuristics may appropriate weighing pros cons opening capabilities assessment incorporated decisionmaking informing one openness choices incorporating analysis publications say anything yet generalizable levels skill computational resources required recreate capabilities given type code pseudocode etc shared information community adopt model absence regulation central access licensing models another potential model openness use call central access licensing model users able access certain capabilities central location collection remotely accessible secure interlinked data centers underlying code shared terms conditions apply use capabilities model increasingly adopted industry services sentiment analysis image recognition place limits malicious use underlying technologies example limitations speed use imposed potentially preventing harmful applications terms conditions explicitly prohibit malicious use allowing clear legal recourse appendix questions researchcentralised access provides alternative publication allows universal access certain capability keeping underlying technological breakthroughs away bad actors though also researchers note though black box model extraction may allow bad actors gain access underlying technology additionally similarly early proposals effect information processing tax emails order disincentivize spam centralized infrastructures better enable constraints placed use services attacks like automated spear phishing could made less economical though see laurie clayton criticism approach liu camp discussion increased interest following success bitcoin may lead advances area finally note concentration services particular set organizations may heighten potential malicious use organizations including acting blessing relevant organization well insider threats indeed workshop attendees considered risks concentration power biggest threat technologies note however report decided focus direct malicious use risks rather systemic threats see scope addition monopolistic behavior subtle risks introduction backdoors machine learning systems users may unaware initial research questions arise related central access licensing model sorts services might one want available basis effectively service provider determine whether uses malicious user determine whether service provider malicious proposal technologically legally politically feasible might object centralised access model grounds enough technology gap actors without access develop technologies independently bastani dwork naor see ghodsi appendix questions potential risks downsides centralised access aggravating political security risks effective black box model extraction different contexts useful limits amount frequency queries models countermeasure model inversion extracting training data model fredrikson forms attack membership inference ascertaining whether certain data contained training data would associated limits cloud providers vet safety security systems without inspecting internal workings information private cloud computing providers sufficiently flexible services allow experimentation required researchers would intervention applicable preventing potentially harmful dissemination trained systems sharing regimes favor safety security one possible approach reducing security risks selectively share certain capability information data trusted parties somewhat analogous approach used cyber domain information sharing analysis centers isacs information sharing analysis organizations isaos companies share information cyber attacks amongst antivirus large tech companies serve points concentration knowledge sharing giving advantages kinds actors case one might imagine arrangement particularly powerful hazardous capabilities ones lend straightforwardly automated hacking shared organizations individuals meet certain criteria established safety security routines agreeing random inspection members group agency group mutually agreed oversight inspection powers approach might valuable facilitating collaborative analysis safety security issues thus getting fraction benefit open source approach even larger number eyes problem reducing shokri appendix questions researchsome risks associated diffusion based analysis concluded harm diffusion capabilities would published several questions arise proposals benefits limitations existing isacs isaos elements models useful sorts criteria might applied organization individual order ascertain trustworthiness deal particularly sensitive information types information might shared amongst group stage developments capabilities evaluated individually latter basis information types limited sharing apply code research papers informal notes sufficient trust established groups kind coordination seen mutually beneficial particular incentives created would make sort collaboration likely instance creation shared cluster test certain kind research potential risks downsides type sharing regime note mechanism partial overlap risk assessment technical areas special concern central access licensing model security ethics social impact education future develope recently discussion role ethics education light ongoing public private discussion potential pitfalls educational efforts might beneficial highlighting risks malicious applications researchers fostering preparedness make decisions burton appendix questions researchtechnologies open designed order mitigate risks yet research impacts educational efforts researchers career development eventual suggesting possible areas research best practices ethics policy education science engineering general applicable especially around mitigating security risks ethics education designed effectively engage interests concerns developers rather seen merely box ticked burden unrelated one practical sometimes occurs domains ought included curriculum ethical methodologies principles theories could curriculum iterated time state security advances would effective providing curriculum ethics educators philosophy disciplines brought better community develop internal capacity teach specific ethics ethics statements standards another way acting ethical concerns could multistakeholder conversation develop ethical standards development deployment systems could signed companies research organizations others deploying systems two examples processes ieee global initiative ethical considerations artificial intelligence autonomous systems development asilomar principles several questions remain open institutional frameworks appropriate ensuring statements standards concerning ethics fully implemented order ensure mere technological greenwash instance community developed standards include statements reporting accountability sunderland ieee standards association future life institute appendix questions companies research organizations statement ethics either taken directly one communal standards developed house particular situation encouraged standards statements kind best way foster conversation ethics alternatives processes appropriate revising updating ethics statements standards order ensure remain flexible incorporate best practice whilst retaining sense permanence objectivity norms framings social incentives noted previous sections substantial security risks associated cases one actor could gain exploiting risks time also substantial upsides progress research development many cases used enhance rather diminish security raises questions like following upsides development framed way galvanize focus mutually beneficial developments discourage harmful exploitation analogous cases lessons learned technology could used thought manner governed way benefited processes allowed govern emergence implementation normative culture beneficial order ensure creation strong enforceable effective norms avoid normative culture used preserve rigid biased norms hamper diversity creativity within sector role diverse normative cultures across fields development safety risk management play allowing diverse range perspectives inform public debates ensuring people consider insiders debates fewer people consider outsiders appendix questions researchtechnologically guaranteed privacy several threats within digital security political security domains automated spear phishing personalised propaganda rely attackers gaining access private information individuals addition procedural legal measures ensure individuals privacy increasing research technological tools guaranteeing user data privacy may also applicable context systems highlight two technologies potentially relevant differential algorithms secure party computation remain open questions regarding technologies algorithmic privacy combined technologies either general specific domains implementing algorithmic privacy terms performance terms financial viability services mechanisms financial educational legal could encourage adoption algorithmic privacy systems lessons learned efforts technologically guaranteed privacy apple use differential privacy differential privacy many machine learning models currently developed companies commercial use apis see central access licensing without precautions possible individuals break anonymity underlying dataset machine learning model deployed public use via model inversion attack membership inference attack even without access training data attacker cases query model way information underlying data set revealed surveyed methods providing differential privacy machine learning systems though address differential privacy neural networks methods reported example abadi general differentially private machine learning algorithms combine training data noise maintain privacy minimizing effects performance generally differentially private algorithms fredrikson shokri concept first developed dwork referring strong guarantees probability information leakage appendix questions researchlose performance compared equivalents privacy may become concern teams developing models incentivized keep datasets private secure computation secure computation mpc refers protocols allow multiple parties jointly compute functions keeping party input function private instance one simple mpc protocol allows users jointly compute outcome vote without sharing individual votes one another important practical application mpc protocols make possible train machine learning systems sensitive data without significantly compromising privacy example medical researchers could train system confidential patient records engaging mpc protocol hospital possesses technology company could similarly learn users data cases without needing access data active open source development effort openmined currently aiming develop platform allow users sell others right train machine learning systems data using mpc number frameworks also proposed addition mpc opens new opportunities privacypreserving web applications cloud computation example one company may develop machine learning models make predictions based health data individuals want send company copies personal medical data may instead opt engage mpc protocol company particular mpc protocol individual receives output point process company gain knowledge individual medical data nevertheless still able provide service mpc could also help enable surveillance extent systems play active roles surveillance instance recognizing faces videos flagging suspicious individuals basis web activity mpc used increase individual privacy particular mpc makes possible operate systems without needing collect access often sensitive data used make relevant classifications time use mpc protocols remains limited fact many cases increase overhead associated yao lindell pinkas openmined rouhani dowlin trask garfinkel forthcoming appendix questions researchwith computation multiple orders magnitude means mpc relatively simple computations use cases increased privacy would especially valuable monitoring resources one type measure might help predict prevent misuse technology would monitor inputs systems monitoring regimes context potentially dangerous technologies notably monitoring fissile materials chemical production facilities purpose implementing nuclear chemical weapon agreements obvious example input might possible monitor computing hardware efforts made past survey computing resources major ongoing public effort best available information likely withheld due commercial state secrecy one possible benefit public database global distribution computing resources could better understand likely distribution offensive defensive capabilities additionally monitoring place would valuable stronger measures employed enforceable limitations hardware could used questions consideration include feasible would monitor global computing resources different domains less tractable monitor less important capabilities others video game consoles considered light large share total computing limited current role could done information drawbacks effort encouraging wasteful racing computing power would inputs better suited monitoring computing resources exploring legal regulatory interventions much discussion focuses interventions carried researchers practitioners within development community however broader space hilbert lopez hilbert lopez appendix questions researchof possible interventions including legal ones considered note government interventions could counterproductive important implications specific policy interventions area carefully analyzed number questions concerning proper scope government intervention security arise list initial examples clear chain responsibility preventing securityrelated problems government departments marketplace actors institutions would ideally responsibilities would interactions academic industry communities suitable would existing institutions playing role much require establishment new institutions founded novel principles innovative structures order effectively operate evolving technical field relevant actors speaking coordinating sufficiently especially across political legal cultural linguistic barriers liability regimes adequate provide right incentives various actors take competent defensive measures prepared government feel much appetite would focused designed increase awareness expertise governments hold developers corporations others liable malicious use technologies explicitly make exempt liability approaches might considered pricing externalities pros cons government policies requiring use machine learning systems defenses adversarial examples forms malicious use data poisoning adversarial example attacks aimed disrupting systems subject legal penalties traditional forms hacking calo cooper see farquhar appendix questions researchcan legal related tactics like search engine optimization dealt international agreements considered tools incentivize collaboration security security community public policy model aim affect government policy scope policy responsibility distributed across individuals organizations governments requirement systems operating online otherwise interacting humans example telephone identify blade runner law increase political security kind process used developing policies laws govern dynamically evolving unpredictable research development environment desirable community norms ethical standards public policies laws say thing much gained different levels governance respond different kinds risk near term technical safety bad actor high uncertainty low uncertainty risks seems unlikely interventions within development community within institutions including policy legal institutions work well long term unless degree coordination groups ideally discussions safety security within community informing legal policy interventions also willingness amongst legal policy institutions devolve responsibility safety community well seeking intervene behalf achieving likely require high degree trust different groups involved governance suitable channel facilitate proactive collaboration developing norms ethics education standards policies laws contrast different sectors responding reactively different kinds pressures face different times seems likely result clumsy ineffective responses policy technical communities alike considerations motivated recommendations future humanity institute university oxford centre study existential risk university cambridge center new american security electronic frontier foundation openaithe malicious use artificial intelligence forecasting prevention mitigationfebruary malicious use artificial intelligence
