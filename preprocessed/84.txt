official official method ethical defence defence science technology group dstg report outcomes workshop represent official position defence represents views expressed participants stakeholders workshop official dstg official authors kate michael jason robert aerospace division defence science technology group plan jericho royal australian air force trusted autonomous systems defence cooperative research centre oduced aerospace division defence science technology group department defence box canberra act telephone mmonwealth australia work copyright apart use permitted copyright act part may reproduced process without prior written permission department defence approved public release official dstg official executive summary recent developments field artificial intelligence highlighted significant potential technology increase defence capability reducing risk military operations however clear significant work also needs undertaken ensure introduction technology result adverse outcomes defence challenge failure adopt emerging technologies timely manner may result military disadvantage premature adoption without sufficient research analysis may result inadvertent harms explore achieve ethical defence workshop held canberra july august people organisations attended including representatives defence australian government agencies trusted autonomous systems defence cooperative research centre tasdcrc civil society universities defence industry outputs workshop represent small part substantial ongoing investment appropriate methodologies frameworks theories guide development evaluation deployment adaptation ethical autonomous systems across defence tasdcrc report articulates views participants outcomes workshop consideration represent views australian government report provided support development defence policy doctrine research project management aim aim workshop develop pragmatic based ethical methodology projec defence objective objective workshop bring together best national international subject matter experts work complex moral issues create pragmatic methodology ensure ethical future method workshop attendees contributed based hypotheses discussions view developing methods inform military leadership ethics using autonomous systems defence context consultation defence stakeholders workshop consolidated outputs report workshop resulted identification five facets ethical defence see figure twenty based topics explored considering method ensuring ethical defence official dstg official figure facets thical defence facets emerged workshop represent broad areas inquiry provide framework resource investigations ethical acets identified categorising based participant hypotheses taking account applicable guidelines principles government professional bodies academia workshop attendees noted existing ethical principles varied type justification could conflict contradict thus needed grounded clear methodology additional governance frameworks order effective therefore rather propose singular ethical principles defence report aims provide developing facets ethical considered official dstg official iii including questions ask topics consider methods may relevant defence projects stakeholders facets ethical defence associa ted questions align unique concerns regulatory regimes defence subject example times conflict defence required comply international humanitarian law ihl lex specialis nternational human rights law lex generalis armed conflict jus bello defence also required comply international legal norms respect use force engaged armed conflict jus bellum applying military force international humanitarian law particularly concepts proportionality distinction military necessity direct military equivalent requires specific set requirements responsibilities must considered practical methodology thical defence consistent agreement workshop effective practical methodology would support projects manage ethical risks three tools developed workshop organisers assist defence industry developing systems defence three tools checklist development ethical systems ethical risk matrix describe identified risks proposed treatment larger programs ata item descriptor contractors develop formal legal ethical assurance rogram plan leapp included project documentation programs ethical risk assessment certain threshold noted facets questions topics methods identified report outcomes single workshop rather exhaustive review ethical considerations information report potential understanding ethical considerations defenc however subsequent ethical research consultation defence tasdcrc yield comprehensive frameworks assist facilitating research consultation developed supporting tools including brochure poster downloaded along publication fro official dstg official page intentionally blank official dstg official contents background methodology results responsibility education command governance effectiveness integration transparency human factors scope confidence resilience trust sovereign capability safety supply chain test evaluation misuse risks authority pathway data subjects law protected symbols surrender traceability explainability accountability method developing ethi cally defence ethical defence checklist ethical risk matrix legal ethical assurance program plan leapp summary contributors references appendix comparison ethical fra meworks official dstg official appendix ethical risk matrix appendix speakers facilitators ethical defence workshop appendix organisations attendance workshop appendix contexts defence enterprise rear echelon functions appendix taxono decision probl ems appendix data ite description appendix detailed judging criteria appendix declaration perceived conflic interests kate devi official dstg official background rapid growth artificial intelligence capabilities defence sector led recognition defence requires better understanding ethical issues associated emerging technology well robust relevant framework guide development operation systems containing royal australian air force raaf plan jericho realised experts multiple disciplines needed come together address lack understanding frameworks commenced concept development ethics workshop early plan jericho defence science technology group dst trusted autonomous defence cooperative research centre tasdcrc agreed jointly plan run workshop figure figure participants listening expert speakers engaging workshop activities jericho official dstg official intent develop pragmatic ethical methodology projects defence lead planners workshop kate devitt dstg tasdcrc wing commander michael gan raaf jericho defence participation organised wing commander gan academic scientific contributions participants organised devitt fields expertise represented speakers included ethics war ethics data autonomous systems defence adaptive autonomy human factors affe human teaming assurance autonomy appendix speakers facilitators ethical defence workshop wide range military academic scientific industry participants engaged australia overseas workshop activities appendix organisations attendance workshop official dstg official methodology workshop designed elicit based hypotheses regarding ethical diverse range perspectives contexts work conducted ing bayesian epistemology recommends increasing diversity stakeholders number independent evidential interactions hypotheses produce defensible result bovens hartmann devitt hajek hartmann method encourages inclusive yet based approach ethical aiming reliable useful results defence noting single workshop limited number attendees contributors accommodate fact represents given moment time subsequent research using similar methodologies appropriate parameters recommended ensure framework ensure ethical defence robust defensible achieve workshop aims based social platform used platform similar existing social platforms facebook reddit work internet computers tablets smart phones require specific software downloaded participants assumed least smart phone therefore could access platform additionally digital platform enabled unable attend workshop person contribute remotely asynchronously increasing inclusivity diversity attendees participants informed well hypothesis simple proposition reasonable person could either agree disagree dogs ought companion animal allowed domestic flights ins ide aeroplane cabin forming hypotheses encouraged users use words imply obligatory permissible forbidden many never ought permitted may occasionally sometimes ought cases participants given definition artificial intelligence autonomous systems guide thinking instead workshop organisers provided participants set contexts could used defence examples potential autonomous systems frame hypothetical considerations appendix contexts defence betterbeliefs platform used workshop background author kate devitt used free trial workshop please see section declaration perceived conflict interests statement appendix official dstg official contexts based adf warfighting functions modified suit purposes workshop designed capture potential defence applications including warfighting warfighting activities figure table lay contexts defence active sessions workshop force application force protection force sustainment situational understanding personnel enterprise logistics business process improvement users invited pick one identified context imagine possible ethical hypothesis context add hypothesis platform users urged explore wide range ideas told need strongly agree hypothesis add indeed users encouraged add hypotheses sceptical curious add radical unusual controversial hypotheses add hypotheses would like input feedback add hypotheses feel poorly supported evidence add hypotheses believe quite sure enough evidence investigate thoroughly official dstg official add hypotheses evidence add hypotheses believe users encouraged use wide range evidence nternet workshop back ideas evidence cited hypotheses ranged wikipedia articles blog posts magazine newspaper articles reports reputable institutions peer reviewed publications prize awarded workshop participant contributed greatest quality ideas rated peers evidence platform appendix detailed judging criteria organisers aware many biases digital platform could reveal including safe people feel contribut ing potentially controversial ideas online different circumstances previous use platform found participants low end organisational hierarchies interactive generated ideas got greater traction participants higher organisational hierarchy increase participation ease barriers entry workshop platform deployed first rganisers key stakeholders opened participants workshop days workshop prior workshop workshop leaders contributed initial hypotheses platform provide starting point participants show ideas perfectly worked fully formed intended tentative controversial etc speakers facilitators invited steer conversation around evidence might published preprints organisers offered help speakers register log platform walk via phone organisers populated set hypotheses modified institute electrical electronics engineers ieee ethic ally aligned design ieee global initiative ethics autonomous intelligent systems workshop participants invited register onto platform ahead workshop encouraged familiarise platform voting hypotheses ranking evidence try ing add hypothesis participants used platform workshop around small tables people platform available participants day workshop participants wished discuss hypotheses data complete could arrange eleconference official dstg official previous use platform shown less vocal participants workshop sessions appreciated safe digital space formulate ideas find evidence contrast socially dominant participants disproportionately influence scope conversation events workshop program divided oral presentations see appendix speakers facilitators ethical defence workshop four active sessions see table active session consisted targeted brief small group people discussions active sessions participants invited sit one eight tables table focusing different context within appendix contexts defence hypotheses evidence categorised facets topics compared existing government ethical frameworks ethics principles approved australian government department industr innovation science principles recommendations ethical use artificial intelligence approved department defense defense innovation board principles ieee ethically aligned design plus two meta reviews published harvard university fjeld hilligoss achten daniel feldman kagay nature machine intelligence journal jobin ienca vayena provided engineering scientific guidance consolidate framework see appendix comparison ethical principles note report refers frameworks information seek recommend singular set ethical principles defence report summarises outcomes workshop represent views australian government ethics see also dod adopts principles artificial intelligence ethics feb available official dstg official table workshop nteraction essions session brief activities resources military decision making attendees briefed tristan taxonomy decision types system might tasked made single maker multi maker decisions sequential decisions see appendix taxonomy decision problems partcipants also briefed julian tattersall constraints military decision table tasked discuss military context come examples decisions context identify ethical issue challenge within decisions find evidence online urls ethical issue propose ethical hypotheses betterbeliefs relating ethical context appendix taxonomy decision problems military decision making see defence act australian government addp joint planning australian defence doctrine publication figure levels conflict ooda loop brehmer human factors attendees iefed fiona kerr human factors cognitive anthropological sociological relating ethical defence including utonomy system oversight model table tasked discuss military context respect cognitive anthropological sociological factors affect decision identify ethical issue challenge decisions emerging considerations find evidence online urls ethical issue see endsley see appendix taxonomy decision problems details also french maule papamichail decision behaviour analysis support key constraints include constitutional requirements principle legality rule law legislative requirements act cth looked limitations constraints within executive power command also contrasting functions strategic operational tactical level rear echelon functions army navy air force joint civilian official dstg official propose ethical hypotheses betterbelief relating ethical context accommodate cognitive anthropological sociological factors ethical metaanalysis attendees briefed derek leben meta civilian ethical principles common principles promotion human values rofessional responsibility human control technology fairness discrimination transparency explainability afety security accountability privacy ethical theories utilitarianism contractarianism kantianism irtue ethics ethics etc might constrain meaning principles table asked discuss military context respect bottom reasons might challenge usefulness validity existing ethical principles civilian domain find evidence online urls counter established ethical principles add hypotheses necessary add betterbeliefs platform consider theories could change way principles could constructed propose ethical hypotheses betterbeliefs using different theories see principled artificial intellig ence map ethical rights based approaches fjeld global landscape ethics guidelines jobin ienca vayena wrap attendees briefed betterbeliefs hypotheses evidence end workshop encouraged continue add platform aug ust data would collated official dstg official results figure decision ashboard hypotheses emerging ethical defence workshop total attendees used online based social platform added ethical hypotheses added pieces supporting refuting evidence rated quality users evidence times voted hypotheses times data patchy expected revealing limits method also provided many hypotheses investigate figure hypotheses sorted much evidence quality evidence weight woe represented axis much participants believed hypotheses degree belief represented axis woe score could theory keep getting weightier evidence accrues whereas official dstg official dob score based proportion users voted hypothesis agreed disagree refuting evidence algorithm counteracts supporting evidence meaning contentious hypotheses woe score closer hypotheses yellow red white zones included report offer opportunities study limits digital data collection included absence speaker data relatively brief opportunity participants contribute data platform hypotheses workshop met threshold evidence woe belief dob items evidence diversity contributors greenlit forming basis topics report topics forged combination bottom workshop hypotheses top consultation key defence stakeholders including dstg adf tasdcrc consideration ethical frameworks hypotheses clustered forged five facets consideration ethical efence table table ethical principles topics emerging workshop facets ethical defence topics emerging workshop responsibility responsible education command governance controlled effectiveness integration transparency human factors scope confidence resilience trust trusted sovereign capability safety supply chain test evaluation misuse risks authority pathway data subjects law used lawfully protected symbols surrender deescalation traceability actions recorded explainability accountability facets questions topics methods based results single workshop rather exhaustive review ethical considerations many ideas expressed may valid scrutiny research workshops recommended explore appropriate frameworks methods ethical defence official dstg official responsibility responsible commanders appointed conduct campaigns operations assigned military forces authority commit military personnel battle potentially threatening circumstances commanders therefore vitally important responsibility accountable actions command control department defence offers opportunity augment aspects human making offering advantages embedded expertise larger scale operations speed precision reliability well enhanced patience vigilance scharre horowitz however may unclear responsible decisions actions combat operations involving employment military operations change commander responsibility programmers others responsible machines two key challenges must addressed operating systems particularly employing machine learning firstly order effectively ethically employ given system commander must sufficiently understand behaviour potential consequences operation secondly difficulty identifying specific individual responsible given decision action machine learning systems completely overwrite initially programmed code based learn environment encounter circumstances could uncontrolled environment responsible decisions made machines environmentally driven autonomy information adaptive may give defence advantages ought ethics technologies managed answering question responsibility underpins many subsequent concepts framework including governance traceability participants felt education critical enable commander enact responsibilities particularly combat systems official dstg official education first four key imperatives start educating defence national security personnel general mick ryan commander australian defence college want decision trust algorithms need makers involved capable understanding development algorithms going necessarily involved real decisions algorithms would schmidle hicks hunter samp coll workshop participants considered importance education role command felt defence teaches leadership management military officers teach aspects human behaviour cognition social factors thus human lead manage need understand without understanding human uncomfortable relationship break quickly likely least aspects embedded every defence function capability without early education military personnel likely fail manage lead interface canno understand therefore trust command today information age humans issue commands information environment information environment controls industrial age machines context exists inside information environments participants grappled question command coders algorithm person procured person deployed person relied applied responsibility critical decisions spread across multiple decision makers commanders designers acquisition agencies operators offering multiple opportunities exercise authority also make mistakes suggestions participants included allocation ethical legal responsibility could across network causally relevant decision floridi could help reduce mistakes augment human decision makers bear responsibility ekelhof pursuit accountability military decisions workshop attendees felt important decisions made assistance captured accountability frameworks mechanism assign responsibility located back propagation network theory strict liability jurisprudence common knowledge epistemic logic official dstg official including domestic international law international committee red cross argues human approach help ensure human beings ultimately responsible decision noted high volume high velocity information environments cyber communications electronic warfare decision makers rely increasingly autonomous systems due limits human processing capacities proactive ethical legal frameworks may help ensure fair accountability humans within systems ensuring operators individuals disproportionately penalised system tiered making defence examine legal cases responsibility civilian domain guide aspects relevant frameworks apportioning responsibility test uber autonomous vehicle accident ormsby defence could also consider arguments humans within complex systems without proactive frameworks risk caught moral crumple zones elish locus responsibility falls human operators rather roader system control within section governable issues consider future research include potential impact complexity makers malfunctions managed apportion appropriate levels responsibility human makers unforeseen complexity factors may put unreasonable cognitive burden makers apart complexity situation mistake malfunction deliberate corruption enabled system processes analyses data information intelligence inform making could cause mistake could inform thus undermine human making ways could risky destabilizing kania complexity risks associated leads onto principles governability trustworthiness must capable operating within human system control see section governable competence integrity security system must ensured see section trusted research human decisionmaking may seek redefine expectations obligations military ommand using official dstg official governance controlled australia longstanding well position use military force application military force controlled accordance government direction must compliant domestic international law achieve australia implements system control department defen human discretion point interface machine technology important point interface vary angus campbell chief defence force commonwealth creators must consider context used see appendix contexts defence controlled point interface rough control achieved vary depending nature system operational environment must work conducted understand humans capable operating ethically within based systems control regards control lethal autonomous weapons australia presented certain conventional weapons meeting geneva department defence expressing legal policy technical professional forms controls imposed systematically throughout life cycle weapons nine stages table table system ontrol weapons department defence system control stage one legal policy framework stage two design development stage three testing evaluation review stage four acceptance training certification stage five pre selection stage six weapon use parameters stage seven pre certification training stage eight strategic military controls use force stage nine evaluation official dstg official effectiveness participants suggested systems deployed demonstrating effectiveness thorough experimentation simulation limited live trials etc robust testing required allowing assessment decision making relevant cenarios presenting varying scenarios possible assess capability system operate environments varying levels risk dynamics decision requirements ahner ieee ethically aligned design argues creators operators autonomous intelligent systems provide evidence effectiveness fitness purpose autonomous intelligent systems integration participants suggested system integration would improve robustness diversity making abbass automotive vehicle automation provides example highly integrated human driver cognitive functions collision notifications blind spot monitoring assured clear distance ahead forth however important consider individual differences cognitive abilities ensure integration fits operator greenwell social integration natural consequence use society transparency transparency refers operator awareness autonomous agent actions decisions behaviours intention identified one factor could improve human trust autonomous systems certain amount transparency seems improve operator performance improving situation awareness reducing workload however much transparency also decrease operator performance bhaskara skinner loft endsley contexts need make reasoning transparent others people use technology time without knowing works never question operator act transparent information timely manner transparency assist making however overly explanatory may lead information overload decision paralysis work needed ensure balance explainable models maintaining performance turek ieee ethically aligned design argues basis particular decision always discoverable allowing differences user need requirements legal review team versus operator making tactical decisions official dstg official human factors particip ants advocated cognitive psychology neurophysiology considered developing systems machine collaboration optimised safeguard poor making including automation bias mistrust system much automation render made decisions optimal barnes chen hill neurophysiological impacts technological interaction intermediation need better understood factored design use complex information systems lead cognitive fatigue distraction via modal delivery performance loss neural switching factors sufficiently considered deciding appropriate level use use better design human loop processes partnerships drnec marathe lukos metcalfe endsley sparrow liu wegner autonomous technologies may enable better situational awareness better understanding operational environment allow humans increase control hand autonomous technologies present fundamental challenges military struc tures military mind making processes relationships human actors technologies challenges considered carefully use autonomous technologies could result unacceptable loss control implementing technologies gives rise additional new challenges regard human interfaces ethics trust training ekelhof risk people start work new technology experience working reliab rather learning technology limits makes users vulnerable unknown system errors different contexts reliance automation may time result degradation humans cognitive skills coordination capabilities hoffman sarter johnson hawley cognitive relationship human machine critical system proper use machine decision making already affects military decisions influence increase capabilities develop tempo conflicts increases danzig cases assigning humans decisions improve use autonomous countermeasures respond faster human reaction times thwart attack seffers united states navy zender scope participants advised caution pointed many technical issues autonomy brittleness capacity deal emergence software validation graceful degradation requirements learning systems transparency mean full autonomy possible high levels official dstg official reliability robustness yet achieved also necessary human accurate mental model system capabilities order develop sufficient trust system choose use endsley guaranteed human ultimate maker humanautonomy teams sufficiently manages systemic risks given increasing system complexity humans produce errors action inaction human intervention counterproductive particularly high tempo environments demand fast processing communication capabilities human makers nuanced flexible contextual ways brittle ais struggle machine complexity confounds human decision makers even ample time considered judgment danzig matter much autonomy within systems people use properly trust want chiou lee consideration trust transparency system could improve effectiveness human pairing providing confidence information choices offered enhance decision capability human operator christensen lyons confidence help commanders know trust information machine telling come confidence factor richard ross coffman freedberg participants considered whether system provide advice also provide level confidence advice confidence reporting needs terms classification probability object analysed likelihood assessment object true confidence whether class even contained within model degree designed trained assess object question attainable output softmax function similar needs derived means gal ghahramani prevalence automation bias due users high confidence data presented alexander also many different sources uncertainty types ignorance relevant human decision figure many real applications internal maki process must understood detail mclellan softmax regression kind logistic regression normalizes input value vector values follows probability distribution whose total sums allows nuanced interpretation values rather binary neural network model see simplified official dstg official understanding uncertainty managed critical ost algorithms deal uncertainty internally way perhaps using rigorous framework stochastic probability heuristic method attempt deal one type ignorance conveying meaningfully human users without causing information overload unsolved problem figure taxonomy ignorance uncertainty russell thomas thomas recognising true value data algorithm paramount warfighters commanders developers certifiers able trust rely may confidence levels need disclosed aspects nested confidence levels decisions made said unclear meant confidence regarding system confidence intervals indicate accuracy reliability certain confidence level mean claims confidence decision know enough limitations information useful human makers consequences wrong part making process disclosure confidence levels apply information used human machine participants felt work needed done investigate order confidence levels useful must level understanding use trust humans need intervene calibrated trust information required effectively enable humans interact likely broad varied ultimately determined experimentation real word application chen official dstg official analytic confidence humans broken along three dimensions reliability available evidence range reasonable opinion responsiveness new information friedman zeckhauser grey box process fosters trust transparency human element output system going way ensure confidence part decision process christensen lyons new developments modelled reduction cost prediction allowing imperfect decisions human adjustment models improve agrawal gans goldfarb resilie nce participants highlighted importance system resilience namely system exhibits ability foresee contain recover anomalous situations hollnagel woods leveson describe resilience achieved organi sations systems stating conceptualised combination system ability prevent something happening prevent something becoming worse recover anomalous situations foresee contain recover participants considered whether deployed detect system anomalies improve resilience systems particularly risk cyber supervised machine learning detection expected unsupervised learning detection uncommon patters probabilistic reasoning used system sutton barto provide overview different machine learning techniques examples application match counterparts associated detection anomalies patterns decision making provides motivation applications standard tools supervised machine learning unsupervised machine learning probabilistic reasoning trust trusted systems defence need trusted users operators commanders support staff military government civilian population nation trust trusted trustworthy concepts well explored researchers davis level expert group artificial intelligence hoff bashir hoffman johnson bradshaw underbrink lee see schaefer chen szalma hancock wang jamieson hollands level expert group artificial intelligence european union believe essential trust remains bedrock societies communities official dstg official economies sustainable development argue trustworthy must lawful ethical robust model trust report captures diverse hypotheses suggested participants context establishing trust technical systems people organisations develop deploy figure figure two model trust incorporating reliability integrity honesty character suitable systems connelly crook combs ketchen aguinis connelly miller devers devitt kim ferrin cooper dirks two model suggests trust humans consists competency integrity competence comprises skills reliability experience integrity comprises motives honesty character model useful understand human trust prompts consider trust might similar asymmetric humans autonomous systems notably systems intrinsic integrity exhibit behaviours internal processing due integrity lack therein human teams systems example humans may trust another human high integrity human driver much lower competence autonomous counterpart self car large increasing body literature trust future projects may draw human system competent yet exactly right skills succeed specific context fails task reached limit experience competence improves human systems learn skills operator training become reliable better test evaluation experienced data official dstg official training integrity comprises motives honesty character trust system intends ethical transparent actions embodies culture regardless competence inclines take responsibility actions thoughtful empathetic others positive traits two model trust combines ability ethics model explain humans might continue use technology trusting reliability even trust manufacturers example services google maps trusted users guide journeys without users knowing anything underpinning algorithms users trust systems many reasons including system reliability predictability people trust experts peers communities organisations government institutions etc thus users may trust corporations google good mapping world even trust google abuse position information power auspices surveillance capitalism zuboff operators hold multiple levels trust systems using depending aspect trust scrutiny cases users may develop reliance low integrity technology predict easily using known flight path adversary drone develop countermeasures users may also depend technologies convenience rather trust finally individual differences exist propensity trust highlighting trust relational rather objective property trust complex active research area authors offer model framework interpret results workshop rather definitive valid model trust sovereign capability participants considered impact australia potential reliance overseas suppliers reliance might expose defence anti proprietary systems platforms encumbered international traffic arms regulations itar one author dingle raised similar concern relation lack spare parts joint strike fighter workshop participants agreed risk lack investment sovereign could impact ability achieve sovereign decision superiority defence objective meet needs sovereign capability regards national security science technology interdepartmental committee established march defence committee endorsed six national security science technology priorities potential improved appropriate applications cybersecurity intelligence border security management investigative support official dstg official forensic science preparedness protection prevention incident response technology foresighting callinan safety participants indicated systems safe safety case could demonstr ated experimentation simulation limited live trials etc testing varying scenarios help assess capability system operate environments varying dynamics decision requirements levels risk ahner safe avoid negative side effects pursuing goals avoid reward hacking scalable oversight actions able explore safely robust distributional shift safe different contexts trained amodei considerations participants accord australian thical principles reliability safety throughout lifecycle systems reliably operate accordance intended purpose department industry innovation science program testing used show presence bugs never show absence dijkstra however noted test evaluation limited guarantees adaptive systems operating unforeseen contexts indicating levels risk need understood design deployment systems supply chain participants noted generated unsecure suppl chains contain backdoors vulnerable hacking recent scale cyber result breach within vendor supply chain langcaster better data transparency might ensure provenance suppliers partic ipants considered whether could used acquisition decisions validate verify veracity origins componentry suppliers gaps data flag authentication needs occur increasingly practical ethical templates assist procurement institute ethical machine learning acquisition perhaps like art purchasing authentication requires history certification follow dutton see also sroufe curkovic discussion supply chains participants felt aspects developing military scrutinised ethicality end product military application cradle ave assessment ethics development felt increase capacity ethical assurance use military official dstg official end unjust biases identified mitigated algorithm datasets learning protoc ols interpretative layer participants argued systems inclusive accessible involve result unfair discrimination individuals communities groups accordance australia civilian ethical principles department industry innovation science department defence thical principles appendix participants also noted defence would different obligations civilian domain concerning data supply chain whether supply chain would transparent given security considerations increasingly available tools assist developers check unfair discrimination ibm trying make systems transparent biases visible fairness toolkit utilising toolkit help identify explain limits biases training data model bias tests data bias evaluation deployed systems celis huang keswani vishnoi ibm research trusted lockwood speicher ibm toolkit designed improve trust demonstrating systemic disadvantages unprivileged groups conversely systemic advantage privileged groups defence context jus bello ethical principles must abided particularly appropriate discrimination combatants non proportionality coates test evaluation participants considered requirements operational test evaluation brought service including article weapons additional protocol geneva conventions international committee red cross identified risk undesirable consequences unintended combinations legitimate rules patterns traditional test evaluation defines desired system response anticipated operating conditions response matrix intractably large preventing engineers fully enumerating system requirements scheidt hibbitts chen bekker paxton recent developments deepmind alphago alphazero muzero programmed explicit responses situations encountered machine instead solve problem produce decision within domain explicitly encoded software muzero particularly impressive even coded rules games able learn play schrittwieser gives potential high performance challenging complex domains see australian article review process protocol additional geneva conventions august relating protection victims international armed conflicts protocol june official dstg official without prior knowledge underlying dynamics challenging test evaluate existing article weapons additional protocol geneva conventions many applications rely deep learning algorithms especially sensor recognition deep learning systems however still prone error even ideal conditions shortcomings targeted adversarial technologies targeted operator classification algorithms heart many future systems tramèr participants pointed value testing evaluating significant adversarial scenarios potentially rigorous second third order effects likely unknown new technology regardless participants suggested iterative test ing throughout design application burton misuse risks participants pointed potential misuses risks may categorically different extensive depending anticipated level autonomy planned contexts use ieee global initiative ethics autonomous ntelligent systems example highly autonomous systems must sufficiently resilient adaptive threats operate intended context use capabilities become powerful widespread expansion existing threats due lower costs expansion actors carry attacks increase rate attacks increased set potential targets new threats may arise additional capabilities afforded malicious actor able exploit new system vulnerabilities attacks enabled growing use likely finely targeted difficult attribute brundage cyber capabilities change system behaviour either deliberately malware significant threat trust autonomy dowse cyber mitigation key maintaining trust integrity autonomous systems systems must resilient able defend attack incl uding protecting communications feeds ability take control systems demonstrated commercial vehicles including ones still require drivers internet things connection worst scenario systems could operate behalf opposing forces cia surveillance drone captured iran predator unencrypted video feed reportedly intercepted although hacked controlled insurgents using piece commercial cots software official dstg official took control landed provided opportunity technical exploitation cnn wire staff participants felt developed cognisant risks cyber interference incorporate processes systems maintain cyber hygiene australian cybersecurity centre availability dirty data train see mit project emonstrates data produce psychopathic yanardag cebrian rahwan presents method produce unintended behaviours participants suggested methods identify data provided negatively influenced behaviour countermeasures mitigate risk correct behaviour rand corporation report win kelman points liabilities responsibilities autonomous vehicles hacked uninhabited aerial vehicles many vulnerabilities complex ict architecture multiple attack surfaces kim wampler goppert hwang aldridge asked whether creators could defend potential risks misuses unknown unknowns foreseen even scrupulous organisations methodology predicting unknown unknowns educe risks developing kim order develop malicious developers need access models weightings data forth enable access modify nefarious reasons reason serious consideration must given withholding publication limiting release documentation code justified researchers developers consider wider range factors weighing obligations responsible publication including potential cidents misuses harms means limiting harms crootof many data science tools make difficult impossible assess true accuracy model sufficient validate models need validate data preparation model performance model building including parameter optimi sation engineering rapidminer australian ethical principles recommend decisions made systems contestable civilian domain means system significantly impacts person community group environment timely process allow people challenge use output system contestibility department industry innovation science worksh participants felt defence consider use systems could contested within military making communicate divergences civilian military ethical making australian public official dstg official authority pathway participants considered role assist tactical decision makers making ethical decisions example could used help decision makers trigger point make ethical correct judgements paired interactive interfaces built build ethical awareness habits reasoning actions staines formosa ryan assisting medical decision makers regard shortliffe might able take available information account process efficiently assist human determine whether objects combatants non potentially reducing risk civilian death consider vincennes incident civilian airbus mistaken tomcat linnan case multiple conflicting sources information human biases lead loss civilian craft use programmed prioritise abidance international law integrates multiple sources data trusted tactical decision makers might prevented tragedy ethically software might helped ommanding officer receive disconfirming evidence change actions tool might combine multiple lines evidence present scenarios commander rating likelihood civilian aircraft rather fighter however support tool would also need align operational requirements may time evaluate multiple scenarios clear presentation within temporal envelop would ensure commander could see alternate hypotheses coordinated attack scenario make informed decision best course action programmed ethical legal considerations could incorporated teams mum configurations afrl loyal wingman program idea manned platform pairs unmanned aircraft operating wingman scout fawkes menzel case computer readouts confirm civilian flight via iff mode three civilian transponder signal multiple personnel recalled identification flight even remembered observing iff mode two military signals crew vincennes also reported aircraft descending though fighter rather ascending confirmed sides departed airport min late confused crew vincennes respond multiple requests information vincennes identify commercial rather military intent one reason disconfirming evidence computer readouts sides may changed attack behaviour vincennes commanding officer believed iranians conducting coordinated attack similar displayed operation praying antis vincennes certainly surface attack speedboats incident commanding fficer hypothesis plausible situation official dstg official data subjects workshop participants expressed concern data defence personnel working rear echelon functions might affected areas posting prom otion disciplinary performance management recruitment appendix contexts defence workshop participants cognisant potentially different circumstances defence personnel faced versus civilians regards data privacy one hand civilian domain australian thical principles state throughout lifecycle systems respect uphold privacy rights data protection department industry innovation science participants noted defence uses national defence requires information secure available data subjects still defence personnel data treated ethically participants felt consideration impact systems personnel important participants noted use data statistical research tools could cause harm personnel use larger pools data pulled personnel research tasks heightened risk individuals could harmed programs access anonymous surveys system level demographic data could attribute negative comments individual using mosaic theory techniques participants wondered whether risk individual acceptable compared business intelligence gained organisation mosaic theory based research within financial surveillance contexts would used attribute data provided individual davidowitz kerr kugler strahilevitz law used lawfully adf strong record compliance applicable legal frameworks developers cognisant legal obligations within anticipated use technology law within defence context specific ethical considerations must understood international humanitarian law ihl lex specialis nternational human rights law lex generalis forged ethical theories war theory jus bellum governing resort force jus bello regulating conduct parties engaged lawful combat coates jus post bellum regarding obligations combat jus vim concerning use force short war galliott legal frameworks accompany defence activities human mean compliance produce ethical outcomes liivoja mccormack using augment human aking could lead better humanitarian outcomes official dstg official many national laws potentially apply military use ranging privacy act copyright act public service act public governance performance accountability act archives act crimes act criminal code amendment cybercrime act addition many policies directives may apply hav force law military contexts also typically extant set rules called ules ngagement among things specify conditions must met order fire upon target legal compliance may able built algorithms relies sufficiently unambiguous well specified encoded rules computer interpret meets stakeholder expectations practice laws always clear even humans addition many complicated conditions many interconnections laws work needed clarify best enable abidance applicable laws protected symbols surrender workshop participants argued defence might used recognise protected symbols signs surrender thought may reduce number operational accidents human error significant negative political humanitarian impact examples human errors include mistaken attacks medical facilities attack médecins sans frontières msf hospital afghanistan multiple attacks hospitals yemen saudi coalition lewis despite reporting location military forces displaying red crescent sign hospitals attacked military forces mistaken belief military targets analysis inadvertent attacks reveal patterns human errors deconfliction since structures strike list identification since attacks failed identify either nature medical facilities red crescent symbol marking structure medical facilities technology may enable greater protections human errors oakford however parties conflict particular state actors known misuse protected emblems red cross crescent rder gain tactical advantage use ambulances vehicle borne improvised explosive devices iraq afghanistan example misuse protected symbol falsifying protected symbols enable targeted act ion constitutes act perfidy similarly falsely representing protected objects protected objects fool would also constitute act perfidy systems seek improve abidance ihl must embedded information environment anticipates deception disinformation misinformation regards protected objects official dstg official humans make many errors conflicts example civilians misidentified hostile forces kolenda reid rogers retzius weapon systems recognised protected systems incidence even intentional incidents could reduced minimally minai could used today forms existing conventional weapons prevent unintended harm scholz galliott minai deals ethically impermissible contrasted maxai ethical machine guided acceptable non actions minai includes use machine learning detect cross diverting unintended strike stopping missile sam striking passenger aircraft carrying innocent civilians case loss life flight sam permitted participants felt autonomy might assist conflicts example shooting unmanned drone reduced ethical risk given harm loss life human operators providing new calculus actions achievement military objectives shooting drone may still provoke escalation retaliatory use force lesser extent shooting crewed aircraft attributable nature cyber systems brings new challenges force escalation participants felt could used increase situational awareness commanders enable manage escalation escalation better information knowledge understanding conflict manned unma nned systems consideration force escalation ties bigger question proportionality use unmanned systems dynamics escalation deterrence using systems evolving needs better understood schaus johnson illustration recent escalation related unmanned systems president trump decision call strike iran retaliation shooting drone june though strike legal action trump claims called strike informed people would likely killed strike twitter trump said cocked loaded retaliate last night different sights asked many die trump cited chappell ten minutes strike begin trump decided strike proportionate shooting unmanned drone trump cited chappell regardless whether narrative makin fact decision made example provides case leader explained decisions using ethical calculus shooting unmanned though expensive drone thought warrant projected loss also note though strike aborted less lethal use force remained open official dstg official traceability actions recorded legislative requirements defence record making however increasing use within systems means manner records must considered records represent systems involved causal chain events humans ais part decisions participants felt information needs accessible explanatory training expertise humans must open scrutiny background theories assumptions training test evaluation process ais must retained information systems available understandable auditors said aspects human making inscrutable aspects decisions ais may remain opaque organisations certify acquire systems determine required levels explanation decisions lead expected outcomes positive outcomes factors lead decisions may come scrutiny however low likelihood negative outcomes occur participants felt organisations able rewind decision process understand occurred lessons might learned noting decisions made uncertainty always chance producing negative outcomes even making process defensible operators acting appropriately explainability participants supported consideration human oversight understanding explainability concepts complex variously interpretable participants discussed lessons explainability autonomous manoeuvring characteristics augmentation system mcas boeing max caused hundreds civilian deaths mcas allowed deployed aircraft story many human errors operators testing authorities sufficiently informed regards autonomous systems board max aircraft campbell order examine means understood darpa invested explainable xai turek produce explainable models reducing prediction accuracy enable human users understand appropriately trust effectively manage human systems path easy explanations decrease scepticism increase automation bias heaven one shared definition constitutes sufficient explanation official dstg official however models explainability social sciences may assist endeavours produce truly explainable miller accountability australian domestic legislation imposes obligation commonwealth departments record retain records relating certain decisions likely decisions captured similar legislative requirements see archives act australian government participants felt human logistics systems able output explanations decisions made accordance legislative obligations appropriate transparency decision making improves ability educate system provide feedback outcomes build trust system human operators partic ipants felt evidence operation systems ought intelligible technically transparent experts see section transparency explainable stakeholders citizens consumers meaningfully consent challenge use operations blacklaws example article general data protection regulation gdpr provides safeguards data subjects automated making might legal significant consequenc individual european parliament council individual consent merely legal technical check boxing requires centred ongoing social contract see section titled digital age british academy royal society participants suggested systems ought able provide evidence decision made identifying exactly provide evidence developer users etc must still investigated potential reviews decisions must supported evidence decision process testing support decision making enabled system must demonstrate based rather decision process wilkinson basis particular decision defence retained according legislative requirements matter deployed defence data training theoretical underpinning making models actions recorded auditable appropriate levels government appropriate made available public information see gdpr new data protection law available official dstg official method developin ethically defence many benefits increasing autonomous systems capabilities defence including removi humans threat environments reducing sustainment costs achieving greater mass battlefield exploiting asymmetric advantage accelerating capability development timelines capitalising advances made civil sector consistent agreement workshop effective practical methodology would best support defence ndustry developing systems method ethical means assessing ethical compliance design deployment requiri repeated testing prototyping reviewing technological ethical limitations developers already must produce risk documentation technical issues similar documentation ethical risks ensures developers identify acknowledge attempt mitigate ethical risks early design process throughout daniels williams vallor projects involving machine ethics specify ethical basing risking strategies upon consequentialism kantian virtue ethics ethics care forth machine ethics see cave nyrup vold weller leben tavani workshop focus machine ethics topic noted participants would value subsequent research engagement three tools developed workshop organisers assist defence industry developing systems defence three tools currently internal review checklist development ethical systems ethical risk matrix describe identified risks proposed treatment see appendix larger programs ata item descriptor contractors develop formal legal ethical assurance program plan leapp included project documentation programs ethical risk assessment certain appendix data item description eng see marcus hellyer report accelerating autonomy autonomous systems tiger helicopter replacement official dstg official ethical defence checklist main components checklist describe military context explain types decisions supported explain integrates human operators ensure effectiveness ethical decision making anticipated context countermeasures protect potential explain employ subject matter experts guide employ appropriate verification validation techniques reduce risk ethical risk matrix create hical risk matrix see appendix ethical risk matrix detail project activity define activity undertaking indicate ethical facet topic activity intended address estimate risk project objectives issue addressed define specific actions undertake support activity provide timeline activity define action activity outcomes identify responsible party ies provide status activity see appendix contexts defence see appendix taxonomy decision problems defence act critical decision analysis cognitive task analysis methods stanton salmon rafferty see topics particularly governance trusted sections examples see appen dix example use consultants contractors hire employees relevant expertise military ethics decision science law human factors data science assist project conceptualisation planning seek best practice aut onomy intelligent system test evaluation methods accelerate certification assurance acquisition adoption social license official dstg official legal ethical assurance program plan leapp programs ethical risk assessment certain threshold comprehensive legal thical program plan provided legal ethical assurance program plan leapp describes contractor plan assuring software acquired contract meets commonwealth legal ethical assurance lea requirements draft ata item description appendix data item description provides guidance contractors developing legal ethical assurance programs complex defence systems leapp provides defence visibility contractor legal ethical planning supports progress risk assessment provides input defence internal planning including weapons reviews article additional protocol distributed review comment defence ndustry stakeholders considered defence contracts summary many benefits increasing autonomous systems capabilities defence including removing humans threat environments reducing capability costs achieving asymmetric advantage however significant work needs undertaken ensure introduction technology result adverse outcomes explore achieve ethical defence workshop held canberra july august total people organisations attended including representatives government civil society universities defence industry workshop resulted identification five facets ethical defence based topics explored considering method ensuring ethical defence report conveys pragmatic methods ethically defence projects methods also pertinent ethics autonomous systems semi manned teaming humanautonomy teaming report focuses outcomes workshop consideration represent views australian government tools suggested ethically risk projects include ethical checklist ethical risk matrix lea larger acquisitions method ethical defence aims practically ensure accountability considering ethical risks assigning risk making humans accountable decisions ethics outputs workshop mall part substantial ongoing investment appropriate methodologies frameworks theories guide development evaluation deployment adaptation ethical autonomous systems across official dstg official defence trusted autonomous systems defence cooperative research centre tasdcrc outputs support development defence policy doctrine research project management first outputs report accompanying brochure poster downl oaded contributors following individuals contributed report including hypotheses evidence informed creation ethical facets topics methodology hussein abbass eugene aidman andrew back christopher bailey saba bazargan trent beilken adella bhaskara robert bolia stephen bornstein glenn burgess dragana calic massimiliano cappuccio darren carruthers jessica casben fell wygene chong mal christie susan cockshell nikki coleman emily defina harley dennett kate devitt bradley donnelly piers duncan shane dunn heather emery peter francis michael gan michelle gee antonio giardina alex gibbs damian gilchrist anne goyne chris gyngell marcus hellyer rachel horne paul jones dale lambert derek leben larry lewis scott lowe glenn logan fiona kerr ian koegelenberg dean lewis mark lilley duncan macintosh luke marsh ryan messina samantha murray tyson nicholas simon tristan perez vanessa pigrum helen pongracic carmine pontecorvo daniel pope travis reddy jerome reid ben rice morgan saletta jason scholz alison spark julian tattersall anh naomi van der linden tim van gelder samuel white sarah white kate yaxley kath ziesing official dstg official references abbass social integration artificial intelligence functions automation allocation logic autonomy trust cognitive computation agrawal gans goldfarb exploring impact artificial intelligence prediction versus judgment information economics policy ahner test evaluation autonomous systems international test evaluation symposium retrieved alexander may reliance technology creating new dark age interesting engineering retrieved amodei olah steinhardt christiano schulman mané concrete problems safety arxiv preprint arxiv australian cybersecurity centre cyber hygiene australian signals directorate retrieved hygiene archives act act barnes chen hill humans autonomy implications shared decision making military operations army research laboratory retrieved bhaskara skinner loft agent transparency review current theory evidence ieee transactions machine systems blacklaws algorithms transparency accountability philosophical transactions royal society mathematical physical engineering sciences bovens hartmann bayesian epistemology oxford oxford univer sity press official dstg official brehmer dynamic ooda loop amalgamating boyd ooda loop cybernetic approach command control international command control esearch technology symposium future brundage avin clark toner eckersley garfinkel filar malicious use artificial intelligence forecasting prevention mitigation report published future humanity institute university oxford centre study exist ential risk university cambridge center new american society electronic frontier foundation openai retrieved burton habli lawton mcdermid morgan porter mind gaps assuring safety autonomous systems engineering ethical legal perspective artificial intelligence doi callinan defence security sovereign strategic advantage australian strategic policy institute retrieved strategic campbell may redline many human errors brought boeing max verge retrieved error faa cave nyrup vold weller motivations risks machine ethics proceedings ieee celis huang keswani vishnoi classification fairne constraints meta provable guarantees proceedings conference fairness accountability transparency chappell june trump says called strike iran see proportionate npr retrieved chen lakhmani stowers selkowitz wright barnes situation awareness agent transparency official dstg official human teaming effectiveness theoretical issues ergonomics science chiou lee cooperation agent systems support resilience microworld experiment human factors journal human factors ergonomics society christensen lyons trust humans learning machines developing gray box mechanical engineering cnn wire staff obama says asked iran return drone aircraft cnn retr ieved coates ethics war manchester manchester university press commonwealth australia october foreign affairs defence trade legislation committee senate retrieved connelly crook combs ketchen aguinis integrity trust interorganizational relationships matters journal management connelly miller devers cloud suspicion trust distrust interactive effect interorganizational contracting strategic management journal crootof october artificial intelligence research needs responsible publication norms lawfare retrieved needs responsible daniels williams day zero ethics military war rocks retrie ved danzig technology roulette managing loss control many militaries pursue technological superiority center new american security retrieved official dstg official davidowitz abandoning osaic theory mosaic theory securities analysis constitutes illegal insider trading ujl pol davis individual differences operators trust autonomous systems review literature dst joint operations analysis division defence science technology group departmen defence defense innovation board principles recommendations ethical use artificial intelligence department defense retrieved department defence addp joint planning addp retrieved department defence australian defence doctrine publication campaigns operations edition department defence national security science technology policy priorities retrieved department defence addp command control department defence australia system control applications autonomous weapon systems group governmental experts emerging technologies area lethal autonomous weapons systems march august geneva department defence australian defence doctrine publication command control edition department industry innovation science ethics principles retrieved principles devitt homeostatic epistemology reliability coherence coordination bayesian virtue epistemology rutgers state official dstg official university new jersey new brunswick retrieved fro devitt trustworthiness autonomous systems abbass scholz reid eds foundations trusted autonomy cham springer international publishing dijkstra reliability mechanisms notes structured programming retrieved dingle sarah july officials reveal enough spare parts joint strike fighter abc news retrieved arent parts dowse need trusted autonomy military cyber security abbass scholz reid eds foundations trusted autonomy cham springer international publishing drnec marathe lukos metcalfe trust automation decision neuroscience applying cognitive neuros cience methods understand improve interaction decisions involved human automation interaction frontiers human neuroscience dutton authenticity art levinson oxford handboo aesthetics ekelhof lifting fog targeting naval war college review elish moral crumple zones cautionary tales robot interaction engaging science technology society endsley autonomy lessons learned automation research human factors european parliament council regulation european parliament council april protection natural persons regard processing personal data free movement data repealing directive general data protection regulation retrieved official dstg official fawkes menzel future role artificial intelligence journal joint air power competence centre fjeld hilligoss achten daniel feldman kagay principled artificial intelligence map ethical rights based approaches retrieved florian tramèr alexey kurakin nicolas papernot ian goodfellow dan boneh mcdaniel ensemble adversarial training attacks defenses international conference learning representations vancouver canada floridi faultless responsibility nature allocation moral responsibility distributed mor actions philosophical transactions royal society mathematical physical engineering sciences freedberg art command science breaking defence retrieved french maule papamichail decision behaviour analysis support cambridge cambridge university press friedman zeckhauser analytic confidence political decision theoretical principles experimental evidence national security professionals political psychology gal ghahramani dropout bayesian approximation representing model uncertainty deep learning international conference machine learning icml jun new york galliott force short war modern conflict jus vim edinburgh edinburgh university press art gdpr automated individual decision including profiling retrieved individual greenwell bender loft bowden whitney lipp visser one size fits one benefits customizing automation accommodate differences operator multitasking defence human science symposium human sciences impact warfighter university canberra official dstg official hajek hartmann bayesian epistemology dancy sosa steup companion epistemology chicester john wiley sons ltd heaven asking explain make things worse artificial intelligence machine learning mit technology review retrieved things hellyer accelerating autonomy autonomous systems tiger helicopter replacement australian strategic policy institute retrieved hicks hunter samp coll assessing third offset strategy center strategic international studies retrieved high expert group artificial intelligence ethics guidelines trustworthy retrieved hoff bashir trust automation integrating pirical evidence factors influence trust human factors hoffman johnson bradshaw underbrink trust automation ieee intelligent systems hoffman sarter johnson hawley myths automation implications military procurement bulletin atomic scientists hollnagel woods leveson resilience engineering concepts precepts ashgate publishing ibm research trusted fairness open source toolkit retrieved ieee global initiative ethics autonomous intelligent systems ethically aligned design vision prioritizing human well autonomous intelligent systems retrieved official dstg official international committee red cross protocol additional geneva conventions august relating protection victims international armed conflicts protocol june retrieved opendocument international committee red cross artificial intelligence machine learning armed conflict centred approach retrieved armed approach jobin ienca vayena global landscape ethics guidelines nature machine intelligence kania battlefield singularity artificial intelligence military revolution china future military power center new american security retrieved singularity kerr mosaic theory fourth amendment dec future cybersecurity info security retri eved kim wampler goppert hwang aldridge cyber attack vulnerabilities analysis unmanned aerial vehicles american institute aeronautics astronautics retrieved kim ferrin cooper dirks removing shadow suspicion effects apology versus denial repairing versus integrity trust violations journal applied psychology kim characterizing unknown unknowns pmi global congress america vancouver british columbia canada kolenda reid rogers retzius june strategic costs civilian harm applying lessons afganistan current future conflicts open society foundations retrieved official dstg official civilian kugler strahilevitz actual expectations privacy fourth amendment doctrine mosaic theory supreme court review langcaster cyber security supply chain apmg international retrieved security leben ethics robots design moral algorithm new york routledge lee see trust automation designing appropriate reliance human factors journal human factors ergonomics society lewis protecting medical care conflict solvable problem retrieved cna arlington virginia liivoja mccormack routledge handbook law armed conflict new york routledge linnan iran air flight beyond free passage mistaken state responsibility yale int lockwood january artificial intelligence explain decision iot retrieved mclellan december inside black box understanding decision zdnet retrieved miller explanation artificial intelligence insights social sciences artificial intelligence oakford august one american failed quest protect civilians yemen atlantic retrieved saudi airstrike official dstg official ormsby march uber fatality unveils accountability issues lawyers weekly retrieved rapidminer correctly validate machine learning models rapidminer ryan april building brilliant adf strategist retrieved schaefer chen szalma hancock meta analysis factors influencing development trust automation implications understanding autonomy future systems human factors scharre horowitz artificial intelligence every policymaker needs know center new american security schaus johnson unmanned aerial systems influences conflict escalation dynamics center strategic international studies retrieved systems scheidt hibbitts chen bekker paxton need artificial intelligence advanced test evaluation met hods space exploration planetary science vision workshop scholz galliott weapons moral imperative minimally autonomy international conference science innovation land power adelaide schrittwieser antonoglou hubert simonyan sifre schmitt graepel mastering atari chess shogi planning learned model nature retrieved seffers smarter electronic warfare armed forces communications electronics association retrieved official dstg official shortliffe computer programs support clinical decision making reply jama journal american medical association sparrow liu wegner google effects memory cognitive consequences information fing ertips science speicher heidari grgic gummadi singla weller zafar unified approach quantifying algorithmic unfairness measuring individual roup unfairness via inequality indices proceedings acm sigkdd international conference knowledge discovery data mining london united kingdom sroufe curkovic examination iso supply chain quality assurance journal operations management staines formosa ryan morality play model developing games moral expertise games culture stanton salmon rafferty cognitive task analysis methods human factors methods practical guide engineering design ashgate publishing sutton barto reinforcement learning introduction ser adaptive computation machine learning series cambridge massachusetts mit press tavani levels trust context machine ethics philosophy technology australian govern ment defence act retrieved british academy royal society data management governance century retrieved institute ethical machine learning procurement framework practical templates support procurement retrieved thomas rainforest ignorance uncertainty retrieved rainforest official dstg official turek explainable artificial intelligence xai darpa retrieved artificial turek explainable artificial intelligence xai darpa retrieved artificial united states navy aegis weapon system aws united states navy fact file retrieved cid vallor ethical toolkit practic markkula center applied ethics retrieved wang jamieson hollands trust reliance automated combat identificati system human factors wilkinson counter side based practice oxford review retrieved intuitive based winkelman buenaventura anderson beyene katkar baumann autonomous vehicles hacked liable rand corporation yanardag cebrian rahwan norman worlds first psychopath mit media lab scalable cooperation retrieved zender anti missile defence artificial intelligence beyond horizon issg retrieved zuboff age surveillance capitalism fight human future new frontier power publicaffairs official dstg official appendix comparison ethica frameworks facets ethical topics emerging workshop australian government ethics principles department industry innovation science ieee ethically aligned design principles ieee global initiative ethics autonomous intelligent systems defense ethical principles defense innovation board principled artificial intelligence map ethical rights based approaches fjeld global landscape ethics guidelines jobin responsibility responsible education command human social environmental wellbeing throughout lifecycle systems benefit individuals society environment centred values throughout lifecycle systems respect human rights diversity autonomy individuals human rights autonomous intelligent systems shall created operated respect promote protect internationally recognized human rights creators shall adopt increased human well primary success criterion development responsible human beings exercise appropriate levels judgment remain responsible development deployment use outcomes dod systems promotion human values professional responsibility responsibility official dstg official governa nce controlled effectiveness integration transparency human factors scope confidence resilience empowerment transparency explainability transparency responsible disclosure ensure people know significantly impacted system find system engaging effectiveness creators operators shall provide evidence effectiveness fitness purpose transparency basis particular decision always discoverable competence creators shall specify operators shall adhere knowledge skill required safe effective operation governable dod systems designed engineered fulfil intended function possessing ability detect avoid unintended harm disruption human automated disengagement deactivation deployed systems demonstrate unintended escalat ory behaviour human control technology transparency transparency trust trusted sovereign capability safety reliability safety throughout lifecycle systems reliably operate accordance intended purpose fairness throughout lifecycle systems inclusive accessible involve data agency creators shall empower individuals ability access securely share data maintain people capacity equitable dod take deliberate steps avoid unintended bias development deployment combat systems would inadvertently cause harm persons fairness non discrimination safety security privacy justice fairness maleficence privacy official dstg official supply chain test evaluation misuse risks authority pathway data subjects result unfair discrimination agains individuals communities groups privacy protection security throughout lifecycle systems respect uphold privacy rights data protection ensure security data contestability system significantly pacts person community group environment timely process allow people challenge use output system control identity awareness misuse creators shall guard potential misuses risks operation reliable dod systems explicit defined domain use safety security robustness systems tested assured across entire life cycle within domain use law used lawfully protected symbols surrender equivalent equivalent equivalent equivalent traceablility actions recorded accountability responsible different phases system lifecycle identifiable accountable outcomes accountability shall created operated provide unambiguous rationale decisions made traceable dod engineering discipline sufficiently advanced technical experts possess accountability explainability official dstg official explainability accountability systems human oversight systems enabled appropriate understanding technology development processes operational methods systems including transparent auditable methodologies data sources design procedure documentation official dstg official appendix ethical risk matr table ethical risk matrix advice complete section activities ethical issue addressed risks actions timeline outcome assignee status define activity undertaking indicate ethical issue activity intended address estimate risk project objectives issue addressed define specific actions undertake support activity provide timeline activity define action activity outcomes identify responsible provide status update table example completed ethical risk matrix activities ethical issue addressed risks actions timeline outcome assignee status project activity identify mitigate unjust biases algorithm high evaluate bias conduct reduction risk project increase stakeholder buy stakeholder complete bias official dstg official appendix speakers facilit ators ethical defen workshop gpcapt jerome reid director plan jericho royal australian air force bob bolia research leader aerospace effectiveness aerospace division defence science technology group dst prof jason scholz ceo trusted autonomous systems defence cooperative research centre tasdcrc larry lewis vice president director center autonomy artificial intelligence centre naval analyses usa wgcdr julian tattersall australian defence force chap nikki coleman royal australian air force susan cockshell group leader human autonomous decision superiority defence science technology group fiona kerr founder director neurotech institute jai galliot research leader values defence security technology group australian defence force academy university new south wales lead ethics law trusted autonomous systems activity tasdcrc saba bazargan department philosophy university california san diego usa derek leben ethics autonomous systems university pittsburgh usa seth lazar project lead humanising machine intelligence anu ellen broad data ethics professor jacob hohwy principle investigator cognition philosophy lab monash university tim van gelder research lead swarm project university melbourne shane dunn scientific advisor joint division defence science technology group wgcdr julian tattersall royal australian air force official dstg official tristan perez research lead assurance autonomy trusted autonomous systems defence cooperative research centre rick shaw partner consulting part actuaries practice deloitte rain liivoja law university queensland lead ethics law trusted autonomous systems activity tasdcrc official dstg official appendix organisations att endance workshop australian army department foreign affairs trade attorney general department defence science technology group australian defence force academy fal lawyers australian defence magazine international committee red cross australian maritime safety authority joint capabilities joint information warfare information warfare joint intelligence australian national university mandarin australian strategic policy institute monash university bae systems neurotech institute boeing phantom works royal australian air force centre defence leadership ethics royal australian navy cna analysis solutions royal melbourne institute technology cyborg dynamics engineering skyborne technologies dalhousie university thales cranlana centre ethical leadership deakin university trusted autonomous systems defence cooperative research centre defence centre university california san diego defence force recruiting university melbourne defence legal university new south wales defence people group university pennsylvania defence science technology group univer sity pittsburgh defence signal cyber command university queensland defendtex university technology sydney deloitte official dstg official appendix contexts fence vast number potential military applications made necessary develop effective taxonomy ethical defence workshop taxonomy required ensure workshop addressed widest range applications defence warfighting business applications avoid exclusively focusing narrow applications autonomous weapons systems also designed identify different applications defence warrant different treatment relation ethical issues ensure relevance adf warfighting functions selected starting point taxonomy referred contexts defence contexts designed capture potential defence applications customised take consideration practical limitations background number participant contexts necessarily used universal taxonomy defence adf warfighting functions defined capabilities activities conducive military success operational level defence function set related joint capabilities activities grouped together help joint commanders integrate synchronise direct campaigns operations defence adf currently recognises warfighting functions command situational understanding force generation sustainment force projection force protection force application purpose workshop force application force protection situational understanding retained force generation sustainment subdivided force sustainment three level contexts personnel enterprise logistics business process improvement done emphasise role nonwarfighti functions adf addition category resulted contexts defence discussion decision made incorporate force projection workshop force sustainment context include command warfighting function incorporating command function somewhat controversial significant evidence function impacted however given command function significant overlaps functions excluded avoid duplication confusion particularly military participants general warfighting functions within adf doctrine currently review anticipated renamed joint functions existing functions remain unchanged possible addition official dstg official feedback taxonomy workshop positive participants military expertise invited share knowledge domain participants resulting contexts subsequently divided enterprise echelon contexts used active discussion sessions online platform contexts defence listed tag force application description conduct military missions achieve decisive effects kinetic non kinetic offensive means examples autonomous weapons aws combat vehicles subsystems used support strategic operational tactical planning including optimisation deployment major systems used modelling simulation used planning mission rehearsal used support targeting cycle including collateral damage estimation used information warfare generative adversarial network gan generated announcement strategic communication used identify potential vulnerabilities adversary force attack used discrimination combatants combatants additional function capturing capabilities activities information domain current approved warfighting functions used purpose ethical defence workshop official dstg official tag force protection description measures counter threats hazards minimise vulnerabilities joint force order preserve freedom action operational effectiveness examples autonomous defensive systems close weapons systems used cyber network defence used develop employ camouflage defensive deception systems techniques autonomous decoys physical optic radio frequency countermeasures identify potential vulnerabilities friendly force requires protection used simulate potential threats modelling simulation rehearsal activities autonomous medical personnel recovery systems tag force sustainment description activities conducted sustain fielded forces establish maintain expeditionary bases force sustainment includes provision personnel logistic form support required maintain prolong operations accomplishment mission examples autonomous combat logistics resupply vehicles automated combat inventory management predictive algorithms expenditure resources fuel spares munitions medical systems used combat environments expeditionary bases predicti algorithms casualty rates personnel equipment algorithms optimise supply chains recovery repair maintenance equipment algorithms support provision information climate environment topography used battle damage repair front maintenance official dstg official tag situational understanding description accurate interpretation situation likely actions groups individuals within situational understanding enables timely accurate decision making examples enables supports intelligence surveillance reconnaissance isr activities including object recognition categorisation still full motion video removal unwanted sensor data identification enemy deception activities anomaly detection alerts monitoring social media source media channels optimisation collection assets fuses data disseminates intelligence strategic operational tactical decision makers decision support tools battle management systems supports command control functions algorithms used predict likely actions groups individuals used assess individual collective behaviour attitudes rear echelon functions tag personnel description activities support raising training sustaining rts personnel examples used human resource management including record keeping posting promotion disciplinary performance management recruitment retention modelling future personnel requirements prediction supply demand events anomalies used individual collective training education including modelling simulation used testing certification personnel used model capability preparedness permanent reserve personnel official dstg official tag enterprise logistics description activities support rear enterprise logistics functions including support permanent military facilities examples autonomous rear supply vehicles warehouses used optimisation rear supply chains inventory management used depot intermediate maintenance including digital twinning predictive maintenance global supply chain analysis prediction optimisation level analysis prediction resource demand supply fuel requirements used day operation permanent military facilities tag business process improvement description activities support rear administrative business processes related personnel logistics examples used information management record informational assistants policy chatbots supports management policy procedures used optimise business administrative processes including modelling simulation tools used enterprise business planning strategic operational tactical level official dstg official appendix taxonomy decisi problems content contributed tristan perez reformatted report see also french maule papamichail decision behaviour analysis support cambridge cambridge university press decision type decision single decision maker single decisions decision whether continue current mission objectives consider alternatives given changes operational conditions decision deploying particular type weapon towards hostile asset multi sequential decisions time management supply chain support replenishment supplies mission number days months motion control network autonomous systems deliver interruptible communications missile guidance towards fixed target multi decision maker decisions conflict games cooperative noncooperative iterated iterate zero sum zero sum two players games two governments negotiating contested land sea area sequential games two craft pursue evade situation multiple autonomous systems avoiding collisions seeking attain individual mission goals managing network military assets engagement consensus decisions social choice resolution security council number countries developing guidelines conduct trials autonomous systems international maritime organisation meeting group manned assets group deciding engage hostile asset jury deciding guilt innocence prime minister council decision escalating war official dstg official appendix data item description example possible legal ethical assurance program plan leapp official defence document content approved official use data item descriptio number title legal eth ical assurance progr plan artifici intelligence systems description intended use legal ethical assurance program plan leapp describes contractor plan assuring software acquired contract categorised artificial intelligence meets commonwealth legal ethical assurance lea requirements contractors acquiring supplying software classified contract leapp expected describe approach plans procedures applied management software acquired supplied would typically include monitoring review subcontractors developing software configuration management acquired software integration verification software elements supplied contract commonwealth uses leapp provide visibility contractor technical planning progress risk assessment purposes provide input commonwealth planning leapp subordinate following data items data items required contract software management plan smp integrat support plan isp configuration management plan cmp verification validation plan applicable documents following documents form part extent specified herein xxxx australian defence framework ethical preparation instruct ions generic format content data item shall comply general format content preparation instructions contained cdrl clause entitled general requirements data items official dstg official data item shall include traceability matrix defines specific content requirement contained addressed sections within data item specific content description functionality leapp shall describe relevant context environments software required function leapp shall describe nature decisions software making supporting integration human operators leapp shall describe software integrates human oper ators ensure effectiveness legal ethical making anticipated contexts countermeasures misuse leapp shall describe countermeasures within software prevent misuse ethical frameworks subject matter experts leapp shall describe scientific academic ethical frameworks used develop software leapp shall identify legal ethical subject matter experts used contractor guide software development verification validation lea aspects leapp shall describe lea verification validation software integrated effort within contractor program leapp shall identify design milestones lea tests performed assess compatibility among human performance requirements personnel aptitude skill requirements training requirements equipment design aspects personnel equipment software interfaces leapp shall identify major objectives describe methods applied lea program legal ethical assurance subcontractor efforts leapp shall define work conducted subcontractors shall scoped managed monitored ensure contract objectives leapp shall define subcontractor documentation relating legal ethical assurance controlled integrated overall project documentation expectations contractor leapp shall identify expectations contractor respect commonwealth order ensure lea objectives met legal ethical assurance system analysis leapp shall describe participation lea system mission analysis determination system functional requirements capabilities allocation system functional requirements development system functional flows performance system effectiveness studies leapp shall describe methods used contractor answer following questions responsible controlled trusted used lawfully actions recorded official dstg official derivation personnel training requirements leapp shall describe methods contractor shall ensure operator maintainer personnel training requirements based upon lea requirements developed system analysis data legal ethical assurance working group sow requires contractor establish lea working group leawg leapp shall include plan leawg including objectives terms reference leawg membership points contact leawg arrangements conduct leawg meetings official dstg official appendix detailed judging cri teria conclusion workshop prize awarded scientific collaborative user betterbeliefs platform measured quality quantity evidence rat ing evidence suggested others live digital eaderboard available participants workshop eligible prize users add multiple pieces evidence get evidence evaluated users rate quality evidence suggested others points assigned maximum pts user highest number points prize criteria quality evidence pts quality evidence added user measured way users rate quality points assigned average quality user evidence star rating averaged evidence added ratings stars pts stars pts stars pts stars pts stars pts stars pts stars pts pts stars star pts star pts pts assigned number unique users rated evidence points assigned ranking users ratings others least rat ings others apportioning points based quartile rank pts pts pts pts criteria quantity evidence pts total number items evidence added user points assigned ranking users items evidence added least items evidence added apportioning points based quartile rank pts pts pts pts criteria rate people evidence pts total number unique items evidence rated user points assigned ranking users number unique items evidence rated least number unique items evidence rated apportioning points based quartile rank pts pts pts pts official dstg official appendix declaration perce ived conflict interests kate vitt kate devitt led build betterbeliefs social platform academic researcher queensland university technology qut qut staff tamara pearce distinguished professor kerrie mengersen alok chowdhury commercial research agreements expedia queensland fire emergency services world hospital congress investment qut bluebox instantiation theories kate phd thesis philosophy grounded bayesian virtue epistemology improve collective based making uncertainty however platform draws transdisciplinary research philosophy business innovation design bayesian statistics cognitive science information technology four contributing researchers owned qut fri day june company betterbeliefs pty licensing agreement qut use kate devitt ceo betterbeliefs pty kate devitt permanent employee defence science technology group dstg aerospace division human factors group social ethical robotic researcher declared background supervisor helen pongracic upon employment dstg nov ember discussed approved specific use betterbeliefs workshop craig rogers director commercialisation intellectual property technology partnerships office dst used trial tool jul aug ust cost dstg jericho tasdcrc trial business process fast based ideation physical virtual workshop participants capture workshop data kate devitt used tool workshop improve effectiveness efficiency communication documentation around ethical defence dst staff member commercial gain kate devitt declared interest platform participants workshop email person phone made clear using tool business tool dstg staff member commercial gain workshop participants wished discuss commercial aspects platform directed betterbeliefs chief operating officer business development manager tamara pearce tamara kate devitt commits recus ing commercial conversations regarding betterbeliefs platform duties official dstg official dst commercial activities undertaken kate devitt betterbeliefs managed application secondary employment per dstg policy guidelines tamara pearce manages agreement jericho trial use platform including information security information management including platform post official dstg official defence science technology group document control data document title method ethical defence security classification document title author kate devitt michael gan jason scholz robert bolia produced defence science technology group department defence box canberra act dstg number dstg report type technical report document date january task number task sponsor plan jericho air force trusted autonomous systems defence cooperative research centre research division aerospace division major science technology capability aerospace systems effectiveness science technology capability human factors secondary release statement document approved public release announceable limitations citable documents yes research library thesaurus ethics artificial intelligence artificial intelligence systems autonomous operations philosophy report outcomes workshop represent official position defence represents views expressed participants stakeholders workshop
