Artificial intelligence in the audiovisual sector IRIS Special IRIS Special 2020 -2 Artificial intelligence in the audiovisual sector European Audiovisual Observatory , Strasbourg 2020 ISBN 978-92-871-8806 -9 ( print edition ) Director of publication – Susanne Nikoltchev , Executive Direc tor Editorial supervision – Maja Cappello , Head of De partment for legal information Editorial team – Francisco Javier Cabrera Blázquez , Sophie Valais , Legal Analysts European Audiovisual Observatory Authors ( in alphabetical order ) Mira Burri , Sarah Esken s , Kelsey Farish , Giancarlo Frosio , Riccardo Guidotti , Atte Jääskeläinen , Andrea Pin , Justina Raižytė Translation France Courrèges , Julie Mamou , Marco Polo Sarl , Nathalie Sturlèse , Stefan Pooth , Erwin Rohwer , Sonja Schmidt , Ulrike Welsch Proofreading Anthony Mills , Catherine Koleda , Gianna Iacino Editorial assistant – Sabine Bouajaja Press and Public Relations – Alison Hindhaugh , alison.hindhaugh @ coe.int European Audiovisual Observatory Publisher European Audiovisual Observatory 76 , allée de la Roberts au F-67000 Strasbourg , France Tél . : +33 ( 0 ) 3 90 21 60 00 Fax : +33 ( 0 ) 3 90 21 60 19 iris.obs @ coe.int www.obs.coe.int Cover layout – ALTRAN , France Please quote this publication as : Cappello M . ( ed . ) , Artificial intelligence in the audiovisual secto r , IRIS S pecial , European Audiovisual Observatory , Strasbourg , 2020 © European Audiovisual Observatory ( Council of Europe ) , Strasbourg , December 2020 Opinions expressed in this publication are personal and do not necessarily represent the views of the European Audiovisual Observa tory , its members or the Council of Europe Artificial intelligence in the audiovisual sector Mira Burri , Sarah Eskens , Kelsey Farish , Giancarlo Frosio , Riccardo Guidotti , Atte Jääskeläinen , Andrea Pin , Justina Raižytė Foreword According to Elon Musk , the founder of SpaceX and CEO of Tesla , `` we should be very careful about artificial intelligenc e , '' it may be `` our biggest existential threat . '' Sounds scary , doesn ’ t it ? And yet , everybody is talking about it , and more and more companies are using it . It is the future , or so they say . But what is AI ? It is certainly not the dystopian vision served up by Hollywood in so many films , from 2001 , Space Odyssey to Blade Runner or Terminator . Not yet , at least . I am afrai d that the answer to the question “ What is AI ? ” is much more prosaic than all that : in the end , AI is mostly computers being computers ; sof tware code gulping tons of data and using all this raw information according to predefined instructions . Of course , the potential is awe -inspiring . Medicine , economics , transportation , energy … you name it . The practical applications are seemingly limitle ss . However , as with any other technical development , it is not without risks . AI also has a dark side , of course , bu t probably not as dramatic as Elon Musk would have us believe . Not yet , at least . In the audiovisual industry , as in other sectors , the in creasing use of artificial intelligence is likely to herald a paradigm shift , as it can transform the entire value ch ain : from content production , programming and advertising , to consumer expectations and behaviours due to the abundance of offers and devic es and the personalisation of content . On the dark side , though , AI can contribute to the proliferation of “ fake news ” , and it raises issues regarding users ’ right to information , media diversity and pluralism , and data protection , to name but a few . The European Audiovisual Observatory has decided to take a closer look at these effects by publishing this report , followi ng a workshop we organised in December 2019 , to discuss the opportunities and challenges raised by AI in the audiovisual sector , particularly in the journalistic field and in the film sector . More information about the interesting event , including a summar y of the discussions and links to the participants ’ presentations , is available here : https : //www.obs.coe.int/en/web/observatoire/ -/workshop -artificial -intelligence -in-theaudiovisual -industry - This report , conceived , shaped and coordinated by the European Audiovi sual Observatory ’ s legal department during the difficult months of lockdown , explores different issues requiring analysis from a regulatory standpoint , and is divided into three parts . The first is devoted to general umbrella issues and opens with Chapter 1 , written by IT specialist Riccardo Guidotti ( University of Pisa ) , who explains what AI is and delves in particular into the AI black box problem , that is to say the lack of transparency in how AI systems operate and make decisions , as well as into how e xplainable AI could be made possible . Two overview chapters follow this technical introduction : in Chapter 2 , Andrea Pin ( University of Padua ) offers an explanation of the regulatory problems thrown up by the collection and use of the stuff AI dreams are m ade of : Big Data . Chapter 3 , written by Sarah Eskens ( University of Amsterdam ) , provides an overview of issues relating to the impact of AI on freedom of expression and information , including the legal framework for AI use by the media and the effects on t he freedom of expression rights of others . The second part of the publication presents specific fields of media law and p olicy where AI may have a profound impact in the future . First comes cultural diversity in the algorithmic age . Mira Burri ( University of Lucerne ) discusses in Chapter 4 how , from news personalisation to recommendation algorithms on video on demand service s , AI appears to hold the key to our information needs and entertainment wishes , what effect this has , and whether there is a need for regulation . Other tricky legal questions are dealt with by Giancarlo Frosio ( Center for International Intellectual Proper ty Studies at the University of Strasbourg ) in Chapter 5 : if machines can “ create ” works , can they be copyright holders ? Or can a pers on or company be the copyright holder of a work created by a machine ? In Chapter 6 , Justina Raižytė ( European Advertising Standards Alliance ) explains how AI offers a new world of possibilities for advertisers and , in theory , can be more convenient for the customer , but also raises important privacy issues . In Chapter 7 , Kelsey Farish ( law firm D AC Beachcroft LLP , London ) takes us on a tour of personality rights issues - ghost acting , life and post-mortem personality rights , and infringement issues ( notably deepfakes ) . In the third part of the publication , Atte Jääskeläinen ( LUT University and Lo ndon School of Economics and Political Sciences ) presents in Chapter 8 what are , in his view , the main regulato ry challenges raised by AI in the audiovisual sector , focusing on possible fields of regulation along with potential risks . The introductory tex ts and the concluding remarks , authored by Francisco Javier Cabrera Blázquez , senior legal analyst at the Europ ean Audiovisual Observatory , aim at putting all these diverse legal and policy issues in perspective To this brilliant set of authors go my warme st thanks for having made this report so rich . To our readers , I can just say : enjoy the read ! Strasbourg , December 2020 Maja Cappello IRIS Coordinator Head of the Department for Legal Information European Audiovisual Observatory The Council of Europe is addressing AI in the Human Rights and other specific contexts . We invite you to visit https : //www.coe.int/en/web/artificial -intelligence/home for more information about the work of the Council of Europe ’ s Ad hoc Committee on Artificial Intelligence ( CAHAI ) . Table of contents 1 . Artificial intelligence and explainability ................................ ............................... 3 1.1 . What is artificial intelligence ? ................................ ................................ ................................ ................................ ................... 3 1.1.1 . A short history of artificial Intelligence ................................ ................................ ................................ ............ 4 1.1.2 . Different approaches for artificial intelligence ................................ ................................ ............................. 7 1.1.3 . Applications of artificial intelligence ................................ ................................ ................................ ................ 8 1.2 . What is explainable artificial intelligence ? ................................ ................................ ................................ ........................ 10 1.2.1 . Motivat ions for XAI ................................ ................................ ................................ ................................ ............... 11 1.2.2 . The dimensions of interpretability ................................ ................................ ................................ .................. 12 1.2.3 . Different explanations and how to read them ................................ ................................ ............................ 16 1.3 . AI and XAI in the media field ................................ ................................ ................................ ................................ .................. 21 1.3.1 . AI applications and explainability ................................ ................................ ................................ ................... 22 1.3.2 . VOD services in practice ................................ ................................ ................................ ................................ ...... 25 1.4 . Conclusion ................................ ................................ ................................ ................................ ................................ ...................... 26 2 . The stuff AI dreams are made of – big data ................................ ........................ 31 2.1 . Introduction ................................ ................................ ................................ ................................ ................................ ................... 31 2.2 . Privacy as the big data gatekeeper ................................ ................................ ................................ ................................ ....... 33 2.2.1 . The United States of America ................................ ................................ ................................ ........................... 33 2.2.2 . The European Union ................................ ................................ ................................ ................................ ............. 34 2.2.3 . China ................................ ................................ ................................ ................................ ................................ ........... 36 2.2.4 . Three differe nt approaches ? ................................ ................................ ................................ .............................. 36 2.3 . Big data bias and discrimination ................................ ................................ ................................ ................................ ............ 37 2.4 . Informing the people : Media , misinformation , and illegal content ................................ ................................ .......... 39 2.5 . Big data politics and the political bubble ................................ ................................ ................................ ........................... 42 2.6 . Media as surveillance watchdogs ? ................................ ................................ ................................ ................................ ........ 44 2.7 . The media market : Big data -driven market strategies ................................ ................................ ................................ ... 46 2.8 . Regulatory approaches to AI -based systems ................................ ................................ ................................ ..................... 48 2.9 . Conclusion ................................ ................................ ................................ ................................ ................................ ...................... 49 3 . Implications of the use of artificial intelligence by news media for freedom of expression ................................ ................................ ................................ .......... 53 3.1 . Introduction ................................ ................................ ................................ ................................ ................................ ................... 53 3.2 . AI applications for news media ................................ ................................ ................................ ................................ .............. 54 3.3 . The use of AI by news media as an element of media freedom ................................ ................................ ................. 56 3.3.1 . Democratic role of the news media ................................ ................................ ................................ ................ 56 3.3.2 . Beneficiaries of media freedom ................................ ................................ ................................ ........................ 57 3.3.3 . Duties and responsibilities and journalistic codes of ethics ................................ ................................ . 59 3.4 . Implications of AI for the freedom of expression rights of news users and other participants in public debate ................................ ................................ ................................ ................................ ................................ ................. 62 3.5 . Obligations of states regarding media freedom ................................ ................................ ................................ ............... 65 3.6 . Conclusion ................................ ................................ ................................ ................................ ................................ ...................... 67 4 . Cultural diversity policy in the age of A I ................................ ............................. 69 4.1 . Introduction ................................ ................................ ................................ ................................ ................................ ................... 69 4.2 . Understandi ng the changed environment of content creation , distribution , use and re -use ......................... 70 4.2.1 . Understanding the new intermediaries ................................ ................................ ................................ ......... 70 4.2.2 . Implications of AI -driven editorial agents ................................ ................................ ................................ .... 72 4.3 . Possible avenues of action : New tools addressing and engaging digital intermediaries ................................ . 76 4.3.1 . Governance of algorithms ................................ ................................ ................................ ................................ .. 76 4.3.2 . Governance through algorithms ................................ ................................ ................................ ....................... 79 4.4 . Concluding remarks ................................ ................................ ................................ ................................ ................................ .... 83 5 . Copyright - Is the machine an author ? ................................ ................................ . 87 5.1 . Introduction ................................ ................................ ................................ ................................ ................................ ................... 87 5.2 . Technology ................................ ................................ ................................ ................................ ................................ ..................... 89 5.3 . Protection : Can AI -generated creativity be protected ? ................................ ................................ ................................ .. 91 5.3.1 . Personality : Can a machine be a legal person ? ................................ ................................ .......................... 91 5.3.2 . Authorship : Can a machine be an author ? ................................ ................................ ................................ .... 94 5.3.3 . Originality : Can a machine be original ? ................................ ................................ ................................ ...... 100 5.4 . Policy options : Are incentives necessary ? ................................ ................................ ................................ ......................... 103 5.4.1 . No protection : Public domain status of AI -generated works ................................ ............................... 105 5.4.2 . Authorship and legal fictions : Should a human be the author ? ................................ ......................... 106 5.4.3 . Should a robot be the a uthor ? ................................ ................................ ................................ ........................ 112 5.4.4 . Sui generis protection for AI -generated creativity ................................ ................................ .................. 113 5.4.5 . Providing rights to publishers and disseminators ................................ ................................ ................... 113 5.5 . Conclusions ................................ ................................ ................................ ................................ ................................ .................. 114 6 . AI in advertising : entering Deadwood or using data for goo d ? ....................... 119 6.1 . Introduction ................................ ................................ ................................ ................................ ................................ ................. 119 6.2 . AI in advertising : From tracing online footprints to writing ad scripts ................................ ................................ .. 120 6.2.1 . Programmatic advertising : The stock market of ads and data ................................ ............................ 121 6.2.2 . Algorithmic creativity : AI dipped in the ink of imagination ................................ ................................ . 124 6.2.3 . From creative games to gains ................................ ................................ ................................ ......................... 125 6.2.4 . Conclusion : AI enabled intelligent advertising ................................ ................................ ......................... 129 6.3 . Concerns regarding Big Data and AI ................................ ................................ ................................ ................................ ... 130 6.3.1 . Existing legal framework in Europe ................................ ................................ ................................ .............. 131 6.3.2 . Conclusion : ( Mostly ) the Good , the Bad and the Ugly ................................ ................................ ............ 133 6.4 . Using AI for intelligent ad regulation ................................ ................................ ................................ ................................ . 134 6.4.1 . Avatars gathering data for good ................................ ................................ ................................ .................... 135 6.4.2 . AI advancements for advertising compliance in France ................................ ................................ ....... 136 6.4.3 . Harnessing technology to bring more trust to the Dutch ad market ................................ ............... 137 6.4.4 . Tech solutions from the ad industry powerhouse ................................ ................................ ................... 138 6.4.5 . Future frontier for advertising self -regulation ................................ ................................ .......................... 139 6.5 . Conclusion : ‘ The great data rush ’ ................................ ................................ ................................ ................................ ......... 140 6.6 . Acknowledgements ................................ ................................ ................................ ................................ ................................ ... 142 6.7 . List of interviews ................................ ................................ ................................ ................................ ................................ ........ 143 7 . Personality rights : From Hollywood to deepfakes ................................ ............ 147 7.1 . Introduction ................................ ................................ ................................ ................................ ................................ ................. 147 7.2 . AI sets the scene : Deepfakes and ghost acting ................................ ................................ ................................ ............... 148 7.2.1 . Deepfakes ................................ ................................ ................................ ................................ ............................... 149 7.2.2 . Ghost Acting ................................ ................................ ................................ ................................ .......................... 149 7.3 . Personality rights and implications ................................ ................................ ................................ ................................ ..... 150 7.3.1 . Angle 1 : Publicity as ( intellectual ) property ................................ ................................ .............................. 151 7.3.2 . Angle 2 : Publicity and brand recognition ................................ ................................ ................................ ... 152 7.3.3 . Angle 3 : Privacy protections ................................ ................................ ................................ ............................ 152 7.3.4 . Angle 4 : Dignity and the neighbouring r ights ................................ ................................ ........................... 154 7.4 . Laws in selected jurisdictions ................................ ................................ ................................ ................................ ............... 156 7.4.1 . Germany ................................ ................................ ................................ ................................ ................................ .. 156 7.4.2 . France ................................ ................................ ................................ ................................ ................................ ....... 158 7.4.3 . Sweden ................................ ................................ ................................ ................................ ................................ .... 159 7.4.4 . Guernsey ................................ ................................ ................................ ................................ ................................ . 160 7.4.5 . United Kingdom ................................ ................................ ................................ ................................ ................... 161 7.4.6 . California ................................ ................................ ................................ ................................ ................................ . 162 7.5 . What next for Europe ’ s audiovisual sector ? ................................ ................................ ................................ ..................... 164 8 . Approaches for a sustainable regulatory framework for audiovisual industries in Europe ................................ ................................ ............................. 171 8.1 . Introduction ................................ ................................ ................................ ................................ ................................ ................. 171 8.1.1 . The basics of AI , simplified ................................ ................................ ................................ .............................. 173 8.2 . How is AI used in audiovisual industries ? ................................ ................................ ................................ ........................ 175 8.3 . Is AI somewhat different than previous technolog ies ? ................................ ................................ ............................... 177 8.3.1. Who is responsible when AI causes harm ? ................................ ................................ ................................ 177 8.3.2 . It ’ s not just the economy ................................ ................................ ................................ ................................ ... 178 8.4 . We have a moral obligation to do good with AI ................................ ................................ ................................ ............. 179 8.5 . Regulation should be human -centric and goal -based ................................ ................................ ................................ . 180 8.5.1 . Major risks should be addressed ................................ ................................ ................................ .................... 181 8.5.2 . Humans are the responsible ones ................................ ................................ ................................ ................. 182 8.5.3 . Transparency as an interim solution ? ................................ ................................ ................................ .......... 182 8.6 . Human -centricity , not technology -centricity ................................ ................................ ................................ ................... 183 Figures Figure 1 . Example of global tree -based explanations returned by TREPAN ................................ ................................ ............... 17 Figure 2 . Example of list of rules explanations returned by CORELS ................................ ................................ ............................ 17 Figure 3 . Example of factual and counter -factual rule -based explanation returned by LORE ................................ ............ 18 Figure 4 . Example of explanation based on features importance by LIME ................................ ................................ ................. 19 Figure 5 . Example of explanation based on features importance by SHAP ................................ ................................ ................ 19 Figure 6 . Example of sal iency maps returned by different explanation methods . The first column contains the image analy sed and the label assigned by the black -box model b of the AI system . ................................ .. 20 Figure 7 . Example of exemplars ( left ) and counter -exemplars ( right ) explanation returned by ABELE . On top of each ( counter - ) exemplar is reported the label assigned by the black -box model b of the AI system . ................................ ................................ ................................ ................................ ................................ ................................ .. 21 Tables Table 1 . Programmatic advertising glossary ................................ ................................ ................................ ................................ ......... 121 Table 2 . Advertising and marketing campaigns enabled by creative AI technologies ................................ ........................ 125 List of abbreviations AGI Artificial general intelligence AI Artificial intelligence AI4SG AI fo r social good ANN Artificial neural networks AVMSD Audiovisual Media Services Directive CAN Creative Adversarial Network CDPA Copyright Designs and Patents Act CGI Computer -generated CJEU Court of Justice of the European Union CPU Traditional pr ocessors DNN Deep neural networks DSP Demand -side-platform EASA European Advertising Standards Alliance ECHR European Convention on Human Rights ECtHR European Court on Human Rights EDPB European Data Protection Board EGE European Group on Ethics in Science and New Technologies EPG Electronic programme guides EPRS European Parliamentary Research Service GAN Generative adversarial networks GDPR General Data Protection Regulation GPS General Problem Solver ” GPU Graphics processor units IAB Interactive Advertising Bureau IP Intellectual Property IPR Intellectual Property Rights LT Logic Theorist ( first reasoning program ) NLG Natural language generation NLP Natural language processing PSB Public service broadcasters ROI Return on investme nt RTB Real-time bidding SRO Advertising self -regulatory organisations SSP Supply -side platform SVM Support vector machines VFX Visual special effects WMFH Work -made -for-hire XAI Explainable AI ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 1 The black box As mentioned in the forewor d of this publication , AI is both a fascinating and scary development . Its current achievements and its potential are awe -inspiring indeed , and the different contributions of this publication bear witness to the many ways AI can revolutionise ( or is alread y revolutionising ) the audiovisual sector . AI machines can write music and lyrics , tell you what to watch and read next , and they can even ( virtually ) bring the dead back from the grave ! Which is maybe why AI , like any other disr uptive technological discov ery of the past , provokes feelings of fearfulness . This is only natural . It is human nature to fear what one can neither comprehend nor control . That is why the most pressing problem to be solved in the AI regulatory field appear s to be the so -called “ black box problem ” . As explained by Riccardo Guidotti in his contribution to this publication , “ black -box models are tools used by AI to accomplish a task for which either the logic of the decision process is not accessible , or it is accessible but not human -understandable ” . In other words , it is a machine taking decisions over humans ’ lives without human oversight or awareness of the reasons behind those decisions . The problem is , according to Guidotti , “ not only the lack of transpar ency but also possible bias es inherited by the black boxes from prejudices and artifacts hidden in the training data used by the obscure machine learning models of the AI systems ” . Indeed , one of the main issues with the use of algorithms today is transpar ency . If , as they say , an a lgorithm is like a cooking recipe , the algorithms used by certain companies must be like the Coca -Cola formula , the best kept recipe secret in the world . But it is also true that many people deal with algorithms the way they deal with certain foods : as lon g as they like what they are eating , they don ’ t really care about the recipe , and in most cases , they actually prefer not to know the ingredients . Anyway , at least in extreme cases , there is plenty to be scared about . Hence the calls from experts to have A I systems whose workings and results are explainable . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 3 1 . Artificial intelligence and explainability Riccardo Guidotti , University of Pisa Artificial Intelligence is nowadays one of the most important scientific and technological areas , with a huge socio -economic impact and pervasive adoption in every field of the modern information society . High -profile applications based on artificial intelligence include voice assistants ( e.g . Siri and Alexa ) , autonomous vehicles ( e.g . self -driving cars , drones , cleaning r obots ) , medical diagnosis , spam filtering , and image recognition . Artificial intelli gence systems achieve their impressive performance in emulating human behaviour mainly through obscure machine learning models . These models are generally based on deep neu ral networks that hide the logic of their internal processes . The lack of transpare ncy on how these models make decisions is a key ethical issue and a limitation to their adoption in socially sensitive and safety -critical contexts . Indeed , the problem is not only the lack of transparency but also the possible biases inherited by black -box models from artifacts and preconceptions hidden in the training data . In addition , artificial intelligence can be used for creating synthetic realistic contents . Artifici al intelligence is profoundly changing the media and entertainment industries , from personalised recommendations to content creation , underpinned by monetisation . 1.1 . What is artificial intelligence ? Artificial intelligence ( AI ) is the “ intelligence ” shown by machines or by any technology or software in performing an activity.1 The term “ artificial ” is used to distinguish it from the “ natural ” or “ biological ” intelligence displayed by humans . AI is a field of research in computer science that tries to understan d the heart of intelligence and to produce intelligent machines that reason and respond , simulating human intelligence . The study of AI is historically considered to be the study of “ intelligent agents ” perceiving an environment and performing actions that maximise their chances of successfully achieving 1 Russell , S. and Nor vig , P. , Artificial intelligence : a modern approach . Pearson . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 4 a predefined target .2 The theories and technologies related to AI have become more and more mature since its birth , and the application fields have been expanding . 1.1.1 . A short history of artificial Intelligenc e The term “ artificial Intelligence ” was proposed by John McCarthy d uring a workshop at Dartmouth University in 19563 to distinguish AI from cybernetics.4 The workshop is recognised as the moment in which AI was born . 1.1.1.1 . The early years of AI The early years of AI ( 1952 – 1969 ) were full of successes limited to the primitive computers of the time and to the belief that computers were no more than powerful calculators only able to do maths . Allen Newell and Herbert Simon , after “ Logic Theorist ” ( LT ) , the first reasoning program , designed the “ General Problem Solver ” ( GPS ) , which , differently from LT , was designed to imitate human problem -solving behaviours . Thanks to GP S , Newell and Simon formulated the famous physical symbol system hypothesis , which states that any system exhibiting intelligence must operate by manipu lating symbols . In 1958 , John McCarthy at MIT defined the high -level programming language Lisp which was used until the 1990s as the dominant AI language.5 In the 1960s , there were many successful n ew research directions6 in AI . 1.1.1.2 . The first AI winter From 1970 to 1980 , AI faced the so -called “ AI winter ” in which the research had a consistent slowdown.7 The researchers ’ promises of progress in AI didn ’ t hold up because of the technical limits imposed by the computers used to realise AI programs that were able to solve only “ toy ” problems.8 There was not enough processing speed or memory to achieve anything really useful . Logic -based AI systems introduced by McCarthy implementing deduction programs were n ot able to solve real problems , as they required 2 Poole , D. , Mackworth , A. , and Goebel , R. , Computational Intelligence . Pearson . 3 Crevier , D. ( 1993 ) . AI : the tumultuous history of the search for artificial intelligence , Basic Books , Inc. 4 AI and cybernetics are two different but interconnected research fields based on the same principle of binary logic . However , while AI is about creating machines that mimic human intelligence and that can behave like humans , cybernetics is based on a constr uctivist vision of the world , and it focuses on human -machine interactions : how a system processes information , responds to it and changes accordingly . Thus , the differences between AI and cybernetic s are not just semantical but rather conceptual . 5 Reilly , E. D. , Milestones in computer science and information technology , Greenwood Publishing Group . 6 McCorduck , P. and Cfe , C. , Machines who think : A personal inquiry into the history and prospects of a rtificial intelligence . CRC Press . 7 Russell , S. and Norv ig , P. , op.cit . 8 Crevier , D. , op.cit . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 5 a hug e number of steps to prove very simple theorems.9 Also , many AI programs practically need enormous amounts of data . Unfortunately , no one in that period had , or was able to collect , a database large eno ugh . The 1970s saw the creation of the successful log ic programming language Prolog ,10 a more fruitful approach to logic for AI that permitted tractable computation . Critics of the logical approach started a debate between the need to have machines that thi nk like people versus the need for machines that can solve problems independently from how people do . Consequently , the agencies that funded AI research became disappointed with the lack of progress and cut off almost all funding for research . Simultaneous ly , research on neural networks was interrupted for almost 10 years after the book Perceptrons was published in 1969 . A perceptron11 is a primitive form of neural network , and nowadays , neural networks are a vital part of modern AI systems . An ( artificial ) neural network is a machine learning model inspired by biological neural networks and composed of artificial neurons . It receives an input , combines the input with the neurons ’ internal state , and produces output using an activation function . The inputs ar e data , such as tables , images , or documents , and t he output is a classification . A neural network learns how to return output based on a certain input from an annotated training dataset . 1.1.1.3 . The boom of AI In the 1980s “ knowledge ” became the focus of AI resea rch , and many companies started to adopt forms of A I called “ expert systems ” . An expert system is an algorithm that , by exploiting a given knowledge represented with “ if–then ” rules , mimes the decision making ability of a human expert.12 An expert system is formed by a “ knowledge base ” that represents facts and rules , and by an “ inference engine ” that applies the rules to the known facts to deduce new facts . Expert systems were among the first successful AI software programmes adopted in business companies . Researchers realised that the power of expert systems came from the knowledge they contained and that “ ... intelligence might be based on the ability to use large amounts of diverse knowledge in different ways ” .13 This injection of confidence in AI pushed lenders to invest again in AI research . In parallel , there was a ’ revival ’ of neural networks . Hinton and Rumelhart made popular “ backpropagation ” ,14 an effective method for training neural networks . This training method made effective the usage of artifici al neural networks ( ANNs ) , m achine learning systems inspired by the biological neural networks of human brains.15 ANNs “ learn ” from examples contained in a dataset of knowledge how to assess a task , but without requiring existing task -specific rules . For in stance , they can recognise if an image 9 McCorduck , P. and Cfe , C. , op.cit . 10 Crevier , D. , op.cit . 11 Tan , P. -N. et al . , Introduction to data mining . Pearson Education India . 12 Jackson , P. , Introduction to expert systems . Addison -Wesley Longman Publishing C o. , Inc. 13 McCorduck , P. and Cfe , C. , op.cit . 14 Rumelhart , D. , Hinton , G. & Williams , R , “ Learning representations by back -propagating errors ” , Nature 323 , 533–536 ( 1986 ) , https : //doi.org/10.1038/323533a0 . 15 Tan , P. -N. et al. , op.cit . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 6 contains a pedestrian or a car by learning from images labelled with their content and without any prior knowledge of the objects studied . 1.1.1.4 . The second winter of AI Investments in research in AI went up and down during “ the second winter of AI ” ( 1987 – 1993 ) . Desktop computers not requiring any form of AI from Apple and IBM were slowly augmenting power and speed , and in 1987 they became more effective than the expensive Lisp and Prolog machines . However , despite criticis ms from some investors and governments , AI kept pushing forward . In these years the concept of “ intelligent agents ” was finalised thanks to economists ’ definition of a “ rational agent ” . An intelligent agent is a system that takes actions that maximise the chances of success with res pect to a predefined goal . In addition , AI became a “ rigorous ” scientific discipline because AI researchers increased the usage of sophisticated mathematical tools for developing AI programs . For instance , probability and decisio n theory were brought into AI by Judea Pearl ’ s book.16 However , despite these evident steps forward , AI as a theoretical academic research field received little attention because algorithms originally developed for AI began to be exploited as parts of large r systems in the technolog y industry , such as data mining , medical diagnosis , speech recognition , search engines , banking software , industrial robotics , etc . 1.1.1.5 . Big data , deep learning and AI Despite the aforementioned advances , the real turning point was mos tly due to the enormous increase in the power of computers by the 1990s . Very famous examples of successes due to these technological advancements in AI are Deep Blue17 and Watson.18 The IBM Deep Blue was the first chess -playing AI system to win against a wo rld chess champion , Garry Kasparov,19 in 1997 . In 2011 , IBM ’ s question -answering system Watson beat the champions of “ Jeopardy ! ” , a TV quiz show , by a significant margin . In addition , starting from 2010 , on top of the advances in computer power , AI entered a new era thanks to technological progress in terms of storage capability , the ease of accessing big data , and advanced machine learning techniques like deep neural networks . ◼ “ Big data ” identifies a huge collection of data that can not be stored , managed a nd processed using conventional software . The era of big data originated from two main flows : o ( i ) the industrial sectors storing information ranging from the log of activities to purcha ses of clients ; 16 Pearl , J . ( 1988 ) , Probabilistic reasoning in intelligent systems . 17 Available at https : //www.ibm.com/ibm/history/ibm100/us/en/icons/deepblue/ . 18 Available at https : //www.ibm.com/ibm/history/ibm100/us/en/icons/watson/ . 19 Russell , S. and Norvig , P. , op.cit . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 7 o ( ii ) the widespread collection by smartphones and mob ile devices of personal information of users from various sources such as online posts on social networks , emails , mobility traces , health records , etc . ◼ Deep neural networks ( DNNs ) are models realised as an evolution of traditional ANN by composition of m any processing layers ( deep ) . Deep learning is the branch of machine learning that studies DNNs . DNNs can be applied for assessing tasks that are much more complex than those that can be solved with ANN , such as image recognition , speech recognition , natur al language processing , etc . However , the recent popularity of DNNs is mainly due to novel computer graphics proces sing units ( GPU ) . GPUs allow a marked acceleration in the learning proc ess of DNNs and their efficient execution , as compared to traditional processors ( CPUs ) . Unfortunately , as discussed in the next chapter , DNNs suffer from a profound drawback : the lack of interpretability.20 1.1.2 . Different approaches for artificial intelligenc e Historically four different notions in terms of dealing with AI have been recognised,21 with respect to two dimensions : 1. observing the artificial way of thinking versus observing artificial behaviour ; 2. modelling humans or modelling an ideal standard ( cal led rationality ) . Hence , the four different notions are “ thinking human ly ” , “ thinking rationally ” , “ acting humanly ” , and “ acting rationally ” . Different researchers with different approaches have aligned with these four notions . As a consequence , research on AI has been divided into subfields that often fail to communicate wit h each other . These sub -fields can be differentiated with respect to philosophical variances and notions , the objectives of reaching particular goals , and the usage of certain technica l methods . Concerning the philosophical differences , we can recognise th e human -centred approach and the rationalist approach . The human -centred approach suggests that AI should simulate natural intelligence . On the other hand , a rationalist approach invol ves a combination of mathematics and engineering , and suggests that huma n biology is irrelevant . Under this vision , either AI can be designed through simple , elegant principles such as logic or optimisation , or it requires solving many distinct and complex problems . Regarding the different challenges in AI , the general problem of creating an intelligence has been divided into sub -problems that consist of specific capabilities that an intelligent system should have . The principal sub -problems are machine lea rning , planning , reasoning , problem -solving , representing knowledge , per ception , robotics , natural 20 Guidotti , R. , Monreale , A. , Ruggieri , S. , Turini , F. , Giannotti , F. , an d Pedreschi , D. ( 2018 ) , “ A survey of methods for explaining black box models ” , ACM computing surveys ( CSUR ) , 51 ( 5 ) :1 –42 . 21 Russell , S. and Norvig , P. , op.cit . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 8 language processing , and social intelligence.22 Each sub -problem corresponds to a subfield of study on computer science . Finally , in the history of AI , we re cognise a broad set of methods belonging to three different categories : 1 . “ Cybernetics ” explores the connections between neurobiology and information theory and tries to design machines that use electronic networks to display rudimentary intelligence ; 23 2 . “ Symbolic AI ” is based on the assumption that through the manipulation of symbols , it is possible to model many aspects of the human intelligence.24 3 . “ Statistical learning -based AI ” relies on strong mathematical approaches . Well-known methods used in AI systems are : “ logic ” , used for knowledge representation and for problem -solving ; “ probabilistic methods ” , used in reasoning , planning , learning , perception , and robotics ; “ search and optimisation methods ” , used for planning and for robotics ; “ machine learning methods ” such as decision tree classifiers , support vector machines ; and “ deep neural networks ” , used to address almost every challenge . A drawback of some of these powerful stat istical learning methods is that they are not interpretable , that is to say a human can not understand the logic of these systems in making decisions . 1.1.3 . Applications of artificial intelligence What can AI do today , and in which fields it is applied ? A complet e answer to this question is not easy , as nowadays AI is applied to a plethora of areas and tasks . In the following section , we briefly report some AI app lications that may be remarkable or interesting for readers of this publication . ◼ Robotic vehicles . Self-driving autonomous vehicles have been made possible thanks to the advancements in AI . Distinct AI components incorporated in systems such as collision p revention , lane changing , braking , etc . contribute to the overall functioning of autonomous cars . AI c ompanies involved with robotic vehicles are Tesla , Google , and Apple.25 ◼ Healthcare . AI in healthcare is used to support doctors . For instance , AI systems can be used for disease diagnosis , analysing the relationship between treatments and outcomes , discove ring issues related to dosage , supporting surgeons during 22 Poole , D. , Mackworth , A. , and Goebel , R. , op.cit . 23 Weiner , N. , Cybernetics ( or control and com munication in the animal and the machine ) , Cambridge ( Massachusetts ) . 24 Haugeland , J. , Artificial intelligence : the very idea . 25 CBInsights , 33 Corporations working on auto nomous vehicles . Retrieved on 16 March 2017 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 9 operations , supporting radiologists in interpreting images , and creating new drugs.26 ◼ Marketing , e conomics and finance . Companies and financial institutions were the first adopters of AI systems for market analysis , churn prediction , price forecasting , stocks supervision , portfolio management , algorithmic trading , etc . Also , AI is effectively used to r educe fraud and financial crimes . ◼ Media . The analysis of media content such as TV programmes , advert isements , movies and videos can be demanded of specific AI applications . The typical usage refers to face or object recognition , automatic subtitling , recog nition of relevant scenes , and to summarise content . Media analysis based on AI allows the creation of descriptive keywords for a media item in order to simplify media searches . Another application consists of monitoring the suitability of media content or automatically detecting appropriate/inappropriate logos and products related to advertisements . ◼ News and publishing . Nowadays , many companies are using AI techniques to generate news and reports automatically . Through AI , companies are also capable of wri ting text . An example of an application is the generation of personalised recaps for sports events.27 Another application turns structured data into comments in natural language . ◼ Music . AI has allowed , to an extent , the emulation of human -like composition , and it helps humans play music or sing.28 Computer accompaniment technologies are able to listen and follow a human performer so that they can play in synchrony . Interactive composition technologies allow AI to respond with a music composition to the perfor mance of a live musician . Finally , proje cts like Google Magenta , Sony Flow Machines , or IBM Watson Beat are able to compose music in any style after analysing large databases of songs . Other AI applications for music also cover music marketing and listenin g. ◼ Deepfakes . Deepfakes are synthetic me dia contents created through AI techniques which appear real to humans.29 Generally , they are images or videos in which a person is replaced with someone else with deep learning methods . The main methods used to creat e deepfakes involve the training of gen erative approaches such as generative adversarial networks ( GAN ) 30 or autoencoders.31 Even though deepfakes can be used for comedic purposes , they are better known as hoaxes , “ fake news ” , celebrity pornographic videos , and financial frauds . Consequently , both governments and industries work to develop AI tools to detect and limit 26 Coiera , E. , Guide to Medical Informat ics , the Internet and Telemedicine , Chapman & Hall , Ltd. , GBR , 1st edition . 27 Available at https : //www.barrons.com/articles/big -data-and-yahoos -quest-for-mass -personalization 1377938511 . 28 Roads , C. , “ Research in music and artificial int elligence ” , ACM Computing Surveys ( CSUR ) , 17 ( 2 ) :163 –190 . 29 Kietzmann , J. , Lee , L. W. , McCarthy , I. P. , and Kietzmann , T. C. , “ Deepfakes : Trick or treat ? ” , Business Horizons , 63 ( 2 ) :135 –146 . 30 Goodfellow , I. , Pouget -Abadie , J. , Mirza , M. , Xu , B. , Warde -Farle y , D. , Ozair , S. , Courville , A. , and Bengio , Y. , “ Generative adversarial nets ” , in Advances in neural information processing systems , pages 2672 –2680 . 31 Makhzani , A. , Shlens , J. , Jaitly , N. , Goodfellow , I. , and Frey , B. , “ Adversarial autoencoders ” , arXiv preprint arXiv :1511.05644 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 10 them . The reason is that , in the foreseeable future , AI will probably be able not only to create realistic images and videos , but full media co ntent such as movies , TV series , and TV programmes like reality shows and quizzes . 1.2 . What is explainable artificial intelligence ? Nowadays , AI systems are not only able to simulate the information process of human thinking and learning , but can also exceed h uman intelligence in resolving some t asks . This is possible because artificial intelligence is not human intelligence and , due to the widespread adoption of complex methods such as deep learning , AI does not act like human intelligence , or at least acts us ing a decision process that is not al ways human understandable . Indeed , the last decade has witnessed the rise of what Frank Pasquale calls the “ black -box society ” ,32 where AI systems adopt obscure decision -making models to carry on their decision processes . This choice is driven by high perf ormance in terms of accuracy33 achieved by these black -box models . Examples include neural networks and deep neural networks , support vector machines ( SVMs ) , and ensemble classifiers , but also compositions of expert syste ms , data mining , and hard -coded sof tware that “ hide ” the logic of their internal decision processes from humans.34 Thus , black -box models are tools used by AI to accomplish a task for which either the logic of the decision process is not accessible , or it i s accessible but not human -underst andable . The lack of explanations of how these black -box models make decisions poses a problem for their adoption in safety -critical contexts and socially sensitive domains such as healthcare and law . The problem is not on ly the lack of transparency but al so possible biases inherited by the black -boxes from prejudices and artifacts hidden in the training data used by the obscure machine learning models of the AI systems . Indeed , machine learning algorithms build models afte r a learning phase that is made po ssible by big data coming from logs of business processes and from the digital traces that people leave behind while performing daily activities ( e.g . purchases , movements , posts in social networks , etc. ) . This huge amount of data might contain human biase s and prejudices . Hence , decision models whose learning is drawn from them may inherit such biases , possibly leading to unfair and wrong decisions . Consequently , the research in explainable AI ( XAI ) has recently garnered m uch attention.35 32 Pasquale , F. , The black box society , Harvard University Press . 33 Tan , P. -N. et al. , op.cit . 34 The interested reader can find details ab out neural networks , SVMs , and ensemble classifiers in Tan , P. -N. et al. , op.cit . 35 Guidotti , R. , Monreale , A. , Ruggieri , S. , Turini , F. , Giannotti , F. , and Pedreschi , D. ( 2018 ) , op.cit . Miller , T. , “ Explanation in artificial intelligence : Insights from th e social sciences ” , Artificial Intelligence , 267:1 –38 . Adadi , A. and Berrada , M. , Peeking inside the black -box : A survey on explainable artificial intelligence ( xai ) . IEEE Access , 6:52138 –52160 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 11 Moreover , the General Data Protection Regulation ( GDPR ) 36 introduces a right of explanation for all individuals , to obtain “ meaningful explanations of the logic involved ” when automated decision making takes place . Despite conflicting opinio ns among legal scholars regarding the real scope of these clauses,37 there is a common agreement that the implementation of such a principle is imperative and that it represents today a huge open scientific challenge . XAI is at the heart of a responsible sc ience across m ultiple industry sectors and scientific disciplines . How can companies trust their AI products without understanding the rationale of their machine learning components ? In turn , how can users trust AI services ? It will be impossible to increa se the trust o f people in AI without explaining the rationale followed by obscure models . 1.2.1 . Motivations for XAI Besides theoretical , ethical , and legal motivations behind the need for explainable AI , there are real cases in which discrimination or errors co uld have been avoided if the AI had not been obscure . Having access to the reasons for AI decisions is particularly crucial in safety -critical AI systems like self -driving cars and medicine , where a possible wrong decision could even lead to the death of p eople . For exa mple , in the case of a self -driving Uber car that knocked down and killed a pedestrian in Tempe , Arizona , in 2018 , the use of interpretable models would have helped Uber understand the reasons behind the decision , and manage their responsibil ities . Another inherent risk of black -box components used by AI systems is the possibility of making wrong decisions learned from spurious correlations or artifacts in the training data . For instance , Ribeiro et al.38 show that a classifier trained to recog nise wolves a nd husky dogs was basing its predictions regarding distinguishing a wolf solely on the presence of snow in the background . The AI made this choice because all the training images with wolves had snow in the background . In another example , in 2 016 , the AI s oftware used by Amazon to determine the areas of the United States to which Amazon would offer free same -day delivery , unintentionally restricted minority 36 Regulation ( EU ) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons wit h regard to the processing of personal data and on the free movement of such data , and repealing Directive 95/46/EC ( General Data Protection Regulation ) . Available at https : //eur lex.europa.eu/legal -content/EN/TXT/ ? qid=1532348683434 & uri=CELEX:02016R0679 -20160504 . 37 Malgieri , G. and Comand é , G. , “ Why a right to legibility of autom ated decision -making exists in the General Data Protection Regulation ” , International Data Privacy Law , 7 ( 4 ) :243 –265 . Goodman , B. and Flaxman , S. , “ EU regulations on algorithmic decisionmaking and a ‘ right to explanation ’ ” , in ICML workshop on human interp retability in machine learning ( WHI 2016 ) , New York , NY . http : //arxiv.org/abs/1606.08813 v1 . Wachter , S. , Mittelstadt , B. , and Floridi , L. , “ Why a right to explanation of automated decision -making does n ot exist in the general data protection regulation ” , Intern ational Data Privacy Law , 7 ( 2 ) :76 –99 . 38 Ribeiro , M. T. , Singh , S. , and Guestrin , C. ( 2016 ) , “ Why should I trust you ? : Explaining the predictions of any classifier ” , in Proceedings of the 22nd ACM S IGKDD International Conference on Knowledge Discovery and D ata Mining , pages 1135 –1144 . ACM . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 12 neighbourhoods from participating in the programme ( often when every surrounding neighbo urhood was al lowed ) 39 . More recently , the journalists of ProPublica showed that the COMPAS score , a predictive model for the “ risk of crime recidivism ” ( proprietary secret of Northpointe ) , has a strong ethnic bias . Indeed , according to this score , a black p erson who di d not re -offend was classified as “ high risk ” twice as often as whites who did not re-offend . On the other hand , white repeat offenders were classified as “ low risk ” twice as often as black repeat offenders.40 1.2.2 . The dimensions of interpretability To “ interpret “ means to give or provide meaning or to explain and present in understandable terms certain concepts.41 Therefore , AI “ interpretability “ is defined as the ability to “ explain “ or to provide meaning with regard to decisions , in terms understan dable to a human.42 This definition assumes that the concepts composing an explanation are self -contained and do not need further explanations . Basically , an explanation is an “ interface “ between a human and an AI , and it is at the same time both human -unde rstandable and an accurate proxy of the AI . We can identify a set of “ dimensions “ to analyse AI systems ’ interpretability that , in turn , reflect on existing different types of explanations.43 1.2.2.1 . Black -box explanation vs. explanation by design We distinguish be tween black -box explanation and explanation by design . In the first case , the idea is to couple an AI with a black -box model with an explanation method able to interpret the black -box decisions . In the second case , the strategy is to substitute the obscure model with a transparent model in which the decision process is accessible by design . More in detail , the black -box explanation idea is to maintain the high performance of the obscure model used by the AI and to use a technique from XAI to retrieve the ex planations.44 This kind of approach is the most frequent one nowadays in the XAI research field . On the other hand , the “ explanation by design “ consists of directly designing a transparent model which is interpretable , and of substituting the black -box 39 Available at http : //www.techinsider.io/how -algorithms -can-be-racist -2016 -4 . 40 Available at http : //www.propublica.org/article/machine -bias-risk-assessments -in-criminal -sentencing . 41 Available at https : //www.merriam -webster.com/ . 42 Doshi -Velez , F. and Kim , B. , “ Towards a rigorous science of interpretable machine learning ” , arXiv preprint arXiv :1702.08608 . Arrieta , A . B. , D íaz-Rodr íguez , N. , Del Ser , J. , Bennetot , A. , Tabik , S. , Barbado , A . , Garc ía , S. , Gil-López , S. , Molina , D. , Benjamins , R. , et al . , “ Explainable artificial intelligence ( xai ) : Concepts , taxonomies , opportunities and challenges toward responsible ai ” , Information Fusion , 58:82 –115 . 43 Guidotti , R. , Monreale , A. , Ruggieri , S . , Turini , F. , Giannotti , F. , and Pedreschi , D. ( 2018 ) , op.cit . 44 Craven , M. and Shavlik , J. W. , “ Extracting tree -structured representations of trained networks ” , in Advances in neural information processing systems , pages 24 –30 . Ribeiro , M. T. , Singh , S. , and Gues trin , C. ( 2016 ) , op.cit . Lundberg , S. M. and Lee , S. -I. , “ A unified approach to interpreting model predictions ” , in Advances in neural information processing systems , pages 4765 –4774 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 13 comp onent in the AI system with the new interpretable model.45 In the literature , there are various models recognised as being interpretable . Examples are “ decision tree “ , “ decision rules “ , and “ linear models “ .46 These models are considered easily understandabl e and interpretable for humans . However , nearly all of them sacrifice performance in favo ur of interpretability . In addition , they can not be applied effectively to data types such as images or text , but only to tabular , relational data , in other words tabl es . 1.2.2.2 . Global vs. local explanations We distinguish between a global or local explanation depending on whether the explanation allows understanding of the whole logic of a model used by an AI system , or whether it refers to a specific case , that is to say onl y a single decision is interpretable . A “ global ” explanation consists in providing a way to interpret any possible decision of a black -box model . Generally , the black -box behavio ur is approximated with a transparent model trained to mimic the black -box beh aviour and also to be human -understandable . In other words , the interpretable model approximating the black -box provides a global interpretation . Global explanations are quite difficult to achieve and , up to now , can be provided only for AI working on tabul ar data . A local explanation consists in retrieving the reasons for the “ outcome ” returned by a black -box model relative to the decision for a specific instance . In this case , it is not required to explain the whole logic underlying the AI , but only the re ason for the prediction with regard to a specific input instance . Hence , an interpretable model is used to approximate the AI black -box behavio ur only in the “ neighbourhood ” of the instance analysed , in other words with respect only to similar instances . T he idea is that in such a neighbourhood , it is easier to approximate the AI with a simple and understandable interpretable model . Several local explanation approaches are analysed in the following sections . 1.2.2.3 . Interpretable models for explaining AI In the fol lowing section , we briefly describe the interpretable models most frequently adopted to explain obscure AI systems or to replace black -box components . ◼ A “ decision tree “ exploits a graph structured like a tree and composed of internal nodes representing te sts on features or attributes ( e.g . whether a variable has a value lower than , equal to or greater than a threshold ) , and leaf nodes representing a decision . Each branch represents a possible outcome.47 The paths from the root to the leaves represent the cl assification rules . The most common 45 Rudin , C. , “ Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead ” , Nature Machine Intelligence , 1 ( 5 ) :206 –215 . Rudin , C. and Radin , J. , “ Why are we using black box models in ai when we don ’ t need to ? a lesson from an explainable ai competition ” , Harvard Data Science Review , 1 ( 2 ) . 46 Freitas , A . A. , “ Comprehensible classification models : a position paper ” , ACM SIGKDD explorations newsletter , 15 ( 1 ) :1 –10 . 47 Quinlan , J. R. , C4.5 : Programs for Machine Learning . Elsevier . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 14 rules are “ if-then rules “ , where the “ if “ clause is a combination of conditions on the input variables . If the clause is verified , the ‘ then ’ part reveals the AI act ion . ◼ For a “ list of rules “ , given an ordered set of ru les , the AI returns as the decision the output of the first rule that is verified.48 ◼ Finally , “ linear models “ allow visualisation of features importance : both the sign and the magnitude of the contrib ution of the attributes for a given prediction.49 If the sign of an attribute -value is positive , then it contributes by increasing the model ’ s output , otherwise , it decreases it . Higher magnitudes of attribute -values indicate a higher influence over the pr ediction of the model . 1.2.2.4 . Desiderata of interpretability Since interpretable models are required to retrieve explanations , some desiderata should be taken into account when adopting them,50 in order to increase the trust in a given model . ◼ “ Interpretability “ consists in evaluating to what extent a given explanation is human -understandable . An approach often used for measuring the interpretability is the “ complexity “ of the interpretable surrogate model . The complexity is generally estimated with the ‘ size ’ of the interpretable model . For example , the complexity of a rule can be measured with the number of clauses in the condition ; for linear models , it is possible to count the number of non -zero weights , while for decision trees it is the depth of the tree . ◼ “ Fidelity “ consists in evaluating to what extent the interpr etable surrogate model is able to accurately ‘ imitate ’ , either globally or locally , the decision of the AI . The fidelity can be practically measured in terms of Accuracy score , F1 -score , etc.51 with respect to the decisions taken by the black -box model . Mor eover , an interpretable model should satisfy other important general desiderata : for instance , having a high accuracy in terms of evaluating the ability of the interpretable surrogate model to take decisions relating to unprecedented instances . ◼ “ Fairness “ and “ privacy “ are fundamental desiderata to guarantee the protection of groups against discrimination,52 and to ensure that the interpretable model does not reveal sensitive information.53 48 Yin , X. and Han , J. , “ Cpar : Classification based on predictive association rules ” , in Proceedings of the 2003 SIAM International Conference on Data Mining , pages 331 –335 . SIAM . 49 Ribeiro , M. T. , Singh , S. , and Guestrin , C. ( 2016 ) , op.cit . 50 Freitas , A . A. , op.cit . 51 Tan , P. -N. et al. , op.cit . 52 Romei , A. and Ruggieri , S. , “ A multidisciplinary survey on discrimination analysis ” , The Knowledge Engineering Review , 29 ( 5 ) :582 –638 . 53 Aldeen , Y . A . A. S. , Salleh , M. , and Razzaque , M. A. , A comprehensive review on privacy preserving data mining . SpringerPl us , 4 ( 1 ) :694 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 15 ◼ “ Usability “ is another property that can influence the trust in a m odel : for example , an interactive explanation can be more useful than a textual and fixed explanation . 1.2.2.5 . Model -specific vs. model -agnostic explainers We distinguish between model -specific or m odel-agnostic explanation methods depending on whether the techniq ue adopted to retrieve the explanation acts on a particular model adopted by an AI system , or can be used on any type of AI . The most used approach to explain AI black -boxes is known as ‘ reverse engineering ’ . The term stems from the fact that the explanati on is retrieved by observing what happens to the output , that is to say the AI decision , when changing the input in a controlled way . ◼ An explanation method is ‘ model -specific ’ , or not gener alisable,54 if it can be used to interpret only particular types of black -box models . For example , if an explanation approach is designed to interpret a random forest55 and internally uses a concept of distance between trees , then such an approach can not b e used to explain the predictions of a neural network . ◼ On the other hand , an explanation method is ‘ model -agnostic ’ , or generalisable , when it can be used independently from the black -box model being explained : the AI ’ s internal characteristics are not ex ploited to build the interpretable model approximating the black -box behavio ur . 1.2.2.6 . User background Varying levels of background knowledge and diverse experiences in various tasks are tied to different notions and requirements for the usage of explanations . Do main experts can be able to understand complex explanations , while c ommon users require simple and effective clarifications . Indeed , the meaningfulness and usefulness of an explanation depends on the stakeholder.56 For instance , taking as an example the af orementioned COMPAS case , a specific explanation for a score may make sense to a judge who wants to understand and double -check the suggestion of the AI support system and possibly discover that it is biased against black people . On the other hand , the sam e explanation is not useful to a prisoner who can not change the reali ty of being black . However , the prisoner can find useful , and therefore meaningful to him , the suggestion that when he is older he will have a lower risk of recidivism and house arrest wi ll be granted more easily . 54 Martens , D. , Baesens , B. , Van Gestel , T. , and Vanthienen , J. , “ Comprehensible credit scoring models using rule extraction from support vector machines ” , European journal of operational research , 183 ( 3 ) :1466 –1476 . 55 Tan , P. -N. et al. , op.cit . 56 Bhatt , U. , Xiang , A. , Sharma , S. , Weller , A. , Taly , A. , Jia , Y. , Ghosh , J. , Puri , R. , Moura , J. M. , and Eckersley , P. , “ Explainable machine learning in deployment ” , in Proceedings of the 2020 Conference on Fair ness , Accountability , and Transparency , pages 648 –657 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 16 1.2.2.7 . Time limitations The time that the user is allowed to spend on understanding an explanation or is available to do so is a crucial aspect . Obviously , the time availability of a user is strictly related to the scenario where the pr edictive model has to be used . In some contexts where the user needs to quickly take the decision , for example surgery or in the event of an imminent disaster , it is preferable to have an explanation that is simple and effective . In contexts , though , where the decision time is not a constraint , such as during a procedure to release a loan , one might prefer a more complex and exhaustive explanation . 1.2.3 . Different explanations and how to read them The emerging field of XAI is giving birth to a broad set of alternatives for explaining the black -box components of AI systems . Indeed , it is not possible to define a unique type of explanation that is suitable for every application . The following sections illustrate the most used types of explanations . 1.2.3.1 . Global expl anations 1.2.3.1.1 . Tree-based explanations Approximating an obscure AI component with a tree was one of the first approaches introduced.57 The TREPAN method is able to represent all the possible decisions taken by a neural network acting on tabular data through a si ngle decision tree . T REPAN builds a decision tree approximating the concepts represented by the networks by maximising a gain ratio58 calculated on the fidelity of the tree with respect to the decision of the neural network . T REPAN results allow to globall y explore a neural network through a tree structure that , starting from a roo t , shows for every path the conditions driving the decision process of the AI system . 57 Craven , M. and Shavlik , J. W. , op.cit . 58 Tan , P. -N. et al. , op.cit . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 17 Figure 1 . Example of global tree -based explanations returned by TREPAN 1.2.3.1.2 . List of rules As previously mentioned , an alternative to explaining black -box classifiers is to directly design transparent models for the AI systems . The CORELS method59 builds a list of rules and provides an optimal solution for tabular data . An example of list of rules is reporte d in Figure 2 . The rules are read one after the other , and the AI takes the de cision of the first rule for which the conditions are verified . Figure 2 . Example of list of rules explanations returned by CORELS 1.2.3.2 . Local explanations The above explanations are global ex planations . However , when the obscure AI models to explain are too complicated , it is better to adopt a local XAI method and separately retrieve the reasons for the decisions for the various instances . Thus , nowadays , research on XAI is focusing more on lo cal explanations . The most representative local explanations are described in the following sections . 59 Angelino , E. , Larus -Stone , N. , Alabi , D. , Seltzer , M. , and Rudin , C. , “ Learning certifiably optimal rule lists ” , in Proceedings o f the 23rd ACM SIGKDD International Confer ence on Knowledge Discovery and Data Mining , pages 35–44 . ACM . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 18 1.2.3.2.1 . Rule-based explanations In if -then rule explanations under the prism “ if conditions , then consequent “ , the “ consequent “ corresponds to the decision of the AI , while the “ conditions “ explain the “ factual reasons “ for the “ consequent “ . For example , the explanation for the denial of a request by a customer of a loan with “ age=22 , race=black , and income=800 ” from a bank that us es an AI could be the factual rule “ if age25 and race=black and income 900 then deny ” . The LORE method builds a local decision tree in the neighbourhood of the instance analysed,60 then extracts from the tree a single rule revealing the reasons for the de cision with regard to the specific instance ( see the green path in Figure 3 ) . ANCHOR61 is another XAI approach for locally explaining AI through decision rules referred to as anchors . An anchor contains a set of features with the values that are fundamenta l for obtaining a certain decision . Figure 3 . Example of factual and counter -factual rule -based explanation returned by LORE 1.2.3.2.2 . Features importance Local explanations can also be returned in the form of features importance . Figure 4 shows the features importance returned by LIME62 with positive and negative contributions towards the black -box outcome and assigning their importan ce . LIME adopts a linear model as an interpretable local surrogate and returns the importance of the features as an explanation exploiting the regression ’ s coefficients . Figure 5 shows the feature importance returned by SHAP.63 SHAP provides the local uniqu e additive feature importance for a specific record . The higher a Shaply value , the higher the contribution of the feature . Under appropriate settings , LIME and SHAP can also be used to explain AI systems working on text . 60 Guidotti , R. , Monreale , A. , Giannotti , F. , Pedreschi , D. , Ruggieri , S. , and Turini , F. ( 2019a ) , “ Factual and counterfactual explanations for black box decision making ” , IEEE Intelligent Syste ms. 61 Ribeiro , M. T. , Singh , S. , and Guestrin , C. ( 2018 ) , “ Anchors : High -precision model -agnostic explanations ” , in Proceedings of the Thirty -Second AAAI Conference on Artificial Intelligence ( AAAI ) . 62 Ribeiro , M. T. , Singh , S. , and Guestrin , C. ( 2016 ) , op.cit . 63 Lundberg , S. M. and Lee , S. -I. , op.cit . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 19 Figure 4 . Example of explanation based on f eatures importance by LIME Figure 5 . Example of explanation based on features importance by SHAP 1.2.3.2.3 . Saliency maps In image processing , typical explanations consist of “ saliency maps “ , in other words images that show the positive ( or ne gative ) contribution of each p ixel to the black -box outcome . Saliency maps are efficiently built to locally explain DNN models by gradient and perturbation -based attribution methods . These XAI approaches search the most important pixels of the image such t hat it maximises the probabili ty that the AI returns the same answer without considering irrelevant pixels . Under appropriate image transformations that exploit the concept of “ super -pixels “ , methods such as LORE and LIME can also be employed to explain AI working on images . The method ABELE64 uses generative models to return a saliency map that highlights the contiguous areas that can be varied maintaining the same decision from the black -box used by the AI . Figure 6 is a comparison of saliency maps for classification of the handwritten digits 9 and 0 under the explanation methods ABELE,65 LIME,66 SALiency,67 GRADInput,68 INTGrad,69 ELRP.70 64 Guidotti , R. , Monreale , A. , Matwin , S. , and Pedreschi , D. ( 2019b ) , “ Black box explanation by learning image exemplars in the latent feature space ” , in Joint European Conference on Machine Learning and Knowl edge Discovery in Databases , pages 189 –205 . Springer . 65 Guidotti , R. , Monreale , A. , Matwin , S. , and Pedreschi , D. ( 2019b ) , op.cit . 66 Ribeiro , M. T. , Singh , S. , and Guestrin , C. ( 2016 ) , op.cit . 67 Simonyan , K. , Vedaldi , A. , and Zisserman , A , “ Deep inside con volutional networks : Visualising image classification models and saliency maps ” , arXiv preprint arXiv :1312.6034 . 68 Shrikumar , A. et al . , “ Not just a black box : Learning important features through propagati ng activation differences ” , arXiv :1605.01713 . 69 Sundararajan , M. et al . , “ Axiomatic attribution for dnn ” , in ICML . JMLR . Tan , P. -N. et al . 70 Bach , S. , Binder , A. , et al . , “ On pixel -wise explanations for non -linear classifier decisions by layer -wise relevan ce propagation ” , PloS one , 10 ( 7 ) : e0130140 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 20 Figure 6 . Example of saliency maps returned by different explanation methods . The first column contains the image analysed and t he label assigned by the black -box mo del b of the AI system . 1.2.3.2.4 . Prototype -based explanations An explanation based on “ prototypes “ returns specimens similar to the instance analysed , which makes clear the reasons for the AI system ’ s decision . Prototypes ar e used as a foundation of representat ion of a category , or a concept.71 Prototype -based explanations can refer to tabular data , images , and text . In Li et al.72 and Chen et al.,73 image prototypes are used as the foundation of the concept for interpretability.74 Kim et al.75 discuss the concept of “ counter -prototypes “ for tabular data , in other words prototypes showing what should be different , to obtain another decision . Exemplars and counter -exemplars are used by ABELE76 to augment the usability of the explanation based on a saliency map . Exemplar s ( left ) and counter -exemplars ( right ) for 9 and 0 are shown in Figure 7 . 71 Frixio ne , M. and Lieto , A. , “ Prototypes vs exemplars in concept representation ” , in KEOD , pages 226 –232 . 72 Li , O. , Liu , H. , Chen , C. , and Rudin , C. , “ Deep learning for case -based reasoning through prototypes : A neural network that explains its predictions ” , in Thirty-second AAAI conference on artificial intelligence . 73 Chen , C. , Li , O. , Barnett , A. , Su , J. , and Rudin , C. , “ This looks like that : deep learning for interpretable image recognition ” , arXiv:1806.10574 . 74 Bien , J. and Tibshirani , R. , “ Prototype selectio n for interpretable classification ” , The Annals of Applied Statistics , 5 ( 4 ) :2403 –2424 . 75 Kim , B. , Koyejo , O. O. , and Khanna , R. , “ Examples are not enough , learn to criticize ! criticism for interpretability ” , in Advances In Neural Information Processing Sys tems , pages 2280 –2288 . 76 Guidotti , R. , Monreale , A. , Matwin , S. , and Pedreschi , D. ( 2019b ) , op.cit . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 21 Figure 7 . Example of exemplars ( left ) and counter -exemplars ( right ) expl anation returned by ABELE . On top of each ( counter - ) exemplar is reported the label assigned by the black -box model b of the AI system . 1.2.3.2.5 . Counterfactual explanations A “ counterfactual “ explanation shows what would have to be different , to change the decisi on of the black -box model . The importance of counterfactuals is that they help people in reasoning on the cause -effect r elations between observed features and classification outcomes.77 While factual , direct explanations such as decision rules , and feature s importance , are crucial for understanding the reasons for a certain outcome , a counterfactual reveals what should chang e in a given instance , to obtain a different classification outcome.78 The aforementioned LORE method79 provides , in addition to a factual explanation rule , a set of counterfactual rules . With respect to Figure 3 , the set of counterfactual rules is highlight ed in purple and shows “ if income  900 then grant , or if race = white then grant ” , clarifying which changes would reverse the decisi on . The ABELE explanation method80 proposes counter -exemplar images highlighting the similarities and differences between sa me-class and other -class instances . 1.3 . AI and XAI in the media field AI technologies are transforming and reinventing the media industr y and its marketing , especially to facilitate the monetisation of content and to provide final users with super personalised services and advertising . In particular , there is a wide usage of AI applications in cinema , television , radio , the written press , and advertising . According to 77 Byrne , R. M. , “ Counterfactuals in explainable artificial intelligence ( xai ) : evidence from human reasoning ” , in Proceedings of the Twenty -Eighth Internati onal Joint Conference on Artificial Intelligence , IJCAI -19 , pages 6276 – 6282 . Apicella , A. , Isgr ò , F. , Prevete , R. , and Tamburrini , G. , “ Contrastive explanations to classification systems using sparse dictionaries ” in International Conference on Image Analy sis and Processing , pages 207 –218 . Springer . 78 Wachter , S. , Mittelstadt , B. , and Floridi , L. , op.cit . 79 Guidotti , R. , Monreale , A. , Giannotti , F. , Pedreschi , D. , Ruggieri , S. , and Turini , F. ( 2019a ) , op.cit . 80 Guidotti , R. , Monreale , A. , Matwin , S. , and Pe dreschi , D. ( 2019b ) , op.cit . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 22 Chan -Olmsted,81 we can recognise two characteristics to distinguish AI applications in the medi a field : ◼ Some applications are more relevant to media audiences , the “ demand side “ , others focus more on internal strategies of media providers , the “ supply side “ . At the same time , some are applicable to both groups , for example audience engagement , augm ented experience , and message optimisation . ◼ Some AI applications refer to “ content creators “ , while others are more relevant to “ content distributors “ for content analysis and discovery . The companies most active , by far , in the adoption of AI technologie s are online news services of companies such as the New York Times and video on dem and services such as Netflix or Prime Video . Examples of such AI applications are recommendation , personalisation , social network monitoring and listening , emotional trackin g and accessibility , video creation and post -production , information verification , predictive success analytics , customer relations , automated drafting , and voice assistants . 1.3.1 . AI applications and explainability Tech companies like Amazon , Netflix , Facebook , and Google are leading AI expansion in the media sector . For instance , the ‘ recommender systems ’ of Amazon Prime , Netflix , and Spotify are based on AI methods.82 A recent survey shows that the most common way in which new media are exploiting AI is to imp rove recommendation services . Another application for AI could be to reinvent the media -audience connection , that is to say AI might be used to understand audience sentiments , preferences and social conversations . This would make possible the matching of a udience interest in real -time to deliver a better consumption experience thro ugh personalised media contents . Finally , AI might help media companies identify new business opportunities : storylines or characters might be created based on users ’ preferences and tastes , opinions on social networks , conversations , etc .. 83 In the follow ing section , we discuss some specific applications of AI in the media industry . 1.3.1.1 . Recommendation The most notable use of AI in the media field is for content recommendation . The aim of a ‘ recommender system ’ is to predict the ‘ rating ’ or ‘ preference ’ a user would give to certain content , with respect to others . Recommender systems usually make use of ‘ collaborative 81 Chan -Olmsted , S. M. , “ A review of artificial intelligence adoptions in the media industry ” , International Journal on Media Manageme nt , 21 ( 3 -4 ) :193 – 215 . 82 Chan -Olmsted , S. M. , op.cit . 83 Kietzmann , J. , Paschen , J. , and Treen , E. , “ Artificial intelligence in advertising : How marketers can leverage artificial intelligence along the consumer journey ” , Journal of Advertising Research , 58 ( 3 ) :263 –267 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 23 filtering ’ and ‘ content -based filtering ’ , as well as other systems suc h as knowledge -based systems.84 Recommender systems have been widely adopted in many fields , but the media field is the one that better fits their usage . The idea of these approaches is to model a user ’ s past behaviour with the media content previously ‘ sel ected ’ or with numerical ratings given to those contents . Besides , recommen der systems can also consider similar behaviours made by other users . The widespread usage of recommender systems and the need to gain trust in AI systems from users implies that ea ch user must have access to explainable recommendations.85 In other words , the recommendations must be not only accurate and useful but also understandable . The most relevant types of explainable recommendations for media are user -based explanations , featur e-based explanations , and item -based explanations : ◼ For user-based explana tions the explanation can be something like : “ This content is recommended to you because similar users have selected it before ” , and it is composed of a set of ( anonymised ) similar u sers together with the contents they have selected . ◼ A feature -based expla nation would reveal : “ This content is recommended to you because it is described by these features ( e.g . features related to topics , actors , music , etc . ) that you like ” , and offers t he features according to the ratings you have assigned to them . ◼ Finally , an item-based explanation would say : “ This content is recommended to you because it is similar to these other contents you have liked before ” .86 Early recommendation models , such as item/user -based models , are transparent and explainable . Achieving greate r transparency has been recognised as a crucial aspect in raising trustworthiness , effectiveness , persuasiveness , efficiency , and satisfaction in the final user.87 Recent advances in A I and the use of DNN have helped improve precision in recommendation , but have completely erased transparency because of the use of complex , obscure models such as DNN . The lack of explainability in recommender systems in the media ind ustry can lead to man y problems . Without letting the users know why specific results are provided , the system may be less effective in nudging the users toward a particular content , which may further decrease the system ’ s trustworthiness . 84 Manning , C. D. , Raghavan , P. , and Sch ütze , H. , Introduction to information retrie val , Cambridge university press . 85 Zhang , Y. and Chen , X , “ Explainable recommendation : A survey and new perspectives ” , arXiv preprint arXiv :1804.111 92 . 86 The interested reader can find in Zhang , Y. and Chen , X . , op.cit . , other relevant types of explainable recommendations . 87 Tintarev , N. and Masthoff , J. , “ A survey of explanations in recommender systems ” , in 2007 IEEE 23rd international conference on data engineering workshop , pages 801 –810 . IEEE . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 24 1.3.1.2 . Personalisation a nd customisation Personalisation in the proposal and curation of media contents is a fundamental aspect addressed in the media industry through AI . Indeed , AI systems in the media industry excel in precisely tailoring content distribution strategy thanks to recommender system s. For instance , AI systems can analyse trends on social networks , to identify the best content to broadcast . Another application is to analyse audiences , to automatically generate titles/summaries/illustrations with keywords that guar antee higher content visibility . In addition , AI can automate media content generation , and curation , regularly update theme -based playlists , and profile users to make customised recommendations . In this way , the media content proposed to each user can be different and tailore d to each user ’ s profile , the journey/commuting of the user , or when and where the media service is used . Other applications are relative to engaging the user with the right content , proposed in the proper format at the right moment in a completely persona lised way . It is like having a personal editor for each individual to curate the perfect reading experience . 1.3.1.3 . Content creation As previously discussed , one of the most recent uses of AI is for creating news , music , and videos . In partic ular , we can use the term ‘ robot journalism ’ or ‘ automated journalism ’ . In this case , AI systems use natural language generation algorithms to turn data and knowledge into news stories , images , and videos . For instance , AI systems can easily write articles that are relatively boring for humans , such as those on weather or financial reports , based on previous articles and available data . With respect to videos , by exploiting image recognition , AI can produce coherent video montages . Most of the major editing software publishers have already added automatic video processing functions to save editors time . Other software programmes like Gingalab88 adopt AI to create automated ‘ best of ’ videos based on pre -defined editorial lines ( e.g . humour , tension , focus on a protagonist , etc. ) . In September 2018 , the BBC broadcast a programme entirely created by a robot.89 1.3.1.4 . Fake content detection The weak point of this incredible achievement of AI that is ‘ creation ’ is the deepfake phenomenon.90 Luckily , although AI can gener ate fake media content , it can also contribute to detecting fake content . Indeed , AI can be a crucial asset in countering misinformation because the same technology used to fabricate a fake can be exploited to detect it . Through extensive analytical capabi lities and machine learn ing algorithms , AI can partially automate the verification of media content like news , images , and videos . 88 Available at https : // gingalab.com/ . 89 Available at https : //www.bbc.co.uk/programmes/b0bhwk3p # : ~ : text=Made % 20by % 20Machine % 3A % 20When % 20A I % 20Met % 20the % 20Archive , Documentary . 90 For a definition of deepfakes see 1.1.3 above . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 25 The main problem is that the quality of the detection comes from the experience of the AI which is translated into the availa bility of data sources f or discriminating between real and fake contents . Besides , such a source of information has to be generated by humans who manually annotate media content as fake or not . This manual step can create bias in the data because humans ma y not be able to verify all the media content necessary to train a fully working AI system , and may have to rely on their feelings about what is real and what is fake . XAI can be crucial in this phase of training for two reasons : First , users of the AI for fake content detection want to be sure that the logic followed in recognising the fake content is human -understandable . The expectation is something like : “ This news is fake because sentences are too repetitive and the images displayed are taken from existing websites. ” ; Second , AI systems must not rely on a biased dataset in providing suggestions . If all the real news comes from the same source , the explanation could reveal something like : “ This news is fake because it is not being shared by the New York Times . ” 1.3.1.5 . Further applicat ions AI and XAI can be used for many other applications in the media industry . In the following section , we name some of them without entering into details . AI can be used as a tool to improve conversations on the Internet , in other words to recognise hate speech , discrimination , trolls , etc . In this case , too , it is vital to access the reasons for which inadequate posts are recognised as such . AI for voice recognition is a basic for many modern services and vocal assistants like Ama zon ’ s Alexa , Google Home , or Apple ’ s Siri , which are present in every smart device . They exploit AI and natural language processing to answer our questions and fulfil our orders . Finally , it is worth mentioning that AI has strategic implications for moneti sing and predicting the success of media content . At the same time , concerning media ethics , XAI becomes crucial for communicating with the audience , in a transparent way , the logic adopted by the AI systems interacting with the users or making decisions f or them . Certain questio ns could arise , and through XAI , users can possibly have these questions answered : For example , what is the right proportion between personalisation and content discovery ? What level of recommendation do we want ? Why is this media c ontent considered real ? Under the GDPR , the first step of the media industry is to clearly reveal which contents are recommended/created by an AI . 1.3.2 . VOD services in practice VoD services have transformed the way we watch media content ranging from TV series and comedy shows to movi es and cartoons . These services algorithmically adapt the users ’ experience through heavy personalisation that is based on a large set of metadata ( including genre , c ategories , cast , and release date ) , on user behaviour data ( such as searching , browsing , r ating , and device type ) , but also on the rows selected for the homepage , the titles selected for those rows , the visuals for each movie , the movies in the playlist , e tc . The AI system adopted evolves , constantly collecting the personal data of ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 26 each user , a nd always offers a customised visualisation of options on which the user is most likely to click , depending on their use and context . The final goal is to find the be st combination of contents that can satisfy users instead of contents simply corresponding to the most users . Algorithms thus underpin creativity and diversity , rather than standardisation . These remarkable features are offered based on the AI recommendati on systems collecting the data of millions of users watching and rating the content on the se platform s. Nobody knows exactly how these recommendation system works . VoD services usually provide a description of their recommendations system in plain languag e , but they do not reveal details of the ir decision -making . In this sense , these AI recomm endation systems are black -box model s par excellence . Theoretically , a user may not be interested in how recommendations are happening because they are just going to relax in front of some enjoyable media content . However , such recommendations may not be e ntirely personal , but channelled by m arketing strategies or even worse by bias in the data used for the machine learning models . When supported by the application of AI using obscure recommenders based on machine -learning models , decisions or predictions r est on the learning obtained by autom ated processes , and the available or selected training dataset may not represent the population it was designed to assess . For instance , statistics based on people avoiding movies with Asian heroes could result in discr imination against this category of fi lm and wrongly rate it with a low score for a population that might nonetheless be interested in this kind of media content . Thus , the use of XAI to understand the training dataset and analyse how the data affect the re sults for different populations is cr ucial in identifying bias . For any of those services , a global explanation could describe how the algorithm behaves in general . For instance , we could discover that the AI recommender will not suggest a three -hour movie just before midnight on a weekday . O n the other hand , a local explanation could describe how the AI behaves for a specific individual . For example , if the customer under analysis generally watches VoD content from 12:00 to 14:00 in her lunch break , at wor k , then the service in question will not suggest a three -hour movie in this time slot . This is because the service in question may have inferred that this is the best course of action based on routine , even though the three -hour movie perfectly fits the us er ’ s interests . On the other hand , pe rhaps the user does not want the service in question to exploit this type of personal information in making recommendations . So detailed explanations would help VoD services gain more trust from their users . Theoretical ly , in every application in the media field using AI , suggestions should be based on unbiased recommendations and a trusted relationship between the service and its users . 1.4 . Conclusion Artificial Intelligence can not be the final solution for any application , and especially in the media field , i t needs to be attached to a human being , both when creating and checking media content , but also when watching recommended media content . Indeed , AI is fundamental on the demand side , on the content access side , and for monetisation . AI ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 27 has a great potenti al for the social good in helping navigate masses of content , by optimising searches and personalised recommendations , and by preventing manipulation . With the appropriate XAI tools and degree of trust from the audience and vendors , AI would effectively bo ost the media industry and all its related sectors and applications . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 29 Big data The obtaining and using of personal data by third parties , whether provided willingly or inadvertently by the users , can also have a very intrusive effect on their personal lives . Moreover , there are situations in which the state or private parties require insight into a user 's life that goes beyond what a user is prepared to accept . In his contribution to this publication , Andrea Pin states that the “ vast deployment of AI nowadays requires that the media sphere become aware of its unique role and that the media sector should strive to use AI in a lawful , ethical , and robust way ” . A matter of special concern is the appropriate role of me dia platforms in managing their contents . Debates are ongoing on the extent to which they should “ go beyond a merely passiv e role to pursue the worthwhile ethical goal for media platforms to patrol their content ” . In these cases , AI ’ s lack of humanity is precisely one of its biggest drawbacks . Filtering algorithms are extremely efficient in addressing and removing potential harmful content , but they can not match humans in making nuanced decisions on complex legal areas .91 91 Barker A. , Murphy H. , “ YouTube reverts to hu man moderators in fight against misinformation ” , Financial Times , 20 September 2020 , https : //www.ft.com/content/e54737c5 -8488 -4e66 -b087 -d1ad426ac9fa © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 3 ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 31 2 . The stuff AI dreams are made of – big data Andrea Pin , Associate Professor of Comparative Public Law , University of Padua 2.1 . Introduction It is commonly said that big data is the oil of the AI revolution.92 Since data science and technological engineering joined forces , a massive flow of in formation has flooded the globe , affecting how we live and understand politics , the economy and culture . Thanks to AI ’ s capabilities , the phenomenon of big data has had an enormous , and probably enduring , impact on how individuals and groups make plans , ob tain infor mation about themselves and the world , entertain themselves , and socialise . Nowadays ’ computers are technologically capacious . Their algorithms are extremely sophisticated . Their neural networks replicate the intellectual processing of human bein gs and ena ble them to make complex analyses . By processing big data , firms can anticipate customers ’ choices and preferences at such an early stage that they can predict what customers want even before they do . Thanks to big data , business processes are mo ving from a “ reactive ” to a “ proactive ” approach.93 The Internet is playing a fundamental role within this scenario . As individuals use the Internet to share information , even about themselves and their lives , practically without interruption , the web gathe rs the ra w materials from which AI will draw inferences , make guesses , and find out responses to queries . Oxford philosopher Luciano Floridi coined the concept of “ onlife “ to describe how frequently and unconsciously human beings transition between the rea l world a nd the online world.94 This phenomenon is escalating . In 2023 it is estimated there will be more than five billion Internet users and 3,6 devices per capita , and 70 % of world population will 92 Pan S. B. , “ Get to know me : Protecting privacy and autonomy under big data ’ s penetrating gaze ” , Harvard Journal of Law and Technology 30 , 2016 , p. 239 , https : //jolt.law.harvard.edu/assets/art iclePDFs/v30/30HarvJLTech239.pdf ; Surden H. , “ Artificial intelligence and law : An overview ” , Georgia State University Law Review 35 , 2019 , p p. 1311 and 1315 . 93 Microsoft Dynamics 365 , Delivering personalized experiences in times of change , 2007 , p. 3 , https : //w ww.hso.com/wp -content/uploads/2020/03/Digitally -transforming -customer -experiences -ebook.pdf . 94 Floridi L. , “ Soft ethics and the governance of the digital ” , Philosophy & Technology 31 , 1 , 2018 , p. 1 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 32 have mobile connectivity.95 The more the world is connect ed , the more big data will be produced . It is not by chance that one of the most hotly currently debated issues is the introduction of 5G networks , since they can provide considerable informational advantage to their owners . The media field and industry a re big players in this scenario . Their job has always consisted in collecting , processing , and disseminating inform ation . Thanks to big data , now they can profile their audience and learn what it expects , how to couch news or to tell a story , or what would be a good finale for a certain movie . Big data allows customisation of the offering through identification of pote ntial news -readers , or movie goers , as “ computers are more accurate than humans at predicting from ‘ digital footprints ’ personality traits [ o r ] political attitudes ” .96 The novelty brought about by big data is also changing the media landscape . “ … [ D ] igit al TV/movies/music and a myriad of online distribution models have been challenging incumbent distributors ( CDs , cable ) for years … Online pub lishers are mining consumer signals from what they read , where they are , the social signals they send –for example what articles they share , what topics are trending on Facebook and Twitter – to serve up personalised , relevant content while not being too r epetitive and predictable , thus automating and surpassing what human editors can do ” .97 Traditional media now comp ete in generating news with non -professional information providers that sift through the web searching for news or bloggers that share their vi ews on social media platforms within which distribution and consumption of content are virtually indistinguishabl e.98 This chapter addresses the most relevant legal ramifications of such a global shift in the media world . It touches upon the crucial issue of privacy protection . It then deals with the potential discriminations and bias that a big data -driven strategy can run into and considers the risks of misinformation , polarisation of politics , and the media field becoming a mass surveillance system . Late r on , the chapter casts a bird ’ s eye view at how media markets and strategies are changing in light of big data dynamics . Finally , it briefly addresses the debates on the correct regulatory approach to big data . Overall , the need to regulate AI has gained much traction throughout the years . Although technologies are global and know no border , the regulatory purpose , approach , 95 Cisco , Cisco Annual International Report ( 2018 -2023 ) W hite Paper , 9 March 2020 , https : //www.cisco.co m/c/en/us/solutions/collater al/executive -perspectives/annual -internet -report/white paper -c11-741490.html ? fbclid=IwAR31 -e732ws1p1cIW5PYHQjVOJkPSzV0dGt3sq_qkX_P8wb9Q4Yn0Ez0a0Y . 96 European Data Protection Supervisor , Opinion 7/2015 Meeting the challenges of big data , 19 November 2015 , p . 16 , https : //edps.europa.eu/sites/edp/files/publication/15 -11-19_big_data_en.pdf . 97 Byers A. , “ Big data , big economic impact ” , 10 , 2015 , https : //kb.osu.edu/bitstream/handle/1811/75420/ISJLP_V10N3_757.pdf ? sequence=1 & isAllowed=y . See also Bruckner M. A. , “ The promise and perils of algorithmic lenders ’ use of big Data ” , Chicago -Kent Law Review 93 , 2018 , p. 8 , https : //scholarship.kentlaw.iit.edu/cklawreview/vol93/iss1/1/ or Ambrose M. L. , “ Lessons from the Av alanche of Numbers : B ig Data in Historical Perspective ” , ISJLP , 11 , 2015 , p. 213 , ( “ Netflix predicts our movies ” ) . 98 Perritt H. H. Jr. , “ Technologies of storytelling : New models for movies ” , Virginia Sports & Entertainment Law Journal , 10 , 2010 , p. 153 , http : //blogs.kentlaw.iit.edu/perrittseminar/files/2016/07/perritt -technologies -ofstorytelling -Westlaw_Document_05_56_ 44.pdf . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 33 and scheme of the big legal players within this scenario – the United States , the European Union and China – diverge deeply . The US a pproach is committed to ensuring that markets within which AI is massively deployed remain open and efficient ; t he EU ’ s paramount concern seems to consist in ensuring that the dignity of the individual is respected ; China is mostly preoccupied with social peace , stability , and the ordered development of its economy . Each of these approaches accords big data a specif ic legal treatment . 2.2 . Privacy as the big data gatekeeper Concerns proliferate that big data -driven tools may integrate in a pervasive system of mass surveillance and manipulation . One of the main safeguards against this threat is privacy . Many countries and supranational legal systems have put in place regulations that limit and monitor what and how information is collected and processed , also with the purpose of constraining big data analytics and preventing social disruption . In this respect , privacy laws s erve as a shield against big data ’ s overreach . 2.2.1 . The United States of America The Western world is split in its understanding and protection of privacy . The approaches of the United States and the European Union are far from aligned . Despite its historical sensitiveness to privacy , the United States lacks comprehensive regulation of the collection and gathering of information on the web . Several leg al regimes coexist , each regulating a specific sector , without any comprehensive nationwide regulation.99 The US approach , however , usually sees information as a new , huge market , with positive ramifications for the national economy . While certain states ha ve started implementing pieces of legislation that protect and regulate privacy , with California in a leading position , the collection and gathering of personal data is largely allowed and even promoted . A quite general legal baseline is that the subjects who confer their data should be merely aware that their information will be processed in various ways , includin g for profiling and the trading of their preferences . Since most of the protagonists of the AI based global industry are based in the US , such a favourable regulatory scheme allows them to fully exploit the advantages of the new oil of data . 99 Houser K. A . & Voss W. G. , “ The end of Google and Facebook or a new paradigm in data privacy ” , Richmond Journal of Law and Technology , 25 , 2018 , p. 18 , https : //jolt.richm ond.edu/files/2018/11/Houser_Voss -FE.pdf . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 34 2.2.2 . The European U nion Privacy protection within the European Union is based on the General Data Protection Regulation ( GDPR ) ,100 which was adopted on 27 April 2016 and became applicable as of 25 May 2018 . The GDPR itself is the peak of a longer process that has enhanced the protection of personal data over the decades , and represents a very different journey from that of the United States . Although the European Union is committed to making it “ easier for business and public authorities to access high quality data to boost gr owth and create value ” ,101 the European Union ’ s overall attitude rests on a rejection of the commodification of personal data.102 The GDPR ’ s legal bas eline is that a subject must give his/her consent to data processing.103 Consent itself must be unambiguous , freely given , and well informed:104 the subject must be given the details about the scope and the purpose of the processing.105 The GDPR ’ s protection cov ers EU citizens as well as any other natural persons ’ data , as long as the processing takes place within the EU . In other words , it protects anyone within its territories.106 The gap between the US and the European approaches has created a rift in the excha nge of data across the Atlantic . The GDPR is very conservative as t o the sharing of information gathered within the European Union , and requires that any data transfer outside EU borders comply with EU standards.107 The EU regulatory philosophy has been perceived to be so protective of privacy that many non -EU citizens ten d to prefer EU based companies over entities not subject to the jurisdiction of the European Union . Conformance with the GDPR has therefore become a reputation asset for companies working in the field of AI even outside the European Union , pushing them to implement privacy protection rules spontaneously.108 100 Consolidated text : Regulation ( EU ) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protec tion of natural persons with regard to the processing of personal data and on the free movement of such data , and repealing Directive 95/46/EC ( General Data Protection Regulation ) ( Text with EEA relevance ) , https : //eur -lex.europa.eu/legal -content/EN/TXT / ? uri=CELEX:02016R0679 -20160504 . 101 European Data Protection Supervisor , Opinion 3/2020 on the European strategy for data , 16 June 2020 , p. 4 , https : //e dps.europa.eu/sites/edp/files/publication/20 -06-16_opinion_data_strategy_en.pdf . See also Council of the European Union , Shaping Europe ’ s Digita l Future – Council Conclusions , 9 June 2020 , https : //data.consilium.europa.eu/doc/document/ST -8711 -2020 -INIT/en/pdf . 102 European Data Protection Board , Guidelines 2/2019 on the processing of personal data under Article 6 ( 1 ) ( b ) GDPR in the context of the provision of online service s to data subjects , Version 2.0 , 8 October 2019 , No . 54 , https : //edpb.europa.eu/sites/edpb/files/files/file1/edpb_guidelin es-art_6 -1-badopted_after_public_consultation_en.pdf 103 Art . 6 GDPR . 104 Manheim K. & Kaplan L. , “ Artificial intelligence : Risks to privacy and democracy ” , Yale Journal of Law & Technology , 106 , 2019 , p. 1069 , https : //yjolt.org/sites/default/files/21_yale_j.l._tech._106_0.pdf . 105 Art . 6 , par . 4 , and 7 , GDPR . 106 European Data Protection Supervisor , Opinion 3/2018 EDPS Opinion on online manipulation and personal data , 19 March 2 018 , p. 14 , https : //edps.europa.eu/sites/edp/files/publication/18 -03-19_online_manipulation_en.pdf . 107 Art . 45 GDPR . 108 Moerel L. & Lyon C . , “ Commoditiza tion of data is the problem , not the solution – Why placing a price tag on personal information may harm rathe r than protect consumer privacy , Future of Privacy Forum , 24 June ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 35 Such a high level of privacy protection from the GDPR comes , however , at a cost . The companies ’ need to obtain consent from the Internet us ers who visit their websites translates into a plethora of repeti tious , and sometimes obscure , requests for consent that traditionally pop up as soon as a webpage is displayed.109 This phenomenon has flooded the Internet to the extent that most users simply click “ yes “ and keep navigating the website without paying atten tion to how their information is collected , processed and disseminated.110 This course of action is certainly risky but understandable . Some have made the estimation that a normal person – not a skilled lawyer or a maniacally meticulous Internet user – woul d waste 76 working days per year reading all the privacy warnings that pop up while he/she is online.111 Too much privacy protection can be counter -productive : individuals may give away all the p rotection by consenting in too superficial a manner , thereby allowing massive harvesting of their information . Moreover , the potentials of big data analysis can weak en the privacy protection accorded by the GDPR on many fronts . First , the GDPR imposes fewe r restrictions on anonymised data , as anonymisation is supposed to protect privacy . Thanks to increasing AI capabilities , however , “ it is becoming ever easier to inf er a person ’ s identity by combining allegedly ‘ anonymous ’ data with other datasets includin g publicly available information for example on social media ” 112 … “ The bigger and the more comprehensive ” a data collection , the more likely it is that an individual whose data has been anonymised will be re -identified.113 On top of this , EU privacy rules req uire that individuals be given detailed information regarding the purpose and scope of the processing of the data they confer . Through neural networks and deep lea rning , AI -based systems draw inferences that even software developers can not fully anticipate . This very capacity of big data jeopardises how EU privacy regulation is construed . As big data processing returns results that can not be fully foreseen , it is ex tremely difficult to provide individuals with a detailed picture of what their information wi ll be used for.114 2020 , https : //fpf.org/2020/06/24/commoditization -of-data-is-the-problem -not-the-solution -why-placing -aprice -tag-on-personal -information -may-harm-rather -than-protect -consumer -privacy . 109 European Data Protection Supervisor , Opinion 7/2015 Meeting the challenges of big data , op . cit . , p. 11 . 110 Tsesis A . , “ Marketp lace of ideas , privacy , and the digital audience ” , Notre Dame Law Review , 94 , 2019 , p. 1590 , https : //scholarship.law.nd.edu/cgi/viewcontent.cgi ? article=4845 & contex t=ndlr . 111 Hartzog W. , Privacy ’ s blueprin t , Harvard University Press , 201 8 . 112 European Data Protection Supervisor , Opinion 4/2015 . Towards a new digital ethics , September 11 , 2015 , p. 6 , https : //edps.europa.eu/sites/edp/files/publicati on/15-09-11_data_ethics_en.pdf . 113 European Data Protection Supervisor , Opinion 7/2015 , “ Meeting the challenges of big data ” , op . cit . , p. 15 . 114 AGCM , AGCOM , and Garante per la protezione dei dati personali , Indagine conoscitiva sui Big Data , p. 25-26 , https : //www.agcom.it/documents/10179/17633816/Documento+generico+10 -02-2020+ 1581346981 452/39c08bbe -1c02 -43dc -bb8e -6d1cc9ec0fcf ? version=1.0 . The document explains how “ dynamic consent ” is taking off as a viable option within the EU privacy regulatory scheme . This concept understands consent as a gradual process , during which the subject can be contacted more than once to ask whether he or she consents to a certain usage of his or her information . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 36 2.2.3 . China Chinese public and private institutions draw massive amounts of data from a wealth of sources to profile individuals with the highest degre e of accuracy . Collecting and processing personal data about the Chinese population is instrum ental to China ’ s grand civic plan , which foresees the implementation of a wide -ranging surveillance and monitoring scheme that exploits AI to profile and predict individuals ’ and groups ’ behaviours.115 The overall goal of this plan consists in the constructi on of a pervasive social credit system – an AI -based mechanism that gathers information from personal records , smartphones , and mass -surveillance systems , and th en ranks individuals and accords them privileges and rights based on their previous conduct.116 In China , public institutions are trying to make everyone ’ s life transparent , and not private . To this end , they partner with Chinese private firms . A handful o f big tech companies such as WeChat and Alibaba thus operate as digital hubs for the lives of Chinese citizens.117 The Chinese are encouraged to use the same mobile app for a wide array of activities – from reserving a taxi to paying for a restaurant , socia lising or interacting with a public administration . A huge amount of information about anyone is thus gathered and passed over to public institutions for profiling.118 2.2.4 . Three different approaches ? Odd as it may seem , some have speculated that a similar soci al credit system is already in place also in the private sector of the United States.119 Private com panies don ’ t merely profile their clients to make them loyal . They also sell the information about them to other companies . Personal preferences and purchase habits are thus matched to better profile users , anticipate their decisions , and nudge them.120 A ba nk or an insurance 115 State Council , Notice of the State Council Issuing the New Generation of Artificial Intelligence Development Plan , No . 358 July 2017 , p p. 2-5 , an d 18 -21 , https : //flia.org/notice -state -council -issuing -newgeneration -artificial -intelligence -development -plan . 116 State Council , Notice c oncerning Issuance of the Planning Outline for the Construction of a Social Credit System ( 2014 -2020 ) , No . 21 , 14 June 2014 , https : //chinacopyrightandmedia.wordpress.com/2014/06/14/planning -outline -for-the-construction -of-asocial -credit -system -2014 -2020 . 117 Pieranni S. , Red Mirror , Laterza , 2020 , pp . 22 -23 . 118 Ibid , pp . 40 and 115 . 119 Baker L. C. , “ Next generation law : Data -driven governance and accountability -based regulatory systems in the West , and social credit regimes in China ” , Southern California Interdisciplinary Law Journal , 28 , 2018 , pp . 170-171 , https : //lcbackerblog.b logspot.com/2019/05/just -published -next-generation -law-data.html . 120 The European Parliament has recently called on the European Commission to “ ban platforms from displaying micro -targeted ad vertisements ” : European Parliament , Resolution of 18 June 2020 on competition policy – annual report 2019 , https : //www.europarl.europa.eu/doceo/document/TA -9-2020 -0158_EN.h tml . According to Morozov E . , “ Digital socialism ? ” , New Left R eview , 116/117 , March -June 2019 , p. 62 , https : //newleftreview.org/issues/II116/articles/evgeny -morozov -digital -socialism , “ Amazon got a patent on ‘ anticipatory shipping ’ – allowing it to ship products to us before we even know we want them ” . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 37 company can accurately assess an individual ’ s financial risk based on a variety of information , ranging from his/her education , his/her l ifestyle , or the places and people he/she visits . A political party can assess the political inclina tion of an individual based on the movies he/she watches , the media channels he/she prefers , or his/her family records . It should be of little or no surprise that the overall US approach to data protection overlooks the negative potential of such a private accumulation of personal data . The US culture of rights has traditionally focused on keeping public powers under check . This approach is still livel y , and keeps the US attention focused on the threats of public powers , whereas Europe has always been more attentive to private companies ’ capacity to violate fundamental rights.121 The paradoxical result is that the US is the global hub for big data innova tion , but does not see the big data threat to fundamental rights the way Europe appears to do . Such differen t approaches to privacy have powerful consequences for the ordinary lives of citizens and media companies alike . As will become apparent below , the exploitation of AI -based technologies transforms media corporations into more than information givers . They can become information gatherers and participate in profiling individuals . 2.3 . Big data bias and discrimination Although one would not expect software t o be biased , one of the biggest challenges for data-driven technologies is their discriminatory potential . T he gathering , processing , and dissemination of information can incorporate , embed and amplify prejudices . The most famous example probably is the Mi crosoft chatbot Tay . In 2016 , Microsoft created a Facebook profile for innovative software capable of intera cting on the media platform with other Facebook users by gathering information from the web , identifying trends , and exchanging opinions accordingly . In the span of 16 hours , the Facebook account was opened and then shut down , after its creators realised i t was engaging in sexist and racist posts.122 The software developers certainly did not provide their bot with the set of prejudices it later display ed on the web . Its makers simply used the web itself to teach the bot , which evidently found racism and sexis m to be widespread and attention -drawing . Tay shaped its language and 121 As to the European attentiveness to private companies ’ harmful potential , see European Data Protection Offic er , Opinion 8/2016 EDPS Opinion on coherent enforcement of fund amental rights in the age of big data , 23 September 2016 , p. 5 , https : //edps.europa.eu/sites/ed p/files/publication/16 -09-23_bigdata_opinion_en.pdf . See also Pollicino O. , “ L ’ ‘ autunno caldo ’ della Corte di giustizia in tema di tutela dei diritti fondamentali in rete e le sfide del costituzionalismo alle prese con i nuov i poteri privati in ambito dig itale ” , Federalismi , 15 October 2019 , https : //www.federalismi.it/nv14/editoriale.cfm ? eid=533 . 122 “ Microsoft ‘ deeply sorry ’ for racist and sexist tweets by A I chatbot ” , The Guardian , 26 M arch 2016 , https : //www.theguardian.com/technology/2016/mar/26/microsoft -deeply -sorry -for-offensive -tweets-by-aichatbot . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 38 themes based on the training it was subject to . It learned and adopted prejud ices on its own . Tay ’ s ephemeral life explains the importance of training for AI . AI -based systems require a lot of data in order to learn . The more information they gather , the more capable they become of making inferences and choices . Unfortunately , big datasets to train algorithms are often unavailable , so software programmers often exploit what is already available on the web . This choice is extremely problematic , because human beings can not fully supervise the learning process , and AI can take unfores een or even unwelcome directions . It can draw and incorporate biases from society , boosting them with its activity.123 Unbalanced datasets can unintentionally create biases , as the case of facial recognition exemplifies . Western AI systems of face recognit ion often fail to correctly identify non -Caucasian individuals because other ethnic groups appear on the web l ess often than Caucasians , while AI software developed in China suffers from the reverse problem.124 As a result , there is a higher probability tha t , say , in Western countries an African individual is mistaken for someone else than a Caucasian is . Media syst ems that incorporate big data -based processes therefore face a formidable challenge , as by exploiting AI they may incorporate prejudices and soci al imbalances . Fighting discrimination is very difficult in the field of big data and neural networks because o f the dangers of “ proxy discrimination ” .125 Proxy discrimination is a private or public policy that includes a requisite or factor that is faciall y neutral but actually embeds a discriminatory tradition , practice , or belief . For example , in socially or terri torially divided societies , the zip code or the housing price can serve as a proxy discrimination for insurance policies or zoning , as it may de prioritise some ethnicities while preferring others . Even if software developers expressly prohibit AI from cons idering ethnicity while making inferences , other factors can serve as proxies for discrimination.126 Within a given society , big data -driven mark et strategies , political campaigns , or welfare providers can – even involuntarily – isolate and systematically di scriminate worse -off groups by proxy . 123 Stevens on M. T. & Doleac J. L. , Algorithmic Risk Assessment in the Hands of Humans , Institute of Labor Economics , 1 December 2019 , p. 1 , http : //ftp.iza.org/dp12853.pdf ; Bruckner M. A. , op . cit , p. 25 . 124 Grother P. , Ngan M. , Hanaoka K. , “ Face recognition vendor test ( FRVT ) Part III . Demographic effects ” , National Institute of Standards and Technology Interagency 8280 , December 2019 , https : //doi.org/10.60 28/NIST.IR.8280 . 125 Prince A. E. R. & Schwarcz D . , “ Proxy discrimination in the age of artificial intelligence and big data ” Iowa Law Review 105 , 2020 , p. 1260 , https : //ilr.law.uiowa.edu/print/volume -105-issue -3/proxy -discrimination -inthe-age-of-artificial -intelligence -and-big-data . 126 Idem . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 39 2.4 . Informing the people : Media , misinformation , and illegal content AI is a powerful media tool . It can dis cover facts , detect preferences , profile users and anticipate social trends . In a few words , it can provide peopl e with more of what they want to receive . Customising media offerings through big data has a price , though . AI is a very good tool for the pre -selection of content that media users may find of interest . Given the overflow of information , AI ’ s capacity to p rofile a user can predict his/her interests in a piece of information , making the media ’ s work more effective and the user ’ s experience more en joyable . However , AI exploitation may make media users unaware of the fact that their horizons are narrowing – that the type of information they receive may not portray reality accurately , but only the “ reality “ of what AI understands their interests to be . Feeding users with more of what they already prefer , know , or are interested in , tends to create social bubbles . Big data technologies can filter information depending on what a media user supposedly likes or believes . Instead of widening the horizon of users , AI is thus able to boost individuals ’ intellectual selectiveness . A user -friendly news industry may lose s ight of its purpose of providing society with broad perspectives , fully informed news and challenging viewpoints . Big data -driven media strateg ies can thus unwillingly trigger the creation of informational bubbles . There is the additional risk , however , th at a bubble is generated intentionally . Big tech companies can profile users and information to boost or hinder the spread of certain informati on depending on their market strategies or agendas.127 Big data also pits traditional media against social media . Social media exploit the strong protection normally accorded to freedom of speech , and live off their continuous presence on the web and their capacity to feed the audience with more news.128 They therefore offer a cheap and easily accessible alternative to professional media operators and outlets . Such asymmetric competition has triggered a dangerous “ race to the bottom ” in the field of news pro viders.129 In order to avoid losing the audience , traditional media try to keep up with the speed of non -professional services such as blogs , often at the expense of accuracy.130 AI-based media platforms ’ bubbles often participate in spreading “ fake news ” . A plague in today ’ s news industry , according to some statistics “ fake news ” is capable of 127 Singer H. , “ How Washington should regulate Facebook ” , Forbes , 18 October 201 7 , https : //www.forbes.com/sites/washingtonbytes/2017/10/18/what -to-do-about -facebook . 128 Shefa M. C. , “ First Amendment 2.0 : Revisiting Marsh and the quasi-public forum in the age of social media ” , University of Hawaii Law Review , 41 , 2018 , p. 160 . 129 AGCM , AGCOM , and Garante per la protezione dei dati personali , Indagine conoscitiva sui Big Data , op . cit . , p. 30 . 130 European Data Protection Supervisor , Opinion 3 /2018 EDPS Opinion on online manipulation and personal data , op . cit . , p. 13 ( “ There is evid ence that … concentration and elimination of local journalism facilitates the spread of disinformation ” ) . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 40 reaching more people and mor e quickly than curated , fact -checked information,131 giving life to what Cass Sunstein has called “ cybercascades ” .132 The bubble system aggra vates the process , as it filters out facts and different viewpoints , thereby reinforcing deeply held viewpoints and eve n prejudices . Big data -driven strategies are calling into question the historical role that the media system and freedom of speech have played in democratic regimes . Instead of broadening horizons , challenging viewpoints , exposing biases and making society progress , contemporary media platforms run the risk of mutually insulating social groups and reinforcing deeply held opinions . Tra ditionally , liberal constitutionalism values and protects freedom of speech greatly because different viewpoints make societi es progress through the free exchange of opinions . Contrarily , big data technologies are capable of creating “ echo chambers ” ,133 which expel dissent and gravitate around unchallenged beliefs . Opinions that challenge deeply seated worldviews are ejected from a bubble and will probably find their place within another bubble , which offers virtually no exchange outside itself . 134 Big d ata can thus narrow perspectives and immunise prejudices from the benefits of freedom of speech . Private and public institutions ha ve grown aware of the distortions that big data can cause to media and broader society . For example , Twitter recently created a contentious fact -checker tool with the purpose of detecting “ fake news ” or tweets that harm identifiable groups.135 The EU ’ s Code of Practice on Disinformation136 has urged a comprehensive consideration of the phenomenon , emphasising that “ all stakeholder s have roles to play in countering the spread of disinformation ” . A list of signatories to the code that includes Facebook , Google , M ozilla , TikTok and Twitter has thus promised to “ [ d ] ilute the visibility of disinformation by improving the findability of trustworthy content ” , and to “ facilitate content discovery and access to different news sources representing alternative viewpoints ” . Overall , many are calling for regulation of the deployment of AI in a way that would bring Internet service providers clos er to the “ traditional media responsibility standards ” .137 EU policies especially target terrorist content , child sexual abuse materia l , racism , and xenophobic and hate speech,138 which are usually topics of great concern for today ’ s 131 Idem . 132 Sunstein C. R. , “ # republic : Divided democracy in the age of Social Media ” , Princeton University Press , 2017 , p. 57 . 133 Sasahara K. et al . , “ On the inevitability of online echo chambers ” , https : //arxiv.org/abs/1905.03919 . 134 Jones R. L. , “ Can you have too much of a good thing : The modern marketplace of ideas ” , Missouri Law Review , 83 , 2018 , p. 987 , https : //scholarship.law.missouri.edu/mlr/vol83/iss4/8/ . 135 Pham S. , “ Twitter says it labels tweets to provide ‘ context , not fact -checking ’ ” , CNN Business , https : //edition.cnn.com/2020/06/03/tech/twitter -enforcement -policy/index.html . 136 EU Code of Practi ce on Disinformati on , https : //ec.europa.eu/digital -single -market/en/news/code -practice disinformation . 137 European Data Protection Supervisor , Opinion 3/2018 ED PS Opinion on onli ne manipulation and personal data , op . cit . , p. 16 . 138 Policy Department for Economic , Scientific and Quality of Life Policies , “ Online platforms ’ moderation of illegal content online ” , June 2020 , p. 9 , https : //www.europarl.europa.eu/RegData/etudes/STUD/2020/652718/IPOL_STU ( 2020 ) 652718_EN.pdf . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 41 social media . In fact , given the massive inflow of data , filtering information before deciding whether to host it is technically unrealistic . Online platforms thus normally blend two different schemes : on the one hand , they adopt a “ notice -and-takedown ” system - anyone can compl ain that a specific display of content is in breach of the law and have the medial platform make an assessment ; on the other hand , most platforms adopt big data -based filtering systems that sift through the materials automatically and pervasively , making d ecisions on what should be concealed from the public.139 Most platforms have an additional safeguard against such automated decisions , al lowing individuals to challenge a software decision to remove some material.140 Within the US and the EU , which has “ one of the most comprehensive regulatory frameworks for tracking illegal content online ” ,141 service providers enjoy broad liability exemptions . Such exemptions aim to preserve their positive role in connecting people and disseminating information.142 EU law has reinforced this rule by prohibiting its member states from imposing general obligations on hosting platforms to monitor the material they host.143 The scenario is in flux , however.144 In interpreting the Directive on electronic commerce , the Court of Justic e of the European Union has stated that service providers that do not simply passively display materials are expected to do more than simply review and remove materials when necessary once they are requested to do so.145 In fact , the court stated , a judicia l order of removal extends “ to information , the content of which , whilst essentially conveying the same message [ to which the judicial order refers ] , is worded slightly differently , because of the words used or their combination , 139 Ibid , p. 45 . 140 Ibid , p. 10 . 141 Ibid , p. 6 6 . 142 For the United States , see Title 47 , Section 230 of the Communication Decency Act , https : //www.fcc.gov/general/telecommunications -act-1996 ; For the EU , see Directive 2000/31/EC of the European Parlia ment and of the Council of 8 June 2000 on certain legal aspects of information society services , in particular electronic commerce , in the Internal Market ( ‘ Directive on electronic commerce ’ ) , https : //eur -lex.europa.eu/legal -content/EN/TXT/HTML/ ? uri=CELEX:32000L0031 & from=EN , Art . 14 : “ 1 . Where an information society service is provided that consists o f the storage of information provided by a recipient of the s ervice , Member States shall ensure that the service provider is not liable for the information stored at the request of a recipient of the service , on condition that : ( a ) the provider does not ha ve actual knowledge of illegal activity or information and , a s regards claims for damages , is not aware of facts or circumstances from which the illegal activity or information is apparent ; or ( b ) the provider , upon obtaining such knowledge or awareness , a cts expeditiously to remove or to disable access to the infor mation. ” As for the protection of minors , see Directive 2010/13/EU of the European Parliament and of the Council of 10 March 2010 on the coordination of certain provisions laid down by law , regul ation or administrative action in Member States concerning th e provision of audiovisual media services ( Audiovisual Media Services Directive ; codified version ; text with EEA relevance ) . A consolidated version including the amendments introduced in 2018 is available at https : //eur -lex.europa.eu/legal -content/EN/TXT/ ? uri=CELEX:02010L0013 -20181218 . 143 Policy Department for Economic , Scientific and Quality of Life Poli cies , op . cit . , p. 21 . 144 Nunziato D. C . , “ The marketplace of ideas online ” , Notre Dame Law Review , 94 , 2019 , p. 1521 , https : //scholarship.law.nd.edu/cgi/viewconten t.cgi ? article=4844 & context=ndlr . 145 C-324/09 , L ’ Oréal et al . v. eBay International AG , paras . 113-115 , http : //curia.europa.eu/juris/document/document.jsf ? text= & doci d=107261 & pageIndex=0 & doclang=en & mode =lst & dir = & occ=first & part=1 & cid=12642628 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 42 compared with the informat ion whose content was declared to be illegal ” .146 Some have criticised this sensible principle because it would result in the “ Good Samaritan pa radox ” : the more a platform is committed to patrolling the information it publishes , the more it becomes liable . There are concerns that such a judicial approach would encourage providers to remain passive and limit their monitoring activity in order to av oid liability risks.147 It is now a matter of debate whether the EU should revise its policy and imitate the US approach , which has preserved the liability exempt ion for platforms , as this would encourage them to become more proactive , or whether this would jeopardise the protection of individuals and groups.148 In the context of illegal materials posted on online platforms , AI can certainly play an important role . Given the huge amount of data exchanged and the tendency to create bubbles within which media use rs hardly find information they do not like or viewpoints they disagree with , illegal materials may not be detected by human beings for a long time . Developing AI-based systems that filter content may therefore become advisable or even necessary . AI and bi g data are not just part of the problem – they can be part of the solution . Obviously , AI -based monitoring should not become a form of automated censorship . Pr oviders may exploit AI systems to filter out materials that are simply controversial , thereby ins ulating the public sphere from minoritarian opinions or information that many would find hard to engage with . This risk should be kept in check . 2.5 . Big data poli tics and the political bubble149 Democracies need a sound public sphere to survive and flourish.150 The existence and exchange of alternative worldviews and political opinions is crucial for their survival . More generally , within democracies “ people should b e exposed to materials that they would not have chosen in advance ” ,151 as one of the benefits histori cally associated with democracies is that “ biases are filtered out in the large republic ” .152 Social media have flooded contemporary politics . Legal academia and courts have responded by slowly but steadily developing the classical idea of public forums to 146 C-18/18 , Eva Glawischnig -Piesczek v. Facebook Ireland Ltd . , par . 41 , http : //curia.europa.eu/juris/document/document.jsf ? text= & docid=218621 & pageIndex=0 & doclang=en & mode =lst & dir= & occ=first & part=1 & cid=12642666 . 147 Policy Department for Economic , Scientific and Quality of Life Poli cies , op . cit . , p. 20 ; Policy Department Econ omic and Scientific Policy , “ Liability of Online Service Providers for Copyrighted Content – Regulatory Action Needed ? ” , January 2018 , p. 10 , https : //www.europarl.europa.eu/RegData/etudes/IDAN/2017/614207/IPOL_IDA ( 2017 ) 614207_EN.pdf . 148 Ibid , p. 67 . 149 For a different viewpoint on the filter -bubble/echo chamber issue see chapter 5 of this publication . 150 Wischmeyer T. , “ Making social media an instrument of democracy ” , European Law Journal , 25 , 2019 , p. 172 , https : //onlinelibrary.wiley.com/doi/abs/10.1111/eulj.12312 . 151 Sunstein C. R. , op . cit . p. 6 . 152 McGinnis J. O. , Accelerating Democracy , Princeton University Press , 2013 , p. 127 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 43 incorporate also social media sites that are privately owned.153 Because of their pervasive social role and their pivotal importance in providing the public with news feeds and political opinions , the US Supreme Court has dubbed social media sites as “ the mod ern public square ” .154 They are so essential to social and political life – the court has ar gued – that they must be accessible to the general public.155 Since 2001 , US courts have also “ treated computers and Internet access as ‘ virtually indispensable in the modern world of communications and information gathering ’ . ” 156 Social media are not univer sally accessible places within which everybody is welcomed and able to make an argument , however . Big data analysis allows social media to segment the public sphere in self-referential bubbles.157 Even the media platforms that do not intentionally filter in formation , still tailor their news feeds to their users ’ needs and choices , therefore creating informational bubbles . Such bubbles are capable of dividing public opinion into impenetrable , homogenous spheres of influence.158 The creation of homogenous , part isan , non -conversational echo chambers is no substitute for democratic pluralism159 and can even threaten it.160 The scandal of Cambridge Analytica , which allegedly harvested data of Facebook users without their consent to develop “ psychographic profiles ” an d then target selected individuals to nudge their voting behaviours,161 is just one example of how big data can affect politics.162 And there is wider evidence of the deploymen t of big data -fed bots to influence political agendas.163 Harvard Law Professor Cas s Sunstein has explored the impact of AI -based social media platforms in the political sphere in his acclaimed volume # Republic .164 Sunstein has persuasively shown AI ’ s capacity to generate informational clusters and polarise politics . Political campaigns c an target well -profiled users , exposing them to certain opinions or facts while silencing or downplaying the statements of political opponents or facts that 153 Nunziato D. C. , op . cit . , p. 3 . 154 Packingam v. North Carolina 582 U.S. ___ ( 2017 ) , https : //www.supremecourt.gov/opinions/16pdf/15 1194_08l1.pdf . 155 Ibid . 156 Shefa M. C. , op . cit . , p. 164 . 157 Sunstein C. R. , op . cit . 158 Sasahara K. et al. , op . cit . 159 Wischmeyer T. , op . cit . , p. 173-174 . 160 Manheim K. & Kaplan L. , op . cit . , p. 109 . 161 Ibid , p. 139 . 162 For more examples drawn from various countries , see Gurumurthy A. and Bharthur D. , “ Democracy and the algorithmic turn ” , Sur International Journal of Human Rights , 27 , 2018 , pp . 43-44 , https : //sur.conectas.org/en/democracy -and-the-algorithmic -turn , and Tenove C. , Buffie J. , McKay S. and Moscrop D. , Digital threats to democratic elections : how foreign actors use digital techniques to undermine democracy , January 2018 , passim , https : //democracy2017.sites.olt.ubc.ca/files/2018/01/DigitalThreats_Report -FINAL.pdf . 163 When the Federal Communication Commission considered repe aling some rules regulating the Internet in 2017 , 21 out of 22 million commentsthe Commission received on its website were fake news ( Manheim K. & Kaplan L. , op . cit . , p . 145 . ) 164 Sunstein C. R. , op . cit . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 44 would call into que stion their own platform and agenda.165 AI thus splinters the public sphere into homogenous environments which hardly interact together . Successful politicians often go to extremes to galvanise their supporters and reinforce the bubble system . Big data poli tics often blurs the line between personal and institutional capacity . Many pol itical figures prefer using their personal social media profiles rather than institutional profiles also to communicate with the general public on institutional matters . By usin g their personal profiles , they force the public – which would normally follow institutional media pages and profiles - into their sphere of supporters . Some legal systems have deployed countermeasures to fight this privatisation of the public sphere into separate media echo chambers . The US experience provides the most telling examp le of this development . Many public figures – including President Donald Trump – who have used personal websites for institutional purposes have blocked individuals making criti cal comments about their posts , therefore walling them out from their briefing activity to citizens.166 Some citizens thus ejected from the audience sued the politicians - and won in court . Judges considered the structure of media platforms and how politicia ns were using them , and concluded that such platforms had to be considered public places that should remain open to everyone . Politicians could still “ mute ” their followers , thereby preventing them from engaging in a conversation within their own profile , but not “ block ” them , as this would have prevented some citizens from being informed on matters of public interest.167 2.6 . Media as surveillance watchdogs ? Big data analysis has been instrumental to the development of artificial face recognition techniques . Than ks to AI capabilities , software can peruse and compare an enormous amount of images , to find matches . Differently from old-fashioned close -circuit cameras , which human agents scrutinise looking for matches , today ’ s computer vision has the capacity to proce ss images almost instantly . In a 2019 decision , a Welsh court dealt with artificial face recognition.168 The software that the Welsh police had deployed at several public events was able to process up to 40 faces per second . The total figure is impressive : i n roughly 50 deployments , the software processed roughly 500 000 individuals – one out of six of the t otal population of Wales . AI can become a powerful tool of mass surveillance , as has already happened in countries such as China , where a 165 Mor N. , “ No Longer Private : On Human Rights and t he Public Facet of Social Network Sites ” , Hofstra Law Review 47 ( 2018 ) , p. 669 , https : //www.hofstralawreview.org/wp -content/uploads/2019/04/bb.7.mor_.pdf ( 6 Augu st 2020 ) . 166 Ibidem , p. 42 ff . 167 Knight First Amendment Inst . at Columbia Univ . v. Trump 302 F. Supp . 3d 541 ( SDNY 2018 ) , https : //digitalcommons.law . scu.ed u/cgi/viewcontent.cgi ? article=2780 & context=historical ( 6 August 2020 ) . 168 ( Bridges ) v. The Chief Constable of South Wales Police et al .¸ [ 2019 ] EWHC 2341 , https : //www.judiciary.uk/wp content/uploads/2019/09/bridges -swp-judgment -Final03 -09-19-1.pdf . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 45 project of a sys tematic AI -based surveillance system , with more than half a billion of cameras deployed , is ongoing.169 Face recognition cuts across a variety of issues seen above . First , face recognition techniques are a matter of privacy . They process human faces – not ju st of those in a database , but of everyone . In fact , in order to exclude someone from the group of pe rsons of interest , a software must process their face first . According to the European legal culture , such a massive privacy intrusion must be properly jus tified . As the European Court of Human Rights has repeatedly insisted , public interests do not overri de privacy concerns – on the contrary , they require a preliminary assessment of the expected benefits and costs to ensure that any deployment is proportion ate to the task.170 Second , face recognition techniques runs the risk of being biased . As noted above , “ false positives ” – wrong matches – are more frequent in ethnic groups that are underrepresented in the training materials.171 False positives often have pra ctical consequences , as they may reinforce racial prejudices and nudge public institutions , s uch as police patrols , to target ethnic minorities for which software returns more false positives.172 Third , face recognition can be misleading on a variety of grou nds . Some software programmes are able to exploit the immense AI capabilities by using live and recorded images coming from any Internet source.173 Such technology can exploit the media industry to gather more materials and increase its database . A debate is ongoing on the pros and cons of developing or adopting software that sifts through the web to find matches of people , as has happened in many local police agencies of the U.S. to track down suspects . Such a huge dataset draws on a variety of materials tha t can be spurious , incorporate bias,174 and transform any single bit of social life or media broadcast into a record . 169 Carte r W. M. , “ Big Brother facial recognition needs ethical regulations ” , The Conversation , 22 July 2018 , https : //theconversation.com/big -brother -facial-recognition -needs -ethical -regulations -99983 . 170 Lopez Ribalda and others v. Spain ( apps . No . 1874/13 and 8567/13 : http : //hudoc.echr.coe.int/fre ? i=001 197098 ) ; Gorlov and others v. Russia ( app . no . 2 7057/06 ; 56443/09 ; 25147/14 : http : //hudoc.echr.coe.int/spa ? i=001 -194247 ) ; Antovic and Mirkovic v. Montenegro ( app . no . 70838/13 : http : //hud oc.echr.coe.int/fre ? i=001 -178904 ) ; Bărbulescu v Romania ( app . no . 61496/08 : http : //hudoc.echr.coe.int/spa ? i=001 -177082 ) . 171 Buolamwini J . & Gebru T. , “ Gender shades : Intersectional accuracy disparities in commercial gender classific ation ” Proceedings of Machine Learning Research 81 , 2018 , p p. 1 and 15 , http : //proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf . 172 Fung B. and Metz R. , “ This may be America ’ s first known wrongful arrest involving facial recognition ” , 24 June 2020 , CNN Business , https : //edition.cnn.com/2020/06/24/tech/aclu -mistaken -facia lrecognition/index.html . 173 Hill K. , “ The secretive company that might end privacy as we know it ” , New York Times , 18 January 2020 , https : //www.nytimes .com/2020/01/18/technology/clearview -privacy -facial -recognition.ht ml ; Ducklin P. , “ Clearview AI facial recognition sued again – this time by ACLU ” , Naked Security , 29 May 2020 , https : //nakedsecurity.sophos.com/2020/05/29/clearview -ai-facial -recogition -sued -again -this-time-by-aclu . 174 Geiger R. S. et al . , “ Garbage in , garbage out ? Do machine learning application papers in social computing report where human -labeled training data comes from ? ” , https : //arxiv.org/abs/1912.08320 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 46 It is no surprise that IBM,175 Microsoft176 and Amazon177 have recently issued statements that they will not offer their face recognition technolo gies to the police anymore . Many US states are considering banning artificial face reco gnition or have already implemented legislation that limits or prohibits it.178 There is therefore a growing consensus in Western countries that even public interests cann ot justify pervasive mass surveillance systems that exploit the web . 2.7 . The media market : Big data -driven market strategies Big data has revolutionised the universe of media . Many players in the media industry now depend on big tech companies to better connec t with their audiences.179 In fact , gathering and processing huge amounts of data in a fruitful way requires capabilities that few own . The pool of companies that can harvest big data is very limited , and the majority of market players rely on this pool to b etter understand who their clients are , what type of market strategy they should impl ement or how to gain more visibility . Some big tech companies in the field , such as Amazon , even produce media content themselves . Thanks to their technological capabiliti es , big tech companies thus now operate either ( or both ) as media makers and as media tors between the media industry and its consumers . The Court of Justice of the European Union ’ s landmark Google Spain case180 encapsulates the paramount role that big tech c ompanies now play in the news field and their resistance to the laws governing it . W hen an individual complained that a Google search of his name returned a list of results at the top of which was a very old newspaper item about him that could still ruin h is reputation , Google ’ s first line of defence was that it did not handle personal da ta ; it only connected searches with results.181 In other words , Google made the argument that it was not responsible for what it made available through Google search . The cou rt responded with a historical judgement , showing its awareness of the unique role of Google in Internet searches . It found that Google was responsible for how it ranked its answers to a query , as it could resurrect long forgotten pieces of information tha t would not have been accessible to the general public otherwise . 175 Krishna A. , “ IBM CEO ’ s Letter to Congre ss on Racial Justice Reform ” , 8 June 2020 , https : //www.ibm.com/blogs/policy/facial -recognition -susset -racial -justice -reforms/ . 176 Greene J. Microsoft won ’ t sell police its technology , following similar moves by Amazon and IBM ” , The Washington Post , 11 June 2020 , https : //www.washingtonpost.com/technology/20 20/06/11/microsoft -facial recognition/ . 177 Hao K. , “ The two -year fight to stop Amazon from selling face recognition to the police ” , MIT Technology Review , 12 June 2020 , https : //www.technologyreview.com/2020/06/12/1003482/ amazon -stopped -selling police -face-recognition -fight . See also Hartzog W. , op . cit . , p. 76 -77 . 178 See the Illinois Biometric Information Privacy Act , https : //www.termsfeed.com/blog/bipa/ . 179 Tsesis T. , op . cit . , p. 1589 . 180 Google Spain SL et al . v. Agencia Española de Protección de Datos , C-131/12 , https : //eur -lex.europa.eu/legal content/EN/TXT/HTML/ ? uri=CELE X:62012CJ0131 & from=EN . 181 Ibid. , par a . 22 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 47 Big tech companie s do not simply populate the media market . They deeply affect its dynamics , too . Their unique ability to profile the market entraps their users in a “ lock in ” phenomenon and generates a quasi -market monopoly.182 They are so pervasive and indispensable that those who do not want to use them often have to leave the market altogether . Many Internet users know that “ visiting a single website results typically in the disclosure of b rowsing behavio ur to over 100 third parties who seek to limit their own legal liab ility by means of dense ‘ privacy policies ’ which can run to hundreds of pages ” , but they can not avoid visiting the same websites time and again.183 The few companies that explo it the potentials of big data may patrol their territories even further by engagi ng in “ killer acquisitions ” , through which they purchase innovative start -ups to either mine the data they have collected184 or protect their dominant position.185 In Frank Pasqua le ’ s words , like “ Pharaoh trying to kill off the baby Moses ” , big tech companie s can deny their rivals “ the chance to scale ” .186 The simultaneous presence of more than one company that uses big data does not ensure that a market is competitive.187 Big data can help the development of market strategies , including pricing , that benefit the competitors , not the customers . There is evidence that algorithms of different companies can maximise pricing through an implicit collusive strategy , simply by pro cessing infor mation about the market itself.188 An algorithm can suggest a company raise prices because it predicts that its competitors will decide to do the same . Thanks to user profiling and clustering , they can also “ segment … the market ” and charge eac h user accordi ng to their willingness to pay . These practices create the “ maximum revenue [ for firms ] but no consumer welfare ” .189 Such a data -driven market strategy is usually not punishable , as there is no collusion , but has the benefits that normally att ach to collusiv e behaviours.190 182 AGCM , AGCOM , and Garante per la protezione dei dati p ersonali , Indagine conoscitiva sui Big Data , op . cit . , p. 26 and 78 . 183 European Data Protection Supervisor , Opinion 3/2018 EDPS Opinion on online manipulati on and personal data , op . cit . , p. 7 . 184 Zuboff S. , The Age of Surveillance Capitalism , Profile Books , 2019 , pp . 102 -103 . 185 AGCM , AGCOM , and Garante per la protezione dei dati personali , “ Indagine conoscitiva sui Big Data ” , op . cit. , p. 81 , . See also Hughes C. , op . cit . 186 Pasquale F . , The Black Box Society , Harvard University Press , 2015 , p. 67 . 187 European Data Protection Supervisor , Opinion 3/2020 on the European strategy for data , op . cit . , p. 8 ( where it is warned against the creation or rei nforcement of “ situations of data oligopoly ” ) . 188 Den Boer A. V. , “ Dynamic pricing and learning : Historical origins , current research , and new directions ” , Surveys in operations research and management science , 20 , 2015 , p. 1 , https : //papers.ssrn . com/sol3/papers.cfm ? abstract_id=2334429 ) ; AGCM , AGCOM , and Garante per la protezione dei dati personali , “ Indagine conoscitiva sui Big Data ” , op . cit . 189 European Data Protection Officer , Opi nion 8/2016 EDPS Opinion on coherent enforcement of fundamental rights in the age of big data , op . cit . , p. 6 . 190 Harrington , J. E. Jr. , “ Developing competition law for collusion by autonomous artificial agents ” , Journal of Competition Law & E conomics , 14 , 2019 , p p. 349 -351 , https : //academic.oup.com/jcle/article abstract/14/3/331/5292366 ? redirectedFrom=fulltext . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 48 2.8 . Regulatory approaches to AI -based systems Many have voiced the need for new regulatory schemes in order to ensure that AI is utilised in a way that respects the rule of law , fundamental rights and ethical values . Big tech companies have long resisted public efforts to regulate the field,191 but now appear to have come to terms with the necessity of constraining AI , although they push for company self -regulation rather than state rules . Most constraints , however , do not aim t o depress the utilis ation of AI ; in fact , they are expected to boost its role by making it more trustworthy and reliable.192 There is wide consensus , in fact , that AI needs to be “ lawful ” ( law -compliant ) , “ ethical ” ( committed to respecting ethical principle s and values ) and “ ro bust ” ( technologically and sociologically safe ) , in order to successfully integrate with human societies.193 Debates often emphasise that big data analyses need a new approach to legal regulation . Traditional tools may not be sufficient to ensure that the wo rld of big data respects basic human values . Because of AI ’ s black box structure and large -scale effects , legal sanctions are hardly capable of constraining big data -based technologies and strategies . Lawsuits may arrive late , when on e ’ s reputation or a co mpany is in ruins , and liabilities may be hard to locate . AI needs to incorporate legal values within its data processing , in order to make sure that it protects them while it is operating . Because of the wealth of information it gat hers , its pervasive de ployment and its capacity to replace human operators with robots , AI also poses ethical questions . Digital ethics is a new frontier for AI regulation and has drawn considerable attention especially in the US , in Canada and in Europe , where ethical codes ha ve mushroomed .194 As a field , digital ethics covers a wealth of topics , including “ moral problems relating to data and information … , algorithms … and corresponding practices and infrastructures ” ,195 in a way that cuts across different disciplines and perspect ives . Albeit extremely lively , the situation is magmatic at the moment , also because of the difficulties in drawing lines between the legal and the ethical components of AI regulation.196 191 Zuboff S. , op . cit . , p. 105 . 192 Van Dijk N. & Casiraghi S. , “ The ethification of privacy and data protection law in the European Union : The case of artificial intelligence ” , Brussels Privacy Hub , 6 , 22 , May 2020 , p. 5 , https : //br usselsprivacyhub.eu/publications/BPH -Working -Paper -VOL6 -N22.pdf . 193 High -Level Expert Group on Artificial Intelligence , Ethics Guidelines for Trustworthy AI , p. 2 , https : //ec.europa.eu/digital -single -market/en/news/ethics -guidelines -trustworthy -ai . See N. van Dijk & S. Casiraghi , op . cit . , p. 14 . 194 Jobin A. , Ienca M. and Vayena E. , “ The global landscape of AI ethics guideline s ” , Nature Machine Intelligence , 1 , 2019 , pp . 393 -395 , https : //www.nature.com/articles/s42256 -019-0088 -2 . 195 Floridi L. , op . cit . , p. 3 . 196 For example , see the Council of Europe ’ s Recommendat ion CM/Rec ( 2020 ) 1 o f the Committee of Ministers to member States on the human rights impacts of algorithmic systems , 8 April 2020 , https : //search.coe.int/cm/pages/ result_details.asp x ? objectid=09000016809e1154 , which showcases the variety of regulatory layers necessary for the development of sound AI -based systems . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 49 2.9 . Conclusion Big data is a big reason for the s ocietal , economic , and po litical success of AI . Processing vast amounts of data is crucial for big tech companies . It has not been just a blessing , however , and it requires people working in the field to take action to ensure that AI is beneficial to human beings.197 Chris Hughes , c o-founder of Facebook , has warned that the digitalisation of the economy may contribute to what he perceives to be “ a decline in entrepreneurship , stalled productivity growth , and higher prices and fewer choices for consumers ” .198 The stakes are so high that a member of the National Assembly , the lower house of the French Parliament , has even submitted a proposal to entrench a Charter of artificial intelligence and of algorithms within the preamble of the French constitution , to better protect human rights.199 AI maximises people engagement . Eliciting “ as much response as possible from as many people as possible ” is a key factor of success , as it provides feedback and allows companies to adjust their business plans and models to their customers in real time.200 Political players and social influencers exploit this phenomenon by triggering emotional responses from their potential audience . Big data politics and economy place media at the centre stage , as they spread news , gather inf ormation , process emotions , and co nnect social spheres . Big data aggrandises the role of the media for contemporary societies . Companies , politicians , influencers and other political figures exploit big data to market their ideas , agendas and opinions , as well as to shape their audiences.201 Internet platforms allow legacy media to spread their content and generate new competition between traditional and new outlets . Media players can also play a negative role . Through profiling the “ thinking patterns and ps ychological makeup , ” they can delib erately misinform and mislead an audience.202 Moreover , in countries where few media players operate , or where there are only or almost exclusively state -run social media,203 a political regime can effectively control the n ews and also how people react to it , by disseminating fabricated favourable feedback and insulating unfavourable comments.204 Within the scenario generated by big 197 See the Asilomar Principles , developed in conjunction with the 2017 Asilomar conference . Future of L ife Institute , https : //futureoflife.org/ai -principles . 198 See also Hughes C. , op . cit . 199 http : //www.assemblee -nationale.fr/dyn/15/textes/l15b2585_proposition -loi . 200 Akin Unver H. , “ Artificial intelligence , authoritarianism and the future of political systems ” , Centre for Economics and Foreign Policy Studies , July 2019 , p. 3 , https : //edam.org.tr/wp -content/uploads/2018/07/AKIN Artificial -Intelligence_Bosch -3.pdf . 201 Idem . 202 European Data Protection Supervisor , Opinion 4/2015 . Towards a new digital ethics , op . cit . , p. 7 . 203 Pasquale F. , op . cit . , p. 10 , notes that “ the distinction between state and market is fading ” because of massive AI deployment in strategic sectors of public and private interest . 204 Akin Unver H. , op . cit . , p. 8 . See also Meaker M. , “ How governmen ts use the Internet to crush online dissent ” , The Correspondent , 27 November 2019 , https : //thecorrespondent.com/142/how -government s-usethe-internet -to-crush -online -dissent/18607103196 -db0c0dab . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 50 data , media can discharge a critical role in protecting democracy , equality , minority groups a nd open societies - or in undermining them.205 Finally , mass surveillance can have a chilling effect on creativity and innovation . Despite earlier expectations that AI would simply boost inventiveness,206 some have detected “ a tendency to discourage or penalise spontaneity , experimentation or devi ation from the statistical ‘ norm ’ , and to reward conformist behaviour ” .207 The vast deployment of AI nowadays requires that the media sphere become aware of its un ique role . The media sector should strive to use AI in a lawful , ethical , and robust way . Thank s to their connecting role , the media could encourage the wider world of AI -based businesses to embrace the same values and become lawful , ethical , and robust . I n particular , an ethical commitment may encourage media platforms to go beyond a merely passive role . While many regulations limit providers ’ legal liability for the content they host,208 and more burdens imposed on media have not succeeded in encouraging m ore policing , it can still be a worthwhile ethical goal for media platforms to patrol their cont ent.209 205 High -Level Expert Group on Artificial Intelligence , “ Ethics guidelines for trustworthy AI , op . cit . , p. 11 . 206 Perritt , H. H. , Jr. , op . cit . , p. 107 . 207 European Data Protecti on Supervisor , Opinion 4/2015 . Towards a new digital ethics , op . cit . , p. 9 . See also Pan S. B. , op . cit . , p. 257 ( “ The goal of big data is to generalize ” ) and Pasquale F. , op . cit . , p. 188 . 208 Perritt H. H. , Jr. , op . cit . , p. 149 . 209 ERGA2020 Subgroup 1 – Enforcement , ERGA Position Paper on the Digital Services Act , p. 6 , https : //nellyo.files.wordpress.com/2020/06/erga_sg1_dsa_position -paper_adop ted-1.pdf . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 51 Freedom of expression , diversity and pluralism One specific issue of concern raised by the use of AI relates very particularly to the media field : diversity and pluralism . And yet , for those who are old enough to remember the times when TV channels in a given country could be counted on the fingers of one hand and newspapers were called papers for a reason , the problem of diversity ( at least in quantitative terms ) might seem a bit exaggerated . Nowadays , there are scores and scores of TV channel s and any newspaper on the globe is only one click away . It could actually be said that the only thing preventing anybody today from getting all the information in the world is not algorithms but rather paywalls . But precisely because the information offer ing is so overwhelmingly broad , people look for filters . And as mentioned before , filtering is one thing that AI does very well . Video on demand or news services can carry out this news personalisation for any Internet user , based on his or her personal vi ewing , reading history or other preferences . This has a down side : the so-called filter bubbles that occur when algorithms filter out “ facts and different viewpoints , thereby reinforcing deeply held viewpoints and even prejudices ” .210 The existence and effect s of such filter bubbles are , however , not something everyb ody agrees upon . In her contribution to this publication , Mira Burri , while acknowledging some of the precarious implications of tailored media on diversity and the need to pay attention to the pow er of platforms , voices also doubts about their direct link with a fragmentation of the public discourse and possible polarization of views.211 Even promoters of the filter bubble thesis admit that they can not prove its existence in real life212 and that the e mpirical evidence of these bubbles is so far scarce.213 Sarah Eskens , in her contribution to this publication , notes : “ [ T ] he current challenge for news media and public authorities is to develop journalistic codes of ethics , self -regulatory standards , and po ssibly government regulation to contain the risks of AI for freedom of expression , while enabling AI to contribute to public debate , media pluralism , the free flow of information , and other societal goals ” . 210 See Andrea Pin ’ s contribution to this publication . 211 For other critical views on this matter see e.g . Br uns A. , “ It ’ s Not the Technology , Stupid : How the ‘ Echo Chamber ’ and ‘ Filter Bubble ’ Metaphors Have Failed Us ” , http : //snurb.info/node/2526 . 212 Zuiderveen Borgesius , F. , Trilling , D. , Moeller , J. , Bod ó , B. , de Vr eese , C. H. , & Helberger , N. , “ Should we worry about filter bubbles ? ” Internet Policy Review , 5 ( 1 ) . https : //doi.org/10.14763/2016.1.401 . 213 Helberger N. , Eskens S. , van Drunen M. , Bastian M. , Moeller J. , Implications of AI -driven tools in the media for freedom of expression , https : //rm.coe.int/cyprus -2020-ai-and-freedom -of-expressio n/168097fa82 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 53 3 . Implications of the use of artificial intell igence by news media for freedom of expression Sarah Eskens , University of Amster dam 3.1 . Introduction News media are increasingly using artificial intelligence in their businesses . In 2018 , the Reuters Institute for the Study of Journalism surveyed almost 200 leaders in journalism . Almost three quarters of the leaders surveyed said they we re already using AI in their organisation.214 The use of AI creates opportunities for news media and may help them fulfil their democratic role . A report by the European Broadc asting Union also underlined the opportunities of AI for public service journali sm.215 Accordingly , the use of AI by news media may fall within the scope of the protection of freedom of expression for the media , which is important considering the push to reg ulate AI in various domains . At the same time , the use of AI by news media may affect the extent to which other participants in public debate can exercise their freedom of expression rights . For example , news organisations can use AI to automatically moder ate comments on their websites . If automated moderation is biased towards , for example , general American English , then certain voices in public debate might not be heard . As lawmakers are discussing the need to regulate AI , the question arises to what extent the use of AI by news media can be regulated and how media freedom should b e balanced with other rights and interests associated with the use of AI by news media . The use of AI by news media shapes our information environment and may have significant effects on open debate , media pluralism and diversity , the free flow of informat ion , and 214 Newman N. , “ Journalism , media , and technology trends and predictions 2018 ” . Reuters Institute for the Study of Journalism , p. 29 , https : //reutersinstitute.politics.ox.ac.uk/sites/default/files/2018 01/RISJ % 20Trends % 20and % 20Predictions % 202018 % 20NN.pdf . 215 European Broadcasting Union , “ The next newsroom : Unlocking the power of A I for public service journalism ” , https : //www.ebu.ch/publications/news -report -2019 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 54 other public values attached to the institution of the news media.216 The questions raised by the use of AI by news media are unique due to the democratic role of the new s media . This chapter therefore focuses on the use of AI by news media and not on the use by other types of media , such as entertainment media , which requires a different balancing of interests.217 This chapter is set up as follows : it describes the general framework for the protection of freedom of expression ; it discusses to what e xtent the use of AI falls under media freedom , which kind of news actors that use AI can benefit from media freedom , and what duties and obligations news media have when they use AI ; thereafter , it describes how certain applications of AI in the news media can limit the freedom of expression rights of other participants in public debate , including news users and citizens or politicians who make themselves heard via the media . The p urpose is not to offer an exhaustive overview of all the risks of the use of AI by the news media . Rather , the aim is to illustrate the risks of AI for freedom of expression in order to discuss the substance of the human rights of various participants to p ublic debate . Finally , the chapter analyses what kind of obligations states h ave regarding freedom of expression in the face of the use of AI by news media . But before providing these analyses , it briefly sets out what goals news media have when they use A I . 3.2 . AI applications for news media Similarly to its definition in other studie s about AI and the news media , for the purpose of this chapter , artificial intelligence is loosely defined as “ a collection of ideas , technologies , and techniques that relate to a computer system ’ s capacity to perform tasks normally requiring human intelli gence ” .218 AI is thus an umbrella term that refers to various digital technologies , including , among others , machine learning , image recognition , natural language processing , and na tural language generation . The other chapters in this publication showcase t he variety of applications for media that are considered to be AI . In this chapter , four goals are distinguished for which news media can use AI : newsgathering ; news production ; n ews distribution ; and moderation of reader 216 Council of Europe , Recommendation CM/Rec ( 2018 ) 1 of the Committee of Ministers to member States on media p luralism and transparency of me dia ownership , https : //search.coe.int/cm/Pages/result_details.aspx ? ObjectId=0900001680790e13 # _ftn1 ; Council of Europe , Recommendation CM/Rec ( 2015 ) 6 o f the Committee of Ministers to member States on free , transboundary flow of information on the Internet , https : //search.coe.int/cm /Pages/result_details.aspx ? Obj ectID=09000016805c3f20 . 217 See Chapter 4 of this publication . 218 Beckett C. , “ New powers , new respons ibilities : A global survey of journalism and artificial intelligence ” , London School of Economics and Political Science , p. 16 , https : //blogs.lse.ac.uk/polis/2019/11/18/new -powers -new-responsibilities/ . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 55 comments.219 The first three goals relate to classic journalistic processes , and the fourth goal relat es to the fact that online news media sometimes allow user comments on their websites . As remarked in a recent re port by the Parliamentary Assembly , most of the discussions about the use of AI in online communication processes has focused on content modera tion , while the manner in which AI shapes the online information environment is equally important.220 To begin the journalistic process , news media can use AI for newsgathering . This includes the use of AI to find information and newsworthy events , generate story ideas , and monitor events or issues . Once journalists have gathered information on potential stories , they can use AI for the production of news . This includes the use of AI for writing news items ( sometimes called “ automated journalism “ ) ,221 creatin g images and videos , fact-checking information , or repurposing content for new audiences . In the final step of the journalistic process , news media can use AI for the distribution of news . This includes the use of AI for providing personalised recommendati ons , finding new audiences , marketing the news brand , and selling subscriptions . The use of personalisation often h as a dual goal . Personalisation helps news media better serve their users and , especially for public service media , fulfil their public remit .222 Personalisation also helps news media retain subscribers , increase user engagement , and consequently generate sa les and advertising revenues.223 As news media have opened their online platforms for reader comments , they can use AI to more effectively mo derate these comments . For instance , The New York Times implemented a system that uses machine learning to prioritise comments for moderation and automatically approve comments.224 The New York Times moderates almost 12 000 comments per day and the automate d system allows the comment section to be open for longer and approve comments faster . Other research about the use o f AI in the news media sector discusses the use of AI for comment moderation as part of news distribution.225 However , automated comment moderation brings specific risks for the freedom of expression rights of the people who are commenting on news stories an d engaging in public debate . For the use of AI for other distribution goals , such as personalisation and marketing , news users are 219 Beckett C. , Ibid , p. 20 . 220 Parliamentary Assembly , Report : Need for democratic governan ce of artificial intelligence ( 24 September 2020 ) , para . 18 -19 , https : //pace.coe.int/en/files/28742/html . 221 Dörr K.N. , “ Mapping the field of algorithmic journalism ” , Digital Journalism 4 ( 6 ) , pp . 700–722 , https : //doi.org/10.1080/21670811.2015.1096748 . 222 Van den Bulck H. and Moe H. , “ Public service media , universality and personalisation through algorithms : Mapping strategies and exploring dilemmas ” , Media , Culture & Society 40 ( 6 ) , pp . 875–92 , https : //doi.org/10.1177/0163443717734407 . 223 Bodó B. , “ Selling news to audiences : A qualitative inquiry into the emerging logics of alg orithmic n ews personalization in European quality news media ” , Digital Journalism 7 ( 8 ) , pp . 1054 –75 , https : //doi.org/10.1080/21670811.2019.1624185 . 224 Etim B. , “ The Times sharply increases articl es open fo r comments , using Google ’ s technology ” , The New York Times , https : //www.nytimes.com/2017/06/13/insider/have -a-comment -leave -a-comment.html . 225 Beckett C. , Ibid , p. 28 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 56 addres sees of the communication but they are not themselves active speakers . This chapter therefore considers AI for comment moderation on news platforms as a separate category . After this overview of the various uses of AI in the news media , the next section discusses to what extent the use of AI is protected by media freedom . 3.3 . The use of AI by news media as an element of media freedom In Europe , the European Convention on Human Rights ( ECHR ) provides the legal basis for the human right to freedom of expression . Article 10 ( 1 ) ECHR provides that everyone has the right to freedom of expression , which includes freedom to hold opinio ns and to receive and impart information and ideas without interference by public authorities . The European Court on Human Rights ( ECtHR ) was set up to ensure that states comply with their obligations under the ECHR . The ECtHR has produced a huge body of case law in which it interprets and develops the right to freedom of expression . In one of its first cases on freedom of expression , the E CtHR affirmed that freedom of expression is one of the foundations for a democratic society and for the development of every person.226 3.3.1 . Democratic role of the news media Journalism scholars have distinguished several democratic roles for news media.227 The media are a source of information for democratic debate , by providing citizens information on politics and current affair s. Furthermore , the media function as the “ fourth estate “ by critically scrutinising the exercise of power by government , businesses , a nd other powerful actors . The media also are a mediator between citizens and politicians because they facilitate the exis tence of a public space in which citizens and politicians can communicate via letters , op -eds , broadcasted studio debates , and contribu tions to news articles . The ECtHR has affirmed these various democratic roles of the media . The ECtHR has considered that the news media have the task to distribute information and be a public watchdog.228 In this respect , the ECtHR has determined that free dom of expression protects both the gathering and publication of information,229 and both the content of 226 ECtHR , Handyside v. the United Kingdom [ 1976 ] , 5493/72 , para . 49 , http : //hudoc.echr.coe.int/eng ? i=001 57499 . 227 McNair B. , “ Journalism and democracy ” in T. Hanitzsch and K. Wahl -Jorgensen ( e ds . ) The Handbook of Journalism Studies . Routledge , pp . 237 –49 . 228 ECtHR , Barthold v. Germany [ 1985 ] , 8734/79 , para . 58 , http : //hudoc.echr.coe.int/eng ? i=001 -57432 . 229 ECtHR , Dammann v. Switzerland [ 2006 ] , 77551/01 , para . 52 , http : //hudoc.echr.coe.int/eng ? i=001 -75174 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 57 communication and t he technical means for the distribution and reception of information.230 Additionally , the ECtHR has found that one task of the news m edia includes the creation of forums for public debate.231 The use of AI by news media fits within their democratic roles as protected by the right to freedom of expression . News media can use AI to gather information on new issues , for example by using AI to analyse big data . Furthermore , news media can use AI to distribute relevant information to different citizens , depending on each individual ’ s personal interests and information needs . News media can also use AI to watch and monitor the behaviour of lar ge corporations or the implementation of public policies . Finally , news media can use AI to improve the forum for public deba te by automatically moderating reader comments . Because of their democratic roles , the news media receive special freedom of expre ssion protection . The ECtHR has held that freedom of expression is of particular importance as far as the news media are conc erned.232 In the case of the news media , the ECtHR therefore speaks of “ freedom of the press ” ,233 which is also called media freedom.234 The ECtHR has found that public authorities have a smaller margin of appreciation to decide if there is a pressing social nee d to interfere with media freedom,235 compared to the margin of appreciation that public auth orities have when they interfere with the freedom of expression of other types of speakers . Furthermore , the ECtHR has determined that media freedom protects the new s media against influence from powerful economic or political groups in society , and ensure s their editorial freedom.236 As part of the gathering of information , media freedom protects journalistic sources,237 and media may have a right to access information h eld by public authorities.238 To the extent that the use of AI falls under media freedom , public authorities are thus limited in the regulation of AI . The next section discusses which actors can enjoy media freedom . 3.3.2 . Beneficiaries of media freedom These days , the news media environment is formed by a complex network of different actors , includin g news publishers , news users , and online intermediaries . Legacy news 230 ECtHR , Autotronic AG v. Switzerland [ 1990 ] , 12726/87 , p ara . 47 , http : // hudoc.echr.coe.int/eng ? i=001 -57630 . 231 ECtHR , Társaság a Szabadságjogokért v. Hungary [ 2009 ] , 37374/05 , para . 27 , http : //hudoc.echr.coe.int/eng ? i=001 -92171 . 232 ECtHR , The Sunday Times v. the United Kingdom ( No . 1 ) [ 1979 ] , 6538/74 , para . 65 , http : //hudoc.ech r.coe.int/eng ? i=001 -57584 . 233 ECtHR , The Sunday Times v. the United Kingdom ( No . 1 ) , para . 66 . 234 Oster J. , Media Freedom as a Fundamental Ri ght . Cambridge University Press , p. 48 . 235 ECtHR , Busuioc v. Moldova [ 2004 ] , 61513/00 , para . 65 , http : //hudoc.echr.coe.int/eng ? i=001 -67745 . 236 ECtHR , Manole and Others v. Moldova [ 2009 ] , 13936/02 , par a . 98 , http : //hudoc.echr.coe.int/eng ? i=001 94075 . 237 ECtHR [ GC ] , Goodwin v. the United Kingdom [ 1996 ] , 17488/90 , para . 39 , http : //hudoc.echr . coe.int/ eng ? i=001 -57974 . 238 Ibid .. ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 58 media and digital -born news media gather original information and publish news articles via their own offline and online news outlets . Before the Internet , news publishers reached their audiences directly on the whole , when people bought a certain newspaper or tuned in to a certain radio or television channel . On the Internet , news publishers can still reach their audiences directly , when people browse to news websites or use apps of news publishers . But people are accessing and finding news increasingly via social media , search engines , and news aggregators.239 These platforms function as intermediaries between news publishers and news users . Rather obviously , both traditional news media and digital -born news media qualify for media freedom . But the involvement of online intermediaries in the news environment raises the question to what extent these intermediaries can also rely on media freedom when they use AI . The ECtHR has determined that various actors can fulfil the democratic roles that the media traditionally perform . The ECtHR remarked that there is a strong public interest in enabling campaign gr oups to contribute to public debate by distributing information on matters of public interest.240 The ECtHR has therefore analysed the conduct of public authorities with regard to campaign groups in the light of media freedom ( but it has also held that campa ign groups are expected to meet certain duties and responsibilities typic ally reserved for the media ; see next section ) . In one case , the ECtHR considered that the creation of forums for public debate is not limited to professional news media and that non -governmental organisations may also fulfil that role.241 The ECtHR has the refore characterised NGOs as “ social watchdogs ” . The activities of civil society organisations may thus warrant similar ECHR protection as that afforded to the news media.242 These judge ments of the ECtHR could provide a basis to build on to also recognise online intermediaries as actors comparable to the news media , depending on the societal role they play . As discussed in the previous section , freedom of expression law recognises three democratic roles for the news media : providing information to the publi c ; creating a forum for public debate ; and acting as a watchdog . Online intermediaries can fulfil in particular two of these roles , aided by AI . Online intermediaries can increase the accessibility and findability of information via personalised news feeds and easy access to a range of news publishers . Furthermore , online intermediaries can create forums for public debate by allowing news publishers , politicians , and citizens to post con tent on their platforms in public and private groups and affording diff erent forms of engagement with online content , including ‘ liking ’ , commenting , and forwarding content . Online intermediaries can thus play roles similar to the news media and may have , just like the media , a gatekeeping and agenda -setting function . The Com mittee of Ministers of the Council of Europe has also remarked that online intermediaries may “ exert forms of 239 Newman N. et al . , “ Digital News Report 2020 ” , Reuters Institute for the Study of Journalism , , pp . 11 –12 , https : // reutersi nstitute.politics.ox.ac.uk/sites/default/files/2020 -06/DNR_2020_FINAL.pdf . 240 ECtHR , Steel and Morris v. the United Kingdom [ 2005 ] , 68416/01 , para . 89 , http : //hudoc.echr.coe.int/eng ? i=001 -68224 . 241 ECtHR , Társaság a Szabadságjogokért v. Hungary , para . 27 . 242 Ibid . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 59 control which influence users ’ access to information online in ways compara ble to media , or they may perform other functions that resemble those o f publishers ” .243 On the basis of these freedom of expression principles , one could argue that online intermediaries may qualify for media freedom when they are using AI to perform democr atic roles similar to those of the news media . At the least , online in termediaries may qualify for “ normal “ freedom of expression rights when they are making news more easily accessible through news feeds and search results . In that regard , Van Hoboken distinguishes the production of “ information about information ” by search engines , such as when they publish search results , from the referencing to information elsewhere . Van Hoboken concludes that the publication of search results by a search engine is prot ected under Article 10 ECHR.244 In a similar manner , one could argue th at the AI -driven selection , ranking , and personalisation of news feeds by social media and news aggregators is the production of “ information about information ” and deserves freedom of expression protection . When traditional news media , digital -born news m edia , and ultimately online intermediaries , exercise their media freedom or freedom of expression , they also assume certain duties and obligations . The next section discusses these duties and obligations . 3.3.3 . Duties and responsibilities and journalistic codes of ethics While the first paragraph of Article 10 ECHR guarantees the human right to freedom of expression , the second paragraph lays down that the exercise of freedom of expression “ carries with it duties and responsibilities ” and may therefore be subjec t to restrictions as are prescribed by law and are necessary in a democratic society for a legitimate aim . In other words , Article 10 ECHR contains a mechanism to ensure that people and organisations exercising freedom of expression do so in a responsible manner . For the purpose of this chapter , the focus is on duties and responsibilities and not on the conditions under which interference with the right to freedom of expression may be justified . The question is what are the duties and responsibilities that come with freedom of expression and what do these duties and responsibilities mean for the use of AI by the news media . Various actors have duties and responsibilities when they particip ate in or contribute to the exercise of freedom of expression . The EC tHR has held that in addition to speakers or authors themselves , persons or organisations providing other authors a 243 Council of Europe , Recommendation CM/Rec ( 2018 ) 2 of the Committee of Ministers to member States on the roles and responsibilities of internet intermediaries , para . 5 , https : //search.coe.int/cm/Pages/result_details.aspx ? ObjectID=0900001680790e14 . 244 Van Hoboken J. V. J. , “ Search engine freedom : On the implications of the right to f reedom of e xpression for the legal governance of Web search engines ” , University of Amsterdam , p. 182 , http : //hdl.handle.net/11245/1.392066 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 60 medium or platform , such as publishers245 or Internet news portals,246 take on duties and responsibilities regarding the publication and distr ibution of third -party content . The ECtHR has determined that the scope of an actor ’ s duties and responsibilities depends on various factors . First of all , someone ’ s duties and responsibil ities depend on their situation and the technical means they use fo r communication.247 As news media have a special democratic role , their duties and responsibilities also assume a special significance . The ECtHR has stipulated that the duties and responsibi lities of news media are specifically important when their work mi ght undermine the rights of others.248 Furthermore , the potential impact of the medium forms a factor to determine the scope of duties and responsibilities.249 The more impactful the medium , the more weight the duties and responsibilities of a news media act or retain . Still , the ECtHR has held that the duties and responsibilities of Internet news portals may differ to some degree from those of traditional publishers as regards third -party content .250 In a similar manner , the Committee of Ministers of the Council of Europe has recommended that the duties and responsibilities of online intermediaries should , given the multiple roles they play , be determined with respect to the specific services and ro les they perform.251 The ECtHR has held that the duties and responsibilities of news media mean they should act “ in good faith in order to provide accurate and reliable information in accordance with the ethics of journalism ” .252 Journalist codes of ethics exi sted already long before the ECHR introduced the idea that the exercise of freedom of expression comes with duties and responsibilities . In the 1920s , the American Society of Newspaper Editors adopted the Canons of Journalism , which is seen as one of the f irst codes of ethics for the news media.253 But in the years thereafter , criticism about the corporate press created pressure to subject the news media to government regulation.254 In response , the news media developed codes of ethics , press councils , ombuds men and other forms of self regulation to prevent regulation by the government.255 In Europe , the idea that the news media should not be regulated holds mainly for the printed press . European countries regulate audiovisual media in several ways , most notab ly through the EU Audiovisual Media Services Directive . The manner in which the 245 ECtHR , Éditions Plon v. France [ 2004 ] , 58148/00 , para . 50 , http : //hudoc.echr.coe.int/eng ? i=001 -61760 ; ECtHR , Chauvy and Others v. France [ 2004 ] , 64915/01 , para . 79 , http : //hudoc.echr.coe.int/eng ? i=00 1-61861 . 246 ECtHR , Magyar Tartalomszolgáltatók Egyesülete and Index.hu Zrt v. Hungary [ 2016 ] , 22947/13 , para . 62 , http : //hudoc.echr.coe.int/eng ? i=001 -160314 ; ECtHR [ GC ] , Delfi AS v. Estonia [ 2015 ] , 64569/09 , p ara . 113 , http : //hudoc.echr.coe.int/eng ? i=001 -155105 . 247 ECtHR , Handyside v. the United Kingdom , para . 49 . 248 ECtHR [ GC ] , Bladet Tromsø and Stensaas v. Norway [ 1999 ] , 21980/93 , pa ra . 65 , http : //hudoc.echr.coe.int/eng ? i=001 -58369 . 249 ECtHR [ GC ] , Jersild v. Denmark [ 1994 ] , 15890/89 , para . 31 , http : //hudoc.echr.coe.int/en g ? i=001 -57891 . 250 ECtHR [ GC ] , Delfi AS v. Estonia , para . 113 . 251 Recommendation CM/Rec ( 2018 ) 2 of the Committee of Ministers to Member States on the roles and responsibilities of Internet intermediaries , para . 11 . 252 ECtHR [ GC ] , Bladet Tromsø and Stensaas v. Norway , para . 65 . 253 Ward S.J.A. , The invention of journalism ethics : The path to objectivity and beyond . MQUP , pp . 236 –37 . 254 Ward S.J.A. , Ibid , p. 244 . 255 Ward S.J.A. , Ibid , p. 245 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 61 ECtHR has interpreted the notion of duties and responsibilities now also creates a normative legal basis for a social responsibility theory of the printed press , under which the printed press should commit to self -regulation and codes of ethics for their profession . The question is if current journalistic codes of ethics are fit to deal with the use of AI by news media . In 2001 , journalism scholars concluded that the Internet cr eates new ethical issues for journalists while traditional journalistic codes of ethics provided insufficient guidance for the conduct of news media in the online environment.256 More than a decade later , research into journalistic codes of ethics has found that the majority of codes still do not include rules for online journalism and digital media.257 Helberger and Bastian therefore call for the development of algorithmic journalistic ethics , to guide the news media in their use of AI for the production , pu blica tion , and distribution of news.258 Similarly , Dörr and Hollnhuchner , two communication science scholars , conclude that media organisations should adopt ethical codes for algorithmic journalism.259 Another question is to what extent online intermediarie s that use AI to shape the online environment for freedom of expression should follow codes of ethics . Social media and search engines have long tried to escape responsibility for the manner in which they select and prioritise information by arguing they a re not media . In an interview , the CEO of Facebook stressed that Facebook is “ a social network ” and that he prefers that term over “ social media ” because the notion of a social network focuses on the “ people part ” of the platform and less on the content pa rt of i t.260 If social media are indeed not journalistic entities , then they do not have to follow journalistic codes of ethics . It is apparent , then , that Article 10 ECHR as interpreted in case law of the ECtHR provides a normative legal basis for duties and resp onsibilities for actors contributing to freedom of expression , regardless of whether or not they are “ real “ news media organisations . At the same time , it also becomes clear that the duties and responsibilities of online intermediaries may differ f rom thos e of traditional news media . This means that online intermediaries can not be obliged to follow journalistic codes of ethics , although freedom of expression principles make clear that online intermediaries have responsibilities when they use AI to r egulate expression on their platforms and exercise their own freedom of expression rights . If online intermediaries do not develop adequate codes and other instruments of self -regulation , then governments may justifiably regulate the manner in which online interme diaries exercise their freedom of expression while 256 Deuze M. and Yeshua D. , “ Online journalists face new ethical dilemmas : Lessons from the Nether lands ” , Journal of Mass Media Ethics 16 ( 4 ) , pp . 273–92 , https : //doi.org/10.1207/S15327728JMME1604_03 . 257 Díaz-Campo J. and Segado -Boj F. , “ Journalism ethics in a digital environment : How journalis tic codes of ethics have been adapted to the Internet and ICTs in countries around the world ” , Telematics and Informatics 32 ( 4 ) , pp . 735–44 , https : //doi.org/10.101 6/j.tele.2015.03.004 . 258 Helberger N. and Bastian M. , “ AI , algorithms and journalistic ethics ” , presented at the Future of Journalism conference , Cardiff , 2019 . 259 Dörr K. N. , “ Mapping the field of algorithmic journalism ” , Digital Journalism 4 ( 6 ) , pp . 700–722 , https : //doi.org/10.1080/21670811.2015.1096748 . 260 Swisher K. , “ Zuckerberg : The Recode interview ” , Recode , https : / /www.recode.net/2018/7/18/17575156/mark -zuckerberg -interview -facebook -recode -kara-swisher . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 62 using AI . A similar line of thinking is also evident in the way in which the European Commission approaches online intermediaries . The European Commission threatens to regulate online intermediarie s if the y do not adhere to self -regulatory codes for dis - and misinformation . A similar approach could be taken regarding the use of AI by online intermediaries to shape the news environment . After analysing the freedom of expression principles for the use of AI b y news media and other actors playing a role in the online news environment , the next question is how the use of AI by news media affects the freedom of expression rights of other participants in public debate . 3.4 . Implications of AI for the freedom o f expres sion rights of news users and other participants in public debate The use of AI by news media for newsgathering , production , distribution , and moderation presents various risks for the freedom of expression rights of news users and other stakeholde rs in th e news media environment . It is important to note that the use of AI by news media may also enhance the right to freedom of expression and the right to receive information of news users and participants in public debate . From a regulatory perspecti ve , the question is thus how to contain the risks while allowing AI to have a positive effect on the news media environment and public debate . In the newsgathering stage , news media can use AI to identify trends and facts in big data . Used in this way , AI can unc over original stories in big data that could not be seen by the human eye . However , the use of AI for newsgathering depends on the availability of ( public ) datasets . Events or societal issues that do not come with a large dataset may remain invisib le to th e gaze of the automated story discovery system.261 The voices of the people implicated by events and stories that do not generate big data may stay out of the focus of data -driven news media and these voices may thereby remain unheard in the public debate . In the news production stage , news media can use AI to generate texts and images , verify and fact -check information , automatically translate , write posts for social media , or tailor mass -produced stories to specific audiences . The use of AI for au tomated content production can lead to unlawful output that infringes the rights of others , such as hate speech , defamatory content , or copyright infringement . The question then arises who is accountable or liable for this unlawful content : the news organi sation th at decided to deploy the AI tool , the developer of the AI tool , or the AI itself ? 261 Hansen M. et al . , “ Artificial intelligence : Practice and implications for journalism ” , Tow Center for Digital Journalism , p. 17 , https : //doi.org/10.7916/D8X92PRD . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 63 Legal scholars have argued that it is possible to hold AI agents accountable.262 American legal scholars have also argued that the First Amendment , which guarantees the consti tutional right to free speech , should protect automated speech.263 However , from a positive law perspective , AI can not have legal personhood and thus can not be accountable or liable in European jurisdictions . In 2017 , the European Parliament calle d on the Eu ropean Commission to consider the creation of a specific legal status ( “ electronic person ” ) for robots.264 In its Communication about AI for Europe , the Commission did not mention such an electronic personality.265 This omission suggests that so far , the Europ ean Commission does not intent to consider legal personhood for robots or AI entities under EU law.266 It would appear most appropriate to hold the news media organisation that decides to use AI accountable for unlawful content produced by AI . Reversely , if public authorities want to censor automatically generated content or bots that contribute to public debate , then these tools and their output could be protected both via the freedom of expressi on rights of the news media organisation as well as via the rig ht to receive information of news users.267 In the news distribution stage , news media can use AI to personalise the news offering for each individual news user , which may engage the news users ’ right to receive information . The human right to freedom of exp ression as protected by Article 10 ECHR includes the right to receive information . The ECtHR has determined that the media have the task to provide information and ideas on issues of public in terest and “ the public also has a right to receive them ” .268 In ad dition , the public has a right to be properly informed.269 The right to receive information entails that the public should have access through the media to diverse information.270 At the same t ime , news users do not have a subjective right to receive informati on from the media.271 Still , the use of AI by news media can affect the enjoyment of the right to receive information , such as when personalisation decreases the diversity of information tha t people have access to . A 262 Hage J. , “ Theoretical foundations for the responsibility of autonomous agents ” , Artificial Intelligence and Law 25 ( 3 ) , pp . 255–71 , https : //doi.org/ 10.1007/s10506 -017-9208 -7 . 263 Collins R.K.L . and Skover D. M. , Robotica : Speech rights & artificial intelligence . Cambridge University Press . 264 European Parliament , Report with recommendations to the Commission on civil law rules on robotics , para . 59 , https : //www.europarl.europa.eu/doceo/document/A -8-2017 -0005_EN.html . 265 European Commission , Comm unication from the Commission : Artificial intelligence for Europe , https : //eur lex.europa.eu/legal -content/EN/TXT/ ? uri=CELEX:52018DC0237 . 266 For an in -depth discussion abo ut the legal status of AI concerning copyright law see Chapter 5 of this public ation . 267 Kaminski M.E. , “ Authorship , disrupted : AI authors in copyright and First Amendment law ” , U.C . Davis Law Review 51 ( 2 ) , pp . 589–616 . 268 ECtHR , The Sunday Times v. the Unit ed Kingdom ( No . 1 ) , para . 65 . 269 ECtHR , The Sunday Times v. the United Kingdom ( No . 1 ) , para . 66 . 270 ECtHR , Manole and Others v. Moldova , para . 100 . 271 Eskens S. , Helberger N. and Moeller J. , “ Challenged by news personalisation : Five perspectives on the right to receive information ” , Journal of Media Law 9 ( 2 ) , pp . 259–84 , https : //doi.org/10.1080/17577632.2017.1387353 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 64 limitation on the right to receive inform ation caused by the conduct of news media may give rise to positive obligations for states ( see next section ) . When online intermediaries use personalisation , they may also implicate the freedom of expression rights of news media or citizen journalists pos ting news stories on their platforms to reach a wider audience . As one of the first in Europe , the German government therefore developed legal safeguards for media freedom and the visibili ty of news organisations in the face of personalisation on social me dia and search engines . The new German Medienstaatsvertrag provides that online intermediaries “ may not unfairly disadvantage ( directly or indirectly ) or treat differently providers of jou rnalistic editorial content to the extent that the intermediary has potentially a significant influence on their visibility ” .272 This legal provision is a novelty for European media law , and although it has to be seen how the law works out in practice , digi tal rights organisations state that the new German legislation has “ i mportant symbolic value ” and that its core goals are “ laudable ” .273 Finally , news media can use AI to moderate user comments on their websites . This may engage the right to freedom of expr ession of people who post comments . Research shows that AI systems are more likely to classify social media posts in African American English as offensive compared to posts in general American English.274 If AI-driven content moderation is biased against ce rtain societal groups , then this may lead to unequal chances to communi cate . Other technical limitations for automated content analysis arise from the difficulties automated content moderation systems have in understanding the context of a reader comment , the lack of natural language processing tools trained in the domain in which they will be applied , and the underrepresentation of certain groups of speakers in the training data.275 These technical limitations may lead to false positives and false negative s in the reviewing of comments . As Llansó and colleagues remark , false p ositives can put a burden on individuals ’ freedom of expression , while false negatives “ can result in a failure to address hate speech , harassment , and other objectionable content that may 272 Helberger N. , Leerssen P. and van Drunen M. , “ Germany proposes Europe ’ s fi rst diversity rules for social media platforms ” , Media @ LSE , https : //blogs.lse.ac.uk/medialse/2019/05/29/germany -proposes -europes -firstdiversity -rules -for-social -media -platforms/ . 273 Nelson , M. , “ Germany ’ s new media treaty demands that platforms explain algorithms and stop discriminating . Can it deliver ? ” , AlgorithmWatch , https : //algorithmwatch.org/en/new -media -treaty -germany/ . 274 Sap M. et al. , “ The risk of racial bias in hate speech detection ” , in Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics , 2019 , pp . 1668 –78 , https : //www.aclweb.org/anth ology/P19 -1163 . The Parliamentary Assembly has highlighted that “ [ t ] he use of biased datasets , or datasets that reflect historical bias , prejudice or discriminati on , is a major cause of discrimination in AI ” ; see Parliamentary Assembly , Report : Preventing discrimination caused by the use of artificial intelligence ( 29 September 2020 ) , para . 43 , https : //pace.c oe.int/en/files/28715/html . The above example shows that these risks are equally present in t he media field . 275 Llansó E. et al . , “ Artificial Intelligence , content moderation , and freedom of expression ” , Institute for Information Law , pp . 7 –8 , https : //www.ivi r.nl/publicaties/download/AI -Llanso -Van-Hoboken -Feb-2020.pdf . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 65 create a chilling effect on some individuals ’ and groups ’ willingne ss to participate online ” .276 In principle , the right to freedom of expression does not give people the right to speak on private platforms . The ECtHR has determined that freedom of exp ression “ does not bestow any freedom of forum for the exercise of that ri ght ” .277 Still , the ECtHR also stated that if the bar on access to private property prevents any effective exercise of freedom of expression or destroys the essence of freedom of expre ssion , then states may have a positive obligation to protect the enjoyment of freedom of expression rights by regulating property rights.278 Furthermore , as discussed in the previous sections , when news media or online intermediaries are moderating comments , they are essentially shaping the forum for public debate . The creation of a forum for public debate is a democratic role , which comes with duties and responsibilities . Some news media have accepted these responsibilities regarding the moderation of comme nts . For instance , the New York Times investigated the way it automatically moderates user comments following research about how automated content moderation may discriminate , or reinforce biases.279 Following this discussion of freedom of expression princi ples , rights , and duties and responsibilities for multiple stakeholders in t he news media environment , the final question is what obligations states have regarding freedom of expression in the face of the use of AI by news media . 3.5 . Obligations of states rega rding media freedom The rights and freedoms in the ECHR are formulated as ne gative rights . The provisions prohibit public authorities from interfering with the rights and freedoms of individuals . For example , in the case of freedom of expression , Article 1 0 ( 1 ) ECHR provides that everyone has the right to freedom of expression “ wit hout interference by public authority ” . The human rights in the ECHR thus contain negative obligations for states . Over the years , the ECtHR has accepted that human rights in the E CHR may also give rise to positive obligations for states . In the 1960s , the ECtHR for the first time accepted the idea that states may have positive obligations under certain ECHR rights.280 It took some years before the ECtHR read positive obligations in the right to freedom of expression . But in the 2000s , the ECtHR found that th e right to freedom of expression may contain positive obligations for states , even in the sphere of relations between 276 Llansó E. et al . , Ibid p. 9 . 277 ECtHR , Appleby and Others v. the United Kingdom [ 2003 ] , 44306/98 , p ara . 47 , http : //hudoc.echr.coe.int/e ng ? i=001 -61080 . 278 ECtHR , Appleby and Others v. the United Kingdom , para . 47 . 279 Salganik M.J. and Lee R.C. , “ To apply machine learning responsibly , we use it in moderation ” , NYT Open , https : //open.nytimes.com/to -apply -machine -learning -responsibly -we-use-it-in-moderation -d001f49e0644 . 280 ECtHR , Case ‘ r elating to certain aspects of the laws on the use of languages in education in Belgium ’ v. Belg ium [ 1968 ] , p ara . 27 , http : //hudoc.echr.coe.int/eng ? i=001 -57525 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 66 individuals.281 For example , the ECtHR held that states have a positive obligation to ensure that the public has access through new s media t o impartial , accurate , and diverse information , and that journalists can impart this information.282 Additionally , the ECtHR observed that states have a positive obligation to ado pt a solid legislative and administrative framework to guarantee pluralism in t he audiovisual media market.283 In the case of Dink v. Turkey , the ECtHR formulated a particularly strong positive obligation for states . The ECtHR found that states are required to create a favourable environment for participation in the public debate by a ll the persons concerned , enabling them to express their opinions and ideas without fear.284 The ECtHR repeated this statement in the case of Khadija Ismayilova .285 These two cases concerned attacks and harassment of journalists . In the case of Dink , the ECtHR found that the state had a positive obligation to protect a journalist against attacks by people who felt insulted by his publications . In the case of Khadija Ismayil ova , the ECtHR held that the state had a positive obligation to more effectively investig ate intrusions into the private life of a journalist . McGonagle argues that the notion of a favourable environment has great potential.286 Still , it is an open question how far the positive obligation of states to ensure an enabling environment for freedom o f expression reaches . From a positive law perspective , it currently does not guard against the risks of AI for freedom of expression . Although the ECtHR ’ s recent reiteration of the requirement to ensure a favourable environment may not extend to the use of AI by the news media , the foregoing shows that states do have positive obligations that may be relevant regarding AI . When the use of AI by the news media diminishes the diversity of information that people receive , then the positive obligations of states may be engaged . More concretely , states may have a positive obligation to ensure that news users receive diverse information through AI driven online news media in the event that personalisation and automated content moderation become so pervasive that th ey reduce the diversity of news media content that people receive . In its guidelines on media pluralism and transparency of media owners hip , the Committee of Ministers of the Council of Europe also stresses that states should make efforts to ensure that “ t he broadest possible diversity of media content , including general interest content , ” is accessible to everyone.287 These guidelines appl y to the use of AI by online news media as well . 281 ECtHR , Özgür Gündem v. Turkey [ 2000 ] , 23144/93 , para . 43 , http : //hudoc.ech r.coe.int/eng ? i=001 -58508 ; ECtHR , Fuentes Bobo v. Spain [ 2000 ] , 39293/98 , para . 38 , http : //hudoc.echr . coe.int/eng ? i=001 -63608 . 282 ECtHR , Manole and Others v. Moldova , para . 100 . 283 ECtHR [ GC ] , Centro Europa 7 S.r.l . and Di Stefano v. Italy [ 2012 ] , 38433/09 , para . 134 , http : //hudoc.echr.coe.int/eng ? i=001 -111399 . 284 ECtHR , Dink v. Turkey [ 2010 ] , 2668/07 , 6102/08 , 30079/08 , 7072/09 , 7124/09 , para . 137 , http : / /hudoc.echr.coe.int/eng ? i=001 -100383 . 285 ECtHR , Khadija Ismayilova v. Azerbaijan [ 2019 ] , 65286/13 , 57270/14 , para . 158 , http : / /hudoc.echr.coe.int/eng ? i=001 -188993 . 286 McGonagle T. , “ Positive obligati ons concerning freedom of expression : Mere potential or real power ? ” , in Andreotti O . ( ed . ) Journalism at risk : Threats , challenges , and perspectives , Council of Europe , pp . 9 –35 . 287 Council of Europe , Appendix to Recommendation CM/Rec ( 2018 ) 1 , Guidelines on media pluralism and transparency of media ownership . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 67 Furthermore , on a societal level , the use of AI by the news media and ot her actors in the news media environment may threaten media pluralism . Large news media and online intermediaries have access to more a nd better user data and more powerful AI technologies , which gives them a competitive advantage over local news media . Th e uptake of AI in the news industry for various stages of the journalistic process can push these smaller and local news media out of t he market , which risks decreasing media pluralism . States have a positive obligation to ensure media pluralism amidst the growing popularity of AI for the news business by , for example , creating a level playing field for online news media to use AI and dat a-driven technologies . 3.6 . Conclusion This chapter analysed the implication of the use of AI by news media for the human righ t to freedom of expression , as protected by Article 10 of the European Convention on Human Rights . Four goals in the pursuit of which n ews media can use AI were analysed : newsgathering ; news production ; news distribution ; and moderation of reader comments . The use of AI by news media falls within the democratic roles of the media as recognised and affirmed by the ECtHR : distributing infor mation to the public ; acting as a public watchdog ; and creating a forum for public debate . Because of their democratic ro le , the news media enjoy media freedom . Media freedom protects the use of AI to gather , publish , distribute , and receive information , a s freedom of expression protects both the content and the technical means for communication . Online intermediaries can f ulfil roles similar to the democratic roles of the media when they augment the accessibility of information and enable public debates o n their platforms . The selection , ranking , and prioritising of news by online intermediaries may therefore qualify for fr eedom of expression or even media freedom . News media and other actors exercising or contributing to freedom of expression by using AI also assume duties and responsibilities . For the news media , these duties and responsibilities are spelled out in journa listic codes of ethics and enforced through various self -regulatory instruments . However , current journalistic codes of ethics do not contain guidance for the use of AI . Some scholars are therefore calling for the development of algorithmic journalistic et hics . The concept of duties and responsibilities also provides a normative legal basis to require online intermediaries to develop adeq uate self -regulatory instruments for the use of AI when they contribute to the exercising of freedom of expression . If jo urnalistic codes of ethics and other self regulatory instruments continue to stay behind on the realities of AI in the news media envir onment , then states have a legal justification to regulate this domain when AI has significant effects on the freedom of expression rights of news users and other participants in public debate . The use of AI by news media presents , among others , the follo wing risks for freedom of expression : Events and news stories that do not generate big data may be ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 68 overlooked by the algo rithmic eyes of automated news -gathering systems and the voices of people implicated by these stories may therefore go unheard ; automat ed journalism may produce unlawful content that violates the rights and dignity of other people ; the personalised distrib ution of news may affect the right of news users to receive diverse information , which is an inherent part of freedom of expression ; fi nally , automated moderation of user comments may be biased against minority groups , which could lead to unequal chances t o communicate and participate in public debate . States may have positive obligations to ensure that everyone can effectively enjoy their right to freedom of expression in the face of AI . States have a positive obligation to ensure that news users receive diverse news and to create a favourable environment for freedom of expression . To the extent that the use of AI by large news corporati ons and online intermediaries threatens the competitive viability of smaller players , states may have positive obligation s to create a level playing field for the use of AI by news media . These conclusions resonate with calls from human rights organisation s and digital rights organisations regarding the implications of AI for freedom of expression . The UN Special Rapporteur on the promotion and protection of the right to freedom of opinion and expression recommends that states “ create a policy and legislati ve environment conducive to a diverse , pluralistic information environment ” , which includes “ taking measures to ensure a competitive field in the artificial intelligence domain ” .288 The OSCE Representative on Freedom of the Media289 , as well as Privacy Inter national and Article 19,290 also point to various threats related to AI for freedom of expression . The current challenge for news media and public authorities is to develop journalistic codes of ethics , self -regulatory standards , and possibly government re gulation to contain the risks of AI for freedom of expression , while enabling AI to contribute to public debate , media plura lism , the free flow of information , and other societal goals . The principles embedded within Article 10 ECHR provide concrete guidan ce for public and private bodies when they take up this challenge . 288 Kaye D. , “ Report of the Special Rapporteur on the promotion and protection of the right to freedom of opinion and expression ” , United Nations , para . 64 , https : //freedex.org/wp content/blogs.dir/2015/files/2018/10/AI -and-FOE-GA.pdf . 289 OSCE Representative on Freedom of the Media , Artificia l intelligence & freedom of expression , https : //www.osce.org/representative -on-freedom -of-media/447829 ? download=true . 290 Privacy International and Article 19 , Priva cy and freedom of expression in the age of artificial Intelligence , http : //privacyinternational.org/report/1752/privacy -and-freedom -expres sion-age-artificial -intelligence . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 69 4 . Cultural diversity policy in the age of AI Mira Burri , University of Lucerne 4.1 . Introduction Diversity of content is essential to a vibrant public discourse , to cultural and social inclusion and to cohesion . Cultural diversity has accordingly been long defined as a regulatory objective in national media and cultu ral policies , especially in Europe , and the mandate to protect and foster it has only been strengthened after the 2005 UNESCO Conven tion on Cultural Diversity.291 While cultural diversity has remained a key public policy objective , despite widely differing i mplementations in national policies on the ground , as the technological environment has profoundly changed , some fundamental questi ons have remained unanswered . Two critical questions need to be asked in this sense : Firstly , to what extent the affordances of the digital medium have enabled , as well as challenged , diversity online – both in terms of availability of diverse content and its actual consumption ; secondly , how suited are cultural policy toolkits , as now applied , to actually address and foster eng agement with culturally diverse content . This contribution will show that the answers to these questions are not simple and that po licy-makers may need to engage in complex trade -offs , as well as be more innovative in the implementation of their cultural p olicies – by governing through intermediaries and through technologies . This contribution will look at the affordances of digital media and artificial intelligence ( AI ) in particular and their implications for content policies ; it will not engage however in the broader discussions about creativity in the age of AI,292 nor does it look at diversity as embedded in AI to reduce biases in its decision -making293 or diversity in the AI industry.294 291 See e.g . Burri M. , “ The UNESCO Convention on Cultural Diversity : An appraisal five years after its entry into force. ” International Journal of Cultural Property 20 , 4 , pp . 357–380 , November 2013 . 292 See in this context , Kulesz O. , “ Culture , platforms and machin es : The Impact of Artificial Intelligence on the Diversity of Cultural Expressions ” , report for UNESCO , DCE/18/12.IGC/INF.4 , 2018 . 293 Melendez C. , “ In AI , Diversity Is a Business Imperative ” , The Forbes , 14 November 2019 . 294 See e.g . Paul K. , “ ‘ Disastrous ’ Lack of Diversity in AI Industry Perpetuates Bias ” , The Guardian , 17 April 2019 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 70 4.2 . Understanding the changed environment of content creation , distributio n , use and re -use The transformations in the digital networked environ ment epitomised by the societal penetration of the Internet have been multi -faceted and over the years their effects have been captured , although not without contention , by a host of exc ellent studies.295 The centrality of data and the predominance of multi ple-sided markets for data , as well as the rise of AI , have created a new level of complexity , and it is essential to understand well the contemporary dynamics around content , so as to be able to design adequate cultural toolkits . We focus on those specifi c developments that may be critical for the pursuit of cultural diversity objectives in this new space and are particularly interested in the changed ways content is produced , distributed , accessed , and consumed online , as well as in the related modificati ons in the patterns of user experience and participation , whenever these can be identified . This chapter uses the changing role of intermediaries as critical gatekeepers as an entry point to this complex discussion . 4.2.1 . Understanding the new intermediaries There have been assumptions , some of them backed by evidence , that the digital environment would bring about abundance , diversity and empowerment of users not possible under the conditions o f analogue media.296 One of the core elements supporting these positiv e accounts is that intermediaries do not exist in cyberspace and one can freely choose any content at any time . Yet , as contemporary digital media practice shows , this claim may be flawed . In fact , it may be that there are various intermediaries with different types of control over the choices we make and over the possibility for choices we see . We do not discuss here the physical intermediaries , such as network operators or Internet servic e suppliers ( although these can be very important297 ) , but focus on t hose gatekeepers existing at the applications and the content levels – the so -called “ choice intermediaries “ 298 or “ new editors “ ,299 which often also employ AI technologies . 295 See e.g . Benkler Y. , The wealth of networks : How social production transforms markets and freedom . New Haven : Yale University Press , 2006 ) ; Sunstein C. R. , Repub lic.com 2.0 . Princeton : Princeton University Press , 2007 . 296 Benkler Y. , Weinberger D. , Everything is miscellaneous : The power of the new digital disorder . New York : Henry Holt , 2007 ; Jenkins H. , Convergence culture : Where old and new media collide . New York : New York University Press , 2008 . 297 Benkler Y . ( 2006 ) . 298 Helberger N. , “ Diversity label : Exploring the potential and limits of a transparency approach to media diversity . ” Journal of Information Policy 1. pp . 337–369 , 2011 ; Helberger N. , “ Diversity by design ” , Journal of Information Policy , pp . 441–469 , 2011 . 299 Miel P. and Farris R. , News and information as digital media come of age , Cambridge : The Berkman Center for Internet and Society , 2008 , at p. 27 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 71 To understand the n ew media space , it may be helpful to compare it to the functionin g of legacy media . Conventionally , in the offline/analogue world , editorial roles were concentrated under the roof of a single institution . Editorial choices were based on a certain , limited pool of materials , and editorial products were finite , bounded by the limitations inherent to each medium , such as the pages of a printed newspaper or the length of a broadcast . The targeted audience was also typically addressed in a certain rhythm , which influenced the breadth and depth of the content – for example dai ly newspapers or a weekly edition . The editorial decisions made as to the content and the format reached the entire audience of any given publication or programme in the same way – they were not tailored to a particular user . Depending on the format , there was also a certain balance between local , national and international topics , which were presented in a contextualised and trustworthy manner . These were the key editorial functions of broadc asters and other legacy media , which were in many jurisdictions a lso under a specific mandate to feature local and national content ; there were commonly mechanisms in place to supervise the fulfilment of certain content quantity and quality requirements . In the European Union , for instance , there are , in addition to the obligation to carry a majority of European works on audiovisual channels , requirements and obligations at the national level . Overall , these relatively neatly defined editorial functions had important consequences for the production and distribution of kn owledge.300 They also supported the conviction , which underlies almost all national media policies , that diversity in supply will be reflected in diversity of consumption . The picture is striki ngly different now , as digital media forms remove these analogue limitations and provoke “ fundamental shifts in the composition and consumption of media products ” .301 The “ new editors “ are multiple , disintegrated and distributed.302 The “ new editors “ are AI -driven and it is ultimately algorithms303 that define the new media space . Aggregation is the first such editor and refers to the process of assembling different types of content in a tailored fashion and constantly updating it . This sort of persona lised edito r is offered on different platforms , for different types of content – be it news , entertainment or gossip . It automatically generates information tailored to a particular user profile and/or previous experience in a seemingly seamless and incess ant manner . The mechanism driving this content feed is usually an algorithm that is specific 300 Weinberger D. , Too big to know , New York : Basic Books , 2012 . 301 Miel and Farris at p. 27 . See also Kleis Nielsen R. , Gorwa R. , and de Cock Buning M. , What can be done ? Digital media policy options for strengthening European democracy , Oxford : R euters Institute Report , 2019 . 302 Ibid . ; also Latzer M. , Holln huchner K. , Just N. , and Saurwein F. , “ The economics of algorithmic selection on the Internet ” in Bauer J. M. and Latzer M . ( eds . ) , Handbook on the economics of the Internet . Cheltenham : Edward Elgar . pp . 395−425 , 2016 . 303 For a comprehensive definition of algorithms , see Latzer M. , and Just N. , “ Governance by and of algorithms on the Internet : Impact and consequences ” , in Oxford Research Encyclopedia , Communication , Oxford : Oxford University Press , 2020 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 72 to the platform ( be it Facebook or Instagram for example ) and may discriminate between different types of content.304 Social bookmarking has also become increasing ly important as a mechanism of giving prominence to content . Here the crowd acts as an editor through different ranking and bookmarking systems , such as Reddit , Technorati or Del.icio.us . With the wide adoption of Twitter and Instagram , in particular by yo unger genera tions , the use of hashtags as a type of metadata tag , allowing users to create dynamic , user -generated indexes , has increased . These mechanisms can not only tailor media consumption but also succeed in commanding the attention of large groups.305 This may be true for political campaigns but also for mobilising consumer attention in marketing campaigns . And finally , as a digital intermediary , search is nowadays absolutely essential . It is often the starting point for the majority of online experi ences and is the most significant driver of traffic to most websites . Without being indexed and searchable on the net , content is plainly rendered non -existent.306 Search is again typically driven by proprietary algorithms and the business is highly concent rated around v ery few providers , with Google clearly distancing itself from its competitors . 4.2.2 . Implications of AI -driven editorial agents Through all these different mechanisms , the network functions as a multi -channel editor and an important intermediary i n the content value chain – it replaces in fact the role of traditional media as a “ general interest intermediary ” .307 On the positive side , it has been suggested that “ the networked media environment as a virtual social mind … produces something richer , more representa tive , and more open to ideas than the top -down mass media model of the past ” .308 While we should not un derestimate the affordances of digital platforms and the processes of communication , participation and engagement that they enable , at least so far , there is profound uncertainty and indeed increasing doubt as to the 304 The algorithms often co mbine different mechanism s and are driven by different factors : ( 1 ) general popularity of the item among all users is the simplest approach , where all users get the same recommendation , which ultimately results in popular items beco ming even more popular a nd the disappearing of unpopular items ; ( 2 ) semantic filtering recommends items that match the currently used item or items previously used by the same user on a number of pre -defined criteria ( such as topics , the author or source o f an article ) ; ( 3 ) collaborative filtering or social information filtering is an automated ‘ word -of-mouth ’ recommendations generator – items are recommended to a user based upon values assigned by other people with similar taste . These methods are usually applied in hybrid forms , including also other methods like weighing items by recency or pushing content that has specific features such as paid content . Platforms have also over the years accumulated large amount s of valuable data based on past behavior an d can additionally apply user data such as age or location to calibrate the content feed . See Bozdag E. , “ Bias in algorithmic filtering and personalization ” , in Ethics and Information Technology 15 . Pp . 209–227 , 2013 . 305 Miel and Farris , at p. 30 . 306 Council of Europe , Draft Recomm endation on the Protection of Human Rights with Regard to Search Engines , Strasbourg , 11 March 2010 . 307 Sunstein ( 2007 ) . 308 Miel and Farris , at p. 30 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 73 ability of this self -organising mechani sm to reliably identify salient information.309 There is also a dose of scepticism as to its impact on the diversity and quality of content , and on users ’ ca pabilities to find and access content that is diverse and trustworthy . Thinking about the societal f unctions of the media and the goal of cultural diversity in the context of this chapter ’ s discussion , it could be that this complex environment presents cer tain dangers of reduced diversity and fragmentation of the public discourse.310 First , we need to ack nowledge the possible interferences with users ’ individual autonomy and freedom of choice . As Latzer et al . argue , while filtering reduces search and informa tion costs and facilitates social orientation,311 it can be “ compromised by the production of social risks , among other things , threats to basic rights and liberties as well as impacts on the mediation of realities and people ’ s future development ” .312 The second worry in this context has to do with the impact of tailored media production and consumption . In the former sense , there has been a recent trend towards algorithmic content production , where algorithms drive decision -making in media organisations by predicting audiences ’ consumption patterns and preferences.313 While in some areas this may be viewed as beneficial in giving the audiences what they want , in other areas , such as for news , this may be highly problematic , as local news and current affairs becom e tailored to the demographic , social and political variables of specific communities.314 We shou ld also be reminded of the so -called “ content farms “ , which , based on search -engine data ( such as popular search terms , ad word sales and actual available conten t ) produce content rapidly and cheaply in order to meet that demand . Such creation of content i s completely commodified and possibly harmful to any public interest function of the media , including in the cultural sphere . In the sense of media consumption , the personalisation of the media diet , as based on a distinct profile or previous experience , “ promotes content that is geographically close as well as socially and conceptually familiar ” 315 … “ This keeps users within familiar boundaries , feeding their curio sity with more of the same . When they are looking for new content or information , this reinfor ces existing opinions , gradually removing conflicting views. ” 316 One can of course state that this has been the case with legacy media as well , where people are nat urally drawn to content they have liked in the past – the key difference in the current space is that users see only this content , and their active choice is so diminished or manipulated . Hoffman et al . argue that social media only 309 Ibid . 310 See e.g . Sunstein C. R. Going to extremes : How like minds unite and divide , Oxford : Oxford Univer sity Press , 2009 . ; Pariser E. , The filter bubble : What the Internet is hiding from you , London : Viking , 2011 . 311 Latzer et al . 312 Ibid. , at pp . 29–30 . 313 Napoli P. M. , “ On automation in media industries : Integrating algorithmic media production into media industries scholarship ” in Media Industries Journal 1. pp . 33–38 , 2014 ; also Saurwein F. , Just N. , and Latzer M. , “ Governance of algorithms : Options and limitations ’ , info 17. pp . 35–49 , 2015 . 314 Napoli , ibid. , at p. 34 . 315 Hoffman C. P. , Lutz C. , Meckel M. , and Ranzini G. , “ Diversity by choice : Applying a social cognitive perspective to the role of public service media in the digital age ” , International Journal of Communication , 9 , 2015 , pp . 1360 –1381 . 316 Ibid . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 74 exacerbate this effect b y combining two dimensions of homophily : similarity of peers and of content.317 We should keep in mind in this context that despite a slight reduction in the use of social networking sites as an entry point to content and variations across countries,318 they s till are important gatekeepers . This reinforces the effect of homophily , as well as clearly illustrates the power of a few players and the deep impact of their decisions – for instance , when Facebook changed its algorithm in 2018 and downgraded news , this automatically led to less news consumption.319 The commercialisation of platforms and the radical increase in commercially or politically driven “ fake news ” should also be underscored.320 Despite the slight shift towards reader payment models for new s , it is worth remembering that the vast majority of online consumption still happens through free websites , largely supported by advertising . While some of the aggregated content is taken from legacy media,321 which may disperse some of the conventional cr iticism th at aggregators amplify the impact of unreliable non -traditional sources , it is still true that content is not made more abundant but has merely become more distributed – in this sense we do not have more and diverse content but simply more of the same . Sti ll , it is fair to note that legacy media have responded to the technologically enabled aggregation and offer much more content online than in their print or broadcast versions . With specific regard to news , the Reuters Institute for the Study of Journalism found that private news organisations are making major investments in social media and report significant traffic , off -site reach , and/or additional digital subscribers.322 While this may enable access to a variety of content over more platforms , also entic ing young people , two drawbacks need to highlighted : the first relates to the almost full reliance of media organisations on Facebook , which brings a certain “ platform risk “ with it ; the second is that private sector legacy news organisations ’ approaches t o social media are strongly shaped by path -dependent business models oriented towards advertising and subscriptions , or a mix thereof.323 This again may not lead to a sustainable offering of diverse local , regional and national content.324 Overall , 317 Ibid . 318 For country analyses , see Reuters Institu te for the Study of Journalism , Digital News Report 2018 , Oxford , 2018 . 319 Reuters Institute for the Study of Journalism ( 2018 ) ; also Tucker J . A. et al . Social media , political polarization , and political disinformation : A review of the scientific literatu re , prepared for the Hewlett Foundation , March , 2018 . 320 Reuters Institute for the Study of Journalism ( 2018 ) ; European Commission , Tackling Online Disinformation : a European Approach , COM ( 2018 ) 236 final , 26 April 2018 . 321 Reuters Institute for the Study o f Journalism ( 2018 ) . Aggregators may be somewhat restricted by copyright , see Associated Press v. Meltwater U.S. Holdings , Inc . , 931 F. Supp . 2d 537 , 537 ( S.D.N.Y . 2013 ) and newer initiatives in the field of EU copyright law . 322 They identify three main str ategic aims shaping the different ways in which news organi sations approach social media : ( 1 ) driving on -site traffic through referrals ; ( 2 ) driving off -site reach through native formats and distributed content ; ( 3 ) driving digital subscription sales , ofte n in part through advertising content on Facebook . 323 Cornia A. , Sehl A. , Levy D. A. , and Nielsen R. K. , Private sector news , social media distribution , and algorithm change , Oxford : Reuters Institute for the Study of Journalism , 2018 . 324 A study of US local media has shown for instance that only about 17 percent of the news stories provided to a community were truly local – that i s , about or having taken place within the municipality ; fewer than half ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 75 despite inc reased amounts of content , there may be less local , regional and national content and real difficulties in finding it , because it is - or becomes - marginalised on online platforms . With regard to search engines as intermediaries , it may be g enerally in t he long term interest of search providers to meet the needs of their users – both as consumers and as citizens . Research conducted by the UK ’ s Ofcom suggests that demand for national public service content remains strong , and therefore it shou ld continue t o be in the interest of search providers to ensure that their results give due prominence to such content.325 A recent comparative study also found that those who find news via search engines , on average use more sources of online news , are mor e likely to us e both left - and right -leaning online news sources , and have more balanced news repertoires.326 This said , and as earlier mentioned , search results are generated algorithmically and automatically assign relevance to certain information units . The automated s election is also prone to manipulation using a range of search engine optimisation techniques , whereby sponsored or other content gains more visibility and attracts more attention.327 In concluding this section , which offers only a snapshot o f the complex contemporary media environment , one needs to stress its fluidity and the therewith related uncertainty as to its impact , as far the abundance and diversity of content and the conditions of free speech are concerned . On the one hand , there is a discourse in t he literature that , under different labels such as “ filter bubbles “ 328 or “ echo chambers “ ,329 highlights the risks of the current tailored media diet in leading towards a fragmentation of the public discourse and possible polarisation of view s.330 On the other h and , we are unsure to what extent this is true . A 2017 cross -country report found for instance that although search plays a major role in shaping opinion , it needs to be viewed in a context of multiple media and is not deterministic.331 The s tudy of “ automat ed serendipity ” , which denotes a phenomenon whereby users are drawn to sources they would not have consulted otherwise , also reduces the fears of “ echo chambers “ .332 In the same context , it should be noted that the currently applied tools to track fragmentat ion tell us surprisingly ( 43 percent ) of the news stories were original – that is , actually produced by the local media outlet . See Napoli P. M. , Weber M. , McCollough K. , and Wang Q. , Assessing local journalis m : News deserts , journalism divides , and the determinants of the robustness of local news . News Measures Research Project , August , 2018 . 325 Ofcom „ Ofcom ’ s Second Public Service Broadcasting Review , Phase Two : Preparing for the Digital Future “ , London : Ofco m , 2008 , para . 5.60 . 326 The authors refer to a phenomenon of “ automated serendipity ” , which leads people to sources they would not have used otherwise . See Fletcher R . and Nielsen R. K. , “ Automated serendipity ” in Digital Journalism 6. pp . 976–989 , 2018 . 327 See e.g . Bradshaw S. , “ Disinformation optimised : Gaming search engine algorithms to amplify junk news ” , in Internet Policy Review 8. pp . 1–24 , 2019 . 328 Pariser ( 2011 ) . 329 Sunstein C. R. , Infotopia : How many minds produce knowledge . Oxford : Oxford University Press , 2006 . 330 See also High Level Group on Media Freedom and Pluralism , A free and pluralistic media to sustain European democrac y . Report prepared for the European Commission p. 27 , January 2013 . 331 Dutton W. H. et al “ Search and politic s : The uses and impacts of search in Britain , France , Germany , Italy , Poland , Spain , and the United States ” , Quello Center working paper No 5 pp . 1-17 , 18 May 2017 . 332 Fletcher and Kleis Nielsen ( 2018 ) . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 76 little about audience loyalties and how public attention moves across media.333 Webster and Ksiazek find for instance little evidence that audiences are composed of devoted loyalists.334 “ Moreover , measures of exposu re , no matter how p recise , can not tell us how content affects people . It may be that even modest periods of exposure to hate speech or otherwise obscure media have powerful effects on those who seek it out ” ,335 or it could be that the overall effect is bala nced through other c omponents in the media diet.336 In this sense , we should not concentrate on snapshots but examine dynamics and track evolution over time.337 4.3 . Possible avenues of action : New tools addressing and engaging digital intermediaries In painting the picture of the tra nsformed and transforming media landscape above , we observe the complexity of new “ editorial “ processes and the difficulty for individuals to navigate this potentially rich but distributed content space . We also identify some potential risks of tailored co ntent consumption and polarisation of views in this environment , as the new intermediaries al gorithmically drive supply and demand by selecting information elements and assigning relevance to them.338 Against this backdrop , one can think of two viable channe ls for introducing cultural diversity measures : the first is in addressing the emergent envi ronment and governing the algorithms as critical gatekeepers , since these have so far largely remained unregulated , especially for cultural policy purposes ; the sec ond is using the new intermediaries as a tool to promote cultural diversity exposure , in the sense of “ governance through intermediaries “ . 4.3.1 . Governance of algorithms When speaking of governance of algorithms , there is a more generic , not necessarily cultura l policy -related debate , which has to do with the observation that intermediaries , in partic ular those driven by algorithms , have gained a critical role in the online space and in this sense it is now governed by algorithms.339 This discussion is closely rel ated to that on the appropriate ways to address this new power – that is , the governance of 333 Webster J.G . and Ksiazek T. B. , “ The dynamics of audience fragmentation : Public attention in an age of digital media ” , Journal of Communication 62 , pp . 39–56 , 2012 . 334 Ibid. , at p. 40 . 335 Ibid. , at p. 51 . 336 For very interesting findings , see Pew Research Center , “ Political polarization and media habits : From Fox News to Facebook , how liberals and conservatives keep up with politics ” , Washington , DC : Pew Research , 2014 . 337 For newer trends in media consum ption , see Reuters Institute for the Study of Journalism ( 2018 ) . 338 Saurwein et al . ( 2015 ) , at p. 35 . 339 For an excellent analysis and review of the literature , see Saurwein et al . ( 2015 ) . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 77 algorithms.340 Privacy protection questions have been particularly salient in this latter context341 but also questions around copyright enforcement through intermediar ies , as illustrated by the latest EU copyright reform and the discussion around Article 1 7 of the Copyright in the Digital Single Market Directive.342 Latzer et al . identify nine categories of risk stemming from algorithmic selection that may need to be addr essed : ( 1 ) manipulation ; ( 2 ) diminishing variety , echo chambers and biases ; ( 3 ) constrai nts on freedom of expression ; ( 4 ) surveillance and threats to data protection and privacy ; ( 5 ) social discrimination ; ( 6 ) violation of intellectual property rights ; ( 7 ) abuse of market power ; ( 8 ) effects on cognitive capabilities ; and ( 9 ) growing heteronom y , loss of human sovereignty and controllability of technology.343 We were particularly interested in ( 2 ) , ( 3 ) and ( 9 ) above , as immediately related to the core cultural diversity objectives pursued in the media domain . Saurwein et al . provide a careful an alysis of the different governance options that can address these risks , which , next to conventional command -and-control interventions , may involve regulation by market and various self - and co -regulatory solutions in between.344 Yet , the authors also note that so far there have been hardly any tools designed to address the risks of bias , heteronomy and effects on cognitive capabilities .. It is indeed true in the specific s etting of our discussion that most of these intermediary platforms will not fall under the regulatory scope of the current media regimes . Napoli has argued in this context that we should start approaching algorithms as a distinctive form of media instituti on.345 He believes algorithms should be subject to restrictive types of regulation – that is , a ban on certain types of activities by the platform operators or content on these platforms , to protect privacy and counter graphic violence and hate speech . Napol i suggests that considering the crucial role these new intermediaries play , we ought to develop “ affirmative approaches in the public interest ” ,346 as we have done for traditional electronic media built upon established media policy principles , such as plura lity , diversity , and localism – prescribing for instance certain amounts or types of 340 Saurwein et al . ( 2015 ) . 341 For instance with regard to the right to be fo rgotten , which is now enshrined in the EU data protection regime of the General Data Protection Regulation . 342 See Directive 2019/790 of the European Parliament and of the Council of 17 April 2019 on copyright and related rights in the Digital Single M arket and amending Directives 96/9/EC and 2001/29/EC , OJ L ( 2019 ) 130/92 , https : //eur -lex.europa.eu/legal -content/EN/TXT/ ? uri=CELEX % 3A32019L0790 . See also Montagnani M. L. and Trapova A. Y. , “ Safe harbours in deep waters : A new emerging liability regime for Internet intermediaries i n the digital single market ” , International Journal of Law and Information Technology 26. pp . 294–310 , 2018 ; Senftleben M. , “ Institutionalized algorithmic enforcement – The pros and cons of the EU approach to UGC platform liability ” , Florida International University Law Review 14 , 2020 . 343 Saurwein et al . ( 2015 ) , at p. 37 . 344 Saurwein et al . ( 2015 ) . 345 Napoli P. M. , “ The algorithm as institution : T oward a theoretical framework for automated media production and consumption ” , paper presented at the Media in Transition Conference , Massachusetts Institute of Technology , May 2013 ; Napoli P. M. , “ Social media and the public interest : Governance of news platforms in the realm of individual and algorithmic gatekeepers . Media + the Public I nterest Initiative Working Paper , 2014 . 346 Napoli ( 2014 ) , ibid . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 78 content.347 This could address on the one hand the lack of diverse , trustworthy and local content , which despite the availability of more content online appears scarce , as w ell as increase the possibility for users to access such content.348 It should be no ted in this context that the discussions on the regulation of algorithms , although relatively young , have rapidly evolved . In the age of big data , perils for personal data pr otection and “ fake news ” proliferation , the topic has gathered attention on the pa rt of politicians and the broader public , and the need for action has been recognised.349 However , the form of action is yet to be defined . So far , any action appears to be unf olding in the domains of self -regulation and soft regulatory approaches , as hard intervention may not only hinder platforms ’ and users ’ innovation but also defeat the very goal of promoting free speech in its active and passive forms . In this context , and in an attempt to design appropriate and forward -looking governance tools , one nee ds to carefully consider the experience so far in the field of fighting online disinformation . On the one hand , we must examine to what extent businesses have responded to the increased public awareness and users ’ demands for trust and quality , and to what extent different technical ( for instance by adjusting algorithms ) and other solutions ( for instance working with users and other organisations ) have effectively contributed t owards the defined objective − in this case : constraining the amount and spread o f “ fake news ” .350 Facebook ’ s efforts , subsequent to the 2016 US presidential campaign , may provide a case in point . As a reaction to various accusations , Facebook endorsed a num ber of initiatives − for instance , it disseminated educational tools for informa tion literacy , started the Facebook Journalism Project and joined the News Integrity Initiative with a number of academic and media partners focused on fostering engaged commun ities and more inclusive media , while seeking to better understand misinformatio n. Concretely and in order to reduce the spread of “ fake news ” , Facebook entered into partnerships with about 40 third -party media organisations − such as Snopes , PolitiFact , t he Associated Press , and FactCheck.org . They strive to fact -check shared news stories and identify them with a “ disputed “ label if they did not pass a fact -checking muster . Facebook also installed a “ more info “ button that let s users obtain additional cont ext about articles in their news feeds.351 Despite these wide efforts , research and anecdotal evidence suggest that Facebook ’ s practices may still be insufficient to secure a ‘ healthy ’ media space.352 347 Napoli P. M. “ Social media and the public interest : Governance of news platforms in the realm of individua l and algorithmic gatekeepers ” , Telecommunications Policy 39. pp . 751–760 , 2015 . 348 See Napoli P. M. “ Re-evaluating the long tail : Implications for audiovisual diversity on the Internet ” , in Albornoz L. A. and Garcia Leiva M. T . ( eds . ) , Audiovisual industri es and diversity : Economics and policies in the digital era . Abingdon : Ro utledge , 2 019 , a t chapter 5 ; Napoli P. M. , Social media and the public interest : Media regulation in the disinformation age , New York : Columbia University Press , 2019 . 349 See e.g . Balk in J. , “ Free speech in the algorithmic society : Big data , private governance , and new school speech regulation ” , UC Davies Law Review 51. pp . 1149 –1210 , 2018 . There have also been multiple actions in the EU with regard to data protection and “ fake news ” – for instance , through the adoption of the GDPR . See also European C ommission ( 2018 ) . 350 Reuters Institute for the Study of Journalism ( 2018 ) . 351 The ‘ additional information ’ button for news articles surfaced in the News Feed lets users click through to see : ( 1 ) background pulled from the Wikipedia page about the publisher ; ( 2 ) other articles recently posted by ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 79 The role of governments , civil society and other user orga nisations should also be taken into acc ount . A good recent example of coordinated efforts and working together on multiple fronts has been the European approach towards “ fake news ” .353 The European Commission subscribes to improving transparency of distribut ed information , its diversity and cred ibility and to an effort to fashion inclusive long -term solutions to this effect . Amongst other things , the Commission convened a multi -stakeholder forum to provide a framework for efficient cooperation amongst relevan t stakeholders , including online platforms , the advertising industry and major advertisers , and to secure a commitment to coordinate and scale up efforts to tackle disinformation . The forum ’ s first output was an EU-wide Code of Practice on Disinformation . Adopted in September 2018 , the code se ts out self -regulatory standards to fight disinformation ; it aims at achieving the Commission ’ s objectives by setting a wide range of commitments , from transparency in political advertising to the closure of fake accou nts and demonetisation of purveyors of disinformation . The code also includes an annex identifying best practices that signatories pledge to apply to implement the code 's commitments.354 More decisive steps towards accountability , and even a move towards co -regulatory approaches , may be necessa ry , however,355 as evidentiated by the acute problem of “ fake news ” around the Covid -19 pandemic.356 4.3.2 . Governance through algorithms Moving towards a more targeted cultural diversity toolkit , one may consider endorsing new f orms of editorial intelligence,357 as a sort of public interest mediation of the digital space that seeks to increase the visibility , discoverability and usability of discrete types of the publisher ; ( 3 ) a heat map of where in the world the article is being shar ed and which of the user ’ s Facebook friends have shared it . 352 Levin S. , “ They do n't care : Facebook fact-checking in disarray as journalists push to cut ties ” , The Guardian , 13 December 2018 . For a more in -depth analysis , see Saurwein F. and Spencer -Smith C. , “ Combating disinformation on social media : Multilevel governance and distributed accountability in Europe ” , Digital Journalism , 2020 . 353 European Commission ( 2018 ) . 354 For all documents , s ee https : //ec.europa.eu/digital -single -marke t/en/news/code -practice -disinformation . The latest report of the European Regulatory Group for Audiovisual Media Ser vices ( ERGA ) on disinformation shows some limits in the commitments taken by platforms within the code ; see ERGA Report on Disinformation : Assessment of the Implementation of the Code of Practice , 2020 , https : //erga online.eu/ ? p=732 . 355 Saurwein and Spencer -Smith ( 2020 ) . 356 See e.g . “ Social media firms fail to act on Covid -19 fake news ” , BBC News , 4 June 2020 . 357 We do not address here media literacy policies , whi ch can also be important from the user -centric perspective . See Helberger ( 2011 ) , at p. 357 ; Burri M. , “ The global digital divide as impeded access to content ” , in Burri M. , and Cottier T. ( eds . ) , Trade governance in the digital age . Cambridge : Cambridge University Press . pp . 396–420 , 2012 ; High Level Group on Media Freedom and Pluralism , “ A Free and Pluralistic Media to Sustain European Democracy ” , report prepared for the European Commission , January 2013 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 80 content.358 We may also envision tools that incentivise exposure diversity – that is , the actual consumption of diverse content.359 This is not a completely new or exotic project . The European media framework , under the Audiovisual Media Services Directive ( AVMSD ) 360 includes a suggestion that the promotion of European works may rela te to increasing the “ prominenc e “ of such works.361 From the consultation of regulatory authorities in 2013,362 it appears that many of them were in favour of prominence tools , while being sceptical about the promotion through asset share in catalogues . Many v iew this measure as the most efficient ( also because it relates to actual higher consumption of European works ) and the least burdensome for operators.363 It has also been a standing practice in Europe that public service broadcasters ( PSBs ) have had the pri vilege to occupy the first s lots in electronic programme guides ( EPGs ) and have so been given “ due prominence “ .364 Foster and Broughton show that EPGs have been an important tool for consumers finding and selecting programmes , and there is evidence that chan nels with slots near the to p of each section of an EPG have had an advantage in viewers ’ selection over those further down.365 “ This approach [ of “ nudging “ people towards the choices we hope they will make both in their own and society ’ s wider interests ] has so far worked reasonably well. ” 366 Recent evidence confirms that EPG 358 Miel and Farris , at p. 3 ; also Goodman E. P. , “ Public media 2.0 ” , in Schejter A. M . ( ed . ) , And communications for all : A public policy agenda for a new administration . Lanham , MD : Lexington Books , pp . 263–280 , 2009 ; Webster J. G. , “ User information regimes : How social media shape patterns of consumption ” , Northwestern University Law Review 104 , pp . 593–612 , 2010 . 359 See Helberger N. , “ Media diversity from the user ’ s perspective : An introduction ” , Journal of Information Policy 1 , pp . 241–245 , 2011 ; Napoli P. M. , “ Exposure diversity reconsidered ” , Journal of Information Policy 1 , pp . 246– 259 , 2011 . 360 The AVMS was last reviewed in 2018 : see Directive ( EU ) 2018/1808 of the European Parliament and of the Council of 14 November 2018 amending Direc tive 2010/13/EU on the coordination of cer tain provisions laid down by law , regulation or administrative action in Member States concerning the provision of audiovisual media services ( Audiovisual Media Services Directive ) in view of changing market realit ies , OJ L ( 2018 ) 303/69 . 361 See the latest EU recommendations : Communication from the Commission Guidelines pursuant to Article 13 ( 7 ) of the Audiovisual Media Services Directive on the calculation of the share of European works in on demand catalogues and on the definition of low aud ience and low turnover 2020/C 223/03 , OJ C ( 2020 ) 223/10 . 362 See e.g . European Audiovisual Observatory , IRIS Special : Video on Demand and the Promotion of European Works . Strasbourg : European Audiovisual Observatory , 2013 . 363 European Commission ( 2014 ) , at p. 6 . 364 EPGs have been regulated at the EU level through the Access Directive ( Directive 2002/19/EC of the European Parliament and of the Council of 7 March 2002 on access to , and interconnection of , electronic communications net works and associated facilit ies , OJ L 108/7 , 24 April 2002 , as amended by Directive 2009/140/EC of the European Parliament and of the Council of 25 November 2009 , OJ L 337/37 , 18 December 2009 ) . The implementation of the directive differs – e.g . the Britis h regulation allows a prefer red treatment of PSB channels , while in Germany the regulation of EPGs is based on the equal treatment of public and commercial channels in EPG listings . 365 Foster R. and Broughton T. , “ PSB prominence in a converged media world ” , report commissioned by the BBC , London : Communications Chambers at p. 12 , 2012 . Other factors that influence selection include having a memorable EPG channel number and being adjacent to another popular channel . 366 Foster and Broughton , op.cit , pp . 13–14 . This has been confirmed by a more recent report . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 81 positioning is likely to have a significant impact on a channel ’ s performance.367 Such “ nudging “ , albeit for commercial media , has also worked with the remote controls of SMART TVs , with the big online players , such as Netflix , YouTube and Google Play , appearing as buttons allowing direct access . In a similar way , one may consider a deeper type of intervention that entails some sort of guidance for users as to the “ relevant “ and “ quality “ local , regional or national content , making sure they then consume the “ right mix “ .368 Two critical questions arise in this context – of awareness and of s erendipity – i.e . : “ Do people know about the full range of content opportunities available to them online , and how often do they stumble across content that they like but that they did not know existed ? ” 369 The UK ’ s Ofcom has shown that barriers with respec t to awareness and serendipity may be significant.370 One way of doing this is through the existing PSB syste ms.371 One can first think of an updated variation of the EPG as a tool for enhancing the prominence of both the PSB brand and the local , regional an d national content offering . Foster and Broughton see this “ nudging “ as a two -step process whereby viewers ar e attracted to the PSB channel or brand and then a range of techniques are used to “ lead audiences to a wider range of content than they might othe rwise have chosen for themselves ” .372 The authors have justified the need for new legislation that will ensure prominence of PSB brands or individual service brands373 on online platforms . Prominence requirements should apply to the core elements of any consumer interface , such as a channel gr id or on -demand service menu and each PSB should expect to secure at least one icon/button on the first page of an on -demand guide or its equivalent.374 The same rationale can be applied also for European works.375 367 Ofcom , “ EPG prominence : A report on the discoverability of PSB and local TV services ” , London : Ofcom , 2018 . The data on the effect of prominence on VoD viewing are less comprehensive but suggest a similar correlation . 368 Helberger ( 2011 ) , at p. 346 . Justifying also such an approach , see Sunstein C. R. , “ Television and the public interest ” , California Law Review 88. pp . 499–563 . 369 Ofcom “ Ofcom ’ s Second Public Service Broadcasting Review , Phase Two : Preparing for the Digital Future ” , London : Ofcom , 2008 a t para . 3.95 . 370 Ofcom ( 2008 ) at para . 3.98 . 371 For a fully -fledged analysis , see Burri ( 2015 ) . 372 Foster and Broughton , op.cit . , . At p. 11 . 373 Foster and Broughton argue against prominence given to individual pr ogrammes , which , they argue , may fragment user experience and hurt the overall PSB brand . 374 Foster and Broughton , op.cit . , p. 4 . 375 The amended AVMS contains in its Article 13 such a rule : “ Member States shall ensure that media service providers of on -dema nd audiovisual media services under their jurisdiction secure at least a 30 % share of European works in their catalogues and ensure prominence of those works ’ . Recital 34 explains further that : “ ... The labelling in metadata of audiovisual content that qual ifies as a European work should be encouraged so that such metadata are available to media service providers . Prominence involves promoting European works through facilitating access to s uch works . Prominence can be ensured through various means such as a dedicated section for European works that is accessible from the service homepage , the possibility to search for European works in the search tool available as part of that service , the u se of European works in campaigns of that service or a minimum percen tage of European works promoted from that service 's catalogue , for example by using banners or similar tools . ” ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 82 The second proposition ( fostering serendipi ty ) may help too – “ in particular for introducing viewers to content they wou ld not otherwise look for or challenging users ’ views and expanding their knowledge ‘ by chance ’ ” .376 In this context , a scholars have stressed that “ [ s ] erendipitous encounters migh t alleviate some concerns about restrictive coping strategies and a tendency i n users to hide in their ‘ information cocoons ’ ,377 and ‘ promote understanding ’ and open -mindedness , and thereby also advance democratic goals ” .378 The digital space and different w ays of analysing data and aggregating content do allow for the random delivery o f different types of content , which can be displayed next to the “ chosen by the viewer ” content or in dedicated “ less searched for ” , “ less viewed ” and other “ less popular ” “ not-mainstream ” lists . Also , since it appears that there is a great difference in t he availability and discoverability of discrete genres of content ( e.g . sports versus educational programmes ) , it may be appropriate to establish cross -genre linkages , so as to both highlight this type of content and to increase the chances of overall more diverse consumption.379 However , caution should be exercised with regard to these random offerings , as they can simply be ignored or can even disrupt a viewer ’ s experience . Res earch has shown that there must be more to serendipitous encounters than just cha nce . Schönbach explains that in order to work and incentivise users , surprises must be “ embedded in the familiar ” .380 Helberger expounds further that “ [ i ] n order to be able to make sense out of chance information exposure , the information must resonate with some prior knowledge , interest , or experience for the user ” .381 Hoffman et al . argue along the same line : that we can speak of “ diversity experience ” only if users “ perceive and digest this content according to their motivations , awareness , and capabilities ” .382 Designing tools that work well for this purpose may be a difficult task that partly links to the theme of medi a literacy . Such tools may also be connected to certain algorithmic design functions as “ empowerment nudges , which promote decision -making in t he interests of citizens , as judged by themselves , without introducing further regulation or incentives or using any manipulative measures ” .383 376 Ofcom ( 2008a ) . At paras 3.99 –3.101 . 377 Helberger ( 2011a ) . At p. 454 . 378 Ibid. , referring to Sunstein ( 2007 ) . At pp . 27–28 . 379 For an experiment on fostering content diversity through recommendation systems , see Möller J. et al . , “ Do not blame it on the algorithm : An empirical assessment of multiple recommender systems and their impact on content diversity ” , Information , Communication and Society , 2018 . 380 Schönbach K. “ The own in the foreign : Reliable surprise – An important function of the Media ? ” , Media , Culture and Society 29. pp . 344–353 , 2007 . 381 Helberger ( 2011a ) at p. 462 . 382 Hoffman et al . ( 2015 ) argue that in order to experience diversity onlin e , users must strive for diversity , be aware of the preconditions of diversity , and be able to ensure access to diversity . 383 Hansen P. G. and Jespersen A. M. “ Nudge and the manipulatio n of choice : A framework for the responsible use of the nudge approach t o behaviour change in public policy ” , European Journal of Risk Regulation 1 , pp . 3– 28 , 2013 , at p. 24 . For a fully -fledged analysis with regard to exposure diversity , see Helberger N. , Karppinen K. , and D ’ Acunto L. , “ Exposure diversity as a design principl e for recommender systems ” , Information , Communication and Society , 2017 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 83 Overall , there may be room to contemplate mechanisms that act as “ good aggregators “ and promote the visibility , av ailability and consumption of high quality and trusted local , national and regional content across various platf orms . In the age of AI , it can be assumed that designing such smart editors is doable . The question of balancing between the virtue of the inter vention and its possible side -effects intrinsic to such paternalistic actions remains and should be tackled care fully.384 4.4 . Concluding remarks It is evident that the media landscape has changed profoundly and is still in a state of flux . One discrete change t hat has been truly disruptive for media production , distribution and consumption lies in media ’ s editorial func tions . Digital platforms , such as Facebook and Google , have assumed , although to a different extent , key functions in content mediation and have so started to play a vital role in the realisation of critical public objectives , including in the cultural dom ain . As they impact on the availability of and access to local , national and regional content , these intermediaries may also impinge on the form and content of cultural exchanges , on democratic participation and civic engagement . In the last few years , awa reness has risen as to the risks of algorithmic filtering and tailored media diets that may be severely restricted and/or commercialised . Labels such as “ filter bubbles “ or “ echo chambers “ have captured the attention of scholars and policy -makers alike . Th e jury is still out , however , on the real effects of the mediation through digital platforms and the causal link between types of media exposure and cultural , political and social engagement . This seems to be the case even with more straightforwardly “ bad “ content , such as “ fake news ” . In this sense , two take -aways for policy makers may be highlighted : ( 1 ) we need more data and independent research on the availability of different types of content , the consumption and engagement with that content , the particip ants involved in this process and the impact of these processes on individual and collective democratic and cultural performances ; ( 2 ) it is importa nt to continue the dialogue between content creators , intermediaries , users , advertisers , and other stakeholder s involved in the dynamics of the media space and underline the critical importance of culturally diverse media consumption in this dialogue . The heightened value attached to the availability of culturally diverse choices , the stress on trustworthiness and quality that users understand and appreciate , may very well incentivise platforms to deliver such options . There are indeed already steps in thi s direction – for instance , with regard to flagging or removing certain types of content or certain users , or w ith regard to more transparency as to the sources of content . 384 Helberger N. , “ Merely facilitating or actively stimulating diverse media choices ? Public service media at the crossroad ” , International Journal of Communication 9. pp . 1324 –1340 , 2015 ; Bodo B. et al . “ Tackling the algorithmic control crisis − The technical , legal and ethical challenges of research into algorithmic agents ” , Yale Journal of Law and Technology 19. pp . 133−180 , 2017 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 84 Some form of additional action may still be needed . We sketch two possible avenues that may shape media consumption − governing of and through algorithms . As for the latter , one may consider so me “ good aggregators ” that promote the visibility , availability and consumption of high quality and trusted local , national and regional content . While this may sound interventionist and like possible interference with user autonomy and free speech , as wel l as the freedom of platforms to conduct business , there may be ways to have a diversity -sensitive design that is not at odds with autonomous cho ices but indeed empowers users to make better informed choices . Technology is likely to permit many variations on the theme and policy -makers may need to keep an open mind here , and may experiment with public service media as curators of media experiences . Caution is still required and the pursuit of diversity objectives may not necessarily fit into the practical design of all recommender systems – in the case of search engines like Google for instance , where users actively search for answers , there may be a trade -off between accuracy and diversity.385 With regard to addressing the role of the intermediaries themsel ves and alleviating the risks of tailored and potentially distorted media consumption , there may be a need to act in the public interest . Yet , we can not plainly blame the platform or the recommendation system and target all measures at them . As Helberger ( 2017 ) at al . note users also “ play a role in the realization or erosion of public values on these platforms ” .386 Indeed , we have a “ problem of many hands ” and there is a corresponding need to conceptualise a framework with the participation of , and differen t responsibilities for , all stakeholders – platforms , users , civil society and governments.387 Multi -stakeholder mechanisms derived from Internet gov ernance can be used as a model.388 The experience gathered recently in the domain of tackling online disinfor mation in Europe can provide particularly helpful insights . The realisation of diverse content availability and informed and empowered user choices a s core public values in the media space should be then the result of a dynamic interaction and deliberation between the stakeholders and may result in a palette of measures , such as codes of conduct , guidelines and principles , supervisory bodies of governm ental or non -governmental character that ensure continuous and effective dialogue , or certain technological fixes.389 385 Adomavicius G. and Kwon Y. , “ Maximizing aggregate recommendation diversity : A graph-theoretic approach ” , Proceedings of the 1st International Workshop on Novelty and Diversity in Recommender Systems . DiveRS 2011 . Chicago , 2011 . 386 Helberger N. , Pierson J. and Poell T. , “ Governing online platforms : From contested to cooperative responsibility ” , The Information Society , 2017 , a t p. 2 . 387 Ibid . 388 See e.g . Marda V. and Milan S. , “ Wisdom of the crowd : Multistakeholder perspective on the fake news debate ” , A Report by the Internet Policy Observatory at the Annenbe rg School , University of Pennsylvania , 21 May 2018 . 389 Helberger et al . ( 2017 ) . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 85 Copyright One of the biggest fears raised by AI is the replacement of humans by machines . People are increasingly worried that they will lose their jobs to robots , and this uneasiness has reached the audiovisual sector too . There are more and more examples of the creative intervention of AI in scriptwriting and music composition , just to name two aspects . This technobarbaric invasion i nto the creative realm is still of relatively low import , though , so that the fears of the destruction of creative jobs are most probably unwarranted , at least for the time being . And yet , the issue of the copyrightability of works made by machines has tak en academia by storm . The question is quite pertinent : if we agree that machines can “ create “ works , c an the creating machine be a copyright holder ? Or can a person or a company be the copyright holder of a work created by a machine ? The overview provided by Giancarlo Frosio in his contribution to this publication answers a set of emerging legal questions concerning AI and creativity . AI can also be used against the enemies of creativity to find and remove copyright -infringing material on the Internet and h unt down pirates and industry leaks . However , depending on how algorithms are programmed , there is alw ays the risk of false positives , which can have an impact on the freedom of expression of Internet users . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 87 5 . Copyright - Is the machine an author ? Gianc arlo Frosio , Center for International Intellectual Property Studies ( CEIPI ) , University of Strasbourg  5.1 . Introduction It is claimed that artificial intelligence ( AI ) is a fundamentally disruptive revolution for humankind.390 Intelligent machines are co ming in multiple shapes to serve diverse purposes , replacing humans potentially everywhere391 with , predictably , both positive and negative externalities.392 Apparently , AI shows potential for replacing even those activities that are more inherently human . A lthough s o far most creatives still do not fear being replaced by robots,393 actually , a major field where AI appears to be increasingly proficient is creativity . AI writes poems , novels and news articles , composes music , edits photographs , creates video ga mes , and p roduces paintings and other artworks . Most creative industries will be substantially affected,394 from the audiovisual sector395 to music396 and publishing.397 The time of the A ( I ) uthor has already come . Associate professor , Center for International Intellectua l Property Studies ( CEIPI ) , University of Strasbourg ; non-resident fellow , Stanford Law School Center for Internet and Society ; faculty associate , NEXA Center for Internet and Society . I wish to thank my research assistant , Varnita Singh , for in-depth rese arch and remarkable , critical assistance given in preparing this chapter . 390 Floridi L. , The Forth Revolution : How the I nfosphere is Reshaping Human Reality , OUP , Oxford . Bughin J. et al . ( 2017 ) , Artificial Intelligence : The Next Digital Frontier ? , McKinsey Global Institute Discussion Paper , www.mckinsey.com/~/media/mckinsey/industries/advanced % 20electronics/our % 20insights/how % 20artificial % 20i ntelligence % 20can % 20deliver % 20real % 20value % 20to % 20companies/mgi -artificial -intelligence discussion -paper.ashx . Elsevier , Artificial Intelligence : How knowledge is created , transferred , and used - Trends in China , Europe , and the United States , www.elsevier.com/research -intelligence/resource -library/ai -report . Méni ère Y. , Rudyk I. and Valdes J. , Patents and the Fourth Industrial Revolution : The Inventions behind Digital Transformation , Munich , DE : European Patent Office . 391 ITU , “ Assessing the Economic Impact of Artificial Intelligence ” , Issue P aper No.1 , International Telecommunications Union , Geneva , pp . 12 -15 , www.itu.int/dms_pub/itu -s/opb/gen/S -GEN-ISSUEPAPER -2018 -1-PDF-E.pdf . Pricewaterhouse Coopers ( P wC ) , Sizing the prize : PwC ’ s Global Artificial Intelligence Study : Exploiting the AI Revolution , PwC , www.pwc.com/gx/en/issues/data -and-analytics/publications/artificial -intelligence -study.html . 392 ITU , op.cit . , pp . 17-20 . 393 Pfeiffer A. , Pfeiffer Report : Creativity and technology in the in age of AI , pp . 15 , 29 , https : //www.pfeifferreport.com/wp -content/uploads/2018/10/Creativity -and-technology -in-the-age-of-AI.pdf . 394 New European Media ( 2019 ) , AI in media and creative industries , https : //arxiv.org/ftp/arxiv/papers/1905/1905.04175.pdf . Pfeiffer A. , op.cit . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 88 In this context , the adaptation of the Intelle ctual Property ( IP ) system to AI generated creativity and innovation ( and the challenges that it brings about ) is increasingly becoming a topic of critical interest.398 A substantive corpus of literature dedicated to AI and IP is emerging.399 Of course , exis ting IP regimes , including copyright law , trade secrets and patent law400 can protect software on which AI technology is based.401 However , the protection afforded to the software does not extend to the output possibly generated by the AI . Whether this protection is available is actually still an open question , based on the construction of the present copyright framework . A distincti on should also be made between computer -assisted creativity , which is copyrightable as long as the user contribution is original , and computer -generated creativity proper , where a user 's interaction with a computer prompts it to generate its own expression .402 A report from the European Commission clearly presents the terms of this emerging quagmire : Protection of AI -generated works [ … ] seems to be [ … ] problematic . In light of the humanist approach of copyright law , it is questionable that AI -generated works deserve copyright protection . [ … ] While some copyright scholars clearly advocate for AI -generated works to be placed in the public domain , others have put forward a series of proposals aimed at 395 Artificial Intelligenc e in the audiovisual industry , Summary of the E AO workshop , Strasbourg , 17 December 2019 , European Audiovisual Observatory , Strasbourg , 2019 , https : //rm.coe.int/summary -workshop -2019 -bat2/16809c992a . See also Baujard T. , Tereszk iewicz R. , de Swarte A. , Tuovinen T. , “ Entering the new paradigm of artificial intelligence and series ” , study commissioned by the Council of Europe and Eurimages , December 2019 , https : //rm.coe.int/eurimages -entering -the-new-paradigm -051219/1680995331 . 396 Strum B. et al. , “ Artificial Intelligence and Music : Open Questions of Copyright Law and Engineering Praxis ” , Arts 8 , pp . 115 -129 . BPI , Music ’ s smart future : How will AI Impact the Music Industry , www.musictank.co.uk/wp -content/uploads/2018/03/bpi -ai-report.pdf . 397 Lovrinovic C. and Vol land H. , The future impact of artificial i ntelligence on the publishing industry , Gould Finch and Frankfurter Buchmesse , available at https : //bluesyemre.files . wordpress.com/2019/11/the -future -impact of-artificial -intelligence -on-the-publishing -industry.pdf . 398 Cubert J.A . and Bone R.G.A . , “ The law of intellectual property created by artificial intelligence ” in Barfield W . and Pagallo U . ( eds ) , Research Handbook on the Law of Artificial Intelligence , Edward Elgar , Cheltenham , pp . 411-427 . OECD , Artificial Intelligence in Society , OECD Publishing , Paris , p. 104 -105 , https : / /doi.org/10.1787/eedfee77 -en . WIPO ( 2019a ) , Draft Issues Paper on Intellectual Property Policy and Artificial Intelligence , WIPO , Geneva , https : //www.wipo.int/meetings/en/doc_de tails.jsp ? doc_id=470053 . WIPO ( 2019b ) , WIPO Technology Trends 2019 - Artificial Intelligence , WIPO , Geneva , https : //www.wipo.int/edocs/pubdocs/en/wipo_pub_1055.pdf . 399 Iglesias M. , Sh amuilia S. and Anderberg A. , Intellectua l Property and Artificial Intelligence : A Literature Review , Publications Office of the European Union , Luxembourg , https : //publications.jrc.ec.europa.eu/repository/bitstream/JRC119102/intellectual_property_and_artif icial_intell igence_jrc_template_final.pdf . 400 Whether protecting software as a computer -implemente d invention or as such , depending on the jurisdiction . 401 Calvin N. and Leung J. , “ Who owns artificial intelligence ? A preliminary analysis of corporate intell ectual property strategies and why they matter ” , Future of Humanity Institute , University of Oxfor d , https : //www.fhi.ox.ac.uk/wp -content/uploads/Patents_ -FHI-Working -Paper -Final -.pdf . 402 Payer Components South Africa Ltd v Bovic Gaskins [ 1995 ] 33 IPR 407 . Clark R. and Smyth S. , Intellectual Property Law in Ireland , Butterworths , Dublin . Denicola R. , “ Ex Machina : Copyright Protection for Computer Generated Work s ” , Rutgers University Law Review 69 , pp . 269 -270 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 89 ensuring a certain level of protection . With notable exceptio ns , these proposals [ … ] do not always sufficiently detail the possible elements underpinning such protection.403 In this very regard , this chapter i s meant to answer a set of emerging legal questions within the AI -generated creativity conundrum . How does A I-generated creativity fit with traditional copyright theory and existing doctrines ? In particular , which are the conditions for protection of creat ions generated by AI and deep neural networks under the main copyright regimes ? Should legal personhood for AI be considered ? Is AI an author according to traditional copyright standards ? Can a machine be original ? These questions —which are only a portion of the relevant questions related to AI -generated creativity — can be summarised in the single question of whether AI can be an A ( I ) uthor . Additionally , there are two other fundamental questions beyond the scope of this review , relating to the ( Machine ) L earner and the ( A ) Infringer . They refer to whether an AI can infringe copyright through the machine learning process and training that enables the AI to generate creativity and whether an AI can infringe copyright by creating an infringing output . In addit ion to genuine challenges related to standards for AI authorship , this chapter will finally consider the roa d ahead by reviewing policy options from different theoretical perspectives , such as personality theories and utilitarian/incentive theories of intellectual property . 5.2 . Technology The first book ever written by a computer was The Policeman ’ s Beard is Half Constructed : Computer Prose and Poetry by Racter .404 It was 1984 and Racter ’ s prose was still rather obscure and unpolished . Since then , things have be en changing . The quality of AI generated creativity has improved dramatically , to the extent that a novel written by a machine made the first rounds of a literary competition in Japan , beating in the process thousands of human authors,405 and Sunspring , a sc i-fi film written entirely by an AI , placed top 10 in the Sci -Fi London annual film festival.406 AIVA — as well as Amper or Melodrive — runs an AI that composes music , which is marketed to accompany audiovisual works , advertisements or video games.407 The Z -Machines , a Japanese robot ba nd , perform music changing the pace of their performance according to actions taken by their audience as well as people who access their website,408 while Sony ’ s Flow Machine can interact and 403 Craglia M. , Artificial Intelligence : A Europe an Perspective , Publications Office of the European Union , Luxembourg , pp . 67 -68 . 404 Racter , The Policeman 's Beard is Half Constructed : Computer Prose and Poetry by Racter - The First Book Ever Written by a Computer , Warner Books , New York . 405 Lewis D. , An AI-Written Novella Almost Won a Literary Prize , Smithsonian Magazine , Washington , https : //www.smithsonianmag.com/smart -news/ai -written -novella -almost -won-literary -prize -180958577 . 406 Craig C. and Kerr I. , “ The Death of the AI Author ” , Osgoode Legal Studies Research Paper , pp . 1 -2 . 407 AIVA , https : //www.aiva.ai . 408 Bakare L. , Meet Z -Machines , Squarepusher 's new ro bot band , The Guardian , https : //www.theguardian.com/music/2014/apr/04/squarepusher -z-machines -music -for-robots . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 90 co-improvise with a human music perform er.409 Visual art , however , appears to be the creative field where AI performs best . An AI -generated “ Portrait of Edmond de Belamy ” was sold at Christie ’ s for an astounding USD 432 500.410 Due to massive data availability , enhanced computational resources and novel deep -learning -based architectures , AI has experienced major breakthroughs over the past decade.411 Tightly connected to these advancements , a fundamental development of AI generated creativity has been caused by the advent of the Generative Adversarial Network ( GAN ) .412 This is quite a recent development . In June 2014 , Ian Goodfellow published a paper entitled “ Generative Adversarial Networks ” , and posted the code on GitHub under a BSD licence.413 The paper describes a generative process that uses an advers arial model for machi ne learning . In this scenario , two neural networks compete against each other in a game . Given a training set , this technique learns to generate new data with the same statistics as the training set . This became a wildly popular method for training AI with large datasets . The technology further evolved into Creative Adversarial Network ( CAN ) systems , which build over GANs and “ generate art by looking at art and learning about style ; and become creative by increasing the arousal potentia l of the generated ar t by deviating from the learned styles ” .414 GANs and CANs were deployed by the Paris -based Obvious arts collective to generate the “ Portrait of Edmond de Belamy ” and a series of generative images called “ La Famille de Belamy ” .415 Like Goog le ’ s Deep Mind , whi ch generates and performs music or creates artworks , AI does so by listening to other music or analysing previous artworks online . Pindar Van Arman has been teaching an AI how to be creative for some time now . The project , called cloudpa inter.com , provides an exemplification of the similarities between human and machine learning processes in order to create art.416 Apparently , an AI would learn how to generate creativity through a multiple -step learning process , starting from technical exercises , such as com pleting connecting -dots images , to move later to experimentation , imitation and , finally , independent creation . 409 Deltorn J.M . and Macrez F. ( 2018 ) , “ Au thorship in the Age of Mac hine Learning and Artificial Intelligence ” , Center for International Intellectual Property Studies Research Paper No . 2018 -10 , 22-23 , https : //papers.ssrn . com/sol3/papers.cfm ? abstr act_id=3261329 . 410 Craig C. and Kerr I. , op.cit . , 3-4 . 411 Goodfellow I . , Bengio Y. and Courville A. , Deep Learning , MIT Press , Cambridge . 412 Svedman M. , “ Artificial Creativity : A case against copyright for AI -created visual work ” , IP Theory 9 ( 1 ) , pp . 3-4 . 413 Goodfellow I. et al. , “ Generative Adversarial Networks ” , arXiv , https : //arxiv.org/abs/1406.2661 . 414 Elgammal A. et al. , “ CAN : Creative Adversarial Networks Generating “ Art ” by Learn ing About Styles and Deviating from Style Norms ” , pp . 1 -22 , https : //arxiv.org/abs/1706.07068 . 415 Obvious AI & Art . Available at https : //obvious -art.com . 416 Cloud Paint er . Available at https : //www.cloudpainter.com . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 91 5.3 . Protection : Can AI -generated creativity be protected ? AI is transforming the way we create , and is impacting long -established copyright concepts and doctrines . In particular , genuine issues have been arising regarding the protectability of AI -generated creativity under the current copyright regime . This question can be answered by looking into three major conditions for protectio n and ownership of copyright works : ( 1 ) legal personality ; ( 2 ) authorship ; ( 3 ) originality . 5.3.1 . Personality : Can a machine be a legal person ? A first relevant question would be whether machines can enjoy legal personality . Depending on the jurisdiction , cultu ral and religious belief and legal subjectivity , establishing the personality of machines may become a policy option . Japan always had a special relationship with robots and machines due to the Shinto beliefs that animal or human -like robots can be imagine d to have a soul.417 In October 2017 , Sophia became the first robot to be granted citizenship by the Saudi Arabian government . The move was obviously a PR stunt . Nonetheless , it is an historical step into a possible assimilation of AI and humankind . Actually , one months late r , in November 2017 , Tokyo granted a chatbot official residence status in the Shibuya ward.418 The idea of legal personality of intelligent machines has been also supported by theoretical thinking . Nick Bostrom , for example , notes : `` Machines capable of inde pendent initiative and of making their own plans … are perhaps more appropriately viewed as persons than machines ” .419 Authors have highlighted how there are no legal reasons or conceptual motives for denying the personhood of AI robots : the law should be e ntitled to grant personality on the grounds of rational choices and empirical evidence , rather than superstition and privileges.420 Therefore , arguments have been made in favour of granting personhood to future hypothetical strong AIs that are autonomous ( c apable of making a decision without input action ) , intelligent ( capable of self -programming and integrating information in a framework ) and possess consciousness ( capable of subjective experience ) .421 More strikingly , the European Parliament is considering the possibility of declaring AI and robots “ electronic persons “ . In a resolution on civil law rules on robotics , the 417 Holland -Minkley D. , God in the Machine : Perceptions and Portrayals of Mechanical Kami in Japanese Anime , Master 's Thesis , University of Pittsburgh . 418 Cuthbertson , Tokyo : Artificial Intelligence 'Boy ' Shibuya Mirai Becomes World 's First AI Bot to Be Granted Residency , Newsweek , Washington , https : //www.newsweek.c om/tokyo -residency -artificial -intelligence -boyshibuya -mirai -702382 . 419 Bostrom N. , Superintelligence : Paths , Dangers , Strategies , OUP , Oxford . 420 Solum L.B . , “ Legal Personhood for Artificial Intelligences ” , North Carolina Law Review 70 , p . 1264 . 421 Zimmerm an E. , “ M achine Minds : Frontiers in Legal Personhood ” , pp . 14 -21 , https : //papers.ssrn.com/sol3/papers.cfm ? abstract_id=2563965 . See also Hubbard F.P. , “ Do Androids Dream ? Personhood and Intelligent Artifacts ” , Temple law Review 83 , pp . 406 -474 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 92 European Parliament wonders whether the ordinary rules on liability are sufficient or whether AI calls for new principles and rules.422 Should the autonomous nature of robots be construed in the light of the existing legal categories or should a new category be created ? 423 The resolution claims that “ the more autonomous robots a re , the less they can be considered simple tools in the hands of other actors ( such as the manufacturer , the owner , the user , etc . ) ” 424 It is apparent to the European Parliament that EU legislation can not fully address non -contractual liability for damages caused by autonomous AI . Traditional rules would still ap ply if the cause of the robot ’ s act or omission can be traced back to a specific human agent such as the manufacturer , the operator , the owner or the user . Again , traditional liability rules still ap ply if the robot has malfunctioned or if the human agent could have foreseen and avoided the robot ’ s harmful behaviour . But what if the cause of the robot ’ s act or omission can not be traced back to a specific human agent ? What if there are no manufacturing defects ? And the AI has not malfunctioned ? And the injured person is unable to prove the actual damage , or the defect in the product or the causal relationship between damage and defect ? What if , in fact , the AI has caused damages because it has actually acted autonomously according to its own programming and p urpose ? In this scenario , Directive 85/374/EEC on Product Liability should not apply . The resolution highlights that this makes the ordinary rules on liability insufficient and calls for new rules to clarify whether a machine can be held responsible for it s acts or omissions.425 Although the resolution recognises that “ at least at the present stage the responsibility must lie with a human and not a robot ” , in the long run the it calls for : ( 1 ) an oblig atory insurance scheme which takes into account all potent ial responsibilities in the chain ; 426 ( 2 ) the creation of a specific legal status for robots , “ so that at least the most sophisticated autonomous robots could be established as having the status of e lectronic persons responsible for making good any damage th ey may cause ” .427 The notion of an AI legal personality has been emerging in multiple discussions but so far the debate has been dominated by inconsistent , tinkering attempts at regulating a technol ogy whose development is wholly unpredictable . Therefore , as has often happened , the discourse about granting legal personhood becomes a political issue with no rational basis . In this respect , Saudi Arabia granting citizenship to Sophia is redolent of the Roman emperor Caligula making his horse , Incitatus , a senat or.428 422 Cf . Vladeck D. , “ Machines without Principals : Liability Rules and Artificial Intelligence ” , Washington Law Review 89 , pp . 117 -150 . 423 European Parliament ( 2017 ) , Civil Law Rules on Robotics : European Parliament resolution of 16 February 2017 with recommendations to the Commission on Civil Law Rules on Robotics , 2015/2103 ( INL ) , 16 February 2017 , https : //www.euro parl.europa.eu/doceo/document/TA -8-2017 -0051_EN.pdf . 424 European Parliament ( 2017 ) , op.cit . 425 European Parliament ( 2017 ) , op.cit . See also European Commission , “ Liability for Artificial Intelligence and other Emerging Technologies : Report from the Expert Group on Liability and New Technologies – New Technologies Formation ” , European Union , Brussels , https : //ec.europa.eu/transparency/regexpert/in dex.cfm ? do=groupDetail.groupMeetingDoc & docid=36608 . 426 European Parliament ( 2017 ) , op.cit . 427 Europe an Parliament ( 2017 ) , op.cit . 428 Pagallo U. , “ Vital , Sophia , and Co. —The Quest for the Legal Personhood of Robots ” , Information 9 ( 9 ) , pp . 239-240 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 93 Whether quasi -human or hyper -human AI will be coming , legal personality of machines is certainly unavailable under the present legal framework . Most likely it will be unavailable for the fo reseeable future . Scholarship has been consistently stressing how any hypothesis of granting AI robots full legal personhood has to be discarded until fundamental technological changes may occur.429 Pagallo highlights , among the normative arguments against legal personhood , the “ missing something problem ” , according t o which current AI robots lack most requisites that usually are associated with granting someone , or something , legal personhood : such artificial agents are not self -conscious , they do not posse ss human -like intentions , nor properly suffer.430 Statistical an alysis of different conditions for legal personhood set up by US case law , for example , would also show incompatibility between legal personhood and AI entities.431 This empirical analysis prove s that , to grant personhood , courts look at whether it is being granted directly or indirectly by a statute , if the artificial entity can sue and be sued , and finally if the entity is an aggregate of natural persons.432 These considerations serve also to se t apart AI from corporations that are treated as a legal person . Unlike corporations , AI entities are neither “ fictional ” entities nor associations of natural persons.433 Legal persons are formed by natural persons , who can ultimately exploit rights . In add ition , although legal persons can own a copyright , that copyright originated from a work created by a natural person , who is the author of the work , which then fulfils both the requirements of authorship and originality . This would not be the case with an AI and an AI -generated work , as to be discussed in the next pages . These arguments against AI ’ s legal personality may have already been internalised by policy -makers , as the European Parliament ’ s 2017 resolution could prove by excluding any form of AI lega l personality at least in the short and mid -term . In addition , the European Parliament appears now to exclude AI ’ s legal personality in specific connection to AI -generated creativity . In a recent “ Draft report on intellectual property rights for the develo pment of artificial intelligence technologies ” , the European Parli ament noted , as part of a motion for a parliament resolution , that “ the autonomisation of the creative process raises issues relating to the ownership of IPRs [ but ] considers , in this connec tion , that it would not be appropriate to seek to impart legal per sonality to AI technologies ” .434 Rather than establishing the legal personality of machines , the policy challenge would be 429 Banteka N. , “ Artificially Intelligent Persons ” , Houston Law Review 58 ( forthcoming ) , https : //papers.ssrn.com/sol3/papers.cfm ? abstract_id=3552269 . Mik E. , “ AI as Legal Person ? ” in Hilty R. and Liu K-C. ( eds ) , Artificial Intelligence and Intellectual Property , Oxford University Press , Eng land , forthcoming . Pagallo U. , op.cit . , pp . 230-240 . 430 Pagallo U. , op.cit . , pp . 237-238 . 431 Banteka N. , op . cit . 432 Banteka N. , op . cit . , p. 50 -52 . 433 Banteka N. , op . cit . , p. 19 . 434 European Parliament ( 2020 ) , Draft Report on intellectual property rights for the development of artificial intelligence technologies , 2020/2015 ( INI ) , 24 April 2020 , https : //europarl.europa.eu/doceo/document/JURI -PR-650527_EN.html . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 94 to properly allocate accountability and liability for the activities of AI robots in cases of complex distributed responsibility , for e xample through contracts and business law.435 5.3.2 . Authorship : Can a machine be an author ? Although , absent legal personality , AI can not be vested with authorship or standing for enforcing rig hts on creativity that it might generate , it still remains relevant to consider whether that creativity is protectable under the present legal framework . Answering the broader question of whether AI -generated creativity is protectable under copyright law implies consideration of whether AI can be construed as an author acc ording to traditional copyright standards . This boils down to whether the existence of a human being is an intrinsic requirement for authorship . Can an author be a machine or does it need to be human ? There is actually no definition in international treati es that can provide a definitive answer . However , it appears that textual reference to human creation in the Berne Convention436 may exclude the possibility of construing AI as an author . F or one thing , the term of “ protection ” , linked to the life of the aut hor , appears to rule out machines as authors ( Berne Convention , Art . 7 ) . Again , reference to the nationality —or residence —of the author seems to imply that the notion of authorship only a pplies to human agents ( Berne Convention , Art . 3 ) . Overall , it has be en argued that “ Berne ’ s humanist cast ” and its deference to idealist personality theories strongly support a “ human -centred notion of authorship presently enshrined in the Berne Conventio n ” that would exclude non -human authorship from Berne ’ s scope.437 5.3.2.1 . The E uropean Union A close review of EU law would most likely lead to similar conclusions.438 Although there is no transversal definition in statutory law of the notion of authorship , an autho r is defined as a natural person , a group of persons or a legal person both by Art . 2 ( 1 ) of the 435 Europe an Parliament ( 2017 ) , op.cit . Pagallo U. , op.cit . , pp . 239-240 . 436 Berne Convention for the Protection of Literary and Artistic Works ( as amended on September 28 , 1979 ) , https : //wipolex.wipo.int/en/treaties/textdetails/12214 . 437 Ginsburg J. , “ People Not Machines : Authorship and What It Means in the Berne Convention ” , International Review of Intellectu al Property and Competition Law 49 , pp.131 -135 . See also Aplin T. and Pasqualetto G. , “ Artificial Intelligence and Copyright Protection ” , §5.04 , in Ballardini R. , Kuoppamäki P. and Pitkänen O. ( eds . ) , Regulating Industrial Internet Through IPR , Data Protect ion and Competition Law , Kluwer , Alphen aan den Rijn . Ricketson S. , “ The Need for Human Authorship - Australian Developments : Telstra Corp Ltd v Phone Directories Co Pty Ltd ( Case Comme nt ) ” , E.I.P.R . 34 ( 1 ) , p. 34 . Ricketson S. ( 1991 ) , “ People or machines ? The Berne Convention and the changing concept of authorship ” , Columbia VLA Journal of Law & the Arts 16 , p . 34 . 438 Deltorn J.M . ( 2017 ) , “ Deep Creations : Intellectual Property and the Automata ” , Frontiers in Digital Humanities , p. 8 , https : //www.frontiersin.org/articles/10.3389/fdigh.2017.00003/full . Deltorn J.M . and Macrez F. ( 2018 ) , op.cit . , p. 8 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 95 Software Directive439 and Art . 4 ( 1 ) of the Database Directive440 . In addition , Art . 2 ( 1 ) of the Term Directive441 provides that the principal director of a cinematographic and audiovisual work shall be considered its author or one of its authors . Actually , the travaux préparatoires of the Software and of the Database Directives were more straightforward in endorsing an anthropocentric vision of authorship by referring specifically to “ the human author who creates the work ” and “ the natura l person [ who ] will retain at least the unalienable rights to claim paternity of his work ” .442 The original proposal for a Software Directive concluded : “ [ t ] he human input as regards the creation of machine -generated programmes may be relatively modest , and will be increasingly modest in the future . Nevertheless , a human ‘ author ’ in the widest sense is always present , and must have the right to claim ‘ authorship ’ of the program ” .443 In the Court of Justice of the European Union ( CJEU ) Painer case , Advocate Gene ral Verica Trstenjak stressed the same point by noting that “ only human creations are therefore protected , which can also include those for which the person employs a technical aid , such as a camera ” .444 National legislation of EU member states confirms this approach . For example , Art . L.111 -1 of the French Intellectual Property Code445 requires copyrightable work to be the “ creation of the mind ” . Art . 5 of the Spanish Copyright Act plainly states that “ the author of a work is the natural person who creates it ” .446 And , although Art . 7 of the German Copyright Act does not specifically limit authorship to natural persons , Art . 11 attaches authorship to a personality approach by protecting “ the author in his intellectual and personal relationships to the work ” .447 In addition , EU law — as well as multiple national legislations ( e.g . Dutch Copyright Act , Art . 4 ( 1 ) ; French IP Code , Art . L113 -1 ; Spanish Copyright Law , Art 6.1 ; Italian Copyright Law , Art . 8 ) 448 — endorses a human -centric approach when providing a 439 Directive 2009/24/EC of the European Parliament and of the Council of 23 Apr il 2009 on the legal protection of computer programs , O.J . L111/16 . 440 Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases , O.J . L077/20 . 441 Directive 2006/116/EC of the E uropean Parliament an d of the Council of 12 December 2006 on the term of protection of copyright and certain related rights , O.J . L372/12 . 442 Ramalho A. , “ Will Robots Rule the ( Artistic ) World ? A Proposed Model for the Legal Status of Creations by Artificia l Intelligence System s ” , Journal of Internet Law 21 , pp . 17-18 . 443 European Commission , Explanatory Memorandum to the proposal for a Software Directive , COM ( 88 ) 816 final , 17 March 1989 , p. 21 . 444 Opinion of the AG Trstenjak ( 12 April 2011 ) , C-145/10 Eva -Maria Painer v. Standar d VerlagsGmbH , ECLI : EU : C:2011:239 . 445 Code de la propriété intellectuelle [ Intellectual Property Code ] 1912 . Available at https : //www.wipo.int/edocs/lexdocs/laws/en/fr/fr467en.pdf ( France ) . 446 The Intellectual Property Act 1996 . Available at https : //www.wipo.int/edocs/lexdocs/laws/en/es/es177en.pdf ( Spain ) . 447 Urheberrechtsgesetz – UrhG ( Act on Copyright and Relat ed Rights ) 1965 . Available at https : //w ww.gesetze im-internet.de/englisch_urhg/englisch_urhg.html ( Germany ) . 448 Auteurswet ( Copyright Act ) 1912 . Available at https : //wetten.overheid.nl/BWBR0001886/2012 -01-01 ( Netherlands ) ; Code de la propriété intellectuelle [ Intellectual Property Code ] 1912 . Available at https : //www.wipo.int/edocs/lexdoc s/laws/en/fr/fr467en.pdf ( France ) ; The Intellectual Property Act 1996 . Available at https : //www.wipo.int/edocs/lexdocs/laws/en/es/es 177en.pdf ( Spain ) ; Law for the Protection of Copyright and Neighbouring Rights 1941 . Available at ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 96 presumption of authorship for the person whose name is indicated in the work , in the absence of proof to the contrary ( IP Enforc ement Directive , Art . 5 ) . Some national courts have even clarified that this presumption is only applicable to natural persons creating the work , and not to a legal person who might have obtained the economic rights .449 In theory , this presumption of author ship could apply to AI -generated works , so that the person/s whose name/s is/are indicated in the work is/are regarded as the author/s . Of course , this solution provides no actual protection against infringement , given that the presumption can be rebutted by proving that the person named is not the author , but an AI is . A brief overview of other major jurisdictions might lead to similar concl usions regarding the application of the notion of authorship to AI . 5.3.2.2 . Australia Australian law sets a quite clear stat utory bar for non -human authors by defining an author as a “ qualified person ” in Section 32 ( 1 ) of the Australian Copyright Act , who , Section 32 ( 4 ) in turn , defines as an Australian citizen or a person resident in Australia .450 Australian courts , then , link originality as a condition for protection of authorship . In Acohs v. Ucorp , involving subsistence of copyright in data sheets generated elect ronically , the court clarified that a work needs to “ spring from the original efforts of a single human author ” .451 The Phone Directories decision reinforces the point by noting that copyright “ only subsists if it originates from an individual ” .452 Finally , IceTV v. Nine Network Australia decided a case dealing with copyright for computer generation of weekly TV program schedules by concluding that only authors , thus persons according to the statutory definition , can be original.453 5.3.2.3 . United States The protection o f products of computational creativity is not novel in the United States . Scholars started discussing possible p rotectability of computer -generated creativity in the https : //www.wipo.int/edocs/lexdocs/laws/en/it/it211en.pdf ( Italy ) . 449 Herlitz PBS A G vs. Real ister OÜ , Estonian Supreme Court ( 7 February 2012 ) Case No . 3 -2-1-155-11 ( Estonia ) . See also Vasamae E. , “ Presumption of authorship : only natural persons ” , Kluwer Copyright Blog , Amsterdam , available at http : //copyrightblog.kluweriplaw.com/2012/03/19/presumption -of-authorship -only-natural persons/ ? doing_wp_cron=1594514535.1866068840026855468 750 . 450 Copyright Act 1968 . Available at https : //www.legislation.gov.au/Details/C2019C00042 ( Australia ) . 451 Acohs Pty Ltd v. Ucorp Pty Ltd ( 2010 ) 86 IPR 492 ( AUS ) . 452 Phone Directories Co Pty v Telstra Corporation Ltd ( 2010 ) 194 FCR 142 ( AUS ) . See also McCutcheon J. , “ The Vanishing Author in Computer -Generated Works : A Critical Analysis of Recent Australian Case Law ” , Melbourne University Law Review 36 ( 3 ) , pp . 9 41-969 , https : //www.researchgate.net/publication/289409001_The_vanishing_author_in_computer generated_works_A_critical_analy sis_of_recent_Australian_case_law . 453 IceTV Pty Ltd v. Nine Network Australia Pty Ltd [ 2009 ] HCA 14 , 239 CLR 458 ( AUS ) . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 97 late 1960s.454 The US Congress created a committee to determine whether computers or compute r programmes can be authors whose output can be copyrighted . In 1978 , the National Commission on New Technologi cal Uses of Copyrighted Works ( CONTU Commission ) noted that computers were mere “ inert tools of creation “ which were not yet independently creati ng works . The CONTU Commission did not discuss copyright protection of automated works devoid of human authorsh ip because it was considered too speculative at the time.455 In 1986 , the Congress Office of Technology Assessment ( OTA ) issued a report arguing th at although computers were more than “ inert tools of creation “ the copyrightability of computer -generated work s was undeterminable.456 The US Copyright Act does not have an express statutory definition of authorship , so that authors have initially argued tha t textually , the statute does not limit authorship to human authors.457 However , both additional textual refer ences and case law apparently exclude the possibility of construing non -human agents as authors under the statute . In particular , Section 101 of the Copyright Act458 defines anonymous works as the “ ones where no natural person is identified as an author ” , thus pointing at natural persons as potential authors . Also , there is a long -lasting understanding that the constitutional history of the word “ copyri ght “ would disp ose in favour only humans as “ authors “ .459 U.S. courts have consistently supported this understanding . The Supreme Court has plainly stated that “ [ a ] s a general rule , the author is [ … ] the person who translates an idea into a fixed , tangible e xpression entitled to copyright protection ” .460 In Feist v Rural , the U.S. Supreme Court discusses at length the notion of authorship and author by reviewing the notion of originality , which would refer to inh erently human features , such as “ creative spark ” or “ intellectual production , of thought , and conception ” .461 Earlier cases would support the same conclusion . The Trade -Mark Cases state that the copyright law only protects “ the fruits of intellectual labor ” that “ are founded in the creative powers of the 454 Milde K.F. , “ Can a Computer Be an “ Author ” or an “ Inventor ” ? ” , Journal of the Patent Office Society 51 , pp . 378-406 . 455 National Comm ission on New Technological Uses of Copyrighted Works ( CONTU ) , Final Report , United States , p .44 . See also Bridy A . ( 2012 ) , “ Coding Creativity : Copyright and the Artificially Intelligent Author ” , Stanford Technology Law Review 5 , 22 -24 , para 53 -60 . Miller A.R. , “ Copyright Protection for Computer Programs , Databases , and Computer Generated Works : Is Anything New Since CONTU ? ” , Harvard Law Review 977 , pp . 977-1072 . 456 US Office of Technology Assessment , Intellectual Property Rights in an Age of Electron ics an d Information , United States . 457 Bridy A . ( 2012 ) , op.cit. , 20 , para 49 . Denicola R. ( 2016 ) , op.cit . , p. 275 -283 . Miller A.R. , op.cit . , pp . 1042 -1072 ; Samuelson P. ( 1986 ) , “ Allocating Ownership Rights in Computer -Generated Works ” , University of Pittsbu rg Law Review 47 ( 4 ) , pp . 1200 -1204 . 458 The Copyright Act of 1976 . Available at https : //www.copyright.gov/title17/title17.pdf ( US ) . 459 Butler T. , “ Can a computer be an author ? Copyright aspects of artifi cial intelligence ” , ( Comm/Ent ) , A Journal of Communications and Entertainment Law 4 ( 4 ) , pp . 733 -734 . Clifford , R.D . ( 1996 ) , “ Intellectual Property in the Era of the Creative Computer Program : Will the True Creator Please Stand up ” , Tulane Law Review 71 , 1682-1686 . Kasap A. , “ Copyright and Creative Artificial Intelligence ( AI ) Systems : A Twenty -First Century Approach to Authorship of AI -Generated Works in the United States ” , Wake Forest Intellectual Property Law Journal 19 ( 4 ) , p. 3 58 , https : //papers.ssrn.com/sol3/papers.cfm ? abstract_id=3597792 . Milde K.F. , op.cit . , pp . 391392 . 460 Community for Creative Non -Violence v. Reid , 490 U.S. 730 ( 1989 ) . 461 Feist Publications v. Rural Telephone Service , 499 U.S. 340 ( 1991 ) ( USA ) . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 98 mind ” .462 In the Burrow -Giles case , the US Supreme Court recalled that copyright law is limited to “ original intellectual conceptions of the author ” .463 A recent case shed some further clarifications on the m atter . This time , Naruto , a macaque monkey , came to the rescue . In Naruto v. Slater , two “ monkey selfies “ that received worldwide recognition were the subject of a dispute about whether animals can own copyright . The self -portraits were taken by seven -year-old crested macaque “ Naruto “ when wildlife photogra pher David Slater left his camera unattended on one of his visits to Indonesia . Shortly thereafter , Wikimedia Commons published the pictures on its website under the assumption that the monkey selfies hav e no human author and therefore belong to the public domain . Wikimedia consistently refused to take down the pictures . Changing earlier stances advertising the selfies as entirely taken by the monkeys with no human intervention , Slater later claimed the se lfies were the result of his setting up the camera w ith the right angle , lighting , optimising settings and just luring the monkeys into pressing the camera button . Although the question of whether the selfies belong to the public domain was not ultimately reviewed , courts had the opportunity to consider wh ether Naruto could be vested with a copyright for its selfie . In 2014 , the monkey selfies were published in a book through Blurb Inc. which identified Slater and Wildlife Personalities Ltd as the copyrigh t owners . In 2015 , People for the Ethical Treatment of Animals ( PETA ) filed a complaint of copyright infringement as next friends and on behalf of Naruto against Slater , Wildlife Personalities Ltd and Blurb Inc. before the District Court , California . The D istrict Court granted the motion to dismiss filed by the defendants on the basis that Naruto failed to establish statutory standing under the Copyright Act and noted : “ If the humans purporting to act on Plaintiff ’ s behalf wish for copyright to be among the areas of law where nonhuman animals have standing , they should make that dubious case to Congress – not the federal courts. ” 464 The decision was appealed and while the parties agreed to a settlement , the Court of Appeals declined to dismiss the appeal and affirmed the lower court decision . The majority found that while animals have Art . III standing to sue , animals do not have statutory standing under the Copyright Act.465 The court relied on the Ninth Circuit decision in Cetacean Community . v. Bush , where i t was held that animals have statutory standing only i f the statute plainly states so.466 Moreover , the terms ‘ children ’ , ‘ grandchildren ’ , ‘ legitimate ’ , ‘ widow ’ , and ‘ widower ’ used in the statute necessarily imply that the Copyright Act excludes animals tha t “ do not marry and do not have heirs entitled to prope rty by law ” .467 The findings in the Naruto decision can easily be extended to any non-human and AI -generated creativity . Meanwhile , the “ Third Edition of the Compendium of U.S . Copyright Office Practice s ” , which was published in December 2014 after the Narut o case started , provided 462 Trade -Mark Cases , 100 U.S. 82 ( 1879 ) ( USA ) . 463 Burrow -Giles Lithographic Co. v. Sarony , 111 U.S. 53 ( 1884 ) ( USA ) . 464 Naruto v. David Slater , 15-cv-04324 -WHO ( N.D. Cal . 2016 ) ( USA ) ( “ Naruto 2016 ” ) . 465 Naruto v. David Slate r , F.3d 418 ( 9th Cir . 2018 ) ( USA ) ( “ Naruto 2018 ” ) . 466 Cetacean Community . v. Bush , 386 F.3d 1169 ( 9th Cir . 2004 ) ( USA ) . 467 Naruto v. David Slater , F.3d 418 ( 9th Cir . 2018 ) ( USA ) ( “ Naruto 2018 ” ) . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 99 a non -binding expert guidance that excluded non -human authorship.468 The compendium repeatedly refers to persons or human beings when discussing authorship . More specifically , under Section 306 , “ The Human Authorship Requirement ” lim its registration to “ original intellectual conceptions of the author ” created by a human being . As clarified under Section 313.2 , “ Works that Lack Human Authorship ” , works produced by nature , animal or plants and similarly , works created by a machine or by a mechanical process without intervention from a human author are not copyrightable . Making reference to the Trade -Mark Cases and Burrow -Giles , the Copyright Office concluded that it would refuse to register a claim if it determines that a human being did not create the work.469 5.3.2.4 . China In China , the questions of AI authorship and copyrightability of AI -generated works have been discussed by multiple courts . The Chinese position on AI authorship appears aligned with that of other jurisdictions , although it lea ves some room for potential protection . In Beijing Feilin Law Firm v Baidu Corporation , affirming the requirement of human authors , the court denied copyright protection to works created solely by m achines.470 The matter involved a report published by the pl aintiff — a Beijing -based law firm — on its official WeChat account . After an unidentifiable Internet user published the report online without permission , the plaintiff brought an infringement suit before the Beijing Internet Court . The report had been gen erated using Wolters Kluwer China Law & Reference —a legal information query software . While the plaintiff argued that the tool was used only for assistance , the defendants claimed that the entire report was generated by the software . The court agreed with the plaintiff . However , although the disputed report was found to be protected by Chinese copyright law , the court considered also the protectability of the report automatically generated by the s oftware . In discussing protection of works exclusively gene rated by an AI , the court held that the notion of authorship requires the work to be created by a natural person . The court , however , came up with some interesting incentive analysis which rejects the conclusion that the work should be freely available in the public domain . Thus , the court believed that some sort of protection should be given to the user — not the software developer already rewarded with copyright over the software — in order to inc entivise purchases of the software as well as generation an d distribution of the works . Unfortunately , the judgement does not clarify which form this protection should take . 468 U.S . Copyright Office , Compendium of U.S . Copyright Office Pr actices , 3rd edition , https : //www.copyright.gov/comp3/comp -index.html 469 U.S . Copyright Offic e , op.cit . , Section 313.2 . 470 Beijing Feilin Law Firm v Baidu Corporation ( 26 April 2019 ) Beijing I nternet Court , ( 2018 ) Beijing 0491 Minchu No . 239 . He K. ( 2020b ) , “ Feilin v. Baidu : Beijing Internet Court tackles protection of AI/software generated work and holds that copyright only vests in works by human authors ” , The IPKat , http : //ipkitten.blogspot.com/2019/11/feilin -v-baidu -beijing -internet -court.html . Chen M. , “ Beijing Internet Court denies copyright to works created solely by artificial intelligence ” , Journal of Intellectual Property Law & Practice 14 ( 8 ) , pp . 14 -18 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 100 In a later decision , Shenz hen Tencent v. Yinxun , the Nanshan District Court in Shenzhen basically confirmed the Beijing ruling.471 The two deci sions mirror each other insofar as the courts provided protection to the original contributions from human agents , rather than creativity exclusively AI -generated . The plaintiff Tencent Technology developed an AI writing assistant , Dreamwriter . In August 2 018 , the plaintiff published one of the AI -created works on its website , informing readers that the article had been written by Tencent ’ s AI Dreamwriter . The defendant allegedly published the arti cle on their website without the consent of the plaintiff . I n a suit for infringement , the plaintiff argued that as authors of the article , they have exclusive rights under copyright law . They claimed that the article was generated under their supervision and they were responsible for the organisation and creation of the article as well as any liability arising thereof . In favour of the plaintiff , the court ruled that the article met the requirements of being an original literary work , as the content was a product of the input data , trigger conditions and arrangemen t of templates and resources selected by an operational group of the plaintiff . Since the expression of the article came from individual choices and arrangements made by the plaintiff , the AI -gene rated article was considered a work of legal entities under Article 11 of the Copyright Law and the defendant was held liable for infringement . However , although the court might have viewed the work as an integrated intellectual creation , deriving both fro m the contribution by the human team and the operation of Dr eamwriter , the protectability granted apparently stems from the human team contribution , rather than any AI contribution . 5.3.3 . Originality : Can a machine be original ? Besides the construction of the n otion of authorship , also the notion of originality as a condition for copyright protection appears to preclude protection of AI -generated creativity . Textual references and case law construe originality through an anthropocentric model that emphasises sel f-consciousness . Originality is defined through a so-called personality approach that describes an original work as a representation of the personality of the author . The word ‘ author ’ itself bears this meaning on its face , as the most accredited etymology of the word would have it deriving from the ancient Greek αὐτός , which means ‘ self ’ .472 This characterisation of originality builds upon idealist personality theories , according to which intellectual products are manifestations or extensions of the persona lities of their creators.473 Therefore , originality as a 471 Shenzhen Tencent v. Yinxun , Nanshan District People 's Court of Shenzhen , Guangdong Province [ 2019 ] No . 14010 ( China ) , available at https : //mp.weixin.qq.com/s/jjv7aYT5wDBIdTVWXV6rdQ . He K. ( 2020a ) , “ Another decision on AI -generated work in China : Is it a Work of Legal Entities ? ” , The IPKat , http : //ipkitten.blogspot.com/2020/01/another -decision -on-ai-generated -work.html . 472 Frosio G. , Reconciling Copyright with Cumulative Creativity : The Third Paradig m , Edward Elgar , Cheltenham , p. 16 . 473 Fichte J. , Proof of the illegality of reprintin g : a rationale and a parable , Berlinische Monatsschrift 21 , p. 44 7 . Hegel G.H. , Philosophy of rights , Thomas Knox , Clarendon Press , Oxford , para . 69 . Kant I . ( 1785 ) , Von der Unrechtmäßigkeit des Büchernachdrucks [ On the injustice of counterfeitingbooks ] , B erlinische Monatsschrift 5 , ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 101 repre sentation of ‘ self ’ and self -consciousness would be , in theory , beyond the reach of machine -generated creativity . This construction of originality has been widely endorsed by the majority of juri sdictions . It has sidelined earlier approaches building upon Lockean fairness theories and endorsing “ sweat of the brow ” doctrines that rewarded “ skills , labour and efforts ” in creating intellectual work regardless of whether the work was representative of the personality of the author.474 In the European Union , three directives have vertically harmonised the notion of originality . According to Article 1 ( 3 ) of the Software Directive , Article 6 of the Term Directive , and Article 3 ( 1 ) of the Database Directive , a work is original if it is “ the author ’ s own intellectual c reation ” .475 Later , the CJEU ‘ horizontally ’ expanded originality to all copyright subject matters and further clarified the scope of the notion . In the Infopaq case , the CJEU noted that “ [ i ] t is only through the choice , sequence and combination of those word s that the author may express his creativity in an original manner and achieve a result that is an intellectual creation. ” 476 The Eva -Maria Painer decision further explained that a work — in that instance a portrait photograph — is original and can be protec ted , if it is : ( 1 ) an intellectual creation of the author ; ( 2 ) reflects their personality ; ( 3 ) expresses their free and cre ative choices in the production of that photograph.477 By making those various choices , the author of a portrait photograph can stamp t he work created with his ‘ personal touch ’ .478 Finally , in the Football Dataco case , the CJEU rejected any remaining “ sweat of the brow ” doctrines and noted that significant labour and skill of the author can not as such justify copyright protection , if that l abour and that skill do not express any originality in the selection or arrangement.479 Works produced merely based on tec hnical rules or constraints lack the creative freedom required for authorship . US jurisprudence has equally endorsed this personality ap proach to originality . Since early cases , such as Burrow -Giles v. Sarony , considering the copyrightability of a portrait photograph of Oscar Wilde , the U.S. Supreme Court has clarified that originality derives from the free creative choices of the author t hat imbue the work with his personality480 “ such as the final product duplicates his conceptions and visions ” of what the work should be.481 In particular , in the Burrow -Giles case , the court held photographs copyrightable because they could be traced from the photographer ’ s “ own original mental conception ” .482 Later , in Feist v. Rural , the U.S. Supreme Court clearly stated th at only pp . 403 –417 . See also Fisher W. , “ Theories of intellectual property ” , in Munzer S . ( ed . ) New essays in the legal and p olitical theory of property , Cambridge University Press , Cambridge , pp . 168 –200 . 474 See e.g . International News Service v. Associated Press , 248 U.S. 215 ( 1918 ) ( USA ) . Jeweler 's Circular Publishing Co. v. Keystone Publishing Co. , 281 F. 83 ( 2nd Cir . 1922 ) ( USA ) . See also Rahmatian A. , “ Originality in UK Copyright Law The Old ‘ ‘ Skill and Labour ’ ’ Doctrine Under Pres sure ” , IIC 44 , pp . 4 –34 . 475 For a discussion see Rosati E. , Originality in EU Copyright - Full Harmonization through Case Law , Edward Elgar , Cheltenham . 476 Infopaq International A/S v Danske Dagblades Forening , C-5/08 ( 2009 ) ECLI : EU : C:2009:465 . 477 Eva-Maria P ainer v Standard VerlagsGmbH and Others , C-145/10 ( 2011 ) ECLI : EU : C:2011:798 . 478 Eva-Maria Painer v Standard VerlagsGmbH and Others , C-145/10 ( 2011 ) ECLI : EU : C:2011:798 . 479 Football Dataco Ltd and Others v Yahoo ! UK Ltd and Others , C-604/10 ( 2012 ) ECLI : EU : C:20 12:115 . 480 Burrow -Giles Lithographic Co. v. Sarony , 111 U.S. 53 ( 1884 ) ( USA ) . 481 Lindsay v. The Wrecked and Abandoned Vessel R.M.S . Titanic , 52 U.S.P.Q.2d 1609 ( S.D.N.Y . 1999 ) ( USA ) . 482 Burrow -Giles Lithographic Co. v. Sarony , 111 U.S. 53 ( 1884 ) ( USA ) . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 102 works with a minimum of creativity that represents the personality of the author can be original ; labour and efforts alone in creat ing a work would not qualify for copyright protection.483 In light of these systemic considerations , output such as co mputational shorthand484 or listing of automatically numbered hardware parts created using software systems have been found to lack the origin ality for protection under copyright.485 Actually , Samuelson — and other authors — would argue there are no statuto ry limitations in the U.S. on treating a machine as an author as “ [ t ] he copyright standard of originality is sufficiently low [ so ] that comput er-generated works , even if found to be created solely by a machine , might seem able to qualify for protection. ” 486 I would argue that , after the Feist case , originality is not only a quantum question . For AI -generated creativity purposes , it is irrelevant w hether the standard of originality is low or high . The standard the AI fails to reach is qualitative rather than quantitative . AI can not express ‘ self ’ . The creativity that it generates can not express the personality of the author because AI has none . In t his regard , the United States joining the Berne Convention in 1988 and the Feist case in 1991 signal the crystall isation of a global , more harmonised view of copyright . This alignment of the United States with the European model also includes a constructio n of originality in personality theory terms.487 More recently , a few remaining — mainly common law — jurisdiction s have been joining this personality approach to originality . This has been the case in Australia,488 India,489 and the United Kingdom,490 which have finally rejected previous “ labour , skill and efforts ” approaches . Just a few countries still follow “ sweat of the brow ” doctrines and reject personality approaches to originality , including South Africa491 and New Zealand.492 In sum , there appears to be an ext remely consistent international construction of the notion of originality which emphasises an anthropocentr ic vision according to which a work is original if it is a representation of ‘ self ’ , a representation of the personality of the author . Only if that inner attachment between the author and the work is present , is the originality requirement fulfilled , and protection granted . Of course , only a sentient self conscious being would be capable of representing ‘ self ’ through a work . In turn , even if any poss ible textual anthropocentric construction of authorship is disregarded , absent the creator ’ s self -conscious ness , the originality requirement that lies in the representation of 483 Feist Publications v. Rural Telephone Service , 499 U.S. 340 ( 1991 ) ( USA ) . 484 Brief English Systems v. Owen , 48 F.2d 555 ( 2d Cir . 1931 ) ( USA ) . 485 Southco , Inc. v. Kanebridge Corporation , 390 F.3d 276 ( 3d Cir . 2004 ) ( USA ) . 486 Samuelson P. ( 1986 ) , op.cit. , pp . 1199 -1200 . See also Brown N. , “ Artificial Authors : A case for copyright in computer -generated works ” , Columbia Science and Technology L aw Review 9 , pp . 24-27 . Kaminski M. , “ Authorship , Disrupted : AI Authors in Copyright and First Amendment Law ” , UC Davis Law Re view 51 , p . 601 . Contra see Clifford , R.D . ( 1996 ) , op.cit . , pp . 1694 -1695 . 487 Price M. E & Pollack M. , The Author in Copyright : Notes for the Literary Critic , 10 Cardozo Arts & Entertainment Law Journal 703 ( 1992 ) , pp . 717 -720 , https : //larc.cardozo.yu.edu/faculty -articles/123 . 488 IceTV Pty Ltd v. Nine Network Australia Pty Ltd [ 2009 ] HCA 14 , 239 CLR 458 ( AUS ) . 489 Eastern Book Co. & Ors v. D.B . Modak & Anr ( 2008 ) 1 SCC 1 ( India ) . 490 Temple Island Collections v New English Teas ( No . 2 ) [ 2012 ] EWPCC 1 . Rahmatian A. , op.cit . , pp . 4-34 491 Appleton v. Harnischfeger Corp. 1995 ( 2 ) SA 247 ( AD ) at 43 –44 ( SA ) . 492 Henkel KgaA v. Holdfast [ 2006 ] NZSC 102 , [ 2007 ] 1 NZLR 577 ( NZ ) . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 103 the personality of the author can never be fulfilled . Therefore , unless it can b e claimed that machines have achieved self -consciousness , which might be the case for futuristic , hypotheti cal , strong AI , but not today,493 AI-generated creativity can not meet the originality requirement under the present legal framework.494 As some have arg ued , only a novel , perhaps a more formal , objective approach — as opposed to the existing , subjective app roach — to the concept of originality would be able to include within the scope of copyright protection works created by creative robots as well as art works generated by digital tools.495 From this objective perspective , a judge should look at the final out put per se , considering the field of art , the objective opinion of users , and similarity to other works , while disregarding the subjective intention of the author.496 In this respect , the standard for originality in copyright should align itself more closel y to the standard for novelty in patent law , which considers protectable subject matter from a social/historical perspective rather than an individual/su bjective perspective.497 5.4 . Policy options : Are incentives necessary ? Scholars and courts have raised the point that a legal system that does not grant protection to AI -generated creativity would create negative externalities from an ‘ incentive theory ’ perspect ive . Incentive theory or utilitarianism,498 which is dominant in the United States and common law jurisdictions , is more removed from the humanity of its author than personality theories heavily influencing civil law jurisdictions.499 This provides more room f or argument in favour of non -human authorship and protectability of AI-generated creativity . Ac cording to the incentive theory approach , “ providing financial incentives in order to encourage the growth and development of the AI industry and ensure the diss emination of AI -generated works is arguably the ultimate goal of assigning copyright to human a uthors ” .500 Although a computer does not need an incentive to produce its output , the incentive may be useful for the person collaborating with the 493 Zimmerman E. , op.cit . , pp . 1 4-21 . 494 Clifford , R.D . ( 1996 ) , op.cit . , 1694 -1695 . Deltorn J.M . ( 2017 ) , op.cit . , p. 7 . Deltorn J.M . and Macrez F. ( 2018 ) , op.cit. , p. 8 . Gervais D.J. , “ The Machine as Author ” , Iowa Law Review Vol . 105 , pp . 1 -60 . Mezei P. , “ From Leonardo to the Next Rembran dt – The Need for AI -Pessimism in the Age of Algorithms ” , https : //papers.ssrn.com/sol3/papers.cfm ? abstract_id=3592187 . Ramalho A. , op.cit . , pp . 22-24 . 495 Yanisky -Ravid S. and Velez -Hernandez L.A. , “ Copyrightability of Artworks Produced by Creative Robots , Driven by Artificial Intelligence Systems and the Originality Requirement : The Formality -Objective Model ” , Minnesota Journal of Law , Science & Technology 19 ( 1 ) , pp . 40-48 . 496 Bonadio E. and McDonagh L. , “ Artificial Intelligence as Producer and Consumer of Copyright Works : Evaluating the Consequences of Algorithmic Creativity ” , Intellectual Property Quarterly 2 , pp . 112 -137 , https : //papers.ssrn.com/sol3/papers.cfm ? abstract_id=3617197 . 497 Cf . Boden M. , The Creative Mind : Myths And Mechanisms , Routledge , London , p. 32 . 498 Fisher W. , op.cit . , pp . 177-180 . 499 Kaminski M. , op.cit . , p. 599 . 500 Hristov K. , “ Artificial Int elligence and the Copyright Dilemma ” , IDEA : The Intellectual Property Law Review 57 , p. 444 . See also Brown N. , op.cit . , 20-21 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 104 computer.501 In particular , authors argue that there should be some additional incentive to encourage industry to invest the time and money that it will take to teach machines to behave intelligently502 or to reward users training and instructing AI to generate content .503 As some argue , considerations of public policy under a utilitarian perspective would make it imperative for some form of protection to be given to AI -generated outputs whether copyright or unfair competition law protection or a sui generis protection,504 as the process of creation — by human or computer — has no impact on its contribution to public welfare.505 However , most civil law jurisdictions may not be so fundamentally influenced by welfare and incentive considerations and may prefer to value syste mic balan ce , thus rejecting any departure from the personality theory approach that shapes the civil law copyright perspective — and in fact the notion of originality in the large majority of jurisdictions . Therefore , although AI -generated creations may ju stify inc entives to bolster innovation and commercialisation , the necessity of such incentives is questionable considering the impact they can have on human creations.506 For example , considering the vast number of automated creations , granting protection f or these w orks could devalue human authorship and existing jobs in the field and hamper creativity,507 as it could discourage artists from publishing their creations due to the fear of infringing protected material508 or clog the creative ecosystem with stan dardised and homogenised AI generated outputs , impacting cultural diversity and identity politics . The question to be determined is whether expansion of current copyright protection to computer -generated works is useful . The current legal framework may already provid e enough protection through patent and copyright law to the underlying software , sui generis protection to databases or other legal mechanisms such as competition law to protect automated works without an extension of the existing copyright reg ime to non -human authors.509 The questions should be investigated from a law and economics approach before any solutions are favoured.510 Ginsburg and Budiardjo have stressed this point : ‘ [ w ] e can conjure up a variety of scenarios supporting or 501 Hristov K. , op.cit . , 438-439 . Miller A.R. , op.cit . , 1067 . 502 Bridy A . ( 2012 ) , op.cit . , 1-27 . Butler T. , op.cit . , p. 735 . Farr E .H. , “ Copyrightability of Computer -Created Works ” , Rutgers Computer & Technology Law Journal 15 , pp . 73 -74 . Kasap A. , op.cit . , pp . 361-364 ; Abbott R. , “ I Think , Therefore I Invent : Creative Computers and the Future of Patent Law ” , 57 B.C.L . Rev . 1079 ( 2016 ) , http : //lawdigitalcommons.bc.edu/bclr/vol57/iss4/2 . Milde K.F. , op.cit . , p. 390 . 503 Brown N. , op.cit . , p.37 . Denicola R. , op.cit . , p. 283 . Ralston W.T. , “ Copyright in Computer -Composed Musi c : HAL Meets Handel ” , Journal of the Copyright Society of the USA 52 , pp . 303-304 . Samuelson p. ( 1986 ) , op.cit . , pp . 1224 -1228 . 504 Milde K.F. , op.cit . , pp . 400-403 . 505 Butler T. , op.cit . , p. 735 . Denicola R. , op.cit . , p. 273 . Kaminski M. , op.cit . , p. 599 . 506 Craglia M. , op.cit . , pp . 67 -68 . 507 Bonadio E. and McDonagh L. , op.cit . 508 Deltorn J.M . ( 2017 ) , op.cit . 509 Deltorn J.M . and Macrez F. ( 2018 ) , op.cit . , p. 24 . 510 Craglia M. , op.cit . , p. 68 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 105 debunking the call for sui generis protection , but without empirical evidence , it would be imprudent ( and premature ) to seek to design a regime to cover authorless outputs ” .511 5.4.1 . No protection : Public domain status of AI -generated works As our earlier review of requiremen ts for protecti on has suggested , the construction of the notion of legal personality , authorship and originality under the present copyright regime might exclude AI -generated creativity from copyright protection.512 Relegating AI generated creativity to the public domain w ould therefore be a possible policy option — and that most likely endorsed under the present legal framework . With this approach , the ownership of copyright depends on the amount of human intervention . Mere data selection and classification by humans is in sufficient to meet the ‘ originality ’ requirement ; instead , actual and substantial human contribution to guide the AI system in creation is necessary for the granting of protection.513 Only when there is substantial human input , and all creat ive choices are e mbedded in the computer code or users ’ instructions , would copyright be vested with the human author.514 In this regard , four models of allocating authorship have been identified : ( 1 ) sole authorship to the user of the tool , if the designer of the tool does not contribute to the creative work generated ; ( 2 ) sole authorship to the designers of the tool , if the operator plays no role in the output and the self -generative tool creates output based on the training and creative raw material provi ded by the designe r ; ( 3 ) joint authorship to the user and the programmer , when the outputs reflect the creative contributions of both designer and user ; ( 4 ) authorless works — neither designer nor user contribute sufficient expression to form an original w ork of authorship.515 In any event , if the creative output results both from human and machine choices , materials resulting from machine -made choices must be filtered out as is customary with public domain materials.516 Only independently copyrightable human contributions will be protectable . 511 Ginsburg J. and Budiardjo L.A . , op.cit . , p. 448 . See also Ginsburg J. , op.cit . , pp . 131-135 . 512 Aplin T. and Pasqualetto G. , op.cit . , §5.01 -09 . Clifford , R.D . ( 2018 ) , “ Creativity Revisited ” , IDEA : The IP Law Review 59 , pp . 2 6-29 . Clifford , R.D . ( 1996 ) , op.cit . , 1700 -1702 . Huson G. , “ I , Copyright ” , Santa Clara High Technology Law Journal 35 , pp . 72-78 . Mezei P. , op.cit . Palace V.M. , “ What if Artificial Intelligence Wrote This : Artificial Intelligence and Copyright Law ” , Florida Law Review 71 ( 1 ) , p p. 238 -241 . Saiz Garcia C. , “ Las obras creadas por sistemas de inteligencia artifi cial y su protección por el derecho de autor ( AI Created Works and Their Protection Under Copyright Law ) ” InDret 1 , pp . 38 -39 , https : //ssrn.com/abstract=3365458 . Gervais D.J. , op.cit . , pp . 1 -60 . Ramalho A. , op.cit . , pp . 22-24 . Svedman M. , op.cit . , pp . 1-22 ; 513 Selvadurai N. and Matulionyte R. , “ Reconsidering creativity : copyright prot ection for works generated using artificial intelligence ” , Journal of Intellectual Property Law & Practice jpaa062 , p. 539 . 514 Gervais D.J. , op.cit . , pp . 51 -60 . Selvadurai N. and Matulionyte R. , op.cit . , p. 538 . 515 Ginsburg J. and Budiardjo L.A . , “ Authors and Machines ” , Berkeley Technology Law Journal 34 ( 2 ) , pp . 404-445 . 516 Gervais D.J. , op.cit . , p. 54 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 106 An additional test has been proposed which would determine whether a work deserves protection depending on how much of the developers ’ meaning transmits to the final work and whether the user/developer could predict the output.517 Such a test would involve implementing traditional copyright requirements granting protection only if the work is the product of the human authors ’ imagination and a conception of it . If this test is implemented , copyright law should prompt a shi fting of the traditio nal burden of proof , so that the claimant must prove human authorship of certain AI -generated outputs by establishing that the output foreseeably includes a meaning or message that the author wishes to convey to his or her audience.518 5.4.2 . Authorship and legal f ictions : Should a human be the author ? In order to avoid AI -generated creativity falling in the public domain , and to grant necessary incentives to human agents involved with the AI creative process , proposals have been made — and le gislation has been enac ted — to set up a legal fiction , so that authorship of AI -generated works is conferred to the agents expending skills , labour and efforts to create , train or instruct the AI in the first place . This approach has also been termed the “ fictional human author theory ” .519 This policy approach emerged quite early , when the creative potential and mechanics of machine learning and AI were wholly unknown . In the United Kingdom , the copyright protection of a computer -generated sequence for a l ottery was discussed as early as 1985 in Express Newspapers v. Liverpool Daily Post . Justice Whitford assigned copyright protection for the automated output to the plaintiff and refused the notion that copyright in the work could be vested in the computer . The computer , he held , is a mere tool for creation ; arguing that the computer is the author is similar to suggesting that in a written work , “ it is the pen that is the author of the work rather than the person who drives the pen ” .520 This position has been recently powerfully summ arised by Dan Burk in terms of proximate cause , intent and volition , so that “ [ i ] f there is an author , it is one or more of the humans who are sufficiently causally proximate to the production of the output . [ … ] But the author is n ever the machine ” .521 517 Boyden B. , “ Emergent Works ” , Columbia Journal of Law and the Arts 39 , pp . 377 -394 . 518 Boyden B. , op.cit . , 393 -394 . 519 Wu A.J. , “ From Video Games t o Artificial Intelligence : Assigning Copyright Ownership to Works Generated by Increasingly Sophisticated Computer Programs ” , AIPLA Quarterl y Journal , pp . 173-174 . 520 Express Newspapers Plc v. Liverpool Daily Post & Echo Plc [ 1985 ] 1 WLR 1089 ( UK ) . 521 Burk D.L. , “ Thirty -Six Views of Copyright Authorship , By Jackson Pollock ” , Houston Law Review 58 , pp 1 -38 . See also Hedrick S.F. , “ I 'Think ' , Ther efore I Create : Claiming Copyright in the Outputs of Algorithms ” , NYU Journal of Intellectual Property & Entertainm ent Law 8 ( 2 ) , pp . 324 -375 , and Grimmelmann J. , “ There is No Such Thing as a Computer -Authored Work And It is a Good Thing , Too ” , Columbia Jou rnal of Law and the Arts 39 , pp . 403-416 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 107 The U nited Kingdom was the first jurisdiction to provide specific protection to computer -generated creativity.522 Section 9 ( 3 ) of the Copyright Designs and Patents Act 1988 ( CDPA ) 523 clarified that for computer -generated works , the autho r is the person who undertak es the arrangements necessary for the creation of the work . In addition , Section 178 provides that “ computer -generated , in relation to a work , means that the work is generated by computer in circumstances such that there is no h uman author of the work ” . Under this regime , the term of protection for computer -generated works would be 50 years from when the work was made . Shortly thereafter , other common law countries , including Hong Kong , India , Ireland , Singapore , and New Zealand , enacted similar legal arran gements.524 There are , however , two issues that challenge this arrangement . The first is fundamental and systemic . Would this approach be sustainable under a legal framework that builds upon the notion of originality as an expres sion of the author ’ s personal ity as adopted by EU law as well as most international jurisdictions ? Of course , programming , training and imparting instructions would be unlikely to fulfil the requirement of an original contribution from the human counterpar ts , as ultimately any ‘ expres sion ’ would be the result of the AI creative process . As long as the present subjective standard for originality is in place , any fictional human author theory would crumble in the face of the lack of originality of AI -generate d creativity . The work itself , whose fictional authorship is attributed to a human agent , would actually remain unoriginal , thus unprotectable . It is worth noting that “ fictional human author theory ” and ‘ necessary arrangements ’ approaches have been enacte d in the UK and other common law countries when ‘ sweat of the brow ’ or ‘ skill and labour ’ originality standards were still dominant in those jurisdictions . Since then , as previously mentioned , changes have been occurring , with the personality standard for originality fully or partiall y replacing any alternative approach,525 challenging the systemic compliance policy approach of Section 9 ( 3 ) CDPA . The second issue is of more practical nature . This approach makes it tricky to allocate who is the person in cha rge of the necessary arrangeme nts.526 Does the AI generated work belong to the person who built the system , such as the software developer , the manufacturer , the person who trained it , or the person who fed it specific 522 Guadamuz A. , “ Do Androids Dream of Electric Copyright ? Comparative Anal ysis of Originality in Artificial Intelligence Generated Works ” , Intellectual Property Quarterly , pp . 169 -186 . 523 Copyright , Designs and Paten ts Act 1988 . Available at https : //www.legisl ation.gov.uk/ukpga/1988/48/contents ( UK ) 524 Copyright Ordinance cap 528 , Section 11 ( 3 ) , https : //www.elegislation.gov.hk/hk/cap528 ( Hong Kong ) ; Copyright Act 1957 , Section 2 ( d ) ( vi ) , https : //www.wipo.int/edocs/lexdocs/laws/en/in/in122en.pdf ( India ) ; Copyright and Rela ted Rights Act 2000 , Section 21 ( f ) , http : //www.irishstatutebook.ie/eli/2000/act/28/enacted/en/html ( Ireland ) ; Copyright Act 1987 chapter 63 , Section 7A , https : //sso.agc.gov.sg/Act/CA1987 # pr27 - ( Singapore ) ; Copyright Act 1994 , Sect ion 5 ( 2 ) , http : //www.legislation.govt.nz/act/public/ 1994/0143/latest/DLM345634.html ( New Zealand ) . 525 Temple Island Collections v New English Teas ( No . 2 ) [ 2012 ] EWPCC 1 . Guadamuz A. , op.cit . , p. 178-180 ; Rahmatian A. , op.cit . , pp . 4-34 . 526 Dorotheu E. , “ Reap the benefits and avoid the legal uncertainty : who owns the creations of artificial intelligence ? ” , Computer and Telecommunications Law Review 21 , p. 85 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 108 inputs like a user ? 527 In Guadamuz ’ s vi ew , however , the system ’ s ambigu ity should actually be seen as a positive feature that deflects the user/programmer dichotomy question and renders a case -by-case analysis basis.528 In any event , the question “ who is in charge of the necessary arrangements ? ” has been answered in multiple wa ys both by case law and scholarship . 5.4.2.1 . Should the programmer be the author ? A first possible answer to the question “ should the programmer be the author ? ” was provided in Nova Productions v Mazooma Games , a case in which Section 9 ( 3 ) of the CDPA was applied . The case concerned copyright for frame images generated by a computer program using bitmap files and displayed on the screen when the users played a snooker video -game . The court refused to grant authorship to the user as their input was not artistic in n ature : The appearance of any particular screen depends to some extent on the way the game is being played . For example , when the rotary knob is turned the cue rotates around the cue ball . Similarly , the power of the sho t is affected by the precise moment t he player chooses to press the play button . The player is not , however , an author of any of the artistic works created in the successive frame images . His input is not artistic in nature and he has contributed no skill or labour of an artistic kind . Nor ha s he undertaken any of the arrangements necessary for the creation of the frame images . All he has done is to play the game .529 Instead , the court found the programmer to be the sole author and the person who made the n ecessary arrangements , noting that “ [ t ] he arrangements necessary for the creation of the work were undertaken by [ the plaintiff ] because he devised the appearance of the various elements of the game and the rules and logic by which each frame is generated and he wrote the relevant computer pro gram.530 ” In truth , the Nova Productions outcome may have been a direct consequence of the rudimental technology at stake , and , as Guadamuz argued , a different allocation of authorship might result depending on the specifics of the case and technology under review.531 Nonetheless , the approach has been proposed in other jurisdictions , such as the United States , requiring the courts to bend the language of the Copyright Act , so that , where neither the programmer nor the us er meet the requirements of authorship o f a copyrightable work , the court should assign the copyright to whoever owns the copyright to the computer program.532 527 Bonadio E. and McDonagh L. , op.cit . , pp . 117 -119 . Kasap A. , op.cit . , pp . 364-376 . 528 Guadamuz A. , op.cit . p. 177 . 529 Nova Productions Ltd v. Mazooma Gam es Ltd & Ors Rev 1 [ 2006 ] EWHC 24 ( Ch ) ( 20 January 2006 ) ( UK ) . See also Farr E.H. , op.cit . , 75-78 . 530 Nova Productions Ltd v. Mazooma Games Ltd & Ors Rev 1 [ 2006 ] EWHC 24 ( Ch ) ( 20 January 2006 ) ( UK ) . See also Farr E.H. , op.cit . , 73-74 . 531 Guadamuz A. , op.cit . , p. 177 . 532 Wu A. J. , op.cit . , pp . 173 -174 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 109 Vesting authorship in the programmer of AI -generating content prompts a fundamental critique . The allocation of authorship to the software developer — or to owners of AI technologies such as companies and investors —may constitute a blatant misperception533 . In fact , at least in state -of-the-art neural network ( GAN and CAN ) based creativity , there appears to be no direct causal connection betw een the software developers and the final AI -generated output , as the expression embedded in that output is the result of the training of the machine and the instructions given to create that specific output . I n light of this , first , from a systemic perspe ctive , it could be argued that this arrangement opens a fundamental inconsistency . Actually — as also the Beijing Internet Court highlighted in a case mentioned earlier — the software developer has been already rewarded with exclusive rights over the softw are that generates works.534 In addition , given that precisely this legal fiction is meant to provide incentives to create AI generated works , where its public domain status would presumptively fail to do so , a sound economic analysis would probably discoura ge a policy option that rewards the same market player twice . Finally , from a more practical perspective , this policy solution would potentially entitle coders to aggressive copyright protection for innumerabl e pieces of creativity,535 which would also lower any incentive for the original programmer to create more software.536 US case law appears also to endorse the conclusion that software and output are two very distinct entities , and ownership over the former does not imply rights over the latter . In two cas es , the courts have ruled that the output created using an infringing copy of software or of a programme is not considered an infringing derivative work . In Design Data v. Unigate Enterprises , affirming the district court decision , the court of appeals rul ed that the plaintiffs ’ copyright over the computer programme did not extend to the output created by the programme ( drawings and data for steel buildings ) .537 In Rearden v. Walt Disney Co. , movies created us ing an ( infringing ) copy of the plaintiff ’ s softwa re were not considered derivative works of the software because although the software did a significant amount of work , the lion ’ s share of creative expression in the movie was attributable to the defendant s.538 533 Abbott R. , “ Artificial Intelligence , Big Data and Intellectual Property : protecting computer generated works in the United Kingdom ” in Aplin T . ( ed . ) , Research Handbook on intellectual property and digital tech nologies , Edward Elgar , England , pp . 323-324 . Svedman M. , op.cit . , 10-11 . Bridy A . ( 2016 ) , “ The Evolution of Authorship : Work made by Code ” , Columbia Journal of Law and the Arts 39 , pp . 400-401 . Bridy A . ( 2012 ) , op.cit . , 24-25 , para 62 . Samuelson P. ( 1986 ) , op.cit . , pp . 1207 -1212 . 534 Beijing Feilin Law Firm v Baidu Corporation ( 26 April 2019 ) Beijing Internet Court , ( 2018 ) Beijing 0491 Minchu No . 239 . He K. ( 2020b ) , op.cit . See also Bonadio E. and McDonagh L. , op.cit . , p. 117 . Chen M. , op.cit . , pp . 14-18 . Samuelson P. ( 1986 ) , op.cit . , pp . 1207 -1212 . 535 Svedman M. , op.cit . , p. 14 . 536 Huson G. , op.cit. , p. 74 . 537 Design Data Corp. v. Unigate Enterprise , No . 14 -16701 ( 9th Cir . 2017 ) ( USA ) . 538 Rearden v. Walt Disney Co , No . 17 -cv-04006 -JST ( N.D. Cal . 2018 ) . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 110 5.4.2.2 . Should the user be the author ? Allocating rig hts in AI -generated output to the user of the generator programme might be a more sound solution.539 The recent Beijing decision earlier described stressed such a conclusion.540 Samuelson has argued that the user is the reason the AI -generated work comes into being , thus “ [ i ] t is not unfair in these circumstances to give some rights to a person who uses the work for its intended purpose of creating additional works ” .541 This solution would not be novel under c opyright standards . For example , in the United States , copyright —and authorship — are given to users for being the instrument of fixation542 as in the case of a person who tape -records a jazz performance.543 In this scenario , the user would be the author of the sound recording , rather than the jazz performers . S imilarly , the user could be construed as the author of the fixation of the AI -generated work . Of course , a specific provision , such as 9 ( 3 ) CDPA , should be introduced to that end . Most likely , in some exceptional cases , such as when the user does not have any control over the software other than running it , awarding copyright to the user would be a sub -optimal policy choice at odds with copyright incentive theory.544 In this case , joint authorship betwe en users and programmers could be a possible solution,545 depending on the legal scheme for joint authorship made available by different jurisdictions . In a “ Draft Report on intellectual property rights for the development of artificial intelligence technol ogies ” , the European Parliament seemingly endorsed the sam e view and proposed to entrust AI users with copyright over AI -generated works . The draft report “ [ t ] akes the view that consideration must be given to protecting technical and artistic creations gen erated by AI , in order to encourage this form of creation ; considers that certain works generated by AI can be regarded as equivalent to intellectual works and could therefore be protected by copyright ” .546 Therefore , the draft report “ recommends that owner ship of rights be assigned to the person who prepares and p ublishes a work lawfully , provided that the technology designer has not expressly reserved the right to use the work in that way ” .547 Apparently , this proposal implies ownership of rights to be also assigned to the users , as the draft report makes reference to copyright protection , rather than a sui generis protection , stating that “ it is proposed that an assessment should 539 CONTU , op.cit. , p. 45 . See also Ralston W.T. , op.cit . , pp . 303 -304 . 540 Beijing Feilin Law Firm v Baidu Corporation ( 26 April 2019 ) Beijing Internet Court , ( 2018 ) Beijing 0491 Minchu No . 239 . He K. ( 2020b ) , op.cit . 541 Samuelson P. ( 2020 ) , “ AI Authorship ? ” Communicat ions o f the ACM 63 ( 7 ) , pp . 20 -22 . Samuelson P. ( 1986 ) , “ Allocating Ownership Rights in Computer -Generated Works ” , University of Pittsburg Law Review 47 ( 4 ) , pp . 1200 -1204 . 542 17 U.S.C . § 114 . 543 Samuelson P. ( 1986 ) , op.cit . , pp . 1200 -1204 . However , most count ries favor neighbouring rights protection for sound recordings , rather than copyright as in the Unites States . 544 Ralston W.T. , op.cit . , pp . 304-305 . 545 E.g . Bonadio E. and McDonagh L. , op.cit . , 117 -118 . 546 European Parliament ( 2020 ) , op.cit . 547 European Parl iament ( 2020 ) , op.cit . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 111 be undertaken of the advisability of granting copyright to such a ‘ creative work ’ to the natural person who prepares and publishes it lawf ully [ … ] ” .548 5.4.2.3 . Should the employer be the author ? Scholars have proposed the work -made -for-hire ( WMFH ) doctrine549 as a legal framework to ensure the protectability , ownership and account ability of works generated by AI systems.550 This model would be based on th e fiction that the AI system is a creative employee or independent contractor of the users — humans or legal entities — that use AI systems and enjoy its benefits.551 As Samuelson ar gues , “ one who buys or licenses a generator program has in some sense ‘ emplo yed ’ the computer and its programs for his creative endeavours , similar considerations to those that underlie the work made for hire rule support allocation of rights in computer -generated works to users ” .552 Thus , ownership of the copyright and liability fo r any infringements arising from the work would be imposed on the human or legal entity considered the employer or commissioner of the AI system that creates the work . Adoption o f this regulatory framework would trigger a few critiques . First , an argument is often made that employers are treated as authors of work -for-hire works despite having no role in the output , thus similar arrangements could be devised for AI generated creat ivity.553 This position , however , seems to miss the fact that as part of the WMFH legal fiction , the underlying work has been created by a human author and fulfils the originality standard under the present legal framework . This would not be the case with AI -genera ted creativity . Second , this arrangement would face challenges on the grounds that it would be a misapplication of the WMFH doctrine , as it is difficult to define a legal , contractual employment or agency relationship between a human and a machine.554 The a pplication of the WMFH doctrine would be especially problematic in jurisdictions such as France where transfers of ownership to employers or commissioning parties must be explicitly provided for in the employment or commissioning agreement 548 European Parliament ( 2020 ) , op.cit . 549 Under US copyright law , work made for hire constitutes an exception to the rule that only the author ( or those deriving rights from the author ) can claim copyright over a protectable work . Unde r this doctrine , the employer is considered the author of a work even if an employee created the work . It is defined u nder Section 101 of the Copyright Act . A work created by an employee during their course of employment or specially ordered or commissione d for use by the employer is a work made for hire if the parties so agree in a signed agreement ( United States Copyrig ht Office , “ Works Made for Hire ” . Available at copyright.gov/circs/circ09.pdf ) . 550 Bridy A . ( 2016 ) , op.cit . , pp . 400-401 . Bridy A . ( 2012 ) , op.cit . , 26 , para 66 . Hristov K. , op.cit . , 431-454 . Kaminski M. , op.cit . See also Pearlman R. , “ Recognizing Artificial Intelligence ( AI ) as Authors and Inventors under U.S . Intellectual Property Law ” , Richmond Journal of Law & Technology 24 , pp . 1 -38 . Yanisky-Ravid S. ( 2017 ) , “ Generating Rembrandt : Artificial Intelligence , Copyright , and Accountability in the 3A Era , The Human -Like Authors are Already Here : A New Model ” , Michigan State Law Review , pp . 659 -726 . 551 Yanisky -Ravid S. , op.cit . , pp . 659-726 552 Samu elson P. ( 2020 ) , op.cit . , pp . 20 -22 ; Samuelson P. ( 1986 ) , op.cit . , pp . 1200 -1204 . 553 Brown N. , op.cit . , p.39 . Kamin ski M. , op.cit . , 602 . 554 Bonadio E. and McDonagh L. , op.cit . , pp . 114 -115 . Bridy A . ( 2012 ) , op.cit . , p. 27 , para 68 . Butler T. , op.cit . , pp . 739-742 . Huson G. , op.cit . , pp . 73-75 . Ramalho A. , op.cit . , pp . 18-19 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 112 and will not be implied . It seems obvious that in order for the WMFH doctrine to apply to AI-generated works some substantial statutory and jurisprudential reconstruction of the notion of ‘ employer ’ and ‘ employee ’ must in any event first occur.555 5.4.3 . Should a robot be the au thor ? One policy option — although quite residual according to the schol arship556 — would be to construe the AI as the author . A fiction would have to be established in the law to provide AI with legal personality , so that it can author a work and own a cop yright,557 or at least the law would have to be amended to reflect the fact that a computer can be an author in a joint work with a person558 . According to Pearlman , the law should recognise sufficiently creative AIs as authors when the AI creation is origin al and developed independently from human instructions , so that the AI is t he cause of creativity , not a mere machine working under the instructions of a human author.559 Once the AI is declared the author , rights would be immediately assigned to a natural or legal person , such as the creator/programmer of the AI , the user of the A I , or as a joint work . The law should identify the person entitled to receive the transfer and exercise the rights . Still , also in this scenario , meeting the requirement of origin ality could be an insurmountable burden for a machine . The notion of origina lity would most likely have to be tweaked to include works originating from a machine , as mentioned before.560 However , if legal personhood is granted to a machine , an argument coul d also be made that , once recognised as a ( legal ) person , the machine would b e capable of original creativity according to the personality approach that governs copyright law and construes originality as an expression of the personality of the author . In a ny event , allowing AI as author would require substantial amendments to the l egal framework . As noted , given the early state of technological development , amending the law before truly intelligent machines have even materialised — and whose materialisation and evolution remains as of today just hypothetical speculation — would be a sub-optimal policy option.561 555 Hristov K. , op.cit . , pp . 445-447 . 556 E.g . Bonadio E. and McDonagh L. , op.cit . , p. 116 . Farr E.H. , op.cit . , p. 79 . Ralston W.T. , op.cit . , pp . 302-303 . Samuelson P. ( 1986 ) , op.cit . , pp . 1199-1200 . 557 Ihalainen J. , “ Computer creativity : artificial intelligence and copyright ” , Journal of Intellectual Property Law & Practice 13 ( 9 ) , pp . 724 –728 . 558 Abbott R. , op.cit . 559 Pearlman R. , op.cit . , pp . 1-38 ) . 560 Yanisky -Ravid S. and Velez -Hernandez L.A. , op.cit . , pp . 40 -48 . 561 Huson G. , op.cit . , pp . 77-78 . Liebesman Y. , “ The Wisdom of Legislating for Anticipated Technological Advancements ” , J. Marshall Rev . Intell . Prop . L. 10 , p. 1 72 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 113 5.4.4 . Sui generis protection for AI -generated creativity Proposals have also suggested the creation of a related sui generis right ( where no authorship or originality would be a necessary requirement ) which might protect the investme nt made in developing and training AI -generating creativity.562 For example , McCutcheon has suggested a sui generis rights regime for AI -generated creativity similar to database r ights , thereby protecting the investment in the creation but not requiring an author , nor authorship , nor originality.563 While denying protectability under the traditional copyright scheme , the Australian Copyright Law Review Committee noted that , if compu ter-generated creativity needs protection , this should be “ more akin to that extended to neighbouring rights [ … ] the protection extended to performers , producers of phonograms and broadcasting organizations ” .564 Japan has been considering a novel sui gener is regime for non -human -created intellectual property based on a trademark -like a pproach with an emphasis on protection against unfair competition.565 This approach seeks to limit the protection of AI works by allowing flexibility in levels of protection ba sed on the popularity of the AI -generated works as a proxy for goodwill.566 This wou ld leave out obscure works created for the sole aim of copyright protection . The proposal would allocate ownership of the work to the individual or company that had created the AI.567 In the same vein , with the goal of limiting overbroad protection of algori thmic creativity , some authors propose a thin scope of the sui generis right , coupled with strong fair use safeguards , with a short duration of around three years or so.568 5.4.5 . Providing rights to publishers and disseminators Finally , further proposals suggest providing rights to publishers and disseminators of AI generated works . On the one side , the regime for anonymous/pseudonymous works could be applied to AI -generated works . According to several national regimes , such as Spain , France , Italy and Sweden569 , the person who publishes the work will exercise the rights . 562 Ciani J. , “ Learning from Monkeys : Authorship Issues Arising From AI Te chnology ” in Moura Oliveira P. , Novais P. , Reis L. ( eds ) , Progress in Artificial Intelligence EPIA 2019 Lecture Notes in Computer Science vol . 11804 , Springer , Cham . 563 McCutcheon J. , op.cit . , pp . 965-966 . 564 Ricketson S. ( 2012 ) , “ The Need for Human Authorsh ip - Australian Developments : Telstra Corp Ltd v Phone Directories Co Pty Ltd ( Case Comme nt ) ” , E.I.P.R . 34 ( 1 ) , 54 . 565 Intellectual Property Strategic Program 2016 , pp . 10 -11 , http : //www.kantei.go.jp/jp/singi/titeki2/kettei/chizaikeikaku20160509_e.pdf . 566 Intellectual Property Strategic Program 2016 , op.cit . , p. 11 . 567 Intellectual Property Strategic Program 2016 , op.cit . 568 Bonadio E. and McDonagh L. , op.cit . , 136 -137 . 569 The Intellectual Property Act 1996 , Article 6 . Available at https : //www.wipo.int/edocs/lexdocs/law s/en/es/es177en.pdf ( Spain ) ; Code de la propriété intellectuelle [ Intellectual Property Code ] 1912 , L113 -6 . Available at ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 114 On the other side , an additional policy option could provide to the disseminator of AI generated creativity a rig ht similar to the EU ’ s publisher rights relating to previously unpublished works , as i n Art . 4 of Directive 2006/116/EC.570 Under this scheme , the protection covers the first lawful publication/communication of previously unpublished public domain works . Si milarly , AI -generated works would be in the public domain , therefore the ‘ disseminator ’ scheme would only reward someone for the dissemination of AI-generated creation . The duration of the right could be limited to 25 years for example , as in the case of A rt . 4 of Directive 2006/116/EC.571 5.5 . Conclusions Anthropocentrism and the personality right approach strongly influence the present copyright legal framework , in particular the notion of originality , from the Berne Convention to major jurisdictions . Thus , AI -generated creativity falls short of all fundam ental requirements for granting copyright protection , including legal personality , authorship and originality . Utilitarian/incentive approaches push for the adoption of legal fictions that do not satisfactorily address and overcome internal systemic incon sistencies . Still , even if the law fiction ally claims that the work is human -made rather than AI -made , the work itself remains unoriginal as machines will be inherently incapable of originality under a personality standard . Only a fundamental overhaul of t he copyright system , sidelining the curren t anthropocentric approach , can provide full copyright protection to AI -generated creativity proper , when no human intervention can be construed as an original expression . This would be ill -considered , especially g iven the primitive stage of technological development in the field . Residual sui generis approaches are also available and , most likely , a preferable option , if policy -makers choose to provide monopolistic incentive to AI-generated creativity . In that case , the incentive should fall upon the users if they contributed any meaningful labor and effort to the AI -generated output , because otherwise programmers , marketers and investors would be double -dipping into earlier rewards linked to the AI-generating content software . But are incentives really nee ded ? The need for such incentives should be empirically proved together with the positive externalities that they would bring about for the creative ecosystem as a whole . In fact , there is well -established historical evidence that property rights are not t he only incentive to creativity.572 Miscellaneous research and market evidence show that open and free access to creative works or alternative business https : //www.wipo.int/edocs/lexdocs/laws/en/fr/fr467en.pdf ( France ) ; Law for the Protection of Copyright and Neighbouring Rights 1941 , Arti cle 9 . Available at https : //www.wipo.int/edocs/lexdocs/laws/en/it/it211en.pdf ( Italy ) ; Act on Copyright in Literary and Artistic Works 1960 , Article 7 . Available at wipo.int/edocs/lexdocs/laws/en/se/se124en.pdf ( Sweden ) . 570 Ramalho A. , op.cit . , pp . 22 -24 . 571 Ramalho A. , op.cit . 572 E.g . Frosio G. , op.cit . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 115 models may provide stronger incentive to AI -generated creativity than IP -based protection models,573 without creating the negative externalities of propertisation and exclusive rights . AI creative capacities might scale up at singularity pace , swamping the cultural marketplace with an unmanageable me sh of rights to clear and copyright trolling escalating towards ultimate computational doom . As noted , the copyright soup is already too thick . Infinite AI monkeys574 may eat it all up , and then there will be nothing left to use 573 E.g . Bonadio E. and McDonagh L. , op.cit . , 122 -123 . Svedman M. , op.cit , pp . 13 -14 . 574 Borel É. , “ Mécanique Statistique et Irréversibilité ” , J. Phys . ( Paris ) 5 ( 3 ) , pp . 189 –196 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audi ovisual Observatory ( Council of Europe ) 20 20 Page 117 Advertising The worries raise d by AI are , to a certain extent , nurtured by sci ence fiction literature and films . And yet , science fiction tends to foresee the future . Think , for example , of Steven Spielberg ’ s “ Minority Report ” 575 . There is a scene in which a man walks down an alley insi de a shopping centre . His eyes are flashed by a m ultitude of cameras equipped with eye -recognition software . Immediately , the shop windows start to show on flashy screens advertising specially tailored to him . Science fiction , really ? It is actually not so far removed from what we already experience in r eal life today . In this age of the Internet , connected TV sets and ‘ second screens ’ , the possibilities of obtaining the personal data of media users in both legal and illegal ways have multiplied exponential ly . Such data are a very important commodity for advertisers , which can be used to provide individually targeted ads on online services and on all sorts of connected devices . Furthermore , personal data obtained via search engines , social media and connecte d devices can be used as a means to provide a bet ter experience for the user of an online service . In her contribution to this publication , Justina Raižytė reminds that “ building a sustainable AI framework for advertising and the use of data and technology for good is in the interest of the advertising community itself ” , since it is the only way to earn consumer trust , which “ is , and always wi ll be , a true gold standard in advertising ” . 575 https : //www.imdb.com/title/tt0181689/ . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 119 6 . AI in advertising : entering Deadwood or using data for good ? Justina Raižytė , European Advertising Standards Alliance576 6.1 . Introduction Artificial intelligence ( AI ) jumped from futuristic movie scripts and ficti onal stories straight into our living rooms , cars , pockets and shopping bags a while ago . It didn ’ t take long before advertising , alway s fuelled with creativity and hungry for innovation , saw the potential of automated technologies and adopted AI as its ri ght-hand man , who can lead consumers through their journeys to becoming customers and loyal clients . Machine learning technologies all ow advertisers to more quickly analyse data on people ’ s interests , preferences , locations and demographics , and even to p redict their desires , create tailored targeting plans and deliver more relevant ads . In the process , the cost of advertising is reduced , while responsiveness and effectiveness rates increase . Consumers are also supposed to become more satisfied and even be entertained with personalised ads , which provide fewer annoying or irritating commercial messages . However , massive data flows that al low marketers to segment audiences and target consumers leave many people uneasy . Anxiety and the feeling of being consta ntly tracked while browsing , listened to by electronic devices in pockets , and targeted by unfairly priced offers , raise fears of loss of privacy and autonomous decision -making to algorithms . That ’ s why today ’ s technology -fuelled advertising ecosystem toda y is frequently painted in colour tones of the classic westerns : with dark shades of lawlessness and tinted principles of ethics . Which brings us to the gates of Deadwood : one of the hometowns of settlers , who were caught by the “ Gold Fever ” and rushed acr oss the oceans in pursuit of wealth . The legends of the town have recently been brought back to life on our screens with movie magic an d impeccable storytelling that depict the essence of the chaotic spirit of the wild west , thereby offering an interesting allegory for the debates on technology and market developments that we are having today . 576 Disclaimer : the views expressed in this paper are those of the auth or and do not necessarily reflect the official policy or position of any other organi sation , company , or individual mentioned in the text . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 120 Where do we find AI in advertising nowadays ? What are the ethical principles behind harnessing people ’ s personal data and adopting automated technologies for marketi ng purposes ? What are the risks and benefits of using the power of algorithms in creating , delivering and monitoring the ads ? These and other questions will be investigated in this paper through the prism of existing market practices and policy frameworks , as well as explored through the prism of targeted qualitative interviews conducted with experts working in the AI and advertising fiel ds ( including practitioners from the advertising agencies and tech companies ; independent analysts ; and experts in data p rivacy law and advertising self -regulation ) . The first part will look at the key applications of AI in advertising and will discuss how various machine learning tools help to better target , optimise and even design commercial communications . The second cha pter will present the most prominent concerns and issues , which are linked to machine learning applications in marketing , and will inve stigate the safeguards which are ( or should be ) in place to mitigate them . The third part will explore how technologies a re being used to harness the power of data for good causes , such as protecting consumers from bad ads , and how AI is potentially going to shape the advertising regulatory field in the future . The paper will conclude on the relationship between AI and adve rtising through the lens of the earlier introduced wild west metaphor . The last part will summarise the arguments by discussing similar ities and differences between the historic gold rush era and the data rush phenomenon put forward by the author , and will ask a final question : are we about to enter a virtual Deadwood ? 6.2 . AI in advertising : From tracing online footprints to writing ad scrip ts “ There is no data like more data ” is a well -known quote attributed to Rober t Mercer,577 frequently used to emphasise the essential role of data in developing and adopting AI algorithms in different industries and human activities . AI use in advertising e cosystems is not an exception . From crunching personal data in tailoring the delivery of ads based on user preferences and browsing history in a split second , to training algorithms to recognise patterns in vast volumes of historic and contextual data ( and ultimately create new content ) , AI and machine learning techniques in advertising are applied broadly and for a variety o f purposes . This first chapter will investigate the main use of AI in the advertising ecosystem today , and will discuss how such advan ced algorithms have been transforming the ad industry . 577 Lee , K.F. , AI Superpowers : China , Silicon Vall ey , and the New World Order , Houghton Mifflin Harcourt , Boston . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 121 6.2.1 . Programmatic advertising : The stock market of ads and data Accordi ng to the Interactive Advertising Bureau ( IAB ) , most of the growth of AI in marketing today is attribute to programmatic advertising , which is the use of AI and other machine learning technologies to buy and optimise advertising in real -time , with the goal of increasing efficiency and transparency for both the advertiser and the publisher.578 In programmatic advertising , AI is used in ad planning , placement , automatic adjustment , optimisation and campaign metrics.579 The key elements of programmatic advertising are outlined in the “ programmatic advertising glossary ” in the table below . Table 1 . Programmatic advertising glossary ◼ Real-time bidding ( RTB ) ◼ Real-time bidding is a way of buying and selling online ads on a case -by-case basis through real time auctions that occ ur in the time it takes a webpage to load on a user ’ s browser ( i.e . around 100 milliseconds ) . During this time , the inform ation about the page where an ad will be placed and the user loading it passes through an ad exchange , which auctions it off to the ad vertiser willing to pay the highest price for it , and the winning bidder ’ s ad is then loaded into the webpage.580 RTB allow s advertisers to target better and quicker , enabling ads which , for example , only show X brand ’ s ads to users who previously visited X brand ’ s website but didn ’ t make a purchase . Advertisers bid based on their interest and how the data about the user measu res up against their targeting parameters : the higher the ‘ match ’ , the higher the price.581 ◼ Ad exchange ◼ An ad exchange is essentially a stock market for programmatic advertising , and it is where ad inventory ( i.e . ad space ) gets auctioned . It ’ s a virtual platform where publishers meet advertisers , are matched and agree on a price to display their ads , which all happens in milliseconds , du e to automated technology . Unlike ad networks , which used to focus on pre -packaged ad inventory , an ad exchange focuses on audience metrics.582 It sits in the middle of the programmatic ecosystem , plugged into respective platforms on both the advertiser ’ s an d the publisher ’ s side . ◼ Demand -side platform ( DSP ) ◼ A demand -side platform is a tool or software programme that allows advertisers to 578 Rask , O. , What is Programmatic Advertising ? The Ultimate 2020 Guide , Match2One , https : //www.match2one.com/blo g/what -is-programmatic -advertising/ . 579 IAB ( 2019 ) , Artificial Intelligence in Marketing Report , IAB Data Center of Excellence , https : //www.iab.com/insights/iab -artific ial-intelligence -in-marketing/ . 580 Marshall , J. , WTF is real -time bidding ? , Digiday , https : //digiday.com/media/what -is-real-time-bidding/ . 581 SMAAT O , Real-Time Bidding ( RTB ) : The Complet e Guide , SMAATO , https : //www.smaato.com/real -timebidding/ . 582 IAB Europe ( 2017 ) , The advent of RTB , IAB Europe , https : //iabeurope.e u/blog/laypersons -programmatic/ . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 122 buy ad placements automatically . Advertisers sign up with a DSP , which is in turn connected to an ad exchange.583 When a us er triggers a website that is connected to the ad ex change , an auction signal is sent to the exchange . The exchange then asks the DSP if the advertiser has any ads that might fit the placement and , if so , the bid for an ad space in sent back to the auction in real time . A winning bidder gets to show their a d to the website visitor.584 ◼ Supply -side platform ( SSP ) ◼ On the other side , publishers use a supply -side platform to manage their ad space . The SSP connects to an ad exchange and makes clear what kind of i nventory is available . Through RTB this inventory i s automatically auctioned off to the highest bidder . While a DSP ’ s purpose is to buy programmatic ad space as cheaply as possible from publishers with desirable inventory , the SSP has the opposite function : selling ad space for the highest possible price , connecting to several different ad exchanges in order to maximise the publisher ’ s exposure to potential buyers.585 Although programmatic advertising is mostly referred to in the context of online digital channels , including display , mobile , video and social media , programmatic ad purchasing has also found its way into traditional media , including TV586 , and even to digital out -ofhome billboards and signage,587 where powerful algorithms paired with mobile locat ion data and visual sensors enable ad placem ent on digital screens at bus stops , which can now focus on specific targets - young commuters in the morning rush hour , for example . 6.2.1.1 . The AI role in programmatic advertising All key elements involved in the prog rammatic advertising value chain highlight t he crucial role of machine learning applications in this process , which allow ad selection and placement decisions to happen in the blink of an eye , rendering AI inseparable from the notion of programmatic advert ising itself . These sophisticated , automated technologies permit all market actors to enjoy numerous speed - , efficiency - and predictive analysis -based advantages . Overall , these 583 Rask , O. , op.cit . 584 Wang , J. , Zhang W. & Yuan , S. , Display Advertising with Real -Time Bidding ( RTB ) and Behavioural Targeting , ArXiv , https : //arxiv.org/abs/1610.03013 . 585 Rask , O. , op.cit . 586 Although advanced , beyond broad demographic -based audience measurement issues are still named among the key challenges in transforming traditional linea r TV advertising buying into programmatic , some station groups are nevertheless beg inning to embrace impression based TV ad buying , with some companies working to standardize advanced TV audience segments and opening up more addressable broadcast TV invent ory . See Blustein , A. , The programmatic TV dream is edging closer to reality , The D rum , Carnyx Group Ltd , https : //www.thedrum.com/news/2020/02/19/the -programmatic -tv-dream -edging -closer -reality . 587 Côté , R. , What is programmatic DOOH ? , Broadsign , 2020. https : //broadsign.com/blog/what -is-programmatic digital -out-of-home/ ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 123 broad benefits are summed up in the following key objectives of AI in programm atic advertising today:588 ◼ Personalisation of ads , where AI and machine learning can take real -time behavioural data from consumers and serve highly tailored and relevant ads , based on attributes such as age , gender , location and millions of other data point s. The process is powered by strong predict ive algorithms helping to determine which consumers are likely to engage with advertisers ’ commercials . ◼ Audience targeting , where leveraging AI , marketers can scan through content on the Internet and determine whi ch ads are best suited for particular audie nces or channels . Through the use of image recognition , these systems also help place ads correlated with images that can be found on the page of an article or website.589 Moreover , when set up correctly , AI is able to continuously evolve the audience based on actual performance , and expand it to other segments that may share the same purchasing behaviour.590 ◼ Performance optimisation , where machine learning algorithms can automatically analyse how ads are performing ac ross specific platforms and offer recomme ndations . These AI systems are also able to track the metrics not only of the advertiser ’ s campaigns but also those of the advertiser ’ s competitors . They have built -in ‘ situational awareness ’ , which allows machine l earning algorithms to adjust quickly , shi fting ad spend to alternate channels and changing advertising messages to reflect market patterns and consumer behaviours.591 ◼ Media mix modelling , where AI is used to identify consumers most receptive to their campaig ns on different media channels , thus inc reasing digital advertising return on investment ( ROI ) . AI can continuously issue recommendations on how to refine the media mix ; brands and agencies can therefore completely automate their marketing mix allocation — saving valuable time and money . To summ arise , AI and machine learning allow advertising ecosystem players to analyse huge volumes of data in real -time , tailoring messages through AI -enabled hyper personalisation , and to find the best times and channels to communicate . Therefore , it comes with n o surprise that over 80 % of surveyed advertising executives and early adopters of AI , reported positive ROI for their AI initiatives and strong intentions to increase such investment in the future.592 588 IAB ( 2019 ) , op.cit . 589 Schmelzer , R. , AI Makes A Splash In Advertising , Forbes , https : //www.forbes.com/sites/cognitiveworld/2020/06/18/ai -makes -a-splash -in-advertising/ # 24c0287c7682 . 590 Rowan , M. , The Impact of Art ificial Intelligence in Advertising , AW360 , https : //www.advertisingweek360.com/the -impact -of-artificial -intelligence -in-advertising/ . 591 Schmelzer , R. , op.cit . 592 Deloitte , State of AI in the Enterprise , 2nd edition , the Deloitte AI Institute , Deloitte , https : //www2.deloitte.com/us/en/insights/focus/cognitive -technologies/state -of-ai-and-intelligent automation -in-business -survey.html . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 124 6.2.2 . Algorithmic crea tivity : AI dipped in the ink of imagina tion “ Being creative can be quite similar to having the sword of Damocles hanging above your head “ - many ad script creators struggling with approaching deadlines , too many ideas and too little time , would probably ag ree with these words of apparent hyperb olised wisdom . Except , the phrase was not uttered by an ad executive , but was in fact produced by InspiroBot – an AI software programme “ dedicated to generating unlimited amounts of unique inspirational quotes '' , which has been trained to create random phra ses based on countless inspiring lines found on the Internet . Although the ‘ sword of Damocles ’ example is a fun one created by AI in the preparation of this paper , the actual application of AI in the creation of ads is much more advanced . AI -powered syste ms can already partially or fully design ads , leveraging natural language processing ( NLP ) and natural language generation ( NLG ) , two AI -powered technologies used to write ad copy.593 Moreover , computer vision , paired w ith image recognition technologies , promises a future where users can ‘ shazam ’ 594 any video content or picture and instantly match it with existing promotions . Some tech -powered companies already provide AI -based solution s to generate images for marketing pu rposes . Usually supported by machine learning technologies falling into the category of Generative Adversarial Networks ( GANs ) , such companies are able to generate ‘ artificial models ’ increasingly difficult to distingui sh from real people,595 and can create faces for a marketer ’ s advertising campaigns , easily adaptable to fit different audiences and demographics . Moreover , although mouse clicks are the essential driving force for digital marketing , AI is possibly bringin g in a new advertising trend : the era of Voice.596 According to 2019 data , 89 % of surveyed marketing professionals believed that voice assistants would be a significant marketing channel over the coming three to five years , with over one third of respondents calling them an “ extremely important channel ” .597 Alexa , Siri , Google Home and other devices and voice assistants popularised interactive voice interfaces and paved the way for conversational voice advertising . Powered by AI and 593 Kaput , M . , AI for Advertising : Everything You Need to Know , Marketing AI Institute , https : //www.marketingaiinstitute.com/blog/ai -in-advertising . 594 Based on Shazam Entertainment Ltd - a mobile application which can identify music , movies , advertising , and television shows , based on a short audio sample played ; other types of image recognition -based apps have been prototyped in the industry , such as Smartify ( available at https : //smartify.org/about -us ) – Shazam for art and museums . 595 Gonfalonieri , A. , Integration of Generative Adversarial Networks in Business Mo dels , A Medium , Towards Data Science , https : //towardsdatascience.com/integration -of-generative -adversarial -networks -in-business -models47e60263aec4 . 596 Tushinskiy , S. , Voice is the New Click : Why Voice Commands Will Replace the Click as the Standard Measure for Brands , Medium , Instreama tic , https : //medium.com/ @ instreamatic/voice -is-the-new-click-why-voice commands -will-replace -the-click-as-the-standard -measure -for-61225e4e7caa . 597 Kinsella , B. and Mutchler , A . ( 2019 ) , The State of V oice Assistants as a Marketing Channel Report , Voicebot.ai , https : //voicebot.ai/the -state -of-voice -assistants -as-a-marketing -channel -report/ . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 125 harnessing speec h recognition and natural language understanding , they offer new ad formats for marketers , publishers , and consumers . According to Charlie Cadbury , the CEO of Say It Now598 , the five most exciting trends in voice include : various service providers empoweri ng voice assistants ( e.g . managing food delivery ) ; improved discovery of third -party skills and name -free skill invocation in voice assistants ; voice commerce ; digital interactive audio engagement ; and location aware voice services , delivered in cars or ea r buds . Asked for a “ moon -shot ” idea for voice adve rtising application , Cadbury noted that the “ clue is in the ‘ voice assistant ’ ” , where he wants to see consumers treating their digital assistants like a real aid in their life , trusting their advice and me aningfully delegating tasks . 6.2.3 . From creative games to gains Some of the world ’ s top advertisers have already invested in AI -enhanced creative processes , delivering noteworthy results and ad campaigns which have captured consumers ’ attention , and made media headlines . The campaigns and brand -agency partners hips presented in table 2 Error ! Reference source not found . provide a selection of cases where AI tool s were used for creative marketing purposes and resulted in the production of advertising content at least partial ly designed by automated technologies . Kerry Richardson , one of the co -founders of Tiny Giant599 , believes that consumers will soon see more cr eative applications for AI , and more cases of humans and creatives working together to create campaigns , where agen cy creatives will think of an idea or concept and then use AI tech to help execute it . Table 2 . Advertising and marketing campaigns enabled by creativ e AI technologies ◼ Lexus in partnership with IBM 's Watson , The & Partnership London and Visual Voice 600 ◼ This particu lar Lexus commercial is the first TV ad entirely scripted by AI . Using a number of data points as input , including 15 years ' worth of Cannes Lion award winning ads and 10 years of the best ads in the ‘ luxury ’ sector , as well as points relating to ‘ intuitio n ’ and how people make decisions , IBM Watson technology identified elements common to award -worthy commercials.601 An AI engine then formed the script flow and outline . The creators themselves expressed surprise over 598 Charlie Cadbury from Say It Now ( available at https : //www.sayitnow.ai/ ) was interviewed o n 19 June , 2020 for the purposes of this paper . 599 Kerry Richardson from Tiny Giant ( available at https : //www.tinygiant.io/ ) was interviewed on 22 June , 2020 for the purpose s of this paper . 600 The ad campaign can be viewed at Variety.com . Available at https : //variety.com/2018/digital/news/lexus ai-scripted -ad-ibm-watson-kevin -macdonald -1203030693/ . 601 Spangler , T. , F irst AI -Scripted Commercial Debuts , Directed by Kevin Macdonald for Lexus , Variety , https : //variety.com/2018/digital/news/lexus -ai-scripted -ad-ibm-watson - kevin -macdonald -1203030693/ . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 126 the fact that instead of the expected “ ma d and weird ” output , they received the narrative with a footnote to every single line with a data point , explaining why the decision had been made.602The result was a rather perplexing story of a Lexus engineer putting the finishing touches on a new model , a self-aware car and a televised crash test , but it proved that machine -written creative copy is more than a distant possibility . ◼ Malaria No More in partnership with RG/A , Ridley Scott Associates and Synthesia603 ◼ In the “ Malaria Must Die ” campaign , David Be ckham lends his voice to the fight against malaria for non -profit organisation Malaria No More , in its battle to eradicate the mosq uito-borne disease . The novel campaign depicts Beckham apparently fluently speaking in nine languages as he invites listeners to get involved.604 As he shifts between different languages , Beckham ’ s various voices are actually those of malaria survivors whos e features have been digitally mapped onto those of the famous sportsman with the help of AI -powered video synthesis technolog y.605 ◼ Deutsche Bahn in partnership with Ogilvy Germany , Frankfurt , Getty Images and Spirable606 ◼ Deutsche Bahn , the German rail com pany , launched a campaign encouraging domestic travel using photos of German locations that mirror famous world tourist destinat ions . The “ No Need To Fly ” campaign invites Germans to enjoy the benefits of cheaper train travel . It used AI to identify German locations resembling iconic world landmarks . Then , using Facebook data , it targeted travel enthusiasts and local influencers wi th dynamic video ads including the real -time juxtaposition of travel costs associated with international landmarks and their Ger man counterparts.607 ◼ Cheltenham Science Festival in partnership with Tiny Giant608 ◼ “ AIDA : AI Science Festival Curator ” , an AI -gene rated festival curator for the Cheltenham Science Festival , took 10 years of festival talks as a dataset , trained it on a recurrent neural network , and generated around 800 new potential talks for the festival.609 AIDA ’ s suggestions were submitted to a Twitt er poll for the world to select a winner . The talk on “ Introvert Narwhals ” was delivered during the event by 602 Faull , J. , Lexus reveals ad ‘ created b y AI ’ . Is it a gimmick ? No . Will it win any awards ? Probably not , The Drum , Carnyx Group Ltd , https : //www.thedrum.com/news /2018/11/16/lexus -reveals -ad-created -ai-it-gimmick -nowill-it-win-any-awards -probably -not . 603 The ad campaign can be viewed at TheDrum.com . Available at https : //www.thedrum.com/news/2019/04/09/david -beckham -lends -his-voice -malaria -ai-petition .. 604 Butcher , M. , The startup behind that deep -fake David Beckham video just raised $ 3M , TechCrunch , https : //techcr unch.com/2019/04/25/ . 605 Glenday , J. , David Beckham lends his voice to Malaria AI petition , The Drum , Carnyx Group Ltd. , https : //www.thedrum.com/news/ 2019/04/09/david -beckham -lends -his-voice -malaria -ai-petition . 606 The ad campaign can be viewed at wersm.com . Available at https : //wersm.com/how -deutsche -bahn increased -sales -by-24-thanks -to-instagram/ . 607 Desreumaux , G. , How Deutsche Bahn Increased Sales By 24 % Thanks To Instagram , Wersm , https : //wersm.com/how -deutsche -bahn -increased -sales -by-24-thanks -to-instagram/ . 608 The ad campaign can be viewed at TinyGiant .io . Available at https : //www.tinygiant.io/case -study -one-aida . 609 Tiny Giant , AI Festival curator Cheltenham Science Festival , Tiny Giant , https : //www.tinygiant.io/case -study-one-aida . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 127 AIDA , whose actual audio voice was created using deep learning to turn input text into a nuanced , human -sounding voice . AIDA proved a great success , and later appeared on BBC Radio , and was also honoured with the Data & Marketing Association gold award for best use of AI in 2019.610 ◼ JPMorgan Chase ; ongoing partnership with Persado ◼ In 2019 , JPMorgan Chase announced a five -year , enterprise -wide deal wi th Persado , one of the leading agencies in the use of AI , to generate high -performing marketing creatives . Their successful pilot proved that that AI -enabled marketing copy is highly effective , delivering a lift of up to 450 % in click -through rates on ads rendered by Persado , compared with others in the 50 -200 % range.611 Persado ’ s proprietary technologies were used to rewrite copy and headlines based on an advanced marketing language knowledge base of more than one million tagged and scored words and phrases . Through the tool , JPMorgan Chase redrafted marketing messages in its card and mortgage businesses , to create th e most compelling message possible for individuals and targeted groups of customers.612 6.2.3.1 . “ Virtuality ” of influencer marketing : A case study Lil Mi quela is a musician streaming music on Spotify , a designer who owns her clothing brand , a model working with luxury fashion brands and a social media star with over 2.4 million followers on Instagram.613 She presents herself as “ Musician , change -seeker and robot ” – a computer -generated ( CGI ) character and a first world -famous virtual influencer . Although Lil Miquela isn ’ t truly an AI creation , she has inspired companies to invest heavily in virtual humans and envision future digital beings completely powered by AI and existing autonomously on social media platforms.614 With production of high quality 3D models becoming more affordable , some creators are already envisioning virtual humans ‘ living ’ their own lives without any human involvement – from posting 610 Data & Marketing Association , Gold Best Use of AI , Data & Marketing Association Awards , https : //dma.org.uk/awards/winner/2019 -gold-best-use-of-ai . 611 Persado , JPMorgan Chase A nnounces Five -Year Deal with Persado For AI -Powered Marketing Capabilities , Persado , https : //www.persado.com/p ress-releases/jpmorgan -chase -announces -five-year-deal-with-persado for-ai-powered -marketing -capabilities/ . 612 Business Wire , JPMorgan Chase Announcement Concerning Pref erred Stock , Business Wire , https : //www.businesswire.com/news/home/20191031005537/en/JPMorgan -Chase -Announcement -Preferred Stockl . 613 As of 1 July , 2020 . 614 Alexander , J. , Virtual creators aren ’ t AI — but AI is coming for the m , The Verge , Vox Media , https : //www.theve rge.com/2019/1/30/18200509/ai -virtual -creators -lil-miquela -instagram -artificial intellig ence . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 128 pictu res or videos , and the captions that go with them , to interacting with their followers.615 While the id ea of virtual humans , empowered by machines , is not new , the “ proliferation of smartphones and the popularity of image sharing sites such as Instagram have accelerated our awareness of these virtual humans and elevated them to a position of influence , ” say s Scott Guthrie616 , an independent influencer marketing consultant and analyst . The fashion industry was first to embrace the potential benefits of virtual m odels : synthetic humans do not need beauty regimes , adjusted clothing sizes or multiple takes at a photoshoot ; they always show off the sponsoring -brand garments in the best possible way , always turn up on time and always deliver content adhering to the br ief.617 6.2.3.2 . Real dangers in artificial reality Despite their virtual nature , digital beings are raising real concerns , foremost among them : transparency . Rupa Shah , founder of Hashtag Ad Consulting618 , notes that deployment of advanced technologies means it is bec oming increasingly difficult to distinguish virtual influencers by sight alone . Attention to detail in the rendering of every image allows them to appear in any context or scene , at any destination , to achieve the brand ’ s desired narrative , and NLP makes t heir communication feel natural and responsive . Advertising self -regulatory codes , enfor ced by ad standards bodies across Europe , already require that all commercial communications must be immediately and unambiguously identifiable , using appropriate disc losure.619 However , these rules will arguably need to be extended to virtual influencers , additionally requiring their owners and creators to inform consumers about their virtual nature – which is under the complete control of a brand . Dudley Neville -Spence r , director and head of data analysis at the Virtual Influencer Agency620 , agrees that vi rtual influencers can exacerbate already -existing issues 615 Bradley , S. , Even better than the real thing ? Meet the virtual influencers taking over your feeds , The Drum , Carnyx Group Ltd , https : //www.thedrum.com/news/2020/03/20/even -better -the-real-thing -meet -the-virtual influencers -taking -over-your-feeds . 616 Scott Guthrie616 , an influencer marketing management consultant , event speaker and blogger . Aavailable at https : //sabguthrie.info/ . Interviewed on 22 June , 2020 for the purposes of this paper . 617 Guthrie , S. , “ Virtual Influencers : More Human Than Human ” , Ch . 15 in Yesiloglu , S. and Costello , J . ( ed . ) , Influencer Marketing : Building Brand Communities and Engagement , Routledge , London . 618 Rupa Shah from Hasht ag Ad Consulting . Available at : https : //www.hashtaga d.co.uk/ ) . Interviewed on 22 June , 2020 for the purposes of this paper . 619 European Advertising Standards Alliance , Best Practice Recommendation on Influencer Marketing , EASA , https : //www.easa -alliance.org/products -services/publications/easa -best-practice -guidance . 620 Comments from Dudley Neville -Spencer , director and head of data analysis at the Virtual Influencer Agency and strategy & insights director at Live & Breath , are taken from a live online webinar hosted by Persollo on 30 June , 2020 , see Persollo , Ethics , Influencers and Growth , Persollo Webinar 3 , 30 June 2020 , https : //www.blog.persollo.com/post/persollo -webinar -3-ethics -influencers -and-growth . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 129 in influencer marketing and advocates for a special watermark for virtual beings.621 He is working alongside Shah to develop a virtual influencer code of ethics , with a focus not just on transparency , but also on other areas of social responsibility , such as body image and diversity . Many prominent voices in the industry have expressed concern that virtual influencers may lead to problems of self -esteem and mental health , related to harmful human portr ayal and idealised , unrealistic beauty standards.622 Shah adds that regulators should be ready for this , and prepared to tackle any concerns consumers may have . 6.2.3.3 . The future of virtual influencers Globally , the influencer market is growing fast , and is predi cted to expand to USD 9.7 billion in 2020.623 AI is not only used to create virtual influencers , it is also adopted in the selection and evaluation phases of influencer mark eting , helping brands identify the most appropriate social media influencers for pot ential campaigns and vet them ( e.g . checking for potentially fraudulent follower numbers ) . Guthrie believes further technology advances will allow virtual influencers to become “ unshackled ” from pre -scripted animation paths , and freely interact and learn from each human conversation . He also predicts that in the future the subgenre of virtual influencers will splinter into at least three smaller categories : virtual brand ass istants ( virtual humans designed and operated by a brand , driven entirely by a brand ’ s purpose ) ; customer service representatives ( virtual beings functioning as chatbots , but with human like emotions and body form ) ; and virtual influencers ( virtual human i nfluencers either owned by a sponsoring brand or operating in their own right ) . Finally , as virtual influencers continue to evolve , the audiences will decide how quickly they are ready to embrace digital avatars in their social media feed and engage with them . Perhaps some experts ’ predictions that there wo n't be a brand without some sort of virtual representative will become true in the near future.624 6.2.4 . Conclusion : AI enabled intelligent advertising Intelligent advertising is said to be a third phase and a n ew frontier of digital advertising , building on interactive and programmatic market ing.625 It builds on interactivity and automation from the previous phases , but adds new attributes , such as personalisation that goes beyond a user ’ s interests , and shifts to wards predicting their needs in various 621 Persollo , op.cit . 622 Bradley , S. , op.cit . 623 Influencer Marketing Hub , The State of Influencer Marketing 2020 : Benchmark Report , Influencer Marketing Hub , https : //influencermarketinghub.com/influencer -marketing -benchmark -report -2020/ . 624 Persollo , op.cit . 625 Li , H . , “ Special Section Intro duction : Artificial Intelli gence and Advertising ” , Journal of Advertising , Aug/Sep2019 , Vol . 48 Issue 4 , p . 333-337 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 130 contexts and time -frames , issuing highly i ndividualised commercial content in real -time and at scale.626 It merges programmatic buying and programmatic creativity techniques , and opens the door to uniquely tailored adv ertising experiences that promise to be even more relevant and useful content . However , for intelligent advertising to be effective and earn consumer trust , it can not be sealed in a non -transparent black box which generates promotional messages based on i llegitimately collected user data and unfair algorithms . The next part of this chapter will therefore investigate challenges related to AI in advertising and discuss necessary safeguards . 6.3 . Concerns regarding Big Data and AI Most uses of AI in advertising t oday rely on algorithms and large datasets containing information about users ’ ch aracteristics and personal preferences , and serving up tailored , ’ hand -picked ’ commercial content.627 Naturally , such an optimisation process raises ethical and legal challenges , particularly those regarding privacy and biased algorithms . This chapter will therefore look into existing legal safeguards protecting citizens and consumers from potential harms related to issues of data protection and automated decision -making . Althoug h this part will focus on the European context , it should be noted that policies addressing privacy and data protection issues exist also elsewhere in the world and could be the subject of a similar analysis.628 Scholars have argued that good privacy legisl ation in the age of AI should protect consumers from potential AI -based discrim ination , lack of consent , and data abuse , and should include several key components : a requirement for transparency , so that AI has a deeply rooted right to the information it i s collecting ; an opt -out for consumers ; data collected and the purpose of the A I limitation by design ; and the option for data deletion by consumer request.629 Civil society groups have also been calling for “ clear red -lines for impermissible use , democratic oversight , and a truly fundamental rights -based approach 626 Chen , G , et . al , “ Understanding Programmatic Creative : The Role of AI ” , Journal of Advertising , Aug/Sep2019 , Vol . 48 Issue 4 , 347-355 . 627 Lee , K. F. , op.cit . 628 For e xample , the California Consumer Privacy Act ( CCPA ) , which introduces new consumer rights around businesses ’ use , deletion , withdrawal and access to personal information ( see Paka , A. , How Does The CCPA Impact Your AI ? , Forbes Technology Council , F orbes , https : //www.forbes.com/sites/forbestechcouncil/2020/02/20/how -does-the-ccpa-impact -yourai/ # 7d 27ce7c43c7 ) , or the Act on Protection of Personal Information ( APPI ) in Japan , which is expected to be further amended in 2020 with introduction and promotion of pseudonymised data in the context of feeding the AI , see GLI , AI , Machine Learning & Big Data Laws and Regulations Japan , Global Leg al Insights , https : //www.globallegalinsights.com/practice -areas/ai -machine -learning -and-big-data-laws-andregulations/japan . See also Chapter 2 of this publication . 629 Intel AI , Rethinking Privacy For The AI Era , Forbes , Insight team , https : //www.forbes.com/sit es/insights -intelai/2019/03/27/rethinking -privacy -for-the-ai-era/ # 693cda737f0a . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 131 to AI regulation ” , to create a trustworthy AI system.630 Although the scope of this paper is limited to automated technology use in marketing , the human rights approach , particularly in relation to th e right to privacy and data protection ( Art . 8 , ECHR ) and the prohibition on discrimination ( Art . 14 , ECHR ) are also worth taking into account , especially concerning the ways in which collected personal data can be ultimately repurposed and how algorithms built with intentional and non -intentional bias might lead to segmentation and differentiated treatment of targeted social ( or consumer ) groups.631 Finally , scholars have also warned of “ power asymmetry between those who develop and employ AI technologies , a nd those who interact with and are subject to them ” .632 Taking these issues into account , the following section will look into existing accountability and responsibility mechanisms to address and mitigate these risks . 6.3.1 . Existing legal framework in Europe In February 2020 , the European Commission published a white paper proposing a strategy to ensure the successful uptake of AI in the European Union via an appropriate policy and regulatory framework and the creation of an “ Ecosystem of Excellence and Trust ” .633 The white paper pointed to a strict legal framework in the EU , which already ensures inter alia consumer protection , addresses unfair commercial pract ices and protects personal data and privacy , notably the “ General Data Protection Regulation and other sec torial legislation covering personal data protection , such as the Data Protection Law Enforcement Directive ” .634 Although the GDPR does not refer to AI specifically , it is set up in a technologically -neutral manner , to face any technological change or evolut ion , and therefore fully captures the processing of personal data through an algorithm.635 Furthermore , even AI systems that rely on anonymised data m ay still be subject to GDPR regulation , since some anonymisation techniques are not necessarily able to annu l the risk of re -identification.636 Furthermore , according to an assessment by the European Data 630 EDRi , Can the EU make AI “ trustworthy ” ? No – but they ca n make it just , EDRi , https : //edri.org/can -the-eu-make -ai-trustworthy -no-but-they-can-make -it-just/ . 631 Wagner , B. , Study On The Human Rights Dimensions of Autom ated Data Processing Techniques ( In Particular Algorithms ) And Possible Regulatory Implications , Council of Europe , Committee of Experts on internet intermediaries ( MSI -NET ) , https : //rm.coe.int/study -hr-dimension -of-automated -data-processing -inclalgorithms/16807 5b94a . 632 Yeung , K. , Responsibility and AI , Council of Europe study DGI ( 2019 ) 05 , Council of Europe , Expert Committee on human rights dimensions of automated data processing and different forms of artificial intelligence , ( MSI AUT ) , https : //rm.coe.int/responsability -and-ai-en/168097d9c5 . 633 European Commission , White Paper On Artificial Intelligence - A European approach to excellence and trust , Brussels , 19.2.2020 , COM ( 2020 ) 65 , https : //ec.europa.eu/info/publications/white -paper -artificial -intelligence european -approach -excellence -and-trust_en . 634 European C ommission , op.cit . 635 European Data Protectio n Board , EDPB Response to the MEP Sophie i n't Veld 's letter on unfair algorithms , EDPB , https : //edpb.europa.eu/our -work-tools/our -documents/letters/edpb -response -mep-sophie -int-velds letter -unfair -algorithms_en 636 Zaccaria , E. , Artificial Intelligence : addressing the risks to data privacy and beyond , PrivSec Report , https : //gdpr.report/news/2020/06/01/artificial -intelligence -addressing -the-risks-to-data-privacy -and-beyond/ . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 132 Protection Board ( EDPB ) , a “ risk based approach , the data minimisation principle and the requirement of data protection by design and by default ” , as well as pro visions regarding accountability , transparency and the prohibition of any decision -making based solely on automatic processing , make the current le gal framework suitable to address many of the potential risks and challenges associated with the processing o f personal data through algorithms.637 Finally , a report on the impact of GDPR on artificial intelligence , published in June 2020 by the European Pa rliamentary Research Service ( EPRS ) , concludes that GDPR “ provides meaningful indications for data protection in the context of AI applications ” , and that data “ controllers engaging in AI -based processing should endorse the values of the GDPR and adopt a r esponsible and risk -oriented approach ” .638 Geraldine Proust , director for policy at the Federation of European D irect and Interactive Marketing ( FEDMA ) 639 , who shared her expertise on data protection laws in the EU , concurs , saying that the GDPR does indeed provide principles that protect personal data processed by technologies using AI , and that it requires that orga nisations be accountable , and that they not only respect these principles , but also be able to demonstrate that they are respecting them . Proust also points out that “ organisations must process only necessary , adequate and accurate personal data ” . She adds : “ Moreover , the processing must be fair , transparent , lawful and for a legitimate purpose . If the purpose may be achieved without personal data , an alternative approach must be taken , for example the data can be anonymised ” . This calls for IT experts , man agers and data protection officers to work together as early as possible in the marketing creative process , to achieve the right balance between innovation and ethics . The EDPB also stated that considering the already extensive existing legal framework , th e focus should be on the development of existing norms , accountability and Data Protection Impact Assessments ( DPIAs ) in the context of machine learning algorithms . Proust supports such an approach and thinks that current legislation should be properly imp lemented and assessed first , and that any new laws “ must be balanced to avoid hindering the development and use of this technology and aligned w ith data protection legislation to avoid contradictions ” . Guidelines issued by relevant authorities could be a good way to provide additional clarity and advice for the application of specific legal requirements , where necessary . A recent EPRS report emph asises the need for such guidance , stating that controllers and data subjects “ should not be left alone ” and sho uld be “ provided with guidance on how AI can be applied to personal data consistently with the GDPR ” .640 The authors of the EPRS report call for a multilevel approach and for institutions to actively engage in broad societal debates with all stakeholders , in cluding controllers , processors , and civil society , in order to develop appropriate responses and high -level indications 637 European Data Protection Boa rd , op.cit . 638 European Parliamentary Researc h Service ( 2020 ) , The impact of the General Data Protection Regulation ( GDPR ) on artificial intelligence , Study , European Parliamentary Research Service , Scientific Foresight Unit ( STOA ) , PE 641.530 , https : //www.europarl.europa.eu/RegData/etudes/STUD/2020/641530/EPRS_STU ( 2020 ) 641530_EN.pdf . 639 Geraldine Proust from FEDMA . Available at : https : //www.fedma.org/ . Interviewed on 7 July , 2020 for the purposes of this paper . 640 European Parliamentary Research Service , op.cit . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 133 “ based on shared value s and effective technologies ” .641 To this end , several useful guidance documents have already been published by the European institutions , including the European Commission , Council of Europe and the EDPB,642 as well as by industry stakeholders.643 Many more are likely to be introduced in the coming years and together with the regulatory and self -regulatory instruments the y will hopefully be useful tools contributing to the overall success of AI adoption , consumer protection and trust in technologies . 6.3.2 . Conclu sion : ( Mostly ) the Good , the Bad and the Ugly The response to existing key concerns over the use of AI in marketing fit well into the borrowed frame of the famous Sergio Leone western entitled : “ The Good , the Bad and the Ugly ” . Overall , there is mostly goo d news , relating to the fact that the legislation and policy guidelines existing today provide a solid framework to build sustainable AI systems for advertising which safeguard human rights and protect consumers ’ interests without hampering further innovat ion . Moreover , businesses , from global tech corporations to start-ups , appear to have reevaluated the long-term bene fits of consumer trust , and are calling for a human -centric approach in designing and applying AI , from its functioning , sensing , cognitive and learning abilities,644 to considerations on how it affects end -users ( micro approach ) , as well as society and the ethical environment in general ( macro approach ) . Dutch company DEUS calls it a “ humanity -cantered ” approach in marketing , where it is parti cularly relevant , because advertising addresses people ’ s needs , desires and , frequently , pressure points leading thro ugh their purchasing journeys . As consumers become more aware of the use of their data in advertising and eager to know even more,645 it app ears inevitable that the topic of the ethical use of AI in marketing will 641 European Parliamentary Research Service , op.cit . 642 For example Guidelines on Artificial Intelligence and Data Protection ( 2019 ) by the Consultative Committee of the Convention for the Protection of Individuals with regard to the Processing of Personal Data ( Convention 108 ) . Available at https : //rm.coe.int/guidelines -on-artificial -intelligence -and-data-protection/168091f9d8 . Council of Europe ; Ethics Guidelines for Trustworthy Artificial Intelligence ( 2019 ) by the High -Level Group on Artificial Intelligence , European Commission . Available at : https : //ec.europa.eu/futurium/en/ai -alliance consultation/guidelines # Top ) ; Guidelines 4/2019 on Article 25 Data Protection by Design and by Default ( 2019 ) by the European Data Protection Board . Available at https : //edpb.europa.eu/our -work -tools/public consultations -art-704/2019/guidelines -42019 -article -25-data-protection -design_en ) . 643 For example , High Level Principles on Artificial Intelligence ( 2020 ) by the European Tech Alliance ( EUTA ) . Available at http : //eutechalliance.eu/wp -content/uploads/2020/02/EUTA -High -Level -Principles -on-AI.pdf ) ; The Seven -Step Ad Tech Guide ( 2020 ) by the Data & Marketing Association ( DMA ) and the Incorporated Society of British Advertisers ( ISBA ) addressing privacy challenges of RTB in programmatic advertising . Available at https : // dma.org.uk/u ploads/misc/seven -step-ad-tech-guide -v9.pdf ) . 644 Yamakage , Y. and Okamoto , S. , Toward AI for human beings : Human centric AI , Zinrai . Fujitsu scientific & technical journal . January 2017 , Vol.53 . no . 1 , pp . 38-44 . 645 According to an EDAA survey on how EU cit izens perceive digital advertising since the adoption of the GDPR : 97 % of consumers are aware that data are used for online advertising , 62 % have some understanding ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 134 continue to be prioritised by civil society , policy -makers and responsible industry players , who all appear to agree on the need for a trustworthy AI framework . The bad news comes w ith fact that all the above -mentioned policies and strategies will only be useful as long as sufficient enforcement me chanisms are in place and there is active demand for accountability and transparency . In short , there must be resistance to desensitisatio n regarding all the data that consumers are providing in exchange for more relevant information and services . This tra nsparent exchange needs to remain a focus point at the individual and society levels . Finally , the ugly truth is that the speed of techn ological development is always likely to surpass the efforts of lawmakers regarding the application of new technologie s , for example facial recognition , thus creating new challenges . That is why it is essential to insert ethical standards into the design o f AI and other technologies used in the advertising ecosystem and beyond . As noted by all interviewed experts , technol ogy is important , but people and organisational culture are more important , and they can steer tech adoption towards any chosen ethical pr inciples . 6.4 . Using AI for intelligent ad regulation Advertising self -regulatory organisations ( SROs ) are independent ad standards bodies ensuring responsible commercial communications through self -regulation ( SR ) and enforcement of advertising codes . Based on a set of Best Practice Recommendations on Digital Marketing Communications , issued by the European Advertising Stan dards Alliance ( EASA ) ,646 all digital online advertising fall under SROs ’ remit , meaning all new or emerging digital advertising form ats and practices , such as product promotion delivered by a voice home device or through a post by a virtual influencer spons ored by a brand , are subject to the same ethical standards requiring that they be legal , decent , honest and truthful.647 Although t he primary responsibility of SROs is to ensure the compliance of ads , by handling consumer and competitor complaints and provi ding voluntary ex ante copy advice , ad standards bodies are increasingly dedicating their resources to providing tech assisted ad monitoring , particularly in the online environment , which is seeing a yearly double -digit increase in ad spend.648 In fact , in 2 019 two SROs received EASA Best Practice of how it works , and 72 % would like know more about how informati on about them is used onli ne . See European Interactive Digital Advertising Alliance , Consumer Research – How EU citizens perceive digital advertising since GDPR , EDAA , https : //www.edaa.eu/consumer -research -how-eu-citizens -perceive -digital -advertising -since -gdpr/ . 646 The EASA membership comprises 28 such SROs across Europe and 13 industry associations , representing the entire advertising value chain ( i.e . brands , agencies , media , publishers and digital platforms ) . 647 European Advertising Standards Alliance , Best Practice Recommendation on Digital Marketing Communications , EASA , https : //www.easa -alliance.org/products -services/publications/easa -best-practice guidance . 648 IAB Europe ( 2020 ) , AB Europe AdEx Benchmark 2019 Study , IAB Europe , ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 135 Awards for their use of technology in online monitoring : the ad standards body in the UK the Advertising Standards Authority ( ASA ) - won a Platinum Award for its Avatar Monitoring project , while the French SRO - Autorité de Régulation Professionnelle de la Publicité ( ARPP ) - received a Gold Award for its AI programme delivering “ Compliance as a Service ” .649 In order to foster the exchange of best practices and help scale SR tech empowered innovations and knowledge on AI and machine learning applications in the ad regulatory environment at the European level , in March 2020 the EASA established a working group on “ Data Driven SR ” . The following sections will look into ongoing SR AI projects and discuss how these , and ot her related tech initiatives , can help promote trustworthy advertising . 6.4.1 . Avatars gathering data for good In 2019 the UK ad standards body , the ASA , used avatars – automated data capture programmes , which replicated the online profiles of specific age gro ups – to monitor online display advertising of rest ricted products , such as alcohol , gambling , HFSS ( high fat , salt , or sugar ) foods and soft drinks , directed at British consumers . The avatar monitoring involved avatars representing seven different age pro files , which visited 250 websites and YouTube chann els , and related sites , chalking up a total of 196,000 page visits , and capturing information on over 95 000 ads served in a two week period – a volume impossible to attain using traditional investigative approaches.650 The exercise was the first time avata r technology had been used for regulatory monitoring in this way , and allowed the ASA to gather information on whether ads for restricted products were being inappropriately targeted at specific audiences o r served alongside inappropriate media.651 Althoug h the automated technology used in this successful pilot for automated monitoring approaches wasn ’ t employing AI systems , the ASA continues to focus on bringing machine learning algorithms into SROs ’ everyda y activities as part of their longterm Tech4Good programme , currently comprising four projects . The ASA has also employed Brandwatch technology , a machine learning -based social intelligence software programme , to discover illegal or non -compliant ads on s ocial media . In the first https : //iabeurope.eu/knowledge -hub/iab -europe -adex -benchmark -2019 -study/ . 649 European Advertising Standards Alliance , Press Release : Easa ’ s Best Practice Awards 2019 , EASA , https : //easa -alliance.org/news/easa/press -release -best-practice -awards -2019 . 650 European Advertising Standards Alliance , 2018 European Trends in Advertising Complaints , Copy Advice and Pre-clearance , EASA , https : //www.easa -alliance.org/products -services/publications/easa -statistics . 651 The Advertising Standards Authority ( 2019 ) , ASA monitoring report on HFSS ads appear ing around children 's media , The Adverti sing Standards Authority Ltd , https : //www.asa.org.uk/resource/asa -monitoring -report -onhfss-ads-appearing -around -children -s-media.html ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 136 monitoring exercise , 12 000 problem posts featuring Botox ads652 were removed over a period of three months.653 Guy Parker , the chief executive of the ASA654 , thinks AI technologies have the potential to deliver efficiencies in SROs ’ op erations and improve the effectiveness of ad regulation . “ We believe that regulators that don ’ t embrace it will be left behind ” , Parker adds . He thinks AI applications in the ad compliance field “ offer the potential to respond to the scale challenge of reg ulating online advertising ” , including “ numero us small and medium sized businesses who are not always aware of the rules and their importance. ” 6.4.2 . AI advancements for advertising compliance in France The French ad standards body , the ARPP , started using AI in its operations in 2019 , as part of its “ Compl iance as a Service ( CaaS ) ” programme . The first three projects focused on detecting industry ’ s priorities for AI use via dedicated R & D workshops , development of chatbot assistant “ Jo ” ( an interactive chatbot gu ide for requesting advertising pre clearance a nd copy advice services from the ARPP ) , and a deep -learning application for alcohol , super -imposed text , and gender representation detection and analysis in TV advertising . In early 2020 , the ARPP extended the scope of its supervised learning system for gender depiction from face detection to automatic analysis of voices and age groups , and ran an exhaustive analysis of television advertising received for ARPP pre -clearance approval . Nearly 131 hours of video m aterial were analysed by three supervised lear ning models using image , voice recognition technologies and tracking actors in a scene , allowing the ARPP to assess the evolution of the representation of men and women.655 Mohamed Mansouri , deputy director of t he ARPP656 , says that the main reasons the SRO is pursuing AI technologies are : time efficiency thanks to the machine learning automation of low -added -value tasks ; and a desire to create modern , agile advertising self-regulation taking advantage of the lates t technologies , for everyone - industry professionals , public authorities and consumers . The consultation with the industry during the workshops allowed further definition of the priority areas for the ARPP ’ s monitoring services and further evolution of its AI programme . 652 Botox products and services can not be advertised to the public in the UK . 653 The Advertising Standards Authority ( 2020 ) , Annual Report 2019 , The Advertising Standards Authority ( ASA ) and Committee of Advertising Pr actice ( CAP ) , https : //www.asa.org.uk/news/using -technology -for-good -ourannual -report.html . 654 Guy Parker from the ASA . Available at http : //https : //www.asa.or g.uk . Interviewed on 23 June , 2020 for the purposes of this paper . 655 Mansouri , M. , Intelligence artificielle et représentation féminine/masculine dans la publicité audiovisuelle . Après les visages et le genre : la voix et l ’ âge ! , ARPP blog , ARPP , https : //blog.arpp.org/2020/03/05/intelligence artificiell e-et-representation -feminine -masculine -dans-publicite -audiovisuelle -visages -genre -voix-age/ . 656 Mohamed Mansouri from the ARPP . Available at https : //www.arpp.org/ Interviewed on 24 June , 2020 for the purposes of this p aper . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 137 6.4.2.1 . Invenio and beyond : A case s tudy In 2020 , Mansouri together with ARPP ’ s tech -partner company Sicara657 and other experts from the French SRO launched the Invenio project , comprised of four modules : ◼ a web -crawler : an automatic ad collector on a series of sites , currently used in display advertising ; ◼ detection of potential breaches using AI based on computer vision and text analysis ; ◼ reporting of breaches and validation by the ARPP ’ s lawyers and experts , looped back into the model to improve it s accuracy ( currently based on mislea ding therapy claims and prohibited financial advertising ) ; ◼ an automatically triggered alert system when an ad pointing to the specified prohibited sites is found . Invenio means ‘ I found ’ in Latin , and it ’ s a suitable name for the project , which helps to significantly save time in identifying non -compliance cases and tackle more breaches , according to Mansouri . However , its value is also seen on an educative level , and enabling various players in the ad value chain to a udit their program flow . Mansouri exp lains that the next phases for Invenio expansion involve : detection of other types of common breaches in areas like advertising of cosmetics and electronic cigarettes ; lack of disclosure of commercial collaborations and other forms of adverting with regard to influence marketing and video ads . He also adds that the future vision for Invenio includes the European dimension , “ which is more than ever essential to demonstrate the validity of self -regulation at the European l evel ” . Asked whether he sees a dange r that AI tools may be used too widely in the future and may thus misjudge and over -police ads , Mansouri offers reassurance : “ The human element is fundamental in the system ” and nothing , he adds , is decided without prio r legal analysis and validation by ex perts . “ AI allows to process loads of data very efficiently , but on very basic things . Even if the models improve its accuracy with use , the legal syllogism to date can not be automated ” . 6.4.3 . Harnessing technology to bring more trust to the Dutch ad market Another frontrunner when it comes to exploring AI and its application to ad self regulation is the Dutch SRO Stichting Reclame Code ( SRC ) , which is currently exploring different possible applications of automated technolo gies . SRC ’ s core objective is “ buildi ng trust in the ad industry ” . Building on its dominant position in the field of offline ad self -regulation , SRC is seeking to become a force for good in the online environment 657 More information about Sicara ava ilable at https : //www.sicara.fr/ . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 138 as well . Otto van der Harst , the director o f SRC,658 is convinced that advertisin g self regulatory organisations “ need to take action and get a deep understanding of the advertising tech world ” while maintaining their position as independent regulators . He believes that , together , the Dutch SRO and the ad industry are “ standing at the dawn of a new decade in online commerce and advertising ” . SRC ’ s technology partner , DEUS , concurs , saying that the “ use of data science and new technologies offers an opportunity to start using the enormous amounts of d ata in the online advertising ecosys tem for good ” . Nathalie Post from DEUS659 adds that one of the key focus areas for SRC in the Netherlands is the protection of vulnerable people ( e.g . minors , people with addiction problems , the elderly ) from potentially h armful commercial content ( e.g . tar geted alcohol , gambling , slimming , plastic surgery and Botox product ads , as well as excessive volumes of HFSS ads , and misleading medical claims ) . The DEUS team sees five areas where automated technologies can be particu larly helpful in supporting SRC in these areas of activity : using avatars to simulate profiles of specific ( vulnerable ) target groups ; using social listening tools to monitor social media influencers ; using NLP and computer vision to automate the registrat ion , categorisation and reporting o f ads that breach the advertising code ; using computer vision to identify ads that contain certain biases , such as a lack of diversity ; and gaining a better understanding of data flows in the RTB ecosystem , to address pot ential breaches of advertising code s. Otto van der Harst is confident that the dream of having AI -enabled SR services is already on the horizon , and that the coming years will be about experiments , discussions with advertising self -regulatory bodies , plat forms and agencies , where he expect s to align all serious parties involved : “ AI and machine learning are just instruments to see that the online world remains a safe advertising space ” . 6.4.4 . Tech solutions from the ad industry powerhouse SROs are not the only ones tracking irresponsible ads an d trying to make the online space safer by employing AI technologies . Some of the online ad industry giants , standing at the very forefront of tech development are also actively applying AI tools to ensure a safe and sustainable ad environment online . In April 2020 , Google published its annual “ bad ads ” report , claiming to have blocked and removed 2.7 billion bad ads in 2019 ( 0.4 billion more than in 2018 ) , in other words 10 million ads per day , 5,000 ads per minute and m ore than 100 per second.660 658 Otto van der Harst from SRC . Available at https : //www.reclamecode.nl/ . Interviewed on 20 June , 2020 for the purposes of this paper . 659 Nathalie Post from DEUS . Available at https : //deus.ai/ . Interviewed on 22 June , 2020 for the purposes of this paper . 660 Spencer , S. , Stopping bad ads to protect users , Google Ads , Google , https : //blog.google/products/ads/stopping -bad-ads-to-protect -users . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 139 “ We tak e great pride in being a resource for people around the world searching for important information , ” says the Google team661 interviewed for this paper “ Along with trusting the information surfaced , we know users should also be able to trust the ads they are seeing. ” As the digital advertising ecosystem grows , new threats are rising , requiring continuous adaptation of companies ’ policies , and the improvement of technology . “ As we get better at detecting trends and patterns wi th scammers and fraudsters , we ar e responding in kind with new technology to stop these emerging threats and take more account -level action , ” the Google experts continue . In 2019 , they doubled down on the tech to address long standing abuse of phishing and trick-to-click ads . A dedicated task force at Google tracked and analysed the tactics bad actors were using to circumvent Google ’ s systems and collect personal information from users . “ While phishing ads range from those that exploit people who are intere sted in cryptocurrency to others looking for information on passport renewals to ads leading users to fake bank websites , we found common denominators in how they evade our systems that allowed us to improve our tech to stop them , ” the Google team says . Although technology helps Google sp ot potential violations , it is the combination of tech and talent that allows effective enforcement . “ We have thousands of people at Google dedicated to helping us fight bad ads , bad sites and scammers online , ” the team notes . “ We ’ re constantly reviewing a ds , sites and accounts to ensure that they comply with our policies. ” . Implementing AI and other machine learning technology allows Google to charge their enforcement efforts 24/7 and enables them to assess multiple variabl es when taking decisions about ta king down an ad . Asked about the fact that more bad ads are being removed every year , Google ’ s team replied that the increase in numbers is indicative of a couple of key factors , including the dynamic nature and evolving s ize of the digital advertising ec osystem , as well as ongoing improvements in adapting to the different ways in which bad actors try to game the system . According to Google ’ s experts : “ No system will be 100 % perfect , but we ’ re vigilant and always working to improve our tools. ” 6.4.5 . Future front ier for advertising self -regulation Intelligent advertising was mentioned earlier as a potential aim of those creating and adopting AI applications for advertising . It ’ s therefore also worth asking what the future of AI-enhanced advertising regulation sho uld be and how it can be made intelligent , that is to say not merely reactive and punitive , but anticipatory of emerging issues and supportive of industry actors in proactive ways . 661 A team of experts from Google ( available at : https : //ab out.google/ ) was interviewed on 8 July , 2020 fo r the purposes of this paper , and provided the response from the company on the topics discussed in this chapter . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 140 The interviewed SROs all agree that ad sta ndards bodies have to respond to ad innovations with tech innovations of their own . Guy Parker from the ASA thinks that AI and other forms of automated tech will provide SROs with better intelligence on where and how they should be intervening or providing services . He adds that although the ASA “ will never achieve perfection ” , the technology will be at the heart of reducing irresponsible and harmful online ads in the future . Mohamed Mansouri from the ARPP adds that AI will essentially help SROs increase ef ficiency , go deeper and wider , an d act quickly in the digital ad realm , where channels , formats and content grow exponentially . He adds that collaboration in creating and employing AI technologies is very important as it allows the development of collectiv e intelligence and responds to th e challenges associated with the inherently cross -border digital environment . Otto van der Harst from SRC agrees , saying SROs need to get a grip on the ad ecosystem if they “ want to be relevant in the future ” and use tech a ssistance to have some form of in dependent oversight and be able to deliver a credible response to the current market developments . Finally , European cooperation will likely play an important role in the scaling of existing initiatives , the sharing of expe rtise and the mutual learning of the various actors . The SRO network in Europe , coordinated by the EASA , has seen new formats of commercial communications disrupting the ad industry many times in the past and has proved agile and flexible in adapting to ch anges in technology and societies , while respecting European cultural diversity . Through the sharing of best practices and collective discussion of future challenges , the SROs have continued to inspire and support the ad industry in the creation of respons ible advertising and the preserva tion of consumer trust . The ongoing cooperation on the use of AI and other automated technologies is one the most exciting European -wide initiatives , one that will likely be an incubator for the promising future of intellig ent advertising self -regulation . 6.5 . Conclusion : ‘ The great data rush ’ Many practitioners and scholars writing about AI describe its increasing and expanding applications in different industry sectors , including advertising , using a big data wave analogy - with reference to a tsunami -like pow er forcefully transforming and reshaping the environment , sometimes in an unrecognisable way . However , unlike tsunamis , the operationalisation of data does not occur as natural phenomenon . It needs to be engineered That ’ s w hy I believe that a more useful a nalogy to describe AI applications in marketing and advertising is the gold fever of the 19th century , which led to massive changes in the world economy and trade patterns , and spurred migration and rapid social mobility . N ot unlike those new settlers who sailed across oceans in pursuit of the American dream , the advertising industry today is experiencing a great data rush , which promises even greater benefits to those who harness and properly channel data , turning consumers into profit -bringing customers . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 141 Much like the innovations introduced during the gold rush era , AI applications in advertising have already generated numerous benefits for both industry and consumers . AI has made advertising easier to deliver and cheaper t o place in front of the relevant consumers . Machine learning technologies have also made it possible to seamlessly integrate new formats of advertising in our everyday lives , from voice assistants offering us tailored products and services , based on our pa st purchasing history and other contributing factors , to virtual influencers naturally interacting with us on digital platforms , exchanging holiday tips with audiences and promoting aspirational lifestyles . On the other hand , gold fever was also frequentl y associated with the lawless pursuit of wealth , encapsulated by the term “ wild west ” . It alludes to a disruptive nature of the new AI -enhanced forms and formats of advertising . Although today ’ s market race to develop and implement the most effective AI to ols for advertising sh ould not be compared to the dramatic face -offs depicted in westerns , there are still challenges and concerns regarding a potential lack of oversight of AI technologies . Civil society and policy -makers are troubled by increasing person al data collection , au tomation of decisions and market asymmetry . Accountability and transparency are paramount to ensure that people don ’ t feel alienated by AI and can instead embrace and fully benefit from the technologies that help them find relevant information faster and g et their queries answered quicker - and may even help them with their creative projects . In conclusion , is AI a gateway to a Deadwood -like advertising ecosystem , functioning without adherence to existing rules , exploiting consumers a nd designed to profit only those who develop the technological expertise and grab the golden power source of data ? No , and in reality , such a gloomy future , and indeed the wild west scenario , are very unlikely . As discussed in this paper , the constant pres sure from civil societ y , as well as the detailed requirements of the regulatory frameworks and self regulatory initiatives , put the ethical use of AI at the centre of continuing public debates . Recent policy developments and the views of the interviewed ex perts show a strong commitment to human -centric AI and its application in advertising . However , strategies and guidelines have to be continuously implemented in practice and safeguards only work if there is a will to trigger and enforce them - which is why consumers also have t he responsibility to know their rights , be active and remain vigilant about demanding proper protection and accountability from market actors . Finally , and perhaps most importantly , building a sustainable AI framework for advertising and the use of data an d technology for good is in the interest of the advertising community itself . Only by embedding ethical principles in the machine learning algorithms , collecting and using personal data in a respectful way that reflects high standards of transparency and r esponsibility , and fostering AI applications in marketing that help to identify bad actors and hold them to account , can the industry expect to earn lasting consumer trust . After all , trust is , and always will be , a true gold standard in advertising . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 142 6.6 . Acknowledgements Much like AI algorithms , which need good data input to learn , this article could not have been developed without the insights of the experts interviewed , who kindly agreed to share their expertise , knowledge and futur e predictions related to the use of AI in advertising . I would like to thank Kerry Richardson from Tiny Giants , Charlie Cadbury from Say It Now and Nathalie Post from DEUS for sharing their expertise on the intersections between AI and creativity , technolo gy-enabled new adverti sing formats and the development of a human -centric AI approach . A big thanks to independent influencer marketing consultant Scott Guthrie and Rupa Shah from Hashtag Ad Consulting for sharing their thoughts on the development of virtu al influencers , ethics , and the possible future of virtual humans as marketing channels . I also want to thank Geraldine Proust from FEDMA who kindly guided me through the legal frameworks concerning AI use in advertising and shared her insights on the key challenges for machine learning applications in advertising going forward . Many thanks to the Google team that provided insights and further explanations about the company ’ s efforts to use advanced technology and human expertise to remove bad ads and keep their platforms safe . Last but not least , I am very grateful to my colleagues from the advertising self -regulatory organisations - Guy Parker from the ASA , Otto van der Harst from the SRC and Mohamed Mansouri from the ARPP - for taking challenging steps to adopt AI and other ma chine learning technologies to continue to ensure high ethical standards in advertising and for allowing me to join them on this exciting journey , to learn along the way and to discuss the future developments together , searching for i nnovative solutions wi th an emphasis on a strong European collaboration . AI in advertising is in some ways a labyrinth in which it is impossible to visit every corner . However , with the guidance of all the interviewed experts I hope I have found several possible paths throug h it . Those paths , analysed in this chapter , represent my own take on AI in advertising and should not be attributed to any particular organisation or individual mentioned in the text . Finally , the European Audiovisual Observatory sho uld not be held respon sible for any of the quotes and opinions provided in this paper , including those of all the interviewed experts and the author herself . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 143 6.7 . List of interviews ◼ Charlie Cadbury from Say It Now , https : //www.sayitnow.ai/ . Interviewed on 19 June 2020 . ◼ Google expert team , https : //about.google/ . Interviewed on 8 July 2020 for the purpo ses of this paper , and provided the response from the company . ◼ Scott Guthrie , an independent influencer marketing management consultant , event speaker and blogger , https : //sab guthrie.info/ . Interv iewed on 22 June 2020 . ◼ Otto van der Harst from SRC , https : //www.reclamecode.nl/ . Interviewed on 20 June 2020 . ◼ Mohamed Mansouri from the ARPP , https : //www.arpp.org/ . Interviewed on 24 June 2020 . ◼ Guy Parker from the ASA , https : //www.asa.org.uk . Interviewed on 23 J une 2020 . ◼ Geraldine Proust from FEDMA , https : //www.fedma.org/ . interviewed on 7 July 2020 . ◼ Nathalie Post from DEUS , https : //deus.ai/ . Interviewed on 22 June 202 0 . ◼ Kerry Richardson from Tiny Giant , https : //www.tinygiant.io/ . Interviewed on 22 June 2020 . ◼ Rupa Shah from Hashtag Ad Consulting , https : //www.hashtagad.co.uk/ . Interviewed on 22 June 2020 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVI SUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 145 Personality rights AI can be so creative it can go way beyond helping in the scriptwriting process . After all , a script is only the beginning of the creative process . The story and the ideas in a script have to be translated into images . In most cases , these stories talk about people . People played by actors . AI can not only write the script and play the music but it can also provide the actors . Or at least turn any actor into the a ctor you always wished to have in your film . Making him or her younger or older , for instance . The re are very recent examples of this : in “ Gemini Man ” , the character played by Will Smith has to fight against a younger clone of himself . A similar de aging p rocedure was applied to the main characters in Martin Scorsese ’ s “ The Irishman ” . In “ Star Wars : Ro gue One ” , Carrie Fisher looks younger than ever , and Peter Cushing , who died in 1994 , also has his moment of post -mortem glory . But normally , after hype comes hysteria . If you read the newspapers these days , you may come across headlines such as : “ In the a ge of deepfakes , could virtual actors put humans out of business ? ” 662 Indeed , imagine for example a gangster film with a digital Marlon Brando but without his n otorious backstage behaviour . Which director would not want that ? For this , you just need the rel evant hardware and software … and a ghost actor . That is , an actor whose face is replaced by that of the more famous one . Cheaper and , in the case of Brando , p robably better behaved . On top of that , AI makes it substantially easier to create digital extras . As you can imagine , these developments , both technological and artistic , raise personality rights issues . These legal issues are regulated by law and then se ttled by contract . But a contract can be unfair to the party with less bargaining power . Like an unknown actor . Or a dead person . There is also a darker side of this issue . Deepfakes . They can be used in different , harmful ways . First of all , commercial misappropriation . Deepfakes can be used for fake endorsements of products . There is another issue : identity abuse ( mostly in porn films ) . In her contribution to this publication , Kelsey Farish remarks that “ especially in the case of novel technologies such a s deepfakes and ghost acting [ … ] [ P ] ersonality rights require a careful consideration of situatio nal context ” . 662 Kemp L. , “ In the age of deepfakes , could virtual actors put humans out of business ? ” , The Guardian , https : //www.theguardian.com/film/2019/jul/03/in -the-age-of-deepfakes -could -virtual -actors -put-humansout-of-business . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 147 7 . Personality rights : From Hollywood to deepfakes Kelsey Farish , DAC Beachcroft LLP “ The body is not a thing , it is a situation : it is the inst rument of our grasp upon the world ” Simone de Beauvoir 7.1 . Introduction Lawyers do not often turn to Hollywood actors for professional insight , but when it comes to new technologies that may harm one ’ s public image , Scarlett Johansson is a worthy exception . Du ring an interview with The Washington Post , Johansson , one of the most recognisable and highly -paid film stars in the world , explained “ nothing can stop someone from cutting and pasting my image or anyone else ’ s onto a different body and making it look as eerily realistic as desired ” .663 Although computer -generated special effects are nothing new , Johansson was referring to a then relatively unknown practice of superimposing celebrities ’ faces into pornographic videos , using a sophisticated artificial intelli gence system . Today , we refer to this sort of face -swapping video , whether pornographic or otherwise , as a deepfake . When asked about initiating court proceedings , Johansson admitted she felt it was a “ useless pursuit , legally ” because “ every country has their own legalese regarding t he right to your own image ” . She added : “ So while you may be able to take down sites in the U.S. that are using your face , the same rules might not apply in Germany. ” 664 These rules , which seek to protect how a person ’ s likeness appears in publications and videos , are 663 Harwell , D. , Scarlett Johansson on fake A I-generated sex videos : ‘ Nothing can stop someone from cutting and pasting my image ’ , The Washington Post , www.washingtonpost.com/technology/2018/12/31/scarlett johansson -fake-ai-generated -sex-videos -nothing -can-stop-someone -cutting -pasting -my-image/ . 664 Harwell D. , op.cit . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 148 commonly referred to collectively as personality rights . However , personality rights are actually comprised of many different laws which have complicated exceptions and nuances . Generalisations are difficult to make , the outcomes of lawsuits ar e often unpredictable , and as correctly noted by Johansson , the laws differ drastically from country to country . This chapter seeks to clarify some of the confusion surrounding personality rights , and aims to offer some practi cal commentary on the risks a nd advantages deepfakes and ghost acting present to the film , television , broadcasting , and non -news media industries . The section “ AI sets the scene ” introduces the technology , and the following one on “ Personality rights and implications ” covers the lega l framework from four different angles with real -world examples . The section “ Laws in selected jurisdictions ” builds upon the legal framework and summarises how personality rights are recognised in Germany , France , Sweden , Guer nsey , the United Kingdom665 and California . Finally , the last section “ What next for Europe ’ s audiovisual sector ? ” discusses certain notable shortfalls in the laws as well as potential trends . 7.2 . AI sets the scene : Deepfakes and ghost acting Research suggests t hat the incredible diversity of human faces is the result of an evolutionary pressure to make each of us easily recognisable due to the highly visual nature of our personal interactions.666 Because we are particularly adept at distinguishing faces from each other , we are likewise quic k to sense when faces look eerie or unnatural,667 and scientists and visual special effects ( VFX ) specialists have long struggled to accurately recreate animations of facial expressions . This changed in 2014 thanks to profound adva ncements in the subset of artificial intelligence known as deep machine learning.668 665 The laws of the United Kingdom are referred to throughout this chapt er , but the country has distinct legal systems in Scotland , England and Wales , and Northern Ireland . Unless otherwise noted , references to any of the United Kingdom ’ s laws are as typified by the courts of England and Wales , or “ English law ” . 666 Sanders R. , Human faces are so variable because we evolved to look unique , Berkeley News , University of California Berkeley , https : //news.berkeley.edu/20 14/09/16/human -faces -are-so-variable -because -we-evolved to-look-unique/ . 667 Mori M. , The Uncanny Valley : The Origi nal Essay by Masahiro Mori , IEEE Spectrum , translated by K. F. MacDorman and N. Kageki [ Japanese orig . 不気味の谷 ( Bukimi No Tani ) 1970 ] . English translation available at : www.spectrum.ieee.org/automaton/robotics/humanoids/the -uncanny -valley . 668 Han J. , Ian Goodfellow : Invented a Way for Neural Networks to G et Better by Working Together , MIT Technology Review , www.technologyreview.com/lists/innovators -under -35/2017/inventor/ian -goodfellow . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 149 7.2.1 . Deepfakes Deepfakes first gained notoriety when users on the website Reddit shared hyper -realistic pornographic videos depicting Scarlett Johannson , Gal Gadot , and Emma Wat son , amongst others.669 Today , deepfakes thrive beyond that world of image -based sexual abuse , and are available as a form of entertainment for anyone to make or enjoy . The deepfake creation software is free to download on file distribution sites such as Bit Torrent and GitHub , YouT ube tutorials provide step -by-step instructions , and some freelance creators even sell bespoke deepfakes for as little as EUR 5 per video on marketplaces such as Fivver . Mobile apps like ZAO , Doublicat , and AvengeThem can generate f ace-swapped videos using just one selfie as their source,670 and even the mainstream apps Instagram and Snapchat have ‘ filters ’ which can easily do the same . Although the technology will undoubtedly continue to improve , most deepfakes made casually and quick ly are often easily det ectible as fakes upon closer inspection . Nevertheless , they remain a popular phenomenon because no specialised technical knowledge is required . Besides , minor inconsistencies or glitches are no deterrent for those who make them simpl y out of curiosity , or for a laugh . 7.2.2 . Ghost Acting Making someone look older , younger , or otherwise different for theatrical purposes is as old as the art of performative storytelling itself , and computers have been used to animate the human face since the 1970s.671 But it was not until the 2000s that film worthy facial alterations were possible , evidenced particularly by The Lord of the Rings ( 2001 ) and The Matrix Reloaded ( 2003 ) . Many VFX techniques include the mapping and scanning of an actor ’ s face and bod y , to generate a virtu al model known as a digital double . The digital double is then modified and superimposed on the body of a stand -in performance double.672 The performance double may be the very person whose face was originally scanned , and often , the fi nal cut depicts an ac tor as either a younger or an older version of themselves . More controversially , the digital double can depict an actor whose death has made their physical presence in the production impossible . These practices are known as ghost acti ng or hologram acting , and may be integral to narrative continuity and the cohesive vision of the production . Rather than rely on facial mapping captured during new performances , VFX specialists use existing film 669 Cole S. , AI-Assisted Fake Porn Is Here and We ’ re All Fucked , Motherboar d Tech by VICE , www.vice.com/en_us/article/gydydm/gal -gadot -fake-ai-porn . 670 Beebom staff , 8 Best Deepfake Apps and Webs ites You Can Try for Fun , Beebom , www.beebom.com/best deepfake -apps -websites . 671 Parke F. I. , “ Computer generated animation of faces ” , Association for Computing Machinery '72 Proceedings of the ACM Annual Conference , 1 : 451 –457 . 672 Cosker D. , Eis ert P , and Helzle V. , Facial Capture and Animation in Visual Effects , pgs . 311 -321 in Digital Representations of the Real World : How to Capture , Model , and Render Visual Reality , University of Bath , Department of Computer Science , http : //cs.bath.ac.uk/~dpc/papers/VFX_2015.pdf . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 150 footage of the deceased actor to create the ir digital double , wh ich is then again modified and superimposed on the body of a stand -in performance double . By way of recent example , after Carrie Fischer ’ s untimely death in 2016 , Lucasfilms used archived footage of the late actress to recast her as Pr incess Leia in the 20 19 film , Star Wars : The Rise of Skywalker . As a notable aside , this was despite assurances made by a studio executive that they had “ no intention of beginning a trend of re -creating actors who are gone ” .673 7.3 . Personality rights and implic ations Personality r ights are aimed at providing an individual the ability to control the publication of his or her appearance , or certain characteristics of it . Protected characteristics typically include photographs and pictures of the face and body , but can also include na mes , distinctive styles , signatures , voices , or even mannerisms . Accessories deeply associated with the individual may also be protected , as seen in Italy when the use of a famous singer ’ s hat and glasses for an advertisement without hi s consent was consid ered a publicity violation .674 When taken together , these attributes may be called one ’ s “ persona ” or “ image ” , with the latter referring not to a picture as such but to one ’ s public image . For this reason , some jurisdictions including the United Kingdom and France refer to personality rights as “ image rights ” . But regardless of what they are called , they can present some curious legal complications for the audiovisual sector . Because technology and society have changed in ways that have o utpaced the law , la wyers must turn to older , more established doctrines to resolve disputes concerning the use of someone ’ s image . Personality rights are therefore often said to have two distinct aspects : publicity and privacy . The right of publicity conce rns use of one ’ s image for commercial purposes , and the right of privacy seeks to prohibit unwarranted intrusion into one ’ s intimate or family life . It is worth pausing here to remember that the law is a nuanced language , whose obscure rules and ancient pr ecedents have certa in mythological qualities which reflect the social norms from which they develop . The proper use of personality rights depends on context as well as culture , and even within the European Union there is no unified approach . In a sense , wh at we observe from a legal perspective is analogous to a dimly -lit nightclub , in which the laws concerning intellectual property rights , branding and advertising , reputation management , freedom of speech , emotional distress and consumer protection all danc e together , but not necessarily in harmony . The remainder of this section attempts to organise the dancefloor somewhat , by considering personality rights from four different angles . 673 Robinson J. , Star Wars : The Last Jedi —What Happened to Leia ? , Vanity Fair , www.vanityfair.com/hollywood/2017/12/star -wars-the-last-jedi-does-leia-die-carrie -fisher -in-episode -ix . 674 Dalla v Autovox SpA Pret . Di Roma , 18 apr . 1984 , Foro It . 19 84 , I , 2030 , Giur . It . 1985 , I , 2 , 453 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 151 7.3.1 . Angle 1 : Publicity as ( intellectual ) property Movie stars , professional a thletes and other celebrities can earn substantial amounts of money beyond their day job at the studio or stadium . Lucrative uses of their persona may include paid advertisements , official merchandising , or collaborations with fa shion houses . It is not onl y the individual whose financial interests are at play : his or her management team , corporate sponsors , film studios , record labels , and so on will care about the monetary value of his or her persona , too . With that in mind , this first angle looks at the p ublicity aspect of personality rights , as a form of economic protection . Under the labour theory of property , an individual is entitled to the fruits of his or her own labour.675 Intellectual property is , by extension , a right acq uired through mental and cre ative labour . Copyright laws are a form of intellectual property which recognises the effort and investment involved in producing creative works , ranging from feature films to Tiktok clips , and everything in between . Copyright l aws prohibit others from cop ying , modifying or using such creations without the creator ’ s permission and , in the online ecosystem , copyright infringement claims have become a pervasive way for creators and studios to assert control over their content . Unfo rtunately , there are several practical challenges to this copyright infringement approach to personality rights . Firstly , a somewhat paradoxical complication can arise when attempting to assert copyright protections on behalf of the person depicted . Recall that it is the labour of th e photographer or videographer which is protected by copyright , and those rights are often passed directly from the creator to the studio or company producing the film in question . For this reason , a person can not bring a copyri ght lawsuit just because he or she is featured in the audiovisual content . Although some rightsholders may be willing to initiate lawsuits on behalf of the person depicted , this will not always be the case , and especially not when the dispute is between th e rightsholder and the perfo rmer . Hundreds or even thousands of images may have been used to generate a digital double . Once those images have been blended , ascertaining the relevant copyright owners of those original images may be impracticable , if not im possible . Additionally , there are certain uses of copyrighted material which are lawful despite a lack of authorisation . These exceptions notably include satire and parody , and in the United States , transforming a creative work to create new expressions o r meaning may likewise be pe rmissible . 675 Hughes J. , The Philosophy of Intellectual Property , Georgetown University Law Center and Georgetown Law Journal , 77 Geo . L.J . 287 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 152 7.3.2 . Angle 2 : Publicity and brand recognition As with angle 1 , angle 2 concerns commercial use of one ’ s publicity , but shifts focus away from viewing one ’ s image in audiovisual content as property . Instead , under the princ iple of unjust enrichment ( a lso known as unjustified enrichment ) , it is unlawful to unfairly benefit financially from the goodwill or reputation of another . Just as specific symbols and names are protected through trademarks to distinguish a brand ’ s services and goods from its compet itors , it is possible to protect the image of a person when that image is used to signify a certain quality , provenance or affiliation . But unlike the trademarking of a discrete symbol or a phrase , it is impossible to trademark every aspect of a celebrity ’ s persona . Firstly , video footage is not capable of trademark protection . Secondly , even if a particular shot or picture has been trademarked , this will not prevent someone from using different ph otographs to create the deepfake or ghost acting performance . To bridge this gap , several jurisdictions are seeking to redress the financial harm arising from a misappropriated image . This is especially relevant in cases of false or misleading endorsements , as when British fashion retailer Topshop sold a T -shirt wh ich prominently displayed a photograph of the Grammy Award -winning singer Rihanna . Topshop had a proper copyright licence to use the image , but because Rihanna demonstrated that the shirt damaged the attractive magnetism of her personal brand , she successf ully sued Topshop for misuse of her publicity.676 In another lawsuit coincidentally involving a photograph of a pop star on T shirts , the German Federal Court awarded the 99 Luftballons singer Nena a fee on the basis that she had been deprived of payment for use of that particular image.677 Worth noting here is that in some jurisdictions , this brand recognition angle may only be successful for the person who is able to prove the financial damage to h is or her publicity . Understandably , this leaves much to be de sired for lesser -known figures , or those who can not prove the monetary value of their persona . 7.3.3 . Angle 3 : Privacy protections The two angles explored thus far have considered how publicity laws ca n protect the use of one ’ s image for advertising and other com mercial purposes . Angle 3 considers the ways in which privacy laws operate to prohibit unwarranted intrusion into one ’ s intimate or family life , and how those laws might apply to deepfakes and g host acting . Whereas property rights are inherent to ownership of some tangible or intellectual asset , the right to privacy arises automatically by virtue of being human . 676 Robyn Rihanna Fenty v Arcadia Group Brands Ltd ( t/a Topshop ) , Court of Appeal ( Ci vil Division ) - [ 2015 ] EWCA Civ 38 . 677 Nena , BGH , Urt . V. 14 October 1986 VI ZR 10/86 Oberlandesgerichtsbezirk Celle , Landgericht Lüneburg . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 153 The European Convention on Human Rights ( hereafter , “ the Convention ” ) 678 is the key le gislation to protect human rights and political freedoms in Eur ope , and applies to all member states of the European Union as well as 20 other countries . Article 8 of the Convention grants everyone a fundamental right to privacy , which includes protection against unwanted intrusion into one ’ s personal space . As anyone familiar with documentaries or reality television will know , visual images enable the viewer to act as a spectator or voyeur with regard to the subject ’ s life.679 Photographs and film footage a re accordingly treated with caution at law , and are regarded by the courts with heightened scrutiny . Even so , privacy laws by no means provide absolute protection for one ’ s image . Most societies recognise that privacy must be balanced against – and in some cases yield to - other competing rights . For instance , the news media will have a right , and in some situations a duty , to share otherwise ‘ private ’ photographs of notable figures , if doing so is in the public interest . Although privacy is a fundamental h uman right under the Convention , so too is the right to freedom of expression under Article 10 . Most countries beyond the remit of the Convention have a similar provision : in the United States , this is chiefly the First Amendment to that country ’ s Constitu tion.680 In most privacy cases therefore , analysis will turn on w hether the image was captured in public , or whether the subject had a reasonable expectation of privacy at the time . Using a telescopic lens to take paparazzi shots of a celeb lounging toples s by the pool of her gated villa will , naturally , be construed di fferently than a photograph which captures her fully dressed on the red carpet at a film festival . A problem we encounter from a privacy law angle , however , is that in reality , the millions o f photographs taken and shared each day will mostly fall somewher e between these two extremes . As such , it is not easy to predict which images will be deemed an intrusion into an individual ’ s private life , or misuse of his or her confidential information . Additionally , as a matter of popular opinion , it is understood th at a celebrity who benefits financially from his or her fame must necessarily give up some aspect of his or her privacy . Whether or not this is fair is another matter . Where audiovisual cont ent discloses confidential details , for example if a person speak s to reveal private facts , an invasion of privacy may be at issue . However , beyond this scenario , privacy laws are likely not suitable tools for countering unwanted deepfakes or ghost acting performances . Firstly , multiple images and videos are often blend ed together to make a digital double , and determining which if any of those used was initially private could be next to impossible . Secondly , and perhaps more importantly , deepfakes by their very definition depict something that never happened , and fantasy scenarios can not constitute an invasion of privacy . As for using footage depicting a deceased actor , the heirs or estate of a performer would struggle to assert post -mortem 678 European Convention on Human Rights ( formally the Convention for the Protection of Human Rights and Fundamental Fre edoms ) , www.echr.coe.int/Documents/Convention_ENG.pdf . 679 Michael Douglas , Catherine Zeta -Jones & Ors v Hello ! Ltd. & Ors [ 2005 ] EWCA Civ 595 . 680 First Amendment to the Cons titution of the United States , www.constitution.congress.gov/constitution/amendment -1/ ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 154 privacy rights . T he European Court of Human Rights has consistently hesitated to recognise privacy rights for the deceased , unless their privacy is connected to those who are living.681 In all but a few circumstances , a deceased individual has no privacy to speak of which m ay be infringed and , because privacy rights are inalienable to the person concerned , they are neither inheritable nor transferable . 7.3.4 . Angle 4 : Dignity and the neighbouring rights The perspectives discussed above have aimed to provide some useful commentary on the publicity and privacy aspects of personality rights . Althou gh the laws mentioned offer adequate protections in some instances , they can also leave open the possibility for misappropriation . To resolve this , personality rights could be expanded to co ver emotional and mental well -being , irrespective of financial or privacy implications . This fourth and final angle , therefore , centres on the notion that every person has a fundamental right of dignity and personal integrity . It is also arguable that laws that currently exist to protect the integrity of recorded perform ances may be available to cover virtual performances , too . The Geneva Convention recognises that “ respect for the personality and dignity of human beings constitutes a universal principle w hich is binding even in the absence of any contractual undertaking ” .682 This explicit recognition of dignity is enshrined in the post-war constitution of Germany , and elsewhere throughout the case law and legislation of most European countries . It is reason able to conclude that these laws were inspired by a desire to prote ct a person ’ s integrity , individuality , and self -determination.683 By way of example , the widely -cited privacy case of von Hannover v Germany No . 2684 concerned Princess Caroline of Hanover , the eldest daughter of Prince Rainier III of Monaco . Princess Carolin e had long attempted to keep photographs of herself out of the German press . When photographs of her and her family were published without her consent , the matter ultimately landed before the European Court of Human Rights . In its judgment , the court decla red that “ a person ’ s image constitutes one of the chief attributes of his or her personality , as it reveals the person ’ s unique characteristics and distinguishes the person from his or he r peers . The right to the protection of one ’ s image is thus one of th e essential components of personal development. ” 681 Buitelaar , J.C. , Post-mortem privac y and informational self -determination , Ethics and Information Tec hnology , 19 ( 2 ) , pp.129 –142 , https : //link.springer.com/article/10.1007/s10676 -017-9421 -9 . 682 Geneva Convention prea mble , Convention ( IV ) relative to the Protection of Civilian Perso ns in Time of War . Geneva , 12 August 1949 , https : // ihldatabases.icrc.org/ihl/385ec082b509e76c41256739003e636d/6756482d86146898c125641e004aa3c5 # : ~ : text = ( 1 ) % 20Persons % 20taking % 20no % 20active , on % 20race % 2C % 20colour % 2C % 20religion % 20or . 683 Abraha m , K. and White E. , “ The Puzzle of the Dignitary Torts ” , Cornell L aw Review 104 ( 2 ) , pp.317 –380 , www.core.ac.uk/download/pdf/228302795.pdf . 684 Von Hannover v. Germany ( no . 2 ) 40660/08 [ 2012 ] European Court of Human Rights 228 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 155 Obviously , the Internet makes it remarkably simple to publish audiovisual content that has the potential to embarrass and humiliate . The discursive nature of social media also makes such content subject to exponential exposure and further ridicule . In addition to damaging the depicted individual ’ s self -esteem and mental health , such videos could have considerable knock -on eff ects for his or her co -stars and corporate partners . Although still relatively nasce nt in legal scholarship on the subject , arguments for legal solutions centred on dignity embrace a more holistic understanding of identity . In due course , legal recognition of this facet of personhood may suitably modernise personality rights , and thereby protect people from the harms of misused technologies.685 Somewhat frustratingly , however , during court battles where a person ’ s honour and peace of mind is at issue , the co ncept of dignity is often used as a mere placeholder to express an abstract ideal . Wh ilst the text of the law may emphasise the importance of a person ’ s dignity , we frequently see academics and practising lawyers struggle to define cohesive rules for how s uch a right should operate in reality . The resolution of many cases , including von Ha nnover , ultimately defers to privacy or defamation laws . As explained above , these will often require the harmed individual to overcome the publisher ’ s rights of expressio n. There is , however , a faint hope for those in the performing arts . Whereas copyrigh t seeks to protect the interests of a work ’ s author or creator , neighbouring rights respect the necessary input made by a musician , dancer or actor in a recorded performan ce . These neighbouring rights are so named as they “ neighbour ” the concept of copyrig ht ( they may also be called ‘ “ performer ’ s rights ” to avoid confusion with “ authors ’ rights ” ) . Neighbouring rights generally seek to secure credit for the performer , as wel l as to prohibit modifications to a recording which may damage the performer ’ s intell ectual or personal interests . In essence , neighbouring rights address problems arising from pirated copies or broadcasts of shows which do not adequately compensate the pe rformers involved . Despite their obvious importance with respect to performances sho wn through an audiovisual medium , neighbouring rights are very rarely discussed in the context of personality rights . Usually , personality rights disputes concern the misu se of static photographs , which can be easily altered to realistic effect , rather tha n a recorded performance . But as we have seen , advances in artificial intelligence and VFX have made manipulated videos more likely to be confused or implied as genuine . T his new era of creating audiovisual works that imitate true performances may warrant an update to how neighbouring rights legislation has historically defined ‘ performance ’ . Recognition of non -consensual virtual performances has precedence in California , where courts have compensated individuals for their digital ‘ enslavements ’ in video games . Musicians in the band No Doubt , for example , successfully sued the makers of Band Hero , a game which allowed players to select highly realistic digital avatars to 685 Dunn S. , Identity Manipulati on : Responding to advances in artificial intelligence and robotics , presented as a working paper at the WeRobot Conference April 2020 , and provided to Kelsey Farish through private correspondence in July 2020 with Ms Dunn ’ s kind permission to cite . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 156 simulate performing in a rock band.686 If deepfakes or ghost acting performances are recognised as ‘ performances ’ under the law , this may protect an individual ’ s image in cases where he or she has been forced to become a digitised performer against his or her will . In the interests of completeness , therefore , neighbouring rights should be cons idered together with any other rights of publicity or privacy that may comprise the personality rights framework . 7.4 . Laws in selected jurisdictions By way of summary , as ex plained in section 2 , personality rights are often split into two broad concepts . The first concerns the exploitation of one ’ s fame and reputation for financial gain , and is regarded as the right of publicity . We can view the right of publicity from severa l related but distinct angles , namely , intellectual property rights ( angle 1 , above ) , and brand protection laws ( angle 2 , above ) . Separate from commercial publicity , the second concept seeks to protect one ’ s personal life by prohibiting the publication of certain images by way of privacy laws ( angle 3 , above ) . Dignity as an aspect of person ality has received less attention in personality rights scholarship , and neighbouring rights even less so ( angle 4 , above ) . Whether or not any of these rights extend beyo nd death varies , but post -mortem rights will typically be viewed as a form of property which an individual may pass down to his or her heirs . It remains to be seen just how future litigation concerning deepfakes and ghost acting will play out . Arguably , f or the selected jurisdictions in this section 3 at least , laws concerning brand recogn ition and reputation will likely be most relevant . Rights to dignity and neighbouring rights may also be applicable , and could potentially offer a more modernised approac h to protecting one ’ s persona . On the other hand , intellectual property and privacy ri ghts are perhaps less important when considering manipulated images of individuals appearing in audiovisual content . In any event , the publicity , privacy and dignity of a n individual must be analysed on a case -by-case basis , and will always involve a balan cing exercise against the competing rights of others , freedom of expression . 7.4.1 . Germany Home to Europe ’ s largest audiovisual market , Germany ’ s media sector was worth some EUR 23 billion in 2018687 and employed more than 520 000 media workers as of 2017.688 Recog nition for personality rights is broad , and rooted in the German Constitution . As a 686 No Do ubt v. Activision Publishing , Inc . , 122 Cal.Rptr.3d 397 ( Cal . Ct. App . 2001 ) . 687 European Audiovisual Observatory , Yearbook 2019/2020 Key Trends – Cinema , television , video , and audiov isual services on demand – The pan -European landscape . European Audiovisu al Observatory , http : //yearbook.obs.coe.int/s/document/key -trends/2019 . 688 Weidenbach B. , Beschäftigte in der Medienbranche in Deutschland 2017 , Statista . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 157 near-perfect example of the dignity protections discussed under angle 4 above , the German Constitution provides that “ human dignity shall be inviolable ” and “ every person shall have the right to free development of his personality ” ( Grundgesetz , Articles 1 and 2 ) .689 These fundamental protections are complemented by the civil code , under w hich one who commits unlawful injury to another ’ s right of personality is liable for comp ensation ( BGB , §823 ) .690 In Germany , it is possible for one ’ s dignity to survive beyond their natural life , so close relatives may protect a deceased person against dis repute of his or her life image.691 All aspects of a person ’ s identity fall within Germany ’ s unified right of personality , but images and photographs of an individual are subject to heightened protections . The German Copyright Act provides that where images depict an identifiable individual , they “ may only be distributed or publicly displayed wi th the consent of the person depicted ” ( UrhG , §19a and §22 ) .692 Recognisability includes not only depictions of the face , but other distinguishing characteristic s , as well as cartoons and even doppelgängers or lookalikes . Importantly , the concept of distribu tion is interpreted widely , and thus even the casual photographer would technically require consent before posting an image of another person to social media , or sharing it with friends through text messaging apps . Consent is likewise required from a perfo rmer before broadcasting or otherwise communicating their recorded performance ( Section III , UrhG ) . Consent is however not required when depicting persons of contemporary history , nor for pictures in which the people appear only incidentally ( as “ accessor ies ” ) , nor where the publication serves a greater interest in art and culture ( KunstUrhG , §23 ) .693 However , this balancing exercise has shifted towards protecti ng the image rightsholder in recent years.694 As for particularly intimate images , for example those depicting someone in their home , the Criminal Code criminalises the taking , transmission , and use of photographs 689 Grundgesetz , formally Grundg esetz für die Bundesrepublik Deutschland [ Basic Law for the Federal Republic of Germany ] . English translation used www.gesetze -im-internet.de/englisch_gg/englisch_gg.html . 690 BGB , formally Bürgerliches Gesetzbuch [ German Civil Code ] in the version promulgated on 2 January 2002 ( Federal Law Gazette page 42 , 2909 ; 2003 page 738 ) last amen ded by Article 4 para . 5 of the Act of 1 October 2013 . English translation used www.gesetze -im-internet.de/englisch_bgb/englisch_bgb.html . 691 Seyfert C. , Regional Court Frankf urt am Main : Postmortem personality right of a Holocaust survivor prevails over publications by a British history professor ( Case 2 -03 O 306/19 ) , Zeller & Seyfert Rechtsanwältern , www.zellerseyfert.com/en/litigationblog -detail/items/regional -court -frankfurt -am-main -postmortem personality -right -of-a-holocaust -survivor -prevails -over-publications -by-a-british -hi.html . 692 UrhG , formally Urheberrech tsgesetz [ Act on Copyright and Related Rights ] Copyright Act of 9 September 1965 ( Federal Law Gazette I , p. 1273 ) , as last amended by Article 1 of the Act of 28 November 2018 ( Federal Law Gazette I , p. 2014 ) . English translation used www.gesetze -im-internet.de/englisch_urhg/englisch_urhg.html . 693 KunstUrhG , formally Gesetz betreffend das Urheberrecht an Werken der bildenden Künste und der Photographie [ Law on the copyright in works of the fine arts and photography ] Law of January 9th , 1907 ( RGBl . I p. 7 ) last amended by the Act of February 16 , 200 1 ( BGBl . I , p. 266 ) , 1 August 2001 , www.gesetze -iminternet.de/ kunsturhg/__23.html . 694 Coors C. , “ Image Rights of Celebrities vs. Public Interest – Striking the Right Balance Under German Law ” , Journal of Intellectual Property Law & Practice ( 2014 ) 9 ( 10 ) : 835 -840 , www.ssrn.com/abstract=2738514 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 158 which violate another ’ s intimate privacy , p unishable by up to two years ’ imprisonment or a fine ( StGB , §201a ) .695 Regarding the publicity aspec t of personality rights , German courts are increasingly willing to defend individuals against unwanted commercial exploitation of their image.696 Unlike the approach seen in the United Kingdom , prior commercialisation of one ’ s persona is not expressly a prec ondition for having a protectable right of publicity . In cases where a deceased person is shown , consent from the subject ’ s relatives is required for a per iod of 10 years following their death . In a judgment concerning photographs of screen star Marlene Di etrich ( who had died several years prior ) the Federal Court of Justice held that in any unauthorised exploitation of a picture , the owner of the personalit y right is entitled to compensation irrespective of the gravity of the infringement.697 7.4.2 . France Widely regarded as the birthplace of cinema , France has by many metrics the most productive film industry in Europe : nearly 300 films or more have been made in France each year since 2015.698 French personality rights , which may literally be translated as the right s of ( or to ) one ’ s image , include privacy laws which aim to protect a person from unwanted exposure , as well as commercial rights to allow such images t o be exploited as a marketable asset.699 As a general rule , before the image of any individual is communic ated to the public , consent must be obtained from the person shown . As elsewhere , France defines image widely to cover an individual ’ s likeness , voice , photograph , portrait , or video reproduction . French courts have confirmed blurring the face of a model m ay not in itself resolve an image rights violation , where other parts of the body are still visible.700 This philosophy is largely rooted in France ’ s st rong protections for one ’ s privacy or intimate family life . The Civil Code states everyone has the right t o respect for their private life , and importantly , empowers French courts to utilise any measures that are appropriate to prevent or end an invasion o f the intimacy of private life ( Code civil , 695 StGB , formally Strafgesetzbuch [ Criminal Code ] in the version promulgated on 13 Nove mber 1998 ( Federal Law Gazette I p. 3322 ) last amended by Article 3 of the Act of 2 October 2009 ( Federal Law Gazette I p. 3214 ) . English translation used www.gesetze -im-internet.de/englisch_ stgb/ . 696 Peters M. , The Media and Entertainment Law Review – Germany , The Law Reviews , www.thelawreviews.co.uk/edition/the -media -and-entertainment -law-review -edition -1/1211744/germany . 697 Marlene Dietrich , BGH 1 December 1999 - 1 ZR 49/97 - Kammergericht LG Berlin . 698 Lemercier F. , 301 feature films produced by France in 2019 , Cineuropa - the best of European cinema , https : //cineuropa.org/en/newsdetail/387425/ . 699 Logeais E. and Schroeder J -B. , “ The French Right o f Image : An Am biguous Concept Protecting the Human Perso na ” , 18 Loyola University Entertainment Law Review 511 , https : //digitalcommons.lmu.edu/ cgi/viewcontent.cgi ? article=1366 & context=elr & httpsredir =1 & referer= . 700 Mr X v Umanlife , TGI de Paris , judgment of 16 November 2018 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 159 Article 9 ) .701 Accordingly , French judges have over time progres sively developed stronger personality rights for claimants on a case -by-case basis.702 The quality of consent will be a dispositive issue , and is not always clear -cut . Recently , the Paris Tribunal found that a professional model participating in a photo shoo t for advertising purposes did not imply her consent to all forms of commercial exploitation.703 Exceptions to the consent requirement include where footage is captured in a public place , or where images depict well -known figures partaking in official dutie s or activities otherwise connected with their notoriety , subject to the person ’ s right to dignity . Parody and strictly private use are also except ions . French courts may also award enhanced damages in cases where a celebrity has avoided endorsements or ot her commercial exploitations of his or her image in the past . The Penal Code also establishes a criminal offence for privacy violations , which carr ies a sanction of one year ’ s imprisonment and a fine of EUR 45 000 ( Code penal , Article 226 -1 ) .704 Beyond the p urview of privacy law , the French Intellectual Property Code provides that a performing artist shall enjoy the right to respect of his or her name , quality and performance ( IPC , Article 212-2 ) .705 As this is a perpetual right attached to the individual , it m ay be passed down to his or her heirs so that they may protect the artist ’ s performance and memory . 7.4.3 . Sweden For a country with a relatively smal l population , Sweden has produced a remarkable number of international film and television stars , notably inclu ding Greta Garbo , Ingrid Bergman , Max von Sydow , Stellan Skarsgård , and Alicia Vikander . In addition to being a hotspot for the Scandi Noir genre , the country has created several programmes that have gone on to achieve wide acclaim in other markets , such a s the Wallander , The Bridge , and the Girl With The Dragon Tattoo franchises . That the country has no separate personality right as such may there fore come as a surprise . In stark contrast to Germany and France , personality rights are essentially omitted from Swedish law.706 In cases where the news media has misappropriated one ’ s image , the Freedom of Press Act is applicable , but Sweden tends to emp hasise freedom of expression over an individual ’ s right to privacy . This approach is somewhat unusual when compa red 701 Code civil [ French Civil Code ] , www.legifrance.gouv.fr/ 702 Sullivan C. L. a nd Stalla -Bourdillon S. , Digital Identity and French Personality Rights – A Way Forward in Recognizing and Protecting an Individual 's Rights in His/Her Digital Identity , Computer Law & Security Review ( 2015 ) , www.ssrn.com/abstract=2584427 . 703 Mrs X v SARL Denim , TGI de Paris , 17th chamber , judgment of 21 November 2018 . 704 Code penal [ French Criminal Code ] , www.legifrance.gouv.fr/ 705 IPC , formally Code de la p ropriété intellectuelle [ French Intellectual P roperty Code ] , www.legifrance.gouv.fr/ . 706 Ondreasova E. , “ Personality Rights in Different European Legal Systems : Privacy , Dignity , Honour and Reputation ” , The Le gal Protection of Personality Rights , pp.24 –70 . Brill | Nijhoff , https : //brill.com/view/book/edcoll/9789004351714/B9789004351714_004.xml . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 160 to many other European countries , and is perhaps attributable to the fact that Swedish law has deep reverence for transparency and openness , and therefore also for public access to information . This is evidenced by the controversial Utgivningsbevis , a sort of publishing licence which permits companies to openly publish personal details about individuals.707 Similarly , a person ’ s taxable income is also a matter of public record.708 Somewhat confusingly , the “ principle of publicity ” in Sweden refers not to th e publicity aspects of personality rights , but rather the principle that government documents are largely unclassified and subject to public s crutiny . Notwithstanding the above , Sweden ’ s Act on Names and Pictures in Advertising mandates that consent must b e obtained before using someone ’ s name or picture , or a representation which clearly indicates that specific person , for commercial purposes ( Lag om namn och bild i reklam ( 1978:800 ) ) .709 The Swedish Tort Liability Act also states that non-financial harms ma y be compensated , but only if the violation constitutes a criminal act or otherwise endangers health and life [ Skadeståndslag ( 1972:207 ) , Cha pter 2 ] .710 While defamation is a criminal offence in Sweden under the Criminal Code ( Brottsbalken ) 711 it occurs only w here someone falsely or without “ reasonable grounds ” accuses another of “ being a criminal or of having a reprehensible way of living , or otherwise furnishes information intended to cause exposure to the disrespect of others ” ( Brottsbalken , Chapter 5 §1 ) . T he Criminal Code also permits family members or the public prosecutor to initiate prosecutions for “ disturbing the peace ” of the deceased , if doing so is in the public interest ( Brottsbalken , Chapter 5 §4 ) . These narrow protections aside , the gaps in Swede n ’ s personality rights legislation are palpable , and judges in Sweden have been largely unwilling to fill them through case law.712 7.4.4 . Guernsey The Bailiwick of Guernsey is an island off the coast of northern France and , while a British Crown dependency , has a legal system distinct from that of the United Kingdom . Although home to only 63 000 inhabitants , its favourable corporate tax treatments , scenic environs and English -speaking population have contributed to its burgeoning film production a nd 707 Herlin -Karnell E. , Corona and the Absence of a Real Constitutional Debate in Sweden , Verfassungsblog on Matters Constitutional , www.verfassungsblog.de/corona -and-the-absen ce-of-a-real-constitutional -debate -insweden/ 708 Marçal , K. , Sweden shows that pay transparency works , The Financial Times , www.ft.com/content/2a9274be 72aa -11e7 -93ff-99f383b09f f9 . 709 Lag om namn och bild i reklam ( 1978:800 ) [ The Act On Names And Pictures In Advertising ] . English translation used www.kb.se/Dokument/Bibliotek/biblioteksjuridik /names_pictures.pdf . 710 Skadeståndslag ( 1972:207 ) [ Swedish Tort Liability Act ] . Available at www.riksdagen.se/sv/dokument lagar/dokument/svensk -forfattningssamling/skadestandslag -1972207_sfs -1972 -207 . 711 Brottsbalken , SFS 1962:700 [ Swedish Criminal Code ] English translation used www.legislationline.org/download/id/1700/file/4c405aed10fb48cc256dd3732d76.pdf . 712 Ondreasova E. , op.cit . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 161 film finance se ctor.713 Interestingly for our purposes , Guernsey established the world ’ s first statutory registration regime for personality under its Image Rights Ordinance 2012.714 Broadly speaking , this legislation functions similarly to other laws con cerning trademarks . Protected images may include photos and pictures of the individual , but also film footage , as well as his or her name , voice , signature , likeness , mannerisms and personal attributes , such as a sports jersey number . Living persons , or pe rsons who have died within 100 years of the application , as well as groups and teams or even fictional characters , may be registered . Applicants must be proprietors of the personality in question , and may therefore be the individual , or his or her authoris ed representatives o r heirs . An infringement occurs if the registered protected image ( or one similar to it ) is used for a commercial or financial benefit without the proprietor ’ s consent , and such use either confuses the public or damages the reputation of the person depicte d. When assessing damages , the court will consider all relevant factors , to include any economic consequences and lost profits , as well as any moral prejudice suffered by the victim . Registrations are valid for an initial 10 -year period , and may be renewed for another 10 . Although there is no requirement that the applicant be established or resident in Guernsey , the enforcement will only concern infringements or misappropriation in Guernsey . However , the law has been designed with modern media and cross -border digital services in mind715 and so clearance searches prior to broadcasts made available on the island , regardless of where based , would be prudent . 7.4.5 . United Kingdom At the time of writing , the current government of the Un ited Kingdom has emphasised the importance of separating the country from the political and economic ecosystem of the European Union . Despite Brexit however , UK television shows and films remain an inexorable aspect of the audiovisual market in wider Europ e , and are enjoyed by audiences t hroughout the continent . This notwithstanding , the United Kingdom , like Sweden , does not formally recognise personality rights in its legislation . And unlike many of its counterparts in Europe , English courts have also resi sted any temptation to recognise such rights through case law . To quote the judgment from Rihanna ’ s case mentioned above : “ There is today in England no such thing as a free -standing general right by a famous person ( or anyone else ) to control the reproduc tion of their image. ” Rather than attempt to fashion some discrete personality right , judges in the United Kingdom normally prefer to rely on the 713 Tustin B. , Guernsey Film : More Than You Might Think , Mondaq , www.mondaq.com/guernsey/film television/171220/guernsey -film-more -than-you-might -think . 714 Image Rights ( Bailiwick of Guernsey ) Ordinance , 2012 . 715 Shires S ( 2015 ) , Guernsey image rights exposed , Lexology , www.lexology.com/library/detail.aspx ? g=9829178f -e93d -4ead -94d0 -bfbfaa81f8b7 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 162 more traditional legal tools at their disposal . In this sense , there are several ways in which an individual c an protect his or her image which typically focus on disclosure of private facts , and harm to one ’ s business interests or reputation . Due to the nature of how the common law in the United Kingdom has developed , and the fact that the United Kingdom has no codified written Constitution , pr ivacy is not regarded as a distinct right as such . Instead , judges respect the fact that privacy is an important social value , which in turn underpins specific laws related to the breach of confidence or the misuse of parti cularly sensitive information . Fr om the late 1990s , courts have regarded the privacy protections available under the UK ’ s Human Rights Act 1998 , which mirrors the European Convention on Human Rights . That said , on the relatively rare occasions when privacy matters pertaining to images hav e come before English courts , judges have tended to favour the protection of free speech and other press freedoms . There are notable exceptions for images which constitute confidential information , or depict children or par ticularly intimate scenes . When protecting one ’ s publicity as a commercial asset , the most relevant option is often the tort of ‘ passing off ’ , but success will depend on whether the celebrity has “ a significant reputation or goodwill ” in the first instanc e.716 From the dignity and reputati onal perspective , unauthorised use of a person ’ s image may give rise to the common law offence of malicious falsehood , but only insofar as it contains false words which result in quantifiable monetary loss.717 Falsehoods th at damage an identifiable individua l ’ s reputation may constitute defamation , but following reforms to the Defamation Act 2013,718 only where this causes “ serious harm ” to the individual depicted . The above should be read also in the context of the Copyrigh t , Designs and Patents Act ( CDPA ) 719 which allows a performer in some circumstances “ to object to derogatory treatment of performance , with any distortion , mutilation or other modification that is prejudicial to the reputation of the performer ” ( CDPA , s. 20 5 ) . Before using a recorded performan ce , consent must be obtained from the actor , musician , dancer , or other performer in question ( CDPA , s. 182 ) . This statute was inspired by a case concerning clips featuring the actor Peter Sellers which were used after his death to make a new Pink Panther film . His personal representatives then successfully argued for Sellers ’ post-mortem right to prevent the unauthorised use of his performances.720 7.4.6 . California There is no federal right to privacy in the United States of America : privacy protections are regul ated by reference to specific sectors or topics , such as financial or healthcare 716 Edmund ‘ Eddie ’ Irvine v Talksport [ 2002 ] EWHC 367 ( Ch ) . 717 Marathon Mutual Ltd v Waters [ 2009 ] EWHC 193 1 ( QB ) ) . 718 Defamation Act 2013 , www.legislation.gov.uk/ukpga/2013/26/contents/enacted . 719 Copyright , Designs and Patents Act 1988 , www.legislation.gov.uk/ukpga/1988/48/contents . 720 Rickless v. United Artists Corporation [ 1988 ] QB 40 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 163 information . Although there are federal intellectual copyright statutes and codes concerning unfair competition and advertising , it is la rgely the laws of a particular state which will be of key importance to protect one ’ s publicity and privacy . As home to both Hollywood and Silicon Valley , perhaps no place better reflects the zeitgeist of celebrity and technology than California . Californi a protects publicity both in its civil codes as well as at common law , thanks in part to its world -renowned entertainment industry and the Californian propensity to embrace and respect emotions . The California Civil Code ( CIV ) 721 prohibits the unauthorised usage of another ’ s name , voice , signatu re , photograph or likeness for advertising purposes without their consent ( CIV §3344 ) . A guilty defendant will be ordered to pay the injured party the greater of either USD 750 ( approx . EUR 635 as of August 2020 ) or t he actual damages suffered , which will include a disgorgement of profits . The Fred Astaire Celebrity Image Protection Act later amended §3344 to protect the commercial use of a deceased individual ’ s name , image or voice for 70 years post mortem.722 However , this section applies to merchandise , ad vertisements , and endorsements only , and exempts fictional and nonfictional entertainment , dramatic , literary , and musical works from liability . The common law publicity right covers any misuse of an individual ’ s ide ntity , which is broader than the specifi c characteristics listed in the statute , for the “ defendant 's advantage , commercially or otherwise ” .723 California courts recognise that the right of a person to be free from unauthorised and unwarranted publicity is an aspect of privacy.724 Several privacy l aws are applicable to the misuse of one ’ s image , and each is distinguished based on whether the harm is economic or dignitary in nature . False content that injures a person ’ s reputation may fall under the tort of d efamation , and content that is not technic ally false but nevertheless harms the victim ’ s mental or emotional well -being may constitute the tort of false light.725 Due to having residents who are frequently under the spotlight ( both metaphorically , and literally ) , the state is regarded as one of the most claimant -friendly jurisdictions in which to bring a personality rights infringement case . It would however be remiss to ignore the fact that the competing free speech protections available through the First A mendment are strong , even for images and 721 CIV ( California Civil Code ) , www.codes.findlaw.com/ca/civil -code/ . 722 Fred Astaire Celebrity Image Protection Act , see §3344.1 of the California Civil Code . 723 Clint Eastwood v. National Enquirer , Superior Court , 149 Cal.App.3d 409 ( Cal . Ct. App . 1983 ) . 724 Fairfield v. American Photocopy Equipment Co. , ( 1955 ) 138 Cal . App . 2d 8 2 , 291 P.2d 194 725 In common law jurisdictions , if a publication is false and harms a person ’ s reputation , defamation might have occurred . In some U.S. states including California , however , there is a separate tort ( legal harm ) which covers communications w hich are not technically false , but are nevertheless misleading . To this point , courts in Cali fornia recognise that false implications can lead to false and ultimately harmful impressions about an individual . This distinction is subtle and nuanced , but as a generalisation , defamation seeks to remedy damage to a person ’ s reputation . Truth is a defen ce to defamation ; in other words , where a statement is true , it is not defamation . Conversely , a factually accurate statement or photograph can “ place someone und er a false light ” . California ’ s tort of false light therefore seeks to address damage to a per son ’ s feelings – irrespective of its veracity . CACI ( Judicial Council of California Civil Jury Instructions ) 2017 edition . No . 1802 . False Light . https : //www.justia.com/trials -litigation/docs/caci/1800/1802/ . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 164 videos published by corporations . As a notable example , the actor Dustin Hoffman sued a magazine over a digitally -manipulated image used in a fashion story , which purported to show him dressed in designer clothes . T he courts found that as the magazine had no intent to commit harm and the image itself was not purely for commercial reasons , the publisher was entitled to free speech.726 Persons of notoriety , including individuals who become involved in events worthy of public interest , will on balance have fewer privacy protections than an ordinary member of the public . Importantly for those seeking to alter the appearance of an actor through ghost acting or similar techniques , California uses a transformative work test to determine whether a use of a person ’ s ima ge is protected by the First Amendment . Under this test , the more a new work ‘ transforms ’ original footage to provide a different meaning or message , the more likely it is that it will be exempt from copyright pr otections ( Copyright Code , §107 ) .727 With resp ect to images of individuals in particular , California courts will consider whether the “ celebrity ’ s likeness is so transformed that it has become primarily the defendant ’ s own expression rather than the celebri ty ’ s likeness. ” 728 7.5 . What next for Europe ’ s audio visual sector ? This chapter has sought to establish the multifaceted nature of personality rights , which most typically comprises various rights of publicity and privacy . There is also scope to incorporate rights to dignity and integrity , together with a p erformer ’ s neighbouring rights , into this framework . But regardless of how such laws are theoretically classified , there are some practical tips and observations which may assist in mitigating r isks associated with deepfakes and ghost acting performances . Some jurisdictions have passed or proposed deepfake -specific laws to address image -based sexual abuse or electoral interference . For example , the U.S. state of Virginia became the first to upda te its so -called ‘ revenge porn ’ laws , making it a misdemeanour to publish manipulated photos or videos which depict someone nude or their genitalia without consent.729 Texas was the first state to criminalise the sharing of deepfake videos made with intent to injure a political candidate in the days leading up to a vot e.730 Of course , deepfakes can be deeply damaging without being sexual or political in nature . 726 Dustin Hoffman v. Capital Cities/ABC , Inc. , 255 F. 3d 1180 ( 9th Cir . 2001 ) . 727 Copyright Code , formally U.S. Code , Title 17 Copyr ights , §107 Limitations on exclusive rights : Fair use , www.law.cornell.edu/uscode/text/17/107 . 728 Comedy III Prods. , Inc. v. Gary Saderup , Inc. - 25 Cal . 4th 387 , 106 Cal . Rptr . 2d 126 , 21 P.3d 797 ( 2001 ) . 729 Virginia House Bill 2678 , formally a Bill to amend and reenact § 18.2-386.2 of the Code of Virginia , relating to unlawful dissemination or sale of images of another ; falsely created videographic or still image , https : //law.lis.virginia.gov/vacode/title18.2/chapter8/section18.2 386.2/ # : ~ : text=Any % 20person % 20who % 2C % 20with % 20the , or % 20female % 20breast % 2C % 20where % 20such . 730 Texas Senate Bill 751 , formall y a bill Relating to the creation of a criminal offense for fabricating a deceptive video with intent to influence the outcome of an election , www.legiscan.com/TX/text/SB751/2019 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 165 In lieu of statutory instruments , big tech companies have attempted to regulate deepfakes appearing within their remit . Facebook and its sister company Instagram have officially ‘ banned ’ deepfakes , as have Twitter , Reddit and Pornhub . Despite having once embraced the deepfake trend , Tiktok has also recently ‘ banned ’ deepfakes following takeover discussions with U.S. corporations.731 The use of inverted commas around the word banned is intentional : regardless of any official statements or policies , removal or moderation of deepfakes is exceptionally difficult , meaning the prohibition on deepfakes is often in name only . Firstly , distinguishing a deepfake from an authen tic video is a considerable challenge in and of itself , as evidenced by the Deepfake Detection Challenge led by Facebook , Microsoft , and a small army of artificial intelligence expert s.732 Some efforts include meta -tagging source images and watermarking , but no widely available solution exists as of yet . Secondly , even if a deepfake were itself detected , the ease and desirability of remaining anonymous online make the discovery of a dee pfake ’ s creator a potentially impossible feat . In addition to these clear technical issues , we must also consider the complications surrounding context and intention . The term ‘ deepfake ’ speaks to the method of production or its face -swapping characteristi cs , and not its substance : the medical and educational fields are two area s in which the technology has been used admirably for social benefit.733 In short , there is not always a bright line separating an unwanted deepfake from one which is acceptable . Leaving the specifics of how ‘ bad ’ deepfakes could be separated from the ‘ good ’ , novel and entertaining content has an incredible propensity to go viral , even if fake or misleading . Though a somewhat cynical view to take , platforms which depend on advertising clicks and page views may find it suits their business interests to keep exciting content online . Furthermore , even if a deepfake is deemed suitable for removal , doing so may have a chilling effect on freedom of expression . Finally , even where a deepfake has been removed from a platform , this remedy may be superficial , as the vi deo could still very easily appear elsewhere . What ’ s more , the so -called Streisand effect734 has shown that attempting to suppress information may unintentionally make it more widesp read . 731 Statt N. , TikTok is banning deepfakes to better protect against misinformation , The Verge , www.theverge.com/2020/8/5/21354829/tiktok -deepfakes -ban-misinformation -us-2020 -election -interference . 732 Wiggers K. , Facebook , Microsoft , and others launch Deepfake Detection Challenge . VentureBeat . 733 Kalmykov M. , Positive Applicati ons for Deepfake Technology , Hackernoon.com , www.hackernoon.com/the light-side-of-deepfakes -how-the-technology -can-be-used-for-good -4hr32pp . 734 The Streisand effect is named for the 2003 lawsuit launched by American actress and singer Barbra Streisand against a photographer , Kenneth Adelman . Streisand sought to suppress the publication of the photographs Adelman had taken of her house , locat ed on the Californian beaches of Malibu . However , Adelman ’ s photography was for the California Coastal Records Project , a scientific coastal erosion research project which provides pictures of the California coast for study . Her lawsuit was ultimately dism issed and , as a result of the publicity garnered over the lawsuit , led to even more interest in the photographs of her home . See Cacciottolo M. , The Streisand Effect : When censorship backfires , BBC News , https : //www.bbc.co.uk/news/uk 18458567 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 166 When audiovisual content is published online , it may be difficult to protect it from being used in ways not originally intended , or otherwise misappropriated by third parties . Nevertheless , it is still possible for private parties to contractually a gree as to how personality rights are to be exploited or protected . Performe rs often enter into new contracts for each separate project undertaken , and setting clear parameters from the outset can help avoid disputes later . Legal jargon need not be used , b ut it is prudent to specify in writing the ways in which a person ’ s image ma y be used , shared , and transferred to others . Both parties would be well -served to carefully consider how the content should be used beyond the scope of the original production , a s well as any provisions for additional remuneration . Where a studio uses fo otage from an earlier performance and then repurposes it , additional payments to the performer for re -use of footage are unlikely unless specifically stipulated in a contract . From a reputational perspective , it may also be appropriate to include anti -disparagement clauses or so -called morality clauses , both of which seek to prevent one party from injuring the reputation of the other . For the actor , this will be especially important in jurisdictions such as the United Kingdom , Sweden , and the United States , as in those places defamation and harm to dignity are notoriously difficult to establish . From a purely financial perspective , unwanted modification of appearances may harm or ev en destroy the working relationship between an actor and those working behin d the camera . Creative differences and demands , whether reasonable or not , have been known to derail or even sink productions . The loss or recasting of a star midway through shooti ng can cost a studio thousands , or even millions , of euros . Substantial modi fications beyond artistic necessity should therefore be discussed in advance , especially where such alterations have the potential to injure the feelings or interests of the actor . As a final point , as exciting and innovative as it may be to take someone ’ s image to create a digital double or ghost acting performance , doing so carries unavoidable risk . When we sit down to enjoy a film or television show we are , to paraphrase Ingmar Bergman , consciously priming ourselves for illusion . We put aside will and i ntellect to make way for a fictional narrative to unfold in our imagination.735 But the recent verisimilitude of digitally created faces is something altogether different , because i t has the potential to remove the autonomy and self -determination of the acto rs concerned . It also has the tendency to manipulate the evaluative or decision -making processes of the audience . When individuals are falsely depicted in non -fictional videos , in cluding documentaries , interviews and advertisements , the risk of financial , reputational and societal harm is even more palpable . It stands to reason that as artificial intelligence becomes more sophisticated , the distinction between authentic performance s and those digitally generated will blur . If the human eye is unable to disc ern the difference , perhaps 735 Bergman I. , Four Screenplays , Secker & Warburg , London . Translated from the Swedish by L. Malmstrom and D. Kushner . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 167 the law will likewise cease to distinguish the two , and thus extend rights of personality to cover one ’ s virtual self . If only one thing is remembered from this chapter , let it be that personality rights require a careful consi deration of situational context . Where such rights are litigated , courts are entrusted to interpret rather than to create the law , and thus merely affirm the applicability of esta blished rules which have evolved from that society ’ s customs . Regardless of o ne ’ s legal training or authority , it is no straightforward task to deliberate upon questions of art , truth , expression and identity – each of which speaks to the core of what it m eans to be human . When asked about personality rights exploitation and protec tion , especially in the case of novel technologies such as deepfakes and ghost acting , it appears that the typical lawyer ’ s answer must suffice , at least for now : it depends . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory ( Council of Europe ) 20 20 Page 169 Regulating AI The “ consideration of situational context ” mentioned by Ke lsey Farish in her contribution to this publication should probably be extended to all the legal issues dealt with in these pages . And there is an important fact ( already mentioned in the foreword ) to be recalled : computers will be computers , stupid machin es that only know the difference between a one and a zero , and as such , the results of their soulless calculation efforts will depend on and/or require human intervention and oversight . And very often , h uman intervention means regulation . Atte Jääskeläinen outlines in his contribution to this publication some principles that , in his view , should be applied to the regulation of AI . As observed before , transparency is the most fundamental principle here , si nce it “ serves human needs to make sense of how the s ystems work and address responsibilities to the right persons ” . Jääskeläinen suggests , however , that we need to accept that “ unknown risks may be impossible to regulate , at least if the regulation is based on the technology , not on goals ” . Moreover , regula tion of AI should “ reduce public risk without destroying creativity and innovation ” , and “ unnecessary obstacles to using data to create well -being and doing good ” should be removed . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Obse rvatory ( Council of Europe ) 20 20 Page 171 8 . Approaches for a sustainable regulatory framework for audiovisual indust ries in Europe Atte Jääskeläinen , LUT University , Finland , and LSE , London736 8.1 . Introduction A software programme detects the ball and the players in the picture of a football match and zooms in to where the action is . And since the cameras are extremely sharp , the ‘ virtual director ’ , a computer relying on machine -learning algorithms , is able to produce a full match broadcast featuring multiple cameras angles – without a human touch . The aim of Dutch football association KNVB and Dutch media company Talpa is to broadcast 80 000 amateur football matches live yearly , with no people involved . A software programme analyses your behaviour in social media and can detect your personality in the widely -used psychologi cal model Big 5 , attaining the same accuracy as the filling in of a questionnaire with information about some 200 Facebook likes . The result : a system that could be used to influence elections by targeting political messages for those most likely to be aff ected by a certain style of personalised advertising . A software programme developed by regional Swedish publisher Mittmedia uses personalisation combined with journalistic target -setting with a clear approach to contextualising data and using machine lea rning . I think we will see total personalisation and automation of publishing within the near future says the company ’ s chief technology officer . A software programme developed by Swiss company Largo predicts from an early script what an audience ’ s respo nse will be , on a country by country basis . Based on this analysis , 736 Atte Jääskeläinen is professor of practice at LUT University , Finland , and visiting senior fellow at LSE , London . He was director of news and current affairs of The Finnish Broadcasting Company 2006 -2017 and CEO of The Finnish News Agency 2004 -2006 . He co -authored with Maike Olij the EBU News Report 2019 “ The Next Newsroom . Unlocking the Power o f AI for Public Service Journalism ” . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Obse rvatory ( Council of Europe ) 20 20 Page 172 data scientists advise which parts of the script should be changed to increase the market appeal of a film and maximise revenues generated . All these real -life examples illustrate how arti ficial intelligence is already affecting the audiovi sual industry or its environment in a strategic way : audiovisual production may be largely automated ; audience behaviour may be analysed like never before ; this information can be used to both optimise th e value customers get from the market , but also to g uide creative and journalistic work and use it in democratic processes - sometimes in a way in which democracy was not supposed to work . Some have predicted that this evolution leads to a doomsday for hum ankind , if not properly regulated . As the Future Tod ay Institute ’ s Amu Webb wrote in 2019 : “ The lack of nuance is one part of AI ’ s genesis problem : some dramatically overestimate the applicability of AI in their workplaces , while others argue it will becom e an unstoppable weapon. ” 737 Regulation of AI , especia lly regulation of AI in areas that are relevant to the audiovisual industry , is a complex question with no clear answers . That complexity affects decision -making in the field . For both authorities and po liticians , the field of AI is hard to get a grip on , as the whole concept of AI is unclear and the target is moving fast : just when you think you ‘ get ’ it , new forms have already emerged . Regulation is a reactive process and in a fast -changing area it ofte n becomes obsolete before it can be applied.738 Some of the examples of AI generate the feeling that computers are creating something almost magical . Typically , this illusion is based simply on the use of smart mathematics with the help of huge computationa l resources available through cloud computing and fast telecommunications . What appears as creativity is just freedom of biases that limit human thinking combined with the ability to check and produce all alternatives , including those that humans would not consider even when called on to think out of the box . The authors of a recent book about the “ simple economics ” of predictive AI explain : “ All human activities can be described by five high -level components : data ; prediction ; judgement ; action ; and outcom es . As machine intelligence improves , the value of hum an prediction skills will decrease because machine prediction will provide a cheaper and better substitute . However , the value of human judgement skills will increase. ” 739 The OECD has estimated that almost half of all professions will either disappear or fundamentally change within 15 -20 years because of automation and new self -learning 737 Webb A. , “ The big nine before it ’ s too late ” , WMG Weekly , https : //www.wmgweekly.com/post/2019/06/08/the -big-ninebefore -it-s-too-late . 738 Petit N. , “ Law and regulation of artificial intelligence and robots - Conceptual framework and normative implications ” , https : //papers.ssrn.com/sol3/papers.cfm ? abstract_ id=2931339 . 739 Agrawal A. , Gans J. and Goldfarb A. , “ Prediction machines : The simple economics of artificial intelligence ” , Harvard Business Press . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Obse rvatory ( Council of Europe ) 20 20 Page 173 technologies.740 From a practical point of view , it appears that the challenge is alignin g processes in such a way that the strength of both machines and humans can be used in the best possible manner . Technologies don ’ t exist in isolation from culture and values . Some academics see increased automation as leading to a major redefinition of va lues in closer connection with computing .741 Others argue that communication can no longe r be defined as only a human -to-human phenomenon.742 One fundamental observation is that we are shifting into a many -to-many communication era , in which billions and bil lions of connections exist between individuals , powered by automation , defining our under standing of the networked world we live in .743 This chapter seeks to clarify some of the ethical and moral issues that should be taken into account when designing effec tive and ethically sound regulation for this technology area , which is at the same time fa scinating and , for some , frightening . 8.1.1 . The basics of AI , simplified The term “ artificial intelligence ” is not clear . One common definition is that AI describes machin e processes that would require intelligence if performed by humans . The term was originall y coined by John McCarthy , who began research into AI in the 1950s . He assumed that human learning and intelligence could be simulated by a machine . But in its most basic form , artificial intelligence is “ a system that makes autonomous decisions , a branch of computer science in which computers are programmed to do things that normally require human intelligence ” .744 One of the pioneers of artificial intelligence , Marvin Minsky , described artificial intelligence as a “ suitcase term ” : there are many concepts packed inside . Most applications of artificial intelligence today use technologies that fall into the domain of machine learning . With machine learning , computers lear n from data without being explicitly programmed . 740 OECD , The Future of Work . OECD Employm ent Outlook 2019 . Highlights , https : //www.oecd ilibrary.org/employment/oecd -employment -outlook -2019_9ee00155 -en . 741 Coddington M. “ Clarifying journalism ’ s qua ntitative turn ” , Digital Journalism , Routledge , 3 ( 3 ) , pp . 331 –348 . Milosavljević M. and Vobič I. , “ ‘ Our task is to demystify fears ’ : Analysing newsroom management of automation in journalism ” , Journalism , SAGE Publications , https : //journals.sagepub.com/doi/abs/10.1177/1464884919861598 ? journalCode=joua . 742 Lewis S. C. , Guzman A. L. and Schmidt T. R. , “ Automation , journalism , and human –machine communication : Rethinking roles and relationships of humans and machines in news ” Digita l Journalism , Routledge , 7 ( 4 ) , pp . 409–427 . 743 Jääskeläinen A. and Olij M. , “ The next newsroom : Unlocking the power of AI for public service journalism ” , European Broadcasting Union , https : //ww w.ebu.ch/publications/news -report -2019 . 744 https : //futuretodayinstitute . com/trend/artificial -intelligence/ .. ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Obse rvatory ( Council of Europe ) 20 20 Page 174 ◼ In traditional programming , data are run o n the computer , which produces the output . Programmers therefore have to know the rules if the desired output is to be achieved . ◼ In machine learning , data and exampl es of the desired output are first run on the computer , which then learns from them to crea te its own rules . These are then used to produce the output . A very powerful and resource -consuming kind of machine learning , deep learning , uses algorithms called ‘ artificial neural networks ’ , which are modelled on the way neural networks operate in the h uman brain . Advances in deep learning have made language technologies and image recognition much more sophisticated and therefore have opened up substantial opportun ities in the audiovisual sector . The key benefit of deep learning is that it is able to ab sorb huge amounts of data . This has allowed machine learning to accomplish tasks it never could have managed before . On the other hand , it also requires huge amounts of training data and expensive computational resources , so using it on a large scale has o nly recently become possible - and is still limited . The different types of machine learning are based on how the machines use data to learn rules . The oldest kind o f machine learning is called supervised learning . It uses a set of desired outcomes to trai n the computer . The algorithm then comes up with rules that will allow the computer to produce results similar to those of the training dataset . In unsupervised lear ning , the computer is used to group a huge dataset in a meaningful way . This approach does not require a set of training data , as the data set is typically clustered based on its internal logic . One of the more recent models is reinforcement learning , in w hich the system learns on the fly from feedback it receives from its environment . This fiel d is developing fast and is quite useful as these systems based on reinforcement learning can quickly adapt to new situations and learn from user behaviour – which c an suddenly change , for any reason . For example , the most advanced recommendation systems u se reinforcement learning as a way to monitor and adapt to the behaviour of users . All three learning models can be combined in a complex system . An advanced system typically has multiple algorithms and can conjoin different approaches to achieve the desir ed outcome for a specific situation . For this kind of system , it is crucial to understand the problem , the context and the information contained in the data . What i s confusing about the different areas of artificial intelligence is that people often mix u p the dimensions of AI . For example , machine learning often appears alongside image recognition and natural language processing in lists of key AI application areas . But machine learning is present in almost all modern applications of artificial intelligen ce , including medical diagnosis , self -driving cars , prediction systems and automatic classification . Concerning the need to regulate AI , a very important categorisat ion is narrow or weak AI , in which the system performs a single task related to a specific problem . A much more difficult area of regulation is so -called artificial general intelligence ( AGI ) , which is a ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Obse rvatory ( Council of Europe ) 20 20 Page 175 type of AI that can solve complex problems in any co ntext and define its goals autonomously . While there are bold initiatives to reach this kin d of autonomy of computers , like Google ’ s DeepMind and OpenAI , this kind of AI has not yet been achieved . Most researchers believe that we are still decades away , at least , from reaching this level of AI.745 8.2 . How is AI used in audiovisual industries ? By audi ovisual industries , we traditionally mean the production and marketing of movies , television and the Internet ’ s audiovisual content . However , as it is difficult to define clear boundaries for AI , it is not wise to limit our thinking only to the specifics o f this particular sector . Delivering messages nowadays often happens with mixed methods - and these methods may even be autonomously selected , based on individual p references , by data driven AI systems . Therefore , the challenges of regulating AI in the aud iovisual sector are strongly related to other sectors close to it . The key question is : what are we trying to achieve with regulation and how should it be applied i n areas relevant to this sector . The range of potential applications is already diverse , and developing fast into areas that we can ’ t even imagine yet . However , it would be neither wise nor effective to apply the same rules to automatic translations , self -driving cars , sensitive personal data and advanced camera technology , to mention just a few of the application areas . How to get a grip on this issue then ? First , we should try to increase our understanding of the consequences of different usages of AI in audiovisual industries . As they vary substantially , even a rough categorisation helps to und erstand the values that should be protected with regulation . In the absence of a better and more sophisticated categorisation , one can use here a categorisation em ployed in the report for the European Broadcasting Union on how to use AI in public service journalism : “ The Next Newsroom ” 746 , which could work as a basic framework to understand the strategic relevance of different types of AI technologies for the audiovisual industry . First , artificial intelligence can be considered as a growing set of practica l tools . This is AI at a purely operatio nal level , aiming primarily to automate repetitive tasks and reduce costs . For example , the solutions including AI systems for editing and media management tasks are numerous , and their adoption is increasing with su bstantial speed . Tools used for transcri bing and translating languages , and for detecting specific material 745 See e.g . Joshi N. , et al . “ How far are we from achieving artificial general intelligence ? ” , https : //www.forbes.com/sites/cognitiveworld/2019/06/10/how -far-are-we-from -achieving -artificial -general intelligence/ # 5ebe24f06dc4 and Fjelland R. , “ Why general artificial intelligence will not be realized ” , https : //www.nature.com/articles/s41599 -020-0494 -4 . 746 Jääskeläinen A. and Olij M. , op.cit . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Obse rvatory ( Council of Europe ) 20 20 Page 176 in archives , make reusing material easier and faster , and change the value -creation logic in production . For example , Deutsche Welle uses AI -based l anguage processing just to keep the news room on track with what is happening real -time in its news operations in multiple languages . Swiss Broadcasting is one of the companies that has developed advanced systems to detect persons and places in archived vid eo footage747 . Irish broadcaster RTE and Al Jazeera even collaborated to create a system that measures the airtime of politicians during election campaigns and flags content that might carry a regulatory problem . The system is based on an advanced method of detecting not only items and persons in the pictures , but also their context.748 One could reasonably ask : Is there anything special in these tools that requires specific regulation ? Or is it simply enough that these tools be used in a responsible way . After all , these are just tools and technol ogies to help get the work done . Second , AI allows the creation of a data -savvy culture that rests on defining and knowing your objectives and learning ways to measure and optimise , based on them . This also allows for a very strategic use of AI : targeting messages and optimising value for individual customers based on information about their preferences and behaviour . The same type of optimisation and personalisation AI is also used to optimise the financial results of audiovisual operations , for example by creating more efficiency in marketing campaigns by testing the effectiveness of different messages or identifying interesting market clusters and opportunities . One of the fundamental challenges in the era of abundanc e that digital technologies have creat ed is finding good content amidst too much clutter . So there ’ s a need to connect content with the audience that is interested in it . This kind of optimisation is not limited to online offerings . For example , Spain ’ s RT VE has a promising research project on designing television scheduling using AI algorithms . They ask : which TV programs fit the taste for the audience at a specific time of the day or on a specific day of the week ? 749 It is technically already possible to co nnect all a user ’ s devices submitting information about their musical preferences , movies watched , television routines and even to detect their mood from their personal health devices , and to then direct them to the best content . Add information about weat her , work calendar and local traffic , and you have quite a powerful personal assistant serving you what may be interesting right now , right here . All these services already exist , and most of them are based on audiovisual content . In reality , some of the g lobal tech giants are already offerin g something like this . Just think of what Google Assistant or Apple ’ s portfolio of services are able to do , and all 747 Rezzonico P. , “ Artificial intelligence at the service of the RTS audiovisual archives ” , FIAT/IFTA , http : //fiatifta.org/index.php/a rtificial -intelligence -at-the-service -of-the-rts-audiovisual -archives/ 748 TM Forum , “ AI indexing for regulatory practise ” , https : //www.tmforum.org/ai -index ing-regulatory -practise . 749 Cibrián E. et al . “ Artificial intelligence and machine learning for commercial analysis in the audiovisual sector : A case study of designing TV schedules ” , http : //www.kr.inf.uc3m.es/artificial -intelligence -and-machine learning -for-commer cial-analysis -in-the-audiovisual -sector -a-case-study -of-designing -tv-schedules/ . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Obse rvatory ( Council of Europe ) 20 20 Page 177 those functionalities are combined on our mobile phone ’ s operating system – controlled by those same co mpanies . Third , AI can be used in uni que processes aiming to create better and more distinctive content . This involves not only optimising and repeating what has already been done , but creating completely new approaches without the limitations and biases o f the human brain . This area poses in teresting challenges as sometimes a good outcome created by a machine does not actually feel better than one created by a human , or may not be acceptable according to our ethical code . Another interesting angle is the q uestion of how to maintain creativity and artistic motivation , and identity when computers take part in the process and work in a way that could be defined as creative - at least according to some definitions . 8.3 . Is AI somewhat different than previous technol ogies ? How to prevent AI from causing harm ? How to mitigate risks involved with creating such AI systems ? Is the world safe when cars drive autonomously on the streets ? Or , is the world fair , if crime is detected based on where you live or how you look int o the camera ? Before jumping into reg ulating AI we should ask : how is it different ? What makes AI so special that it would need special attention from regulators ? Are the problems really new ones , looked at from a human ’ s and society ’ s perspective ? Or are they just new versions of the same fu ndamental problems that the law may already address ? 8.3.1. Who is responsible when AI causes harm ? The key concept resulting from the question of who is responsible when AI causes harm is AI ’ s assumed ability to act human -like without human -like responsibility and control . In other words : If AI has potential autonomy , should it be controlled and regulated ? Another special feature is the fact that AI ’ s actions are difficult to foresee when systems are designed . This is especi ally true if systems are supposed to be ‘ creative ’ , as you would expect in the audiovisual sector . What if the systems create results so unexpected that it is impossible to say that the designer of the system should have foreseen them and is therefore resp onsible for the outcomes ? Typically a nd traditionally , we have not considered machines responsible for their actions . The responsible party is the one who uses the machine or the one who built the machine - without enough care750 . In theory , it is reasonable to imagine a world where machines w ould have responsibilities and would have to compensate for the harm they cause . We do have 750 Petit N. , op.cit . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Obse rvatory ( Council of Europe ) 20 20 Page 178 constructs like companies with a legal personality which may carry duties and claim invoices . However , in most cases we have co nsidered humans the ones best suited to carry moral responsibilities and do ethical value -weighing . In all high -end technology , it is however difficult to locate the relevant actor responsible for outcomes that may occur only later and in contexts the orig inal builder never thought about . Autonomy is , as the European Group on Ethics in Science and New Technologies ( EGE ) states in their report “ Artificial Intelligence , Robotics and ‘ Autonomous ’ Systems ” , an important aspect of human dignity which should not be relativised and shifted to techno logy . Machines can ’ t take the moral standings of humans nor inherit human dignity . All our moral and legal institutions are based on the idea of humans taking on moral responsibilities , like being accountable or liable , or carrying duties.751 8.3.2 . It ’ s not just the economy It is indisputable that personalisation is valuable for individuals , but especially in an industry with substantial cultural and societal relevance it is crucial that these systems serve interests beyond thos e of the individual , in other words the interests of the audience or society as a whole . It is essential to find an acceptable balance between these potentially competing interests . In recent times , some of the most fundamental challen ges of democracies ha ve been created by ‘ targeting machines ’ in the wrong hands : “ fake news ” on a massive scale , deep fakes , or the ability to fashion a filter bubble in which to live . Audiovisual industries have special relevance in the democratic process es of our societies , both at the national and the European levels . And , we live in a global arena , especially when AI is considered . Data and software services are increasingly offered through global systems and often in a market controlled by US or Chines e companies . How a su stainable creative and audiovisual sector can be fostered when strategic use of AI in the field is becoming more and more important , is also a question of European competitiveness and will define what kind of soft power role Europe has in the future . The a udiovisual sector as a whole is tightly connected with the cultural and political needs of societies . However , while culture has higher societal values and relevance , it also has economic value in the marketplace and economic reality . In their understandin g of the economic impact of culture , some divide it into ‘ institutional value ’ connected to the macroeconomic effects on the national or international level for economies , and ‘ micro -economic ’ value , which is the basis of single transa ctions in which 751 European Group on Ethics in Science and New Technologies , “ Statement on artificial intelligence , robotics and ‘ autonomous ’ systems ” , European Commission , Directorate -General for Research and Innovation , http : //ec.europa.eu/research/ege/pdf/ege_ai_statement_2018.pdf . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Obse rvatory ( Council of Europe ) 20 20 Page 179 peopl e pay for cultural experiences . Institutional value is the theoretical basis on which economic subsidies have been granted to cultural industries752 . The concept of AI for social good ( AI4SG ) provides some inspiration for how to design systems that promote s ocietal value . These include trustworthiness as a basis of society and using all technologies in the aim to positively impact life.753 Other recommendations include developing systems in steps and testing them in the lab before launchi ng them in production , and preventing manipulation through outside intervention . Promoting social good is often successful when users are involved in designing the systems , the autonomy of the user is respected and informs the system design , and the user is given the ability to provide the systems and their outputs with sense and meaning . 8.4 . We have a moral obligation to do good with AI When we consider that best way of regulating an industry , there ’ s always a trade -off of costs of regulation against ben efits . When we see only risks , and try to avoid harm and establish accountability with regulation , we may lose some of the benefits , as regulation typically disincentivises innovation and leads to costs.754 The problem with tight regulation is that it typic ally restricts risk -taking , cr eativity and value creation . Therefore , we have to ask what level of risk is acceptable and who should carry the risk if something goes wrong . So , in designing regulation it is essential that we look at both sides of the phen omenon . On the philosophical s ide , one has to address the question of how to inspire innovation and creativity , and how not to establish a system that discourages risk -taking . Risk is fuel to the economy and well -being . Risk -taking is part of creativity an d value creation in audiovisua l industries as well . Therefore , both in the field of AI in general , as also in the field of audiovisual industries , before regulating a specific - or in this case unspecific set of technologies - one has to ask whether there is a problem that has to be s olved . Going even further : is there some regulation that should be removed to enable doing good with AI ? Or should regulation be put into place to enable easier access to data or rights needed for the shift towards a new indus trial era , also in audiovisual industries ? The discussion about regulation of AI has its roots in the field of basic human instincts and feelings which make us fear that machines will take ultimate control over us . 752 La Torre M. , “ Defining the audiovisual industry ” , in La Tor re M . ( ed . ) The economics of the audiovisual industry : Financing TV , film and web . Palgrave Macmillan UK , pp . 16 –34 . 753 Taddeo M. , “ Trusting digital technologies correctly ” , Minds and Machines , 27 ( 4 ) , 565 –568 . Taddeo M. , Floridi , L. , “ The case for e-trust ” , Ethics and Information Technology , 13 ( 1 ) , 1 -3 . 754 Gurkaynak G. , Yilm az I. and Haksever G. , “ Stifling artificial intelligence : Human perils ” , Computer Law & Security Review , 32 ( 5 ) , pp . 749 –758 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Obse rvatory ( Council of Europe ) 20 20 Page 180 This is especially the case with the imag ined Artificial General Intell igence with a will of its own . This ability to act independently of humans and the partly fictional construct of human -like intelligence is the basis of doomsday predictions and underpins calls for specific regulation of AI . While often regulation is consi dered necessary to manage risks and prevent harm , in the case of audiovisual industries , regulation could also be seen from another ethical angle : we have a moral and ethical obligation to do good ; how can we encourage the good usage of AI in a responsible way , and could regulation create an environment that fosters creativity and innovation ? In other words : richer European life and economic prosperity . Regulation is typically established when there is a problem that needs solv ing . But , we can only lose som ething if we have first gained it . 8.5 . Regulation should be human -centric and goal -based Let ’ s remind ourselves that in a world full of risks , some of the risks are desirable , because taking them is the basis of creativity and wel l-being . Fundamentally , the qu estion of regulating AI in the audiovisual industries is a question about which risks are so undesirable that they deserve to be regulated.755 If we want an AI system to be creative , should we allow it to create unforeseen resu lts ? What are the real conseque nces of these risks if taken ? 756 Applying ethical rules mechanically can sometimes be tricky . For example , sometimes , demanding transparency may result in a ridiculous situation . With creative work in the audiovisual sector , w ho has ever known how an artist came to a particular artistic conclusion ? Do we even want to know ? Isn ’ t the mystique part of the fascination ? Why should we demand transparency from the machines that are used in the creative part of the industry if we don ’ t demand the same from humans ? I n this case , there is no public or private interest in protecting someone from creativity with the help of technology . On the other hand , the benefits of using AI in audiovisual industries can be especially promoted through effective regulation , because it minimises risksrelated to a lack of clarity . Are there obstacles in the present regulatory system that should be removed ? Should we foster the creation of regulated data -sharing arrangements to make new businesses easier to establish and more value for cu stomers and citizens easier to create ? 755 Buiten M . C. , `` Towards Intelligent Regulation of Ar tificial Intelligence '' . European Journal of Risk Regulation . 10 ( 1 ) : 41 –59 , https : //www.cambridge.org/core/journals/european -journal -of-risk-regulation/article/towards intelligent -regulation -of-artificial -intelligence/AF1AD1940B70DB88D2B24202EE933F1B . 756 Scherer M . U. , `` Regulating Artificial Intelligence Systems : Risks , Challenges , Competencies , and Strategies '' . Harvard Journal of Law & Technolog y , Vol . 29 , No . 2 , Spring 2016 , p. 364 , https : //papers.ssrn.com/sol3/papers.cfm ? abstract_id=2609777 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Obse rvatory ( Council of Europe ) 20 20 Page 181 In my view , Europe suffers from an overly risk -centred approach to regulation . While we evaluate risks and consider managing them , US and Chinese players are already on the global playi ng field , and establishing defen ces for their already -dominant roles in the industry . 8.5.1 . Major risks should be addressed Our technology already allows us , together , to destroy nature and even the whole of humankind . According to Huber , these are “ public ris ks ” that are so broadly distribu ted and outside the individual risk bearer ’ s understanding and control that they pose threats to human health and safety757 . In the audiovisual sector , risks that may cause most harm are actually of this kind , and they are th ose that result in the unintentio nal destruction of the foundations of our societies because citizens are manipulated and nudged for commercial and political purposes . In a way , it ’ s one example of the ” tragedy of the commons ” ,758 a still -discussed concept in which individuals acting accord ing to their self interest behave contrary to the common good . One approach to this set of risks is to use human rights as a lens and a policy tool . Our legal system places the obligation to avoid the infringement of human rights . However , if democracy is in danger because of increased usage of targeting , who is responsible ? And even if the concept of responsibility could be created , are judges and national legal systems capable of identifying the respo nsible parties at a speed that makes the regulation eff ective ? Machine learning systems have repeatedly been both accused of making – and , it has been revealed , actually make - of biased decisions or predictions.759 It is actually possible that the system m ay be biased because it was designed to be so . More ofte n , though , the bias comes from the data used in training the system . And , finally , these data often just reflect and reveal the bias of current reality , and the decisions made by humans . They therefor e mirror our present societal values and choices , and hu man and cultural biases . This , again , reflects the societal nature of AI systems especially in the audiovisual industries . We have to be careful not to blame the AI systems for something that actually might have societal value : revealing how biased the dec isions humans have made until now really are . Instead , we should welcome the systems , as they make us more conscious of our values – taking , of course , care that unethical decisions are not applied in practice before testing and the analysis of results . 757 Huber P. , “ Safety and the second best : The hazards of public risk managemen t in the courts ” , Columbia Law Review , 85 ( 2 ) , pp . 277 –337 . 758 Feeny D. et al . , “ The tragedy of the commons : Twenty -two years later ” , Human ecology , 18 ( 1 ) , pp . 1 –19 . Hardin G. , “ The tragedy of the commons ” , Journal of Natural Resources Policy Research . Taylo r & Francis , 1 ( 3 ) , pp . 243 –253 . Stavins R. N. , “ The problem of the commons : Still unsettled after 100 years ” , The American economic review , 101 ( 1 ) , pp . 81 –108 . 759 See chapters 1,2 and 3 of this publication . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Obse rvatory ( Council of Europe ) 20 20 Page 182 8.5.2 . Humans are the responsible ones We can ’ t avoid concluding that a well -functioning regulatory system in a fast -changing world should be flexible and based on fundamental principles rather than constitut ing an attempt to regulate the technology . There are alr eady approaches that may function well : focus on the goals and be human -centric , not technology -centric . One of the fundamental principles to build on is the question of allocating legal responsibilit y . In all societies , there is a system in which responsi bility , liability , and in some cases even accountability , is allocated in cases where damage to others is caused . In our present systems , this responsibility can ’ t be allocated to technologies or mach ines , but can be assigned to humans , companies and other legal entities . In some industries , the risks have been considered so huge that organisations carry a heavier responsibility for results even in the absence of negligence . AI is created by humans who are well educated and often aware of the possible risks their technology may create for users or objects . It is not unbearable for them - or in practice for the institutions they represent - to carry the responsibility of their actions , and in some fields even to carry strict liability without fault . So far , whenever regulation appears to be about technology , it is in reality about the persons who created or used that technology , and organisations in which they are employed . And , interestingly , while AI -based technology may have its own faults , often humans ar e even more faulty . The issue is that we have become used to human faults but consider the same faults caused by technology to be less acceptable .760 One core question is whether there really is a new risk that AI creates , perhaps even as yet unknown .761 8.5.3 . Transparency as an interim solution ? Without transparency , citizens and consumers face decisions they do not understand and have no control over . To assess whether there should be liability for an AI -based decision , the courts , too , need to understand how the AI made its decision . So , requiring transparency and explainability might be a suitable solution to some of the ethical and legal problems , and h as already been recommended as a tool for regulation .762 Actually , in the discussion about sustainable AI regula tion , transparency is a central concept , at least as an interim solution . Transparency in relation to data refers to the obligation to keep users , customers or clients informed about how their dat a are being used . In the world of algorithms , transparency means the need to explain the way they work to the extent that they are understandable for the users . Explainability - a concept close to transparency - means 760 Petit N. , op.cit . 761 Scherer M. U. , op.cit . , p. 3 64 . 762 See chapter 1 of this publication . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Obse rvatory ( Council of Europe ) 20 20 Page 183 ultimately , even , that the values on w hich the systems base their behaviour should be traceable . However , a balance must be struck between the benefits and costs of this transparency . Sometimes , requiring transparency may in practice mean implementation of the system is rendered technically unfeasible .763 Requiring more transparency may even oblige us t o accept that systems are less accurate than they could technically be . An interesting choice , actually : if a diagnostic system is more accurate as an unexplainable black box , would you still save a life with it - without knowing how ? So , black and white regulation requiring transparency in all cases in which AI is applied is not feasible either . There are other problems with transparency , as well . There may be trade secrets that can ’ t be revealed or the costs of maintaining transparency may result in a concentration of industries that is undesirable.764 Requiring costly transparency may have negative effects on innovation.765 Sometimes the logic of machines simply can ’ t be expressed in a language understandable by humans . And how can accountability be traced i n a technology field largely based on sharing resources like pieces of code and AI algorithm models globally ? 766 8.6 . Human -centricity , not technology -centricity The discussion about reg ulation of AI has followed two dominant routes : one based on the point of vie w of the legal system ; the other aligned with the notion of starting from the technologies , and then building regulatory needs bottom -up from specific AI applications.767 However , the basis of a good and functioning regulatory system rests not on these conce pts but on the needs of humans and societies . While all this discussion about the special distinctive features of AI technology is valuable , fundamentally AI is just a technology - a piece of computer software whose core domain is mathematical calculations - and it is fair to question whether it is so fundamentally novel as often presented.768 In conclusion , human -centricity in regulating AI may mean : ◼ transparency serves human need s to make sense of how the systems work and address responsibilities to the rig ht persons ; 763 Buiten M. C. , op.cit . 764 Scherer M. U. , op.cit . 765 Buiten M. C. , op.cit . 766 Leonelli S. , “ Locating ethics in data science : Responsibility and accountability in global and distributed knowledge production systems ” , Philosophical transactions . Series A , Mathematical , physical , and engineering sciences , 374 ( 2083 ) , https : //www.ncbi.nlm.nih.gov/pmc/articles/PMC5124067/ . 767 Petit N. , op.cit . 768 Edelman R. D. , “ Here 's how to regulate artificial intelligence properly ” , https : //www.post -gazette.com/opinion/Op -Ed/2020/01/14/R -David -Edelman -Here -s-how-to-regulate artificial -intelligence -properly/stories/202001140013 . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Obse rvatory ( Council of Europe ) 20 20 Page 184 ◼ accepting that unknown risks may be impossible to regulate , at least if the regulation is based on the technology , not on goals ; ◼ we should try to reduce public risk without destroying creativity and innovation ; ◼ we should look at the present leg al environment , especially in Europe , and remove unnecessary obstacles to using data to create well -being and doing good ; ◼ humans should have more real control over how thei r data is used ; however the present GPDR framework does not function well towards th at goal,769 as the consents are in reality given without real understanding and a large part of personal data usage happens through third parties ; the European Union should critically review its policies in the field of AI and data , and centre more on enabli ng the doing of good , without forgetting that major risks , especially to democracies , should be addressed . 769 See chapter 2 of this publication . ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Obse rvatory ( Council of Europe ) 20 20 Page 185 Concluding remarks The common sense expression “ with great power comes great responsibility ” ( made famous by Spider -Man ’ s comic books but dati ng back at least to the French Revolution ) 770 fits AI like a glove . AI has enormous potential for doing both good and evil . That is why we find it fascinating and scary at the same time , and while some will tend to worry , others will set the accent on the ma rvellous things that can be achieved with this ground -breaking technological development . Indeed , a reading of the different contributions published in this report shows there is no single vision of how AI should be regulated , and yet there are certain pri nciples that appear to be ( in one way or another ) in the minds of all of the authors : explainability , trust , privacy , pluralism , but also freedom of expression , creativity and innovation . If we manage to combine all those goals , AI can be a blessing for hu manity in many ways . Unless , of course , one day Elon Musk ’ s worst nightmares become reality and machines take over the world . But such dystopian fut ure is not on the horizon . Not yet , at least . 770 https : //quoteinve stigator.com/2015/07/23/great -power/ .
