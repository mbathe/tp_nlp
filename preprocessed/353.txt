1 Trust Manifesto November 6th , 2019 2 OUR GUIDING OBJECTIVE AI Must be Ethical by Design Arm believes that the technology sector has a responsibility to ensure that the development of AI1 is guided by certain principles in order to generate public trust in the underlying technology and its applications . Further , Arm believes that unless the technology sector gains this trust , then it will fail to deliver the full potential that we are confident AI technology can bring to individuals , businesses and societies across the globe . Arm would like to see the technology sector come together to create an ethical framework to ensure that AI is developed in a fair and responsible way . Without such a framework , there is a risk that regulation will become onerous and fragmented , and will not allow AI to succeed.Creating the right ethical framework requires collaboration and dialogue . We have drawn up some principles – and some challenges – which we believe could help drive the debate . We welcome others to join us in doing so . We believe that ethics should be incorporated in the key design principles for AI products , services and components . However , at present there is no defining set of ethics to follow and so we call for the formation of an industry-wide working group to define and standardize a set of ethics that can be adopted by anyone deploying AI technologies . Since ethics are so critical to AI , it is essential that anyone working in the field has a solid foundation in the issues . We call on all universities and colleges that teach AI to include mandatory courses on issues relevant to ethics in AI at undergraduate and graduate level . Further , we believe that all businesses developing AI technologies must ensure that their staff complete mandatory professional training in the field of AI ethics . TRUST MANIFESTO 1 For the purposes of this document , we define AI as the simulation of human intelligence processes by machines , especially computer systems . At a basic level , these new systems bring about the ability to correlate historical data to provide informed decisions , using techniques that describe solutions which may be beyond human ability . 3 TRUST MANIFESTOEthical Principles of Trust in AI Systems There are many issues that must be addressed in the development of an ethical framework for AI that enhances trust . As a starting point , Arm proposes the following principles . 1/ WE BELIEVE ALL AI SYSTEMS SHOULD EMPLOY STATE-OF-THE-ART SECURITY Given the risk of cyberattacks on critical AI systems causing major disruption , all AI deployments should take advantage of task-specific advanced hardware and software security . Only by ensuring an end-to-end chain of security can we truly trust AI technology and the data , actions and insights that the technology will create . 2/ EVERY EFFORT SHOULD BE MADE TO ELIMINATE DISCRIMINATORY BIAS IN DESIGNING AND DEVELOPING AI DECISION SYSTEMS The technology sector is global and the AI industry , in turn , is global and serves a community of diverse customs , values and perceptions about what is ethical . There is wide recognition that the careful use of training data is crucial in ensuring that discrimination and bias do not enter AI systems to the extent that the implementation of such data may be illegal or unfair . Concerns about this are already playing a role in the debates about using AI in areas as diverse as criminal justice and facial recognition technology . Standards must be developed to both assess the quality of training data and to enable traceability so that systems can be linked to the data sets on which they were trained . 3/ WE BELIEVE AI SHOULD BE CAPABLE OF EXPLAINING ITSELF AS MUCH AS POSSIBLE : WE URGE FURTHER EFFORT TO DEVELOP TECHNOLOGICAL APPROACHES TO HELP AI SYSTEMS RECORD AND EXPLAIN THEIR RESULTS Where appropriate , the way an AI system works should be capable of being transparent , and the decisions that result from it should be explainable to a human interrogator including non-specialist users of AI . 4/ USERS OF AI SYSTEMS HAVE A RIGHT TO KNOW WHO IS RESPONSIBLE FOR THE CONSEQUENCES OF AI DECISION MAKING In future , AI systems will make life-threatening decisions such as in autonomous vehicles or robotic surgery . The industry needs to work with standards and regulatory bodies to develop commonly acceptable frameworks for mapping liability where it is a concern . 5/ HUMAN SAFETY MUST BE THE PRIMARY CONSIDERATION IN THE DESIGN OF ANY AI SYSTEM In general , if AI technologies are not able to demonstrate they can operate as well , if not better than humans , in instances where human harm is possible , they should not be deployed . 6/ WE WILL SUPPORT EFFORTS TO RETRAIN PEOPLE FROM ALL BACKGROUNDS TO DEVELOP THE SKILLS NEEDED FOR AN AI WORLD Opinions differ as to the likely impact of AI on jobs , but most agree that the nature of work is going to change , and the tech sector can not be complacent . All stakeholders should look afresh at the skills training provided in schools , colleges and elsewhere , and help our training providers to respond fast to the demand for new skills . This needs to include training people in appropriate skills across the whole of society .
