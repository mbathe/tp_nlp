ethical introduction biometrics forensics ethics group bfeg commissioned report response recent field trials live facial recognition lfr undertaken south wales police swp metropolitan police service mps report outlines framework ethical principles taken consideration developing policy use lfr technology policing purposes details swp trials covered series reports published big brother watch london policing ethics panel universities lice science institute crime security research institute cardiff university outline trial design evaluate trial performance raise number ethica legal issues pertaining deployments aim report provide short general briefing applies recent field trials also use lfr policing contexts widely read conjunction afore mentioned reports briefing document outlines ethical issues raised use live real face recognition technology policing purposes focuses use technology relatively controlled environments namely public spaces people gathered relatively static example concert venues sports stadiums public rallies clearly defined entry exit points people channelled past cameras xample approaches railway stations airports shopping centres political marches demonstrations terminology definitions police use facial recognition technology variously described live facial recognition automated facial recognition metropolitan police service wales police assisted facial recognition iometrics forensics ethics group outline definition live facial recognition technology based upon international standards organisation iso biometric vocabulary iso used throughout document biometric recog nition automated recognition individuals based biological behavioural characteristics example facial image dna voice gait automated recognition implies machine system used recognition either entire process assisted human live facial recognition lfr automated one matching near video images individuals curated watchlist facial images recent field trials lfr used assist recognition persons interest watchlist meant police personnel required possible match identified system system alert decide actions taken ground issues arising police use live facial recognition technology ethical issues arising police use live facial recognition technology interim report biometrics forensics ethics group facial recognit ion working group february evidence gathering process bfeg facial recognition working party gathered evidence representatives swp mps academics cardiff martin innes bethan davies essex peter fussey universities undertaken evaluations swp mps field trials respectively police digital service home office defence science technology laboratory dstl biometrics surveillance camera information commissioners offices forensic science regulator civil society groups big brother watch liberty technical issues substantial body scientific research development facial recognition algorithms platforms systems may used live facial recognition lfr briefing document focuses four issues may affect performance lfr policing contexts data training algorithms generation outputs role human operators deployments wild data training lfr algorithms biometric technologies facial recognition require machine algorithms trained dataset labelled system recognise faces within parameters data trained previously exposed certain types faces example blac asian ethnic minority faces female faces lfr training datasets bias feed forward use technology human operators high scientific concerns intrinsic potential racial gender bias within lfr software generation outputs lfr technology probability based provides probability match captured image environment enrolled image watchlist multiple factors affect probability match including quality rolled images pixel size lighting background custody images versus social media etc quality captured images algorithm matching performance size watchlist environmental conditions principally limited lighting camera position image captured thresholds set determine match biometric decision determining number false correct matches whether match instigates near real time response whether response includes human decides take action overrule machine biometric match role human operators key aspect use technology relationship output lfr human operators responses lfr software decide output interpreted upon decision responsibility system operator field trials police personnel required verify override poss ible match identified system decide action taken example intervention identity verification arrest concern error bias accuracy algorithmic output results biased decision part human operators example system generates many correct matches operators may start defer algorithm decision act upon matches without first verifying match accuracy alternatively system generates many false matches operators may begin ignore override outputs thereby missing correct matches finally thresholds set high matches generated operators may adjust thresholds produce potenti ally false matches may result interventions attendant ethical consequences deployments lfr wild machine learning taking place exposure algorithm new sources data public space every police trial potentially operational deployment every operational deployment experimental trial inheren ambiguity means difficult discern purpose recent police field trials police operations experiments raises questions securing consent trial participation nature composition watchl ists whether simulated contain images persons interest extent field trials risk undermining public confidence trust policing conclusions number questions accuracy live facial recognition lfr technology potential biased outputs biased decision part system operators ambiguity nature current deployments need differentiate errors biases herent design training technology introduced human operator decides action basis system output addition biometrics forensics ethics group bfeg notes lack independent oversight governance use lfr pending development legislative framework bfeg recommends police trials lfr comply usual standards experimental trials including rigorous ethical scientific design bfeg drafted number ethical principles used inform deployments frame policy found annex accomp anied set questions arise live facial recognition used policing contexts found annex references swp trialled technology two modes afr afr locate trials involve real one facial matching big brother watch face lawless growth facial recognition policing may london policing ethics panel interim report live facial recognition july davies innes daw son evaluation south wales police use automated facial recognition september parkhi vedaldi zisserman deep face recognition visual geometry group university oxford buolamwini gebru gender shades intersectional accuracy disparities commercial gender classification proceedings machine learning research susskind future politics living together world transformed tech oxford oxford unive rsity press biases predicting recidivism see angwin larson mattu kirchner machine bias propublica may authors report authored facial recognition working group biometrics forensics ethics group mbers group professor nina hallowell chair oxford university professor louise amoore durham university professor simon caney warwick university peter waggett ibm annex ethical principles inform use live facial recognition following ethical principles based upon developed biometrics forensics ethics group taken account considering deployment live facial recognition lfr automated biometric recognition technologies policing purposes public interest use technology permissible employed public interest cases might straightforward example public interest able identify engaged criminal activity cases may less straightforward effectiveness use technology justified ffective tool identifying people avoidance bias algorithmic injustice use technology legitimate involve exhibit undue bias unjust two ways first kinds misrecognition inherently demeaning second technology biases result unequal discriminatory treatment individuals example members groups may much likely detained required identify themsel ves automated biometric recognition systems including data tra ining sets used public places open scrutiny effective oversight impartiality deployment technology deployed policing purposes must used even way example used ways disproportionally target certain events others without compelling justification necessity individuals normally rights conduct lives without monitored scrutinized given use technology interferes rights technology used less invasive techniques available furthermore technology used ways minimize interference people engaging lawful behaviour proportionality addition meeting necessity requirement technology also meet proportionality requirement permissible benefits proportionate loss liberty privacy benefits sufficiently great justify interference rights impartiality accountability oversight construction watch lists humans algorithms involved construct ion watchlists use technology essential impartial free construction watchlists needs subject oversight independent body public trust technology used policing purposes important using either operational deployments trials engage public consultation provide rationale use cost evaluation use technology needs take account whether resources requires could better used elsewhere annex questions arising live facial recognition used policing contexts questions accompany ethical principles treated exha ustive checklist intended aid interpretation ethical principles deploying live facial recognition lfr public interest lfr deployed instance crime prevention intelligence gathering etc effectiveness accurate technology false rates calculated lfr technology validated using ground truth datasets criteria successful deployment true positive false positive matches increased arrests less criminal fewer arrests quality captured images system set importance cam era position network data transmitted trade speed accuracy system features quickly police officers respond match location system field information field office receive match information detailed enough inform accurate identification intervention training human operators human operator behaviour algorithmic human operator error measured avoidance bias algorithmic injustice algorithmic bias taken account algorithmic bias measured nature data training datasets impartiality deployment ployment sites decided decides lfr deployed community impact assessment undertaken necessity legal basis use technology watchlist include enrolled images children proportionality purpose deployment lfr use lfr proportionate costs individual liberty benefits public safety use lfr retention captured images data proportionate impartialit accountability oversight construction watch lists oversight deployments use lfr evaluated compiled watchlist big watchlist watchlist enrolled images watchlist derived accurate enrolled images watchlist guidelines used compilation watchlist oversight compilation watchlist captured images data stored long capt ured images data retained deployment captured images data stored deployment access captured images data captured images data shared organisations shared public trust lfr deployed trial operational context extensively lfr deployment advertised community aware general public deployment adequate transparency deployment members general public easily find information deployment oversight board set public representation board cost use lfr cost crown copyright publication licensed terms open government licence except otherwise stated view licence visit engovernment write information policy team national archives kew london email psi identified third party copyright information need obtain permission copyright holders concerned
