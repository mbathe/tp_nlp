briefing eprs european parliamentary research service author tambiama madiega members research service september guidelines ethics artificial intelligence context implementation summary discussion around rtificial intelligence technologies impact society increasingly focus question whether regulated following call european parliament update complement existing union legal framework guiding ethical principles arved human approach respectful european values principles part approach published guidelines ethics april european commission president ursula von der leyen announced commission soon put forward legislati proposals coordinated european approach human ethical implications background paper aims shed light ethical rules recommended designing devel oping deploying implementing using products services moreover identifies ome implementation challenges presents possible action ranging soft law guidance standardisation legislation field ethic calls clarifying guidelines fostering adoption ethical standards adopting legally binding instruments inter alia set common rules transparency common requirements fundamental rights impact assessments provide adequate legal framework face recognition technology finally paper gives overview main ethical frameworks development outside united states china briefing human approach artificial intelligence key ethical requirements implementation challenges possible action international context outlook eprs european parliamentary research service centric approach rtificial intelligence background artificial intell igence commonly refers combination machine learning techniques used searching analysing large volumes data robotics dealing conception design manufacture operation programmable machines algorithms automated decision making systems adms able predict human machine behaviour make tonomous decision technologies extremely beneficial economic social point view alread used areas healthcare instance find effective treatments cancer transport instance predict traffic conditions guide autonomous vehicles efficiently manage energy water consumption increasingly affec daily ves potential range application broad sometimes referred fourth industrial revolution however studies concur brings many benefits also highlight number ethical legal economic concerns relat ing primarily risks facing human rights undamental freedoms instance poses risks right personal data protection priva equally risk discrimination algorithm used purposes profile people resolve situations criminal also concerns impact technologies robotics labour market jobs destroyed automation furthermore calls assess impact algorithms automated decision making systems adms context defective products safety liability digital currency block chain disinformation fake news potential military application algorithms autonomous weapons systems cybersecurity finally question develop ethical princip les algorithms design also approach policy across world looking ways tackle risks associated development said considered front regard establishing framework ethical rules leading debate eur opean parliament called european commission assess impact made wide recommendations civil law rules robotics january parliament drew code ethic robotics engineers asked commission consider creation european gency robotics tasked provid ing technical ethical regulatory expertise nee ded environment background commission adopted communication promote development europe published coordinated plan endorsed council european union coordinat member states national building groundwork april commission published set non ethics guidelines trus tworthy prepared commission high expert grou composed independent experts document aims offer guidance foster secur development ethical systems recent report algorit hmwatch organisation promoting transp arency use algorithms lists examples adms already use applications wide instance slovenia ministry finance uses machine system detect tax evasion tax fraud belgium police using predictive algorithm predict car robberies poland technology used profile unemployed people decide upon type assistance appropriate guidelines ethics artificial intelligence context implementation notion uman core principle guidelines must develop approach respectful european values principles approach strives ensure human values central way systems developed deployed used monitored ensuring respect fundamental rights including set treaties european union charter fundamental rights european union united reference common foundation roo ted respect human dignity human enjoy unique inalienable moral status also entails consideration natural environment living beings part human ecosystem well sustainable proach enabling flourishing future generations approach unfold context global race policy adopted frame analysis differentiate strategy strategy developed mostly private initiatives self chinese strategy essentially government characterised strong coordination private public investment technologies approach seeks remain faithful cultural preferences higher standard protection social risks posed particular affecting privacy data protection discrimination rules unlike lax jurisdictions end ethics guidelines promote trustworthy system lawful complying applicable laws regulations ethical ensuring adherence ethic principles values robus technic social perspectiv order avoid causing unintentional harm furthermore guidelines highlight software hardware systems need human develop deploy use adhere nce key ethical requirements outlined key ethical requirements guidelines addressed stakeholders designing developing deploying implementing using affected including companies researchers public services government agencies institutions civil society organisations individuals workers consumers stakeholders voluntarily opt use guidelines follow seven key requirements see box right developing deploying using systems human agency oversight respect human autonomy fundamental rights heart seven ethic rules guidelines prescribe three measures ensure requirement reflected practice make sure system hamper fundamental ghts fundamental rights impact assessment undertaken prior development mechanisms put place afterwards allow external feedback potential infringement fundamental rights human agency ensured users able understand interact systems satisfactory degree right end users subject decision based solely automated processing produces legal effect users significantly affect enforced key requirements achieving trustworthy human agency oversight robustness safety privacy data governance transparency diversity non discrimination fairness societal environmental accountability eprs european parliamentary research service machine full control therefore always human oversight human always possibility ultimately decision made system hen design ing product service developers consider type technical measures implemented ensure human oversight instance provide stop button procedure abort operation ensure human control different types fundamental rights impact assessments already used european commission adopted set guidelines fundamental rights impact assessments uses checklist identify fundamental rights could affected proposal assess systematically impact envisaged policy option rights general data protection regulation gdpr provides regulatory framework obliges data controller apply data protection impact assessment dpia government canada als developed algorithmic impact assessment assesses potential imp act algorithm citizens digital questionnaire evaluating potential risk public automated decision system tool mandatory canada technical robustness safety another essential requirement secure reliable systems software trustworthy requires algorithms secure reliable robust enough deal errors inconsistencies life phases system requirement ensuring cybersecurity practice vulnerabilities taken account building algorithms requires testing system understand mitigate risks cyber hacking developers put place process capable assessing safety risks involved case someone uses system building harmful purposes instance system compromised possible human ontrol take abort system tackle important question applies twofold approach first foster ing cooperation community security community econd reflecting modify legal framework governing liabilities human liability regime machine liability regime privacy data protection lot consideration data protection privacy stakeholders must comply general data protection regulation gdpr matter principle furthermore guidelines advise community ensure privacy personal data protected building running system citizens full control data data used harm discriminate practice means systems designed guarantee privacy data protection end developers apply design techniques data encryption data anonymi sation ensure quality data avoid socially constructed biased inac curacies errors mistakes end data collection biased developers put place oversight mechanism control quality data sets transparency transparency paramount ensur ing biased guidelines introduce number measures ensure transparency industry instance data sets processes used build ing system documented traceable also systems identifiable humans need aware interacting system furthermore systems related human decisions subject principle explain ability according possible understood traced humans guidelines ethics artificial intelligence context implementation diversity non fairness guidelines focus strongly avoi ding unfair bias products services designed practice developers make sure design algorithms biased use inadequate data set stakeholders may directly indirectly affected systems consulted involved development implementation systems conceived consideration whole range human abilities skills requirements ensu accessibility persons disabilities societ environmental wellbeing systems used enhance positive social change encourage sustainability environmental responsibility systems words easures securing environmental friendliness systems encouraged opting less harmful energy consumption method social impacts systems people physical mental wellbeing must monitored considered moreover effects systems society democrac including regarding electoral context assessed accountability mechanisms put place ensure responsibility accountability systems outcomes internal external independent audit put place especially systems whose use affects fundamental rights reporting systems negative impacts availabl including blowers impact assessment tools used end situations implementation key ethic requirements creates conflict decision trade decision choose ful fil one ethic requirement another evaluated continuously accessible edress mechanisms implemented implementation challenges implementing phase guidelines started academics stakeholders warned number implementation challenges need clarification lack clarity wording guidelines criticised many respect thomas metzinger professor theoretical philosophy university mainz member commission expert group warns guidelines short deliberately vague tak long risks consideration furthermore regrets non ethical principles draft guidelines deleted watered final text two lines never used build autonomous lethal weapons social scoring systems however prot racted negotiations final version explainability part wide concept xplainability making explanations algorithmic decision system available requirement explainable addresses fact complex machines algorithms often provide insights behavio processes sometimes results black box effect situation systems cap able produc ing results process results produced reasons algorithm makes specific decisions fully understandable humans explainability therefore particularly important ensure fairness use algorithms identify potential bias training data requirement means explanation available systems influence shape decision process designed rationale deploying explainability must address technical processes system related human decisions taken accordance guidelines eprs european parliamentary research service text instead referred issues concerns inclu clearly formulated prohibition another expert group member andrea renda together task force centre european policy studies ceps also published report highlighting shortcomings draft ethics guidelines report warn particular lack hierarchy principles would otherwise allow institutions tailor policy approach lack egulatory oversight ethics guidelines non however concerns raised regarding lack regulatory oversight support implementation non research advocacy organisation algorithmwatch stresses recommendations guidelines issued far provide oversight mechanisms ensure enforce compliance voluntary commitments without mechanism however little incentive adhere ethical principles others also warn risk technology industry financing shaping ethical debate algorithms automated decision systems lack regulatory oversight raises issue empowerment public bodies authorities monitor enforcement ethical guidelines institute argues expanding powers regulators oversee audit monitor technologies domain institute favours sector approach focuses application technologies within individual mains health education transport need oordination actions national levels several member states started work establishing national framework ethic parallel initiatives outline moves country france dating march french trategy sets one core principles requirement technologies must explainable socially acceptable end government required put place several policies order develop algorithm transparency audits include ethics training engineers researchers carry discrimination impact assessment encourage designers consider social implications algorithms produce ensure principle human responsibility applied setting boundaries use predictive algorithms law enforcement context furthermore proposed consultative ethics committee digital technologies set purpose organi sing public debate field germany initially ethic debate essentially driven specific industry interests resulted adoption june set ethical rules automated connected vehicular traffic transport ministry thics commission november national strategy launched setting range measures ethics instance document advocates using ethics design approach development stages uses pledges promote research ovel ways pseudonymising anonymising data differential privacy furthermore federal government review whether german airelated legal framework covers aspects related algorithm decisions services products necessary adapt order make possible verify whether undue discrimination bias legislation governing use personal non personal data applications reviewed possibil ity establish expand government agencies privat auditing institutions verify algorithmic decision making process examined guidelines ethics artificial intelligence context implementation finland august ministr economic affairs issued report recommending set parliamentary monitoring group promote ethical value base extensively society monitor evaluate pilots technology development associated ethical aspects artificial intelligence group would tasked creation rules assessment practices context defining responsibilities situations machine taking decisions autonomousl united kingdom committee standards public life announced march launching inquiry use public services aim examining whether rules sufficient ensure high standards conduct upheld technologically assisted decisio adopted widely across public sector particular focus risks biometrics ongoing discussions report biometr ics forensics ethics group outlines ethical issues raised use live real face recognition technology frt based machine techniques recommends development adequate legal framework background house commons science technology committee urge government issue moratorium current use frt prohibit frt trials proper legislative framework introduced guidance trial protocols oversight evaluation system established risk fragmentation mber states likely enact diverging national ethical rules could fragment landscape domain fragmentation may hamper emergence pan european services therefore coordinated actions national levels key ensuring coherent harmonisation ethic guidelines avoiding discrepancies within possible action following publication guidelines ethics commission launched pilot phase june invited stakeholders provide feedback practical implement ation key requirements end end ompanies participating pilot report experience implement ing guidelines based feedback received level expert group propose revised version compliance assessment list commission early something crucial context reflect following question extent voluntary ethical rules driven industry pace strategies sufficient address ethical issues raised development calls stronger intervention part public authorities influence development enforcement rules european commission president ursula von der leyen announced put forward legislati proposals coordinated european approach human ethical implications first days office policy cademics stakeholders called action implement complement ethics guidelines equally ensure harmonised approach avoid fragment ation possible action focusing ethical issues ranges soft law guidance hard law legislation clarification guidelines one main recommendations ceps task force report adopt guidance allowing identify applications business models potentially problematic prohibited incompatible core values legislation report stresses extensive explanations provided establish effective fairness standards necessary focus extensively setting appropriate redress eprs european parliamentary research service mechanisms individuals another great chall enge clarify implement requirement explainability context complexity algorithms make difficult provide lear explanation justif ication decision made machine black box effect ensuring harmonised application guidelines throughout would require spell ing concept detail explainability part sys tems made explainable may result cost interpretability order apply guidelines consistently efficiently stakeholders would need additional recommendations key questions need ensure explainability design differentiate level transparency required face cases supports decision humans may raise fewer explainability issues full automated decision systems iii extent intellectual property rights trade secret protection limited implementation explainability requirement regard institute argues companies waive trade secrecy legal claims inhibit full auditing understanding software trade secrecy contributes black box effect makes hard assess bias contest decisions remedy errors standardisation standardi sation expected play essential role driving market adoption standards influence developmen deplo yment particular systems product certification serve disseminate best practices case cybersecurity environmental sustainability number standardisation organisations working technical tandards parallel ethical standards also instance joint technical committee international organization standardization iso international electrotechnical commission iec working developing standards ensure trustworthiness technology outset expert working groups considering technically achieve systems robustness resiliency reliability accuracy safety security privacy another leading standardisation organisation insti tute electrical electronics engineers ieee publish ethical framework setting ethical issues recommendations serve reference policy eng ineers developers companies deploying selling using systems practice ieee seeks develop specific industry standards processes related transparency accountability algorithmic bias certification background commission rolling lan ict standardisation identifies three main actions relation standard namely oster ing coordination standardisation efforts europ ensur ing coordination standardisation efforts europe international standa rdisation efforts iii integrat ing outcomes high expert group artificial intelligence within standardisation roadmaps however aunching standardisation process raises many questions similar technical standards ethical standards voluntary measures standards made mandatory become condition awarding procurement ensure industry players implement researchers stress however sufficient grounds adoption public certification mandatory stand ards europe self framework ethical standards ieee standard establishes process model engineers technologists address ethical consideration throughout various stages system initiation analysis design new product systems standards address manner personal privacy terms offered read agreed machines describe specific methodologies selection data sets address eliminate bias algorithms created guidelines ethics artificial intelligence context implementation evolving early anticipate enough certainty market develop fact standards vague certification enforcement oversight uncle perf orms ethical certifications criticised one concern standardisation certification bodies focus enabling become marketable existing market logic control development risk race bottom regulatory oversight development organisations may choose locate jurisdictions pose lax rules implementing ethical standards also pointed regulatory framew ork number proposals legislation discussed including several described legislation ransparency decision systems transparency paramount ensur ing biased systems explainable calls legislate make transparency requirement mandatory instance finnish national strategy paper recommend assessing ethic obligation could imposed platforms done gdpr paper stresses particular certain parts algorithm developed used platforms could prohibited distorts restricts competition without justification could build existing legislative initiatives research transparency conducted recent years july adopted new regulation requiring roviders online intermediation services online search engines implement set measures ensure transparency fairness contractual relations online businesses online retailers hotels restaurants businesses app stores use online platforms sell provide services customers commission also carrying analysis algorithmic transparency background parliament study recommends creation regulatory body algorithmic ecision tasked defining criteria used differentiate acceptable algorithmic decision systems subject algorithmic impact assessment systems prohibited obligations falling algorithmic decision system providers obligation make systems auditable new legislation could also address responsibility informing persons affected systems also clarify ing explain ability requirements set ting specific liability certifications regimes sector legislation health sector arguably important ensure rigorous implementation ethical rules specific sector health care human control algorithms decision systems paramount background finnish national strategy proposes formulate ethics rules specific healthcare ecosystem study university oxford stresses need nalyse implementation gdpr field health research needed amend laws create clarity interpretation guidance legislation face recogn ition technology use face recognition technology frt becoming widespread across europe giving rise growing concerns frt considered processing data gdpr principl subject strict terms conditions use however echnology experts disagree whether gdpr framework robust enough address issues created growing use frt whether ditional legislation necessary ensure fundamental rights already adoption national frt legislation discussed member states see particular debate mentioned eprs european parliamentary research service number legally bindin instruments could adopted translate ethical rules hard law mandatory influential industry players international context clearly front debat ethical social implications government entities world also looking issues united states hile range industry players already developed codes conduct ethics calls government regulation collaborative industry groups partnership including microsoft amazon facebook apple pledged develop share best practices inclu ding ethics association computing machinery acm also published code ethics professional conduct guide ethical conduct computing professionals furthermore ompanies developing ethical guidelines instance microsof advisory board google disclosed principles ethic charter guide responsible development use research however growing concern self ill enough tackle ethical challenges posed development institute issued report concluding internal governance structures technology companies failing ensure accountability systems argues therefore government agencies need greater power oversee audit monitor technologies especially involving face recognition china china growing interest setting ethical framework development china released next generation artificial intelligence development plan setting long term strategic goals developme country one objective establish regulatory ethical frameworks ensure healthy development china china would promote self industry enterprises increase punishments data abuse violations personal privacy unethical activities regard artificial intelligence industry alliance bring together chinese tech firms universities released draft guidelines self field may call imple menting principl controllable transparent explainable similar ones enshrined ethical guidelines furthermore new generation governance expert committee established ministry scienc technology released june document outlining eight non principles guide development china ese principles largely mirror rules instance development conform values ethics morality based premise safeguarding societal security respecting huma rights eliminate bias discrimination process data acquisition algorithm design technology development product application protect personal privacy countries organisations orld canada already adopted number guiding principles governing use administration public services public nstitutions required incorporate ethical principles including privacy transparency concerns application directive automated decision federal institutions outlines responsibilities federal institutions provides rules help assess mitigate risks associated deploying automated decision system australia also well advanced office australian info rmation commissioner published guide ata analytics australian rivacy principl working national ethics framework address standards codes guidelines ethics artificial intelligence context implementation conduct field preparatory work establishing ethical framework also ongoing india new zealand singapore south korea japan nternational organisations engaging setting international rules field ethic may oec associated nations adopted non list guidelines development use algorithmwatch ethics guidelines global inventory lists ethical frameworks principles developed across globe recent years seen flurry initiatives companies governments ngos research bodies propose ethical rules ethical principles laid jurisdict ions seem relatively similar though less detailed essentially self ory nature even though growing demand government oversight outlook policy globe looking tackle risks associated development april published guidelines ethics bec oming front runner setting framework ethical rules exist far essentially self ory nature growing demand government oversight str ong calls clarifying guidelines fostering adoption ethical standards adopting legally biding instr ument order inter alia set common rules transparency set common requirements fundamental rights impact assessments provide adequate legal framework face recognition technology main references boucher artificial intelligence works briefing eprs march age artificial intelligence european political strategy centre european commission march ethics guidelines trustworthy independent high expert group artificial intelligence european commission april artificial ntelligence european perspective jrc european commission kritikos artificial intelligence ante portas legal ethical reflections briefing eprs march governance framework algorithmic accountability transparency study scientific foresight unit stoa eprs apri understanding algorithmic opportunities challenges study stoa eprs march endnot see definition provided high expert group artificial intelligence glossary section ethics guidelines trustworthy commonly agreed definition overview notion difficulty defining philip boucher eprs briefings artificial intelligence works artificial intelligence matters see eprs briefing economic pacts artificial intelligence marcin szczepański july see data quality artificial intelligence mitigating bias error prot ect fundamental rights fra focus agency fundamental rights june see two eprs publications mihalis kritikos algorithms could abide ethical principles glance note november artificial intelligence ante portas legal ethical reflections briefing march furthermore parliament adopted solution comprehensive european industrial policy artificial intelligence robotics february european economic social committee issued initiative opinion may also lling code ethics development application use furthermore april european countries signed declaration cooperation artificial intelligence see definition provided high expert group artificial intelligence glossary section ethics guidelines trustworthy see age artificial intelligence european political strategy centre european commissio march ibid see well artificial intelligence european perspective jrc european commissio action could also taken clarify issue liability damages measures encou rage data eprs european parliamentary research service see andrea renda artificial intelligence ethics governance policy challenges report ceps task force see pricew aterhousecooper predictions insights shape business strategy report argues made explainable cost explains every step must documented explained process becomes slower may expensive see oecd see peter cihon standar governance international standards enable global coordination research development university oxford april see jens popper artificial intelligence across industries international electrotechnical commissio iec whitepaper october see marc böhlen cited industry standards give artificial intelligence conscience matthew linares opendemocracy media platform february see alan winfield ethical standards robotics university west england bristol february see renda see marc böhlen cited linares see cihon see draft european commission priorities working document published politico august see work age artificial intelligence four perspectives economy employment skills ethics ministry economic affai employment finland see following eprs studies governance framework algorithmic accountability transparency ril understanding algorithmic decision opportunities challenges march cost non robotics artificial intelligence liability insurance risk management june august swedish data protection authority dpa imposed first fine since gdpr came effect may fine imposed school creating facial recognition ogram violation gdpr generally gdpr affects machine learning techniques remains unclear many respects see also mapping regulatory proposals artificial intelligence europe access non advocacy group november work started undertaken application frt chengen border control see biometrics schengen information system fostering identification capabilities jrc blog european commission july google also established advanced technology external advisory council ateac featuring prominent academics designed monitor use artificial intelligence decided dissolved april amid controversy appointment independence council members see joint pledge artificial intelligence industry self draft comment june see hinese government governance principles new generation artificial intelligence develo responsible artificial intelligence june eight principles regard harmony friendliness fairness justice inclusivity sharing respect privacy controllable shared responsibility open collabo ration agile governance see responsible artificial intelligence government canada digital disruption white paper series treasury board canada secretariat april overview see regulation artificial intelligence selected jurisdictions law library congress united states january disclaimer copyr ight document prepared addressed members staff european parliament background material assist parliamentary work content document sole responsibility author opinions expressed herein taken represent official position parliament reproduction translation commercial purposes authorised provided source acknowledged european parliament given prior notice sent copy european union photo credits mopic fotolia eprs contact intranet internet blog guidelines ethics artificial intelligence context implementation
