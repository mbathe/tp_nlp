understanding artificial telligence ethics afety guide responsible design implementation systems public sector david leslie public policy programme public policy programme alan turing institute set may aim developing research tools techniques help government innovate data technologies improve quality people lives work alongside policy makers explore data science artificial intelligence inform public policy improve provision public services believe governments reap benefits technologies make considerations ethics safety first priority document provides guidance apply principles ethics safety design implement ation algorithmic systems public sector shortly release workbook bring recommendations made guide life workbook contain case studies highlighting guidance contained applied concrete projects also contain exercises practical tools help strengthen process governance project please note guide living document evolve improve input users affected stakeholders interested part ies need participation please share feedback policy work supported exclusively turing public policy programme research undertaken turing public policy programme supported entirely public funds work licensed terms creative commons attribution license permits unrestricted use provided original author source credited license available cite work leslie understanding artificial intelligence ethics safety guide responsible design implementation systems public sector alan turing institute understanding artificial intelligence ethics safety table contents ethics intended audience xisting government guidance ethics thics ethical platform responsible delivery roject preliminary considerations ethical atform three building responsible project delivery ecosystem sum values fast track principles fairness data fairness design fairness outcome fairness implementation fairness putting principle discriminatory non action accountability accountability deserves consideration model completion sustainability stakeholder impact assessment safety accuracy reliability ecurity obustness risks posed accura reliability risks posed security robustness transparency defining transparent three critical tasks designing implementing transparent map ping ransparency process ransparency establishing process governance ramework outcome transparency explaining outcomes clarifyin content implementing responsibly defining nterpretable technical aspects choosing designing using interpretable system guide lines designing delivering sufficiently interpretable system guideline look first context potential impact domain need guideline draw standard interpretable techniques possible guideline considerations black box systems guideline think interpretability terms capacities understanding securing responsible delivery human implementation protocols practices step consider aspects application type domain context define roles step define delivery relations map delivery processes step build ethical implementation platform conclusion bibliography understanding artificial intelligence ethics safety thics intended audience xisting government uidance following guidance esigned outline values principles guidelines assist department delivery leads ensuring develop deploy ethically safely responsibly designed complement supplement data ethics framework data ethics framework practical tool used project ini tiation phase ethics remarkable time human promise ushered convergence ever availability big data soaring speed stretch cloud computing platforms advancement increasingly sophistica ted machine learning algorithms brave new digitally interconnected world delivering rapid gai power better society innovations already dramatically improving provision essential social goods services rom healthcare education transportation food supply energy environmental management bounties fact likely start machine learning systems organically mprove enlargement access data growth computing power become effective useful information age continues develop apace may long technologies become gatekeepers advance ment vital public interests sustainable human development prospect progress help humanity confront urgent challenges exciting legitimate worries still abound new rapidly evolving chnology steep learning curve means mistakes miscalculations made unanticipated harmful impacts inevitably occur exception order manage impacts responsibly direct development systems toward optimal public benefit make considerations ethics safety first priority involve integrating considerations social ethical implications design use systems every stage delivery project also involve collaborative effort data scientists product nagers data engineers domain experts delivery managers team align development artificial intelligence technologies ethical values principles safeguard promote wellbeing communities technologi affect including primer ethics guide provid ing conceptual resources practical tools enable steward responsible design implem entation projects ethics set values principles techniques employ widely accepted standards right rong guide moral conduct development use technologies understanding artificial intelligence ethics safety values principles techniques intended motivate morally acceptable practices prescribe basic dutie obligations necessary produce ethical fair safe applications thics field ethics largely emerged response range individual societal harms misuse abuse poor design negative unintended consequences systems may cause way orient importance building robust culture ethics table represents consequential forms potential harms may take potential harms caused systems bias discrimination gain insights existing structures dynamics societies analyse data driven technologies reproduce reinforce amplify patterns marginalisation inequality discrimination exist soc ieties likewise many features metrics analytic structures models enable data mining chosen designers technologies potentially replicate designers preconceptions biases finally data samples used train test algorithmic systems often insufficiently representative populations drawing inferences creates real possibilities biased discriminatory outcomes fed systems flawed start denial individual autonomy recourse rights citizens subject decisions predictions classifications produced systems situations may arise individuals unable hold directly accountable parties responsible outcomes systems automate cognitive functions previousl attributable exclusively accountable human agents complicate designation responsibility algorithmically generated outcomes complex distributed character design production implementation processes systems may make difficult pinpoint accountable parties cases injury negative consequence accountability gap may harm autonomy violate rights affected individual unexplainable unjusti fiable outcomes many machine learning models generate results operating high dimensional correlations beyond interpretive capabilities human scale reasoning cases rationale algorithmically produced outcomes rectly affect decision subjects remain opaque subjects use cases lack explainability may acceptable applications processed data could understanding artificial intelligence ethics safety harbour traces discrimination bias inequity unfairness opaqueness model may deeply problematic invasion privacy threats privacy posed systems result design development processes result deployment projects anchored structuring processing data development technologies frequently involve utilisation personal data data sometimes captured extracted without gaining proper consent data subject handled way reveals places risk revelation personal information deployment end systems target profile nudge data subjects without knowledge consent ould circumstances interpreted infring ing upon ability lead private life able intentionally manage transformative effects technologies influence shape development sort privacy invasio consequently harm person basic right pursue goals life plans free unchosen influence isolation disintegration social connection capacity systems curate individual experiences personalise digital services holds promise vastly improving consumer life service delivery benefit also comes potential risk excessive automation example might reduce need human interaction algorithmically enabled hyper limiting exposure worldviews different might polarise social relationships well cohesive societies built lations trust empathy mutual understanding technologies become prevalent important relations preserved unreliable unsafe poor outcomes irres ponsible data management negligent design production processes questionable deployment practices ways lead implementation distribution systems produce unreliable unsafe poor outcomes outcomes direct damage wellbeing individual persons public welfare also undermine public trust responsible use societally beneficial technologies create harmful inefficiencies virtue dedication limited ublic resources inefficient even detrimental technologies ethical platform responsible delivery roject building project delivery environment enables ethical design deployment systems requires multidisciplinary team effort demands active cooperation team members maintaining deeply ingrained culture responsibility executing governance architecture adopt ethically sound practices every point innovation implementation lifecycle task uniting culture responsible innovation governance architecture bring values principles ethical fair safe life require team accomplish several goals understanding artificial intelligence ethics safety ensure project ethically permissible considerin impact may wellbeing affected stakeholders communities ensure project fair non accounti potential discriminat ory ffects individuals social groups mitigating biases influence model outputs aware issues surrounding fairness come play every phase design implementation pipeline ensure project worthy public trust guaranteeing extent possible safety accurac reliability security robustness product ensure project justifiable prioritis ing transparency process model designed implemented transparency interpretab ility decisions behaviours call governance architecture ethical platform two important reasons first intended provide solid processed footing values principles protocols ethical platform stand team better able design implement systems ethically equitably safely secondly intended help facilitate culture responsible innovation help provide ethical platfo stand project team united collaborative spirit develop technologies public good preliminary considerations ethical platfor aim rem ainder document provide guidance comprehensive possible presentation values principles governance mechanisms necessary serve purpose responsible innovation keep mind however issues discussed document apply equally project clearly machine learning algorithm trained detect spam emails present fewer ethical challenges compared one trained detect cancer blood samples milarly image recognition systems used sorting outing mail raise fewer ethical dilemmas compared facial recognition technologies used law enforcement application safety directly impact lives people process potentially sensitiv social demographic data need less proactive ethical stewardship high projects project team need evaluate scope possible impacts project affected individuals communities apply reasonable assessments risks posed individual wellbeing public welfare order formulate proportional governance procedures protocols may also keep mind projects social ethical impacts stakeholders communities even diverting redistributing limited intellectual material economic resources away concerns possibilities socially beneficial innovation ethical considerations pri nciples policy formation therefore play salient role every prospective project understanding artificial intelligence ethics safety three building responsible project delivery ecosystem setting ethical platform responsible project delivery involves building cultural ground involves providing team means accomplish goals establishing ethical permissibility fairness trustworthiness justifiability project take three building make ethical platform possible basic level necessitates gain workin knowledge framework ethical values support underwrite motivate responsible data design use ecosystem called sum values composed four key notions respect connect care protect objectives sum values provide accessible framework start thinking moral scope societal ethical impacts project establish criteria evaluate ethical permissibi lity second concrete level ethical platform responsible project delivery requires set actionable principles facilitate orientation responsible design use systems called fast track principles composed four key notions fairness accountability sustainability transparency objectives fast track principles provide moral practical tools make sure project bias non fair safeguard public trust project capacity deliver safe reliable innovation third concrete level ethical platform responsible project delivery requires process governance framework pbg framework operationalises sum values fast track principles across entir project delivery workflow objective pbg framework set transparent process design implementation safeguard enable justifiability project product summary visualisation three building blocks platform understanding artificial intelligence ethics safety use guide guide intended assist stewarding practices responsible innovation entails ethical platform put practice every step design implementation workflow turning sum values fast track principles pbg framework practice require team continuously reflect act justify sum value background challenge creating culture responsible innovation begins task building accessible moral vocabulary allow team members explore discuss ethical stakes projects involved considering taking field ethics moral vocabulary draws primarily two traditions moral thinking bioethics human rights discourse bioethics study ethical impacts biomedicin applied life sciences human rights discourse draws inspiration declaration human rights anchored set universal principles build upon idea humans equal moral status bearers intrinsic human dignity understanding artificial intelligence ethics safety whereas bioethics largely stresses normative values underlie safeguarding individual instances technological practices affect interests wellbeing human rights discourse mainly focus set social political legal entitlements due human beings universal framework juridical protection rule law main principles bioethics include respecting autonomy individual protecting people harm looking well others treating individuals equitably justly main tenets human rights include entitlement equal freedom dignity law protection civil political social rights universal recognition personhood right free unencumbered participation life community sum values respect connect care protect sum values incorporate conceptual elements bioethics human rights discourse eye applying critical elements specific social ethical problems raised potential misuse abuse poor design harmful unintende consequences systems also meant utilised guiding values throughout innovation lifecycle preliminary steps project evaluation planning problem formulation processes design development tes ting stages implementation reassessment sum values visualised follows key concept context practical ethics word normativity means giv concept value belief puts moral demand one practices concept value belief indicates one ought circumstances concept value belief applies example hold moral bel ief helping people need good thing confronted sick person street requires help help belief puts normative demand act accordance indicating ought namel come needy person aid understanding artificial intelligence ethics safety order ocus detailed exploration values meanings contents presented individually formulating question values charging respect dignity individual persons ensure abilities make free informed decisions lives safeguard autonomy power express right heard secure capacities make independent contributions life community support abilities flourish fully develop emselves pursue passions talents according freely determined life plans connect sincerely openly inclusively safeguard integrit interpersonal dialogue meaningful human connection social cohesion prioritise diversity participation inclusion points design development deployment processes innovation encourage voices heard opinions weighed seriously sincere throughout production use lifecycle use advancement proliferation technologies strengthen developmentally essential relationship interacting human utilise innovation enable bonds interpersonal solidarity form individuals socialised recognised use technologies foster capacity connect reinforce edifice trust empathy reciprocal responsibility mutual understanding upon ethically well founded social orders rest care wellbeing design deploy systems foster cultivate welfare stakeholders whose interests affected use harm technologies minimise risks misuse abuse understanding artificial intelligence ethics safety prioritise safety mental physical integri people scanning horizon technological possibility conceiving deploying applications protect priorities social values justice public interest treat individuals equally protect social equity use digital technologies essential support protection fair equal treatment law prioritise social welfare public interest consideration social ethical impacts innovation determining legitimacy desirability technologies use empower advance interests well many individuals possible think big wider impacts technologies conceiving developing think ramifications effects externalities others around globe future generations biosphere whole general rule sum values orient deliberating ethical permissibility rospective project also provide framework concepts consider ethical impacts system across design use monitoring lifecycle taking sum values starting point conversation also encourage discussion within team weigh values one another consider trade use case specific circumstances arise values com tension fast track principles background sum values intended provide general normative guideposts moral motivations thinking social ethical aspects project delivery specifically catered actual processes involved developing deploying systems make clear needed next step toward actionable orientation responsible design use technologies would helpful briefly touch upon necessitated emergence ethics first place marvin minsky great cognitive scientist pioneer def ined follows artificial intelligence science making computers things require intelligence done humans standard definition key principal motivation driven development field applied ethics artificial intelligence understanding artificial intelligence ethics safety humans things require intelligence hold responsible accuracy reliability soundness judgements moreover demand actions decisi ons supported good reasons hold accountable fairness equity reasonableness treat others creates need principles tailored design use systems emergence expanding ower things require intelligence heralded shift wide array cognitive functions algorithmic processes held neither directly responsible immediately accountable consequences behaviour inert program machinery systems morally accountable agents created ethical breach sphere applied science growing number frameworks ethics currently trying fill targeted principles fairness accountability sustainability transparency meant fill gap new smart agency machines fundamental lack moral responsibility fast track principles fairness accountability sustainability transparency becoming well track principles members project delivery team better able support responsible environment data innovation issues fairness accountability sustainability transparency operate every juncture every level project delivery work flow demand cooperative attention deliberative involvement technical expertise domain knowledge management skill policy competence ethical innovation team effort start finish introduce scope fast track principles summary visualisation understanding artificial intelligence ethics safety keep mind initially fairness accountability sustainability transparency grouped together fast acronym nece ssarily relate plane equivalents principles accountability transparency governing principles accountability entails mans answerable parts play across entire design implementation workflow also demands results work traceable start finish principle transparency entails design implementation processes justifiable demand well algorithmically influenced outcome interpretable made understandable affected parties governing roles accountability transparency different rom dependent roles fairness sustainability latter two qualities algorithmic systems designers implementers held accountable transparency outcomes practices practices according principle fairness desig ners implementers held accountable equitable harming anyone bias discriminat ion according principle sustainability designers implementers held accountable producing innovation saf ethical outcomes wider impacts whereas principles transparency accountability thus provide procedural mechanisms means systems justified producer implementers hel responsible fairness sustainability crucial aspects design implementation outcomes systems establish normative criteria governing constraints four principles therefore deeply interrela ted equal one important thing keep mind delve details fast track principles transparency accountability fairness also data prote ction principles algorithmic processing involves personal data complying simply matter ethics good actice legal requirement enshrined general data protection regulation gdpr data protection act dpa detailed information specific meanings transparency accountability fairness data protection principles context gdpr dpa please refer guide data protection produced information commissioner office fairness thinking fairness design deployment systems important always keep mind technologies matter neutral may seem designed produced human beings bound limitations contexts biases human error prejudice misjudgement ente innovation lifecycle create bias point project delivery process preliminary stages data extrac tion collection pre critical phases problem formulation model building implementation understanding artificial intelligence ethics safety additionally data technologies achieve accuracy efficacy building inferences datasets record complex social historical patterns may contain culturally crystallis forms bias discrimination silver bullet comes remediating dangers discrimination unfairness systems problem fairness bias mitigation algorithmic design use therefore simple strictly technical solution said best practices fairness design implementation level non technical self level technical control means evaluation hold great promise terms securing morally acceptable beneficial outcomes treat affected stakeholders fairly equitably different ways characterise define fairness design use systems consider principle discriminatory non minimum required threshold fairnes principle directs harm others biased discriminatory outcomes may result practices innovation data airness responsible data acquisition handling management necessary component algorithmic fairness results project generated biased compromised skewed datasets affected stakeholders adequately protected discriminatory harm project team keep mind following key elements data fairness principle discriminatory non designers users systems process social demographic data pertaining features human subjects societal patterns cultural formations prioritise mitigation bias exclusion discriminatory influences outputs implementations models prioritising discriminatory non implies designers users systems ensure decisions behaviours models generate discriminatory inequitable impacts affected individuals communities entails designers users ensure systems developing deploying trained tested properly representative relevant accurate generalisable data sets data fairness model architectures include target variables features processes analytical structures correlations interactions inferences unreasonable morally objectionable unjust ifiable design fairness discriminator inequitable impacts lives people affect outcome fairness deployed users sufficiently trained implement responsibly without bias implementation fairness understanding artificial intelligence ethics safety representativeness depending context either underrepresentation overrepresentation disadvantaged legally protected groups data sample may lead systematic sadvantaging vulnerable stakeholder outcomes trained model avoid kinds sampling bias domain expertise crucial assess fit data collected procured underlying population modelled technical team members possible offer means remediation correct representational flaws sampling sufficiency mportant question consider data collection procurement process amount data collected sufficient intended purpose project quantity data collected procured significant impact accuracy reasonableness outputs trained model data sample large enough represent sufficient richness significant qualifying attributes members population classified may lead unfair outcomes insufficient data sets may equitably reflect qualities rationally weighed producing justified outcome consistent desired purpose system members project team technical policy competences collabora determine data quantity respect sufficient fit source integrity measurement accuracy effective bias mitigation begins commencement data extraction collection processes sources instruments measurement may introduce discriminatory factors dataset incorporated inputs training data biased prior human decision judgments prejudiced scoring ranking interview evaluation become ground truth model replicate bias outputs system order secure discriminatory non must best make sur data sample optimal source integrity involves securing confirming data gathering processes involved suitable reliable impartial sources measurement sound methods collection timeliness recency data sets include outdated data changes underlying data distribution may adversely affect generalisability trained model provided distributional drifts reflect changing social relationship group dynamics loss accuracy regard actual characteristics underlying population may introduce bias system preventing discriminatory outcomes scrutinise timeliness recency elements data tha constitute dataset relevance appropriateness domain knowledge understanding utilisation appropriate sources types data crucial building robust unbiased system solid domain knowledge underlying population distribution predictive classificatory goal project instrumental choosing optimally relevant measurement inputs cont ribute reasonable determination defined solution make sure domain experts collaborate closely technical team assist determination optimally appropriate categories sources measurement understanding artificial intelligence ethics safety ensure uptake best practices responsible data acquisition handling management across project delivery workflow initiate creatio dataset factsheet alpha stage project factsheet intained diligently throughout design implementation lifecycle order secure optimal data quality deliberate bias aware practices optimal auditability include comprehensive record data provenance procurement lineage storage security well qualitative input team members determinations made regard data representativeness data sufficiency source integrity data timeliness data relevance splits unforeseen data issues encountered across workflow design fairness human beings hand stages construction systems fairness design must take precautions across project workflow prevent bias discriminatory influence problem formulation initial stage problem formulation outcome definition technical non members team work together translate project goals measurable targets involve use domain knowledge technical understanding defin optimised formalis able way translate project objective target variable measurable proxy operate statistically actionable rendering defined outcome points choices must made design algorithmic system may introduce structural biases ultimately lead discriminatory harm special care must taken identify affected stakeholders consider vulnerable groups migh negatively impacted specification outcome variables proxies attention must also paid question whether specifica tions reasonable justifiable given general purpose project potential impacts outcomes system use individuals communities involved challenges fairness aware design problem formulation stage show need making diversity inclusive participation priority start project lifecycle involves collaboration entire team attainment stakeholder input acceptability project plan also entails collaborative deliberation across project team beyond ethical impacts design choices made data pre human judgment enters process algorithmic system construction stage labelling annotating organising training data utilised building model choices made classify structure raw inputs must taken fairness aware manner due consideration given sensitive social contexts may introduce bias acts classificati similar fairness aware processes put place review automated outsourced classifications likewise efforts made attach solid contextual information ample metadata dataset downstream analyse data rocessing access properties concern bias mitigation understanding artificial intelligence ethics safety feature determination model constructive task selecting attributes features serve input variables model involves human decisions made sorts information may may relevant rationally required yield accurate unbiased classification prediction moreover feature engineering tasks aggregating extracting decomposing attributes datase may introduc human appraisals biasing effects reason discrimination awareness play large role stage model workflow domain knowledge policy expertise team proceed modell ing stage aware choices made grouping separating including excluding features well general judgements comprehensiveness coarseness total set features may significant consequences vulner able protected groups process tuning hyperparameters setting metrics modelling testing evaluation stages also involves human choices may discriminatory effects trained model technical team proceed attentiveness bias risk continual iterations peer review project team consultation encouraged ensure choices made adjusting dials metrics model line bias mitigation discriminatory non evaluating analytical structures design fairness also demands close assessment existence trained model lurking hidden proxies discriminatory features may act significant factors output including hidden proxie structure model may lead implicit redlining unfair treatment sensitive group basis unprotected attribute interaction attributes stands protected sensitive one desig ners must additionally scrutinis moral justifiability significant correlations inferences determ ined model learning mechanisms cases processing social demographic data related human features complexity high dimensionality machine learning models preclude confirmation discriminatory non inferences reason uninterpretability human assessors models avoided systems process draw analytics data arising human relationships societal patterns complex socioeconomic cultural formations designers must prioritise degree interpretability sufficient ensure inferences produced systems non discriminatory cases possible different transparent explainable model portfolio models chosen analytical structures must lso confirmed procedurally fair rule procedure employed system consistently uniformly applied every ecision subject whose information ing processed system team able certify rule procedure used render tcome given individual rule procedure applied individual way regardless subject similarities differences first understanding artificial intelligence ethics safety implementers respect able show algorithmic output replicable rules procedures applied inputs uniformity application rules procedures secures ual procedural treatment decision subjects precludes rule algorithmic processing targeted specific person may disadvantage individual outcome fairness part minimum safeguarding discriminatory non forethought well consideration must put going define measure fairness impacts outcomes system developing great diversity beliefs area outcome fairness properly classify makes consequences algorithmic ally supported decision equitable fair allocatively different approaches different pri nciples focus demographic parity individual fairness others error rates equitably distributed across subpopulations determination outcome fairness heavily depend specific use case fairness outcome considered technical feasibility incorporating chosen criteria construction system note diffe rent fairness methods involve different types technical intervention pre modelling post processing stages production means determining fairness definition cooperative multidisciplinary effort across project team find summary table main definitions outcome fairness integrated researchers formal models well list current articles technical resource consulted orient team relevant knowledge base note rapidly developing field technical team keep updated advances first four fairness types fall category group fairness allow comparative criteria non considered model construction evaluation final two fairness types focus instead cases individual fairness cont issues effective bias considered assessed level individual agent take note though technical approaches limited scope terms bigger picture issues algorithmic fairness alre ady stressed many formal approaches work use cases distributive allocative consequences order carry group comparisons approaches require access data attributes may often navailable unreliable well accurate demographic information underlying population distribution furthermore unavoidable trade inconsistences technical definitions must weighed determining best fit use case consult project team technica expertise consider use case appropriateness desired formal approach understanding artificial intelligence ethics safety formalis able definitions outcome fairness type fairness definition statistical parit group fairness outcome fair group selected set receives benefit equal similar proportions correlation sensitive protected attribute allocative result approach intended prevent disparate impact occurs outcome algorithmic process disproportionately harms members disadvantaged protected groups true positive rate parity group fairness outcome fair true positive rates algorithmic prediction classification equal across groups approach intended align goals bias mitigation accuracy ensuring accuracy model equivalent tween relevant population subgroups method also referred equal opportunity fairness aims secure equalised odds advantageous outcome qualified individuals given population regardless protected disadvantaged groups members false positive rate parity group fairness outcome fair disparately mistreat people belonging given social group misc lassifying higher rate members second social group would place members first group unfair disadvantage approach motivated position sensitive group advantaged groups milar error rates outcomes algorithmic decisions positive predictive value parity group fairness outcome fair rates positive predictive value fraction correctly predicted positive cases predicted positive cases equal across sensitive advantaged groups outcome fairness defined terms parity precision probability members different groups actually quality predicted across groups individual fairness individual fairness outcome fair treats individuals similar relevant qualification similarly approach relies establishment similarity metric shows degree pairs individuals alike regard specific task counterfactual fairness individual fairness outcome fair automa ted decision made indiv idual belonging sen sitive group would individual member different group closest possible alternative counterfactual world like individual fairness approach method defining fairnes focu ses specific circumstan ces affected decision subject using tools contrastive explanation moves beyond individual fairness insofar brings causal influences behind algorithmic output also presents possibility offering subject automated decision knowledge factors changed could influence different outcome could provide actionab recourse change unfavourable decision understanding artificial intelligence ethics safety selected references technical resources dwork hardt pitassi reingold zemel fairness awareness proceedings innovations theoretical computer science conference acm statistical parity individual fairness zemel swersky pitassi dwork learning fair representations international conference machine learning demographic parity hardt price srebro equality opportunity supervised learning advances neural information processing systems equality opportunity chouldechova fair prediction disparate impact study bias recidivism prediction instruments big data balancing error rates feldman friedler moeller scheidegger venkatasubramanian certifying removing disparate impact proceedings acm sigkdd international conference knowledge discovery data mining acm test disparate impact zafar valera rodriguez gummadi fairness beyond disparate treatment dispar ate impact learning classification without disparate mistreatment proceedings international conference world wide web international world wide web conferences steering committee disparate mistreatment verma rubin fairness definitions explained proceedings international workshop software fairness fairware summa comparison kusner loftus russell silva counterfactual fairness advances neural information processing systems counterfactual fairness ustun spangher liu actionable recourse linear classification proceedings conference fairness acc ountability transparency extension counterfactual fairness technical resources exploring fairness tools university chicago open source bias audit toolkit machine learning developers datasets software detecting algorithmic discrimination berlin eur ecat fairtest unwarranted association discovery platform columbia university ibm fairness open source toolkit fairness posi tion statement project team thoroughly consider use case appropriateness well technical feasibility formal models fairness relevant system incorporated model application prepare fairness posi tion statement fps fairness criteria employed system made explicit explained plain non language made publicly available review affected stakeholders implementation airness project team approaching beta stage begin build plan implementation training support plan include adequate preparation responsible unbiased deployment system users automated understanding artificial intelligence ethics safety decision systems present novel risks bias misapplication point delivery special attention paid preventing harmful discriminatory outcomes critical juncture project lifecycle order design optimal regime implementer training support pay special attentio unique pitfalls bias deployment technologies give rise loosely classified decision bias commonly automation bias automation bias decision bias technological halo effect users automated decision systems may tend become hampered critical judgment rational agency situational awareness result faith perceived objectivity neutrality certainty superi ority system may lead errors omission implementers lose capacity identify respond faults errors deficiencies might arise course use automated system become complacent overly deferent directions cues decision bias may also lead errors commission implementers defer perceived infallibility system thereby become unable detect problems emerging use reason failure hold results available information may lead known syndrome deg radation role human reason deskilling critical thinking hampers user ability complete tasks automated condition may bring loss ability respond system failure may lead afety hazards dangers discriminatory harm combat risks decision bias operationalise str ong regimes accountability site user dep loyment steer human decision act basis good reaso solid inferences critical judgment automation bias extreme sers automated decision system may tend disregard salient contributions evidence reasoning either result distrust skepticism technologies general result importance prudence common sense human expertise aversion non amoral character automated systems may also influence decision subjects hesit ation consult technologies high impact contexts healthcare transportation law order secure safeguard fair implementation systems users well utilise algorithmic outputs tools making evidence judgements consider following measures training implementers include conveyance basic knowledge statistical probabilistic character machine learning limitations auto mated decision technologies training avoid anthropomorphic understanding artificial intelligence ethics safety human portrayals systems encourage users view benefits risks deploying systems terms role assisting human judg ment rather replacing forethought given design user interface human factors possibilities implementation biases systems designed processes encourage active user judgment situational awareness interface user system designed make clear accessible user system rationale compliance fairness standards confidence level ideally happen runtime manner training implementers include pre exploration cognitive judgmental biases may occur across deployment context done use case based manner highlights particular misjudgements may occur people weigh statistical evidence examples latter may include overconfidence prediction based historical consistency data illusions clustering data oints necessarily indicates significant insights discounting societal patterns exist beyond statistical results putting rinciple discriminatory non ction con sidering put principle discriminatory non action come together managers project team map team member involvement stage project pipeline alpha beta considering fairness aware design implementation workflow perspective allow team concretis make explicit end paths accountability clear peer manner essential establishing robust accountab ility framework schematic representation fairness aware workflow complete final row understanding artificial intelligence ethics safety considering fairness aware design implementation workflow perspective also assist pinpoint ing risks bias downstream discrimination streamlining possible solutions proactive pre anticipatory way stage project pipeline column table relevant members team carry collaborative self regard applicable dimension fairness three process accountability considering role accountability proje delivery lifecycle important first make sure taking best practices approach data processing aligned principle data ethics framework beyond following general guidance however pay special attention new unique challenges posed public sector accountability design implementation systems responsible project delivery requires two related challenges public sector accountability confronted directly accountability gap mentioned utomated decision self whereas human agents call account judgements decisions instances judgments decisions affect interests others statistical models underlying hardware compose systems responsible morally relevant sense creates accountability gap must addressed clear imputable sources human answerability attach decision assisted produced system complexity production process establishing uman answerabili simple matter comes design deployment systems due complexity multi character development use systems typically project delivery workflows include department delivery leads technical discriminatory non step identify fairness bias mitigation dimensions apply specific stage consideration example data pre stage dimensions data fairness design irness outcome fairness may issue step scrutinise particular project might pose risks unintended vulnerabilities areas step take action correct existing problems identified strengthen areas weakness possible discriminatory consequences take proactive bias measures areas identified pose potential future risks understanding artificial intelligence ethics safety experts data procurement preparation personnel policy domain experts implementers others due production complexity may become difficult answer question among parties involved production systems bear responsibility ese systems uses negative consequences impacts meeting special requirements accountability born two challenges call sufficiently concept ould make project properly accountable concept broken two subcomponents accountability answerability auditability answerability principle accountability demands onus justifying algorithmically support decisions placed shoulders human creators users systems means essential establish continuous chain human responsibility across whole project delivery workflow making sure accountability effective end end necessitates gaps permitted answerability responsible man authorities first steps design system algorithmically steered outcomes answerability also demands explanations justifications content algorithmically supported decisions processes behind production offered competent human authorities plain understandable coherent language explanations justifications based upon sincere consistent sound impartial reasons accessible non hearers auditability whereas notion answerability responds question accountable automation supported outcome notion auditability answer question designers implementers systems held accountable aspect accountability demonstrating responsib ility design use practices justifiability outcomes project team must ensure every step process signing implementing project accessible audit oversight review successful audit requires builders implementers algorithmic systems keep records make accessible informatio enables monitoring soundness diligence innovation processes produced system auditability also requires project team keep records make accessible information enables monitoring data provenance analysis stages collection pre modelling training testing deploying purpose previously mentioned dataset factsheet moreover requires team enable peers overseers probe itically review dynamic operation system order ensure procedures operations producing model behaviou safe ethical fair ractically transparent algori thmic models must built auditability reproducible equipped recording monitoring data processing understanding artificial intelligence ethics safety deliberate incorporation elements accountability answerability auditability project lifecycle may cal led accountability acco untability deserves consideration across entire design implementation workflow best practice actively consider different demands accountability sign places roll project refer process ensuring accountability design development stages project anticipatory accountability anticipating project accountability needs prior completed following similar logic refer process addressing account ability start deployment project remedial accountability initial implementation system remedying issues may raised effects potential externalities two subtypes accountability sometimes referred accountability accountability respectively anticipatory accountability treating accountability anticipatory principle entails take primary importance decisions made actions taken project delivery team prior outcome algorithmically supported decision process kind ante accountability prioritised remedial accountability focu ses instead corrective justificatory measures taken automa tion supported process completed ensuring project delivery processes accountable prior actual application system world bolster soundness design implementation processes thereby effectively possible harms individu wellbeing public welfare likewise establishing strong regimes anticipatory accountability making design delivery process open publicly accessible possible put affected stakeholders position make tter informed knowledgeable decisions involvement systems advance potentially harmful impacts also strengthen public narrative help safeguard project reputational harm remed ial accountability remedial accountability seen along lines necessary fallback rather first resort imputing responsibility design deployment systems strong regimes remedial accountability less important accountability design systems must designed facilitate end answerability auditability requires responsible humans across entire design implementation chain well activity monitoring protocols enable end ove rsight review understanding artificial intelligence ethics safety providing necessary justifications bearing systems lives affected stakeholders putting place comprehensive auditability regimes part accountability framework establishing transparent design use practices methodically logged throughout project delivery lifecycle essential components sort remedial accountability one aspect remedial accountability must pay close attention need provide explanations affected stakeholders lgorithmically supported decisions aspect accountable transparent design practices called explicabi lity literally means ability make explicit meaning algorithmic model result offering explanations results lgorithmically supported decision involves furnishing decision subjects interested parties understandable account rationale behind specific outcome interest also involves furnishing decision subject interested parties explanation ethical permissibility fairness safety use system tasks content clarification practical justification explored detail part section transparency sustainability design ers users systems remain aware chnologies may transformative long effects individu als society order ensure deployment system remains sustainable support sustainabil ity communities affect team proceed continuous sensitivity impacts system stakeholder impact assessment project team come together evaluate social impact sustainability project stakeholder impact assessment sia whether project used deliver public service back administrative capacity refer stakeholders referring primarily affected individual person term may also extend groups organisations sense individual members collective may also impacted design deployment systems due consideration stakeholders given levels purpose carrying sia multidimensional sias serve several purposes include help build public confidence design deployment system public sector agency done responsibly facilitate strengthen accountability framework bring light unseen risks threaten affect individuals public good understanding artificial intelligence ethics safety underwrite well decision transparent innovation practices demonstrate forethought due diligence within organisation also wider public team convene evaluate social impact sustainability project sia three critical points project delivery lifecycle alpha phase problem formulation carry initial stakeholder impact ssessment sia determine ethical rmissibility project refer sum values starting point considerations possible effects project individual wellbeing public welfare cases conclude project significant ethic social impacts open initial public views properly considered bolster inclusion diversity voices opinions design development process participation representative range stakeholders also consider consulting internal organisational stakeholders whose input likewise strengthen openness inclusivity diversity project alpha beta model trained tested validated team revisit initial sia confirm system implemented still line evaluations conclusions original assessm ent check logged section sia applicable changes added discussed launch system sia made publicly available point must also set timeframe eassessment system operation well public consultation predates provides input timeframes decided team case basis proportional scale potential impact system individuals communities affect beta phase system gone live team intermittently revisit sia check logged reassessment section sia applicable changes added discussed reassessment focus evaluating existing sia real worl impacts considering mitigate unintended consequences may ensued wake deployment system public consultation input beta stage undertaken ent stakeholder input included deliberations keep mind specific focus social ethical sustainability stakeholder impact ssessment constitutes one part governance platform project comple ment accoun tability framework auditing activity documentation sia broken four sections questions responses section general questions possible big social ethical impacts use system plan build section team collaboratively formulate relevant sector use case questions impact system understanding artificial intelligence ethics safety affected stakeholders section provide answers additional questions relevant evaluation section provide opportunity members team reassess system light real impacts public input possi ble unintended consequences prototype sia stakeholder impact assessment project name alpha phase problem formulation general questions completed date identifying affected stakeholders stakeholders project likely affect groups stakeholders vulnerable might project negatively impact goal objective defin ing outcome target variable system optimising fair reasonable widely acceptable definition target variable measurable proxy reflect reasonable justifiable translation project objective statistical frame translation justifiable given general purpose project potential impacts comes implementation communities involved iii possible impacts individual might implementation system impact abilities affected stakeholders make free independent decisions lives might enhance diminish autonomy might affect capacities flourish fully develop might arm physical mental integrity risks individual health safety adequately considered addressed might infringe privacy rights data processing end designing system implementation end deploying possible impacts society interpersonal relationships might implementation system adversely affect stakeholder fair equal trea tment law aspects project expose vulnerable communities possible discriminatory harm might use system affect integrity interpersonal dialogue meaningful human connection social cohesion understanding artificial intelligence ethics safety values civic participation inclusion diversity adequately considered articulating purpose setting goals project might values incorporated project design project aim advance interests well many affected individuals possible might disparate socioeconomic impacts result deployment sufficiently considered wider impacts system future gene rations planet whole alpha phase problem formulation sector use case questions completed date section shou consider sector use case issues surrounding social ethical impacts project affected stakeholders compile list questions concerns anticipate state team attempting address questions concerns alpha beta completed date reviewing results initial sia answer following questions trained model actual objective design testing results still line evaluations conclusions contained original assessment assessment differ areas concern arisen regard possibly harmful social ethical impacts moved alpha beta hase must also set reasonable timeframe public consultation beta phase date public consultation beta impacts date planned beta phase beta phase completed date reviewed recent version sia results public consultation answer following questions content existing sia compare real impacts system measured vailable evidence performance monitoring data input implementers public steps taken rectify problems issues emerged unintended harmful consequences ensued wake deployment system might negative impacts mitigate redressed understanding artificial intelligence ethics safety maintenance processes model adequately taken account possibility distributional shifts underlying population model proper retuned retrained accommodate changes environment date public consultation beta impacts date next planned beta phase safety beyond safeguarding sustainability project relates social impacts individual wellbeing public welfare project team must also confront related challenge technical sustainability safety technically sustainable system safe accurate reliable secure robust securing goals however difficult unremitting task systems operate world filled uncertainty volatility flux challenge building safe reliable especially daunting job however must met head making goal producing safe reliable technologies central project able mitigate risks system failing scale faced real unknowns unforeseen events issue safety paramount importance potential failures may produce harmful outcomes undermine publ trust order safeguard system unctions safely must prioritise technical objectives accuracy reliability security robustness require technical team put careful forethought construct system accurately dependab operates accordance designer expectations even confronted unexpected changes anomalies perturbations building system meets safety goals also require rigorou testing validation well int egration adequate mechanisms oversight control operation accuracy reliability security obustness important gain strong working knowledge safety relevant operational objectives accuracy reliability security robustness accuracy performance metrics machine learning acc uracy model proportio examples generates correct output performance measure also sometimes characterised conversely error rate frac tion cases model produces incorrect output keep mind instances choice acceptable error rate accuracy level adju sted accordance use case specific needs application instances may largely set domain established benchmark understanding artificial intelligence ethics safety performance metric accuracy central component establishing nuancing team approach safe said pecifying reasonable performance level system may also often require refine exchange measure accuracy instance certain errors significant costly others metric total ost integrated model cost one class errors weighed another likewise precision sensitivity system detecting uncommon events priority say instance medical diagnosis rare cases dis ease use technique precision recall method addressing imbalanced classification would allow weigh proportion system correct detections frequent rare outcomes proportion actual detections rare event ratio true detections rare outcome sum true detections outcome missed detections false negatives outcome general measuring accuracy face uncerta inty challenge must given significant thought confidence level system depend heavily problems inherent attempts model chaotic changing reality concerns accuracy must cope issues unavoida ble ise present data sample architectural uncertainties generated possibility given model missing relevant features underlying distribution inevitable changes input data time reliability obje ctive reliabil ity system behaves exactly designers intended anticipated reliable system adheres specifications programmed carry reliability therefore measure consistency establish confidence safety ystem based upon dependability operationally conf orms intended functionality security goal security encompasses protection several operational dimensions ystem confronted possible adversarial attack secure system capable maintaining integrity informa tion constitutes includes protecting architecture unauthorised modification damage com ponent parts secure system also remains continuously functional accessible authorised users keeps confidential private information secure even hostile adversarial conditions robustness objective robustness thought goal system function reliably accurately harsh conditions conditions may include adversarial intervention implementer error skewed goal automated learner reinforcemen learning applications measure robustness therefore strength system integrity soundness operation response difficult conditions adversarial attacks perturbations data poisoning undesirable reinforcement learning behaviour risks osed accuracy eliability understanding artificial intelligence ethics safety concept drift trained machine learning systems operate static models world built historical data become fixed systems parameters freezing model released wild makes accuracy reliability especially vulnerable changes underlying distribution data historical data crystallised trained model architecture cease reflect population concerned model mapping function longer able accurately reliably transform inputs target output value systems quickly beco prone error unexpected harmful ways much valuable research done methods detecting mitigat ing concept distribution drift consult technical team ensure members familiarised research sufficient knowledge available ways confront issue cases remain vigilant tentially rapid concept drifts may occur complex dynamic evolving environments project intervene remaining aware transformations data crucial safe team actively formulate action plan anticipate mitigate impacts performance system brittleness another possible challenge accuracy reliability machine learning systems arises inherent imitations systems many high performing machine learning models deep neural nets dnn rely massive amounts data brute force repetition training examples tune thousands millions even billions parameters collectively generate outputs however actually running unpredictable world systems may difficulty processing unfamiliar events scenarios may make unexpected serious mistakes ecause neither capacity cont extual ise problems programmed solve common ability determine relevance new unknowns moreover mistakes may remain unexplainable given high dimensionality computational complexity mathematica structure fragility brittleness especially significant consequences safety applications like fully automated transportation medical decision support systems undetectable changes inputs may lead significant failures progress made finding ways make models robust crucial consider safety first weighing viability risks posed security robustness adversarial attack adversarial attacks machine learning models maliciously modify input data imperceptible ways induce misclassification incorrect prediction instance undetectably altering pixels picture adversarial attacker mislead model generating incorrect output like identifying panda gibbon stop sign speed limit sign extremely high confidence good amount attention paid risks adversarial attacks pose deep learning applications like computer vision kinds perturbations also effective across vast range machine learning techniques uses spam filtering malware detection understanding artificial intelligence ethics safety vulnerabilities systems adv ersarial examples serious consequences safety existence cases subtle targeted perturbations cause models misled gross miscalculation incorrect decision potentially serious safety implication adopti critical systems like applications autonomous transportation medical imaging security surveillance response concerns threats posed safe trusted environment technologies adversarial attacks field call adversarial machine learning emerged past several years work area focuses securing systems disruptive perturbation points vulnerability across pipeline one major safety strategies arisen research appro ach called model hardening advanced techniques combat adversarial attacks strengthening architectural components systems model hardening techniques may include adversarial training training data methodically enlarge include adversarial examples model hardening methods involve architectural modification regularisation data pre manipulation second notable safety strategy runtime detection system augmented discover apparatus identify trace real existence adversarial examples consult members technical team ensure risks adversarial attack taken account mitigated throughout lifecycle valuable collection resources combat adversarial attack found robustness data poisoning different rela ted type adversarial attack called data poisoning threat safe reliable involves malicious compromise data sources point collection pre data poisoning occurs adversary modifies manipulates part dataset upon model trained validated tested altering selected subset training inputs poisoning attack induce trained system curated misclassification system malfunction poor performance pecially concerning dimension targeted data poisoning adversary may introduce backdoor infected model whereby trained system functions normally processes maliciously selected inputs trigger error failure order combat data poisoning technical team become familiar state art filtering detecting poisoned data however technical solutions enough data poisoning possible data collection procure ment often involves potentially unreliable questionable sources data originates uncontrollable environments like internet social media internet things many opportunities present ill attackers aim manipulate training examples likewise third party data curation processes crowdsourced labelling annotation content identification attackers may simply handcraft malicious inputs project team focus best pra ctices responsible data management able tend data quality end priority misdirected reinforcement learning behaviour different set safety risks emerges approach machine learning called reinforcement learning widely understanding artificial intelligence ethics safety applied methods supervised learning largely focus guide model transforms inputs outputs according fixed mapping function resulted passively received training contrast learner system actively solves problems engaging environment trial error exploration problem behaviour determined objective ximising reward function defined designers flexibility model however comes price potential safety risks system operating real without sufficient controls may determine reward ising course action optimal achieving desired objective harmful people model lack context common sense empathy understanding unable identify scenarios may dama ging consequences anticipated constrained programmers difficult problem unbounded complexity world makes anticipating pitfalls detrimental variables veritably impossible existi strategies mitigate risks misdirected reinforcement learning behaviour include running extensive simulations testing stage appropriate measures constraint programmed stem continuous inspection mon itoring system behaviour better predicted understood finding ways make system interpretable decisions better assessed mechanisms system enable human override system shut safety safety risks face project depend among factors sort algorithm machine learning techniques using type applications techniques going deployed provenance data way specifying objective problem domain specification applies best practice regardless variab ility techniques circumstances safety considerations accuracy reliability secur ity robustness operation every tage project lifecycle involve rigorous protocols testing validating verifying monitoring safety system performance safety self relevant members team stage workflow self evaluate team design implementation practices line safety objectives accuracy reliability security robustness safety self logged across workflow single document running fashion allows review transparency understanding artificial intelligence ethics safety defining transparent important remember transparency principle ethics differs bit meaning everyday use term common dictionary understanding transparency defines either quality object one see clearly quality situation process clearly justified explained open inspection free secrets transparency principle ethics encompasses meanings one hand transparent involves interpretability given system ability know model performed way specific context therefore understand rationale behind decision behaviour sort transparency often referred way metaphor opening black box involves content clarification intelligibility explicability hand transparent involves justifiability processe design implementation outcome therefore involves soundness justification use normative meaning transparent practically justifiable unrestric ted way one demonstrate design implementation processes gone particular decision behaviour system decision behaviour ethically permissible non worthy public trust three critical tasks designing mplementing transparent definition transparency principle ethics asks think transparent terms process behind design implementation practices lead algorithmically support outcome terms product content justification outcome proce distinction crucial clarifies three tasks team responsible safeguard ing transparency project process transparency task justify process offering explanation affected stake holders able demonstrate considerations ethical permissibility public trustworthiness operative end design implementation processes lead automated decision behaviour task supported following best practices outlined herein throughout project lifecycle putting place robust aud itability measures accountability framework outcome transparency task clarify content explain outcome offering explanation affected stakeholders able show plain language understandable non model performed way specific decision behaviour context therefore able clarify communicate rationale behind decision behaviour explanation socially meaningful sense terms logic explanation simply understanding artificial intelligence ethics safety reproduce formal characteristics technical meanings rationale mathematical model rather translated everyday language human practices therefore understandable terms societal factors relationships decision behaviour implicates outcome transparency task justify outcome offering explanation affected stakeholders able demonstrate specific decis ion behaviour system ethically permissible non worthy public trust tysecuring outcome justification take content clarification outcome task starting point weigh explanation justifiability criteria adhered throughout design use pipeline ethical permissibility nondiscrimination public trustworthiness undertaking optimal approach process transparency start support safeguard demand normative explanation outcome justification mapping ranspare ncy exploring three tasks individually may helpful visualise relatio nship connected components transparent process transparency establishing process governance framework central importance end operability good governance practices guide strategy build responsible project workflow processes three components essential creati responsible workflow aintaining strong regimes professional institutional transparency clear accessible process governance understanding artificial intelligence ethics safety framework framework establishing well auditability trail pbg framework robust activity logging protocols consolidated digitally process log professional institutional transparency every stage design implementation project team members held rigorous standards conduct secure maintain professionalism institutional transp arency standards include core values integrity honesty sincerity neutrality objectivity impartiality rofess ionals involved research development production implementation technologies first foremost acting fiduciaries public interest must keeping core values civil service put obligations erve interest concerns furthermore rom start finish project lifecycle design implementation process transparent open public scrutiny possible restrictions accessibility levant information limited reason able protection justified public sector confidentiality analytics may tip bad actors methods gaming system service provision process governance framework far guide presented main steps necessary establish ing responsible innovation practices proj ect perhaps vital measures effective operationalisation values principles und erpin development ethical safe rganising governance considerations actions pbg framework better able accomplish task purpose pbg framework provide template integrations norms values principles motivate steer responsible innovation actual processes characterise design development pipeline accompanying guide focused primarily cross industry standard process data mining crisp keep mind structured integration values principles innovation processes applicable related workflow models like knowledge discovery databases kdd sample explore modify model assess semma pbg framework give landscape view governance procedures protocols organising control structures project workflow constructing good pbg framework provide team big picture relevant team members roles involved governance action relevant stages workflow intervention targeted cons ideration necessary meet governance goals explicit timeframes necessary follow actions continual monitoring clear well protocols logging activity instituting mechanisms assure end aud itability understanding artificial intelligence ethics safety help get summary picture components process transparenc explored far fit pbg framework landscape view enabling auditability process log controls place governance framework organised better able manage consolidate information necessary assure end auditability information include records activity results yielded pbg fra mework model development data gathered across modelling training testing verifying implementation phases centralising information digitally process log preparing way optimal process transparency proces log enable make available one place information may assist demonstrating concern parties affected decision subjects responsibility design use practices justifiability outcomes system processing behaviour log also allow differentially organise accessibility presentation information yielded project crucial preserving protecting data legitimately remain unavailable public view afford team capacity cater presentation results different tiers stakeholders different interests level expertise ability curate explanations use rreceiver mind vital achieving goals interpretable justifiable outcome ransparency explaining outcome clarifying content beyond enabling process transparency pbg framework must also put place standards protocols ensure clear understandable explanations outcomes system decisions behaviours problem tasks understanding artificial intelligence ethics safety properly inform evidence judgments implementers designed support offered affected stakeholders concerned parties accessible way multifaceted undertaking demand careful forethought participation across entire project team simple technological solution effectively clarify convey ration ale behind model output particular decision behavioural context team use sound judgement common sense order bring together technical aspects choosing designing using sufficiently interpretable system delivery aspects able clarify communicate plain non socially eaningful language system performed way specific decision behaviour context good grasp rationale criteria behind decision problem behaviour system essenti producing safe fair ethical model sufficiently interpretable able draw humanly understandable explanations factors layed significant role determining behaviours may able tell things wrong system crucial unavoidable issue reasons already explored ensuring safety high impact systems transportation medicine infrastructure security requires human verification systems properly learned critical tasks charged complete also requires confirmation confronted unfamiliar circumstance anomalies perturbation systems fail make unintuitive errors moreover ensuring systems operate without causing discriminatory harms requires effective ways detect mitigate sources bias inequitable influence hat may buried dee within feature spaces inferences architectures without interpretability one tasks necessary delivering safe mora lly justifiable remain ncomplete defining interpretable gain foothold techn ical delivery dimensions interpretability first need solid working definition interpretable end may useful recall defini tion offered accompanying guide artificial intelligence science making computers things require intelligence done humans characterisation important brings essential feature explanatory demands interpretable thin require intelligence done humans means things require reasoning processes cognitive functioning cognitive dimension direct bearing think offer ing suitable explanations algorithmically generat outcomes expla ining algorithmic model decision behaviour involve making explicit particular set ctors determin outcome play role evidence supporting understanding artificial intelligence ethics safety conclusion reached involve making intelligible affected individuals rationale behind decision behaviour produc reasoning evidence inference person makes explan ation task demanding comes systems reasoning processes occur humans one level rather human reasoning interpreting includes aspects logic applying basic principles validity lie behind give form sound thin king aspect aligns need formal logical explanation systems aspects semantics gaining understanding things work way mean aspect aligns need explanation technical rationale behind outcomes systems aspects social understanding practices beliefs intentions clarifying content interpersonal relations societal norms individual objectives aspect aligns need clarification socia lly meaningful content outcomes systems aspects moral justification making sense considered right wrong everyday activities choices aspect aligns justifiability systems good reasons four dimensions human reasoning processes must factor explaining decisions behaviours systems first evidently understanding logic technical innerworkings semantic content ese systems precondition ensuring safety fairness seco ndly ecause designed used achieve human objectives fulfil surrogate cognitive functions everyday social world need make sense systems terms consequential roles decisions behaviours human reality social context outcomes matters greatly finally actually affect individuals society direct morally consequential ways need able understand explain outcomes terms mathematical gic technical rationale social context also terms justifiability impacts people delving deeply technical delivery aspects interpretable show four dimens ions human reasoning directly line different levels demand explanations outcomes systems particular logical semantic dimensions weigh heavily technical considerations whereas social moral dime nsions significant point delivery note though different dimensions human reasoning necessarily mutually exclusive build depend upon significant cascading ways approaching explanations interpretable therefore treated holistically inclusively technical explanation logic rationale given model instance seen support context clarification socially meaning ful content socially meaningful content viewed forming basis explaining outcome moral justifiability understanding artificial intelligence ethics safety considering make outcomes decision problem systems maximally transparent affected stakeholders take rounded view human reasoning account help address effectively spectrum concerns stakeholders may technical aspects choosing designing using interpret able system keep mind face task choosing numerous machine learning algorithms may seem daunting need sticking priority outcome transparency team ble follow straightforward simple guidelines selecting sufficiently interpretable optimally performing algorithmic technique exploring guidelines necessary provide background information help better understand face explanation actually involved technically interpretable good grasp actually needed explanation enable effectively target interpretability need project facets expl anation technically interpretable good starting point understanding technical dimension explanation works interpretable systems remember systems largel mathematical models carry step computations transforming sets statistically interacting independent inputs ets target outputs machine learning bottom applied statistics probability theory fortified several mathematical techniques subject methodologically rigorous requirements logical validation mathematical sciences demand rigour informs facet formal logical explanation systems sometimes called mathematical glass box characterisation refers transparency strictly formal explanation matter complicated even case deep neural net hundred million parameters algorithmic model closed system effectively computable operations rules transformations mechanically applied inputs determine outputs restricted sense machine learning models fully intelligib mathematically transparent formally logically important characteristic systems makes possible supplemental eminently interpretable computational approaches model approximate simplify even complex high dimensional among fact possibility fuels technical approaches interpretable soon explored formal way understanding technical explanation machine learning systems however immediate limitations tell model mathematically intelligible operates according collection fixed operations parameters tell much components model trans formed specif ied group inputs corresponding outputs tell anything rationale behind algorithmic generation given outcome second dimension technical explanation semantic facet interpretable semantic explanation offers interpretation functions individual parts understanding artificial intelligence ethics safety algorithmic system generation output whereas formal logical explanation presents account stepwise application procedures rules comprise formal framework algorithmic system semantic explanation helps understand meaning procedures rules terms purpose input mapping operation system role play determining outcome model computation difficulties surrounding interpretability algorithmic decisions behaviours arise semantic dimension technical explanation easiest illustrate starting simplest case machine learning model basic task follow ing rationale transforms given set inputs given set outputs relatively unp roblematic instan simple linear regression single predictor variable response variable predictive relationship directly expressed regression coefficient representing rate direction predicted change changes hypothetical model completely interpretable technical perspective following reasons linearity change value predictor variable directl reflected change value response variable constant rate interpretable prediction yielded model therefore directly inferred linearity dimension predictive models essential feature automated decision systems many heavily regulated high sectors predictions yielded high inferential clarity strength monotonic ity value predictor changes given direction value response variable changes consistently either opposite direction interpretable prediction yielded model thus directly inferred monotonicity dimension also highly desirable interpretability condition predictive models many heavily regulated sectors incorporates reas onable expectations consistent application sector specific selection constra ints automated decision systems example selection criteria gain employment agency firm includes taking exam reasonable expectation outcomes would candidate scored better candidate candidate things equal would selected employment monotonic predictive model uses exam score predictor variable application success response variable would effect guarantee expectation met disallowing situations scores better gets selected number features dimensionality feature interactions low enough mapping function simple enough ena ble clear global understanding function part mod relation outcome three desirable interpretability characteristics imagined model allow direct intuitive reasoning relation predictor response variable model clearly minimal capture density relationships interactions attributes complex situations degree noisiness unavoidable task app rehending subtleties nderlying data distributions tricky understanding artificial intelligence ethics safety fact great strides forward enabled contemporary convergence expanding computing power big data availability advanced machine learning models exactly capacity better capture model intricate complicated dynamics real situations still incorporation complexity scale models also meant significant challenges semantic dimension technical explanation systems machine lea rning system come possess ever greater access big data increasing comput ing power designers correspondingly able enlarge feature spaces number input variables systems turn gradua lly complex mapping functions many cases meant vast improvements predictive classificatory performance accurate expressive models also meant growing prevalence non non high complexity expanding array black models high feature spaces complex functions introduced machin learning systems effects changes given input become entangled values interactions input understanding individual components transformed outputs becomes extremely difficult complex unintu itive curve decision functions many mod els preclude linear monotonic relations inputs outputs likewise high optimisation techniques involving millions parameters comp lex correlations well beyond limits human cognition understanding illustrate increasing complexit involved comprehe nding input mappings visual representation depict difference lin ear regression function deep neural network rising tides computational complexity algorithmic opacity consequently pose key challenge responsible design deployment safe fair ethical systems potential advance public interest implementation high performing increasingly interpretable machine learning models weighed agains tangible risks posed lack interpretability systems understanding artificial intelligence ethics safety careful answer question fact simple trade performance interpretability may real important domain applications others exist increasingly sophisticate developments standard interpretable techniques regression extensions decision trees rule lists may prove effective use cases need transparency paramount furthermore supplemental interpretability tools function make black box models semantically qualitatively explainable rapidly advancing day day factors team consider work together decide models use project starting point considerations let turn basic guidelines may help steer hat dialogue toward points relevance concern guidelines designing delivering sufficiently interpretable system use table begin thinking integrate interpretability project aspects topic become extremely technical important make sure dialogue making system interpretable remains multidisciplinary inclusive moreover crucial stakeholders given adequate consideration deciding upon delivery mechanisms project include policy operational design leads technical personnel charge operating trained models implementers odels decision subjects affected outcomes note first three guideline focus big picture issue need consider order incorpor ate interpretability needs project planning workflow ereas last two guidelines shift focus user requirements desig ning implementing sufficiently interpretable system guidelines designing delivering sufficiently interpretable system guideline look first context potential impact domain need determining interpretability requirements project several related factors taken account formulate project approach interpretability type application start assessing kind tool building environment apply clearly big difference computer vision system sorts handwritten employee edback forms one sorts safety risks security checkpoint likewise big difference random forest model triages applicants licencing agency one triages sick patients emergency department understa nding system purpose context application give better idea stakes involved use hence also good starting point think scope interpretability needs instance low models understanding artificial intelligence ethics safety safety directly impact lives people process potentially sensitive social demographic data likely lower need extensive resources dedicate comprehensive interpretability platform dom specificity acquiring solid domain knowledge environment system operate gain better insight potential sector standards explanation benchmarks justification inform approach interpretability knowledge may also obtain useful information organisational public expectations regarding scope content depth explanations previously offered relevant use cases existing technology one purposes project replace existing algorithmic technology may offer sort expressive power performance level advanced machine learning techniques planning deploy carry assessment performance interpretability levels existing technology acquiring knowledge provide important reference point consider ing possible trade perfo rmance interpretability may occur prospective system also allow weigh costs benefits building complex system higher interpretability needs comparison costs benefits using simpler model guideline draw standard interpretable techniques possible order actively integrate aim sufficient interpretability project team approach model selection development proces goal finding right fit domain risks needs available data resources domain knowledge task appropriate machine learning techniques effectively assimilating three aspects use case req uires open practicality often times may case high safety potentially sensitive environments heighten demands thoroughgoing accou ntability transparency projects instances demands may make choosing standard sophisticated non techniques overriding priority techniques may include decisions trees linear reg ression extensions like generalis additive models decision lists case reasoning logistic regression many cases reaching black box model first may appropriate may even lead inefficiencies project development interpretable models perform well require suppleme ntal tools techniques facilitat ing interpretable outcomes also available solid domain knowledge context awareness key components use cases data resources lend well meaningful representations domain expertise incorporated int model architecture interpretable techniques may often desirable opaque ones careful data pre iterative model development cases hone accuracy interpretable systems ways may make advanta ges gained combination performanc transparency outweigh benefits semantically intransparent approaches understanding artificial intelligence ethics safety use cases however data processing needs may disqualify deployment sorts straightforward terpretable systems instance applications sought classifying images recognising speech detecting anomalies video footage effective machine learning approaches likely opaque feature spaces kinds systems grow exponentially hundreds thousands even millions dimensions scale complexity conventional methods interpretation longer apply indeed unavoidability hitting interpretability wall certain important applications supervised unsupervised reinforcement learning given rise entire subfield machine learning research focuses providing technical tools facilitat interpretable explainable use black box models best fits purpose project proceed diligently follow procedure recommended guideline clarity let define black box model system whose innerworkings rationale opaque inaccessible human understanding systems may include neural networks including recurrent convolutional deep neural nets ensemble methods algorithmic technique random forest method strengthens overall prediction combining aggregating results several many different base models support vector machines classifier uses special type mapping function build divider two ets features high dimensional feature space guideline considering use black box systems thoroughly weigh impacts risks consider options available supplemental interpretability tools ensure level semantic expla nation domain appropriat consistent design implementation safe fair ethical formulate interpretability action plan team put adequate forethought explanations outcomes sys tem decisions behaviours problem tasks optimally provided user decision subject affected parties may helpful explore three suggested steps assessing viability responsible design implementation black box model greater detail thoroughly weigh impacts risks first step evaluating feasibility using complex system focus issues ethics safety general policy team utilise black box models potential impacts risks thoroughly considered advance team determi ned use case domain specific needs support responsible design implementations systems understanding artificial intelligence ethics safety supplemental interpretability tools provide system domain appropriate level semantic explainability reasonab sufficient mitigate potential risks therefore consistent design implementation safe fair ethical consider options available supplemental interpretability tools next team assess whether technical methods expla nation satisfy specific interpretability needs use case determined deliberations suggested guideline appropriate algorithmic approach intend use consult closely technical team stage model select ion xploratory processes trial often guide discovery hase innovation lifecycle informed constrained solid working knowledge technical art possible domain available useable interpretability approaches task lining model selection process demands interpretable requires conceptual tools enable thoughtful evaluation whether proposed supplemental interpretability approaches sufficiently meet project explanatory need first importantly prepared ask right questions evaluating given interpretability approach involves establishing much clarity possible explanatory results approach contribute user ability offer solid coherent reasonable accounts rationale behind given algorithmically generated put relevant questions ask serve end sort explanatory resources ill interpretability tool provide users implementers order enable exercise better evidence judgments assist offering plausible sound reasonable account logic behind algorithmically generated output affected individuals concerned parties explanatory resources interpretability tool offers useful providi affected stakeholders sufficient understanding given outcome might explanatory resources offered tool misleading confusing team take questions starting point evaluating prospective interpretability tool tools assessed terms capaciti render reasoning behind decisions behaviours uninterpretable black box systems sufficiently intelligible users affected stakeholders given use case domain specific interpretability needs keeping mind two technical dimensions supplemental interpretability approaches systematically incorporated evaluation processes stage innovation workflow understanding artificial intelligence ethics safety first involves possible explanatory strategies choose pursue course design implementation lifecycle strategies largely determine paths understanding able provide users decision subjects largely define explain model outcomes hence kinds explanation able offer second involves coverage scope actual explanations choices make explanatory coverage determine extent kinds explanations planning pursue address single instances model outputs range broadly cover underlying rationale behaviour general across instances choices make explanatory coverage largely govern extent system locally globally interpretable broad overview two dimensions follows meant orient basi concept expanding field research prepared working technical team think strengths weaknesses various approache note additionally rapidly developing area relevant members team keep abreast latest developments field interpretable xai explainable two technical dimensions supplemental interpretability approaches determining explanatory strategies achieve goal securing sufficiently interpretable system team need get clear explain model outcomes explanatory strategies decide pursue shape paths understanding provide users model decision subjects four explanatory strategies pay special attention internal explanation pursuing internal explanation opaque del involves making intelligible components relationships within function two ways hat goal internal explanation interpreted one hand seen endeavour explain operation model considerin globally comprehensible whole aspiration pry open black box building explanatory model enables ful grasp opaque system internal contents strengths weaknesses approach discussed next section global interpretability hand search internal explanation indicate pursu kind engineering insight sense internal explanation seen attem pting shed descriptive inferential light parts operation system whole order try make work better acquiring sort internal understanding general relationships working parts trained model patterns responses allow researchers advance step gaining better data scientif grasp understanding artificial intelligence ethics safety improve similarly type internal explanation seen attempt ing shed light opaque model operation breaking understandable analysable digestible parts instance case dnn interpretable characteristics vectors features layers parame ters practical point view kind aspiration engineering insight ends data scientific advancement inform goals technical team throughout model selection design workflow numerous methods exist help provide nformative representations innerworkings various black box systems gaining clearer descriptive understanding internal composition system contribute greatly project ability achieve higher degree outcome transparency apacity foster best practices pursuit responsible data science general external post explanation external post explanation attempts capture essential attributes observable behaviour black box system subjecting number different techniques reverse engineer explanatory insight post approaches test sensitivity outputs opaque model perturbations inputs others allow interactive probing behavioural characteristics others still build proxy based model utilis simplified interpretable techniques gain better understanding particular instances predictions classifications external post approach present established machine learning research explanatory strategy good reason allows data scientists pose mathem atical questions opaque systems testing building supplemental models enable greater insight inference drawn experimental interventions post approach allows moreover seek evidence reasoning behind given opaque model prediction classification tilising maximally int erpretable techniqu like linear regressi decision trees rule lists case reasoning several examples post explanation explored section local interpretability take note initially though critics rightly point approximations simplified supplemental models complex original many post explanations fail accurately represent certain areas opaque model feature space deterior ation accuracy parts original model domain frequently produce misleading uncertain results post explanation concern supple mental explanatory infrastructur different kind explanatory strategy involves actually inc orporating secondary explanatory faciliti system building instance image recognition system could primary component like convolutional neural net extracts features understanding artificial intelligence ethics safety inputs classifies secondary component like built recurrent neu ral net attention mechanism translates extracted features natural language representation produces sentence explanation result user words system like designed provide simple explanations data processing results research integrating attention interfaces like systems continuing advance toward making implementations sensitive user needs explanation human instance ultimodal methods combining visualisation tools textual interface developed may make provision explanations interpretable implementers decision subjects furthermore incorporation domain knowledge logic convention structures architectures complex models increasingly allowing better user representations prototypes built gradually enabling sophisticated explanatory infrastructures integrated opaque systems make essential think ilding explanation projects counterfactual explanation counterfactual explanation kind post hoc approach deserves special attention insofar moves beyond post explanations provide affected stakeholders clear precise options actionable recourse practical remedy counterfactual explanations contrastive explanations offer succinct computational reckonings specific factors influenced algorithmic decision changed better alternatives realised subject decisio incorporating counterfactual explanations system point delivery would allow stakeholders see input variables model modifi outcome ould altered benefit additionally responsible design perspective incorporating counterfactual explanation development testing phases system would allow team build model incorporates actionable variables input variables ill afford decision subjects concise options making practical changes would improve chances obtaining desire outcome counterfactual explanatory strategies used way incorporate reasonableness encouragement agency design implementation project said important recognise counterfactual explanation offer innovative way contrastively explore feature importance may influence outcome complete solution problem interpretability certain cases instance sheer number potentially significant features could play counterfactual explanation given result make clear direct explanat ion difficult obtain selected sets explanations seem potentially arbitrary moreover understanding artificial intelligence ethics safety yet limitations types datasets functions kinds explana tions applicable finally kind explanati concedes opacity algorithmic model outright less able address concerns potentially harmful feature interactions multivariate relationships may buried deep within model architecture view typology explanatory strategies coverage scope main question need broach dimension coverage scope supplemental interpretability approach extent oes interp retability approach cover explanation singe prediction classification model extent cover explanation innerworkings rationale model whole across predictions extent oes cover distinction single instance total model explanation often characterised difference local interpretability global interpretability types explanation offer tentially elpful support provision significant information rationale behind algorithmic decision behaviour ways also face difficulties local interpretability local semantic explanation aims enable interpretability individual cases general idea behind attempts explain black box system terms specific instances regardless complex architecture decision function system may possible gain interpretive insight innerworkings focus ing single data points neighbourhoods feature space words even high dimensionality curviness model makes opaque whole expectation insight understanding artificial intelligence ethics safety interpretable methods applied locally smaller sections model changes isolated grouped variables mana geable understandable general explanatory perspective yielded several different interpretive strategies successfully applied significant areas black box machine learning one family strategies roed neural networks dnn particular identifying features input vector data points make representative target concept given model trying classify example digital image dog converted vector pixel value processed deep neural net interpretive approach ill endeavour tell system yielded dogpositive output isolating slices set data points relevant successful classific ation model accomplished several related ways called sensitivity analysis identifies relevant features input vector calculating local gradients determine data point moved change output label output sensitivity changes input values identifies relevant features another meth identify feature relevance downstream sensitivity analysis called salience mapping strategy moving backward layers neural net graph allows mapping patterns high activation nodes ultimate generates interpretable groupin salient input variables visually represented heat pixel attribution map second local interpretive strategy also seeks explain feature importance single prediction classification perturbing input variables howev instead using nudges feature space highlight areas saliency uses prod opaque model area around relevant prediction supplemental interpretable model constructed establishes relative importance features black box model output well example strategy called lime local interpretable model explanation lime works fitting interpretabl model specific prediction classification produced opaque system concern sampling data points random around target prediction classification using build local approximation decision boundary account features figure prominently specific prediction classification scrutiny way works relatively uncomplicated lime generates simple linear regression model weighting val ues data points produced randomly perturbing opaque model according proximity original prediction classification closest values instance explained weighted heaviest supplemental model produce explanation feature importance locally faithful instance note type model lime uses prominently sparse linear regression understanding artificial intelligence ethics safety function reasons semantic transparency discussed interpretable models decision trees likewise employed lime indeed appear step right direction future interpretable host issues present challenges approac remains unresolved instance crucial aspect properly define proximity measure neighbourhood local region explanation appli remains unclear small changes scale chosen measure lead greatly diverging explanations likewise explanation produced supplemental linear model quickly become unreliable even small virtually unnoticeable perturbations system attempting approximate challenges asic assumption always simplified linear model successfully approximates underlying model reasonably well near given data point lime creators largely acknowledged shortcoming recently offered new explanatory approach call anchors high precision rules incorporate formal structures reasonable patterns operating within underlying model implicit linguistic conventions work sentiment prediction model establish suitable faithful boundaries explanatory coverage predictions classifications related equally significant local interpretive strategy called shap shapley additive explanations shap uses concepts game theory define shapley value feature concern provides measurement influence underlying model prediction broadly value calculated featur averaging marginal contribution every possible prediction instance consideration might seem impossible strategy straightforward shap calculates marginal contribution relevant feature possibl combinations inputs feature space instance opaque model explaining features shap would calculate marginal contribution feature consideration times one calculation combination possible combinations features method allows shap estimate shapley values input features set produce complete distribution prediction instance example would entail calculations procedure computa tionally burdensome become intractable beyond certain threshold means locally calculation specific instance shap axiomatically guarantee consistency accuracy reckoning marginal effect feature note shap platform offer methods approximation avoid excessive computational expense despite alculational robustness shap also faces kind difficulties lime way shap calculates marginal contributions understanding artificial intelligence ethics safety constructing two instances first instance include feature measured second leaves calculating prediction instances plugging values underlying model result second subtracted first determine marginal contribution feature procedure repeated possible combinations features weighted average marginal contributions feature concern computed contestable part process comes shap defines absence variables consideration eave feature one directly measured one others included combinatio consideration replaces stand feature value drawn selected donor sample drawn existing dataset method sampling values assumes feature independenc values sampled correlated ways might significantly affect output particular calculation consequence interaction effects engendered stand variables necessarily unaccounted conditional contributions approximated result introduction uncertainty explanation produced complexity multivariate interactions underlyi model may sufficiently captured simplicity supplemental interpretability technique drawback sampling well certain degree arbitrariness domain definition ause shap become unreliable even minimal perturbations model approximating despite limitations existing tools local interpretability important think local considering issue coverage scope explanatory approaches plan incorporate project able provide explanations specific predictions classifications paramount importance securing optimal outco transparency also ensuring system implemented responsibly reasonably global nterpretability motivation behind creation local interpretability tools like lime shap well many others mentioned derived least part need find way avoid ing kind difficult double bind faced alternative app roach coverage scope interpretable global interpretability prevailing view providing global explanation black box model entail offering alternative interpretable model captures innerworkings logic black box model sum across predictions classifications difficulty faced global interpretability arises seemingly unavoidable trade need global explanatory model sufficiently simple understandable human need model sufficiently complex capture intricacies mapping function black box model works whole understanding artificial intelligence ethics safety clearly real problem appears theoretical inevitable important keep mind practical standpoint serviceable notion global interpretability need limited conceptual puzzle least two less ambitious constructive ways view global interpretability potentially meaningful contributor responsible design implementation interpretable first useful attempts already made building explanatory models employ interpretable thods like decision trees rule lists case classification globally approximate neura nets tree ensembles support vector machines results enabled deeper understanding way human interpretable logics conventions like rules representationally generated prototypes measured mapped onto high dimensional computational structures even allow degree targeted comprehensibility logic parts capacity peek black box great practical impo rtance domains trust user public acceptance critical realisation optimal outcomes moreover ability move back forth interpretable architecture high processing structures enable knowledge discover well insight kinds dataset population patterns ich crucial macroscale decision making areas ranging public health economics science climate change able uncover global effects relationships complex model behaviour data distributions demographic ecological level may prove vital establishing valuable practically useful knowledge unobservable significant biophysical social configurations hence lthough models solved understandability puzzle opened new pathways innovative thinking applied data sciences may immense public benefit future secondly mentioned auspices aspiration engineering insight descriptive analytical kind global interpretability seen driving force data scientific advancement seen practitioner centred lens sort global interpretability allows data scientists take wide angled discovery view black box model relationship patterns arise across range predictions figuring opaque system works make work better fully understanding patterns continuous priority good research understanding relevance features complex interactions dataset level measurement analysis dimensions incorporating explanatory aspirations global interpretability best practice research innovation hould encouraged project understanding artificial intelligence ethics safety formulate interpretability action lan final step need take ensure responsible approach using black box models formulate interpretability action plan team put adequate forethought explanations outcomes system decisions behaviours problem tasks optimally provided users decision subjects affected parties action plan include following clear articulation explanatory strategies team intends use detailed plan indicates stages project workflow design development strategies need take place succinct formula tion explanation delivery strategy addresses special provisions clear simple user explication called supplemental interpretability tools black box models utilised see delivery implementation guideline detailed timeframe evaluating team progress executing interpretability action plan role responsibility list maps detail various task responsibilities need fulfilled execute plan guideline think interpretability terms capacities human understanding begin deliberate specific scope content interpretability platform important reflect exactly aiming making model sufficiently interpretable good initial step take process think makes even simplest explanations clear understandable words begin thinking interpretability terms capacities limitations human cognition perspective becomes apparent even straightforward model like linear regression function decision tree become uninterpretable dimensionality presses beyond cognitive limits thinking human recall example simple linear regression thi instance one feature relates response variable understanding predictive relationship easy model parsimonious however started add features covariates even though model would remain linear nce intuitively predictable able understand relationship response variable predictors coefficients feature weights would quickly become difficult say added ten thousand features trained model understanding model prediction comes role ind ividual parts play producing prediction become difficult certain cognitive limit quantity entities human thinking handle given time model would lose significant degree interpretability seein interpretability continuum comprehensibility dependent capacities limits individual human interpreter key needed order deliver interpretable system limits consider inc lude cognitive understanding artificial intelligence ethics safety boundaries also varying levels access relevant vocabularies explanation explanation results trained model uses support vector achine divide feature space planar sepa rator instance may easy understand technical operator auditor entirely inaccessible non offering good explanations take expertise level account interpretability platform cognitively equi table securing responsible delivery human implementation protocols practices demand sensitivity human factors inform approach devising delivery implementation processes start finish provide clear effective explanations content rationale algorithmic outputs hav begin building human ground pay close attention circumstances needs competences capacities people project aims assist serve means context critical unde rstanding use case well drawing upon solid domain knowledge better able define roles relationships better able train users implementers system better able establish effectual implementation platform clarify content facilitate understanding outcome users affected stakeholders alike diagram securing human implementation protocols practices might look like let consider steps turn building checklist essential actions taken help ensure human implem entation project specifics approach depend heavily context poten tial impacts project assume understanding artificial intelligence ethics safety generic case construct checklist around hypothetical algorithmic decision system used predictive risk assessment step consider aspects application type domain cont ext define roles determine user needs assess members communities serving affected implementation system vulnerable among socioeconomic cultural edu cation backgrounds affect capacities interpret understand explanations intend provide fine explanatory strategy accommodate requirement provide clear non details rationale behind algorithmically supported result thinking providing explanations affected stakeholders start needs disadvantaged first way able establish acceptabl baseline equitable delivery interpretable reviewing guideline make list define roles potentially involved delivery stage project role specify levels technical expertise domain knowledge well possible goals objectives role instance predictive risk assessment case decision subject role subject predictive analytics possible oals objectives receive fair unbiased reasonable determination makes sense discover factors might changed receive different outcome technical domain knowledge likely low average technical expertise average domain knowledge advocate role support example legal counsel care worker concerned party automated decision possible oals objectives make sure best interests safeguarded throughout process help make clear going decisions made technical domain knowledge likely average technical expertise high level domain knowledge implementer role user system decision support possible oals objectives make objective fair decision sufficiently responsive particular circumstances anchored solid reasoning evidence judgement technical domain knowledge likely average technical expertise high vel domain knowledge system role provider support maintenance system use understanding artificial intelligence ethics safety possible oals objectives make sure machine learning system performing well running accordance intended design handle technical dimension information processing particular case answer technical questions system results arise technical domain knowledge likely high level technical expertise average domain knowledge delivery manager role member implementation team oversees operation responds problems rise possible oals objectives ensure quality automation supported assessment process high needs decision subject serv intended project oversee overall quality relationsh ips within implementation team members team communities serve technical domain knowledge likely average technical expertise good high level domain knowledge step define delivery relations map del ivery processes assess possible relationships defined roles significant bearing project implementation formulate descriptive account relationship eye part play delivery process predictive risk assessment example decision implementer primary relationship implementation process information dialogue wit implementer exercise unbiased judgment comprehension outcome treated highest priorities implementers prepared answer questions offer evidence clarifications justifications deter minations achievement well mutual understanding central aim implementer system operator critical operational relationship within implementation team communication levels kept high case case shared goal two parties optimise quality decisions optimising use algorithmic decision system ways accessible user conversations implementers system operators problem avoid much possible focus specialised vocabularies party domain expertise delivery manager operator implementer quality cross relationship within implementation team direct bearing overall quality delivery algorithmically supported decisions safeguarding latter require open easily accessible lines communication maintained livery managers operators implementers unforeseen implementation problems tackled multiple angles ways anticipate stem future difficulties additionally differ ent use cases may present different explanatory chall enges best addressed multidisciplinary understanding artificial intelligence ethics safety team input good communications within implementation team essential enable challenges addressed timely efficient manner start building map delivery ocess involve incorporating understanding needs roles relationships relevant actors involved implementation system wider objective providing clear informative understandable explanations algorithmically supported decisions vital recognise implementation stage project principal goal delivery process two translate statistically expressed results humanly significant reasons translate algorithmic outputs socially meaningful outcomes overlapping objectives direct bearing way build map project delivery process organise dutie implementation two components technical component involves determining effective way convey communicate users decision subjects statistical results model information processing factors figured logic rationale results translated understandable reasons subjected rational evaluation critical assessment social component involves clarifying socially meaningful content outcome given algorithmically assis ted decision translat ing model technical machinery input output variables parameters functional rationale everyday language humanly rele vant categories relationships informed formulation purpose objective intended elements design first place effects model output real human life impacts und erstandable terms specific social individual context life conveyable two components delivery process fleshed turn technical component responsible implementation general rule use results statistical analysis guide actions done properly kind analysis offers solid basis empirically derived evidence helps exercise sound well supported judgment matters informs good understanding factors work producing result particular statistical analysis algorithmic decision system means able grasp factors instance input features weigh heavily determining given algorithmically generated decision reasons may warrant rational accept ability result seen perspective interpret ability analysis factors fact thing reasons operating support conclusions understanding artificial intelligence ethics safety clearly understood factors lie behind logic result decision causes rather form evidentiary basis rational soundness goodness inferences support whether ultimat ely agree decision result analysis reasons work together comprise conclusions make claims validity called tribunal rational criticism reasons words must bear rden continuous assessment evaluation contestation element especially crucial responsible implementation systems serve surrogate cognitive function society decisions results way imm une demands rational justification thus must delivered optimally responsive demands results lgorithmic decision support systems sense serve stand acts speech representation fore bear justificatory burdens cognitive functions must establish validity conclusions operate constraint surrogates dialogical goal convince good reasons charge responsive demands rational justification essential way map delivery strategy devise best relay explain statistical results systems need start play supporting evidence reasoning however easy job interpreting results data scientific analysis often highly technical activity depart widely conventional everyday styles reasoning familiar moreover various performance metrics deployed systems confusing times seem cross depending upon metrics chosen also unavoidable dimension uncertainty must accounted expressed confidence intervals error bars may bring confusion users decision subjects may taking deliberate human approach delivery proces able find effective way convey model statistical results users decision subjects non socially meaningful language enables understand evaluate rational justifiability tho results good point departure divide map task means content delivery substance content delivered means content delivery start mapping serviceable ways presenting communicating model results consider users decision subjects perspectives primary importance guiding questions ask sketch dimension delivery process well provisional answers delivery process explaining system results aid augment user decision subject mental models ways organising filtering information get clear pictur technical meaning understanding artificial intelligence ethics safety assessment explanation best way frame statistical inferences meanings effectively integrated user cognitive space concepts beliefs answering hese questions largely depend use case type application building important start responding concentrating differing needs capabilities explainees roperly first seek input domain experts users affected stakeholders suitably scan horizons existing needs capabilities likewise take human approach exploring types explanat ion delivery methods would best suited target groups much valuable research done field human interaction study human factors work consulted mapping delivery ans gathered enough background information begin plan going line means delivery varying levels technical literacy expertise cognitive need possessed relevant stakeholder groups involve implementation project multi approach minimally require individual attention paid explanatory needs capacities implementers system operators decision subjects advocates multi approach pose different challenges different level instance ental models implementers ways conceptualising information receiving algorithmic decision system may cases largely shaped accumulation domain know filter xpertise developed long periods practice users may predisposition automation distrust aversion bias taken account formulating appropriate means explanation delivery contexts opposite may case implementers tend rely automated systems means explanation delivery must anticipate different sort mental model adjust presentation information accord ingly event need ood empirical understanding implementer decision context maintain knowledge ongoing assessment bias risk areas conveyance communication assessments enerated algorithmic decision systems attempt bolster user practical judgment ways mitigate possibility either sort bias assessments present results evidence reasons support bett capacitate objectivity implementers reasoning processes understanding artificial intelligence ethics safety story different regard cognitive life technically inclined user mental models system operators natives technical vocabulary epi stemic representations statistical results may adept model based problem tasks arise implementation less familiar identifying responding cognitive needs limitations non stakeholders incorporating ongoing communication exercises training roles delivery process may capacitate better facilitate implementers decision subjects understanding technical details assessments generated algor ithmic decision systems ongoing development activities helpfully enrich operators mental models may also inspire develop deeper responsive effective ways communicating technical yields analytics oversee finally mental models decision subjects advocates show broadest range conceptualisation capacities delivery strategy prioritise facilitation optimal explanation seline level needs disadvantaged build depth multi approach providing effective explanations delivery options presented decision subjects advocates latter suggestion entai beyond provision baseline explanation algorithmically generated result options given decision subjects advocates view detailed technical presentations sort available implementers oper ators proviso reasonable limitations placed transparency accordance need protect confidential personal organisational information prevent gaming system non stakeholders dequately prepared gain baseline know ledge kinds statistical probabilistic reasoning factored technical interpretation system output able comprehend technical terms technical components presented way enable explainees easily translate statistical inferences meanings results understandable rationally assessable terms best available media presenting chnical results engaging comprehensible ways meet challenges consider supplementing implementation platform knowledge enrichment resources provide non technical stakeholders access basi technical concepts vocabulary minimum consider building plain language glossary basic terms concepts include technical ideas covered algorithmic component given explanation explanat ion platforms digital also make user friendly possible hyperlinking technical terms used explanations plain language glossary elaborations possible explanatory demonstrations technical concepts like performance metrics formal fairness criteria confidence intervals etc provided users decision subjects engaging easy way understanding artificial intelligence ethics safety graphical visualisation techniques consistently used make tentially difficult ideas accessible moreover explanation interfaces simple learnable usable possible tested measure ease neither technical experience domain knowl edge able gain proficiency use understanding content substance technical content delivered overall interpretability system largely hinge effectiveness even technical content delivery strike balance determining best convey communicate rationale statistical results may treated appropriately decision supporting clarifying reasons clear limitations potential uncertainties statistical results explanations offer mislead implementers decision subjects easy tasks require substantial forethou ght map content clarification aspect delivery process assist non list recommendations consider map execution technical content delivery component responsible implementation project list sake specificity assume predictive risk assessment example explanation presented plain non language optimally understandable way tha results provided enable affordance better judgment part implementers optimal understanding part decision subjects implementer side primary goal explanation support user ability offer solid coherent reaso nable justifications determinations decision outcomes decision subject side primary goal explanation make maximally comprehensible rationale behind algorithmic component decision process decision subject undertake properly informed critical evaluation decision outcome whole explanation present results facts evidence sparse complete sound manner possible clear indication components explanation operating premises components operating conclusions inferential rationale connecting premises conc lusions explanation therefore make explicit rational criteria determination whether example global inferences drawn population reasoning demographic analysis locally instance infer ences drawn indication feature significance proxy model cases optimisation criteria operative algorithmic system specified made explicit connected logic rationale decision explan ation make available records activity results design development processes project yielded building link process transparency dimension project outcome transparency make result whole sufficiently interpretable understanding artificial intelligence ethics safety done simply linking including public component process log pbg framework explanation provided implementer come standa implementation disclaimer may read follows explanation specify make explicit governing performance metrics together acceptability criteria used select metrics standard benchmarks followed establishing criteria appropriate possible ller information model validation measurement including confusion matrix roc curve results external validation results made available explanation provide confirmatory information formal fairness criter specified project fairness policy statement met explanation include clear representations confidence intervals error bars certainty estimates make quantitatively explicit possible confidence range specific predictions users decision subjects fully understand reliability levels uncertainty surrounding explanation offers categorically ordered scores instance risk scores scale explanation must also explicitly indicate actual raw numerical probabilities labels predicted outcomes placed categories help delivery process avoid producing confusion abou relative magnitudes categorical groupings various scores fall information also provided relative distances risk scores specific cases risk categories placed unevenly distributed may possible example two cases fall high risk category say farther apart terms actual values risk probabilities two cases two different categories say may misleading user implementation disclaimer results intended assist making evidence judgment meant neither replace reasoned deliberations constitute sole videntiary basis judgement results also derived statistical analysis means unavoidable possibilities error uncertainty results specified performance measures confidence intervals provided results based population data refer specifically actual circumstances abilities individual subject prediction inferences draw directly therefo based statistical generalisation understanding life context concrete potential individual person impacted decision understanding artificial intelligence ethics safety explanation possible include counterfactual explanatory tool implementers affected individuals opportunity gain better contrastive understanding logic outcome alternative possibilities social component responsible implementation established first step delivery responsible implementation process aking clear rationale behind technical content algorithmic model statistical results determining best convey communicate results may appropriately treated decision supporting clarifying reasons leaves second related task content clarifica tion implicit first step must made explicit treated reflectively second beyond translating statistically expressed results humanly significant reasons make sure socially meaningful ontent clarified implementers able thoughtfully apply results real human lives impact terms specific societal individual context lives situated involve explicitly translat ing model technical machinery input output variables parameters functional rationale everyday language humanly relevant meanings categories relationships informed formulation purpose objectives intended elements design first place also involve training preparing implementers intentionally assist carrying translation particular case due regard dignity deci sion subjects supported interpretive charity reasonableness empathy context determination outcomes affect internals mechanisms output model become useably interpretable implementers able apply input features relevance specific situations attributes decision subjects able critically assess manner inference tha led conclusion able adequately weigh normative considerations prioritising public interest safeguarding individual well factored system original objectives clarified socially meaningful content model results implementer able readily apply evidentiary contribution holistic wide consideration particular circumstances decision subject time weighing circumstances greater purpose algorithmically assisted assessment important note understanding enabled clarification social context stakes algorithmically supported decision process goes hand fuller considerations moral justifiability outcome process good starting point considering integrate clarification socially meaningful content algorithmi model output map delivery process consider might think project content lifecycle understanding artificial intelligence ethics safety content lifecycle output algorithmic system begin end computation rather begins human purposes ideas initiatives lay behind conceptualisation design system creating technology shared public act ivity animated human objectives beliefs algorithmic system brought world result collective enterprise ingenuity intention action collaboration human choices values therefore punctuate esign implementation systems choices values inscribed algorithmic models inception project human choices values come play formulate goals objectives achieved algorith mic technologies come play define optimal outcome use technologies translate goals objectives target variables measurable proxies human choices values come play deci sions made sufficiency representativeness relevance appropriateness data sampled come play curate data label organise annotate choices values operate ell make decisions craft feature space select omit aggregate segregate attributes determinations relevant reasonable desirable undesirable factor kinds inputs going inclu processing going group separate moreover data points imbued residua human choices values carry forward historical patterns social cultural activity may contain configu rations discrimination inequality marginalisation must thoughtfully reflectively considered implementers incorporate analytics reasoned determinations whereas human choices values translated algorithmic systems build responsible implementation systems requires translated rationale logic behind algorithmic model output properly understood affects real existence decision subject transform variables parameters analytical structures back human currency values choices norms shaped construction purpose intended design optimisa tion logic start virtue algorithmically supported outcome afford stakeholders degree deliberation dialogue assessment mutual understanding necessary make fully compreh ensible justifiable likewise virtue implementation process secure accountability give due regard sum values understanding artificial intelligence ethics safety content lifecycle algorithmic systems therefore three phases translation human purposes values choices design process digital processing proxies purposes values choices statistical frame translation purposes values choices clarifying socially meaningful content result affects life decision subject implementation process visualisation three phases ontent lifecycle translation ule beneficial result framing implementation process terms content lifecycle gives clear context measure identify explanatory needs given application think measurement translation rule states translated algorithmic system regard human choices societal values determine content purpose directly proportional hat terms explanatory needs clarification justification must translated translation rule organically makes two distinctions great bearing delivery process responsible implementation first divides question needs explaining two parts issues socially meaningful content nee clarification explanatory need comes transl ation model categories meanings relations originate social practices beliefs intentions issues normative rightness need justi fication explanatory need comes translation model choices considerations bearing ethical permissibility discriminatory non public trustworthiness two parts line called interpretable justifiable respectively also identified tasks delivering transparent secondly translation rule divides two dimensions translation translation translation aspects intention intention translating understanding artificial intelligence ethics safety intention involves active awareness human purposes objectives inte ntions factor construction systems translating hand directly intention put differently intentional dimension implementation system user specific context direct consequences subject affected outcome human beings intention intention united intelligent action precisely unity enables people reciprocally hold accountable consequences say contrast artificial intelligence systems fulfil surrogate cognitive functions society neither intentional accountable design application divided systems intention intention must remain punctuation points human involvement sponsibility manifest either side vacant mechanisms data processing translation important enabling implementer capacity intentionally translate social normative content model results critical element responsible delivery project might helpful think concretely translation rule considering action let compare two hypothetical examples use case ear cancer detection system radiomics machine learning application uses high throughput computing identify features pathology undetectable trained radiological eye use case predictive risk assessment appl ication supports decision making child social care radiomics case translating dimension involves minimal social content clinical goal inscribed model objective lesion detection features relevanc largely voxels extracted pet scanner images however normative aspect translating case significant ethical considerations looking patient wellbeing clinical safety paramount wider justice oncerns improving healthcare health equity factor well explanatory needs receiving clinical decision support clinical decision subject thus lean less heavily dimension clarification socially meaningful content normative dimension justifying safety system priority patient wellbeing issues improved delivery equitable access technical content ecision support may crucial issues surrounding reproducibility results robustness system may fact great concern assessment validity outcome translating component imple mentation remains directly proportional minimal social content substantial ethical concerns objectives translated thus inform explanatory justificatory needs result general explanat ory demands child social care risk assessment use case entirely different social content translating dimension intricate multi extensive chosen target variable may child safety prevention severe mistreatment measurable proxy home removal children within certain timeframe selected features deemed relevant may include age understanding artificial intelligence ethics safety children public health records previous referrals family history violent crime welfare records juvenile criminal records demographic information mental health records complex socioeconomic cultural formations may additionally influence representativeness quality dataset well substance data normative aspect translating also subtle complicated ethical considerations prot ecting welfare children risk combined concerns parents guardians treated fairly without discrimination objectives providing evidence decision support also driven hopes accurate results ned determinations preserve integrity sanctity familial relations safe appropriate goals purposes may play well making overburdened system service provision efficient accelerating decision without harming quality decisions case predictive risk assessment translating burdens frontline social worker immense terms clarifying content terms mor justification example analytical results yielding high risk score based relative feature importance demographic information welfare records mental health records criminal history implementer would scrutinis particular decision subject situation socially meaningful content factors could clarified terms living context relevant relationships behavioural patterns stakeholders directly affected cou features relevance thoroughly deliberatively assessed effective interpretability model result would case heavily depend implementer ability apply domain order reconstruct meaningful social formations intentions relationships constituted concrete form life predictive risk modelling applies implementer well decision would involve careful weighing socially clarified content gainst wider predictive patterns data distribution yielded model results may otherwise gone unnoticed weighing process would turn informed normative need translate mor ally implicating choices concerns objectives influenced informed predictive risk assessment model development first place interpretive burden frontline social worker would immense first implemen ter would deliberate critically informed awareness legacies discrimination inequity tend feed forward kinds evidentiary sources drawn upon analytics active reflexivity crucial retaining punctuating role human involvement responsibility sensitive high environments importantly frontline social worker would evaluate real impact ethical objectives point delivery would results analytics aligned ethical concerns purposes fostered construction model implementer would reflectively align potentially diverging ethical point view tho results objectives normative understanding artificial intelligence ethics safety triangulation original intention implementer intention content clarification system results fact crucial safeguard delive justifiable enables reanimation moral involvement responsibility critical juncture content lifecycle step build ethical implementation platform train ethical implementation continuous challenges translation content clarification normative explanation inform set implement ation training achieve optimal outcome transparency addition necessary training prevent implementation biases users system discussed shoul prepare train implementers stewards interpretable justifiable entails able rationally evaluate crit ically assess logic rationale behind outputs systems convey communicate algorithmically assisted decisions individuals affected plain language includes xplain ing everyday accessi ble way decision model performed way specific context result factored final outcome implementation apply conclusions reached model focused cons ideration particular social circumstances life context decision subject affected parties treat inferences drawn results model computation evidentiary contributions broader rounded coherent understanding individual situation decision subject affected parties weigh interpret ive understanding gained integrating model insights rounded picture life context decision subject greater purpose societal objective algorithmically assisted assessment justify ethical permissib ility discriminatory non blic trustworthiness system outcome processes behind design use make implementation platform relevant part capstone sustainability track projec important element gauging impacts technology individuals communities touches access frontlines potentially transformative long effects implementation platform assist gaining access medium application communication enable sustainably achieve objectives goals set project responsible implementation also sounding board well site feedback cooperative sense real effects system use understanding artificial intelligence ethics safety implementation platform dialogically collaboratively connected stakeholders effects bound commu nities serves part shared project advance immediate long wellbeing provide model sheet impleme nters establish protocols implementation reporting part roll project prepare summary sheet implementers includes summation information system technical specifications relevant details indicated section substance technical content delivered include relevant information performance metrics formal fairness criteria validation implementation disclaimer links summaries relevant information process logs framework links summary information stakeholder impact assessment also set protocols implementation reporting proportional potential impacts risks system use foster outcome und erstanding dialogue perhaps single important aspect building platform ethical implementation awareness realisation interpretable justifiable dialogical collaborative effort types explanation mediated language every explanatory effort participatory enterprise understanding reached acts communication interpretability justifiability systems depend shared human capacity give ask reasons ends reaching mutual understanding implementers decision subjects respect first foremost participants explanatory dialogue success exchange hinge eciprocal readiness take perspective willingness enlarge respective mental models accordance new communicatively achieved insights understandings reasons implementation platform encourage open mutually respectful sincere well dialogue reasons affected voices must heard considered demands explanation arise manners response expression remain clear straightforward optimally acce ssible deliberations inclusive unfettered impartial tend generate new ideas insights well better inferentially sound conclusions approaching interpretability justifiability project manner advance responsible implementation likely encourage improvements design delivery performance understanding artificial intelligence ethics safety conclusion mathematician maida vale named alan turing sat pencil paper using image linear tape divided evenly squares list symbols basic rules drew sketch show step process human carry calculation simplest oper ation arithmetic complex nonlinear differential equation turing remarkable invention known simply turing machine solved perplexing mathematical question effective calculation question define algorithm turing show means compute number showing human created process idea behind modern general purpose computer turing astonishingly humble innovation ushered digita age eight decades later step forward together open horizo rapidly evolving digital future difficult image started thought experiment small room kings college cambridge become humanly defining force live increasingly dynamic integrated computational reality connected devices containing countless sensors actuators intermingle omnipresent algorithmic systems cloud computing platforms rise internet things edge computing expanding smart automation infrastructure industry workplace systems progressively coming compri cyber frame fabric networke society better worse rtificial intelligence simply becoming general purpose technology like steam power electrici essentially becoming gatekeeper technology uniquely holds potential exponential advancement human wellbeing possibilities emergence significant risks society future yet humankind must ultimately choose direction key turn choice leaves difficult questions lap moral agency present shape data society tomorro take values motivations currently driving gath ering energies technological advancement artificial intelligence come influence future society ways life transform identities warm subjects guide und erstanding ethics safety offered one way move forward answering questions significa sense attempted prepare take turing lead see design implementation algorithmic models eminently human activity activity guided purposes values activity involved development deployment system morally socially responsible starting point human action intention crucial underpinning responsible innovation prioritis considerations ethical purposes value behind trajectories technolog ical advancement vested societal stakeholders able take reins innovatio steer course algorithmic creations accordance shared sion better human future look like understanding artificial intelligence ethics safety acknowledgments writing guide would simply possible without hard work dedication insight many interlocutors within alan turing institute meaningful partnerships turing public olicy programme formed stakeholders across government take latter group first office artificial intelligence oai government digital service gds vision commitment responsible innovation enabling condition development work particular patience incisiveness oai sebastien krier jacob beswick gds bethan charnley instrum ental bringing project completion also incredibly grateful impact interactions ministry justice moj data science hub developing framing guide input moj megan whewell philip howard jonathan roberts olivia lewis ross wyatt data science innovation board left significant mark research last least ongoing partnership information commissioner office project particular ico colleagues carl wiper alex hubbard key contributor guide focus fairness transparency accountability project expl aims provide practical guidance organisations explaining supp orted decisions subjects decisions taking inspiration work project expl input gathered course two citizens juries held manchester coventry current guide emphasises importance communication attempts build vision human context implementation ethics fellow within public policy programme turing benefited tremendously surrounded immensely talented group thinkers doers whose commitment making connected world better place interdisciplinary research advisory intervention inspiration every day programme director helen margetts deputy director cosmina dor obantu crucial inimitable supports oject inception small brilliant team researchers josh cowls christina hitrova involvement turing data ethics group also tremend ous source insight inspiration project given ambitious deadlines accompanied guide final stages production heroic efforts review contents whole parts made florian ostmann michael veale david watson mark briers evelina gabsova alexander harris anna fitzmaurice perceptive feedback notwithstanding unclarities appear understanding artificial intelligence ethics safety reflect faults author alone understanding artificial intelligence ethics safety bibliography readings included bibliography organised main themes covered guide please use starting point exploration comp lex topics many thanks tireless efforts jess morley corianna moffatt without bibliography could compiled sum values general fairness data fairness design fairness outcome fairness implementation fairness accountability stakeholder impact assessment safety accuracy reliability security robustness transparency process governance interpretable responsible delivery human implementation protocols practices individual societal impacts machine learning algorithm systems sum values access toronto declaration protecting rights equality non machine learning systems retrieved adamson havens chatila designing value future ethical autonomous intelligent systems proceedings ieee american medical association ama code medical ethics retrieved american psychological association ethical principles psychologists code conduc retrieved article governance teeth human rights strengthen fat ethics initiatives artificial intelligence retrieved human beauchamp childress principles biomedical ethics edition oxford university press usa understanding artificial intelligence ethics safety cath governing artificial intelligence ethical legal technical opportunities challenges philosophical transactions royal society mathematical physical engineering sciences cowls floridi prolegomena white paper ethical framework good society european commission ethics guidelines trustworthy retrieved european group ethics science new technologies artificial intelligence robotics autonomous systems retrieved felten preparing future artificial intelligence washington white house floridi cowls beltrametti chatila chazerand dignum schafer ethical framework good society opportunities risks principles recommendations minds machines retrieved floridi taddeo data ethics philosophical transactions royal society mathematical physical engineering sciences future life institute asilomar principles retrieved global future council human rights prevent discriminatory outcomes machine learning world economic forum retrieved house lord select committee artificial intelligence ready willing able retrieved ieee ieee global initiative ethics autonomous intelligent systems retrieved latonero governing artificial intelligen upholding human rights dignity data society retrieved national commission protection human subjects biomedical behavioral research belmont report ethical principles guidelines protection human subjects research washington united states government printing office nuffield council bioethics collection linking use data biomedical research health care ethical issues retrieved nuffield council bioethics artificial intelligen healthcare research retrieved pielemeier advantages limitations applying international human rights framework artificial intelligence data society points retrieved advantages ramesh checklist protect human rights artificial research nature raso hilligoss krishnamurthy bavitz kim artificial intelligence human rights opportunities risks berkman klein nter research publication retrieved reform thinking nhs retrieved understanding artificial intelligence ethics safety royal society machine learning power promise computers learn example retrieved taddeo floridi force good science statistics authority code practice statistics ensuring public confidence statistics retrieved unesco report comest robotics ethics retrieved universit montral montreal declaration responsible retrieved department homeland security menlo report ethical principles guiding information communication technology research retrie ved national science technology council preparing future artificial intelligence retrieved villani meaningful artificial intelligence towards french european strategy humanity retrieved yuste goering carmena carter fins kellmeyer four thical priorities neurotechnologies nature news retrieved general fairness binns fairness machine learning lessons political philosophy retrieved binns van kleek veale lyngs zhao shadbolt reducing human percentage perceptions justice algorithmic decisions proceedings chi conference human factors computing systems acm retrieved holstein vaughan daum iii dudk wallach improving fairness machine learning systems industry practitioners need lepri oliver letouz pentland vinck fair transparent accountable algorithmic decision processes premise proposed solutions open challenges philosophy technology mittelstadt allo taddeo wachter floridi ethics algorithms mapping debate big data society selbst boyd friedler venkatasubramanian vertesi fairness abstraction sociotechnical systems proceedings conference fairness accountability transparency acm retrieved suresh guttag framework understanding unintended consequences machine learning retrieved veale van kleek binns fairness accountability design needs algorithmic support high public sector decision proceedings conference human factors computing systems acm retrieved understanding artificial intelligence ethics safety data fairness abadi agrawal ailamaki balazinska bernstein carey gehrke beckman report database research communications acm retrieved abiteboul stoyanovich weikum data responsibly acm sigmod blog retrieved alper becker satagopam grous lebioda jarosz schneider provenance enabled stewardship human data gdpr era ambacher ashley berry brooks dale flecker trustworthy repositories audit certification criteria checklist center research libraries retrieved antignac sands schneider data minimisation language approach long version retrieved bell hours lungley cunningham corti scaling digital data services social sciences data service retrieved case bower niss sun vargo debiasing representations removing unwanted variation due protected attributes retrieved custers data dilemmas information society introduction overview discrimination privacy information society springer berlin heidelberg retrieved custers schermer responsibly innovating data mining profiling tools new approach discrimination sensitive privacy sensitive attributes responsible innovation springer dordrecht retrieved dai yoshigoe parsley improving data quality deep learning statistical models davidson freire provenance scientific workflows challenges opportunities proceedings acm sigmod internati onal conference management data acm retrieved european commission expert group fair data turning fair reality european union retrieved faundeen developing criteria establish trusted digital repositories data science journal retrieved joshi kaloskampis nolan generative adversarial networks gans synthetic dataset generation binary classes data science campus retrieved dataset heureux grolinger elyamany capretz machine learning big data challenges approaches ieee access retrieved ruggieri pedreschi turini dcube discrimination discovery databases proceedings acm sigmod international conference management data acm retrieved sabou bontcheva derczynski scharl corpus annotation crowdsourcing towards best practice guidelines lrec stoyanovich howe abiteboul miklau sahuguet weikum fides towards platform responsible data science proceedings international confer ence scientific statistical database management acm retrieved understanding artificial intelligence ethics safety swingler perils ignoring data suitability sui tability data used train neural networks deserves attention presented ncta proceedings international conference neural computation theory applications retrieved varshney alemzadeh safety machine learning cyber systems decision sciences data products big data retrieved vidgen nguyen tromble hale margetts harris challenges frontiers abusive content detection forthcoming acl zheng wang ordieres comparison data preprocessing approaches applying deep learning human activity recognition context industry sensors retrieved design fairness barocas selbst big data disparate impact rev retrieved calders verwer three naive bayes approaches discrimination classification data mining knowledge discovery calmon wei vinzamuri ramamurthy varshney optimized pre discrimination prevention advances neural information processing systems retrieved prevention lagatta conscientious classification data scientist guide discrimin ation classification big data hajian bonchi castillo algorithmic bias discrimination discovery fairness data mining proceedings acm sigkdd international conference knowledge discovery data mining acm retrieved kamiran calders data preprocessing techniques classification without discrimination knowledge information systems retrieved lehr ohm playing data legal scholars learn machine learning ucdl rev retrieved passi barocas problem formulation fairness proceedings conference fairness accountability transparency acm retrieved singh san preprocessing technique discrimination prevention data mining ijes retrieved singhal jena study weka tool data preprocessing classification clustering international journal innovative technology explori engineering ijitee retrieved van der aalst bichler heinzl responsible data science springer fachmedien wiesbaden outcome fairness understanding artificial intelligence ethics safety agarwal beygelzimer dudk langford wallach reductions approach fair classification retrieved albarghouthi vinitsky fairness programming proceedings conference fairness accountability transparency acm retrieved chiappa gillam path counterfactual fairness retrieved chouldechova fair prediction disparate impact study bias recidivism prediction instruments retrieved corbett pierson feller goel huq algorithmic decision making cost fairness dwork hardt pitassi reingold zemel fairness awareness proceedings innovations theoretical computer science conference retrieved feldman friedler moeller scheidegger venkatasubramanian certifying removing disparate impact proceedings acm sigkdd international conference knowledge discovery data mining acm retrieved friedler scheidegger venkatasubramanian choudhary hamilton roth comparative study fairness interventions machine learning proceedings conference fairness accountability transparency acm retrieved grgi zafar gummadi weller case proc ess fairness learning feature selection fair decision making nips symposium machine learning law vol retrieved zafar gummadi weller fairness diversity randomness algorithmic decision making retrieved zafar gummadi weller beyond distributive fairness algorithmic decision making feature selection procedurally fair learning thirty aaai conference artificial intelligence retrieved hardt price srebro equality opportunity supervised learning advances neural information processing systems retrieved johansson shalit sontag learning representations counterfactual inference retrieved kamishima akaho asoh sakuma fairness classifier prejudice remover regularizer flach bie cristianini eds machine learning knowledge discovery databases vol kleinberg mullainathan raghavan inherent trade fair determination risk scores retrieved kusner loftus russell silva counterfactual fairness advances neural information processing systems retrieved russell kusner loftus silva worlds collide integrating different counterfactual assumptio fairness guyon luxburg bengio wallach fergus vishwanathan garnett eds advances neural information processing systems retrieved assumptions understanding artificial intelligence ethics safety ustun spangher liu actionable recou rse linear classification proceedings conference fairness accountability transparency acm retrieved verma rubin fairness definitions explained international workshop software fairness fairware ieee retrieved wachter mittelstadt russell counterfactual explanations without opening black box automated decisions gdpr retrieved wexler tool code probing machine google blog retrieved zafar valera rodriguez gummadi fairness constraints mechanisms fair classification retrieved zafar valera rodriguez gummadi fairness beyond disparate treatment disparate impact learning classification without disparate mistreatment proceedings international conference world wide web international world wide web conferences steering committee retrieved zemel swersky pitassi dwork learning fair representations international conference machine learning retrieved zhang bareinboim fairness decision causal explanation formula presented aaai conference artificial intelligence aaai retrieved liobait measuring discrimination algorithmic decision making data mining knowledge discovery retrieved implementation fairness alexander blinder zak trust algorithm performance cognition neurophysiology computers human behavior bahner hper manzey misuse automated decision aids complacency automation bias impact training experience international journal human studies base fallacy probability judgments acta psychologica bigman gray people averse machines making moral decisions cognition vol chen procci boyce wright garcia barnes situation awareness agent transparency arl aberdeen proving ground army research laboratory retrieved crocoll coury status recommendation selecting type information decision aiding proceedings human factors society annual meeting vol los angeles sage publications dietvorst simmons massey algorithm aversion people erroneously avoid algorithms seeing err journal experimental psychology general retrieved con domeinski wagner schoebel manzey human redundancy automation monitoring effects social loafing social compensation proceedings human factors ergonomics understanding artificial intelligence ethics safety society annual meeting santa monica human factors ergonomics society dzindolet pierce beck dawe perceived utility human automated aids visual detection task human factors gigerenzer todd simple heuristics make smart london england oxford university press gilovich thom know fallibility human reason everyday life new york free press kahneman evaluation moments past future choices values frames retrieved kahneman thinking fast slow london england allen lane kahneman slovic tversky judgement uncertainty heuristics biases new york cambridge university press kahneman tversky psychology prediction psychological review retrieved karau williams social meta review theoretical integration journal personality social psychology retrieved klauer musch naumer belief bias syllogistic reasoning psychological review lee see trust automation technology designing appropriate reliance human factors lee understanding perception algorithmic decisions fairness trust emotion response algorithmic management big data society logg minson moore algorithm appreciation people prefer algorithmic human judgment organizational behavior human decision processes lord ross lepper biased assimilation attitude polar ization effects prior theories subsequently considered evidence journal personality social psychology mcguirl sarter supporting trust calibration effective use decision aids presenting dynamic system confidence information human factors mercado rupp chen barnes barber procci intelligent agent trans parency human teaming multi management human factors moray monitoring complacency scepticism eutactic behaviour international journal industrial ergonomics moray inagaki attention complacency theoretical issues ergonomics science mosier skitka human decision makers automated decision aids made parasuraman mouloua eds automation human performance theory application mahwah erlbaum mosier skitka heers burdick automation bias decision performance hightech cockpits international journal avi ation psychology nkal goodwin thomson gnl pollock relative influence advice human experts statistical methods forecast adjustments journal behavioral decision making understanding artificial intelligence ethics safety packin algorithmic decision death second opinions new york university journal legislation public policy forthcoming retrieved parasuraman manzey complacency bias human use automation attentional integration human factors parasuraman molloy singh performance consequences automation international journal aviation psychology rovira mcgarry parasuraman effects imperfect automation decision making simulated command control task human factors sacha senaratne kwon ellis keim role uncertainty awareness trust visual analytics ieee transaction visualization computer graphics sarter schroeder supporting decision making action selection time pressure uncertainty case icing human factors schaefer chen szalma hancock meta factors influencing development trust automation implications understanding autonomy future systems human factors shafir choosing versus rejecting options better worse others memory cognition taber lodge motivated skepticism evaluation political beliefs american journal political science tversky kahneman judgment uncertainty heuristics biases science retrieved tversky kahneman framing decisions psychology choice scienc retrieved accountability institute algorithmic accountability policy toolkit retrieved binns algorithmic accountability public reason philosophy technology retrieved cavoukian taylor abrams privacy design essential organiz ational accountability strong business practices identity information society center democracy technology digita decisions retrieved diakopoulos algorithmic accountability journalistic investigation computational power structures digital journalism diakopoulos friedler arenas barocas hay howe lson principles accountable algorithms social impact statement algorithms retrieved donovan caplan hanson matthews algorithmic accountability primer data society tech algorithm briefing algorithms perpetuate racial bias inequality retrieved understanding artificial intelligence ethics safety ico big data artificial intelligence machine learning data protection retrieved janssen kuk challenges limits big data algorithms technocratic governance government information quarterly kroll huey barocas felten reidenberg robinson accountable algorithms rev ret rieved handle malgieri comand right legibility automated decision exists general data protection regulation international data privacy law retrieved sullivan nevejans allen blyth leonard pag allo ashrafian legal regulatory ethical frameworks development standards artificial intelligence autonomous robotic surgery international journal medical robotics computer assisted surgery reed regulate artificial intelligence philosophical transactions royal society mathematical physical engineering sciences retrieved stahl wright ethics privacy big data implementing responsible research innovation ieee security privacy veale binns edwards algorithms remembe model inversion attacks data protection law philosophical transactions royal society mathematical physical engineering sciences wachter mittelstadt floridi transparent explainable accountable robotics science robotics wachter mittelstadt floridi right explanation automated decision exist general data protection regulation international data privacy law zook barocas boyd danah crawford keller gangadharan pasquale ten simple rules responsible big data research plos comput ational biology stakeholder impact assessment institute algorithmic impact assessments toward accountable automation public agencies retrieved toward diakopoulos friedler arenas barocas hay howe jagadish unsworth sahuguet venkatasubramanian wilson zevenbergen prin ciples accountable algorithms social impact statement algorithms fairness accountability transparency machine learning retrieved karlin canadian algorithmic impact assessment retrieved karlin corriveau government canada algorithmic impact assessment take two retrieved impact reisman schultz crawford whittaker algorithmic impact assessments practical framework public agency accountability institute retrieved understanding artificial intelligence ethics safety vallor ethical toolkit ractice retrieved hong kong information accountability foundation ethical accountability framework hong kong china report prepared office privacy commission personal data retrieved information accountability foundation data stewardship accountability data impact assessments oversight models detailed support ethical accountability framework retrieved canada treasury board canada secretariat algorithmic impact assessment retrieved safety accuracy reliability ecurity obustness amodei olah steinhardt christiano schulman man concrete problems safety retrieved auernhammer kolagari zoppelt attacks machine learning lurking danger accountability powerpoint slides retrieved demar bosni detecting concept drift data streams using model explanation expert systems applications google perspectives issues governance retrieved gpfert hammer wersing mitigating concept drift via rejection international conference artificial neural networks springer cham irving askell safety needs social scientists distill kohli dvijotham uesato gowal towards robust verified specification testing robust training formal verification deepmind blog retrieved kolter madry materials tutorial adversarial robustness theory practice retrieved marcus deep learning critical appraisal retrieved muoz biggio demontis paudice wongrassamee lupu roli november towards poisoning deep learning algorithms back optimization proceedings acm workshop artificial intelligence security acm retrieved nicolae sinn tran rawat wistuba zantedeschi edwards adversarial robustness toolbox retrieved understanding artificial intelligence ethics safety ortega maini building safe artificial intelligence speci fication robustness assurance deepmind safety research blog medium retrieved ranjan sankaranarayanan castillo chellappa improving network robustness adversarial attacks compact convolution retrieved ratasich khalid geissler grosu shafique bartocci roadmap toward resilient internet things cyber systems ieee access retrieved salay czarnecki using machine learning safely automotive oftware assessment adaption software process requirements iso retrieved shi erpek sagduyu ectrum data poisoning adversarial deep learning milcom ieee military communications conference milcom ieee retrieved song jin huang multi adversarial perturbations ieee international conference data mining icdm ieee retrieved warde goodfellow adversarial perturbations deep neural networks hazan papandreou tarlow eds perturbations optimization statistics cambridge mit press webb lee goethals petitjean analyzing concept drift shift sample data data mining knowledge discovery retrieved zantedeschi nicolae rawat efficient defenses adversarial attacks proceedings acm workshop artificial intelligence security acm retrieved zhao liu pan data poisoning attacks multi relationship learning thirty aaai conference artificial intelligence retrieved zhang sheng alhazmi adversarial attacks deep learning models natural language processing survey transparency acm public policy council statement algorithmic transparency accountability retrieved ananny crawfo seeing without knowing limitations transparency ideal application algorithmic accountability new media society retrieved antunes balby figueiredo lourenco meira santos fairness transparency machine learning trustworthy cloud services annual international conference dependable systems networks workshops dsn burrell machine thinks understanding opacity machine learning algorithms big data society citron technological due process washington university law review retrieved understanding artificial intelligence ethics safety citron pasquale scored society due process automated predictions retrieved crawford schultz big data due process toward framework redress predictive privacy harms bcl rev retrieved edwards veale slave algorithm right exp lanation probably remedy looking duke tech rev retrieved kemper kolkman transparent algorithmic accountability without critical audience information communication society retrieved turilli floridi ethics information transparency ethics information technolog weller challenges transparency arxiv preprint retrieved process governance andrews benbouzid brice bygrave demortain griffiths yeung algorithmic regulation london sch ool economics political science retrieved arnold bellamy hind houde mehta mojsilovic nair ramamurthy reimer olteanu tsay varshney piorkowski factsheets increasing trust services supplier declarations conformity retrieved fro bender friedman data statements natural language processing toward mitigating system bias enabling better science transactions associ ation computational linguistics retrieved calo artificial intelligence policy primer roadmap ucdl rev retrieved agostino durante introduction governance algorithms philosophy technology gebru morgenstern vecchione vaughan wallach daum iii crawford datasheets datasets retr ieved holland hosny newman joseph chmielinski dataset nutrition label framework drive higher data quality standards retrieved mitchell zaldivar barnes vasserman hutchinson gebru model cards model reporting proceeding conference fairness accountability transparency acm retrieved moons altman reitsma ioannidis macaskill steyerberg collins transparent reporting multivariable prediction model individual prognosis diagnosis tripod explanation elaborat ion annals internal medicine retrieved morley floridi kinsey elhalal overview ethics tools methods research translate principles practices retrieved understanding artificial intelligence ethics safety reisman schultz crawford whittaker algorithmic impact assessments practical framework public agency accountability retrieved saurwein latzer governance algorithms options limitations info retrieved tutt fda algorithms admin rev wachter mittelstadt right reasonable inferences data protection law age big data columbia business law review retrieved interpretable adadi berrada peeking inside black survey explainable artificial intelligence xai ieee access retrieved angelino larus alabi seltzer rudin learning certifiably optimal rule lists categorical journal machine learning research retrieved bach binder montavon klauschen ller samek pixel explanations non classifier decisions layer relevance propagation plos one bathaee artificial intelligence black box failure intent causation harvard journal law technology retr ieved bibal frnay interpretability machine learning models representations introduction retrieved bracamonte challenges transparent trustworthy machine learning power point kddi research retrieved burrell machine thinks understanding opacity machine learning algorithms big data society card black box metaphor machine learning towards data science retrieved caruana kangarloo dionisio sinha johnson case explanation non case learning methods proceedings amia symposium retrieved chen tao barnett rudin looks like deep learning interpretable image recognition retrieved doshi kim towards rigorous science interpretable machine learning retrieved doshi kortz budish bavitz gershman wood accountability law role explanation retrieved understanding artificial intelligence ethics safety dosilovic brcic hlupic explainable artificial intelligence survey international convention information com munication technology electronics microelectronics mipro eisenstadt althoff preliminary survey explanation facilities design support approaches tools lwda presented lwda feldmann measuring machine learning model interpretability retrieved fong vedaldi interpretable explanations black boxes meaningful perturbation proceedings ieee international conference computer vision retrieved gilpin bau yuan bajwa specter kagal explaining explanations approach evaluating interpretability machine retrieved guido tti monreale ruggieri turini giannotti pedreschi survey methods explaining black box models acm computing surveys csur retrieved kleinberg lakkaraju leskovec ludwig mullainathan human decisions machine predictions quarterly journal economi kroll fallacy inscrutability philosophical transactions royal society mathematical physical engineering sciences lakkaraju bach leskovec interpretable decision sets joint framework description prediction proceedings acm sigkdd international conference knowledge discovery data mining acm retrieved lakkaraju kleinberg leskovec ludwig mullainathan selective labels problem evaluating algorithmic predictions presence unobservables proceedings acm sigkdd international conference knowledge discovery data mining kdd lepri oliver letouz pentland vinck fair transparent accountable algorithmic decisio processes philosophy technology liu chen rudin deep learning case reasoning prototypes neural network explains predictions thirty aaai conference artificial intelligence retrieved lipton mythos model interpretability retrieved lipton steinhardt troubling trends machine learning scholarship retrieved lou caruana gehrke hooker accurate inte lligible models pairwise interactions proceedings acm sigkdd international conference knowledge discovery data mining kdd lundberg lee unified approach interpreting model predictions retrieved mittelstadt russell wachter explaining explanations proceedings conference fairness accountability transparency acm retrieved understanding artificial intelligence ethics safety molnar interpretable machine learning guide making black box models explainable leanpub retrieved murdoch singh kumbier abbasi interpretable machine learning definitions methods applications retrieved olhede wolfe growing ubiquity algorithms society implications impacts innovations philosophical transactions royal society mathematical physical engineering sciences park hendricks akata schiele darrell rohrbach attentive xplanations justifying decisions pointing evidence retrieved pedreschi giannotti guidotti monreale pappalardo ruggieri turini open black box data explanation black box decision systems retrieved pedreschi iannotti guidotti monreale ruggieri turini meaningful explanations black box decision systems aaai press poursabzi goldstein hofman vaughan wallach manipulating measuring model interpretability retrieved ribeiro singh guestrin model interpretability machine learning retrieved ribeiro singh guestrin trust explaining predictions classifier proceedings acm sigkdd international conference knowledge discovery data mining acm retrieved ribeiro singh guestrin anchors high model explanations thirty second aaai conference artificial intelligence retrieved rudin please stop explaining black box models high stakes decisions retrieved rudin ustun optimized scoring systems toward trust machine learning healthcare criminal justice interfaces shmueli explain predict statistical science retrieved shaywitz ask physicians drug developers want know forbes retrieved shrikumar greenside kundaje learning important features propagating activation differences retrieved simonite experts want end black box algorithms government wired business retrieved simonyan vedaldi zisserman deep inside convolutional networks visualising image classification models saliency maps retrieved sokol flach glass explaining decisions counterfactual statements conversation virtual assistant proceedings twenty international joint conference artificial intelligence ustun rudin supersparse linear integer models optimized medical scoring systems machine learning retrieved zhang zhu visual interpretability deep learning survey frontiers information technology electronic engineering understanding artificial intelligence ethics safety responsible delivery human implementation protocols practices abdul vermeulen wang lim kankanhalli trends trajectories explainable accountable intelligible systems hci research agen proceedings chi conference human factors computing systems acm retrieved antaki leudar explaining conversation towards argument model european journal social psychology arioua croitoru formalizing exp lanatory dialogues international conference scalable uncertainty management springer cham bex walton combining explanation argumentation dialogue argument computation retrieved biran cotton explanation justification machine learning survey ijcai workshop explainable xai vol retrieved ehsan tambwekar chan harrison riedl automated rationale generation technique explainable effects human perceptions retrieved ginet defense non account reasons explanations journal ethics goebel chander lzinger lecue akata stumpf holzinger explainable new international cross conference machine learning knowledge extraction springer cham habermas remarks discourse ethics justification application remarks discourse ethics cambridge polity press habermas rightness versus truth sense normative validity moral judgments norms truth justification cambridge polity press hoffman mueller klein explaining explanation part empirical foundations ieee intelligent systems retrieved madumal miller sonenberg vetere grounded interaction protocol explainable artificial intelligence retrieved mccarthy operation called verstehen towards redefin ition problem psa springer dordrecht miller explanation artificial intelligence insights soc ial sciences artificial intelligence rapanta walton use argument maps assessment tool higher education international journal educational research springer whittaker progressive disclosure designing effective transparency retrieved taylor interpretation sciences man explorations phenomenology springer dordrecht tomsett braines harborne preece chakraborty interpretable role based model analyzing interpretable machine learning systems retrieved understanding artificial intelligence ethics safety tsai brusilovsky designing explanation interfaces transparency beyond joint proceedings acm iui workshops retrieved iuiatec von wright explanation understanding ithaca cornell university press walton new dialectical theory explanation philosophical explorations walton dialectical explanation argumentation methods artificial intelligence law walton dialogical models explanation exact retrieved walton dialogue system specification explanation synthese walton artificial intelligence tools argument evaluation introduction argumentation weld bansal challenge crafting intelligible intelligence retrieved walton toniolo norman speech acts burden proof computational models deliberation dialogue proceedings first european conference argumentation mohammed lewinski london college publications vol retrieved wendt constitution causation internatio nal relations review international studies winikoff debugging agent programs questions proceedings conference autonomous agents multiagent systems international foundation autonomous agents multiagent systems retrieved zhu liapis risi bidarra youngblood explainable designers human centered perspective mixed ieee conference computational intelligence games cig ieee retrieved individual societal impacts machine learning algorithmic systems amoore cloud geographies computing data sovereignty progress human geography amoore doubtful algorithms machine learning truths partial accounts theory culture society retrieved amoore raley securing algorithms knowledge decision sovereignty security dialogue ananny toward ethics algorithms convening observation probability timeliness science technology human values anderson preemption precaution preparedness anticipatory action future geographies progress human geography anderson security future anticipating event terror geoforum anderson technologies vision war data images mit press understanding artificial intelligence ethics safety arnoldi computer algorithms market manipulation institutionalization high frequency trading theory culture society beer algorithms shaping tastes manipulating circulations popular culture popular culture new media palgrave macmillan london beer social power algorithms information communication society bod helberger irion zuiderveen borgesius moller van velde vreese tackling algorithmic control crisis technical legal ethical challenges research algorithmic agents yale tech retrieved bogost cathedral computation atlantic retrieved bolin andersson schwarz heuristics algorithm big data user interpretation institutional translation big data society bolukbasi chang zou saligrama kalai man computer programmer woman homemaker debiasing word embeddings nips retrieved man browne dark matters surveillance blackness duke university press bucher algorithmic imaginary exploring ordinary affects facebook algorithms information communication society caliskan bryson narayanan semantics derived automatically language corpora contain human biases science retrieved cheney new algorithmic identity soft biopolitics modulation control theory culture society cinnamon social injustice surveillance capitalism surveillance society crandall precision guided seeing ctheory retrieved crandall geospatialization calculative operations tracking sensing megacities theory culture society crawford anxieties big data new inquiry retrieved crawford calo blind spot research nature news retrieved eckhouse lum conti ciccolini layers bias unified approach understanding problems risk assessment criminal justice behavior retrieved eslami rickman vaccaro aleyasen vuong karahalios sandvig always assumed really close reasoning invisible algorithms news feeds proceedings annual acm conference human factors computing systems acm retrieved eubanks automating inequality high tools profile police punish poor martin press ferguson policing predictive policing washington university law review retrieved understanding artificial intelligence ethics safety geiger bots bespoke code materiality software platforms information communication society gillespie relevance algorithms gillespie boczkowski foot eds media technologies essays communication materiality society cambridge mit press iliadis russo critical data studies introduction big data soc iety jasanoff future imperfect science technology imaginations modernity jasanoff kim eds dreamscapes dernity sociotechnical imaginaries fabrication power chicago university chicago press kitchin thinking critically researching algorithms information communication society kiritchenko mohammad examining gender race bias two hundred sentiment analysis systems retrieved kushner freelance translation machine algorithmic culture invisible industry new media society lepri staiano sangokoya letouz oliver tyranny data bright dark sides decision social good retrieved mac kenzie machine learning genomic dimensionality features landscapes richardson stevens eds postgeno mics perspectives biology genome durham duke university press mackenzie production prediction machine learning want european journal cultural studies mackenzie mcnally living multiples large scientific data pursues identity differences theory culture society mackenzie vurdubakis codes codings crisis signification performativity excess theory culture socie mager algorithmic ideology capitalist society shapes search engines information communication society manokha surveillance panopticism digital age surveillance society matzner privacy enough privacy context ubiquitous computing big journal information communication ethics society mendoza bygrave right subject automated decisions based profiling internet law springer cham retrieved mollicchi flatness versus depth study algorithmically generated camouflage security dialogue molnar gill bots gate human rights analysis automated decision canada immigration refugee system citizen lab international human rights program faculty law university toronto retrieved monahan algorithmic fetishism surveillance society murphy algorithmic surveillance collection conundrum international review law computers technology napoli automated media institutional theory perspective algorithmic media production consumption communication theory understanding artificial intelligence ethics safety neyland organizing algorithms theory culture society neyland bearing account witness ethical algorithmic system science technology human values neyland mllers algorithmic rules conditions consequences power information communication society noble algorithms oppression search engines reinforce racism nyu press grady politics redeployment malleable technologies localisation anticipatory calculation algorithmic life routledge retrieved plantin lagoze edwards sandvig infrastructure studies meet platform studies age google facebook new media society redden brand data harm record data justice lab retrieved richardson schultz crawford dirty data bad predictions civil rights violations impact police data predictive policing systems justice new york university law eview online forthcoming retrieved roberge seyfert algorithmic cultures algorithmic cultures essays meaning performance new technologies retrieved schll self loop bits patterns pathways quantified self networked self human augmentics artificial intelligence sentience new york routledge selbst baroc intuitive appeal explainable machines fordham rev retrieved smith high redlining qui etly upgrading institutional racism fast company retrieved institutional striphas algorithmic culture european journal cultural studies van dijck datafication dataism dataveillance big data scientific paradigm ideology surveillance society wilf cheney duranti eisenlohr gershon mackenzie wilf toward anthropology computer algorithmic forms sociality current anthropology retrieved willson algorithms everyday information communication society zarsky trouble algorithmic decisions analytic road map examine efficiency fairness automated opaque decision making science technology human values ziewitz governing algorithms myth mess methods science technology human values zuboff age surveillance capitalism fight future new frontier power profile books turinginst
