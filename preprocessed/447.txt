artificial intelligence australia ethics framework discussion paper page artificial intelligence australia ethics framework discussion paper artificial intelligence australia ethics framework discussion paper page citation dawson schleiger horton mclaughlin robinson quezada scowcroft hajkowicz artificial telligence australia ethics framework csiro australia joint first authors land water author copyright commonwealth scientific industrial research organisation tent permitted law rights reserved part publication covered copyright may reproduced copied form means except written permission csiro important disclaimer csiro advises information contained publication comprises general statements based scientific research reader advised needs aware information may incomplete unable used specific situation reliance actions must theref ore made information without seeking prior expert professional scientific technical advice extent permitted law csiro including employees consultants excludes liability person consequences including limited losses damages costs expenses compensation arising directly indirectly using publication part whole information material contained acknowledgements study funded australian government department industry innovation science authors would like express gratitude experts industry government community organisations formed steering committee guided research authors grateful many researchers csiro niversities shared expertise particular authors would like thank reviewers including professor toby walsh university new sout wales professor lyria bennett moses university new south wales professor julian savulescu university oxford monash university cecilia etulain alfred hospital authors would also like thank individuals attended consultative workshops sydney brisbane melbourne perth people attended live conference brisbane september sharing knowledge perspective artificial intelligence lped make report ossible accessibility csiro committed providing web accessible content wherever possible difficulties accessing document please contact csiroenquiries artificial intelligence australia ethics framework discussion paper page artificial intelligence australia ethics framework public consultation artificial intelligence potential increase well lift economy improve society instance making inclusive help environment using planet resources sustainably aus tralia realise benefits however important citizens trust applications developed businesses governments academia one way achieve align design application ethical inclus ive values consultation approach purpose public consultation seek views discussion paper developed artificial intelligence australia ethics framework feedback inform government approach ethics australia part consultation department industry innovation science welcome written submissions close friday may please note comments submissions published department website unless submission clearly indicate would like comments treated confidential questions consideration principles put forward discussio paper right ones anything missing principles put forward discussion paper sufficiently reflect values australian public organisation designed implemented system based principles would meet needs customers suppliers principles might required meet needs customers suppliers would proposed tools enable organisation implement core principles ethical tools support mechanisms would need able implement principles ethical already best models know related fields serve template follow practical application ethi cal additional ethical issues related raised discussion paper important closing date written submissions friday may email website mail artificial intelligence strategic policy division department industry innovation science gpo box canberra act artificial intelligence australia ethics framework discussion paper page executive summary ethics artificial intelligence growing importance artificial intelligence changing societies economies around world analysis reveals ver past years countries international organisations announced billion programs technologies powerful means considerable potential improved ethical outco mes well ethical risks report identifies key principles measures used achieve best possible results keeping well australians top priority countries worldwide developing solutions recent advances technologies prompted wave responses across globe nations attempt tackle emerging ethical issues figure germany delved ethics automated vehicles rolling comprehensive government ethical guidance development available new york put place automated decisions task force review key systems used government agencies accountability fairness number government advisory bodies notably centre data ethics innovation european union explicitly highlighted ethical development source competitive advantage figure map ecent developments artificial intelligence ethics worldwide data sources pan strategy australian federal budget german ministry transport digital infr astructure national institute transformation india villani report reuters japanese society artificial intelligence european commission parliament singapore government china state council new york city hall canada november society program announced canadian government support research social economic philosophical issues united kingdom november centre data ethics innovation announced advise government governance standards reg ulation guide ethical india june national institute transformation india publish national strategy focus ethical european union october european commission appoints expert group develop ethical legal social policy recommendations germany june federal ministry transport release guidelines use autonomous vehicles including ethical rules new york may mayor blasio announces automated decisions task force develop transparency equity use japan february ethics committee japanese society release ethical guidelines emphasis public engagement australia federal government announces funding development national ethics framework france march president macron announces strategy fund research int ethics open data based villani report recommendations singapore august singapore advisory council ethical use data appointed minister communications information china april ministry tran sport releases standards testing automated vehicle artificial intelligence australia ethics framework discussion paper page approach based case studies report examines key issues exploring series case studies trends prompted ethical debate australia worldwide see figure examples case studies relevant principles data governance identifying data dataset included health information uploaded expected data would useful tool medical research policy development unfortunately discovered combination public available information researchers able personally identify individuals data source quick action taken remove dataset privacy protection fairness automated decisions houston teachers fired automated system used houston school district assess teacher performance cases fire little transparency regarding way operating use challenged court teacher union system proprietary software inner workings hidden case settled district stopped using fairness transparency explainability contestability accountability predicting human behaviour compas sentencing tool compas tool used give recommendations judges whether prospective parolee extensive debate accuracy system whether fair african americans investigations non outlet indicated incorrect predictions unfairly categorise black americans higher risk system proprietary software harm regulatory legal compliance privacy protection fairness transparency explainability figure table issues examined chapters case studies relevant principles data sources office australian information commissioner senate community affairs committee ecretariat propublica northpointe artificial intelligence holds enormous potential improve society general replicates uman intelligence seen unlikely prospect coming decades numerous narrow technologies already incredibly sophisticated handling specific tasks medical technologies autonomous vehicles high profile examples potential save lives transform society benefits come risks automated decisions systems limit issues associated human bias due care focused data used systems ways assess fair safe automated vehicles could save thousands lives limiting accidents caused human error germany transport ministry highlighted ethics framework avs require regulation ensure safety existing ethics context reinvented philosophers academics political leaders ethicists spent centuries developing ethical concepts culminating human based framework used international australian law australia party seven core human rights agreements shaped law ethics framework rewriting laws ethical standards artificial intelligence australia ethics framework discussion paper page updating ensure existing laws ethical principles applied context new technologies core principles generates net system must generate benefits people greater costs harm civilian systems must designed harm deceive people implemented ways minimise negative outcomes regulatory legal compliance system must comply relevant international australian local federal government obligations regulations laws privacy protection system including systems must ensure people private data protected kept confi dential plus prevent data breaches could cause reputational psychological financial professional types harm fairness development use system must result unfair discrimination individuals communiti groups requires particular attention ensure training data free bias characteristics may cause algorithm behave unfairly transparency explainability people must informed algorithm used impacts provided information information algorithm uses make decisions contestability algorithm impacts person must efficient process allow person challenge use output algorithm accountability people organisations responsible creation implementation algorithms identifiable accountable impacts algorithm even impacts unintended data core recent advances key capabilities deep learning made possible vast troves data data collected used means issues related closely intertwined relate privacy data nature data used also shapes results decision prediction made opening door discrimination inappropriate inaccurate datasets used also key requirements australia privac act difficult navigate age predictions people added ethical layers around world making kinds predictions people ranging potential health issues probability end appearing court comes medicine provide enormous benefits healthcare comes human behaviour however challenging philosophical question wide range viewpoints benefits sure risks well creating self prophecies heart big data risk probabilities humans struggle accurately assess fairer australia colloquial motto fair ensuring fairness across many different groups ustralian society challenging cuts right heart ethical different ideas fair means algorithms necessarily treat every person exactly either operate according similar inciples similar situations like goes artificial intelligence australia ethics framework discussion paper page like justice sometimes demands different situations treated differently developers need codify fairness algorithms various challenge managing often inevitable trade offs ometimes right choice considered optimal may disputed stakes high imperative human decision accountable automated decisions australian laws already mandate deg ree circumstances transparency key panacea transparency complex issue ultimate goal transparency measures achieve accountability inner workings technologies defy easy explanation eve cases still possible keep developers users algorithms accountable analogy drawn people explanation brain chemistry making decision necessarily help understand decision made explanation person priorities much helpful also complex issues relating commercial secrecy well fact making inner workings open public would leave susceptible gamed black boxes pose risks hand black boxes inner workings shrouded secr ecy acceptable public interest stake pathways forward involve variety measures different situations ranging explainable technologies testing regulation requires transparency key priorities fairness measures used system measures enabling external review monitoring people always aware decision affects made difficulties automated decisions government departments already austral ian courts justifying decisions transparency debate one component feeding another debate justifiability designers machine justify know independent normative framework serve inform development well justify revise decisions made document part conversation privacy measures need keep new capabilities decades society rules fingerprints collected used new facial recognition gait iris scanning technologies biometric information goes well beyond fingerprint many respects incidents like cambridge analytica scandal demonstrate far privacy breaches modern age technologies potential impact significant ways may need explore privacy means digital world keeping bigger picture focus discussions ethics autonomous vehicles tend focus issues like trolley problem vehicle given choice save life situation swerve right hit elderly person stay straight hit child swerve left kill passengers importan questions worth examining widespread adoption autonomous vehicles improve safety cut hundreds lives los australian roads every year risk lives could lost relatively far scenarios dominate discussion delay testing implementation values programmed autonomous vehicles important though need considered alongside potential costs inaction reduce need skills increase demand others disruption job market constant however may fuel pace change challenges ensuring equality opportunity inclusiveness ethical approach development requires helping people negatively impacted automation transition careers could involve training reskilling new career pathways improved information risks opportunities help workers take proactive action incentives used encourag right type training right times overall acting early improves chances avoiding job ongoing unemployment artificial intelligence australia ethics framework discussion paper page help intractable problems long health environmental issues need novel solutions may able help australia vast natural environment need new tools aid preservation already implemented people serious disabilities health problems able participate society thanks technologies international coordination crucial developing standards electrical industrial products required international coordination make devices safe functional across borders many technologies used australia made already plenty foreign products used regulations induce foreign developers work australian standards point limits internatio nal coordination partners overseas including international standards organisation iso necessary ensure products software meet required standards implementing thical broad set technologies range legal ethical implications one solution emerging issues however tools used assess risk ensure compliance oversight appropriate tools selected individual circumstance toolkit ethical impact assessments auditable assessments potential direct indirect impacts address potential negative impacts individuals communities groups along mitigation procedures internal external review use specialised professionals groups review use systems ensure adhere ethical principles australian policies legislation risk assessments use risk assessm ents classify level risk associated development use best practice guidelines development accessible cross industry best practice principles help guide developers users gold standard practices dustry standards provision educational guides training programs potentially certification help implement ethical standards use development collaboration programs promote incentivise collaboration industry academia development ethical design along demographic diversity development mechanisms monitoring improvement regular monitoring accuracy fairness suitability task hand also involve consideration whether original goals algorithm still relevant recourse mechanisms avenues appeal automated cision use algorithm negatively affects member public consultation use public specialist consultation give opportunity ethical issues discussed key stakeholders best practice based ethical principles development best practice guidelines help industry society achieve better outcomes requires identification values ethical principles concepts serve basis artificial intelligence australia ethics framework discussion paper page report report covers civilian applications military applications scope report also acknowledges research ethics occurring part project australian human rights commission well work undertaken recently established gradient institute work complements research conducted australian council learned academies acola builds upon robotics roadmap australia australian centre robotic vision research perspective framework sits alongside existing standards national health medical research council nhmrc australian code responsible conduct research nhmrc national statement ethical conduct human research artificial intelligence australia ethics framework discussion paper page guide framework evolving domain may single ethical framework guide decision making implementation artificial intelligence chapters ethics framework provide trong foundation awareness achievement better ethical outcomes broad family technologies requires careful specialised approaches chapters provide broad understanding ethics used identify begin crafting specialised approaches ethical framework used isolation key business policy decisions supplement fit applications chapter existing frameworks principles guide lines ethics chapter identifies summarises key approaches issues related ethics around world helps provide broader context current state ethics highlights strategies observed lessons implementation effectiveness chapter data governance section highlights crucial role data modern applications explores ways input data affect output systems well ways data breaches consent issues bias affect outcomes derived technologies data governance crucial ethical organisations developing technologies need ensure strong data governance foundations applications risk fed inappropriate data breaching privacy discrimination laws offers new capabilities new capabilities also potential breach privacy regulations new ways identify anon ymised data example repercussions data organisations safely use organisations constantly build existing data governance regimes considering new enabled capabilities ensuring data governance syste remains relevant chapter automated decisions chapter highlights ethical issues associated delegating responsibility decisions machines existing legislation suggests government departments automated decisions suita ble large volume decisions made based relatively uniform uncontested criteria discretion exceptions required automated decision systems best used tool assist human decision makers used requirements mandated organisations wise approach consider consider human hitl principles design phase automated decisions systems ensure sufficient human resources available handle likely amount inquiries must clear chain accountability decisions made automated system ask responsible decisions made system artificial intelligence australia ethics framework discussion paper page chapter predicting human behaviour chapter examin ethical difficulties emerge creating systems designed take input data humans make judgements people driven human bias programmed humans susceptible biases programmers end making flawed judgments based flawed information even information flawed priorities system aligned expectations fairness system deliver negative outcomes justice means like situations deliver like outcomes different situations deliver different outcomes means developers need pay special care vulnerable disadvantaged protected groups programming full transparency sometimes impossible undesirable consider privacy breaches always ways achieve degree transparency take neural nets example complex explain people would expertise understand way however input data explained outcomes system monitored impacts system reviewed internally externally consider system design suitable framework keeping transparent accoun table necessary ensuring system operating fairly line australian norms values chapter current examples practice chapter examines two areas technologies significant impact poi time vehicles surveillance technologies autonomous vehicles require hands safety governance management authorities competing visions prioritise human life system without cohesi set rules likely deliver worse outcomes optimised australian road rules conditions surveillance technologies consider non key principle technology treat human beings one cog service goal goal serve best interests human beings many ways biometric data replacing fingerprints key tool identification ease enabled voice face gait recognition systems dentify people poses enormous risk privacy artificial intelligence australia ethics framework discussion paper page contents introduction existing frameworks principles guidelines ethics australian frameworks international frameworks organisational institutional frameworks key themes data governance consent privacy act data breaches open data sources bias data automated decisions humans loop hitl black box issues transparency automation bias need active human oversight responsible automated decisions predicting human behaviour bias predictions discrimination fairness predictions transparency policing predictions medical predictions predictions consumer behaviour current examples practice autonomous vehicles personal identification surveillance artificial intelligence employment gender diversity workforces artificial intelligence indigenous communities proposed ethics framework putting principles practice artificial intelligence australia ethics framework discussion paper page example risk assessment framework systems conclusion references appendix stakeholder xpert consultation figures figure map recent developments artificial intelligence ethics worldwide figure table key issues examined chapters case studies relevant principles figure chart indicating australian knowledge consumer data collection sharing figure pie chart showing reasons australian data breaches april figure infographic showing three phases developing automated decision systems figure infographic showing five levels vehicle autonomy figure pie charts consultation attendee demographics artificial intelligence australia ethics framework discussion paper page introduction machine tool help humanity progress faster taking burdens calculations interpretations back task human brain remains always discovering new data nalyzed devising new concepts robot isaac asimov throughout science fiction writer isaac asimov published fictional tales intelligent robots envisioned three rules govern would later add fourth law protect humanity broadly clear four rules would insufficient handle philosophical technical complexity task asimov laws pre decades studies ethics artificial intelli gence arguably began term artificial intelligence coined mathematician ohn mccarthy colleagues today ethics remains rich highly relevant field inqu iry report defined collection interrelated technologies used solve problems autonomousl perform tasks achieve defined objectives without explicit guidance human today capabilities unaided machine learning complex problem solving delivered virtual automated online search tools computerised game simulators mechanical systems robots autonomous vehicles definition compasses recent powerful advances neural nets deep learning well less sophisticated still important applications significant impacts people automated decision systems report deals exclusively civilian applications delve ethics military document focuses narrow performs specific function rather general comparable human intelligence across range fields seen likely prospect enormous benefits already accompanying age new medical technologies potential save lives persuasive indications autonomous vehicles may cut road toll new jobs created economies rejuvenated creative new forms entertainment emerging tools powerful complex means design use subject significant ethical conside rations report ethical design principles good technology ethics centre sydney provides overview philosophical basis ethical approach technology matters highlights importance coming ethical equilibrium satisfies broad range attitudes toward ethical although ethics discussion paper developed keeping concept foundational assumptions lie heart document power alter outcomes get technology technology serve best interests human beings aligned human values notion technology value people make decisions flawed one historian melvin kranzberg said technology neither good bad neutral technol ogy apes artificial intelligence australia ethics framework discussion paper page people people shape technology today cities transformed road infrastructure serve cars smartphones change attention spans evolved workforce medical technologies ivf even changed ways children conceived people born transformed world affected ways lived lives everyone gets access advanced technologies every body gets say used released public domain makes important track consider implications new technologies time emerging accept ability dete rmine outcomes get ethical imperative try find best possible outcomes avoid worst around world people given prison sentences based assessments autonomous systems world trans portation faces possible wave disruption automated vehicles move roads displacing jobs creating new ones watching people surveillance sometimes improving safety sometimes encroaching privacy people asse ssed likely medical problems others assessed gauge consumer preferences effects transformative australian society countries everywhere developing plans era past two ears united states china united kingdom india finland germany european commission countries organisations published strategies important component national strat egies ethical issues raised advancement adoption technologies ethics framework highlights ethical issues emerging likely emerge australia technologies outline initial steps toward mitigat ing reinvent ethical concepts contextualises existing ethical considerations developed centuries practice order keep pace new capabilities emerging via seeks pragmatic solutions future pathw ays rapidly evolving area analysing case studies acknowledging importance ongoing theoretical philosophical discussions implications technology development adoption advanced forms narrow wait government society catch technologies already developing quickly blocking technologies option cutting acces internet would may scope ban particularly harmful technologies emerge internet risks involved use seen reason reject entirely many technologies proven save lives reduce human suffering thus ethical approach restrictive one already cases slow pace regulatory adaptation hindered development potentia lly life technologies numerous stakeholders consulted formulation report expressed concern space could negative consequences drive innovation offshore detriment smaller australian companies advantage established multinationals resources mind also important consider consequences taking action steering ethical development use australia case studies document demonstrate technologies already range effects people around world developers technologies working area yet well regulated means exposed added risk cklash occurs run risk making mistakes scapegoated problems could potentially avoided area well understood proper rules regulations ethical guidance place report emphasises real world case studies specifically related automated systems rather detailed exploration philosophical implications philosophical inquiries also important goal document provide pragmatic assessment issues help foster ethical development australia written goal creating toolkit practical artificial intelligence australia ethics framework discussion paper page implementable methods developing best practice guidelines providing education training used support core ethical principles designed assist developers australia whole research analysis pro fessional ethicists necessary technologies continue shape australian society ethics framework provides guidance approach ethical issues emerge use report argues potential pro vide many social economic environmental benefits also risks ethical concerns regarding privacy transparency data security accountability equity ethical framework one part suite governance mechanis policy tools include laws regulations standards codes conduct ethical framework ensure safe ethical development use fit purpose flexible nimble approaches appropriate regulation governance new emerging digital technologies ethics inform informed laws community values principles take laws account form groundwork formulation specific codes laws egulation intended guide developing governing technologies neither laissez approach sufficient path forward allows flexible solutions fostering innovation fir dedication aligning development human values document aim provide legal guidance regulations possibly legal reform formulated needed appropriate legal governing bodies specific omain application goal document help identify ethical principles elicit discussion reflection developed used australia proactive approach ethical development australia mitigate risks build fairer secure competitive advantage well safeguard rights australians artificial intelligence australia ethics framework discussion paper page existing rameworks principles guidelines ethics following documents publica tions provide outline relevant legislation ethical principles relating use development literature sourced governments multilateral organisations within australia internationally summary stematic review available literature relating ethical use collection key documents give high overview current state ethics selected basis impact visibility australian rameworks artificial intelligence broad set technologies applications across virtually industries aspects government society government agencies already using automated decisions systems streamline provision servi ces existing advice provide insight governance oversight government automated decisions key documents authored government bodies provide background agencies use includes section social security administration act states secretary may arrange use secretary control computer programs purposes secretary may make decisions social security law decision made operation computer program arrangement made subsection taken decision made secretary one numerous legislative clauses allowing government agencies use computers decision since departments social services health education training immigration border protection agriculture water resources veterans affairs given authority let utomated systems make decisions law clarifies imp ortant aspect ethics expressed australian legislation decisions made automated systems human authority must accountable decisions department finance working group automated assistance administrative decision making released best practice guide government agencies seek ing use make decisions guide updated outlines principles covering range issues review mechanisms appropriate ways override decision made automated system guidelines include flow charts automated decisions made checklists help ensure automated decisions bei made according values administrative law checklists help serve valuable starting point developing toolkits use administration guide distinguishes two key types decisions administrative decisions decision required exercise discretion discretion exercisable facts established given high volume routine decisions need made agencies guide judged suitable use automated systems making decisions discretion required cases automated decision systems determined best used decision tools human supervisors distinction clarifies valuable tool artificial intelligence australia ethics framework discussion paper page decision decisions requiring human judgment particularly context public policy administration federal government agencies also developing practices interdepartmental committee regularly convenes discuss government agencies utilise automation becomes pervasive within government industry broader society frameworks best practice guide automated decision help ensure government bodies remain accountable public guidance may also sought examples government action around automated decision making instance new york city government first american government body set task force specifically examine accountability automated decisions automated decisions task force examine automated systems lens equity fairness accountability set release report december recommen procedures reviewing assessing algorithmic tools used city australia international human rights obligations anti legislation australia signatory seven core intern ational human rights agreements international covenant civil political rights iccpr interna tional covenant economic social cultural rights icescr international convention elimination forms racial discrimination cerd convention elimination forms discrimination women cedaw convention torture cruel inhuman degrading treatme punishment cat convention rights child crc convention rights persons disabilities crpd agreements derived universal declaration human ghts released australia also party number related protocols australia human rights parliamentary scrutiny act new bills must accompanied statement compatibility demonstrates align seven aforeme ntioned man rights agreements parliamentary joint committee human rights scrutinises laws confirm compatib austr alia human rights obligations future australian legislation need abide principles amid change occurring due australian human rights commission currently process developing report examining australia human rights obligations cont ext emerging technological issues report released public consultation issues paper alrea released discussion addition australia number anti laws state federal levels federal laws include age discrimination act disability discrimination act racial discrimination act sex iscrimination act measures combat discrimination highly relevant systems vulnerable discriminatory outcomes instance cases systems used historical data leading results replicated biases prejudices original data well flaws collection data ensuring systems artificial intelligence australia ethics framework discussion paper page programs created accordance existing anti laws designers need cons ider likely outcomes caused algorithms design phase data legislation australia data key component necessary developing skills needed work technology large datas ets often required teach machine learning technologies legislation guides data therefore affects development also highly relevant privacy australians key document data australia report productivity commission data availability use report focuses ways streamline access data wel exploring economic benefits could gained improved data access report covers several areas particular relevance ethics framework including assisting individuals access personal data held public encies identifying datasets high value public role third intermediaries assisting consumers make use data benefits costs data standardisation public releases relevance broader develo pment personal information may handled systems part australian government data reform efforts data sharing release bill formulated department prime minister cabinet released discussion paper outlining key principles bill including following goals safeguard data sharing release consistent appropriate way enhance integrity data system build trust use public data establish institutional arrangements data governance via national data commissioner supporting office promote better sharing public sector data office victorian information commissioner also released issues paper outlining key questions relating data used report rticularly concerned exploring potential privacy issues arising development use promotes use ethical data stewardship requires commitment transparency accountability way data collected used report also proposes need independent governance oversight industry ensure principles ethical data stewardship adhered data practices integral aspect ethics systems require effect ive facilitation data sharing collection order function develop however crucial process compromise privacy comprehensively reviewing reforming australia data practices order strike bala nce would help resolve key ethical issues associated development reducing possibility programs could access misuse personal information privacy act privacy issues associated internet new pot ential amplify existing challenges australian privacy act privacy act regulates personal information handled privacy act defines personal information artificial intelligence australia ethics framework discussion paper page opinion whether true whether recorded material form identified individual individual reasonably identifiable common xamples individua name signature address telephone number date birth medical records bank account details commentary opinion person privacy act includes thirteen australian privacy principles apps apply private sector organisations well australian norfolk island government agencies collectively referred app entities privacy act also regulates privacy component consumer credit reporting system tax file numbers health medical research office australian information commissioner responsible privacy functions conferred privacy act international frameworks many strategies developed governments aroun world include discussion ethics information important framing international context australia approach particular key ethical questions explored national strategies united kingdom france germany shaped european union data pro tection laws began implementing general data protection regulation gdpr among largest far data laws world includes right forgotten requires organisations data ope rations measures place allowing members public request removal personal information held another element gdpr privacy design clarifies statutory requirements privacy system des ign phase gdpr also encourages enforce certification systems gdpr also includes sections relevant automated decisions indicating automated decisions systems sole decision entity decision egal ramifications article states data subject shall right subject decision based solely automated processing including profiling produces legal effects concerning similarly significantly affects academics pointed language article vague right explanations automated system may actually exist gdpr european union also official plan development artificial intelligence europe explicitly highlights digital single market key driver development emphasises creation ethic competitive advantage euro pean nations statement european group ethics science new technologies suggested global standard fundamental principles ethical supported legislative action required ensur safe sustainable development european commission also issued draft ethics guidelines trustworthy emphasise human centric trustworthy two points emphasise ethics also certain technical aspects lack technological mastery cause unintentional outlines frame work trustworthy begins ethical purpose moves realisation followed requirements finally technical non methods oversight united kingdom national plan ready willing able explores ethics numerous angles sections inequality social cohesion prejudice data monopolies criminal misuse data suggest ions development code report points numerous state non actors developing ethical principles use coordinated approach lacking many cases according report mechanisms must found ensure current trend artificial intelligence australia ethics framework discussion paper page ethical principles simply translate meaningless box report also nominates alan turing institute national centre research part mandate exploration ethics artificial intelligence document includes code five key elements artificial intelligence developed common good benefit humanity artificial intelligence operate principles intelligibility fairness artificial intelligence used diminish data rights priva individuals families communities citizens right educated enable flourish mentally emotionally economically alongside artificial intelligence autonomous power hurt destroy deceive human beings shou never sted artificial intelligence french national report examines number key ethical issues pro poses measures address instance dis crimination impact assessments suggested one possible measure address hidden bias discrimination citing existence privacy impact assessments european law report also explores black box problem easy expl data going program easy explain data comes occurs within difficult people understand technologies explain processes increasingly important becomes comm used report also extensively canvasses issue automation need retraining measures mitigate impact workforce regulatory level report emphasises designing procedures tools methods allow auditing systems key ensuring systems conform legal ethical frameworks also suggests necessary instate national advisory committee ethics digital technology artificial intelligence within institutional framework germany national report automated connected driving world comprehensive ethics report autonomous vehicles avs date report lays key principles developme avs explicitly stating public sector responsible safety licencing automated systems key requirement report emphasises personal freedom individual paramount concern government must pursued within context public safety prioritisation human life key element ethical framework damage inevitable animals property never placed human life human life must damaged german ethics framework states distinction based personal features age gender physical mental constitution strictly prohibited however general programming reduce number perso nal injuries may justifiable report also notes ethical dilemma situations depend actual specific situation standardised programmed would desirable independent public sector agency systematically process lessons learned situations however may still prove necessary program vehicles deal ethical dilemma situations would indicate degree standardisation humans expected able make decisions brief moment accident may case autonomous vehicles act rapidly require programming beforehand court understands given one second make decision might make decision another reasonable person might made finkel told media generous computerised algorithm run much faster speeds artificial intelligence australia ethics framework discussion paper page organisationa institutional frameworks australian council learned academies australian council learned academies acola compiling comprehensive horizon scan issues affecting development australia identifies social impacts affect australia new zealand input key academics field report covers relevance key industries like agriculture fintech transport well ways affects government social licy report prepared concurrently acola report particular relevance ethical framework discussions individual agency autonomy affect individual sense self elements report cover social licence inclusion privacy data bias well differing concepts fairness algorithms acola report considered complementary framework released provide additional analysis help policymakers understand key issues relating nuffield foundation roadmap research ethical societal implications algorithms data artificial intelligence roadmap research nuffield foundation examines thical implications research first examines ambiguity many key concepts regularly brought discussions ethics values privacy hold different meanings among different audiences aims ensure discussing issues people talk past one another also makes key point number values often conflict inevitably tradeoffs example quality services often conflict privacy convenience conflict dignity accuracy conflict fairness inevitability tradeoffs algorithms dis cussed chapter report institute electrical electronics engineers comprehensive documents regarding ethical development produced institute electrical electronics engineers global initiative ethics autonomous intelligent systems comprised several hundred world leaders across ind ustry academia government group released initial report ethical design based public feedback released cond version review primary goal produce accessible useful framework serve robust reference global development ieee outlines five core principles consider design implementation adherence existing human rights frameworks improving human wellbeing ensuring accountable responsible design transparent technology ability track misuse comprehensive collaborative approach development framework provides well rounded frame reference company governmental academic ethical gui delines artificial intelligence australia ethics framework discussion paper page report reviews current academic research around emerging topical issues report focuses four key issues labour automation bias inclusion rights liberties ethics governance discussion bias inclusion comprehensive crucial section report issue impact design outset ill long negative consequences appropriately addressed according report current known bias attributed lack gender ethnic diversity tech industry however issue may lobal reach many tech branches international companies based thus subject problem december issued report included timeline key ethical breaches involving technologies throughout year also highlighted key developments ethical rese arch emerging strategies combat bias recognising allocative representational harms new observational fairness strategies anti strategies focus appropriate input data measuring results classification pari equal performance across groups even cost accuracy among certain groups cases calibration strategies report included significant sections hidden labour chains production technologies also highlighted act ethics frameworks enough concrete actions need taken ensure accountability justice also produced template algorithmic impact assessments discussed section report one hundred year study artificial intelligence one hundred year study artificial intelligence based stanford university launched effort detail long influence society individuals new report scheduled release every five years aim creating collection reports chronicle development issues raised development course one hundred years primarily focussed north american societies report ide ntifies eight areas likely undergo biggest transformation result transport healthcare education low resource communities public safety workplaces homes entertainment ethical issues associated areas highlighted report focuses mainly current future direction various domains authors suggest restrained government regulation high levels transparency around development provide best climate couraging socially beneficial innovation asilomar principles conference hosted organisation future life institute reviewed discussed key literature developed list key principles known asilomar principles far garnered signatures agreement researchers signatures endorsers principles ethics values section report according onus developer adhere responsible design aim bettering humanity systems designed line accepted values cultural norms protecting individual privacy remaining transparent humans also remain control whether delegate decisions systems goal accomp lishing human objectives universal guidelines artificial intelligence public voice coalition group ngos representatives assembled electronic privacy information center october issued guidelines development guidelines artificial intelligence australia ethics framework discussion paper page based premise primary responsibility systems must reside institutions fund develop deploy systems guidelines right transparency individuals right know basis decision concerns includes access factors logic techniques produced outcome right human determination individuals right final determination made person identification obligation institution responsible system must made known public fairness obligation institutions must ensure systems reflect unfair bias make impermissible discriminatory decisions assessment accountability obligation system deployed adequate evalua tion purpose objectives benefits well risks institutions must responsible decisions made system accuracy reliability validity obligations institutions must ensure accuracy reliability validity decisions data quality obligation institutions must establish data provenance assure quality relevance data input algorithms public safety obligation institutions must assess public safety risks arise deploymen systems direct control physical devices implement safety controls cybersecurity obligation institutions must secure systems cybersecurity threats prohibition secret profiling institution shall establish maintain secret profiling system prohibition unitary scoring national government shall establish maintain general purpose score citizens residents termination obligation institution established system affirmative obligation terminate system human control system longer possible partnership private companies increasingly aware need ethical framework using developing collegiate attitude adopted raditionally competitive tech companies indication importance openness collaboration developing said framework example partnership originally established handful large tech companies made variety industry academic professionals working together better understa impacts society rather comprehe nsive ethics framework group outlined eight tenets members attempt uphold tenets follow fairly standard topics ethical development use focusing particular technology benefits many people poss ible ensuring personal privacies protected encouraging transparency point partnership discussed need reduce bias increase diversity tech industry google june google published company inciples egards development staff within organisation protested addition amiliar principles regarding safeguarding privacy artificial intelligence australia ethics framework discussion paper page developing beneficial humanity addressing bias google also released list applications chosen pursue including limited weapons techn ologies principal purpose causing harm technologies gather surveillance way violates internationally accepted norms technologies whose purpose contravene principles international law human rights response principles without scepticism likely result recent controversies around google contracts military company recently decided renew critics also noted google opportunity much specific actio principles code especially touted concrete standards actively governing google research instance principles stated google seek avoid bias developing algorithms meaningful explanation achieved addressed addition proviso independent review google technology development would likely well received google subsidiary company deepmind also created ethics board however criticised lack transparency membership decision microsoft microsoft also prominent voice ethics debate december microsoft president brad smith wrote company blog microsoft believed governments needed regulate facial recognition necessary ensure technology organizations develop use governed rule law company also put together number principles tools geared toward ethical site includes six key prin ciples fairness inclusiveness reliability safety transparency privacy security accountability also issued guidelines responsible bots examine earn trust ibm key player computing space developer question watson ibm also released set materials ethics addition guidance ethical research trust transp arency measure ibm also released ethics guide developers guide focuses five key areas developers accountability value alignment explainability fairness user data rights stresses ethical development solely viewed technical problem resolved instead requires strong focus communities affects future humanity research institute university oxford future humanity institute calls research building frameworks ensure socially beneficial development report vernance research agenda focuses developing global governance system protect humanity extreme risks posed future advanced report highlights need leaders constitutionally commit developing common good authors acknowledge solution satisfies interest diverse range stakeholders exceedingly difficult complicated argue potential benefits society make worthy endeavour artificial intelligence australia ethics framework discussion paper page ethics art ificial intelligence first section publication bostrom yudkowsky discuss ethical issues associated machine learning developed near future make observatio machine going carry tasks previously completed humans machine required complete function level humans responsibility transparency auditability incorruptibility predictability tendency make innocent victims ream helpless frustration latter sections publication address potential ethical issues associated super machines future scope current report initiative based harvard kennedy school initiative developed short series recommendations help shape global policy framework convene yearly interdisciplinary meeting discuss pressing ethical issues development create global framework supports ethical development including agreement beneficial safeguards transparency standards design guidelines confidence measures implement agreed rules regulations local international levels key themes important note exists relevant work reviewed due length considerations publications discussed provide snapshot current state ethics frameworks assist framing con text australia uniquely tailored framework collectively literature emphasise principles required developing ethical centre responsible design benefits humanity benefit achieved protecting privacy human rights addressing bias providing transparency around workings machines number tools suggested support ethical development use including impact assessments audits consumer data rights oversight mechani sms formal regulation artificial intelligence australia ethics framework discussion paper page data governance plans display display bottom locked filing cabinet stuck disused lavatory sign door saying beware leopard hitchhikers guide galaxy douglas adams issues relating ethics intertwined data sharing use age big data people opinions interactions behaviours biological processes tracked ever however australians largely unaware scale degree data collected sold shared collated used one study people surveyed aware data generated online activities could tracked collected shared organisations see figure however frequently reported unaware extent purpose data collected used shared addition study found austra lians rarely able grasp full implications terms use applying many services social medi products like smartphones figure chart indicating australian knowledge consumer data collection sharing data source consumer data digital economy emerging issues data collection use sharing despite low levels public understanding data governance issues crucial become important development gains pace data immense growing value input technologies value potential exploitation data increases need protect data rights privacy austra lians companies today ability follow activities across many sites webin store shopping loyalty card providers like flybuys everyday rewards ability collect combine information third partiessome companies exchange information customers third parties purposes delivering product service customer signed forall apps ask permission access things device required app workwhen company privacy policy means site share information websites companies correct incorrect know artificial intelligence australia ethics framework discussion paper page consent privacy act personal data regulated australian privacy act classifies information opinion whether true whether recorded material form identified individual indiv idual reasonably identifiable privacy contested term subject many varying interpretations far right degree secrecy privacy explicitly stated human right article universal declaration human rights working personal data protecting consent process fundamental protecting privacy due sensitive nature personal data consent adequately addressed point data collection privacy act stipulates consent express implied must abide four key terms individual adequately informed giving consent individual gives consent voluntarily consent current specific individual capacity understand ommunicate consent third erm privacy act states consent must current however time writing specific provisions right forgotten features recently established general data protection regulation updated data protection laws align international legislation right forgotten could considered future incorporation australia privacy act may measures suitable australian context although right affords individuals greatest control data may difficult enforce adhere especially data already integrated system model already trained may instructive observe right forgotten implemented enforced still early stages implementation review case study cambr idge analytica public trust cambridge analytica scandal exemplifies consequences inadequate consent processes privacy protection facebook app cambridge university researcher able gain access personal informatio users agreed take survey also people users facebook social networks way app harvested data millions facebook users various reports indicate data used develop targete advertising various political campaigns run cambridge analytica news broke alleged breach privacy many felt facebook provided transparent consent process ability one user effectively give consent use others data particularly concerning allegation cambridge analytica used personal data profile target political advertising users without appropriat consent widely criticised cambridge analytica facebook put governmental media scrutiny concerning data practices cambridge analytica become ins olvent facebook stocks plummeted following publication story although recovered full value eight weeks later industry incident serves example cost inadequate data protection policies also demonstrates may sufficient merely follow letter law avoid repeating mistakes consent processes ensure consent current specific transparent regul review data collection usage policies help safeguard breaches broader level artificial intelligence australia ethics framework discussion paper page balance needs struck protecting individual privacy ensuring transparent consent processes also encouraging investment innovation new technologies require rich datasets data breaches vast amounts data collected individuals importance protecting privacy knowing privacy compromised crucial recent amendment australian privacy act addresses concerns notifiable data breaches ndb scheme stipulates personal data accessed disclosed unauthorised way may cause harm affect individuals must ified april june notification data breaches australia majority breaches result human error malicious attacks see figure suggesting security gaps storage use data data breaches costly organisations financial legal nsequences well reputational damage average cost data breach australia million figure pie chart showing reasons australian data breaches april data source notifiable data breaches quarterly report april june mandatory reporting breaches ndb scheme positive move towards ethical data practices australia however reforms supported education training data protection well regular assessment data practices ensure australians trust security private information case study equifax data breach equifax credit reporting agency experienced data breach affecting least million individuals various degrees sensitive ersonal information compromised breach particularly concerning equifax opportunity prevent breach via patch already available several months failed identify vulnerabilities detect attacks systems addition due huge numbe people affected took several weeks identify individuals notify public breach occurred cost breach estimated realm million widely speculated equifax appropr iate measures processes place adequately protect private data held breach extreme example costs consequences implications inadequate data governance world increasingly reliant collection use system fault malicious criminal attack human error artificial intelligence australia ethics framework discussion paper page data develop stronger data governance policies including technical fixes like segmenting networks isolate potential hackers implementing robust data encryption well external legislation creating stronger repercussions consumer data loss help prevent ese types breaches future open data sources australian government developed initiatives better share use reliable data sources instance public data policy statement government committed optimise use reuse public data release non sensitive data open default collaborate private research sectors extend value public data benefit australian announcement backed several subsequent initiatives culminating recent ublication three key reforms new consumer data right whereby consumers safely share data trusted recipients mparison websites compare prod ucts negotiate better deals consumer data right right consumers consent share data businesses implied consent data transfers following initial sharing consumers also keep track revoke consent national data commissioner implement oversee simpler efficient data sharing release framework national data commissioner trusted overseer public data system new legislative governance arrangements enable better use data across economy ensuring appropriate safeguards place protect sensitive information addition reforms tens thousands government datasets available pub lic website resource one reason australia scores highly international open data index measures government transparency online may also useful catalysing innovation development using rich diverse australian datasets publication non data imperative support research innovation ethical issues consider many forms data could alone considered non personal ability detect patterns infer information could mean individuals identified non data information exploited unethical ways infringe right privacy case study ensuring privacy data dataset included health information uploaded expected data would useful tool medical research policy development unfortunately discovered combination public available information researchers able personally identify individuals data source quic action taken remove dataset use enabled devices networks collate predict data patterns heightened risk able identify individuals considered dataset report australia privacy commissioner outline issues involved process data release propose use rigorous risk management processes clear documentation decision processes guiding open publication data artificial intelligence australia ethics framework discussion paper page government privacy amendment offence bill seeks respond gap identified privacy legislation handling personal information making offence deliberately publicly released government information cision making framework ffice australian information commissioner csiro also assist making decisions datasets continued vigilance required ensure datasets useful researchers adequately protected case study locating people via geo recently published paper uses geo generated public available information possibly identify artist banksy chosen remain anonymous study framed investigation use geo solve mystery modern authors suggest methods could used law enforcement locate terrorist bases based terrorist graffiti however ability techniques take public available data make personal inferences individuals poses significant ethical issue privacy consent issues even dealing public available non data evalua tion identifiability data examine non data shared also consider non data could used conjunction data individual office australian inform ation commissioner published best practice guide use data analytics clearly outlines considerations directives ensure effective data governance line australian privacy act particular guide promotes use privacy ensure privacy proactively managed addressed organisational culture practic processes systems bias data machine learning various branches reliant rich diverse data sources effectively train algorithms create output training data include robust inclusive sample creep resulting outputs implicit bias disadvantage advantage certain groups biased data inputs lead discrimination often already vulnerable minority populations one basic requirements preventing bias controlling data inputs ensure appropriate systems used train unbiased datasets yield unfair results explored chapter simply using input data solution either case study demonstrates case study microsoft chatbot tay twitter chatbot developed microsoft way better understand interacts human users online tay programmed learn communicate interactions twitter users particular target audience young american adults however experiment lasted hours tay taken offline publishing extreme offensive exist racist tweets ability tay learn active real conversations twitter opened chatbot misuse ability filter bigoted offensive data adequately developed result tay artificial intelligence australia ethics framework discussion paper page processed learned created responses reflective abusive content encountered supporting adage garbage garbage addition controlling data inputs consideration must given impact indirect discrimination indirect discrimination occurs result use data variables highly correlated variables lead discrimi nation example neighbourhood individual lives often highly correlated racial background use data make deci sions thereby lead racial bias case study amazon delivery amazon recently rolled delivery across select group american cities however service extended neighbourhoods high number current amazo users result predominantly non neighbourhoods largely excluded service disadvantage neighbourhoods excluded delivery marginalised communities likely already facing impact bias discrimination amazon could convincingly argue made decision roll delivery based logistic financial requirements intend exclude non minorities racial demographics tend correlate location decision result indirect discrimination example demonstrates need critical assess ment bias data inputs used make decisions create outputs whether otherwise scientific research programming strategies developed optimise data inputs sampling reduce impact bias issues need addressed development stage developers need able appropriately assess data inputs training education systems support skills required address bias sampling data would help address ethical issue key points data governance crucial ethical organisat ions developing technologies need ensure strong data governance foundations applications risk fed inappropriate data breaching privacy discrimination laws organisations need carefully consider meaningfu consent considering input data feed systems nature input data affects output indiscriminate input data lead negative outcomes one reason testing important offers new capabilitie new capabilities also potential breach privacy regulations new ways identify anonymised data example repercussions data organisations safely use organisations constantly build existing data governance regimes considering new enabled capabilities ensuring data governance system remains relevant artificial intelligence australia ethics framework discussion paper page automated decisions big data processes codify past invent future requires moral imagination something humans provide explicitly embed better values algorithms creating big data models follow ethical lead sometimes mean putting fairness ahead weapons math destruction cathy neil humans faced tens thousands decisions day decisions influenced emotional state fatigue interest topic internal biases external influences decisions make pro fessional setting potential significantly affect greater community example insurance adjustor decision claim judge decision legal case banker decision loan application life onsequences individuals nationally globally used guide decisions government banking finance insurance legal system mining sectors number decisions driven likely grow dramatically develo pment uptake new technology used appropriately automated decisions protect privacy reduce bias improve replicability expedite bureaucratic processes australia challenge lies developing framework accompanying resources aid responsible development use automated decision technologies humans loop hitl automated decisions require data inputs analysed assessed criteria create data outputs make decisions figure design process steps requires evaluation assessment ensure system performs intended figure infographic showing three phases developing utomated decision systems artificial intelligence australia ethics framework discussion paper page concept humans loop hitl developed ensure humans maintain supervisory role automated technologies hitl aims ensure human oversight exception control optimisation maintenance automated decision systems ensure errors addressed humans remain accountable automated decisions aff ect large diverse groups people require design principle society loop sitl example discussed chapter automation cars decisions predictions make far reaching effects society whole incorporating sitl designing automated vehicle ystems involves considering behaviour expected technology aligns goals norms morals various stakeholders hitl sitl promote careful consideration programming used generate automated decisions ensure reflect laws adhere human rights social norms well protect privacy problems occur developed without critical assessment monitoring inputs algorithms outputs article gdpr law states human beings right subject solely automated decisions decisions legal ramifications black box issues transparency various branches artificial intelligence studies explainable transparent seek apply new processes technologies even layers existing programs order make understandable users progra mmers emerging area research likely provide useful tools understanding automated decision mechanisms however important consider transparent systems still operate high error rate significant bias addition attempts explain algorithm processes low hamper effectiveness explanations may still far complex analogy asked chose particular food helpful explain chemical processes occurred brain making decisio question becomes need know algorithm keep accountable functioning according laws rights social norms effective approach regulating need based appropriate levels transparen accountability act service broad principles based objectives case study houston teachers proprietary system used houston school district assess performance teaching staff system used student test scores time assess teacher impact results used dismiss teachers deemed ineffective system teacher union challenged use system court algorithms used assess teacher performance considered proprietary information owners software could scrutinised humans inscrutability deemed potential violation teachers civil rights case settled school distr ict withdrawing use system judge stephen smith stated outputs systems could relied upon without scrutiny may erroneously calculated number reasons ranging data mistakes glitches compu ter code algorithms human creations subject error like human endeavour increasing development uptake decision support systems automated decision systems similar cases likely emerge australia future important understand ethical artificial intelligence australia ethics framework discussion paper page issues inherent automated decision consider methods addressing resolving issues transparency associated complex deep learning systems proprietary systems require multi input recourse mechanisms one viable option protect interests people affected use automated decision systems instance countries implemented right request human review automated decisions decision generated solely automated processing subject decision must made aware ability within month notified lodge request reconsider decision take new decision based solely automated processing recourse autonomous decis ions used automation bias need active human oversight automation bias tendency disrega search contradictory information light computer solution accepted correct relying automated decisions situations provide consistently reliable outcome result increas errors commission omission following failing act advice automated decision system error respectively issues particularly important using automated decisions situations requiring discretion good decision making based advice automated decision systems requires humans involve exercise active thinking involvement rather passively allowing automated decision systems handle task suited operators grow reliant automated systems cease question advice receivin problems emerge demonstrated enbridge pipeline leak case study utomation bias enbridge pipeline leak july pipeline carrying crude oil ruptured near kalamazoo river state michigan resulti clean took five years cost million disaster prompted numerous inquiries well academic papers large amount environmental damage caused delayed reaction rupture allowed oil pump surrounding area hours time two startup moves pump oil entire incident releasing gallons oil area automated system provide warnings control centre personnel review incident found erators heard alarms system seen abnormally low amounts oil reaching destination incorrectly attributed warning signs planned shutdown reviews incident found outsi caller notified leak discovered action taken academics analysed disaster suggested regulators overlooked complacency key driving factor suggested industry policy makers regulators need consider automation bias developing systems reduce likelihood complacency errors recommendations review bodies highlighted poor management incident academics pointed people involved incident experienced detailed earlier incid ents senior staff likely overlook dangerous safety risks junior ones also pointed frequent alarms past due column separation problems resolved pumping oil line clear track thus case experienced staff recommended course action made problem worse difficult problem resolve academics point according researchers artificial intelligence australia ethics framework discussion paper page problem occurred enbridge case add ressed better training given human nature ignore frequent false alarms designers automated systems need carefully consider way systems interact human operators order counteract damaging effects overreliance complacency ensure recommendations provided system easily misinterpreted harmful ways mean careful consideration ways ensure hitl design principles implemented responsible automated decisions systems developed widely applied important create policy outlining responsibility falls things wrong system moral authority held accountable judicial sense decisions judgements human must accountable consequences decisions made main question arising liability decisions entity behind technology ultimately responsible point line draw recent cambridge public law conference highlighted complexity responsible something goes wrong auto mated administrative decisions authorit delegated indeed correct analysis programmer policy maker authorised decision computer concept delegation appropriately used context unlike human delegat computer programme never truly said act independently programmer relevant government agency computer process determines elements administrative decision determination elements treated subject separate decisions elements determined human decision case study automated vehicles arizona pedestrian killed automated vehicle owned uber preliminary report released national transportation safety board ntsb response incident states human present automated vehicle human control vehicle collision occurred various reasons collision could occurred including poor visibility pedestr ian lack oversight human driver inadequate safety systems automated vehicle complexities attributing liability instances collisions involving automat vehicles well documented case although legal matter settled court details released issue liability complex vehicle operated uber supervision human driver operated autonomously using components designed various tech companies following full investigative process ntsb release final report incident identifying factors contributed collision attribution responsibility regards poses pressing dilemma need consistent universal guidelines applicable across various industries utilising technology able make decisions significantly affecting human lives addition policy may provide universal framework aids defining appropriate situations automated decisions judgements may used artificial intelligence australia ethics framework discussion paper page key points existing legislation suggests government departments automated decisions suitable large volume decisions ade based relatively uniform uncontested criteria discretion exceptions required automated decision systems best used tool assist human decision makers used requirements mandated rganisations wise approach consider consider human hitl principles design phase automated decisions systems ensure sufficient human resources available handle likely amount inquiries must clear chain accountability decisions made automated system ask responsible decisions made system artificial intelligence australia ethics framework discussion paper page predicting human behaviour criminal sentences must based facts law actual crimes committed circumstances surrounding individual case defendant history criminal conduct based unchangeable factors per son control possibility future crime taken former attorney general eric holder similar manner systems able process information use make decisions also able extrapolate information recognise patterns used make predictions future behaviours events although previously discussed concepts hitl transparency black box issues accountability apply capability predict future potential actions poses additional specific ethical concerns related bias fairness require consideration used appropriately predictions powerfully accurate replicable efficient used advantage place human generated judgements predictions subject various extraneous variables thou ght noise bias fatigue effort technology could especially useful industries require decision makers generate frequent accurate replicable predictions judgements areas justice policing med icine appropriately assess ethical issues associated use enabled predictive judgement systems crucial first acknowledge inherent issues associated human judgements predictions australian legal system uses precedent sentencing guidelines regulate decision making effort combine discretion address influence bias although judges spend years training may still impacted cognitive biases personal opinions fluctuations interest fatigue hunger policies promote austr alia colloquial motto everyone deserves fair ensuring systems operating fair balanced ways across diverse australian population cornerstone ethical establishing industry standards supported guidel ines could provide baseline level assessment used australia support use fair algorithms case study israeli judges decision fatigue one high profile study israel academics examined parole hearings israel termine factors likely result favourable ruling observing rulings researchers found early day right food breaks judges far ikely grant parole difference extreme cases right rest breaks receiving favourable ruling compared break researchers suggested reason judges simply became hungr tired resulting harsher sentences researchers disputed findings indicating effect particular study likely due factors prospective parolees legal counsel times day cases deferred artificial intelligence australia ethics framework discussion paper page extent decision fatigue general exhaustion affects judicial decisions open deba problems associated decision well supported academic literature difficulties grappling cognitive biases miscarriages justice frequently attributable human error misconduct even best dec ision sometimes resort mental shortcuts heuristics understand situation make decisions well ability perform situations much higher degree replicability consistency humans bias predictions discrimination indirect discrimination occurs data variables highly correlated discriminatory var iables included model give example algorithm might explicitly consider race factor might discriminate neighbourhood filled almost enti rely people one race leading similar result superior ability recognise patterns creates serious potential ethical issues used make predictions human behaviour ensure predictive systems indire ctly biased variables used develop train algorithms must rigorously assessed tested cases higher risk may important run smaller tests simulations using broader public addition model tself assessed monitored ensure bias creep australian legislation prohibits discrimination unfair unequal treatment group individual basis race colour sex religion political opinion national traction social origin age medical record criminal record marital relationship status impairment mental intellectual psychiatric disability physical disability nationality sexual orient ation trade union activity set use many indicators make predictio health behaviour constitute discrimination race example may prove relevant indicator particular health problem could avoided fair skinned people risk skin cancer assesses skin cancer risk would need take account skin tone factor use particular input variable considered discrimination careful consideration need given kind outcomes constitute discrimination helpful considering variables included even bey ond explicit variables also indirect ones researchers pointed many indicators postcodes education family history effectively indicate race without explicitly needing included indicato one example geographic information used determine cost test preparation services revealed method unfairly discriminated asian american students charged higher fees academic thesis revi service non students although ethnicity specifically considered pricing structure service use location based pricing disproportionally impacted asian tudents higher fees result ing indirect discrimination also prompts another ethical question consideration beyond racial discrimination location based discrimination permissible still discrimination issue rac ial bias exposed used courts assess likelihood someone police focus crime hotspots identify potential suspects research debate already occurring suitability ools australian context artificial intelligence australia ethics framework discussion paper page case study compas system sentencing compas correctional offender management profiling alternative sanctions syste currently used many courts advise judges sentencing probation decisions system evaluates individuals using questions assigns risk score ten indicates probability likely person although race directly assessed system zip code research non media outlet propublica found black people profiled compas twice likely incorrectly labelled high risk committing violent repeat offences white people creators algorithm northpointe responded report denying algorithm biased black people northpointe indicated across risk scores ranging one ten equal levels recidivism black white groups racial bias system problem according prop ublica correct predictions acknowledged reasonably fair across two racial groups problem incorrect predictions false positives analysed percent predictions incorrect found significant racial disparity black defendants twice likely rated higher risk white defendants twice likely charged new crimes aft classed lower propublica northpointe able examine system data come opposing findings racial bias system discrepancy two analyses essentially came way group assessed measured fairness balanced accuracy system also suggests internal reviews may miss key problems base analysis assumptions fairness original design ability assess bias predictive systems intrinsically linked ith fairness measured along level transparency involved way compas system weighs assess defendant input variables calculate risk score proprietary software assessment way system eals racial indicators directly assessed lack transparency presents significant ethical issues predictive scores assigned individuals significant effects lives lack clarity system work already resulted one challenge filed supreme court basis due lack transparency accuracy validity compas could isputed case heard complex interactions bias fairness transparency enabled predictive systems exemplified compas case study although use enabled predictive systems help support decision making processes poses great potential benefits boosting replicability reducing human error bias inherent ethical issues must addressed particular effects indirect discrimination fairness appropriate transparency accountability guidelines use systems could allow examine way predictions made turn giving ability make adjustments address bias may need ongoing conversations community data used compas example may explicitly consider race explicitly consider family background offender whether parents married separated would considered fair australia must also ontend different sentencing outcomes racial groups nsw suspect target management rogram stmp introduced identify target repeat offenders pro artificial intelligence australia ethics framework discussion paper page actively disrupt criminal behaviour program come criticism disproportionally targeting aboriginal people finding right balance proactively preventing crime inaccurate group profiling ongoing ethical challenge across jurisdictions designers algorithms need pay careful attention systems come prediction may role government bodies determining general boundaries review monitoring processes existing laws regarding discrimination issues relating separate related issues bias fairness best addressed mitigated fairness predictions challenge ensuring fairness algorithms limited biased datasets input data comes world data colle cted world necessarily fair various population sub groups men women people particular race disability likely represented differently across datasets put automated system various subpopulations rarely ever show exactly input output results makes likely inherently discriminatory one way another assuming input information reasonably accurate accuracy datasets rarely perfect varying levels accuracy produce unfair results makes mistake one racial group observed facial recognition systems constitute racial discrimination issue relatively accurate data represents unfair situation real world disadvantaged groups may disadvantaged historical institutional reasons information necessarily underst ood compensated assess situation based data alone fairness really depends ask fairness difficult concept pin designers essentially reduce statistics researchers come many dozens mathematical definitions define fairness means algorithm many perform extremely well measured one angle different angle produce different results concept differing perspectives fairness exemplified compas case study propublica northpointe diverging perspectives accurately judge parity assessment white black defendants resulting completely different answers whether system biased put simply sometimes mathematically impossible meet every single fairness measure contradict multiple datasets used systems datasets almost never exactly equal acc uracy representativeness tradeoffs sometimes necessary important government society give consideration degree flexibility designers systems comes making trade fairness easures priorities like profit needs serious consideration given whether net benefits algorithm justify existence whether justified ways treats different groups companies consumers faced decisions make algorithms best represent values company prioritises profit ahead various forms fairness justify key consideration transparent decision broader public able make informed choices companies acting accordance public expectations artificial intelligence australia ethics framework discussion paper page case study amazon hiring tool global company amazon began work automated resume selection tool goal system could scan large numbers resumes determine best candidates positions expressed rat ing one five stars tool given information job applicants preceding ten years resear chers realised male dominance tech industry tool assigning higher ratings men women problem larger numbers qualified male applicants key word women appearing resume resulted downgraded tool designed look beyond common keywords particular programming languages focus subtle cues like types verbs used certain favoured verbs like executed likely appear resumes male applicants technology unfairly advantaged male applicants also put forward unqualified applicants hiring tool scrapped likely due problems talent websites linkedin use algorithms resume systems key staff said current state making final hiring decisions instead used tool human recruiters australia anz bank indicated researching use hiring practices states goal find candidates fair unbiased way algorithms used manner take decisions human hands amazon case demonstrates necessarily mean without human bias especially training data hiring tools need ensure data inputs case includes measures like time taken answer certain questions relevant reflective actual performance role testing kind outcome difficult metrics employee performance always easily expressed kpis may indeed potential ethical outcomes tools assumed tools ethical less biased human recruiters transparency policing predictions predictive analytics powered big data boost accuracy efficiency policing australia lessons learned overseas point need strong transparency measures public actively involved program predictive pol icing programs active though little peer material effectiveness predictive policing tools predicting specific crime used either profile people places measure effectiveness particular policing initi atives aim inform police crime trends working focus long persistent problem rather individual crimes case study predictive policing data analysis company palantir partnered new orleans police department began assemble data base local individuals use basis predictive policing used information gathered social media profiles known associates licence plates phone numbers nicknames weapons addresses medi reports indicated database covered around population new orleans operation six years flurry media artificial intelligence australia ethics framework discussion paper page attention secretive program new orleans police department nopd clarified hat program secret discussed technology conferences insufficient publicity meant even city council members unaware program gang member scorecard became focus media coverage groups american civil liberties union aclu pointed operations like require community approval transparency aclu argued data used fill databases could based biased practices stop licies disproportionately target african american males would feed predictive policing databases could mean african americans scanned system creating feedback loop likely targeted key consideration long use program data collected time still serving intended outcome measures ensure regularly assessed nopd erminated agreement palantir defendants identified system raised use technology court defence attempted subpoena documents relating palantir algorithms authorities los angeles police department lapd still agreement palantir relation laser predictive policing system lapd also runs predpol system predicts crime area suggests locations police patrol based previously ported crimes goal creating deterrent effect programs prompted pushback local civic organisations say residents unfairly spied upon police neighbourhoods profiled potentially creating another feedback loop people likely stopped police live certain neighbourhood stopped police likely stopped response local police invited reporters see predictive policing action arguing also helps communities affected crime pointing early intervention save lives foster positive links twee police entire communities police officers also cited media pointing needs sufficient public involvement understanding acceptance predictive poli cing programs order effectively build community links clear ethical issues arise advent predictive policing one key issues need transparency systems work adequately assessed remain accountable citizens affected addition exploitation potentially personal data systems could infringe privacy rights accorded australians privacy act trade increased ability police prevent monitor crime protection personal privacy discussed chapter case study predictive policing brisbane one predictive policing tool already modelled pre dict crime hotspots brisbane using years accumulated crime data system used data predict crime researchers seeing predictions correlated remaining results proved accurate existing models improvement accuracy assaults accuracy predicting unla wful entry better accuracy predicting drug offences theft better fraud system predict long term crime trends short term ones brisbane study used information location app foursquare incorporated information brisbane new york predictive policing tools typical use four broad types information historical data long term crime patterns recorded olice crime hotspots artificial intelligence australia ethics framework discussion paper page geographical demographic information including distances roads median values houses marriages socioeconomic racial makeup area social media information tweets particular location keyw ords human mobility information mobile phone usage check ins associated distribution population brisbane study primarily used human mobility information research needed study suggests types inp information may effective gauging accurate information others careful consideration may warrant emphasizing types input information others given varying impacts privacy less intrusive appr oaches may less likely provoke public distrust public trust case studies demonstrate crucial element effectivenes predictive policing tools debate use policing ongoing one clear outcome new technologies used law enforcement without public endorsement systems effectively serve police general public transparency systems operate circumstances used core ensuring remain ethical accountable communities protect may constructive agencies consider public engagement strategies feedback mechanisms introducing new technologies significantly affect public may also prudent consider risk analysis provide objective information public beneficial outcomes using enabled systems versus traditional policing methods medical predictions predictions abi lity add immense value australian health care system patient management diagnostics care however like new medical advances methods systems used health care require close management gold standard research implem entation case study predicting coma outcomes program china analyses brain activity coma patients able successfully predict seven cases patients went recover despite doctor assessments giving much lower chance recover took examples previous scans able detec subtle brain activity patterns determine patients likely recover one patient given score seven human doctors indicated low probability recovery gave oints subsequently recovered life may saved lives potential kind tool would immense value saving human lives spotting previously hidden potential recovery coma patients given high scores kept life support long enough recover prompts question people low scores rigorous peer research conducted systems relied upon inform clinical decisions ongoing monitoring auditing research also required assuming accurate number patients low scores would need kept life support confirm accuracy system core questions revolve around resour cing families patients may wish try recovery even odds success small crucial decisions cases made among stakeholders hinge solely results machine resources permit amilies option artificial intelligence australia ethics framework discussion paper page sad reality hospital system every day resources determine life death decisions hospital resources limitless system potential direct resources situation best chance recovery net gain lives saved many ways diagnostic tool different diagnostic tools abnormal reading electrocardiography device essentially made similar predic tion life death consequences assisted doctors giving best treatment highest number people health insurance artificial intelligence deliver accurate predictions areas like healthcare ramifications insurance assess someone health accurately human physician excellent result people good health receive lower premiums benefiting insurance company due lower risk happens locates hard health problem insurer increases premium denies person coverage together order able deliver lower premiums customers increase profit australia prohibitions discriminating people pre existing conditions permissible insurers impose waiti period payouts people pre conditions ensure take insurance ahead expensive procedure rules one may become even important moving forward numerous medical technologies prove ability diagnose health problems thus improve ability calculate risk genetic screening one recent example technologies may boost accuracy risk assessments necessarily change nat ure insurance beyond context event dramatic leap accuracy health predictions regulatory responses may needed ensure people health problems priced insurance market present stage absent shift provision healthcare responses likely fit comfortably within existing legislation regarding insurance industry predictions consumer behaviour whether aware australians use social media search engines likely received targeted advertisements include adverts platforms giants google facebook pitched product based online activity provoke mixed feelings among consumer writing journal consumer preferences several scholars recently examined ability technologies accurately predict consumer behaviour provide targeted advertising state may short boon advertise come cost beyond immediate monetary input contend welfare benefits technologies backfire generate consumer reactance undermine sense autonomy consumers seek deci sionmaking may occur consumers feel deprived ability control choices predictive algorithms getting better better anticipating consumers preferences decision making aids often opa que consumers understand lot misunderstanding part consumers regarding techniques used determine preferences targeted advertising questioned senate facebook ceo mark zuckerberg repeatedly deny facebook messenger listens audio messages peo ple better sell adverts facebook appear mining audio messages company utilised machine learning predict users might change brand part loyalty prediction artificial intelligence australia ethics framework discussion paper page program offered advertisers laimed capabilities reported media leaked documents advertising data collection standards address capabilities ensure privacy protected crucial building trust consumers comp anies ensuring balance intrusive beneficial targeted advertising case study manipulating mood states perceptions users controversial research published peer journal used facebook platform demonstrate users moods manipulated filtering feeds comments videos pictures web links posted facebook friends reduced exposure feeds positive content led user posting fewer positive posts pattern occurred negative content study public criticised failing gain informed consent facebook users however setting aside issue informed consent study highlights power filtering practices shape user mood used enhance impact rgeted advertising technology beyond filtering news feeds manipulating video content real time research project called deep video portraits recently showcased international conference innovations animation computer graphics showed videos talking heads seamlessly altered technology produced subtle changes emotion tone diff icult distinguish real footage researchers contend technology used film industry technology also implications fake news phenomenon one deep video portraits researchers michael zollhofer stated press release ever video editing technology must also start critical video content consume every day especially proof examples show used slant information without user knowledge purpose influencing consumers media feel perceive reality manipulations calibre require new controls ensure users trust content receive infor med advertising tactics one potential approach could involve requirements information osted websites like facebook revealing techniques used enhance targeted advertisements measure would similar cookie law requires websites explain users information captured site used sophisticated techniques might required fake videos example defence advanced research projects agency runs program called media forensics developing tool detect doctored video clips key points driven human bias programmed humans susceptible biases programmers end making flawed judgments based flawed information ven information flawed priorities system aligned expectations fairness system deliver negative outcomes justice means like situations deliver like outcomes different situations deliver different outcomes means developers need pay special care vulnerable disadvantaged protected groups programming full transparency sometimes impossible undesirable consider privacy breaches lways ways achieve certain degree transparency take neural nets example complex open explain people would expertise understand anyway however input data explained outcomes system monitored impacts system artificial intelligence australia ethics framework discussion paper page reviewed internally externally consider system design suitable framework keeping transparent accountable necessary ensuring system operating fairly line australian norms values public trust key importance organisations would well advised beyond letter law instead follow best practice designing input data equally effective also varying levels invasiveness carefully consider whether alternative forms less invasive input data could yield equal better results ask less sensitive data could deliver necessary results know trade system using make active choices could justified court public opinion poorly system causes harm public ignorance unlikely acceptable defence artificial intelligence australia ethics framework discussion paper page current examples practice addition addressing ethical issues arisen data automated decisions predictive technologies important consider examples systems integrated ways already could potentially enormous impact society chapter discuss ethical issues associated enabled vehicles surveillance technologies key area focus ethical discussions often used examples areas need focussed attention governments help regulate use autonomous vehicles nave view avs beneficial beneficial deliberately make fighting traffic peter norto autonomous vehicles avs represent major possibility artificial intelligence applications transport however definition autonomy exists spectrum rather binary five levels vehicle autonomy defined society automotive engineers figure figure infographic showing five levels vehicle autonomy data source adapted society automated engineers artificial intelligence australia ethics framework discussion paper page autonomous vehicles australia australia transport ministers agreed phased reform program delivered national transport commission ntc support safe legal operation automated vehicles ntc recently published guidelines trialling automated vehicles australia guidelines describe application process request trial automated vehicles australian roads criteria must addressed applications include details trial location technology trialled traffic management plan infrastruc ture requirements trial organisations engage public manage changes course trial guideline intends support innovation create national set guidelines encourage investment australia global testbed automated vehicles level automated vehicles trials currently run melbourne perth sydney ntc also released policy paper helps clarify traffic laws applied vehicles automated functions point time particular paper clarifies responsibility human driver compliance road traffic laws vehicle conditional automat ion engaged point time recent release ntc addresses laws need changed suppor use automated vehicles ntc currently working several reports including need address insurance issues safety regulation vehicle data preparation changes automated cars bring minister infrastructure transport regional development announced upcoming opening new office future transpo technologies october upcoming initiatives help provide required foresight support enable australia keep pace rapidly changing capabilities automated vehicles costs benefits automated vehicles growing commercial inte rest around avs sales predicted reach million million however man artificial intelligence experts caution level autonomy still much away generally believed well technological barriers affordability capability accessibility avs along privacy concerns coul also impact ture uptake howev avs even without reaching level autonomy also potential deliver numerous social environmental financial benefits research found avs could ease congested traffic low reduce fuel consumption reduce travel costs lowering cost crashes travel time fuel parking enable smaller car fleet however additional convenience mobility afforded avs could also translate greater demand private vehicle travel public transport walking cycling safety represents another major potential benefit vehicle automation research found car crashes result human error fatal crashes caused distr action intoxication fatigue removing human driver equation therefore eliminate incidents estimates suggest full vehicle automation could reduce traffic accidents however also safety concerns surrounding avs especially since high incident march hit killed pedestrian preliminary report accident determine probable cause assign culpability note number design decisions could characterised questionable fact vehicle operator monitors interface via screen car also expected apply emergency braking necessary alerted artificial intelligence australia ethics framework discussion paper page system emergency braking needed avs also introduce issue cybersecurity hacking jeep cherokee demonstrating vulnerabil ity digitally connected cars ethical principles utomated vehicles avs machines make decisions accordance programming determined humans also subject complex difficult ethical considerations key ethical questions surrounding avs include car ogrammed take egalitarian approach maximising benefit highest number people negative approach maximising benefit occupant increasing risk everyone else car owners say setting car moral code situations harm humans unavoidable would acceptable avs perform ind prioritisation based age avs distribute risk driving instance would acceptable program car valued occupants pedestrians vice versa instances fatal crash march responsible harm caused operator car manufacturer relatively straightforward program avs accordance certain rules cross lane boundary collide pedestrians etc although arch crash shows technology still far perfect following rules dilemma situations represent cases rules followed kind decision made accordance ethical principles usually hierarchy constraints needed determine action prompted debate autonomous vehicle weigh outcomes cost human lives various situations accident inevitable utilitarianism maximising benefits reducing harm greatest number people without distinction strong principle underlying considerations ethics avs research mit found people favou utilitarian approach avs however participants approved utilitarian avs theory would like others buy would prefer ride avs protect occupants costs given car manufacturers therefore incentivised produce cars programmed prioritise occupant safety realisation utilitarian ethics avs likely brough regulation utilitarian principles also complex implement give rise ethical conundrums instance following principle harm reduction programmed hit motorcyclist helmet instead one without helmet since chance survival greater alternatively could argued avs possible choose hit cars greater crashworthiness development would disincenti vise purchase safer cars consequentialist approach uses single cost function human harm encodes ethics purely around principle reducing cost therefore broadly feasible utilitarianism consideration ethics avs recent study surveyed millions people across hundreds countries gauge moral preferences avs priorities event unavoidable acciden researchers used online survey get million responses hypothetical ethical dilemmas avs strongest preferenc sparing human lives animal lives sparing lives sparing young lives results indicated popular preference sparing lives children adults notably parts world saw eye avs ake life decisions eastern cultures young lives fit people artificial intelligence australia ethics framework discussion paper page given preference protection western cultures pede strians given extra weight southern cultures expressed stronger preference protecting women german ethics commission report germany became first country world attempt answer codify ethical questions set formal ethical guidelines avs drawn government committee comprised leg technical ethical experts full report contains propositions key among automated connected driving ethical perative systems cause fewer accidents human drivers positive balance risk hazardous situations protection human life must always top priority system must programmed accept damage animals proper conflict means personal injury prevented event unavoidable accident situations distinction individuals based personal features age gender physical mental constitution impermissible every driving situation must clearly regulated apparent responsible driving task human computer drivers must always able decide whether vehicle data forwarded used data sovereignty genuine dilemma situations decision human lives depend actual specific situation standardised programmed would desirable independent public sector agency systematically process lessons learned situations case automated connected driving systems accountability previously sole preserve individual shifts motorist manufacturers operators technological systems odies responsible taking infrastructure policy legal decisions one priority keep mind need uniform set regulations autonomous vehicles operating australian roads takes account australian vehicles may operating different road rules location manufactured ramifications side road vehicle drives presence roundabouts also global context consider road rules global ntext necessitates international collaboration australian government active participant work world forum harmon ization vehicle regulations safety regulations incorporated national law across many countries australia known australian design rules motor vehicle standards act addition another relevant working group global forum traffic safety outcomes working group affect rules made implemented australian state governments australian government becoming involved group rules considered relating autonomous vehicles australia vehicle safety regulations already based international standards longer term context autonomous vehicles likely australia take appropriate standardised international safety frameworks would som localised exceptions local legislation child seatbelts rules relating supply vehicles appropriate side road interim period regulatory processes developed within australia artificial intelligence australia ethics framework discussion paper page ntc currently process considering automated vehicle liability issues also considering regulati around safety assurance systems avs four potential reform options ranging baseline option using existing regulation manage safety right introduction regulatory system nationally managed point supply service would impose primary safety duty manufacturer automated driving system require certify avs adhere safety criteria interestingly report address ethical considerations regards avs stating safety dilemmas ethical implications already largely captured safety criteria safety criteria state avs must able detect appropriately respond variety foreseeable unusual conditions affecting safe operation interact predictable safe way road users road users include automated non vehicle vulnerable road users take steps towards achieving minimal risk condition operate safely prioritise safety strict compliance road traffic laws necessary uniformity also necessary regardless specific priorities chosen certain life scenarios vehicles using similar operating principles easily determine safest way spond given scenario different manufacturers creating autonomous vehicles operate different specifications likely safety would suffer personal identification surveillance ability face voice ven gait recognition systems provide immense potential track identify individuals cases technologies already operating australia without significant problems widespread public objection facial recognition technologies used austra lian airports aid check security immigration processes speed processing reduce costs maintaining security however significant privacy implications widespread use facial recognition technology extensive rules regarding earlier technologies identify individuals fingerprints many respects law caught technological capabilities facial recognition additional biometric information collected beyond fingerprints microsoft particular vocal expressing concern three key implications use facial recognition technology microsoft president brad smith stated first especially current state development certain uses facial recognition technology increase risk decisions generally outcomes ased cases violation laws prohibiting discrimination second widespread use technology lead new intrusions people privacy third use facial recognition technology government mass surveilla nce encroach democratic three uses facial recognition technologies broadly encapsulate challenges rolling technology without adequate oversight accountability mechanisms response growing interest technologies significant debate used australia artificial intelligence australia ethics framework discussion paper page case study surveillance technology crisis situations used service humanitarian objectives surveillance technolog ies facial pattern reco gnition geo mapping life tool event crisis overwhelming amount data collected analysed aid resolution situation well placed manage process trial operation police india test use facial recognition systems able scan faces children various children homes establish identities children registered missing bureaucratic difficulties different agencies courts delhi police able utilise two datasets children registe red missing children residing care institutions two databases able identify almost matches discussions underway use system identify missing children elsewhere india key ingredient outcome ability law enfor cement access datasets enabled surveillance may increase personal safety reduce crime need ensure privacy protected technologies used persecute groups critical author ities need give careful consideration use surveillance ensure appropriate balance struck protecting safety citizens adopting intrusive surveillance measures unfairly harm persecute innocent people monitoring employee behaviour westpac bank among companies australia exploring use facial recognition technologies monitor moods employees representatives indicated goal take pulse teams across organisation use facial recognition mood detection monitor employees used ways ethical unethical one way assess look goal exercise benefit welfare employees maximise profit ethics centre highlights fact technologies keep principle non mind designing technology effectively means humans merely become another part machine machine serve people way aroun addition nhmrc national statement ethical conduct human research states respect human beings involves giving due scope throughout research process capacity human beings make decisions researching utilising technologies monitor people emotions important ensure autonomy right make decisions respected say people smiles logged machine emplo yees disciplined happy enough goal put masquerade happiness please customers profit reasons machine treating humans another component profit outcome hand people emotional state assessed order deliver timely psychological assistance right time people facing stress emotional breakdown technology serving people instead could defended ethical grounds long respected autonomy individuals right choose participate police surveillance ability facial recognition technologies identify track suspects means increased police capabilities also need come commensurate oversight mechanisms particularly important artificial intelligence australia ethics framework discussion paper page given inaccuracies inequities observed application facial recognition technologies overseas united kingdom privacy advocates used freedom information requests gain access results facial recognition programs police report big brother watch indicated london metro area police use facial recognition proved inaccurate arrests made south wales technology inaccurate arrests made roughly number people scanned facial recognition technology innocent members public asked prove identity report pointed lack real statutor guidance use facial recognition technologies warned potential chilling effect people attendance public spaces know observed surveillance academics commissioned police assess use acial recognition systems south wales found helped arrests around suspects stressed required police adapt operating methods achieve results technology took time stated first matches proved accurate improved course project suggest technologies best thought assisted facial recognition tech nologies human still required confirm matches australia government considering implications facial recognition via identity matching services bill still discussion balancing privacy security groups human rights law council raised concerns ways personal biometric information may shared agencies suggest agencies consider framework put forward georgetown law cen ter privacy technology assesses risks involved police use facial recognition technology framework highlights five key risk factors consider targeted versus dragnet searches search convicted criminals suspects innocent people targeted versus dragnet databases database include many people possible including innocent people transparent versus invisible searches people know tha picture used search real time versus fact searches search past information tracking real time established use versus novel use different application facial recognition compared previous applications like fingerprinting australian authorities need give careful consideration use surveillance security ensure appropriate balance struck protecting safety citizens adopting intrusive surveillance measures privacy framework law enforcement incorporates new capabilities delivered facial recognition technologies could incorporate approaches like georgetown framework thus help ing agencies ensure facial recogni tion technologies used appropriate manner artificial intelligence employment two university oxford academics carl benedikt frey michael osborne published study examining impacts automation unique occupation ypes economy found risk replaced also found strong negative relationship automation risks wages lower pay jobs higher chance automated led concern artificial intelligence australia ethics framework discussion paper page around world possibilities higher rates unemployment university oxford study replicated multiple jurisdictions committee economic development australia ceda commissioned study australian economy found similar result workforce risk automation recent research published united kingdom global innovation foundation nesta suggest original university oxford paper many others used similar methodology overstated job losses automation nesta report points create many new jobs also notes jobs impacted disappear automation often requires new skills tasks job stays tact accountants lose jobs spreadsheets rather learned use got better jobs coming decade enablement similar impact recent meta study oecd published found jobs high risk automation another substantially changed whilst much debate many estimates higher lower weight evidence suggests around half jobs significantly impacted positively negatively automation digital technologies smaller still significant number jobs likely fully automated requiring workers transition new jobs new careers retraining reskilling strategic career moves help people achieve better employment outcomes recent study google consulting firm alpha beta finds australian workers average need increase time spent learning new skills lifetime job tasks change per decade much done governments companies individuals improve chances job retention successful career transition light automation one main issues importance acting early well job loss occurs ethical approach widespread automation tasks performed human workers requires helping workers transition smoothly proactively new jobs new careers gender diversity workforces another aspect relating employm ent ethics associated gender balance within workforces australia workplace gender equality agency indicated professional scientific technical services sector female full time female work ers receive less pay average male counterparts broken computer system design related services proportion women sector falls employees risk lack diversity designers developers results lack diversity products make many companies research organisations technology sector committed addressing gender imbalance government recognised australia must deeper stem talent pool supported development decadal plan women stem provide roadmap sustained increa ses women participation stem next decade benefits greater diversity ict workforce felt across many dimensions australian economy including artificial intelligence indigenous communities discussions protocols focused knowledge sharing management indigenous people science decision provide valuable insights frameworks applications context highlights three interrelated issues consider artificial intelligence australia ethics framework discussion paper page based data collected indigenous people needs consider data collected used complies indigenous cultural protocols human ethics appropriately protects indigenous intellectual property knowledge use highlighted discussion paper commissioned australia department industry innovation science indigenous knowledge held benefit community group whole strict protocols governing use indigenous knowledge directed gaining community approval guidelines ethical research australian indigenous studies offer useful starting point guide effort information intelligence analytical proces indigenous knowledge categorised labelled shared incorporated learning feedbacks guided cross collaborative approaches way indigenous knowledge used direct bearing way collected uses indigenous knowledge would considered acceptable communities drawn meaning uses would need clarified upfront needs open accountable indigenous people organisati ons clear learning generated information used inform decisions affect indigenous estates lives principles outlined document provide guidance properly collect handle indige nous knowledge means end point consideration net benefits need place strong emphasis application information impacts communities provide research relationship indigenous knowledge crucial establishing proper standards codes conduct key points autonomous vehicles require hands safety governance management authorities systems need make choices react different circumstances system without cohesive set rules likely deliver worse outcomes optimised australian road rules conditions surveillance technologies consider non key principle technology treat human beings one cog service goal goal serve best interests human beings many ways biometric data replacing fingerprints key tool identification biome tric data includes fingerprints use elements like facial recognition ease voice face gait recognition systems identify people poses enormous risk privacy technologies considered isolation also need take account context used technologies complement various factors used assess risks facial recognition system designers thes systems consider factors workers society get better outcomes take proactive measures assist smooth career transitions gender imbalance terms numbers salaries technical workforces may need addressed applied within indigenous communities needs take account cultural issues importance artificial intelligence australia ethics framework discussion paper page proposed ethics framework always life people want simple answer like lovely quote every complex problem life always simple answer always wrong susan greenfield valuable tool harnessed one used many different goals already companies government agencies finding increasing reliance stems automated decisions creating ethical issues requiring resolution significant ramifications daily lives fundamental human rights economic prosperity australians considered timely response required eight core principles referred throughout report used ethical framework guide organisations use development systems principles seen goals define whether system operating ethically chapt report highlighted specific principles associated case studies dis cussions contained within important note principles considered throughout design use system jus discussed detail chapter generates net system must generate benefits people greater costs harm civilian systems must designed harm deceive people implemented ways minimise negative outcomes regulatory legal compliance system must comply relevant international australian local federal government obligations regulations laws privacy protection system including systems must ensure people private data protected kept confidential plus prevent data breaches could cause reputational psychological financial professional ther types harm person fairness deve lopment use system must result unfair discrimination individuals communities groups requires particular attention ensure training data free bias characteristics may cause algorithm beha unfairly transparency explainability people must informed algorithm used impacts provided information information algorithm uses make decisions contestability algo rithm significantly impacts person must efficient process allow person challenge use output algorithm accountability people organisations responsible creation implementation algorithms identifiable accountable impacts algorithm artificial intelligence australia ethics framework discussion paper page putting principles practice principles provide goals work towards goals alone enough remainder section explore ways individuals team organisations reach goals support practical application core ethical principles toolkit referenced throughout report potential instruments action toolkit address potential solution regarding governance australia intended provide platform upon build knowledge expertise around ethical use development australia unlikely one size fits approach add ress ethical issues associat addition approaches taken address issues unlikely remain static time chapter provides uidance individuals teams responsible aspect design development deployment system interfaces humans help practitioners address three important questions purpose system relevant principles guide ethical use application system assess requirements meeting ethical principles tools processes employed ensure system designed implemented deployed ethical manner additionally sample risk framework guide governance teams assessing levels risk system would invite stakeholders part public consultation share thoughts expertise ethical practically implemented impact assessments auditable assessments potential direct indirect impacts address potential negative impacts individuals communities groups alo mitigation procedures algorithmic impact assessments aia designed assess potential impact system public often used assess automated decis ion systems used governments institute developed aia urging recently appointed new york city nyc task consider using framework ensure automated decision systems used nyc government made according principles equi fair ness accountability four key goals institute aia respect public right know systems impact lives publicly listing describing automated decision systems significantly affect individuals communities increase public agencies internal expertise capacity evaluate systems build procure anticipate issues might raise concerns disparate impacts due process violations ensure greater accountability automated decision systems providing meaningful ongoing opportunity external researchers review audit assess systems using methods allow identify detect problems ensure public meaningful opportunity respond necessary dispute use given system agency approach algorithmic accountabilit artificial intelligence australia ethics framework discussion paper page addition assessing algorithms impact assessments designed address important ethical issues associated office australian information commissioner oaic developed privacy impact assessment identify impact project could individual privacy also affiliated elearning guide help provide guidance organisations privacy design approaches data use adoption use standard auditable impact assessments organisations developing using australia would help encourage accountability ensure ethical principles considered addressed implemented review processes specialised professionals groups review use systems ensure adhere ethical principles australian policies legislation many cases australia likely importing shelf developed internationally different regula tory frameworks cases adequate review process key ensuring technology meets australian standards adheres ethical principles alternatively cases may permissible use programs review syst ems several companies developed tools able effectively assess algorithms used ais report system operating whether acting fairly bias ibm released open source cloud based software creates easy use visual representation shows algo rithms generating decisi ons addition assess algorithm accuracy fairness performance microsoft google working similar tool assess algorithms bias use technologies could improve ability efficiently effectively objectively review components ensure key ethical principles however utilised enabled technologies would require significant degree scrutiny ens ure flaws purporting assess risk assessments assessment largely exercise accounting addressing risks pos use technology consideration given whether certain uses require additional assessment may considere threshold assessments fatml developed social impact statement details requirements developers consider impacted algorithm responsible impact similar assessments may well placed identify high risk applications uses require additional monitoring review additional potential risks used vulnerab populations minorities cases consider whether additional scrutiny required ensure fair example conducting research involving human participants additional considerations must made dealing ulnerable groups minorities one argument concept risk based levels assessment standard level assessment ensure across spectrums acting used according key ethical principles perhaps expect standard prescribed course action rigorous enough ensure low high risk adheres core ethical principles artificial intelligence australia ethics framework discussion paper page best practice guidelines involves development accessible cross industry best practice principles help guid developers users gold standard practices best practice guidelines encompass best available evidence information inform practice example office australia fair work ombudsman published various best practice guides employers employees help identify implement best practice itiatives workplaces similar guidelines could developed provide best practice initiatives support ethical use development use adaptable flexible best practice guides rather rigid policies fit well dynamic nature ifficulty predic ting coming next would straightforw ard adjust best practice guidelines situations scenarios change time australian government already developed best practice guide provide strategies information best practice use technology make automa ted cisions agencies similar guidelines could developed promoted support consideration core ethical issues associated use development education training standards standards certification systems actively explored nationally internationally australia provision certification standards generally overseen relevant industry bodies doctors accountable medical dies extensive regulations behaviour australian medical association code ethics guidance electricians plumbers people involved air repair require certificati demonstrate ski lls guarantee public safety states various requirements regarding certificati repairing motor vehicles engineers australia provides accreditatio programs train engineers coordinati international standards industry bodies data governance australia examining data principles one area implementation standards could large positive impact ethical austral relates data scientists currently agreed upon accreditation standards govern data science profession designers algorithms may significant impacts public operating within profession latively limited guidance oversight australia national standards body standards australia working industry stakeholders developing standards roadmap guide development australian position standards alan finkel australia chief scientist also proposed framework voluntary certification ethical qualified experts office currently exploring internationally international standards organisation iso technical mmittee australia observer developing standards iso jtc artificial intelligence includes technical ethical standards significant scope within australia provide guidance rmulation standards govern designers systems business academic collaboration australia key focus australia national innovation science agenda promotion collaboration funding incentives university funding allocated research done partnership industry invest long critical world research infrastructure artificial intelligence australia ethics framework discussion paper page ensure researchers access infrastructure need one initiative provision intellectual property toolkit help resolve complex issues arise industry academics collaborate australian technology network partnership several innovative universities committed developing collaboration industry recent report put forward five recommendations foster relationships expand place supporting structures deepen phd university collaboration indust ensure initiatives targeting phd employability broad scale link portion phd scholarships industry collaboration implement national communication strategy improve awareness develop deeper understanding industry phd qual ity research addressing ethical design implementation key ensuring austr alia stays ahead curve without methods accessible transfer knowledge theory practice impact lost collaboration increasingly mportant researchers tech industry ensure developed used ethically prioritised monitoring consists regular monitoring automated decision systems accuracy fairness suitability task hand also involve consideration whether original goals algorithm still relevant promotion regular assessment systems used key tool ensure core ethical princ iples addressed although initial assessments deployment critical unlikely provide scope needed assess ongoing impact changing world regular monitoring assess whether still suitable task hand whether still adheres core ethical principles could encouraged best practice guidelines part ongoing impact assessments recourse mechanisms avenues appeal automated decision use negatively affects member public gdpr data protection act include requirement individuals informed use automated decisions affect provide opportunity contest findings recourse mechanisms promote transparency organisations using automated decisions users affected systems also engender trust individuals organisations could used improve public acceptance use provision recourse mechanisms become increasingly important cases black box algorithms process system came decision judgement elucidated may important consider may additional complexities assoc iated provision recourse mechanisms situations systems found faulty demands could made compensation damages incurred result impact system individual ties principle suitability systems need ensure appropriate artificial intelligence australia ethics framework discussion paper page task hand perform manner cause unacceptable levels harm weighed benefits use consultation without public support destination momentum building investing avenues public feedback dialogue key ensuring development use line australians want tool related principle net benefit need systems generate benefits greater costs discussed global symposium regulators regards public consultation keep open door open mind comes one understands problems let alone solutions hearing many perspectives possible expose policymakers regulators issues may radar creative solutions may tried herwise solutions may require law regulation regular large scale cons ultation various stakeholders including general public academics indust members critical importance whe developing regulations diverse range inputs collected diverse group stakeholders various organisations developing materials provide information ethics included lengthy consultation process courted input diverse ried sources cons ultation valuable tool help better understand spectrum ideas concerns solut ions regarding ethic artificial intelligence australia ethics framework discussion paper page example risk assessment framework systems risk assessments commonly used assess risk factors potential cause harm assessment larg ely exercise accounting addressing risks posed use system also useful provide threshold trigger additional action risk mitigation processes preliminary guide individuals teams responsible aspect design development eployment system interfaces humans purpose guide practitioners address three questions purpose system relev ant principles guide ethical use application sys tem tools processes employed ensure system designed implemented deployed ethical manner one example framework stand frameworks tailored individual applicatio first table examines probability risk together consequence risk high probability occurring negative outcomes consequences become severe likelihood risk consequence insignificant risk minor risk moderate risk major risk critical risk rare low low moderate high high unlikely low moderate moderate high extreme possible low moderate high high extreme likely moderate high high extreme extreme almost certain moderate high high extreme extreme second table examines factors cause application contain risk rows near top carry rela tively little risk rows near bottom contain risk different scenarios may contain les risk depending individual circumstances guide provides general overview areas likely contain risks ought considered implementation also worth noting although column number peop affected severe repercussions single person would still viewed major critical consequence artificial intelligence australia ethics framework discussion paper page privacy protection fairness physical harm contestability accountability regulatory legal compliance transparency explainability number people affected insignificant private sensitive data used insignificant effect person human rights insignificant application control influence systems insignificant application operates opt basis intervention required reverse outcome event someone decides opt insignificant clear accountability outcomes insignificant consent gained use data application operates familiar legal territory insignificant inputs algorithm output bounded well understood insignificant application affect individuals minor uses small number people private data minor clear opt opt application minor application controls equipment incapable causing significant harm public nuisance surveillance minor application automatically opts people clear notification easy opt easy obtain human assistance minor legal precedent similar outcomes clear chain responsibility minor identical similar application legal recedent demonstrating compliance consent clearly gained minor application uses difficult like neural nets inputs clear cases totally unexpected inexplicable outputs minor application run within organisation affect small number people major uses large number people private data major opt application unclear minor application may control heavy equipment hazardous material limited potential harm people cause public nuisance major application used widely among public little human resources available assistance appeal minor reasonably clear delineation accountability users developers minor little legal precedent application extensive legal advice sought application reviewed third parties minor application unexpected outputs periodically reviewed understood external review collaboration fostered minor algorithm affect small community people use major application designed way makes likely gather information individuals without express consent major person choice application effect single person human rights major application controls heavy equipment hazardous material expected operate public space major easy way opt major little legal precedent application separation accountability users developers major legal precedent application third parties legal experts consulted consent unclear major application outputs inexplicable review limited effectiveness understanding major application affect large number people around country critical uses major database private sensitive health data critical effect large population human rights critical application control quipment could cause loss life equipment designed secretly gather personal information critical outcomes application opt person affected recourse change outcome critical unclear legal accountability outcomes critical consent gained use large quantities private data clear legal precedent critical inputs uncontrolled algorithm well understood outputs understood critical application affects national global audience people artificial intelligence australia ethics framework discussion paper page variety actions taken mitigate risk many explored thi report measures means comprehensive external organisations yield additional solutions many cases additional measures may also emerge wit new research technologies practices risk actions low internal monitoring testing review industry standards moderate internal monitoring consider lower risk risk mitigation plan internal review testing impact assessments external review high monitoring consider lower risk risk mitigation plan impact assessments internal external review testing consultation specialists detailed plan additional human resources handle legal advice sought liaise industry partners government bodies best practice extreme unacceptable risk invite stakeholders part public consultation share thoughts expertise ethical practically implemented artificial intelligence australia ethics framework discussion paper page conclusion humans allergic change love say always done way try fight clock wall runs counter grace hopper framework discussion paper intended guide australia first steps journey towards integrating policies strategies provide landscape suppo rts positive development use principles tool kit items provide practical accessible approaches harness best offer australia addressing risks opportunity one potential provide better future fairer processes tools address important environmental social issues howev reaching future require input stakeholders across government business academia broader society developers expected bear responsibility achieving outcomes collaboration utmost importance reaching goals artificial intelligence australia ethics framework discussion paper page references ethics commission federal ministry transport digital infrastructure automated connected driving german government germany new york city hall mayor blasio announces first task force examine automated decision systems used city mayor office house lords select committee artificial intelligence ready willing able parliament united kingdom european commission artificial intelligence europe canadian institute advanced research pan artificial intelligence strategy australian government budget overview canberra national institute transforming india national strategy artificial intelligence villani meaningful artificial intelligence rosemain rose france spend billion compete chi reuters march japanese society artificial intelligence japanese society artificial intelligence ethical guidelines japan european commission high expert group artificial intelligence parl iament world first centre data ethics innovation government statement infocomm media development authority composition advisory council ethical use artificial intelligence data minister communications information singapore state council people republic china guidelines ensure safe self vehicle tests state council people republic china people republic china senate community affairs comm ittee secretariat design scope cost analysis contracts awarded implementation associated better management social welfare system initiative parliament australia angwin larson mattu machine bias risk assessments criminal sentencing propublica dieterich mendoza brennan compas risk scales demonstrating accuracy predictive parity northpointe angwin larson propublica responds company critique machine bias story propublica angwin larson bias criminal risk scores mathematically inevitable researchers say propublica office australian information commissioner publication medicare benefits schedule pharmaceutical benefits schedule data commissioner initiated investigation report australian government australian government international human rights system attorney general department australian government privacy act amended australian government canberra corbett pierson feller computer program used bail sentencing decisions labeled biased blacks actually clear washington post moses chan algorithmic prediction policing assumptions evaluation accountability policing society australian government social security administration act federal register legislation reisman schultz crawford algorithmic impact assessments practical framework public agency accountability kleinman ibm launches tool aimed detecting bias khadem tax office computer says federal court says abc october artificial intelligence australia ethics framework discussion paper page human rights law centre dangers unregulated biometric use submission inquiry identity services bill australian passports amendment identity ser vices bill human rights law centre australia awad dsouza kim moral machine experiment nature berg buffie zanna fear robot revolution correct answer yes international monetary fund csiro robots resqu rainforests csiro ray data guru living als modernizes industries typing eyes microsoft news international electrotechnical commission functional safety iec redrup google make accessible businesses cloud automl australian financial review australian human rights commission human rights technology issues paper sydney mccarthy minsky roch ester proposal dartmouth summer research project artificial intelligence beard longstaff ethical design principles good technology ethics centre sydney australia kranzberg technology history kranzberg laws technology culture dutton overview national strategies medium internet available british broadcasting corporation google deepmind nhs app test broke privacy law united kingdom elvery algorithms make important governmen decisions affects abc australia australian government automated assistance administrative decision international covenant civil political rights united nations international covenant economic social cultural rights united nations international convention elimination forms racial discrimination united nations convention elimination forms discrimination ainst women united nations convention torture cruel inhuman degrading treatment punishment united nations convention rights child united nations united nations convention rights persons disabilities united nations united nations universal declaration human rights united nations australian government human rights parliamentary scrutiny act federal register legislation australian government statements compatibility attorney general department australia attorney department australia anti law australian government australia cossins discriminating algorithms times showed prejudice new scientist australian government productivity commission data availability use productivity commission inquiry report department prime minister cabinet new australian government data sharing release legislation issues paper consultation australian government canberra office victorian information commissioner artificial intelligence privacy office victorian information commissioner victoria australian government privacy act federal register legislation australian government australian privacy principles office australian information commissioner australian governme credit reporting office australian information commissioner australian government tax file numbers office australian information commissioner artificial intelligence australia ethics framework discussion paper page australian government health information medical research office austr alian information commissioner european union art gdpr automated individual decision including profiling wachter mittlestadt floridi right explanation automated decision exist general data protection regulation international data privacy law european group ethics science new technologies statement artificial intelligence robotics systems european commission brussels european commission high level expert group draft ethics guidelines trustworthy villani meaningful artificial intelligence towards french european strategy french government belot piper kesper decide would let car determine dies whittlestone nyrup alexandrova ethical societal implications algorithms data artificial intelligence roadmap research ieee ieee global initiative thics autonomous intelligent systems ieee standards association ieee global initiative ethics autonomous intelligent systems ethically aligned design vision prioritizing human well autonomous intellig ent systems ieee global initiative ethics autonomous intelligent systems ethically aligned design vision prioritizing human well autonomous intelligent systems campolo sanfilippo whittaker report institute whittaker crawford dobbe report stone brooks brynjolfsson one hundred year study artificial intelligence report study pane stanford university stanford usa future life institute asilomar principles public voice universal guidelines artificial intelligence electronic privacy information center brussels belgium partnership partnership web page available pichai google principles google specktor google partnership military live science newcomer google principles left bloomberg greene google principles developing good enough next web hern whatever happened deepmind ethics board google promised smith facial recognition time action microsoft issues official microsoft blog microsoft approach website ibm eryday ethics artificial intelligence dafoe governance research agenda future humanity institute oxford bostrom yudkowsky ethics artificial intelligence cambridge handbook artificial intelligence cambridge university press initiative initiative recommendations future society harvard kennedy school nguyen solomon emerging issues data collection use sharing consumer policy research centre aust ralia european commission european commission gdpr home page august available reform government data protection act rosenberg confessore cadwalladr trump consultants exploited fac ebook data millions new york times vengattil cambridge analytica begins insolvency proceedings financial review artificial intelligence australia ethics framework discussion paper page bhardwaj eight weeks cambridge analytica scandal facebook stock price bounces back controversy business insider australia australia government privacy amendment notifiable data breaches act office australian information commissioner notifiable data breaches quarterly statis tics report april june australian government institute ponemon institute cost data breach study australia united states government accountability office data protection actions taken equifax federa agencies response breach government newman equifax officially excuse wired fleishman equifax data breach one year later obvious errors real changes new report says fortune aust ralian government australian government public data policy statement department prime minister cabinet australian government response productivity commission data availability use inquiry australian governme canberra treasury consumer data right australia open knowledge network global open data index place overview hauge stevenson rossmo tagging banksy using geographic profiling investigate modern art mystery journal spatial science balthazar harri prater protecting patients interests era big data artificial intelligence predictive analytics journal american colleg radiology part harvard business school digital initiative tay crowdsourcing nightmare harvard business school calmon wei vinzamuri optimized pre discrimination preve ntion neural information processing systems conference rahwan society programming algorithmic social contract ethics information technology gunning explainable artificial intelligence xai fense advanced research projects agency langford houston schools must face teacher evaluation lawsuit courthouse news service parasuraman riley humans automation use misuse disuse abuse human factors skitka mosier burdick automation bias decision international journal human studies national transportation safety board enbridge incorporated hazardous liquid pipeline rupture release wesley dau complacency automation bias enbridge pipeline disaster ergonomics design perry idecide legal implications automated decision cambridge public law conference national transportation safety board preliminary report highway smith automated driving product liability michigan state law review burns judges common sense judicial cognition griffith law view danziger levav avnaim extraneous factors judicial decisions pnas corbyn hungry judges dispense rough justice nature internet available weinshall shapard overlooked factors analysis parole decisions pnas greenwood eaking remarks art decision federal court australia digital law library australian human rights commission quick guide australian discrimination laws world health organisation skin cancers risk getting skin cancer artificial intelligence australia ethics framework discussion paper page angwin larson tiger mom tax asians nearly twice likely get higher price princeton review propublica stobbs hunter bagaric sentencing enhanced use artificial intelligence criminal law journal australian federal police policing safer australia strategy future capability australian federal police supreme court united states blog loomis wisconsin tition certiorari denied june carlson need transparency age predictive sentencing algorithms iowa law review lohr facial recognition accurate white guy new york times dastin amazon scraps secret recruiting tool showed bias women reuters october anz organisations turning artificial intelligence improve recruitment processes benefit candidates efinancialcareers stanley new orleans program offers lessons pitfalls predictive policing aclu delaney france china strategy lapowsky lapd uses data predict crime wired may crockford app data predicts brisbane criminals strike next sydney morning herald october shakila khan rumi flora dilys salim crime event prediction dynamic featur epj data science chen doctors said coma patients would never wake said would south china morning post september federal register legislation private health insurance act compliat ion andr carmon wertenbroch consumer choice autonomy age artificial intelligence big data customer needs solutions bloomberg government transcript mark zuckerberg sen ate hearing washington post hern facebook feature claims predict user future behaviour guardian kramer guillory hancock experimental evidence massive emotional contagion social networks pnas kim garrido tewari deep video portraits siggraph could make dodgy lip sync dubbing thing past university bath united kingdom european commission internet handbook cookies european commission knight defense department produced first tools catching deepfakes mit technology review usa society automotive engineers taxonomy definitions terms related motor vehicle automated driving systems national transport commission automated vehicles australia national transport commission guidelines trials automated vehicles australia national transport commission clarifying control automated vehicles policy paper national transport commission changing driving laws support automated vehicles policy paper johnston federal govt unveils future tran sport tech office itnews bloomberg philanthropies taming autonomous vehicle primer cities aspen institute center urban innovation usa ackerman toyota gill pratt self cars reality full aut onomy ieee spectrum mervis going fast driverless cars science marowits self ubers could still many years away says research head ctv news canada truett worry autonomous cars coming tomorrow next year autoweek artificial intelligence australia ethics framework discussion paper page litman autonomous vehicle implementation predictions implications transport planning victoria transport policy intitute victoria stern cui delle monache dissipation stop waves via control autonomous vehicles field experiments transportation research part emerging technologies fagnant kockelman preparing nation autonomous vehicles opportunities barrie policy recommendations capitalizing self vehicles transportation international transport forum big data transport understanding assessing options oecd publishing paris france schoettle ivak potential impact self vehicles household vehicle demand usage university michigan transportation research institute michigan usa trommer kolarova fraedrich autonomous driving impact vehicle automation mobility behaviour institute mobility research berlin germany truong gruyter currie estimating trip generation impacts autonomous vehicles car travel victoria australia transporta tion department transportation critical reasons crashes investigated national motor vehicle crash causation survey national highway traffic safety adiministration center statistics analysis washing ton bertoncello wee ten ways autonomous driving could redefine automotive world mckinsey company overly uber suspends testing self cars crash sydney morning herald australia green berg jeep hack chrysler recalls vehicles bug fix wired bogle driverless cars ethical questions risk safety trust still need answer australian broadcasting corporation australia bonnefo shariff rahwan social dilemma autonomous vehicles science ackerman people want driverless cars utilitarian ethics unless passenger ieee spectrum goodall ethics automated vehicles road vehicle automation springer gerdes thornton ethics autonomous vehicles maurer markus autonomes fahren technische rechtliche und gesellschaftliche aspekte berlin heid elberg springer berlin heidelberg commission topics safety assurance system automated vehicles commission current projects motor accident injury insurance automated vehicles national transport commission afety assurance automated driving systems decision regulation impact statement national transport commission melbourne australia reyes vera scully analysis spatio representations robust footstep recognition deep residual neural networks ieee qantas facial recognition qantas travel advice department home affairs using face recognition technology arrivals smartgate australian government times ndia delhi facial recognition system helps trace missing children times india india dehli dockrill thousands vanished children india identified new technology sciencealert may eyers stpac testing monitor staff customers australian financial review national health medical research council updated national statement ethical conduct human research big brother watch face lawle growth facial recognition policing davies dawson innes facial recognition technology aids police georgetown law center perpetual line unregulated police facial recognition america georgetown law center privacy technology artificial intelligence australia ethics framework discussion paper page frey osborne future employment susceptible jobs computerisation technology oxford martin programme impacts future oxford durrant mccalman han impact computerisation automation future employment committee economic development ceda nedelkoska quintini automation skills use training working paper number organisation economic ooperation development paris nesta future skills employment nesta london oecd transformative technologies jobs future canadian innovation ministers meeting organisation economic cooperation development paris alphabeta future skills adapt future work australians undertake third education training change learn prepared alphabeta google australia sydney workplace gender equality agency professional scientific technical services summary robinson mckaige barber report national indigenous fire owledge fire management forum building protocols practical experiences darwin northern territory february csiro northern australia environmental resources hub australia janke legal protection indigenous knowle dge australia australian institute aboriginal torres strait islander studies guidelines ethical research australian indigenous studies australian institute aboriginal torres strait islander studies canberra australia reed regulate artificial intelligence philosophical transactions royal society mathematical physical engineering sciences government canada algorithmic impact assessment governm ent canada canada office australian information commissioner guide undertaking privacy impact assessments australia office australian information commissioner privacy impact assessment elearning varshney introducing fairness ibm fairness accountability transparency machine learning principles accountable algorithms social impact statement algorithms fair transparent machine learning national health medical research council australian research council australian vice committee updated may national statement ethical conduct human research national health medical research council canberra fair ombudsman best practice guides australian government australia erdelyi goldsmith regulating artificial intelligence proposal global solution conference artificial intelligence ethics society administrative rev iew council automated assistance administrative decision making report administrative review council canberra australian medical association ama code ethics australian medical association australia department ucation training licensing process gaining current identified australian occupational licence australian government australia department mines industry regulation safety motor vehicle repairer certificate government wester australia australia engineers australia program accreditation overview available data governance australia leading practice data principles available department industry innovation scie nce national innovation science agenda australian government australia australia department industry innovation science newly updated toolkit live australia australia australian technology network universities enhancing value phds australian industry australian technology network universities australia artificial intelligence australia ethics framework discussion paper page gasser budish ashar module setting stage governance interfaces infrastructures ins titutions policymakers regulators international telecommunications union artificial intelligence australia ethics framework discussion paper page appendix stakeholder expert consultation targeted consultations invited representatives universities institutes industry government conducted across four australian capital cities melbourne brisbane perth sydney workshops key component developing cohesive representative narrative accurately captured perspectives priorities various australian stakeholders addition four consultation sessions advisory technical expert groups engaged development report figure figure pie charts onsultation attendee demographics note total persons consulted workshops additional consultations held industry research government experts consultation approach consultations run informal workshops focused collaborative generative approach participants encouraged share ideas develop collaborate others workshops began presentation introducing topic well objectives structures ethics framework following presentation participants given opportunity question interrogate approach reports appropriate feedback integrated int reports following presentation first discussion session participants given opportunity group together discuss perspectives biggest opportunities australia use adoption factors hat could enable inhibit adoption second discussion session participants asked consider perspectives risk mitigation measures needed ensure wide societal benefits adoption workshops provided robust dialogue diverse perspectives across discussion sections resulted informative snapshot australia unique opportunities challenges key themes prioritization key participants acknowledged need prior itise investment focussed strategic areas take advantage australia unique opportunities address challenges brisbane sydney perth melbourne industry government universities artificial intelligence australia ethics framework discussion paper page whilst opinions domains focus varied reaffirmed investment conducted conjunction major initiatives across australian landscape several discussions potential australia leader integration addition development particularly across primary industries suggestions also made australia potential play world leading role ethical responsible need skilled workers participants recognised significant knowledge gap current workforce whole future skills curriculum next generation knowledge workers needed addressed responsibility ensuring australia strong technically workforce seen shared responsibility across sectors collaboration multidisciplinary approaches required across sectors city need australia develop much stronger collaboration within sectors stated reiterated strong appetite connect industry searchers involved workshops lack infrastructure encourage engagement remove friction need initiatives could help coordinate sectors could work together projects rather compete multi nature discussed along need collaborative approaches ensure australia optimise use adoption positive way data governance discussion focussed steps need made ensure data privacy regulations adhered without limiting development adoption addition need address lack large datasets australia affect ability compete development global scale embracing healthy appreciation strategies mitigate risks demystify artificial intelligence included ensuring adhered ethical principles fairness transparency raised coul limit opportunity australia play leading role nimble responsive frameworks would serve better discussion around need cohesive nationwide approach addressing ethical issues associated use option every session need use good suggested discussed participants particular need use address australia sustainability environmental issues discussed session contact csiroenquiries extraordin ary every day innovate tomorrow help improve today customers australians world imagine collaborate innovate informat ion stefan hajkowicz
