toronto declaration skip main content toronto declaration english français عربى human rights resources contact community authors endorsers toronto declaration toronto declaration english français عربى human rights resources contact community community authors endorsers toronto declaration protecting right equality machine learning systems preamble machine learning systems advance capability increase use must examine impact technology human rights acknowledge potential machine learning related systems used promote human rights increasingly concerned capability systems facilitate intentional inadvertent discrimination certain individuals groups people must urgently address technologies affect people rights world machine learning systems bear accountability harming human rights discourse around ethics artificial intelligence continues declaration aims draw attention relevant framework international human rights law standards universal binding actionable laws standards provide tangible means protect individuals discrimination promote inclusion diversity equity safeguard equality human rights universal indivisible interdependent declaration aims build existing discussions principles papers exploring harms arising technology significant work done area many experts helped raise awareness inform discussions discriminatory risks machine learning systems wish complement existing work reaffirming role human rights law standards protecting individuals groups discrimination context human rights law standards referenced declaration provide solid foundations developing ethical frameworks machine learning including provisions accountability means remedy policing welfare systems healthcare provision platforms online discourse name examples systems employing machine learning technologies vastly rapidly reinforce change power structures unprecedented scale significant harm human rights notably right equality substantive growing body evidence show machine learning systems opaque include unexplainable processes contribute discriminatory otherwise repressive practices adopted implemented without necessary safeguards states private sector actors promote development use machine learning related technologies help people exercise enjoy human rights example healthcare machine learning systems could bring advances diagnostics treatments potentially making healthcare services widely available accessible relation machine learning artificial intelligence systems broadly states promote positive right enjoyment developments science technology affirmation economic social cultural rights focus declaration right equality numerous human rights may adversely affected use misuse machine learning systems including right privacy data protection right freedom expression association participation cultural life equality law access effective remedy systems make decisions process data also undermine economic social cultural rights example impact provision vital services healthcare education limit access opportunities like employment declaration focused machine learning technologies many norms principles included equally applicable technologies housed broader term artificial intelligence well related data systems declaration using framework international human rights lawthe right equality discriminationprotecting rights individuals groups promoting diversity inclusionduties states human rights obligationsstate use machine learning systemspromoting equalityholding private sector actors accountresponsibilities private sector actors human rights due diligencethe right effective remedyconclusionreferences download toronto declaration pdf using framework international human rights law states obligations promote protect respect human rights private sector actors including companies responsibility respect human rights times put forward declaration affirm obligations responsibilities many discussions taking place supranational state regional level technology companies academic institutions civil society beyond focusing ethics artificial intelligence make technology field issues must analyzed human rights lens assess current future potential human rights harms created facilitated technology take concrete steps address risk harm human rights law universally ascribed system values based rule law provides established means ensure rights upheld including rights equality nature universally binding actionable set standards particularly borderless technologies human rights law sets standards provides mechanisms hold public private sector actors accountable fail fulfil respective obligations responsibilities protect respect rights also requires everyone must able obtain effective remedy redress rights denied violated risks machine learning systems pose must urgently examined addressed governmental level private sector actors conceiving developing deploying systems critical potential harms identified addressed mechanisms put place hold responsible harms account government measures binding adequate protect promote rights academic legal civil society experts able meaningfully participate discussions critique advise use technologies right equality declaration focuses right equality critical principle underpins human rights discrimination defined international law distinction exclusion restriction preference based ground race colour sex language religion political opinion national social origin property birth status purpose effect nullifying impairing recognition enjoyment exercise persons equal footing rights list united nations high commissioner human rights recognized necessity preventing discrimination additional classes preventing discrimination governments obligations private sector actors responsibilities proactively prevent discrimination order comply existing human rights law standards prevention sufficient satisfactory discrimination arises system interrogated harms addressed immediately employing new technologies state private sector actors likely need find new ways protect human rights new challenges equality representation impact diverse individuals groups arise existing patterns structural discrimination may reproduced aggravated situations particular technologies example machine learning system goals create markers success reinforce patterns inequality issues arising using biased datasets actors public private must prevent mitigate discrimination risks design development application machine learning technologies must also ensure mechanisms allowing access effective remedy place deployment throughout system lifecycle protecting rights individuals groups promoting diversity inclusion declaration underlines inclusion diversity equity key components protecting upholding right equality must considered development deployment machine learning systems order prevent discrimination particularly marginalised groups collection data help mitigate discrimination groups collecting data discrimination poses particular difficulty additional protections must extend groups including protections sensitive data implicit inadvertent bias design creates another means discrimination conception development end use machine learning systems largely overseen particular sector society technology present largely developed applied reviewed companies based certain countries regions people behind technology bring biases likely limited input diverse groups terms race culture gender backgrounds inclusion diversity equity entails active participation meaningful consultation diverse community including end users design application machine learning systems help ensure systems created used ways respect rights particularly rights marginalised groups vulnerable discrimination duties states human rights obligations states bear primary duty promote protect respect fulfil human rights international law states must engage support discriminatory otherwise actions practices designing implementing machine learning systems public context partnerships states must adhere relevant national international laws regulations codify implement human rights obligations protecting discrimination related rights harms example data protection privacy laws states positive obligations protect discrimination private sector actors promote equality rights including binding laws state obligations outlined section also apply public use machine learning partnerships private sector actors state use machine learning systems states must ensure existing measures prevent discrimination rights harms updated take account address risks posed machine learning technologies machine learning systems increasingly deployed implemented public authorities areas fundamental exercise enjoyment human rights rule law due process freedom expression criminal justice healthcare access social welfare benefits housing technology may offer benefits contexts may also high risk discriminatory outcomes critical states provide meaningful opportunities effective remediation redress harms occur confirmed human rights committee article international covenant civil political rights prohibits discrimination law fact field regulated protected public authorities set treaties dealing specific forms discrimination states committed refrain engaging discrimination ensure public authorities institutions act conformity obligation states must refrain altogether using requiring private sector use tools discriminate lead discriminatory outcomes otherwise harm human rights states must take following steps mitigate reduce harms discrimination machine learning public sector systems identify risks state deploying machine learning technologies must thoroughly investigate systems discrimination rights risks prior development acquisition possible prior use ongoing basis throughout lifecycle technologies contexts deployed may include conducting regular impact assessments prior public procurement development regular milestones throughout deployment use machine learning systems identify potential sources discriminatory outcomes example algorithmic model design oversight processes data processing taking appropriate measures mitigate risks identified impact assessments example mitigating inadvertent discrimination underrepresentation data systems conducting dynamic testing methods trials ensuring potentially affected groups field experts included actors power design testing review phases submitting systems independent expert review appropriate subjecting systems live regular tests audits interrogating markers success bias feedback loops ensuring holistic independent reviews systems context human rights harms live environment disclosing known limitations system question example noting measures confidence known failure scenarios appropriate limitations use ensure transparency accountability states must ensure require accountability maximum possible transparency around public sector use machine learning systems must include explainability intelligibility use technologies impact affected individuals groups effectively scrutinised independent entities responsibilities established actors held account states publicly disclose machine learning systems used public sphere provide information explains clear accessible terms automated machine learning processes reached document actions taken identify document mitigate discriminatory impacts enable independent analysis oversight using systems auditable avoid using black box systems subjected meaningful standards accountability transparency refrain using systems contexts iii enforce oversight states must take steps ensure public officials aware sensitive risks discrimination rights harms machine learning systems states proactively adopt diverse hiring practices engage consultations assure diverse perspectives involved design implementation review machine learning represent range backgrounds identities ensure public bodies carry training human rights data analysis officials involved procurement development use review machine learning tools create mechanisms independent oversight including judicial authorities necessary ensure machine decisions meet international accepted standards due process research development machine learning systems largely driven private sector practice states often rely private contractors design implement technologies public context cases states must relinquish obligations around preventing discrimination ensuring accountability redress human rights harms delivery services state authority procuring machine learning technologies private sector maintain relevant oversight control use system require third party carry human rights due diligence identify prevent mitigate discrimination human rights harms publicly account efforts regard promoting equality states duty take proactive measures eliminate discrimination context machine learning wider technology developments one important priorities states promote programs increase diversity inclusion equity science technology engineering mathematics sectors commonly referred stem fields efforts serve ends though may help mitigate discriminatory outcomes states also invest research ways mitigate human rights harms machine learning systems holding private sector actors account international law clearly sets duty states protect human rights includes ensuring right private sector actors according committee economic social cultural rights states parties must therefore adopt measures include legislation ensure individuals entities private sphere discriminate prohibited grounds states put place regulation compliant human rights law oversight use machine learning private sector contexts present risk discriminatory outcomes recognising technical standards may complementary regulation addition data protection privacy areas law national regional levels may expand upon reinforce international human rights obligations applicable machine learning states must guarantee access effective remedy individuals whose rights violated abused use technologies responsibilities private sector actors human rights due diligence private sector actors responsibility respect human rights responsibility exists independently state obligations part fulfilling responsibility private sector actors need take ongoing proactive reactive steps ensure cause contribute human rights abuses process called human rights due diligence private sector actors develop deploy machine learning systems follow human rights due diligence framework avoid fostering entrenching discrimination respect human rights broadly use systems three core steps process human rights due diligence identify potential discriminatory outcomesii take effective action prevent mitigate discrimination track responsesiii transparent efforts identify prevent mitigate discrimination machine learning systems identify potential discriminatory outcomes development deployment new machine learning technologies private sector actors assess risk system result discrimination risk discrimination harms equal applications actions required address discrimination depend context actors must careful identify direct discrimination also indirect forms differential treatment may appear neutral face value lead discrimination mapping risks private sector actors take account risks commonly associated machine learning systems example training systems incomplete unrepresentative data datasets representing historic systemic bias private actors consult relevant stakeholders inclusive manner including affected groups organizations work human rights equality discrimination well independent human rights machine learning experts take effective action prevent mitigate discrimination track responses identifying human rights risks second step prevent risks developers machine learning systems requires correcting discrimination design model impact system deciding training data use pursuing diversity equity means inclusion machine learning development teams aim identifying bias design preventing inadvertent discrimination submitting systems significant risk resulting human rights abuses independent audits risk discrimination rights violations assessed high impossible mitigate private sector actors deploy machine learning system context another vital element step private sector actors track response issues emerge implementation time including evaluation effectiveness responses requires regular ongoing quality assurances checks auditing design testing deployment stages monitor system discriminatory impacts context situ correct errors harms appropriate particularly important given risk feedback loops exacerbate entrench discriminatory outcomes iii transparent efforts identify prevent mitigate discrimination machine learning systems transparency key component human rights due diligence involves communication providing measure transparency accountability individuals groups may impacted relevant private sector actors develop implement machine learning systems disclose process identifying risks risks identified concrete steps taken prevent mitigate identified human rights risks may include disclosing information risks specific instances discrimination company identified example risks associated way particular machine learning system designed use machine learning systems particular contexts instances risk discrimination publishing technical specification details machine learning functions including samples training data used details source data establishing mechanisms ensure discrimination occurred use machine learning system relevant parties including affected individuals informed harms challenge decision outcome right effective remedy right justice vital element international human rights law international law victims human rights violations abuses must access prompt effective remedies responsible violations must held account companies private sector actors designing implementing machine learning systems take action ensure individuals groups access meaningful effective remedy redress may include example creating clear independent visible processes redress following adverse individual societal effects designating roles entity responsible timely remedy issues subject accessible effective appeal judicial review use machine learning systems people rights stake may pose challenges ensuring right remedy opacity systems means individuals may unaware decisions affect rights made whether process discriminatory cases public body private sector actors involved may unable explain process challenges particularly acute machine learning systems recommend make enforce decisions used within justice system institutions responsible guaranteeing rights including right access effective remedy measures already outlined around identifying documenting responding discrimination transparent accountable efforts help states ensure individuals access effective remedies addition states ensure machine learning systems deployed public sector use carried line standards due process act cautiously use machine learning systems justice sector given risks fair trial litigants rights outline clear lines accountability development implementation machine learning systems clarify bodies individuals legally responsible decisions made use systems provide effective remedies victims discriminatory harms linked machine learning systems used public private bodies including reparation appropriate involve compensation sanctions responsible guarantees may possible using existing laws regulations may require developing new ones conclusion signatories declaration call public private sector actors uphold obligations responsibilities human rights laws standards avoid discrimination use machine learning systems possible discrimination arises measures deliver right effective remedy must place call states private sector actors work together play active committed role protecting individuals groups discrimination creating deploying machine learning systems must take meaningful measures promote accountability human rights including limited right equality per obligations responsibilities international human rights law standards technological advances must undermine human rights crossroads power must act protect human rights help safeguard rights entitled future generations declaration published may amnesty international access launched rightscon toronto canada references human rights committee vienna declaration programme action example see principles accountable algorithms social impact statement algorithms ieee global initiative ethics autonomous intelligent systems ethically aligned design montreal declaration responsible development artificial intelligence asilomar principles developed future life international covenant economic social cultural rights icescr article united nations human rights committee general comment doc vol para ohchr tackling discrimination lesbian gay trans intersex people standards conduct business united nations human rights committee general comment para example convention elimination forms racial discrimination article convention elimination forms discrimination women article institute outlined practical framework algorithmic impact assessments public agencies article general data protection regulation gdpr sets requirement carry data protection impact assessment dpia addition article gdpr requires data protection principles applied design default conception phase product service service lifecycle institute new york university report committee economic social cultural rights affirms addition refraining discriminatory actions state parties take concrete deliberate targeted measures ensure discrimination exercise covenant rights committee economic social cultural rights general comment doc para committee economic social cultural rights general comment doc para guiding principles business human rights additional supporting documentscouncil europe recommendation committee ministers member states roles responsibilities internet intermediariesun guiding principles business human rights principle example see universal declaration human rights article international covenant civil political rights article international covenant economic social cultural rights article committee economic social cultural rights general comment nature states parties obligations doc article para covenant international convention elimination forms racial discrimination article convention elimination forms discrimination women committee economic social cultural rights cescr article general comment domestic application covenant example see julia angwin jeff larson surya mattu lauren kirchner propublica machine bias amnesty international access toronto declaration
