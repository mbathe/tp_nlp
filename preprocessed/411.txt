osce rfom impact artificial intelligence freedom expression introduction key challenges freedom expression age algorithms online ecosystem become participated forum global level sometimes described grand public forum fostered flow information transformed ways journalists perform work audiences consume engage media content sense freedom expression media freedom increasingly exercised online international community recognized emphasized importance online spaces societies public discourse democracy large rights people enjoy offline must also protected online particular freedom expr ession human rights fundamental freedoms apply online today content longer created disseminated solely limited number media workers alone bound professional ethical standards also citizen result necessarily editorial control vast amount published content processes tremendous impact audience behavior information consumption time internet intermediaries especially soc ial media platforms gained dominant position pivotal actors undertake many functions information management previously carried traditional gatekeepers editors publishers shift particularly increased ith exponential growth content shared internet users numbers speak every single hour hours videos uploaded onto youtube million photos since early stage internet various technology solutions deployed facilitate many online communication emerging technologies used support distribution content audiences content curation well filter take illegal otherwise unwanted content content removal processes provide basis society interacts online machine technologies automated algorithmic decision forms artificial intelligence applied aut omated tools measures increasingly used shape arbitrate content practices also recently gained support states put increasing pressure intermediaries automate content moderation trend states push platforms remove content within strict time period short hours even one hour hand states push towards transparency regular auditing instance david goldstone public forum doctrine age information superhighway united nations human rights council resolution promotion protection enjoyment human rights information available omnicore statistics last visited february instance facebook user may simply browse profile cog nition also com municate work content social media platfo rms led creation unmediated social spaces blurred lined private professional roles see example google jigsaw project perspective available last visited february see concise list regulatory initiatives european agency fundamental rights policy initiatives available last visited february see examp network enforcement act netzwerkdurchsetzungsgesetz netzdg adopted germany june directive copyright related rights digital single market european parliament april code conduct counter ing illegal hate speech online european commission twitter facebook microsoft youtube june companies see example recent proposal referred avia law approved july french nation assembly white paper artificial intelligence european approach excellence trust european commission com algorithmic accountability act proposed usa today algorithms used wide range interventions spam filters detection copyright infringements chatbots editorial data content ranking distribution additionally deployed policing onl online speech also offline public spaces example help smart video surveillance systems using facial recognition however impact freedom expression positive negative still severely responsible implementation benefit society genuine risk commercial political state interests could deteriorating effect human rights particular freedom expression media therefore crucia understand better human rights implications use ensure algorithms censor chilling effect free speech key terminology concepts internet intermediaries platforms information gatekeepers internet unique layered structure creates three separate relevant categories actors create publish information targeted information provide platform distribution internet intermediaries intermediaries play essential role enabling flow information two actors without contributing content however unique position prevent mitigate risks may inf licted two categories illegal activity may certain circumstances liable contributors inevitably put pressure potential claimants law intermediaries service oviders enable manage interactions online connecting users internet hosting content online information search engines news aggregators among others intermediaries may carry multiple roles different regulatory frameworks apply depending function services converging process tied closely number risks freedom concentration roles functions intermediaries often described platformization emphasizing dominant position online platforms online platforms software facilities offering two even multi markets providers users content oods services platforms play central role digital ecosystem important means consumers find online information online information finds consumers intermediary role gives platforms economic power int roduce new communication order shape online experience users personali zed basis filter user sees example like share buttons inseparable element almost website social media atforms sense intermediaries especially social media platforms position information gatekeepers engage selection information published ranking editorial control content well result manage processes could great impact human rights democracy large among work see fra paper facial recogniti technology available last visited february among works see rikke frank j√∏rgensen human rights age platforms mit press andrej savin internet law second edition elgar european law series edward elgar publishing ibid council europe role responsibilities internet intermediaries available intermediaries last visited february examples types platforms include ommunications social media platforms operating systems app stores audiovisual music platforms platforms content platforms may include content aggregators well solutions search engines digi tal single market strategy europe analysis evidence scribed mechanisms include example channeling search engines hyperlinks censorship filtering blocking zoning value customization tools infrastructure network access user interaction default homepages hypertext links editorial mechanisms technical controls information content framework identifying internet information gatekeepers international review law computers technology content moderation types content role intermediaries today online platforms called play active role monitoring content online mak ing decisions content permissibility however many cases justified reason remove content manifestly illegal irrespective context child abuse material situation complex regard content considered harmful whether certain content reaches level illegality typically depends context presented particular case hate speech extremist content thus forms content might harmful effect still protected international human rights standards remain accessible online practice many strategies manage counter illegal unwanted content different intermediaries perform various form content moderation prioriti zation deprioritization promotion demotion moneti zation demonetizati online content moderation typically takes place three different levels non focus mainly content removal content curation visible techniques content moderation many instances various types auto mated measures include algorithms deployed first level moderation check content upload filters upload assessments vary across platforms depending technology used internal policies content characteristics predefined categories unwanted material algorithms supposed automatically block content published due content overload attention scarcity platforms regul arly deploy automated tools moderate content second level assess piece content visible particular user long process ranks content based multiple criteria posted informatio previous interaction content similar type content previous interaction similar user usually made public hich criteria mixed algorithmic decision means black boxes employing chine technologies decide content available third level mostly human intervention content moderation based reporting mechanisms often established internal policies companies also referred notice procedures ntd ese cases user may report inappropriate content based platform internal rules triggers reviewing procedure based reports resolved human moderators problematic content might removed accounts poster might temporarily permanently blocked insufficient transparency levels processes terms criteria involved decision process due process often seen one key challenges use algorithms content moderation assess online content decide accessibility intermediaries adopted number internal rules procedures community standards terms services serve set guidelines judge content rules defin content considered harmful unwanted necessarily equa illegal according national legislat ion international frameworks therefore online content regulatory models governed rules set forth private profit entities rather international human rights set criteria justify limitations speech consequential lack consistency clarity well pressure platforms make swift decisions terms whether certain content categorized council rope recommendation committee ministers member states roles responsibilities internet intermediaries march para deciding content show individual users followin factors important exclusive character person wants distribute content user page group business etc form content tex video audio photo etc interest con tent network users utomatically gen erated user profile irect user requests hide starred etc special relationships cont ent users tagging etc usting sponsorship content distributors frank pasquale black box society secret algorithms control money information cambridge harvard university press united nation david kaye report special rapporteur promotion protection right freedom opinion april example sometimes legitimate reason based type platform permissible certain social media mumsnet allow discussion related motherhood linkedin allow professional networking prohibi use platform purposes unlawful national criminal laws particularly removal illicit content platforms raises issue absence judicial oversight without judicial review proper remedy accountability mechanism place shift responsibility states intermediaries already created significant impact enjoyment human rights especially freedom expression artificial intelligence universally agreed definition need discussions many refer systems designed humans operate varying levels autonomy given set human objectives make predictions recommendations decisions influencing real virtual systems act perceiving environment data acquisition interpreting collected data reasoning knowledge processing information derived data deciding best action take achieve given goal forms also adapt behavior analyzing environment affected previous various approaches suggest umbrella term processes essentially delegate decision making executio activities partially completely humans software systems based algorithms set human instructions encoded procedures transforming input data desired output based specific advance techniques include machine learning often defined ability systems adapt improve performance autonomously time without explicitly programmed way majority technologies today fact machine systems automating variety sophisticated tasks previously presumed require human cognition prerequisite advancement machine learning access big data extremely large datasets characterized volume amount velocity speed variety initial human act creating code assigning specific task process machine learning regularly begins observation large datasets application statistical rocess look patterns data make recise decisions future therefore capacity extracts actionable knowledge available data via mathematical models without meaningful human intervention without deeper standing data context particularly problematic example underrepresentation datasets inaccurate missing data inaccurate causation correlation datasets complexity arise due lack transparency explainability algorithmic decision instance hard trace back challenge decisions satirical content matter public interest taken states pressure platforms remove extremist cont ent platforms purging vital evidence human rights violations example context conflict main characteristics processes behind content removal algorithms applications deployed intermediaries way tied question scale complexity networked publics relationship solve problems scale subjectivity say personal practical terms algorithms often deployed identify remove specific content thus remove intended content would need analy different aspects related particular content complex task especially given application across regions languages example detecting bullying online requires understanding relationship two users age number netzdg loi oecd principles artificial inte lligence adopted may european commission high expert group artificial intellig ence ethics guidelines trustworthy gillespie relevance algorithms media technologies essays communication materiality society mit press defined encoded procedures transforming input data desired output based specific calculations surden machine learning law available preparing future artificial intelligence new york times youtu erasing history pressure remove extremist content platforms purging vital human rights evidence october dana boyd social network sites networked publics affordances dynamics implications zizi papacharissi networked self identity community culture social netwo sites routledge new york gillespie custodians internet yale university press exchanged messages nature connection well previous interaction history shared removal relies algorithms studies show automated decisions fail understand contextual nuances behind pieces identification context dependent content requires proper understanding societal political historical cultural nuances order recognize harm content may potentially carry whether removed based huma instructions numerous examples automated tools algorithms struggle detect illegal content requires contextual understanding filtering taking perfectly legitimate content time relevant emphasize removal hateful content remove underlying hate thus problem could exacerbated users blocked immediately thereby pushed open public discussion could encourage join dubious platforms conspiracy theories furthermore cultural legal differences across world put question application systems trained data one region ork effectively areas thus ther also often significant shortcoming automated tools emphasize importance genuine human involvement sometimes referred human loop guarantee efficiency algorithms remain amenable man platforms operating speech police based vague community standards supported algorithms result regularly fail ensure users understand taken instead hey inform users open takedown processes results put place clear simple procedures users challenge takedowns support human reviewers automated decisions security threats algorithms ften deployed detect content laws platform standards perceived threatening national security governments legislators increasingly pressuring intermediaries notably platforms take proactive role policing terrorist extremist content develop proactive automated measures identify content falling category short time frame however evidence researched based justification swift removal online conte currently missing lack evidence demonstrates successful removal terrorist content online fact results reduced security threats vein also effectiveness algor ithms specifically designed identify illegal content addition always certain grey area due particular context nuances calls sophisticated balanced assessment cases false negative system incorrectly identifies illegal content innocent false positive system removes innocent another concern order address illegal content sustainably engagement law enforcement equired reason instant removal content seen extension concealed state additionally content removal operations linked broader security measures order protect integrity platform integ rity service management traffic data includes ofcom cambridge consultants use online content moderation case instance automated take downs political speech marginalized voices based copyright upload filters see reda filters fail cases show trust algorithms clean internet available last visited february example tech dirt youtube takes ariana grande manchester benefit concert copyright grounds june available manchester last visited february eff platform censorship lessons copyright wars ofcom cambridge consultants use online content moderation see also artificial human new era counterterrorism intelligence studies conf lict terrorism ofcom cambridge consultants use online content moderation sarah koslov incitement geopolitical influence facebook content moderation georgetown law technology review measures inauthentic behavior commercial spam bots application algorithms operations also raises free speech concerns however transparen study needed understand possible impact legitimate content freedom expression hate speech uniform definition hate speech international human rights law detection hate speech content subject societal political historical cultural nuances addition wide range hateful expression requires different responses based severity speech community guidelines ocial media companies fail reflect complex nuances therefore implementation automated measures supported algorithms lead removal perfectly legitimate besides problem also concerning hateful content remains online collectively harmful effect particularly marginalized underrepresented groups sense hate speech silencing effect finally counter hate speech first foremost societal problem diverse initiatives policies need undertaken numerous actors automat regulation hate speech otherwise detrimental impact public discourse lead chilling effect self censorshi context plays salient role assessment content simple analysis words phrases rarely result accurate assessment systems struggle recognize figurative speech discern mockery illicit hate speech offensive language sometimes follows heated public debate issues public importance facebook report agreed technology still work well terms detecting contextually complex hate speech supported human however facebook recently claimed using machine learning developed new type detection technology identify flag hate speech using several different improving success rate auto mated additional risk trained data different jurisdiction create unwanted consequences societies different cultural communication rules recent study twitter content written stan dard american english african american english demonstrated evidence systematic racial bias tweets written african american english study concluded consequently systems may discriminate groups often targets abuse trying iii main characteristics processes behind content curation underlying business models many online platforms rely heavily user attention engagement considered treated economic resource time users spend online platforms one key factors determine platforms economic gain result online platforms curate news feeds search results order increase engagement time spent platform aim increase profit amplifying sensational potentially harmful content clickbait content back drop algorithmic solutions determine international human rights law distinguishes severe forms hate speech stat required prohibit including criminal civil administrative measures international criminal law article iccpr forms hate speech states may prohibit protect rights others article cpr discriminatory bias threats harassment lawful hate spee nevertheless raises concerns terms intolerance discrimination meriting critical response states article hate speech explained shirin ghaffary algorithms detect hate speech online biased lack people vox august available facebook last visited february facebook publishes enforcement numbers first time one method involves detecting automatically removing content matches existing hate speech violations database another method involves proactively detecting potentially violating ntent giving score according similarity content already removed violating hate speech policy starting systems began removing posts automatically received high scores matched existing hate speech database facebook community standards enforcement report hate speech removed automatically percent raised hate speech davidson racial bias hate speech abusive language detection datasets may trending topics recommended content neutral reflect corporate profit besides amplifying reach clickbait content provides users content merely based data also characteristics group according user belongs essential understand context merely tool governed operated private companies ranking content regularly based users preferences behavioral data increase time users spend platform drawing upon analysis evident dominant online platforms changed ways access receive impart information lays foundation form opinions due lack transpar ency well awareness processes behind content curation lack scrutiny users general public including researchers regulators however content curation essent ial issue freedom expression needs addressed primarily state actors also non actors including intermediaries positive obligation create enabling environment ensures diversity pluralism sources challenges pluralism diversit general algorithms often deployed categorize individuals groups determine particular political commercial preferences based assessment target individual specifically curtailed content result process social sorting may expose users similar content tends correspond strengthen existing interests amplify views preferences rather offer variety alternative information sources challenge oppose process often referred echo chamber process individuals increasingly cocooning informational communicational universe creation social media provided minorities marginalized voices myriad opportunities connect engage echo chambers especially worrisome reinforce societal power time media outlets journalis struggling adjust new dissemination practices underpinned processes new communication order intermediaries notably social media platforms decide use algorithms information particular users ave opportunity access thus may easy speak cyberspace remains difficult aspects gender inequalities also need taken account explored parti cular regards inequalities access production information well technologies reproduce gender background intermediaries information gatekeepers position potentially hinder public right access pluralistic diverse information bloch wehba automation moderation cornell international law journal forthcoming see example united nations speci rapporteur freedom opinion expression organization security europe osce representative freedom media organization american states oas special rapporteur freedom expression africa commission human peoples rights achpr special rapporteur freedom expression access information anniversary joint declaration challenges freedom expression next decade july para studying algorithmic agents ways potentially shape opinion process tied number ethical legal methodological challenges thus field still exploring right methodological approach urther discussion see bod√≥ tackling algorithmic control crisis technical legal ethical challenges research algorithmic agents yale journal law technology see also study personalized communication bod√≥ interested diversity role user attitudes algorithmic feedback loops policy news personalization digital journalism tarlach mcgonagle minority rights freedom expression media dynamics dilemmas intersentia cambridg mike cormack niamh hourigan eds minority language media concepts critiques case studies multilingual matters clevedon bojana kostic tarlach mcgonagle social new social media nation minorities perspectives fcnm european yearbook minority issues hindmann myth digital democracy princeton oxford university press noble safiya algorithms oppression search engines reinforce raci wired machines taught photos learn sexist view women collett clementine dillon sarah gender four proposals future research cambridge leverhulme centre future intelligence however recent research findings actual role echo chambers impact democratic discourse rather case fact ranking practices often hand political commercial behavioral targeting changed way information consumed may impact way opinions formed impact surveillance including surveillance capitalism freedom expression machine technologies require large amounts data fact impacted business models especially media field information well curation via apps social media platforms offered users free exchange behavioral data data externalities become lucrative internet companies collect users data collect users money addition large amounts personal non data enable data mining therefore become competitive advantage consequently development sustainability online media market also need assessed perspective competition law dominant platforms largest holders data nee data openly accessible order enable free competition innovation avoiding network effect business model intermediaries enables profiling individuals even individual citizens undertake ecautions protect privacy shield data data processing personal digital footprints even mall sufficient various online services powered classify users already developed profiles predict needs bas data people supposedly similar often citizens neither informed processes taking place aware work potentially discriminatory aspects constant surveillance online well offline chilling impact human rights particular right privacy freedom expression could particularly true state actors introduce smart video surveillance technologies public spaces facial recognition apacities could endanger freedom expression also freedom assembly human rights special concerns arise citizens data possession state institutions merged digital profiles citizens create social credit need explore link online profiling surveillance state surveillance online data infrastructure constructed service data business model could facilitate state surveillance permanent surveillance practices coupled profiling dangerous consequences journalists perform work well safety risks evident connection protect ion journalist sources whistleblowers however also less evident equally threatening issues use facial recognition identify journalists example reporting protests tracing back digital footprints individual journalists especially marginalized groups additionally combined restrictive legislation algorithms track newsgathering activities detrimental impact newsgathering investigative conclusion risks posed freedom expression outline ways non state actors deploy algorithms address concerns stemming online ecosystem able make semi decisions filtering ranking removal blocking content automated measures engage wide spectrum content extremist terrorist content hate speech potentially harmful elizabeth dubois grant blank echo chamber overstated moderating effect political interest diverse media information communication society network effect phenomenon whereby increased numbe people participants improve value good service social media platform might therefore grow popularity achieved critical mass users new users deterred using another platform process alre ady taking place china china social credit system epitome disastrous consequences technological advancement without commensurate commitment human oxford human rights hub september available last visited february capture situations journalists trying take informed views terrorist groups motivations action without intent commit terrorist offence article spanish penal code lawful content process profiling curtails online public forums decides information users able access online exacerbating existing risks surveillance key challenges freedom expression stem lack transparency explainability algorithms outsourcing judicial responsibilities protection human rights private entities well lack oversight accountability correction mechanisms essential measure technological regulatory seeks manage control public forums human rights proportionate incor porates checks balances order limit freedom expression media pluralism free flow information fundamental rights therefore crucial first step establish promote clearer understanding policie practices place use equally important understand better impact ture media quality information realization human rights online next step policy recommendations need developed ensure freedom expression media freedom safeguarded using machine technologies looking forward crucial promote better understanding algorithmic decision tices place state non actors impact freedom expression initiate multi dialogue including industry states addressing legitimate concerns address security threats hate speech onlin develop recommendations mitigate negative impacts automated tools prevent infringement free speech media freedom research assess automation affects media freedom journalism benefit algorithms measure impact legislation policies mandating removal content short time period deployment algorithms platforms explore discriminatory effects content moderation technologies especially context digital inclusion marginalized voices conduct studies effectiveness automated measures specifically designed identify illegal content well explore alternative measures combat hate speech instance interface design impacts ers behaviors algorithms could used counter hate speech map current use machine technologies law enforcement agencies potential impact freedom expression organize discussions worksho positive negative implications automated measures identification illegal content online platforms specifically targeting law enforcement selected countries well impact freedom expression
