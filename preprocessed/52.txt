human rights impact assessments analysis recommendations access defends extends digital rights people communities risk organization partner local actors bring human rights agenda use development governance digital technologies intervene technologies adversely impact human rights combining direct technical support strategic advocacy grassroots grantmaking convenings rightscon ﬁght human rights digital age human rights impact assessments analysis recommendations brandie nonnecke director citris policy lab berkeley philip dawson technology human rights fellow harvar kennedy school carr center human rights policy abstract introduction governance human rights algorithmic impact assessments human rights imp act assessments canadaʼs directive automated governance strategy towards systemic approach role standards certifications conclusions recommendations acknowledgment human rights impact assessments analysis recommendations abstract public private sectors increasingly tur ning use algorithmic artificial intelligence impact assessments aias means identify mitigate harms artificial intelligence systems promising lack clarity proper scope methodology best practices aias could inadvertently perpetu ate harms seek mitigate especially human rights explore emerging integratio human rights legal framework governance strategies including within canadaʼs rective automated european commissionʼs proposed digital services act artificial intelligence act well implementation human rights impact assessments hrias systems benefits drawbacks recent implementations aias rias assess systems adopted public private sectors explored conside red context emerging trend toward development standards certifications responsible governance practices conclude priority recommendations human rights framework help better ensure aias corresponding responsible vernance strategies live promise october report publication access ommissioned research part work intersection human rights law artific ial intelligence systems written brandie nonnecke director citris policy lab erkeley philip dawson technology human rights fellow harvard kennedy chool carr center human rights policy previous version report published ctober part harvard kennedy school carr center human rights policy discussi paper series updated expanded version access would like thank brandie phil excellent insightful work access defends extends digital rights users risk around world combining direct technical sup port comprehensive policy engagement global advocacy grassroots grantmaking legal inte rventions convenings rightscon fight human rights digital age human rights impact assessments analysis recommendations introduction response growing recognition societal risks artificial intelligence broadly automated systems ads particul algorithmic impact assessments aias increasingly considered pub lic private sectors identify prevent mitigate harms means improve qualit products term algorithmic impact assessment currently lacks def initional clarity general aias aim identify potential risks health fety ethics implementations human rights development depl oyment algorithmic system well appropriate risk mitigation strategies use algorithmic audits datasheets datasets model cards implementations aias gaining momentum iable governance strategy finding way binding regulation policies also requiring implementation aias mechanism reduce legal risks stemmi liability european commissionʼs artificial intelligence act uggests approach governance prohibiting certain harmful applications calling developers form impact assessment called conformity assessment applications identify necessary oversight algorithmic accountability act proposed nited states congress would required compani large user bases conduct impact assessments highly sensitive ads act exp ected reintroduced national institute standards technology nist sked congress develop risk management framework guide reliability bustness trustworthiness systems used federal national security commission artific ial intelligence issued report recommending gove rnment agencies deploying systems conduct ante risk assessments post impact assessments increase public transparency commerce justice science related agencies propriations bill report together mino rity views house committee appropriations july accountability act cong mic grace dill sen wyden reintroduce bias bill coming onths meritalk proposal regulation laying harmonized ules artificial intelligence artificial intelli gence act european commission last modified april igence selbst negligence aiʼs human users walker jeﬀ dean update work responsible innovation google july farhangi vogl rethink ing explainable machines gdpr right expla nation debate rise algorithmic audits enterprise berkeley tech gebru timnit jamie morgenstern briana vecc hione jennifer wortman vaughan hanna wallach hal daumé iii kate cra wford datasheets datasets arxiv preprint mitchell margaret simone andrew zaldivar parker barnes lucy vasserman ben hutchinson elena spitzer ioluwa deborah raji timnit gebru model cards model reporting proceedings conference fairness accounta bility transparency emanuel moss governing algorithmic impact assessments six observations available ssrn term artificial intelligence typically used refer computer system capable perfo rming tasks would ordinarily require form intelligence accomplish visual perception speech cognition methods wide ranging vary significantly complexity algorithms predictive models computer vision deep learning machine learning natural language processing neur nets problematic nat ure term see daniel leufer term clear meaning ning human rights impact assessments analysis recommendations use improved reporting instance risk assessments impact assessments diﬀerentiated risks ide ntified outset impacts evaluated deployment quantify mitigate identified risks canadaʼs directive automated came eﬀect led development one first aias identify mitigate range risk individual rights economic interests health ads developed deployed public aias hold promise promote development regulatory policy governance mechanisms government corporate actors entify potential harms human rights organizations warned using aia may guidance implementation aias indicates use reserved applications use biometric identification judicial entencing however applications wrongly categorized thereby evade proper oversight would especially problematic case onus determining risk level placed entity developing could lead troubling scenario whe developers artificially reduce perception risk order evade oversight lac common internationally standardized approaches development aias could lead confusion complicate eﬀectiveness approach increasingly dominates governance strategies important questions emerge regarding proper scope methodology best practices might protect aias inadvertently becoming smokescreens human right abuses short development deployment aias substantial risk say implementation aias provide benefits rather significant work remains determine appropriately develop apply aias ensure eﬀectiveness done inappropriately use ultimately enable perpetuate harms seek mitigate explore emerging integration human ghts framework governance strategies including human rights implications aias rely international human rights law framework including declaration human ghts udhr well guiding principles business human rights ungps provide analysis emerging proposals use aias including recommendations ade international intergovernmental organizations regulatory legislative proposals government bodies usage date private sector conclude analyzing tegration human rights emerging legislative proposals canadaʼs directiv automated european unionʼs artificial intelligence act gital services act oﬀer recommendations help guide eﬀective development use huma aias broadly hidvegi daniel leufer estelle massé regulate basis rights risks access directive automated canadian overnment last modified april schmidt national security commission artificial intelligence final report national security commission artificial intelligence human rights impact assessments analysis recommendations governance human rights last years least sets ethic based principles frameworks guidelines developed upport responsible development deployment within public private shown growing consensus forming around core principles including accountability privacy security transparency explainability fairness iscrimination professional responsibility human control promotion human principles gain acceptance within public private sectors focus development appropriate strategies operationalize principles sponsible practices yet process straightforward despite relative convergence principles roposals seldom consensus interpretation principles practice espec ially comes principles developed diverse institutions academia civil society governments varying multistakeholder representation ese institutions diﬀering priorities needs applied diﬀerent ethical framew orks deontological consequentialist utilitarian approaches evaluate benefits risks great heterogeneity principles defined recommendations appropriate operationalization certain scholars argued principle proliferati perpetrated crisis legitimacy complicating already complex task identifyin mitigating risks harms response international human rights framewor normative legal guidance proposed mechanism suppor consistent framing operationalization principles many promi nent professional associations consortia intergovernmental organizations governments ompanies seem institute electrical electronics enginee ieee worldʼs largest technical professional organization issued report stating first principle created operated respect promote prot ect internationally recognized human rights emphasized human rights part risk asilomar principles signatories blic private sectors include need protect human rights design deployment oecd principles asilomar principles future life institute ethically aligned design vision prioritizin human autonomous intelligence systems ieee global initiative ethics autonomous intelligent systems undefined latonero governing artificial intelligence pholding human rights dignity data society alessandro mantelero samantha esposito methodology human rights impact assessment development systems computer law security review eileen donahoe megan macduﬀee artificial intelligence human rights journal democracy latonero principle proliferation cri sis legitimacy carr center discussion paper series ethics guidelines global inventory algorithm watch accessed june fjeld principled artificial intell igence mapping consensus ethical approaches principles berkman klein center internet society harvar university ethics guidelines global inventory algorithm atch accessed june human rights impact assessments analysis recommendations countries pledged uphold specifically protection human european commissionʼs expert group also established set principles one calls ensuring respects fundamental white house oﬀice science technology policy ostp national initiat ive identified need ensure systems infringe upon human rights especially rights privacy civil rights civil canada directive automated decision one first countries develop algorithmic impact assessment tool seeks measure mitigate human rights harms ads used public private sector technology companies like salesforce explicitly identified protecting man rights ethics intel among first global tech companies conduct hrias development use centering human rights within governance strateg ies help operationalize principles across sectors international contexts domain application codification charters case law regulation industry standar human rights norms values gained broad global udhr corresponding international human right instruments guiding principles treaties commentarie national laws related policies guidelines helped clarify core definitions interpretations human rights international human rights norms values may clearer better defined stable principles alone applyi human rights framework facilitates better harmonization reduces risk uncertainty defining applying principles mantelero samantha esposito evi methodology human rights impact ass essment hria development systems computer law security review universal declaration human rights united nat ions core international human rights instruments monitoring bodies united nations human rights oﬀice high commis sioner guiding principles business human rights implementing united nations ʻprotect respect remedyʼ framework united nations human rights oﬀice high commissioner mark latonero governing artificial intelligence upholding human rights ignity data society donahoe megan macduﬀee metzger artific ial intelligence human rights journal democracy mantelero samantha esposito evi methodology human rights impact asse ssment hria development systems computer law security review eileen donahoe megan macduﬀee metzger artificial intelligence human rights journal democracy charles bradley richard wingfield megan metzger national artificial intelligence strategi human rights review second edition global partners digital stanford global digital policy incubator april human rights annual report intel human rights impact assessment article one advisors ethics salesforce accessed directive automated canadian overnment last modified april advancing trustworthy national initiative oﬀice ethics guidelines trustworthy artificial intel ligence european commission expert gro last modified april igence recommendation council rtificial intelligence oecd legal instruments last modified may human rights impact assessments analysis recommendations take example principle tion exists article udhr also widely adopted principle public private sectors operationalization compl icated due absence shared understanding means development deployment systems applying human rights framework relevant charters case law regulation identify interpreted part icular domain appropriate strategies move concept abstra concrete become clearer human rights principles also highlight res ponsible design systems including transparency explainability accountability desirable commercial ethical standpoint prerequisites upholding existing legal obligations instance lack transparency regarding use systems diﬀicult determine whether violation human rights legal obligation ccurred undermining ability seek redress similarly especially public sector reliance recommendation decision insight provided system explai nable accountable odds human rights principles incorporated national admini strative law generally requires individual provided reasons decision made well opportunity contest decision receive remedy ies human rights framework provide substant ive foundation governance architecture needed produce greater specificity defining operationalizing principles public private sectors increase eﬀorts implem ent aias calls require human rights impact assessments hrias also approaches act beginning codify human principles governance oversight promising important consider aias hrias implemented better identify mitigate risks next evaluate esign scope aias hrias turn discussion challenges associa ted implementation algorithmic impact assessments human rights impact assessments long history using impact assessments variety domains including assess mitigate harms environment data security rivacy human rights appropriate scoping implementation methods must carefully negotiated constructed proposal regulation laying harmonized les artificial intelligence artificial intellig ence act european commission last modified april igence human rights technology final report stralian human rights commission last modified may human rights democracy rule law impact assessment ystems council europe hoc committee arti ficial intelligence policy develop group last modified may human rights technology final report australia human rights commission human rights impact assessments analysis recommendations support recent study impact assessments diﬀerent sectors researchers noted methodology largely riven constitutive components including criteria source legitimacy leg islative regulatory mandates define must implement impact assessment iden tifying potential impacts assessed mitigated risks appropriate methods consultation diverse subject matter experts directly aﬀected design implementation impact assessments field nascent lack consensus common standards regarding appropriate configuration application constitutive components including tities administer enforce oversee aias hrias support legitimacy adopt eaningful governance engagement processes support accountability appropriate methods implementation including eﬀectively define identify itigate metcalf define aias emerging gove rnance practices delineating accountability rendering visible harms caused algorithmic ystems ensuring practical steps taken ameliorate harms sources risk identified include presence bias datasets used train system well fairness explainability model identification potential impacts include con textual considerations related equity justice well economic interests health users populations potentially aﬀected proposed system companies may integ rate aias whole part traditional product design reviews risk management due iligence processes implementation aias early perhaps initial design pro cess likely eﬀective identifying mitigating risks widespread investment eployment aias also consider leading termination application appropri ate safeguards put place like privacy design concepts aias could support responsibility design goal aia impact assessment ultimately identify technical adjustments made system der eliminate risks identified reduce acceptable level thei deep expertise knowledge system assessed technology firms likely primary administrators aias creating potential situation firms sized eﬀect included aias implemented transparency aias developed implemented technology firms critical selbst institutional view algorithmi impact assessments harvard journal law technology moss assembling accountability alg orithmic impact assessment public interest data society june metcalf algorithmic impact assessmen accountability impact proceedings acm conference fairness accountability tra nsparency human rights impact assessments analysis recommendations hria tool evaluate potential act ual impact organizationʼs strategy practice product peopleʼs human rights human rights council ungps underpin much criteria guidance plicable best practices hrias ungps recommend assessments human rights pacts undertaken regularly appropriate stages businessʼs operations part human rights due diligence processes instance prior new activity relationship major decisions changes operations market entry product launch pol icy change wider changes business periodically throughout life activity relationship general assessment include identifying may aﬀected cata loging relevant human rights standards issues projecting proposed activity associated business relationships could adverse human rights impacts identified identifying mitigations might eliminate reduce level risk acceptable level large technology companies like facebo begun conducting hrias identify address human rights risks including emanating publishes human rights annual report within whi human rights eﬀects technologies explored certain risk mitigati strategies discussed however company obligation publish reports outlin ing details mitigation actions undertakes feedback civil society orga nizations addressed facebook commissioned hria evaluate role nocide rohingya myanmar yet scholars criticized hria failing cover salient human rights harms facebookʼs tools appropriate mechani sms mitigate harms moving remainder section explore propos existing aias related impact assessment strategies conformity assessmen data protection impact assessments public private sectors better underst emerging trends scope structure corresponding benefits risks associated implementation especially human rights first review canadaʼs directive automated development use aias evaluate mitigat harms ads government public service delivery next consider euʼs governance trategy evaluation act approach governance inclu ding proposed implementation conformity assessments identify mitigate risks emer ging private sector explore relationship act euʼs general data protection regulation gdpr feasibility data protectio impact assessments dpias evaluate mitigate human risks aluate euʼs digital services act dsa oversight mechanisms mitigate risks larg online platforms human rights latonero aaina agarwal human rights impa assessments learning facebookʼs fai lure myanmar carr center discussion paper series march global human rights statement corporation last modified december independent assessment human rights imp act facebook myanmar facebook last modified novem ber latonero aaina agarwal human rights impa assessments learning facebookʼs fai lure myanmar carr center discussion paper series march human rights impact assessments analysis recommendations conclude discussion implementation hrias may diﬀer complement integrated aias impact assessment strategies better ensure protection fundamental human ights canadaʼs directive automated canadian government released direc tive automated directive directiveʼs principal objectives ensure incorporation ads external public service delivery respects core adm inistrative law principles transparency accountability legality procedural fairness ensure harmful eﬀects algorithms administrative decisions assessed end directive includes accompanying impact assessment tool form questionnaire must completed prior development ads completion estionnaire helps internal teams compute raw impact score measures risk auto mation instance rights individuals communities health economi interests well eﬀects overall sustainability ecosystem level impact directive prov ides increasingly rigorous mitigation requirements extensive peer review notice human intervention process ovision meaningful explanation personnel training directive received attention within canada globally government criticized failing enforce requirements since directive came force may aias completed published per sense canadaʼs experience directive highlights challeng global technology institutional support deplo ying resources expertise necessary support implementation compliance tools straightforward process particularly emerging poorly stood technologies ads governance strategy april european commission released artificial intelligence act act act comprehensive approach governance proposed part larger governance strategy includi gdprʼs mandated evaluation oversight automated decision systems dsa proposed oversight large online platforms first provide hig overview act discuss proposal regulation laying harmonized ules artificial intelligence artificial intelli gence act european commission last modified april igence cardoso bill curry national defense skirt federal rules using artificial intelligence privacy commissioner says globe mail last modified february open government portal government canada accessed directive automated canadian overnment april human rights impact assessments analysis recommendations connection oversight requirements automated decision systems instituted gdpr proposed dsa act takes approach egulation establishing three primary levels risk high unacceptable act proposes diﬀerent levels oversight applications addition ally applications posing risk manipulation applications manipulate images aud video content title would transparency obligations applications fall thin category unacceptable risk prohibited uses capable nipulating individuals subliminal techniques applications use critical infrastructure medical devices education pose risk health safety fundamental rights credit scoring hiring decisions must undergo confor mity assessments attesting compliance act providers systems must monitoring system place actively collect cument analyze relevant data throughout systemʼs lifetime development use harmonized technical standards relation bias mitigation risk quali management encouraged facilitate implementation conformity assessments certain remote biometric identification systems however must assessed independent third parties notified bodies prov iders systems attest conformity requirements act throu moreover article act indicates systems conformity harmonized standards shall presumed compliance act poten tially enabling regime systems commentators expressed conc ern barriers participation human rights experts civil society organizations development technical standards could lead recognition harmonized standards address actʼs human rights strengthen accountability protection human rights article act could revised make assessment systemsʼ human rights risks explicit feature providersʼ risk management systems would help incentivize harmonized development human approaches risk management andards conformity assessments within outside furthermore lawmakers consider requiring providers systems submit conformity assessment conduc ted independent third party certain cases instance event monitoring requirements serious incidents reported addition potential requirement remove system market conformity assessment completed finally commission chosen designate defi ned list systems priori consider developing publishing clear objective methodology assigning level risk new systems itial risk designation existing systems ligh new evidence per recommendations civil socie makers also european digital rights edri panopty kon foundation algorithmwatch ropean disability forum edf bits freedom fair trials anec european consumer voice standardisation platform documented migrants veale frederik zuiderveen borgesius emystifying artificial intelligence act socarxiv july human rights impact assessments analysis recommendations consider allowing list prohibited practi ces title list practices title updated provide clear criteria guide ecisions risk designation criteria could based instance oecdʼs ongoing work develop framework classification risk methodology take account criter listed mantelero esposito hrias include guidance clarify situations deployment system poses unacceptable risks society allowed proceed light need harmonized techniques pro posals use gdprʼs data protection impact assessments dpias oﬀered ﬀective mechanism fulfill risk impact assessment obligations put forth act especially applications involving personal gdpr states dpias require type data processing likely result high risk rights freedoms natural persons especially required entity implementin new technology data processing used make automated supports article gdpr aﬀords ata subjects right subject decision based solely automated data subjects insights dpia help inform decision whether approve implementation automated dpias may eﬀective helping identify mitigate risks believe three primary limitations must considered first dpias primarily flagged applications use personal data plications scoping may inadvertently overlook applications pose signi ficant human rights risks without use personal data additional applications uch use control systems critical infrastructure may flagged strenuo oversight evaluation even though failure poses catastrophic human rights implication second dpias framed individual rather groups including broader societal nvironmental risks dpias primarily focused evaluating individual rights privacy human agency may adequately cover identification mitigation risks collective rights cultural identity third overarching guidelines hat included assessed dpias union general data protection regulation article automed individual cluding profiling data protection board edpb european ata protection supervisor edps joint opinion proposal regulation european parliament uncil laying harmonized rules artificial telligence artificial intelligence act may union general data protection regulation article data protection impact assessment hereʼs fix euʼs artificial ntelligence act european data protection board edpb european data protection supervisor edps joint opinion proposal regulation european parliame council laying harmonized rules artificial intelligence rtificial intelligence act may united kingdom information commissionerʼs oﬀice ico information commiss ionerʼs response european commission white paper artificial intelligence european approach excellence trust june mantelero samantha esposito evi methodology human rights impact asse ssment hria development systems computer law security review network experts classifying risk intelligence act fundamental rights civil society statement specifc details proposals update risk categories see issue paper ofing approach human rights impact assessments analysis recommendations great variability guidelines implemented practice across dpias strictly mandated made publicly available poses significant risk realization transparency accountability governance act could complement gdpr providing measures add ressing points another eﬀort underway provide greater transpare ncy oversight systems digital services act dsa dsa represen significant development ongoing eﬀorts identify address human rights impacts large online platforms vlops well algorithmic systems employ particular dsa could impose obligation vlops currently defined million active mont hly users still negotiation conduct annual risk assessments specific thei services appears combine aspects aias hrias specifically article dsa provides vlops must analyze assess systemic risks fundamental rights enshrined charter taking account impact content moderation recommender systems way platforms required evaluate impacts algorithm systems rights enumerated vlops must also submit independent audits assessing reporting compliance obligations dsa including requiremen conduct annual risk assessments platforms must report outcome risk assessments mitigations well implementation mitigations audit recommendat ions every six months compared dpias public reporting requirements risk sessments proposed dsa promising step forward several improvements certain provisions could help close potential gaps oversight mitigation human rights harms first articl dsa could amended clarify requirement conduct annual risk assessments flows platformsʼ general obligation institute human rights due dil igence processes including conducting risk assessments regularly critical stages lifecycle informed ungps latonero agarwalʼs emerging scholarship hria could help avoid pitfalls misconceptions associated hrias noted including potential manipulated decisions respect timin scope promote implementation ongoing human risk anagement processes platforms second given complexity scale scope impact risks assessments performed vlops follow mantelero espositoʼs recommendati hrias conducted complex scenarios case sid ewalk labs include consultations independent human rights experts civil society stakeholder would add higher level accountability legitimacy risk assessments well mitigations mantelero samantha esposito evi methodology human rights impact ass essment hria development systems computer law security review latonero aaina agarwal human rights impa assessments learning facebookʼs fai lure myanmar carr center discussion paper series march commission charter fundamental rig hts kingdom information commissionerʼs oﬀice ata protection impact assessments last accessed human rights impact assessments analysis recommendations proposed similarly article could amended include requirement organizations performing independent audits platformsʼ obl igations specific expertise human rights given identification systemic ris currently provision requires proven expertise area risk management technical competence capabilities well professional ethics finally given global scale platforms likely impact dsa outside supervisory authorities tasked enforcement dsa consider using udhr ungps basis developing idelines content hrias human rights due diligence would safeguard problem scoping risk assessments narrowly help promote gre ater consideration collective societal issues public health mental health environment electoral integrity towards systemic approach aias relied upon protect society potential harms inclusion risks fundamental human rights critical success generally object aias consists algorithmic system including data sets used train systems one current trends associated aias focus assessing sociotechnical aspects potential bias fairness explainability system immediately foreseeable measurable risks consequences metc alf caution aias may lead ontological flattening risks aias manner may inadvertently lead overlooking human rights risk altogether failure identify connection technical weaknesses downstr eam impacts including human occ secondarily chilling eﬀect misidentification facial recognition systems individualʼs freedom assembly expression tendency misinformation amp lify online misogyny radicalization sense range issues consider context aias far extensive traditional product reviews scoping aias narrowly lead false sense due diligence risk identification mitigation lowing tools risks human rights operate freely defining scope hria also presents specifi challenges focus exercise assessment quantifiable techni cal risks system potential impacts rights freedoms ind ividuals communities scope hrias tend broader aias default accordingly subject hria could system assessment likely require consideration risk impacts higher level example resulting deployment product diﬀerent contexts nature overarching business public activity presence adequate legal protections governanc structures including whether history human rights abuses deployed track record supply chain metcalf algorithmic impact assessment accountability impact proceedings acm conference fairness accountability tra nsparency human rights impact assessments analysis recommendations partners furthermore hria idance cautions preemptively narrowing scope human rights freedoms invest igated outset assessment instance consider risks impacts related right privacy equality addition need design appropriate metho dologies conducting aias hrias diﬀerent contexts operationalization also raises important considerations instance light administrative burden costs involv one approach taken companies set central unit develops internal policies procedures governance may incorporate components aias hrias equires hiring additional personnel appropriate expertise consequently increasing operating costs even central responsible unit place additional hurdles arise respect training diﬀerent teams identify mitigate potential risks partic ular account distinct skill sets roles responsibilities personnel various stages lifecycle design development deployment companies may opt conduct training one multidisciplinary workshop time struggle administer governance ent erprise level scalability challenges may compounded potential systems exhibit diﬀerent risks depending context deployment global scale whic systems may operate alternatively another approach taken companies especially enterprises may financial backing develop standalone responsi ble unit may hire external consultants help adapt existing policies pro cedures context upskill employees prioritize conducting standalone aias hrias applications believed higher risk absence proper guidance timing pact assessments also significant eﬀects outcomes credibility examp recent study hria commissioned facebook regarding potential implication genocide myanmar cautioned use hrias post exercises could become form ethics ashing instructed ungps hrias con ducted appropriate intervals aligned critical stages lifecycle part ongoing risk management processes human rights due addition study concluded hrias conducted earliest stages design conception ystems ante hria conducted sidewalk labsʼ project city toronto represents one potential example proach proposed digital solutions including anticipated leverage use assessed prior confirmation project project ultima tely abandoned experts involved consultation pointed human rights flaws proposed final report hria never publicly released exercise included extensive consultation subject matter experts local stakeholders cont ributed acceleration enhancement canon surveillance privacy xpert quits toronto project guardian october latonero aaina agarwal human rights impa assessments learning facebookʼs fai lure myanmar carr center discussion paper series march human rights impact assessments analysis recommendations existing human governance eﬀorts relat mantelero esposito point ias involve extensive research field work including consultations local stakeholde subject matter experts may desirable complex scenarios large smar projects likely burdensome costly serve appropriate models proje cts smaller given developing light touch hrias methodo logies calibrated nature context risk profile stage lifecycle light dynamic nature systems evolve adapt unpredictable ways reliance static governance tools aias may capture snapshot systemʼs operations upfront ineﬀective entifying potential downstream risks necessary mitigations rather continuous monitorin auditing deployed systems regulatory authorities may require development technologies help automate verification compliance complement human ove aiʼs technical capabilities progressing pace greatly outstrips ability govern harms primarily manual risk management processes adaptation policy frameworks increased investment public private sectors could help incentivize development technologies help implement governance scale ultimately design specifications implementatio tactics aias hrias tailored complexity scale context sco projects intended assess including phase development without secto guidance standards training qualified personnel operationalization aias hrias likely face significant hurdles inadequate address specific impacts ghts context poor outcomes associated conducting aias hrias whether due administrative burden failure identify mitigate risks expected negative feedback eﬀects legitimacy least part solution roblem could reside standards bodies ieee international organization standardiz ation iso nist national counterparts beginning develop standards confor mity assessments guide responsible development deployment aias related risk management processes law tools may significant eﬀects human rights diligence context providing guidance regarding best practices clarifying expectations accountability zhang saurabh mishra erik brynjolfsson joh etchemendy deep ganguli barbara grosz terah ons james manyika juan carlos niebles michael sellitto yoav shoham jack clark raymond perrault index nual report index steering committee institute stanford iversity stanford march hadfield rules flat world oxford iversity press may jack clark gillian hadfield regulatory markets safety papers mantelero samantha esposito evi methodology human rights impact ass essment hria development systems computer law security review canadian civil liberties associa tion lester brow toronto waterfront revitalization corporation ontario superior court justice file aﬀidavit kristina verner january human rights impact assessments analysis recommendations role standards certifications parallel development principles exploration regulations standard development organizations sdos natio nal international levels actively working developing standards con formity assessments standards may provide helpful guidance creating implementi eﬀective aias oﬀering definitional clarity operationalize responsible pri nciples practice conformity assessments used verify companyʼs product service process meets normative technical requirements contained standards additional step certification schemes developed enable accredited assessors certify conformity standards issuing certifica tion mark label however caution must taken ensure certifications confusing deceptive leading sense false trust products services witnessed oth processes mature likely certai industry standards conformity assessments incorporated legislation regulation condition compliance diverging approaches regulation propose europe elsewhere international harmonization mutual recognition standard conformity assessments emerge significant geopolitical issues critical protection harms also international trade goods services recognition global importance stand ards ieee demonstrated commitment development human approac report outlines conceptual framework addressing universal human values data agency technical dependability set principles guide developers users engaged design development deployment systems human rights identified firs general principle explicit reference international human rights framework releva nce ungps additionally ieee developing ethics certification program auto nomous intelligent systems ecpais ecpais currently developing set standards ocused bias transparency accountability developer implements ecpai standards add quality assurance mark products services intent raise consumer trust market iso international electrotechnical comm ission iec advancing conformity assessment standard risk management work joint committee artificial intelligence proposed artificial intelligence management system aims standard enable organ izations show implemented continually work improving processes addr ess bias fairness inclusiveness safety security privacy accountability applicability transparency jtc artificial intelli gence international organizations standardizat ion accessed august ethics certification program autonomous intelligent systems ecpais ieee fair deceptive ʻcertified organicʼ claims leave consumers verklempt federal trade commission human rights impact assessments analysis recommendations january congress mandated nist identify provide standards guidelines best practices methodologies procedures proc esses developing trustworthy systems two years nist required develop risk management framework enables assessment trustworthy iden tification appropriate risk mitigation strategies voluntary basis public rivate establish common definitions characterizations principles explainability transparency fairness june nist issued report efining diﬀerent types bias mitigation important first step establishing standards appropriate oversight risk important role standards conformi assessments expected play supporting compliance proposed act explicit linkages made technical assessments systems potential downstream human rights impacts eﬀorts evolve march european committee standardi zation cen european committee electrotechnical standardization cenelec esta blished joint technical committee artificial intelligence proceed development adoption standards related data including intern ational standards already available development organizations like jtc subcommittees artificial intelligence focus producin standardization deliverables address european market societal needs well und erpinning legislation policies principles values european commission issued report lining relevant standards support compliance act including standards fro ieee iso guide appropriate data governance risk management technical data rec ord keeping transparency accountability human oversight accuracy robustne cybersecurity implementation quality management system ensure compliance standards conformity assessments mature implementation certification schemes designed operationalize gaining promine nce certification defined attestation product process person ganization meets specified criteria certifications emerging technology training data model attributes development process organizational thics risk management processes combination certifications voluntar mandatory assessed stage common certifications cihon certification advancing eth ical practice reducing information asymmetries ieee transactions technology society nativi nigris watch standard ization landscape national standards organizations undertak ing similar eﬀorts canada national counter part nist recently received additional funding canad ian government advance development adopt ion standards including risk management standards conformity assessment schemes schwartz proposal identifying managing bias artificial intelligence national institute standards technology nist june assigned task creating risk anagement framework national artificial inte lligence initiative act act included nation defense authorization act national defense authorization act fiscal year actions library congr ess accessed april human rights impact assessments analysis recommendations proposed applications euʼs act example developers applications perform voluntary assessments certain applications required complete mandatory thi conformity assessments widely used many industries may lack legitimacy due inherent potential conflicts inte rest low accountability lack enforcement assessments rigor ous extraordinarily costly require qualified assessors diﬀicult find complex development assessment certifi cation methods automate streamline regulatory compliance one way searchers industry investigating new ways implementing governance certification processes still rly stage initiatives like responsible artific ial intelligence rai certification developed esponsible institute collaboration world economic forum hold first independent accredited certificati programs emerge rai certification seeks support implementation responsibly built systems objective review process certification incentivize implementation appropriate risk identification mitigation strategies however significant challenges successful implementation example false positives certification provided even though certain crite ria met false negatives certification provided even though crite ria satisfied development appropriate standards certificat ions depend access high quality data operations specific collection monitoring measurement therefore critical eﬀe ctiveness standards certifications essential protecting human rights ontexts applications human rights appropriately defining evaluation criteria assessm ent verification processes contained standards certifications critical field concepts fair accountable trustworthy still development defin ing enforcing appropriate procedures uphold human rights equally muddled promising uncover human rights risks whether strategies place mitigate risks use standards certifications indicate human rights due diligence cauti ously implemented conclusions recommendations given important human rights considerations rai sed use systems closer linkages made study practice lessons learned implementation hrias particular aias important role identifying technical foundations needed promote respect human rig hts turn international human rights law whittlestone jack clark gove rnments monitor development arxiv preprint rai certification beta responsible artificial telligence institute accessed hadfield regulatory technologies solve problem university toronto schwartz reisman institute technology society last modified april see also gillian hadfield rules flat world oxford uni versity press may jack clark gillian hadfield regulatory mark ets safety papers human rights impact assessments analysis recommendations serve helpful guide identifying connec tions systemsʼ technical features human rights implications especially vulnerabl individuals communities significant work remains develop best practices successful implementation aias hrias including considerations related aias integrate features hrias appropriate scope structure scalability ming administrative burden respect however emergence common approaches met hodologies aias hrias aided development based echnical standards conformity assessments certification schemes well customized idance implementation variety contexts policymakers advance discussions legisla tion covering algorithmic systems following recommendations could help ensure respect human beyond legislation requiring large platforms conduct risk assessments operations require considerations risks internati onal human rights freedoms disclosure actions taken mitigate risks quality management risk management standar developed explicitly address risks international human rights fre edoms organizations consortia empowered legislat ion perform independent risk assessments conformity assessments audits sho uld include personnel civil society organizations proven human rights expe rtise regimes systems complemented monitoring triggers independent conformity ass essments audits certain cases instance situations companyʼs viola tion obligations raises human rights concerns clear avenues also estab lished people aﬀected systems groups representing flag harms thereby trigger investigations enforcement bodies model risk assessment methodology explicit addresses human rights concerns triggered systems developed involvement relevant stakeholders begin defining approaches human rights risk assessments specific applications algorithmic systems notably context large digital platforms systems build ing best practices identified ungps technical assessment defined expert group emerging scholarship methodology include procedures lin king technical performance systems potential downstream human right impacts individuals communities particular higher risk vulnerability given critical role human rights considera tions development standards conformity assessments certification schemes governments establish meaningful opportunities support mechanisms subsidies travel human human rights impact assessments analysis recommendations rights experts civil society organizations articipate processes national international levels facilitate governance scale policymakers ensure appropriate coordination research development spending standardization pilot programs regulatory sandboxes celerate adoption technologies echnical tools enable bias fairness detection mitigation conti nuous monitoring system performance customization certification schemes ens ure robust implementation variety contexts beginning applications systems acknowledgment earlier version paper published art harvard kennedy school carr center human rights policy discussion paper series
