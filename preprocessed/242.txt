principles progress update principles progress page intentionally left blank principles progress updatetable contents introduction internal governance operations resources research tools responsible practices product impact supporting global dialogue standards policy conclusion end notes principles progress year seen help people find useful information conversational way speak friends family thanks responsible research breakthroughs generative language models enable online translation across dozens new languages foster equity genomic across populations speed damage natural disasters humanitarian relief environmental efforts sampling ways already longterm positive impacts society across business healthcare education sustainability sectors much world flurry research development delivering future already products services emerging opportunity responsibility proactively identify mitigate risks time establish effective frameworks embody technology practices values governance responsible impact naturally raises new questions governance safety fairness effect equitable economic opportunities core google products google ask questions daily remain committed sharing lessons learned emerging responsible innovation practices drawing upon years using machine learning decade research rooted near mission organize world information make universally accessible useful google innovation strategy iterate process innovation means create projects exemplify engineering excellence earliest moments embody values manifested google principles incorporating responsible practices fairness safety privacy transparency early developers machine learning workflow throughout product development lifecycle principled approach research development also practical help avoid burning engineering cycles spent retrofitting technology issue emerges launch even much later aligns product excellence mantra put user first focus building everyone since launched principles built tested governance process align projects across company principles center governance three pillars principles progress principles serve ethical charter inform policies education resources ethics training technical tools test evaluate monitor application principles google products services structures processes include risk assessment frameworks ethics reviews executive accountability year expanded central operations team principles implementation across google product development lifecycle responsible innovation recently moved google office compliance integrity centralized governance across google product areas milestone moment reflects growing maturity governance strategy working complement internal frameworks working number governments organizations exploring concepts governance instance organizations like international organization standardization iso national institute science technology nist publishing management frameworks early next year singapore released model governance continues talk stakeholders financial services veritas india ministry electronics information technology meity considering niti aayog proposed responsible incorporated india mission south debated legislation governments working guidance ceo said important regulate important regulate legislation related principles standards help lower risks people without unduly stifling innovation undermining promise social benefit global level course frameworks overlap important regulatory issues including content safety child safety privacy consumer protection holistic approach help keep new rules impeding innovation competition related emerging technologies hope sharing progress lessons learned issues responsible algorithmic transparency technologies supports important progress made across global community principles progress principles assess view following objectives believe socially beneficial likely benefit people society substantially exceeding foreseeable risks downsides avoid creating reinforcing unfair bias avoiding unjust impacts people particularly related sensitive characteristics race ethnicity gender nationality income sexual orientation ability political religious belief built tested safety designed appropriately cautious accordance best practices safety research including testing constrained environments monitoring appropriate accountable people providing appropriate opportunities feedback relevant explanations appeal subject appropriate human direction control incorporate privacy design principles encouraging architectures privacy safeguards providing appropriate transparency control use data uphold high standards scientific excellence technology innovation rooted scientific method commitment open inquiry intellectual rigor integrity collaboration made available uses accord principles work limit potentially harmful abusive applications addition objectives design deploy following application areas technologies cause likely cause overall harm material risk harm proceed believe benefits substantially outweigh risks incorporate appropriate safety constraints weapons technologies whose principal purpose implementation cause directly facilitate injury people technologies gather use information surveillance violating internationally accepted norms technologies whose purpose contravenes widely accepted principles international law human rights principles progress updateinternal governance operations offers unique range risks along unprecedented benefits world chief among issues technical safety systems function engineers designers planned societal concerns systems reflecting historical unfair bias believe rigorous structured operations risks consistently identified addressed acknowledging even despite best efforts issues harms identified advance accomplishing aims rests three pillars principles education resources structures processes first pillar principles google principles represent first foundational pillar principles serve ethical charter key component google product excellence efforts consistent policies responsible practices enable structured governance let scale practice principled innovation second pillar education resources second pillar governance google commitment providing necessary education resources structured employee education programs including onboarding new technical hires offer wide variety resources help googlers learn skills necessary apply principles frameworks early research development process possible programs reaching portion google population course completions tech ethics training offered employees across roles product areas geographies increased quarter quarter exceeded goal employees engagement responsible innovation challenge set interactive puzzles test employees recall principles launched last year groups gone moral imagination help employees explore potential outcomes outside lived experience continue create innovative internal training programs teach skills needed address emerging challenges example year launched new instructorled course helping users navigate world improving products explainability toolkit geared toward user experience designers product managers principles progress developers introduces concept explainability showcases best practices explaining products work internal ratings usefulness course content average stars principles programs designed educate also motivate mobilize participants take action programs reported last year grew scope reach programs volunteer projects google practice offering employees working hours equivalent one work day per week dedicate passion project could business benefits company value users approval manager example principles pioneers program emphasis people represent points view currently underrepresented technology industry grew year pioneers pilot end google international offices principles pioneers constitute internal community trusted trained employees serve principles aip advisors identify global fairness harms human rights related concerns stress testing products also supplement work profair product fairness also sits within central principles operations team profair explicit specialization goal testing products potential weaknesses biases building centralized experience build upon lessons testing across different models year also launched new internal program senior managers leaders executive principles ethics fellowship program includes educational workshops training principles leaders across multiple product areas geographies based principles ethics fellowship launched trained diverse set employees across global offices employee resource groups learn responsible contribute perspectives google aip operations fellowship among duties fellows develop fictional future scenarios ethics challenges addressing topics deep fakes misinformation hypothetical scenarios supplement growing body responsible innovation case studies ethics review teams draw upon references making decisions new executive principles ethics fellowship tailored business decision makers needs inaugural cohort consisted sixteen executives across ten product areas including cloud devices services hardware youtube principles progress updateai principles case studies case study generation models challenge google generation models models allow users provide text prompt specifying image image generated directly text principles reviewers recognized allowing free generation human images enables many significant potential harms example frozen text encoder diffusion model diffusion model diffusion modeltext text embedding image image golden retriever dog wearing blue checkered beret red dotted principles progress fakes images interpersonal violence images conveying harmful stereotypes pornographic images consequently decision made block ability generate people initial testing even internally internal launch progressed users expressed disappointment could generate people models especially similar models allow generation images people researchers tried find safe way allow least images people generated accomplish employed scaled adversarial testing enabled team generate synthetic images human faces check see whether could use existing classifiers selectively block generation photorealistic human faces faces might belong resemble real people researchers able show existing face classifier works well even generated imagery data hand able loosen prohibitive people allowed rule began allowing generation imagery people long photorealistic face present image however mitigation helped reduce risk deep fakes confusion real person remained risk harms unfair stereotyping approach guidance central responsible innovation team google exploring framework responsible externalization balances value external auditing risks unrestricted data requirements models led researchers rely heavily large mostly uncurated datasets approach enabled rapid algorithmic advances recent years datasets nature often reflect social stereotypes oppressive biased viewpoints derogatory otherwise harmful associations marginalized identity groups run dedicated rounds adversarial testing find flaws model enlisted expert red teaming members product experts intentionally stress test system adversarial mindset help designed systems automatically detect filter words phrases violate policies prohibit users knowingly generating content sexually explicit hateful offensive violent dangerous illegal divulges personal information also eliminate risks exposing personally identifiable information avoiding images identifiable human faces start stringent filtering refine work minimized risk eliminated continuously improving capabilities area principles progress updateimagen relies text encoders trained uncurated data thus inherits social biases limitations large language models risk imagen encoded harmful stereotypes representations guided decision release imagen public use without safeguards place finally extensive work auditing image labeling models forms social bias comparatively less work social bias evaluation methods models conceptual vocabulary around potential harms models established metrics evaluation essential components establishing responsible model release practices outcome leave empirical analysis social cultural biases future work small scale internal assessments reveal several limitations guided decision release model time case generative models imagen may sometimes poor job reflecting parts data distribution especially underrepresented parts may compound social consequence dataset bias imagen exhibits serious limitations generating images depicting people human evaluations found imagen obtains significantly higher preference rates evaluated images portray people indicating degradation image fidelity preliminary assessment also suggests imagen encodes several social biases stereotypes including overall bias towards generating images people lighter skin tones tendency images portraying different professions align western gender stereotypes finally even focus generations away people preliminary analysis indicates imagen encodes range social cultural biases generating images activities events objects result principles review google aims make progress several open challenges limitations future research principles progress study dataset avoiding unfair gender bias challenge researchers team recently developed new studying preventing gender bias machine learning alignment principle avoid unfair research explored gender translation english spanish english german research leverages ways different languages employ gender markers investigate potential gender bias translation models spanish pro drop language means subject pronouns optional spanish german grammatical gender mark gender adjectives modify people objects spanish single possessive pronoun english german separate pronouns grammatical gender differences across languages pose challenge machine translation systems challenge especially difficult translating language without subject pronouns spanish one required gendered subject pronouns english traditional neural machine translation nmt methods translate sentences one one gender information often explicitly stated every sentence seeking novel way address challenge researchers built new model incorporates context surrounding sentences passages translated improve gender accuracy personal pronouns translated translating languages without grammatical gender responsible challenge lies training machine learning systems choose appropriate pronoun maintain gender agreement references throughout content gender translation mistakes especially harmful errors given gender markers often convey person gender identity translate team new dataset built test performance model using gender differences across english spanish german challenge model correctly translate people genders across multiple sentences principles progress updatethe approach researchers applied principles review dataset proactively requested fairness testing reviewers testers assessed team rationale using wikipedia source data researchers chose wikipedia biographies entries geographically diverse contain multiple sentences refer subjects third person using many pronouns reviewers testers also looked researchers strategy prioritize equal representation feminine masculine identities within dataset acknowledging many biographies people available wikipedia researchers used articles groups referred using english train models incorrectly generate gendered pronouns addition reviewers testers looked researchers decision investigate gender translation accuracy names sourcing wikipedia biographies people different nations spread across world outcome result translated wikipedia biographies dataset used evaluate gender bias translation models dataset enables novel method evaluation help reduce gender bias machine translations instance refers person known gender researchers could use dataset compute model accuracy translations refer person dataset provided useful performance measurements new contextaware models using dataset researchers determined models made fewer gender translation errors previous models translated sentence sentence find examples kinds improvements model showed blog research alignment principle accountable people principles reviewers recommended researchers publish data structured document offering details dataset created tested respect principle uphold high standards scientific excellence researchers decided share dataset publicly support improvements systems focused pronouns gender translation researchers make clear dataset focuses specific problem related gender bias aim cover challenges nmt prescriptive determining optimal approach address gender bias dataset research behind aim foster progress challenge across global research community principles progress case study inclusive equitable skin tone scale challenge skin tone plays key role experience treated world factors interact technologies show products built using today artificial intelligence machine learning technologies perpetuate unfair biases work well people darker skin tones computer vision type allows computers see understand images people environments systems designed everyone mind may see understand people darker skin building inclusive systems requires intentional collecting representative datasets training evaluation developing right evaluation metrics building features work users pioneering gender study demonstrated commercial apis perform substantially worse images people color women gender shades evaluated api performance across genders skin tones well intersectionality two findings study inspired members community explore inclusive systems develop best practices measuring improving documenting models datasets represent skin tone approach categorize continuous spectrum skin tones around world meaningful categories work evaluating addressing fairness principles progress updateconsiderations question google asked last two years date tech industry categorizing skin tone fitzpatrick developed harvard dermatologist thomas fitzpatrick fitzpatrick scale originally designed assess sensitivity different skin types dermatological purposes result scale skews towards lighter tones tend scale may work dermatological use cases relying fitzpatrick scale development resulted unintended bias excludes darker google researchers reached ellis monk associate professor sociology harvard university whose focuses social inequalities respect colorism address biases develop representative scale leveraged extensive research skin tone colorism research focuses varying geographic exposure radiation yields different skin tone distributions within across ethnoracial populations monk consulted experts social psychology social categorization well underrepresented communities learn perceived scale monk research resulted monk skin tone mst scale inclusive scale explicitly designed represent broader range skin tones mst scale used national institute health nih university chicago national opinion research entire community mst scale leveraged evaluate datasets models better representation people darker skin year google research center responsible technology partnered monk begin use scale internally plan openly release mst scale larger community openly releasing scale broader industry aim make possible others incorporate scale development processes practitioners collectively improve area globally order validate monk skin tone scale purposes researchers working skin tone fairness google research launched study within peer review study goal understand well participants across diverse communities felt skin tone represented within scale helping identify whether fairness efforts categorization could uncover address potential biases faced across populations evaluations prevent common human biases inadvertently getting reproduced algorithms principles progress participants found mst scale inclusive fitzpatrick scale better representing skin tone also evaluated mst scale representative skin tone point beauty palette used industryleading cosmetic brand known inclusivity larger scales like challenging use cases difficulty applying many tones consistently across wide variety content maintaining statistical significance evaluations example become difficult human annotators differentiate subtle variation skin tone images captured poor lighting conditions outcome mst scale transforms continuous skin tone spectrum tones introduce enough granularity reflect diversity skin tones without increasing complexity enabling training evaluation improve systems understanding skin tones improve fairness evaluation mst internally using mst scale numerous products including pixel photos image search example global users make queries google images see option refine search results skin tone continue collaborate monk refining scale encourage fairness researchers developers users offer improve scale develop models responsibly line google principles principles progress updatein addition designing launching education offerings central principles operations team manages internal hub content put principles practice include case studies streamlined information various services hub main entry point requests ethical reviews new applications central principles operations team finally complement existing review procedures frameworks offer bespoke moral imagination workshop product research teams workshop enables ethical awareness deliberation topics relevant features product development early team project planning process year since first piloted workshop teams learned workshop provides useful bridge taken existing training modules introductions principles tech ethics helping apply knowledge work face daily team found creating space help engineers product managers create mental model ethics resources technical tools consultations fairness help support team culture ethical decision making workshops delivered date feedback workshop participants shows sessions influenced product research strategies measurement ethical strategies effectiveness third pillar structures processes third pillar governance consists structures processes evaluate guide development use use approach focuses reviews areas needed given time includes sensitive topics change time depending emerging cultural technical issues current examples include surveillance creation synthetic media often termed fake news principles process able assemble diverse set stakeholders ensure consider variety perspectives effectively manage risks risk assessment year central principles operations team adopted updated risk assessment framework raf help identify measure analyze ethical risks throughout life product map risks appropriate mitigations develop clearer standards acceptable risk updated raf also draws upon best practices google office compliance integrity enterprise risk management efforts aligned upcoming regulatory requirements principles raf grounded research nuanced sociotechnical harms taxonomy discussed embedding ethical risk management google principles progress principles reviewers provide launch guidance depending product area may include approval approval recommendations holistic rework depending risks identified within framework principles reviews consultations prioritize evaluation impact humans environment product likely operate risk function magnitude harm multiplied likelihood frequency inherent risk amount risk existence absent effect control environment ask reviewers consider impact risk sociotechnical harm probability likelihood frequency occurrence inherent risk useful measuring prioritizing actual prospective impact risk exposure thinking overall potential benefit risks harms also consider harm launching new technology application whether might address current harm issues could remain unaddressed launch example applications help medical specialists diagnosing disease might raise questions potential fairness privacy concerns must weighed value delivering solutions market population may benefit innovations medical challenges principles raf serves foundational support enable principles reviews reviews gather detailed risk information inform provide context central principles reviews reviews may necessary related harms taxonomy draws systematic scoping review crossdisciplinary research including academia ngos government documentation guidance help define describe potential harms algorithmic systems developing taxonomy involved social scientists researchers ethics program managers engineers reflects hundreds analyses drawn principles reviews consultations product teams ethics reviewers central operations team multidisciplinary expertise including ethics philosophy human rights user experience research design engineering linguistics law trust safety raf harms taxonomy help set clear expectations product teams scale consistency equip principles reviewers proactive risk harm identification response strategies enable arrive stronger outcomes alignment principles reviews addition directly aligned principles review process google general machine learning workflow developers strategic approach principles progress updatehelped operationalize capabilities preventing identifying mitigating responsible concerns unfair bias advising teams defining problem solve constructing preparing data building training model evaluating performance integrating products services monitoring performance variations specific product areas customized ethics reviews cloud devices services health cloud responsible governance process example two different types assessments tailored cloud development processes enterprise contexts healthcare finance retail entertainment reviews team year central principles reviews team conducted hundreds ethics reviews across research products including proposals future applications datasets training evaluating models teams representing flagship products including assistant ads youtube search requested principles reviews reviews spanned across large language models datasets community responsibility content quality fairness issues india among topics profair principles consultations product teams year explored potential fairness issues models products utilize text image generation person object detection classification functions teams across google majority reviews approved launch reviewers suggestions applied datasets models consistent outcome create publish detailed documentation datasets models form structured transparency artifacts known data model cards see following section details function like nutrition labels providing information provenance data data card model performance tested fairness model card launches test online space people outside google try experimental applications utilizing lamda language model dialogue applications entailed multiple reviews taking careful approach lamda consider valid concerns fairness factuality anthropomorphization tendency humans see human traits inanimate principles progress technologies date lamda gone eleven distinct principles along rigorous research testing based key metrics quality safety system ability produce statements grounded facts research released earlier year details work goes responsible development lamda addition applied risk framework principles progress updateemerging framework applications pursue surveillance help principles reviewers evaluate technology research context four applications pursue publicly state alongside principles create guidelines based trends growing library cases external research subject matter community expertise year iterating piloting new framework inform responsible development applications gather use information within internationally accepted norms socially beneficial uses surveillance technologies emerging framework pivotal understanding articulating social benefit outweighs potential harm principles review dynamic dataset uses machine learning enable near measurement land cover land use intended positive environmental social impact research featured year dynamic world uses google earth engine combining satellite imagery geospatial datasets analysis capabilities even use cases like dynamic world considerations surveillance arise often international disagreement counts surveillance social norms shifting even faster pace sometimes leaving governments looking private sector guide precedents serve guidelines fact concept norms mean different things different people across cultural regional temporal contexts explored relevant international norm outside broad big brother definition intersections surveillance principles considerations privacy human rights downstream harm conventional applications gathering data might acceptable particular use cases critical work complex issues based internal understanding also seek objectivity learned expertise engaging external experts working google internal human rights team external experts business social responsibility bsr specializes business human rights conducted landscape assessment ethical standards norms one google key findings minimum set norms acceptable use principles progress technology must meet consistent privacy human rights ethical obligations include widely known tenets human rights legitimacy legality necessity proportionality framework reviews findings helped inform framework assessing surveillance application pursue part principles reviews emerging guidelines consists steps review end use surveillance manifest different ways therefore different implications include categories targeted mass indiscriminate surveillance also several types surveillance tech used home workplace public settings collect video audio forms data considerations vary depending end use impacts types potential harm must assessed review user often use cases involve tensions conflicting rights google central responsible innovation team piloting framework support principles reviewers assess new projects google raise potential surveillance issues public sectorprivate end use review user determine imp acts appropriate mitigation relevant principles consideration respective user groups framework ethical review applications surveillance concerns principles progress updateof users security privacy example states emergencies pandemic governmental forms surveillance might acceptable normal times public health reasons contact tracing however transparency oversight also critical factors explanations surveillance easy users access understand mitigations layer safeguards including guidance design use interpret outputs implemented design development phases example model data cards help make potential surveillance related implications transparent ultimately mitigating harmful forms surveillance requires taking approach safeguarding users society first layer protection consists preventative measures specifying contract terms could include feature restrictions mandatory face blurring ongoing ethics assessments engaging independent third parties track monitor report use technologies highly valuable nascent domains surveillance part emerging framework assessing risk surveillance may violate international norms customized mitigation strategy prevent mitigate track support product team efforts address issues launch prevent scope terms mitigate partnership guidance training track ongoing review determining scope use terms use design develop deploy technology mannerreviewing effectiveness prevention mitigation measures time specific contract terms may include feature restrictions technical limitations mandatory face blurring operational grievance mechanisms channels report misuse technology quality assurance procedures verify input data representative biased incomplete procedures identify potential unfair bias technology design testing development deployment outcomes algorithims explainable subject independent restrictions use cases known violate human rights technical limitations restrictions training guidance direction human operators design use interpret outputs work users conduct human rights due diligence deployment mitigations adequately address potential harms caused review cycles assess whether technology used intended without adverse human rights impacts may include securing feedback user affected rights holders stakeholder organizations experts partnering independent organizations use technology review adequately mitigations address potential harms google central responsible innovation team piloting mitigation strategy support product teams consider potential surveillance concerns early product development lifecycle principles progress research tools responsible practices twenty years ago google started using machine learning eleven years ago machine learning especially sort known deep learning helped achieve rapid progress development research teams long forefront technical innovation today reinventing innovation focusing responsible practices research responsible product development google researchers frameworks processes enable confidently pursue publish research incorporating best practices responsible rai development teams design deploy tools help quickly identify consistently remediate known problems unfair bias datasets models research published externalized incorporated products responsibly responsible research researchers continue present leading conferences around world including computer vision pattern recognition conference cvpr association computing machinery fairness accountability transparency facct conference conference neural information processing systems neurips published papers notable topics achieving trustworthiness maintaining fairness uses bringing impacted communities research ensuring culturally enabling new approaches prototyping humancentered adversarial testing lockstep google central operations team processes principles reviews governance described previous section research teams often begin rai evaluation process technical work early product development lifecycle workflow using adversarial testing stress testing model product probe errors harms conduct adversarial testing well learned employ variety techniques leverage social cultural experts google built profair team described earlier create centralized experience adversarial testing incorporates global perspectives engage testers historically marginalized backgrounds whether testing googlers via google product inclusion equity team partnership principles progress updatevolunteers google employee resource groups trusted external vendor diversity testers critical ensuring models assessed across wide spectrum scenarios values also practice thoughtful inclusive equitable task design guide humans label data datasets also known raters order achieve high quality fair evaluations synthetic data always scale number human testers get reliable enough results deepmind made major using machine learning generate synthetic data adversarial datasets preserve privacy require gathering personal information offer source largescale representative data needed model training provide benefits data one aspect adversarial testing data quality especially data generated humans adversarial test cases lack diversity translate poor test coverage areas sufficiently covered resulting failures may discovered production deployment one current focus areas researching high quality analytics characterize adversarial prompts large models outputs tools continued develop update suite rai tools make available public year integrated model remediation library provides techniques addressing bias fairness issues models internal platform automating common workflows across company also available publicly learning interpretability tool lit updated version language interpretability tool released year identifies different inputs affect prediction trace error back training data even measure correlations within model already used improve models search updated lit tool handle number data sizes lit used past internally researchers use tools developed know data kyd first piloted last year year released catalog datasets tool web site kyd help responsible data analysis training evaluation sets centering four concepts provenance data come content data principles progress associations among sensitive content data associated labels data types categories data four analytic concepts focused downstream harms identified research literature useful coming recommendations data filtering simply flagging results documentation example data analysis language models found recent paper published scaling language modeling datasets research team also building datasets meet product needs existing datasets inadequate including leveraging datasets partnerships dataset generation projects include building new image dataset centering diverse representation subjects internal product fairness testing development creating internal synthetic datasets built privacy top mind emphasis photographs inclusive creating externally available wikipedia dataset help avoid unfair gender bias understanding context emerging best practices responsible require clear articulation broader societal context technology may deployed includes considering unfair biases unjust impacts norms values real world situations models operate best practices form basis rai capabilities societal knowledge gathered organized various research knowledge production efforts across research teams office compliance integrity societal context understanding tools solutions scouts research initiative provides people systems scalable trustworthy societal context knowledge required realize responsible robust year scouts societal context repository scr shown help improve tools google shared world enable responsible practices important areas content moderation google incubator building technology explores solutions threats open societies used scr knowledge base supplement balance datasets prior model training perspective api product used identify toxic content online comments result terms used bias mitigation fresher greater coverage additionally entire bias mitigation process perspective api used trusted news principles progress updateinformation organizations around world including wired new york times pais monde transparency artifacts researchers continue iterate designs new transparency artifacts accompany datasets including ones specific particular sectors example contextualized adaptation original datasheet questionnaire applications complement structured transparency artifacts model cards examples externally available model data cards recent google large models include data palm datasheet model recently launched data cards playbook free online guidance people research pair team based workshops conducted major conferences facct create structured transparency artifacts ensure data excellence data clean representative fit purpose google people research team launched data cards playbook playbook helps teams create structured transparency artifacts datasets principles progress benchmarks play important role rai process generative models produce text outputs images music like benchmarks discover areas need fine tuning lead development tools needed downstream users establish measurable rai baselines comparing understanding strengths weaknesses machine learning systems year updated rai language benchmarking capabilities include measurements related toxic language unfair discrimination expressions stereotypes forms marginalization also developed benchmarks generation tasks include sensitivity changes context style images responsible generation responsible generation refers methods help control outputs generative models better meet responsibility goals example may want chatbot reply toxic language even coaxed number recent advances promising responsible generation exploring applications new generative models like palm explosion research prompt models imagen palm help control improve models output example google discovery chain thought prompting illustrated including reasoning steps significantly improve language models responses methods search prompts also used identify kinds prompts lead unintended model particularly exciting relatively new approach control goes beyond using called parameter efficient tuning recently shown small datasets used tune special input model results significantly better another significant branch work control language models focuses control output instead inputs example methods developed reduce likelihood toxic recently mitigate unintended technical guidance responsible product maturity model assessment help scale responsible emerging best practices monitor control model performance time responsible human centered technology team focuses technical realization principles developed internally deployed product maturity model assessment pmma principles progress updatethe pmma helps teams across google leverage machine learning products understand rai domain emerging best practices tools measure maturity models use cases proactively improve maturity models achieve desired rai outcomes use cases time pmma centers extensive questionnaire technical questions based current responsible practices field research development questions sourced latest research emerging academic field responsible internal external google along emerging rai best practices currently implemented google product teams team research scientists engineers product managers user experience specialists technical writers program managers generate refresh pmma questions reflect new advances technical knowledge pmma designed gauge adoption rai practices reflect principles maps survey results maturity model framework prescriptive nature clear courses action provided help teams improve models one maturity level next one teams access pmma results via interactive dashboards visualization tools apply critical input adjusting models closely aligning principles addition understanding models need improve product teams taken pmma consistently ask concrete steps start maintain responsible practices time meet need enable rai across google building library relevant technical guidance documents tooling also creating centralized technical infrastructure eventually automate rai technical tasks underlie pmma questions allowing product teams conduct tasks manner repeatable accurate built scale principles progress impact three tiers complementary governance structures place put principles practice teams building products across google first tier exists within product teams product teams include dedicated user experience privacy trust safety experts providing deep functional expertise consistent principles second tier set dedicated review bodies expert teams includes central principles team office compliance integrity discussed earlier report also includes specialized reviewers expertise specific areas cloud expertise enterprise offerings devices services expertise used responsibly within hardware also health ethics committee reviews health research development across company google employees encouraged engage principles review processes throughout project development lifecycle addition privacy advisory council pac reviews projects potential privacy concerns including exclusively issues related third tier governance structure advanced technology review council atrc rotating committee senior product research business executives council represents broad google atrc addresses complex cases could affect multiple products set precedent technology new council also makes decisions urgent escalations establishes dedicated functions support responsible practices embedded within google product teams google operationalizes practices across company via internal principles ecosystem principles progress policies impacting multiple product areas involves making challenging decisions require deeply considering trade offs ethical risks certain new applications potential business opportunities prioritizing social benefit example year atrc completed two reviews lamda deciding prioritize rigorous responsible generative development testing guardrails speeding technology market directly indirectly responsible research training tools important contributors ensuring principles comprehensively reflected within wide spectrum product innovations announced throughout year example aip socially beneficial principle helps think overall benefits exceed risks including potential privacy concerns information company strive use advanced help people use products services make content available spread misinformation growing global challenge amount misinformation created speed spreads seems like natural least mitigation would need large training dataset misinformation help address outlined youtube continuously training youtube system new data collected responsibly clear user policies gathering informed consent youtube looking leverage even targeted mix classifiers keywords additional languages information regional analysts identify narratives main classifiers catch time make youtube faster accurate catching viral misinformation narratives youtube also working ways update models often order catch hyperlocal misinformation capability support local languages also look opportunities support humanitarian uses example help refugees veterans war ukraine updated look speak android app allows people use eyes select phrases spoken aloud languages include ukrainian broad approach social benefit year launched global initiative bring together research technology funding accelerate progress united nations sustainable development goals sdgs commitment include million support ngos social enterprises working accelerate progress towards sdgs based learned far believe capabilities financial support provide grantees cut half time cost achieve goals also provide fellowships principles progress google employees work alongside organizations six months aip avoid creating reinforcing unfair bias unfair bias exists world datasets models could reflect including unintentionally principle helps consider earliest ideation stage harness truly build everyone cultures around world continue create new programs address emerging challenges fairness example recently launched equitable automated speech recognition program google aims identify eradicate unfair biases voice company mission making world information universally accessible useful global approach enabling communication people across world matter language abilities clear focus biggest product announcements project relate app helps improve communications impaired speech expanded globally available canada australia new zealand india also expanded project euphonia research initiative works community organizations people speech impairments create inclusive speech recognition models year added french hindi japanese also launched language support languages world using universal speech model trained languages largest language coverage speech model date also used add new languages technical milestone google translate first languages added using machine translation trained using texts new language without translations language enable google accelerate addition new languages especially ones relatively translated texts available help give voice world populations aip built tested safety design systems strong security practices avoid user harms including unintended uses results example starting march year chrome rolled new model identifies times potentially malicious sites phishing attacks previous model resulting safer secure aip accountable people using emerging practices designing systems captured people research guidebook first released update regularly design systems humans loop clear opportunities user feedback relevant explanations year expanded upon offerings principles progress updatelaunching explainability course also presented aip incorporate privacy design principles safeguard users privacy apply google privacy principles principles year announced several new uses models keep information private one main proactive practices across google alignment principles ranged convenient transcription options pixel recorder web browsing minimal interruption via new system relevant permission prompts continue use privacy design strategies example pilot update google updated speed limit information google requests photos trusted imagery partners already gather roadway imagery improve delivery routes photos specific stretches road also include speed limit sign partner photo available use combination help operations team identify sign image extract new speed limit information add google maps reference images taken public roads partners required blur identifying information faces license plates extra layer privacy blur photo receive delete photo use update map conference announced user information sent google servers anonymized techniques including use differential privacy edge aip uphold high standards scientific excellence innovation technical field rooted scientific method requiring intellectual rigor multidisciplinary collaboration knowledge sharing google parent company alphabet continued important contributors scientific research papers topics range applying neural networks restore ancient texts integrating deep learning disease detection evidenced place top global corporate research nature make responsible research accessible findable early curated dedicated external collection research papers focused topic responsible aip made available uses accord principles develop utilize principle determine limit potentially harmful deployments including could adapted also consider role providing tools well developing custom solutions integrating tools enterprise customers principles progress responsible approach prioritizes evaluations development guidance enterprise customers implemented safely build deploy applications using google cloud accounting unique social organizational contexts example align cloud vertex principles cloud responsible team conducted evaluation incorporated mitigations risk concerns education opportunities including evaluating testing unfair bias development developing product features enhance privacy limit personal identification increasing product documentation transparency support customers responsible use google cloud vertex vision evaluated cloud responsible review team unfair bias privacy transparency launch principles progress updatesupporting global dialogue standards policy practicing responsible research development requires collective approach vital share learnings receive feedback progress world larger ecosystem continue develop publicly available content explains core products services work tradition search youtube realize raising awareness first step supporting international conversations responsible share learnings emerging best practices via free online educational content programs year increased principles online courses educational programs external audiences include discover daily life course designed middle high school students mind applied digital google free online curriculum part larger grow initiative explains built helps people every day potential challenges faces poses building literacy important component accountability helps prepare people participate civic discussion understand explanations lesson unique users date new external training responsible applying principles google cloud designed provide framework organization interested operationalizing responsible practices make research accessible useful launched interactive scientific people play models getting results real time web browser setup required continue support academic research partnerships fellowships increase diversity equity inclusion field computer science highlights year include serving founding partner inaugural african master machine intelligence ammi program many ammi graduates continued studies taken positions including accra research center offer residency program three cohorts residents date launching google phd fellowships students attending latin american universities selected fellows receive funding three years mentorship google researcher support career principles progress computer science research expanding responsible innovation program internal google fellowship program external program equips students knowledge skills need enter field ethics students currently underrepresented backgrounds including students minority serving institutions historically black colleges universities hispanicserving institutions historically women colleges encouraged apply inaugural cohort engaged twenty announcing million commitment expand education access million students across brings total commitment education million since hosting largest cohort google research mentorship program csrmp date students csrmp aims increase diversity phd graduates fields ensure broader community researchers includes experiences perspectives concerns people worldwide since csrmp hosted students across developing business school case study operationalizing principles targeted future technology industry partnership california management review case taught multiple courses ethics university california berkeley haas school business investing launch insait institute computer science artificial intelligence technology new computer science research institute bulgaria backed bulgarian government endowment fund nearly research include machine learning quantum computing information security robotics google investing million next three years provide insait cloud computing resources access tensor processing unit research specialized infrastructure running machine learning models collaborating see families seeing study analyze trends screen speaking time characters based perceived gender skin tone age scripted television last years research led geena davis institute gender partnership google research technology provider signal analysis interpretation university southern california academic advisor together applied new skin tone classifier based mst monk skin tone scale study representation patterns principles progress updatesystem examine representation nielsen top scripted shows season also take holistic approach prepare people future careers industry around world even formally studying never studied computer science programming announced partnership provide nearly girls training concepts coding algorithms new activities google women engineers new activities form part girlguiding national program within skills future theme span four girlguiding sections age groups created completed offline ensure accessible girls june apac japan reskilling consortium collaboration business governments nonprofit sector provides skills training areas artificial intelligence digital marketing also provides service help trainees find work opportunities consortium already offers training programs partners joining ford motor company founding member michigan central michigan central new innovation hub companies government community stakeholders focus future mobility terms economic opportunity transportation solutions detroit beyond specifically offering cloud infrastructure capabilities data analytics tools michigan central used projects research future mobility solutions google research provided technology including new skin tone classifier based mst monk skin tone scale new study examining representation across gender skin tone age scripted last years principles progress policymakers standards organizations recognize carries risks well opening exciting possibilities optimistic potential standards continue move industry forward responsible way remain actively engaged key conversations international forums organisation economic development oecd international standardization organization iso national standards bodies nist example collaboration private public sectors including dialogue iso others nist developing framework help organizations better manage risks associated filed google response nist request initial framework draft expressed support initiative shared recommendations including clarify roles different stakeholders value chain expand distinction fairness unfair bias determine nist framework integrated standards frameworks relationships work help coordinate efforts drive development consensus standards emerging tech systems common benchmarks evaluation continue contribute public consultation emerging legislation like act share resources policy leaders machine learning policy leaders workshop trained stakeholders around world since launch continue partner external organizations including future humanity institute university oxford centre internet society among many engagements principles progress updateconclusion always reflect human values live full potential complex intersection values new technology require multidisciplinary thinking across computational social sciences including foundational research multimodal content understanding responsible lens essential truly collective approach involves many international interdisciplinary contexts committed collaborative approach building helpful everyone year continue build strategy supported economist impact efforts publish whitepapers economic impact governments encourage adoption middle east north latin shared insights papers respective events uae ministry council americas continue engage key policymakers stakeholders regions internally continue engage external advisors research informs research product design example identify potential fairness considerations photos assistant product teams researchers working generative including imagen parti test kitchen participated equitable research roundtable earr program offers opportunity identify potential fairness considerations group experts othering belonging institute berkeley policylink trust west university texas austin emory university school law early product development lifecycle still lot learn continue learning given dynamic evolving nature technology society act innovation rooted coming big ideas also constant iteration including within governance operations processes tools google principles governance strategy constantly iterate improve also reflects company overall responsible innovation strategy principles progress also means reaching users partners across technology industry geographies academic disciplines cultures governments listening analyzing needs time helps design test learn missteps adjust improve listening helps proactively design new solutions new challenges emerge respond feedback inevitable criticisms respect commitment willingness change helps address world pressing problems helps shape world future important ever get right together principles progress updateend notes addition entities mostrarintegra principles progress principles progress principles progress states principles progress earr principles progress page intentionally left blank principles progress update
