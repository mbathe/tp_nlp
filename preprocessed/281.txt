project expl explaining decisions made introduction part basics explaining definitions legal framework benefits risks goes explanation contextual factors principles follow part explaining practice summary tasks undertake task select priority explanations considering domain use case impact individual task collect data manner task build system ensure able extract relevant information range explanation types task translate rationale system results useable easily understandable reasons task prepare implementers deploy system task consider build present explanation part explaining means organisation organisational roles functions explaining policies procedures documentation annexe example building presenting explanation cancer diagnosis annexe algorithmic techniques annexe supplementary models annexe reading annexe assurance october introduction guidance ico alan turing institute aims give organisations practical advice help explain processes services decisions delivered assisted individuals affected glance increasingly organisations using artificial intelligence support make decisions individuals something something thinking guidance guidance consists three parts depending level expertise organisation parts may relevant others part basics explaining aimed dpos compliance teams part one defines key concepts outlines number different types explanations relevant members staff involved development explaining practice aimed technical teams part two helps practicalities explaining decisions providing explanations individuals primarily helpful technical teams organisation however dpo compliance team also find explaining means organisation aimed senior management part three goes various roles policies procedures documentation put place ensure organisation set provide meaningful explanations affected individuals primarily targeted organisation senior management team however dpo compliance team also find october part basics explaining guidance purpose guidance guidance intended help organisations explain decisions made artificial intelligence systems people affected guidance three parts part basics explaining part part explaining practice part explaining means organisation part guidance outlines definitions legal requirements explaining benefits risks explaining explanation types contextual factors principles underpin rest guidance several reasons explain including complying law realising benefits organisation wider society clarifies apply data protection provisions associated explaining decisions well highlighting relevant legal regimes outside ico remit guidance statutory code practice data protection act dpa instead aim provide information help comply range legislation demonstrate best practice use guidance introductory section audiences contains concepts definitions underpin rest guidance data protection officers dpos organisation compliance team primarily find legal framework section useful technical teams senior management may also need awareness legal framework well benefits risks explaining systems individuals affected use also find glance sections guidance summary document pulls fundamental elements guidance one place makes easier find quickly run sme processes personal data using concerns worth remembering get additional support ico sme web hub october status guidance guidance issued response commitment government sector deal statutory code practice dpa intended comprehensive guidance data protection compliance practical guidance sets good practice explaining decisions individuals made using systems processing personal data guidance ico alan turing institute ico responsible overseeing data protection alan turing institute turing national institute data science artificial intelligence october professor dame wendy hall jérôme pesenti published independent review growing industry second report recommendations support uptake ico turing april government published sector deal deal tasked ico turing independent report sector deal part ongoing efforts made national international regulators governments address wider implications transparency fairness decisions impacting individuals organisations wider society framework explaining processes services decisions delivered improve transparency together develop guidance assist explaining october definitions glance artificial intelligence defined many ways however within guidance define umbrella term range technologies solve complex tasks carrying functions previously required human thinking decisions made using either fully automated human loop form impacted supported decision able hold someone accountable detail output decision decision different one made human umbrella term range technologies approaches often attempt mimic human thought solve complex tasks things humans traditionally done thinking reasoning increasingly done help healthcare used spot early signs illness diagnose disease policing used target interventions identify potential offenders marketing used target products services consumers existed time recent advances computing power coupled increasing availability vast swathes data mean designers able build systems capable undertaking complex tasks information processing power dramatically increased become possible expand number calculations models complete effectively map set inputs set outputs means october correlations models identify use produce classifications predictions also become complex less intrinsically understandable human thinking therefore important consider systems create outputs several ways build systems involves creation algorithm uses data model aspect world applies model new data order make predictions historically creation models required incorporating considerable amounts expert input expert systems applied large numbers rules taken domain specialists draw inferences knowledge base though tended become accurate rules added systems expensive scale labour intensive required significant upkeep also often responded poorly complex situations formal rules upon generated inferences flexible enough recently machine learning models emerged dominant technology kinds models may constructed using different learning approaches build past information contained collected data identify patterns hone classificatory predictive performance three main approaches supervised unsupervised reinforcement learning supervised learning models trained dataset contains labelled data learning occurs models numerous examples used train algorithm map input variables often called features onto desired outputs also called target variables labels basis examples model able identify patterns link inputs outputs models able reproduce patterns employing rules honed training transform new inputs received classifications predictions unsupervised learning models trained dataset without explicit instructions labelled data models identify patterns structures measuring densities similarities data points dataset algorithmic models used cluster data grouping similar data together detect anomalies flagging inputs outliers compared rest dataset associate data point attributes typically seen together reinforcement learning models learn basis interactions virtual real environment rather existing data reinforcement learning agents search optimal way complete task taking series steps maximise probability achieving task depending steps take rewarded punished agents encouraged choose steps maximise reward learn past experiences improve multiple iterations trial error may strategies maximise reward overall rather looking next step guidance applicable three methods mainly focuses supervised learning widely used approaches output decision output model varies depending type model used purpose generally three main types october prediction default loan recommendation would like news article classification email spam cases system fully automated deployed output action taken result decision implemented without human involvement oversight model output decision cases outputs used part wider process human considers output model well information available acts makes decision based often referred human loop model output information human consideration decision use term decision broadly incorporating decision based prediction recommendation classification also refer solely automated process one human involved assisted decision different one made human one key differences individual hold accountable decision made decision made directly human clear individual order get explanation made decision system involved responsibility decision less reading information constitutes meaningful human involvement decision process read guidance automated profiling guide gdpr advice topic draft auditing framework october loss accountability decision made help system rather solely human individual would expect explanation human instead expect explanation accountable system october legal framework glance general data protection regulation gdpr data protection act dpa regulate collection use personal data uses personal data falls within scope legislation use personal data train test deploy system administrative law equality act also relevant providing explanations using detail data protection law data protection law actually mention data protection law require explain decisions individuals relevant laws data protection law data protection law made gdpr dpa together regulate collection use personal data information identified identifiable individuals please note january references gdpr read references equivalent articles gdpr involve use personal data falls outside remit data protection law example use weather forecasting astronomy often use create personal data cases vast amounts personal data used train test models deployment personal data collected fed model make decisions individuals decisions individuals even prediction inferences personal data personal data used train model personal data used test model october deployment personal data used created make decisions individuals cases within scope data protection law data protection law actually mention data protection law technology neutral directly reference associated technologies machine learning however gdpr dpa significant focus large scale automated processing personal data several provisions specifically refer use profiling automated decisionmaking means applies use provide prediction recommendation someone right informed articles gdpr give individuals right informed existence solely automated producing legal similarly significant effects meaningful information logic involved significance envisaged consequences individual right access article gdpr gives individuals right access information existence solely automated producing legal similarly significant effects meaningful information logic involved significance envisaged consequences individual recital provides interpretative guidance rights related automated mainly relates article rights also makes clear individuals right obtain explanation solely automated decision made right object article gdpr gives individuals right object processing personal data specifically including profiling certain circumstances absolute right object profiling direct marketing purposes rights related automated including profiling article gdpr gives individuals right subject solely automated decision producing legal similarly significant effects exceptions cases obliges organisations october adopt suitable measures safeguard individuals including right obtain human intervention express view contest decision recital also provides interpretive guidance article data protection impact assessments article gdpr requires organisations carry data protection impact assessments dpias processing personal data particularly using new technologies likely result high risk individuals dpia always required systematic extensive profiling automated evaluation personal data used decisions produce legal similarly significant effects people dpias therefore likely obligation looking use systems process personal data carry prior processing order identify assess levels risk involved dpias living documents review regularly change nature scope context purposes processing ico published additional guidance dpias including list processing operations require dpia list mentions machine learning profiling automated resulting denial service product benefit dpia indicates residual high risks rights freedoms individuals reduced must consult ico prior processing reading data protection law require explain decisions individuals gdpr specific requirements around provision information explanation decision made process without human involvement produces legal similarly significant effects individual something affecting individual legal rights equivalent impact individual circumstances behaviour opportunities decision welfare loan cases gdpr requires proactive giving individuals meaningful information logic involved well significance envisaged articles give individuals least right obtain human intervention part controller express point view contest article anddata protection impact assessments dpias october give individuals right meaningful information logic involved well significance envisaged article including explanation decision reached recital gdpr recitals legally binding clarify meaning intention articles reference explanation automated decision made recital makes clear right implicit articles need able give individual explanation fully automated decision enable rights obtain meaningful information express point view contest decision even decision part solely automated process meaningful human involvement personal data used still subject gdpr principles gdpr principles fairness transparency accountability particular relevance fairness part assessing whether use personal data fair considering affects interests individuals decision made someone without form explanation information decision may limit autonomy scope unlikely fair transparency transparency clear open honest people use personal data addition information requirements automated processing laid articles gdpr recital states provide information necessary ensure fair transparent processing taking account specific circumstances context process personal data unlikely considered transparent open people decision made personal data used train test system providing explanation form help transparent information purpose processing someone data articles gdpr could also include explanation cases accountability accountable must able demonstrate compliance principles set article gdpr including data minimisation accuracy show treated individual fairly transparent manner making decision one way provide explanation decision document provision whichever type decision make involving use personal data data protection law still expects explain individuals affected parts dpa addition separate provisions part dpa solely automated decisions adverse legal effect significantly affect data subject carried law enforcement purposes competent authorities individuals obtain human intervention express point view obtain explanation decision challenge currently instances october automated law enforcement likely rare also separate provisions part dpa solely automated carried intelligence services significantly affect data subject individuals right obtain human intervention cases also general right individuals information controller processing data results produced processing applied cases request knowledge reasoning underlying however rights may limited exemption safeguarding national security part relevant laws gdpr main legislation united kingdom explicitly states requirement provide explanation individual laws may relevant mean good practice explain decisions listed examples equality act equality act applies range organisations including government departments service providers employers education providers transport providers associations membership bodies well providers public functions behaviour prohibited equality act discriminates harasses victimises another person basis protected characteristics age disability gender reassignment marriage civil partnership pregnancy maternity race religion belief sex sexual orientation using system process need ensure able show result discrimination causes decision recipient treated worse someone else one protected characteristics results worse impact someone protected characteristic someone without one reasonable adjustments mean employers providing service duty avoid far possible reasonable means disadvantage disabled person experiences impairments therefore explain decision recipient decision discriminatory october protected characteristics listed explanation must format decision recipient meaningfully engage reading judicial review administrative law anyone apply challenge lawfulness government decisions means individuals able challenge decision made public sector agency private bodies contracted government carry public functions deployed systems support possible judicially review systems public agencies used make decisions individuals basis decision illegal irrational way made improper reading additional legislation explanation may also indicate compliance best practice legislation plan detail laws may specific sector recommend contact regulatory body concerned may apply legislation may apply includes please note list intended exhaustive legislation may apply cases legislation law enforcement directive consumer rights legislation financial services legislation competition law human rights act legislation health social care regulation around advertising marketingequality human rights commission external reasonable adjustments external administrative law machines government external public sector external october legislation school admissions procedures october benefits risks glance explaining decisions benefits organisation help comply law build trust customers improve internal governance society also benefits informed experiencing better outcomes able engage meaningfully process organisation explain decisions could face regulatory action reputational damage disengagement public detail benefits organisation benefits individuals society risks explaining decisions risks explaining decisions benefits organisation legal compliance set legal framework section guidance number laws sectoral crosssector something relevant say topic explicitly require explanations decisions certain circumstances others broader requirements around fair treatment citizens whatever sector business explaining decisions affected help give board better assurance legal compliance mitigating risks associated trust explaining decisions affected individuals makes good business sense help empower better understand process allow challenge seek recourse necessary handing degree control back individuals way may help foster trust use decisions give edge organisations competitors progressive respectful interactions customers internal governance explaining decisions affected individuals requires within organisation understand models choices processes associated decisions make making explainability key requirement also better oversight systems help ensure systems continue meet objectives support refining increase october benefits individuals society informed public organisations incorporate explanations individuals core element systems general public gain increasing awareness decisions made turn may help public meaningful involvement ongoing conversation deployment associated risks benefits could help address concerns support constructive mutually beneficial debate business society better outcomes organisations required identify mitigate discriminatory outcomes may already present human may exacerbated introduced use providing explanations affected individuals help highlight issues may difficult spot explanations therefore support consistency fairness outcomes different groups across society human flourishing giving individuals explanations decisions helps ensure use humancentric interests customers paramount long processes contest decisions continuously improve systems based customer feedback people confidence express point view risks explaining decisions industry engagement activities carried highlighted number elements may limiting effect information provided individuals explaining decisions explanations set guidance largely designed take issues account mitigate associated risks explained distrust could argued providing much information decisions may lead increased distrust due complex sometimes opaque nature process decisions often undeniably complex explanation types explanation extraction methods offered guidance designed help possible simplify transform complexity understandable reasoning cases fairness physical wellbeing central issue focusing relevant explanation types help build trust reassure individuals safety equity model without dive deeply complexity system rationale particularly case safety performance explanation fairness explanation show addressed issues even rationale decision particularly complex difficult convey commercial sensitivities may concerns explanations decisions disclose commercially october material model system works think explanations set normally risk disclosures neither rationale safety performance explanations require provide information reveal source code algorithmic trade secrets however form view based specific situation think necessary limit detail feature weightings importance justify document reasons personal data due way train model input data particular decisions may concerned inappropriate disclosure personal data someone individual decision explanations identify guidance problem however potential risks rationale fairness data explanation types information others similar individual treated detail input data particular decision one person assess risk part data protection impact assessment dpia make justified documented choices level detail safe provide explanations gaming depending make decisions may need protect risk people may game exploit model know much reasons underlying decisions using decisions identify wrongdoing misconduct fraud detection need limit information provide individuals stronger particularly rationale explanation still provide much information reasoning logic however settings relatively risks associated giving people detail reasons decisions fact often help individuals legitimately adjust behaviour choices make order achieve desirable decision outcome parties consider part initial risk impact assessment model may form part dpia start assumption open transparent possible rationale decisions work back limit tell people decide necessary justify document reasons risks explaining decisions regulatory action speak regulators failure meet legal requirements around explaining decisions treating people fairly may lead regulator take regulatory intervention action ico uses education engagement promote compliance organisations regulate rules broken organisations risk formal action including mandatory audits orders october processing personal data fines reputational damage public media interest increasing often spotlight falls organisations get things wrong provide people explanations decisions make risk left behind organisations getting singled unethical uncaring towards customers citizens disengaged public explaining decisions individuals may leave wary distrustful systems work choose risk disengaged public slower embrace even reject october goes explanation glance need consider provide information two subcategories explanation explanations give information governance system across design deployment explanations tell happened case particular decision different ways explaining decisions identified six main types explanation rationale explanation reasons led decision delivered accessible way responsibility explanation involved development management implementation system contact human review decision data explanation data used particular decision fairness explanation steps taken across design implementation system ensure decisions supports generally unbiased fair whether individual treated equitably safety performance explanation steps taken across design implementation system maximise accuracy reliability security robustness decisions behaviours impact explanation steps taken across design implementation system consider monitor impacts use system decisions may individual wider society detail mean explanation explanations rationale explanation responsibility explanation data explanation fairness explanation safety performance explanation impact explanation mean explanation cambridge dictionary defines explanation october general definition remains valid considering explain assisted decisions individuals affected often also data subjects suggests always approach explanations way people want understand details reasons make clear easy may differ research others reveals context key aspect explaining decisions involving several factors decision person application type data setting affect information individual expects finds useful therefore talk explanations guidance refer one approach explaining decisions made help providing single type information affected individuals instead context affects type explanation use make decision clear easy individuals understand remember audience aiming explanation staff whose decisions supported system need relay meaningful information individual affected decisions affected decision particular thought given vulnerable groups children auditors external reviewers charged monitoring overseeing production deployment system group may require different levels detail within explanation receive level knowledge explanation recipient subject explanation affect detail language need use also take account transparency requirements gdpr least cases solely automated decisions includes providing meaningful information logic significance envisaged consequences decision right object right obtain human intervention human loop still comply transparency requirements situations consider information decisions recommendations made system informs human decision result research engagement identified six different types explanation combine explanation various ways depending specific decision details reasons someone gives make something clear easy october clarifying decision may need supply decision recipient information explanation types however consider information required affected individuals well context decision made plan explanation accordingly also keep mind system need appropriately explainable others may involved decision process could include example implementers using system auditors checking explanation types designed help concise clear way explanations explore six explanation types useful make distinction applies explanations primary aim explaining fully automated decisions justifying particular result individual whose interests affected means demonstrating others involved development system acted responsibly choosing processes behind design deployment making reasoning behind outcome decision clear therefore divided type explanation subcategories process outcome explanations systems demonstrating followed good governance processes best practices throughout design use example trying explain fairness safety particular decision one component explanation involve establishing taken adequate measures across system production deployment ensure outcome fair safe explanations systems clarifying results specific decision involve explaining reasoning behind particular outcome plain easily understandable everyday language meaningful human involvement process also make clear affected individual human judgement assisted output reached addition may also need confirm actual outcome decision meets criteria established design process ensure system used fair safe ethical way rationale explanation explanation help people understand decision helps people understand reasons led october outcome accessible way purposes explanation serve challenging decision vital individuals understand reasons underlying outcome automated decision human decision assisted results system decision wanted expected allows assess whether believe reasoning decision flawed wish challenge decision knowing reasoning supports formulate coherent argument think case changing behaviour alternatively individual feels reasoning decision sound use knowledge consider might changing behaviour aspects lifestyle get favourable outcome future individual already satisfied outcome decision rationale explanation may still useful may validate belief case adjust reasons favourable outcome different expected may need show system performed behaved get decision outcome different components system led transform inputs outputs particular way communicate features interactions parameters significant technical components logic underlying result provide supporting evidence decision reached underlying logic conveyed easily understandable reasons decision recipients thought system results apply concrete context life situation affected individual rationale explanations might answer selected algorithmic model set models provide degree interpretability corresponds impact affected individuals supplementary explanation tools using help make complex system explainable good enough provide meaningful accurate information underlying logic information goes rationale explanations types explanation rationale explanations explanations clarify procedures set help provide meaningful explanations underlying logic model october procedures suitable given model particular domain context possible impacts affected decision recipients wider society set system design deployment workflow appropriately interpretable explainable including data collection model selection explanation extraction explanation delivery procedures explanations provide formal logical rationale system system verified formal specifications verify system operate reliably behave accordance intended functionality technical rationale system output model components variables rules transform inputs outputs know role components play producing output understanding roles functions individual components possible identify features parameters significantly influence particular output translation system workings input output variables parameters accessible everyday language clarify plain understandable terms role factors play reasoning problem model trying address solve clarification statistical result applied individual concerned show reasoning behind decision takes account specific circumstances background personal qualities affected individuals gdpr also refers providing meaningful information logic involved automated decisionmaking articles order able derive rationale explanation need know algorithm works see step part guidance detail guidance help see part explaining practice information extracting technical rationale translating understandable reasons responsibility explanation explanation help people understand helps people understand involved development management model contact human review decision purposes explanation serve challenging decision individuals receipt explanations rationale fairness may wish challenge decision based information provided responsibility explanation helps directing individual person team responsible carrying human review decision also makes accountability october informative explanation also serve informative purpose shedding light different parts organisation involved design deployment system may need show accountable stage system design deployment defining outcomes system initial phase design providing explanation affected individual end definitions mechanisms people held accountable well made design implementation processes system traceable auditable information goes responsibility explanations explanations clarify roles functions across organisation involved various stages developing implementing system including human involvement system parts procured include information providers developers involved broadly roles important overall responsibility lies management model ultimately accountable responsible step design system implementation make sure effective accountability throughout explanations responsibility explanation largely governance design implementation systems strict sense entirely even important information procedures able provide cover information request human review decision object use including details contact next steps long take human reviewer take account present decision explanation give individuals way directly contact role team responsible review need identify specific person organisation one person involved implemented decision used statistical results system come determination individual guidance help see part guidance explaining means organisation information identifying roles involved explaining decision see part guidance explaining practice details information need provide explanation data explanation explanation help people understand october data explanations decisions help people understand data sources data used particular decision generally also help individuals understand data used train test model could provide information within fair processing notice required provide articles gdpr purposes explanation serve challenging decision understanding data input system allow individual challenge outcome think flawed input data incorrect irrelevant additional data taken account individual thinks relevant providing reassurance knowing actions took collecting preparing training test data model help reassure individuals made appropriate responsible choices best interests developing understandable fair accurate system may need show data used train test validate model managed utilised collection processing monitoring data used particular decision information goes data explanations explanations include validating data collected sources data methods used collect took part choosing data collected procured involved recording acquisition procured provided data vetted data quality assessed steps taken address quality issues discovered completing removing data validating split determined data labelling augmentation supported interpretability explainability model measures taken ensure data used train test validate system representative relevant accurately measured generalisable ensured potential bias discrimination dataset mitigated explanations clarify input data used specific decision sources data refers system result particular decision recipient cases output data may also require explanation particularly decision october placed category may clear example case anomaly detection financial fraud identification output might distance measure places certain distance away people based transaction history classification may require explanation guidance help see data collection section part explaining practice deriving explanation type part explaining means organisation provide pointers document demonstrate responsible data management practices across design implementation model fairness explanation explanation help people understand fairness explanation helping people understand steps took continue take ensure decisions generally unbiased equitable also gives people understanding whether treated equitably purposes explanation serve trust fairness explanation key increasing individuals confidence system foster trust explaining individual avoid bias discrimination decisions make proving treated differently others like challenging decision also allows individuals challenge decision made using system individual might feel explanation provide actually suggests treated unfairly may need show explanation fairness relate several stages design development deployment systems dataset fairness system trained tested properly representative relevant accurately measured generalisable datasets note dataset fairness component overlap data explanation may include showing made sure data representative possible affected sufficient terms quantity quality represents underlying population phenomenon modelling assessed recorded suitable reliable impartial sources measurement sourced sound collection methods october accurately reflects characteristics individuals populations phenomena trying model relevant calling domain experts help understand assess use appropriate sources types data serve objectives design fairness model architectures include target variables features processes analytical structures correlations interactions inferences unreasonable unjustifiable may include showing done following attempted identify underlying structural biases may play role translating objectives target variables measurable proxies defining problem start project biases could influence system designers expect target variables measure statistically represent mitigated bias data phase taking account sector organisational context operating process automated outsourced show reviewed done maintained oversight also attach information context metadata coming data later access relevant properties undertake bias mitigation mitigated bias feature space determined relevant features selected input variables model choices made grouping separating including excluding features well general judgements comprehensiveness coarseness total set features may consequences protected groups people mitigated bias tuning parameters setting metrics modelling testing evaluation stages trained model development team iterate model peer review help ensure choose adjust dials metrics model line objectives mitigating bias mitigated bias watching hidden proxies discriminatory features trained model may act influences model output designers also look whether significant correlations inferences determined model learning mechanisms justifiable outcome fairness discriminatory inequitable impacts lives people affects may include showing explicit formal definition fairness chosen data scientists apply different formalised fairness criteria choose specific groups selected set receive benefits comparison others set accuracy precision model distributed among subgroups method applied operationalising formalised fairness criteria example reweighting model parameters embedding classification procedure algorithmic results adjust outcome preferences implementation fairness deployed users sufficiently trained implement responsibly without bias may include showing appropriately prepared trained implementers system avoid automation bias outputs systems bias underrelying system outputs lack trust use results active awareness specific context applied understand particular circumstances individual output applied october understand limitations system includes understanding statistical uncertainty associated result well relevant error rates performance metrics information goes fairness explanations explanation providing people appropriately simplified concise information considerations measures testing carry make sure system equitable bias optimally mitigated fairness considerations come play whole lifecycle model inception deployment monitoring review explanations include details chosen measures mitigate risks bias discrimination data collection preparation model design testing stages measures chosen managed informational barriers design limited access data protected sensitive traits concern results initial ongoing fairness testing external validation showing chosen fairness measures deliberately effectively integrated model design could showing different groups people receive similar outcomes protected characteristics played factor results explanations include details formal fairness criteria implemented case particular decision output presentation relevant fairness metrics performance measurements delivery interface model geared audience done easily understandable way explanations others similar individual treated whether received decision outcome individual example could use information generated counterfactual scenarios show whether someone similar characteristics different ethnicity gender would receive decision outcome individual guidance help see part explaining practice information building fairness design deployment model see also part explaining means organisation information document done achieve fairness safety performance explanation explanation help people understand safety performance explanation helps people understand measures put place steps taken continue take maximise accuracy reliability security robustness decisions model helps make also used justify type system chosen use comparisons systems human decision october purposes explanation serve reassurance individuals often want reassured system safe reliable safety performance explanation helps serve purpose demonstrating done test monitor accuracy reliability security robustness model informative individual receiving explanation decision technically knowledgeable proficient explanation allow assess suitability model software types decision made explanation helps transparent people integrity system challenging decision individuals make informed choice whether want contest decision basis may incorrect carried unsafe hazardous unreliable way closely linked challenging decision basis fairness may need show accuracy proportion examples model generates correct output component may also include related performance measures precision sensitivity true positives specificity true negatives individuals may want understand accurate precise sensitive output particular case reliability dependably system intended programmed carry individuals may want know whether happened process producing decision affected security system able protect architecture unauthorised modification damage component parts system remains continuously functional accessible authorised users keeps confidential private information secure even hostile adversarial conditions robustness system functions reliably accurately practice individuals may want know well system works things wrong anticipated tested system immunised adversarial attacks information goes safety performance explanations explanations include accuracy measure maximising precision reduce risk false negatives chose measures went assuring data collection stage ensure training data reflective characteristics people results october kinds external validation undertaken test confirm model ground truth overall accuracy rate system testing stage monitor measuring concept drift time reliability measure went assuring results formal verification system programming specifications encoded requirements mathematically verified security measure went assuring limitation set able access system manage security confidential private information processed model robustness measure chose measures went assuring system understand responds adversarial intervention implementer error skewed automated learner reinforcement learning applications explanations may able guarantee accuracy individual level able provide assurance system operated reliably securely robustly specific decision case accuracy performance metrics however include model delivery interface results testing splits external validation carried may also include relevant information related system confusion matrix table provides range performance metrics roc curve receiver operating characteristics auc area curve include guidance users affected individuals makes meaning measurement methods specifically ones chosen use easily accessible understandable also include clear representation uncertainty results confidence intervals error bars guidance help see part explaining practice information ensuring accuracy reliability security robustness system see also part explaining means organisation information document done achieve objectives impact explanation explanation help people understand october impact explanation helps people understand considered effects decisionsupport system may individual outcome decision means also helping individuals understand broader societal effects use system may may help reassure people use benefit impact explanations therefore often well suited delivery decision made see task explaining practice guidance deliver explanations purposes explanation serve consequences purpose impact explanation primarily give individuals power control involvement decision made understanding possible consequences decision negative neutral positive individual better assess willingness take part process anticipate outcomes decision may affect reassurance knowing took time consider manage potential effects system society help reassure individuals issues safety equity reliability core components model subject also helps individuals informed benefits risks systems therefore confident active debate development use may need show demonstrate thought system potentially affect individuals wider society clearly show affected individuals process gone determine possible impacts information goes impact explanations explanations include showing considerations gave system potential effects undertook considerations measures steps took mitigate possible negative impacts society amplify positive effects information plan monitor impacts system deployed explanations although impact explanation mainly demonstrating put appropriate forethought potential big picture effects also consider help decision recipients understand impact decisions specifically affect instance might explain consequences individual different possible decision outcomes cases changes behaviour would brought different outcome positive impacts use counterfactual assessment would help decision recipients make changes could lead different outcome future allow challenge october guidance help see part explaining practice information considering impact select appropriately explainable model see also part explaining means organisation information document october contextual factors glance five contextual factors effect purpose individual wishes use explanation deliver explanation domain work impact individual data used urgency decision audience presented detail introduction contextual factors domain factor impact factor data factor urgency factor audience factor introduction constructing explanation individual several factors context decision made effect type explanation people find useful purposes wish use primary research carried particularly members public identified five key contextual factors affecting people want explanations decisions contextual factors set along suggestions explanations prioritise delivering explanation consider factors stages process outlined part guidance considering contextual factors keep mind providing explanations decision recipients also educate systems may therefore worth thinking information provide advance processing order help develop knowledge understanding use among general public domain factor factor october domain mean setting sector deploy model help make decisions people affect explanations people want instance people want know decisions made criminal justice domain differ significantly domains healthcare likewise domain sector specific explanation standards affect people expect explanation example person receiving mortgage decision expect learn reasoning behind determination way matches established lending standards practices explanations prioritise considering domain factor perhaps crucial determiner explanations include prioritise communicating affected individuals system operating setting decision recipients obviously want appropriate safety performance explanations however system operating domain bias discrimination concerns prevalent likely want provide fairness explanation domains unlikely people want expect extensive explanations safety performance outputs recommender systems even lower impact domains explain basic rationale responsibility components well relevant explanation types decision system affects people example low impact applications product recommendations personalisation advertising content may give rise sensitivities around targeting particular demographics ignoring others advertising leadership roles targeted men raise obvious issues fairness impact society increasing importance explanations addressing issues impact factor factor impact factor effect decision individual wider society varying levels severity different types impact change explanations people find useful purpose explanation serves decisions relating life death situations often healthcare domain decisions affect someone liberty legal status impact decision less severe still significant denial utility targeting political message impact trivial directed specific ticket counter system sorts queues airport explanations prioritise general decision high impact individual explanations fairness safety performance impact often important individuals want reassured safety decision trust treated fairly understand consequences however rationale responsibility explanations equally important depending contextual factors example features data used model changeable inferences drawn open interpretation october considering impact contextual factor straightforward hard fast rule case case basis consider combination contextual factors also involve inclusive dialogue across fields expertise involved design development deployment system getting together different team members technical policy compliance domain expertise provide informed vision impact factor model data factor factor data contextual factor relates data used train test model well input data point decision type data used model influence individual willingness accept contest decision actions take result factor suggests think nature data model trained uses inputs outputs deployed consider whether data biological physical biomedical data used research diagnostics social data demographic characteristics measurements human behaviour also consider whether individual change outcome decision factors decision ones influenced changes someone behaviour lifestyle likely individuals may want make changes agree outcome example bank loan decision made based customer financial activity customer may want alter spending behaviour change decision future affect type explanation individual wants however data less flexible biophysical data less likely individual disagree output system example healthcare output produced system suggested diagnosis based genetic data patient fixed something patient easily change explanations prioritise often useful prioritise rationale explanation social data biophysical data social data used individuals receiving unfavourable decision understand reasoning learn appropriately adapt behaviour future decisions biophysical data help people understand decision made however biophysical data used medical diagnoses individuals may prefer simply know decision outcome means reassured safety reliability decision cases makes sense prioritise impact safety performance explanations meet needs hand nature data social subjective individuals likely concerns data taken account decision suitability fairness influencing decision circumstances data fairness explanations help address concerns telling people input data measures put place ensure using data make decisions result bias october urgency factor factor urgency factor concerns importance receiving acting upon outcome decision within short timeframe people want know decision change depending little much time reflect urgency factor recommends give thought urgent decision think whether particular course action often necessary kind decisions make quickly need take action explanations prioritise urgency key factor likely individuals want know consequences reassured model helping make decision safe reliable therefore impact safety performance explanations suitable cases explanations help individuals understand decision affects happens next measures testing implemented maximise monitor safety performance model audience factor factor audience contextual factor individuals explaining decision groups people make decisions individuals within groups effect type explanations meaningful useful level expertise decision broad range people subject decisions make general public indicates might also broad range knowledge expertise people make decisions limited smaller subset employees suggesting may informed things making decisions also consider whether decision recipients require reasonable adjustments receive explanation equality act general rule good idea accommodate explanation needs vulnerable individuals ensure decision recipients able clearly understand information giving using plain language visualisation tools possible may often help note well focusing decision recipient also likely put significant forethought provide audiences appropriate information outputs model instance cases models supporting provide implementers models depth level explanation appropriate assist carrying reasoning way aware model limitations likewise instances models results reviewed auditors provide information systems level depth fit purpose relevant october explanations prioritise people making decisions likely domain expertise might consider using rationale explanation confident understand reasoning logic model particular decision familiar topic decisions additionally people subject decisions technical expertise likely interested technical detail underpinning decision safety performance explanation help alternatively think likely people specific expertise knowledge either topic decision technical aspects explanation types responsibility particular aspects safety performance explanation may helpful people reassured safety system know contact ask decision course even little knowledge area rationale explanation still useful explain reasons decision made plain simple terms may also occasions data used inferences drawn model particularly complex see data factor individuals would rather delegate rationale explanation relevant domain expert expert review come informed conclusions validity suitability reasons decision doctor healthcare setting october principles follow glance ensure decisions make using explainable follow four principles transparent accountable consider context operating reflect impact system individuals affected well wider society detail principles important principles transparent accountable consider context reflect impacts principles relate explanation types principles important decisions unique one sector one type organisation increasingly used areas life guidance recognises use matter organisation approach guidance gives broad steer think explaining decisions individuals please note principles relate providing explanations decision individuals complement data protection principles gdpr first two principles transparent accountable share names gdpr principles extension requirements gdpr means required comply obligations gdpr provide guidance enable follow best practice explaining decisions principles principle two key aspects detailing principles mean practice parts guidance support act accordance different aspects principle signposted october principle principle transparent extension transparency aspect principle gdpr lawfulness fairness transparency data protection terms transparency means open honest use personal data transparent decisions builds requirements making use obvious appropriately explaining decisions make individuals meaningful way key aspects transparent raise awareness open candid use decisions use choose proactively make people aware specific decision concerning advance making decision meaningfully explain decisions giving explanation people decisions give truthful meaningful explanation written presented appropriately delivered right time closely linked context principle guidance help transparent help raising awareness use decisions read policies procedures section explaining means organisation proactive engagement section task explaining practice support meaningfully explaining decisions read policies procedures section explaining means organisation building system aid range explanation types task explaining practice selecting priority explanations task explaining practice explanation timing task explaining practice october principle principle accountable derived accountability principle gdpr data protection terms accountability means taking responsibility complying data protection principles able demonstrate compliance also means implementing appropriate technical organisational measures data protection design default accountable explaining decisions concentrates dual requirements processes actions carry designing outsourcing deploying models ensuring appropriate oversight decision systems answerable others organisation external bodies regulators individuals make decisions key aspects accountable assign responsibility identify within organisation manage oversee explainability requirements decision system assign ultimate responsibility ensure designated capable human point contact individuals query contest decision justify evidence actively consider make justified choices design deploy models appropriately explainable individuals take steps prove made considerations present design deployment models show provided explanations individuals guidance help accountable help assigning responsibility explaining decisions read organisational roles policies procedures sections explaining means organisation support justifying choices make approach explaining decisions read tasks explaining practice help evidence read policies procedures documentation sections explaining means organisation consider context principle october approach explaining decisions principle considering context underlines paying attention several different interrelated elements effect explaining decisions managing overall process consideration something think stages process concept deployment presentation explanation decision recipient therefore several types context address guidance outlined detail contextual factors section key aspects considering context choose appropriate models explanation planning using help make decisions people consider setting potential impact decisions make individual know decision choose appropriately explainable model prioritising delivery relevant explanation types tailor governance explanation governance explainability models robust reflective best practice tailored organisation particular circumstances needs decision recipient guidance help consider context support choice appropriate models explanations decisions make read explaining practice contextual factors section document help tailor governance explainability decision systems use read organisational roles policies procedures sections explaining means organisation reflect impacts principle making decisions performing tasks previously required thinking reasoning responsible humans systems increasingly serving trustees human however individuals hold systems directly accountable consequences outcomes october behaviours value reflecting impacts system helps explain individuals affected decisions use harm impair wellbeing means asking answering questions ethical purposes objectives project initial stages revisit reflect impacts identified initial stages project throughout development implementation stages new impacts identified document alongside mitigating factors implement relevant help explain decision recipients impacts identified reduced potentially harmful effects far possible key aspects reflecting impacts individual wellbeing think build implement system way fosters physical emotional mental integrity affected individuals ensures abilities make free informed decisions lives safeguards autonomy power express supports abilities flourish fully develop pursue interests according freely determined life plans preserves ability maintain private life independent transformative effects technology secures capacities make positive independent contributions social groups shared life community generally wellbeing wider society think build implement system way safeguards meaningful human connection social cohesion prioritises diversity participation inclusion encourages voices heard opinions weighed seriously sincerely treats individuals equally protects social equity uses technologies essential support protection fair equal treatment law utilises innovation empower advance interests many individuals possible anticipates wider impacts technologies developing thinking ramifications others around globe biosphere whole future generations guidance help reflect impacts help reflecting impacts october different types explanation explaining practice support justifying choices make approach explaining decisions read different types explanation explaining practice help evidence read policies procedures documentation sections explaining means organisation principles relate explanation types principles important underpin explain decisions individuals set put practice directly applying explanations use principle explanation relevant considerations transparentrationale technical logic reasoning behind model output input features parameters correlations played significant role calculation model result explain technical rationale underlying model output easily understandable reasons may subjected rational evaluation affected individuals representatives apply statistical results specific circumstances individual receiving decision data data use train model data come ensure quality data used accountableresponsibility accountable stage system design deployment initial phase defining outcomes concluding phase providing explanations mechanisms held accountable made design implementation processes traceable auditable across entire project october consider contextsee task explaining practice information context matters choosing explanation type use model see section contextual factors see help choose explanation types prioritise presenting explanation decision recipient reflect impactsfairness system outputs discriminatory effects sufficiently integrated objectives preventing discrimination mitigating bias design implementation system incorporated formal criteria fairness determine distribution outcomes system made explicit customers advance model prevented discriminatory harm safety performance system safe technically sustainable operating practice system operational integrity worthy public trust designed verified validated model way sufficiently ensures secure accurate reliable robust taken sufficient measures ensure system dependably operates accordance designers expectations confronted unexpected changes anomalies perturbations impact sufficiently considered impacts wellbeing affected individuals communities start finish model design deployment october part explaining practice guidance purpose guidance guidance helps practicalities explaining decisions providing explanations individuals shows select appropriate explanation sector use case choose appropriately explainable model use certain tools extract explanations less interpretable models use guidance guidance primarily technical teams however dpos compliance teams also find useful covers steps take explain decisions individuals starts choose explanation type relevant use case information put together explanation type explanation types derive information organisational governance decisions documentation however given central importance understanding underlying logic system explanations provide technical teams comprehensive guide choosing appropriately interpretable models depends use case also indicate use supplementary tools extract elements model workings black box systems finally show deliver explanation containing relevant explanation types chosen useful way decision recipient status guidance guidance issued response commitment government sector deal statutory code practice data protection act dpa intended comprehensive guidance data protection compliance practical guidance sets good practice explaining decisions individuals made using systems processing personal data guidance ico alan turing institute ico responsible overseeing data protection alan turing institute turing national institute data science artificial intelligence october professor dame wendy hall jérôme pesenti published independent review growing industry second report recommendations support uptake ico turing october april government published sector deal deal tasked ico turing independent report sector deal part ongoing efforts made national international regulators governments address wider implications transparency fairness decisions impacting individuals organisations wider society framework explaining processes services decisions delivered improve transparency together develop guidance assist explaining october summary tasks undertake set number tasks help design deploy appropriately explainable systems assist providing clarification results systems produce range affected individuals operators implementers auditors decision recipients tasks offer systematic approach developing models fashion selecting extracting delivering explanations differentiated according needs skills different audiences directed help navigate detailed technical recommendations part however recognise practice tasks may concurrent cyclical iterative rather consecutive linear may wish develop plan annexe give example tasks may carried particular case health sector select priority explanations considering domain use case impact individual start getting know different types explanation part guidance help separate different aspects decision people may want explain identified think key types explanation people need may additional relevant explanations context organisation way use plan use make decisions people perhaps explanations identify particularly relevant organisation people make decisions absolutely fine explanation types identify intended underline fact many different aspects explanations get thinking aspects whether relevant customers may think list created works organisation might want create either way recommend approach explaining decisions informed importance putting principles transparency accountability practice paying close attention context impact next think specifics context deploying system considering domain work particular use case possible impacts system individuals wider society help choose relevant explanations cases useful include rationale responsibility priority explanations likely identify multiple explanations prioritise decisions make make list document justification choices identified explanations important context decisionsupport system mean discard remaining october choosing prioritise exact science choices may reflect majority people make decisions want know likely individuals still want benefit explanations prioritised probably also useful accountability auditing purposes therefore makes sense make explanations identified relevant available people subject decisions consider prioritise remaining explanations based contextual factors identified useful might people speak colleagues involved procurement testing deployment get views possible speak customers collect data manner collect data use chosen model bearing quality explanation offer decision recipients task therefore emphasises things think stages design process contribute information provide individuals explanation type build system ensure able extract relevant information range explanation types useful understand inner workings system particularly able comply certain parts gdpr model choose right level interpretability use case impact decision recipient use black box model make sure supplementary explanation techniques use provide reliable accurate representation system behaviour translate rationale system results useable easily understandable reasons determine going convey model statistical results users decision recipients understandable reasons central part delivering explanation communicating statistical inferences basis model output played part thinking involves translating mathematical rationale explanation extraction tools easily understandable language justify outcome example extracted rationale explanation provides information relative importance features influence model results global understanding specific decision fits model linear monotonic constraints translate factors simple everyday language understood stakeholders transforming model logic quantitative rationale intuitive reasons lead present information clearly meaningfully possible could textual clarification visualisation media graphical representations summary tables combination october main thing make sure simple way describe explain result individual decision fully automated may use software otherwise person responsible translating result implementer see prepare implementers deploy system human meaningfully involved outcome must appropriately trained prepared use model results responsibly fairly training include conveying basic knowledge nature machine learning limitations automated technologies also encourage users implementers view benefits risks deploying systems terms role helping humans come judgements rather replacing judgement system wholly automated provides result directly decision recipient set provide understandable explanations consider build present explanation finally think build present explanation individual whether website app writing person considerations context cornerstone building presenting explanation consider contextual factors domain impact data urgency audience help decide deliver appropriate information individual considering context also help customise sort much information provide decision recipients way explain results model decision subjects may quite different provide information relevant audiences like auditors may also need explanations though different degrees depth technical detail differentiating way providing information manner help avoid creating explanation fatigue customers saying much time allow protect intellectual property safeguard system gamed delivering explanation decision recipients layered approach helpful presents people relevant information decision making explanations easily accessible required explanations identified priorities first layer others second layer also think information provide advance decision information provide individuals decision particular october task select priority explanations considering domain use case impact individual glance getting know different types explanation help identify dimensions explanation decision recipients find useful cases explaining decisions involves identifying happening system responsible means prioritise rationale responsibility explanation types setting sector working important working kinds explanation able provide therefore consider domain context use case addition consider potential impacts use decide types explanation provide also help think much information required comprehensive choosing prioritise exact science choices may reflect majority people make decisions want know likely individuals still benefit explanations prioritised probably also useful accountability auditing purposes checklist detail introduction selecting priority explanations familiarise different types explanation prioritise rationale responsibility explanation consider domain sector context use case consider potential prioritised rationale responsibility explanations therefore put place documented processes optimise transparency accountability model considered setting sector model used affects types explanation provide considered potential impacts system affect scope depth explanation october examples choosing suitable explanation types introduction consider types explanation need start design process system procurement system outsourcing think involves operationalising principles set basics explaining following considerations help decide explanation types choose familiarise different types explanation introduced different types explanation part guidance basics explaining making sure aware range explanations provide foundations considering different dimensions explanation decision recipients find useful prioritise rationale responsibility explanation likely explanations decisions involve knowing system responsible words likely involve rationale responsibility explanations set use case cover explanations important consider going put place document processes optimise transparency accountability model means making sure organisation policies protocols procedures lined ensure provide clear accessible explanations design deploy system ensure intelligibility interpretability model prioritised outset also means explanation offer affected individuals appropriately covers types explanation given use case possible impacts system considering address explanation types beginning process provide reasonable understanding system works responsible stage process also mean information available decision recipients explanation provided please note although recommend prioritise documenting information rationale responsibility explanations start process may wish provide first layer explanation decision subject task however recommend information provided part explanation practical consider domain sector context use case trying work kinds explanation provide good starting point consider setting sector used certain highly regulated domains standards explanations may largely dictate sort information need provide affected october instance applications employed domains like medicine set provide safety performance explanation line established standards expectations sector likewise setting like criminal justice biased decisionmaking significant concern fairness explanation play important necessary role understanding application domain context setting may also gain insight people expectations content scope similar explanations previously offered due diligence researching sorts expectations help draw background knowledge decide types explanation include part model design implementation processes consider potential impacts paying attention setting model deployed also put good position consider potential impacts especially useful selecting explanations key relevance explanations include part general explanation system assessing potential impact model basis use case help determine extent need include fairness safety performance general impact explanations together scope depth types explanation assessing model potential impact also help understand comprehensive explanation needs includes risks deploying system risks person receiving decision allow make sure scope depth explanations going able offer line impacts specific case example system triages customer service complainants luxury goods retailer different much lower explanatory burden one triages patients hospital critical care unit worked considerations choose appropriate explanations use case addition rationale responsibility explanations already prioritised document choices made prioritise remaining explanations identified explanations relevant use case make available people subject decisions also document made choices examples choosing suitable explanation typesfurther reading see types explanation link basics explaining october recruitment system deployed job application filtering tool company looking hire someone vacancy system classifies decision recipients receive either rejection invitation interview processing social demographic data related individual human attributes social patterns implied cvs submitted resulting concern might bias baked dataset discriminatory features proxies might used model training processing example strong correlation dataset secondary schools attended successful executive placement higher paying positions might lead model trained data discriminate applicants renders recommendations granting job interviews positions certain higher paying profile explanation types choose case prioritise rationale responsibility explanations highly likely need include responsibility rationale explanations tell individual affected hiring decision responsible decision decision reached consider domain sector context use case recruitment human resources domain context suggests bias primary concern case consider potential impacts considering impact system applicant relates whether think decision justified whether treated fairly explanation comprehensive enough applicant understand risks involved use system mitigated risks prioritise explanation types example demonstrates understanding specific area use domain particular nature data important knowing type explanation required decision recipient case fairness explanation required decision recipient wants know discriminated discrimination could due legacies discrimination historical patterns inequity may influenced system trained biased social demographic data addition individual may want impact explanation understand recruiter thought tool impact individual whose data processing data explanation might also helpful understand data used determine whether candidate would invited interview medical diagnosis system utilises image recognition algorithms support radiologist identify cancer october trained dataset containing millions images patient mri scans learns processing billions corresponding pixels possible system may fail unexpectedly confronted unfamiliar data patterns unforeseen environmental anomalies objects recognise system failure might lead catastrophic physical harm done affected patient explanation types choose case prioritise rationale responsibility explanations highly likely need include responsibility rationale explanations tell individual affected diagnostic decision responsible decision decision reached accurate reliable rationale explanation also better support judgement medical professionals involved consider domain sector context use case medical domain context suggests demonstrating safety optimum performance system primary concern case developers consult requirements standards determine scope depth types explanation reasonable expected consider potential impacts impact system patient high system makes incorrect diagnosis explanation comprehensive enough patient understand risks involved use system mitigated risks prioritise explanation types safety performance explanation provides justification possible system sufficiently robust accurate secure reliable codified procedures testing validation able certify attributes depending specific use case fairness explanation might also important prioritise instance demonstrate data collected sufficient quality quantity representativeness system perform accurately different demographic october task collect data manner glance data collect inputting system important role play ability derive explanation type careful labelling selection input data help provide information rationale explanation transparent may wish provide details responsible stage data collection could provide part responsibility explanation aid data explanation could include details source training data collected assessments quality steps taken address quality issues completing augmenting removing data check data used within model ensure sufficiently representative making decisions also consider whether techniques required help fairness explanation ensure modelling testing monitoring stages system development lead accurate results aid safety performance explanation documenting impact risk assessment steps taken throughout model development implement assessments help impact explanation checklist data representative make decisions reliable relevant checked domain expert ensure data using appropriate adequate know data come purpose originally collected collected using synthetic data know created properties know risks using data chosen well risks data subjects data included labelled data using system information including reasons included using unstructured data clear october detail introduction collection data rationale explanation responsibility explanation data explanation fairness explanation safety performance explanation impact explanation introduction collect data use chosen model bearing quality explanation offer decision recipients task therefore emphasises things think stages design process contribute information provide individuals explanation type rationale explanation understanding logic model specific decision much simpler features input variables model draws inferences influence decision already interpretable humans example someone age location limit data transformed extensive feature engineering abstract features difficult humans understand careful transparent data labelling practices set model interpretable possible using data already naturally labelled stage humans labelling data relevant information stage ensure information recorded rich meaningful possible ask charged labelling data tag annotate piece data also reasons tag example rather contains tumour say contains tumour system classifies new images tumours able look back labelling similar examples training data contribute towards explanation decision impact explainability ensured far possible data reflect past discrimination whether based explicitly protected characteristics possible proxies mitigated possible bias techniques masking excluding features proxies clear within organisation responsible data collection october course always possible domain wish use systems may require collection use unstructured data countless different input variables interacting complex ways cases justify document need use data also use guidance next task assess best obtain explanation rationale appropriate model selection approaches explanation extraction responsibility explanation responsibility explanations telling people part organisation responsible overall management model primarily make organisation accountable individuals makes decisions may also want use opportunity transparent people parts organisation responsible stage development deployment process including data collection preparation course may feasible customers direct contact parts organisation depending organisation size interact customers informing people different business functions involved make informed process may increase trust confidence use decisions open informative whole process adopting layered approach delivery explanations likely information sit comfortably second third layer interested individuals access without overloading others much information see task layering explanations data explanation data explanation part giving people information data used train model lot overlap therefore information may already included data collection preparation rationale fairness safety performance explanations however aspects data collection preparation stage could also include example source training data collected assessments quality steps taken address quality issues completing removing data may procedural less directly linked key areas interest fairness accuracy still value providing information responsibility explanation insight individuals model makes decisions confident likely interacting systems trusting use october fairness explanation fairness explanations giving people information steps taken mitigate risks discrimination production implementation system results generates shed light individuals treated comparison others important steps mitigate discrimination bias arise data collection stage example collect data domain expert assess whether sufficiently representative people make decisions also consider data came assess extent reflects past discrimination whether based explicitly protected characteristics race possible proxies post code may need modify data avoid model learning entrenching bias decisions may use techniques masking even excluding features mitigate implicit discrimination dataset prevent bias entering training process exclude features also ensure exclude proxies related features considerations actions take data collection preparation stages feed directly fairness explanations ensure appropriately document early stages reflect explanation safety performance explanation safety performance explanation concerned actions measures take ensure system accurate secure reliable robust accuracy component explanation mainly actions measures take modelling testing monitoring stages developing model involves providing people information performance metrics chosen model various performance related measures used ensure optimal results impact explanation impact explanation involves telling people model decisions makes may impact individuals communities members wider society involves making decision recipients aware possible positive negative effects model outcomes people taken individually whole also involves demonstrating put appropriate forethought mitigating potential harm pursuing potential societal benefits information come considerations made part impact risk assessment data protection impact assessment also practical measures took throughout development deployment model act outcome impact assessment includes data collection preparation stage mitigate risks negative impact amplify possibility positive impact society may covered steps fairness safety performance explanations ensuring collection representative datasets however impact explanation type october opportunity clarify simple terms affects impact society reducing likelihood systematic disadvantaging minority groups improving consistency groups example method october approach data one approach data purposes explanation based provenance information data dependencies processes underpinning decision collectively known provenance decision prov data model vocabulary provenance standardised world wide web consortium organisations use prov uniformly represent link relevant information processes running around model seamlessly query order construct relevant explanations addition organisations depend external data decisions prov allows provenance data linked across organisation boundaries prov standard vocabulary encode provenance form knowledge graph providing account system performed including references people data sets organisations involved decisions attribution data data derivations provenance decision enables trace back decision input data identify responsibility activities found along way allows explicit record data comes organisation associated data collection processing data used train system provenance information provides foundations generate explanations decision well making processes surround decision model transparent accountable prov adopted way uniformly encoding provenance decision within across organisations becomes possible perform range tasks includes able computationally query knowledge graph capturing information data dependencies processes underpinning decision extract relevant information construct desired explanation therefore approach help automate process extracting explanations pipeline around model include explanations processes led decision made responsible step processes whether model solely responsible decision data source influenced decision etc however currently work yet addressed ability build explanations model provenance need couple another approach ones presented task technique used help provide information data explanation also provide details responsibility safety performance explanations online demonstrator illustrating approach described using loan decision scenario reading introduction explanation types see basics explaining october details take measures ensure kinds fairness practice across system design deployment see fairness section understanding artificial intelligence ethics safety guidance produced office government digital service alan turing institute read approach data october task build system ensure able extract relevant information range explanation types glance deriving rationale explanation key understanding system helps comply parts gdpr requires looking hood helps gather information need explanations safety performance fairness however complex task requires know use less interpretable models understand outputs choose right model explanation needs think domain working potential impact deployment system individuals society following consider whether costs benefits replacing current system newer potentially less explainable model data use requires less explainable system use case domain context encourage choosing inherently interpretable system processing needs lead select black box model supplementary interpretability tools help explain black box model chosen appropriate context extract explanations inherently interpretable models look logic model mapping function exploring results directly extract explanations black box systems many techniques use make sure provide reliable accurate representation system behaviour checklist selecting appropriately explainable model know expectations requirements sector domain choosing model taken account specific type application impact model decision recipients considered costs benefits replacing existing technology use system using social demographic data considered need choose interpretable october tools extracting explanation using biophysical data example healthcare setting weighed benefits risks using opaque less interpretable models using black box system considered risks potential impacts using using black box system also determined case use organisational capacity support responsible design implementation systems using black box system considered supplementary interpretability tools appropriate use case using challenger models alongside interpretable models established using lawfully responsibly justified using considered measure performance model best communicate measures implementers decision recipients mitigated bias found model documented mitigation processes made clear model tested including parts data used train model used test formed holdout data record time model updated version changed affects model outputs clear within organisation responsible validating explainability system explanation extraction tools use convey model results reliably clearly help implementers decisions exercise judgements offer affected individuals plausible accurate easily understandable accounts logic behind model output interpretable models confident ability extract easily understandable explanations models systems naïve bayes nearest october detail introduction building system select appropriately explainable model tools extracting rationale explanation introduction rationale explanation key understanding system helps comply parts gdpr requires detailed consideration system works help obtain explanation underlying logic model decide use selection appropriate model also help provide information safety performance fairness explanations therefore important carefully consider select model would also recommend document decision making process evidence considered impact model selection decision recipient select appropriately explainable model selecting appropriate model important whether procuring model external vendor looking build bespoke system cases need consider following factors ensure select appropriate model needs procuring system may wish ask vendor elements need understand system order provide appropriate supplementary explanation tools interpret black box models confident suitable application recognise give full picture opaque model made sure clearly convey limitation implementers decision recipients selecting supplementary tool prioritised need provide reliable accurate close approximation logic behind system behaviour local global explanations combining supplementary explanation tools produce meaningful information system results included visualisation model works included explanation variable importance interaction effects global local included counterfactual tools explore alternative possibilities actionable recourse individual october start consider technical factors consider domain consider specific standards conventions requirements domain system applied example financial services sector rigorous justification standards credit loan decisions largely dictate need use fully transparent easily understandable systems likewise medical sector rigorous safety standards largely dictate extensive levels performance testing validation assurance demanded treatments tools domain specific factors actively inform choices make model complexity interpretability impact think type application building potential impacts affected individuals example big difference computer vision system sorts handwritten employee feedback forms one sorts safety risks security checkpoint likewise also difference complex random forest model triages applicants licensing agency one triages sick patients accident emergency department applications require thorough consider whether prospective models appropriately ensure outcomes safe supportive individual societal wellbeing models directly impact lives people process potentially sensitive social demographic data likely mean less need dedicate extensive resources developing optimally performing highly interpretable system draw appropriate domain knowledge policy expertise managerial vision organisation need consider team looking model technical factors consider selecting model also discuss set technical considerations team vendor select model existing technologies consider costs benefits replacing current data analysis systems newer systems possibly less explainable one purposes using system might replace existing algorithmic technology may offer performance level advanced machine learning techniques planning deploy case may want carry assessment performance interpretability levels existing technology provide baseline compare using advanced system could also help weigh costs benefits building using complex system requires support interpretable comparison using simpler october might also helpful look systems used application area domain help understand resource demands building complex appropriately interpretable system place organisation data integrate comprehensive understanding kinds data processing considerations viability algorithmic techniques select appropriately explainable model need consider kind data processing processing may helpful group kinds data may use system two categories data refers demographic characteristics measurements human behaviour social cultural characteristics people biological physical data biomedical data used research diagnostics data refer demographic characteristics measurements human behaviour mind certain things consider cases processing social demographic data group may come across issues bias discrimination prioritise selecting optimally interpretable model avoid black box systems complex systems may appropriate cases processing biological physical data group purposes gaining scientific insight predicting protein structures genomics research operational functionality computer vision vehicle navigation however application high impact weigh safety performance accuracy security reliability robustness system heavily selecting model note though bias discrimination issues may arise processing biological physical data example representativeness datasets models trained tested cases processing groups data processing directly affects individuals consider concerns bias safety performance selecting model another distinction consider conventional data person payment history length employment given job unconventional data sensor data whether raw interlinked data generate inferences collected mobile phone gyroscope accelerometer battery monitor geolocation device text data collected social media activity cases using unconventional data support decisions affect individuals bear following mind reading information involved using systems see ico auditability framework blogpost october consider data type group data treat way gives rise issues select transparent explainable systems yield interpretable results rather black box models justify use indicating attribute unconventional data represents metadata attribute might factor reasoning generate inferences meet reasonable expectations example gps location data included system analyses credit risk metadata must indicate interpretively significant feature data supposed indicate individual whose data processed interpretable algorithms possible draw standard algorithmic techniques interpretable possible high impact potentially sensitive environments likely need system maximises accountability transparency cases mean prioritise choosing standard sophisticated techniques techniques outlined table annexe may include decision lists linear regression extensions like generalised additive models reasoning logistic regression many cases reaching black box model first may appropriate may even lead inefficiencies project development interpretable models also available perform well require supplemental tools techniques facilitating interpretable outcomes careful data iterative model development hone accuracy interpretable systems result advantages gained combination improved performance transparency may outweigh less transparent approaches black box systems consider using opaque algorithmic techniques make sure supplementary interpretability tools use explain model appropriate meet risks explanatory needs may arise deploying certain data processing activities may feasible use straightforwardly interpretable systems example effective machine learning approaches likely opaque using applications classify images recognise speech detect anomalies video footage feature spaces kinds systems grow exponentially hundreds thousands even millions dimensions scale complexity conventional methods interpretation longer apply clarity define black box model system whose inner workings rationale opaque inaccessible human understanding systems may include neural networks including recurrent convolutional neural nets ensemble methods algorithmic technique random forest method strengthens overall prediction combining aggregating results several many different base models support vector machines classifier uses special type mapping function build divider two sets features high dimensional space october main kinds opaque models described detail annexe use black box models thoroughly considered potential impacts risks advance members team also determined use case organisational resources support responsible design implementation systems likewise use supplemental interpretability tools provide system level explainability needs reasonably sufficient mitigate potential risks system provide decision recipients meaningful information rationale given outcome range supplementary techniques tools assist providing access underlying logic black box models explored annexe part aspect rationale explanation document keep record deliberations cover selected black box model hybrid methods use challenger models select interpretable model ensure explainable data processing carry parallel use opaque challenger models purposes feature insight comparison transparent responsible lawful manner research shown organisations highly regulated areas like banking insurance increasingly using opaque challenger models purposes feature selection comparison insight however continuing select interpretable models customerfacing applications black box challenger models trained data trains transparent production models used benchmark latter feature engineering selection challenger models employed craft feature space reduce number variables feature selection bucket variables feature engineering potentially reduce dimensionality show additional relationships features therefore increase interpretability production model use challenger models purpose make process explicit document moreover highly engineered features drawn challenger models used production models must properly justified annotated metadata indicate attribute combined feature represents attribute might factor reasoning use challenger models process data affected decision recipients even benchmarking purposes properly record document treat core production models document hold explainability standards incorporate insights challenger model processing dimension actual example comparative benchmarking results shared users making decisions types models choosing help get better picture spectrum algorithmic techniques annexe lays basic properties potential uses interpretability characteristics widely used algorithms present techniques also listed table october techniques listed left column considered largely interpretable although like algorithms depends number input features processed four techniques right column less considered black box algorithms broadly interpretable systems broadly black box systems linear regression ensemble methods logistic regression random forest generalised linear model glm support vector machines svm generalised additive model gam artificial neural net ann regularised regression lasso ridge lists sets decision tree supersparse linear integer model slim neighbour knn naïve bayes reasoning cbr prototype criticism reading tools extracting explanations extracting delivering meaningful explanations underlying logic model results involves technical components technical level able offer explanation model reached results need become familiar explanations extracted intrinsically interpretable models get know supplementary explanation tools may used shed light logic behind results behaviours black box systems learn integrate different supplementary techniques way enable provide meaningful information system users decision recipients level extracting delivering meaningful explanations involves establishing tofurther reading algorithm types october convey model results reliably clearly way enables users implementers exercise judgements offer plausible easily understandable accounts logic behind output affected individuals concerned parties technical dimensions interpretability going detail set strategy explaining model need aware couple commonly used distinctions help team think possible desirable explanation local global explanation distinction explanation single instances model results explanation works across outputs often characterised difference local explanation global explanation types explanation offer potentially helpful support providing significant information rationale behind system output local explanation aims interpret individual predictions classifications may involve identifying specific input variables regions input space influence generating particular prediction classification providing global explanation entails offering view captures logic model behaviour whole across predictions classifications kind explanation capture overall significance features variable interactions model outputs significant changes relationship predictor response variables across instances also provide insights patterns crucial big picture model intrinsic explanation providing internal model intrinsic explanation model involves making intelligible way components relationships function therefore closely related overlaps degree global explanation internal explanation makes insights available parts operations system inside insights help team understand trained model improve similarly type internal explanation applied black box model shed light opaque model operation breaking understandable analysable digestible parts example case artificial neural network ann break interpretable characteristics vectors features interactions layers parameters etc often referred peeking black box whereas draw internal explanations interpretable opaque systems external explanations applicable black box systems possible fully access internal underlying rationale due model complexity high dimensionality explanations attempt capture essential attributes observable behaviour black box system subjecting number different techniques explanatory october approaches number different things test sensitivity outputs opaque model perturbations inputs allow interactive probing behavioural characteristics build models utilise simplified interpretable techniques gain better understanding particular instances predictions classifications system behaviour whole getting familiar explanations interpretable models models basically interpretable systems naïve bayes nearest neighbour technical aspect extracting meaningful explanation relatively straightforward draws intrinsic logic model mapping function looking directly results instance decision trees rule lists logic behind output depend interpretable relationships weighted conditional statements words node component kinds models fact operating reason extracting meaningful explanation therefore factors following path connections reasons note though decision tree excessively deep given decision list overly long challenging interpret logic behind outputs reasoning generally speaking operates basis making connections variables time tree list thousands features relationships significantly harder follow thus less interpretable complex cases interpretable model may lose much global well local explainability similar advantages disadvantages long recognised explainability models interpretability made class algorithmic techniques favoured choice highly regulated domains many possess linearity monotonicity characteristics models allow optimal explainability transparency linearity change value predictor variable directly reflected change value response variable constant rate interpretable prediction yielded model therefore directly inferred relative significance weights predictor variable high inferential clarity strength monotonicity value predictor changes given direction value response variable changes consistently either opposite direction interpretable prediction yielded model therefore directly inferred monotonicity dimension highly desirable interpretability condition predictive models many heavily regulated sectors incorporates reasonable expectations consistent application sector specific selection constraints automated systems number features dimensionality feature interactions low enough model underlying distribution simple enough enable clear understanding function part model relation outcome general helpful get know range techniques available building october models listed techniques make rationale behind models readily understandable also form basis many supplementary explanation tools widely used make black box models interpretable technical strategies explaining black box models supplementary explanation tools considering domain impact technical factors chosen use black box system next step incorporate appropriate supplementary explanation tools building model comprehensive technical solution making opaque algorithms interpretable supplementary explanation strategies available support interpretability may shed light significant aspects model global processes components local results however often strategies operate imperfect approximations simpler surrogate models fully capture complexities original opaque system means may misleading overly rely supplementary tools mind fidelity may suitable primary goal technical black box explanation strategy order supplementary tool achieve high level fidelity provide reliable accurate approximation system behaviour practical purposes think locally globally choosing supplementary explanation tools achieve fidelity thinking locally priority primary concern explainability make results specific data processing activity clear understandable affected individuals even important provide supplementary global explanations system understanding relationship system component parts features parameters interactions behaviour whole often critical setting accurate local explanation also essential securing system fairness safety optimal performance help provide decision recipients fairness explanation safety performance explanation sort global understanding may also provide crucial insights model general potential impacts individuals wider society well allow team improve model properly address concerns raised global insights annexe provide table containing details widely used supplementary explanation strategies tools highlight strengths weaknesses keep mind though rapidly developing field remaining date latest tools mean technical members team need move beyond basic information offering annexe cover following supplementary explanation strategies local supplementary explanation strategies global supplementary explanation strategies individual conditional expectations plot ice partial dependence plot pdp october sensitivity analysis relevance propagation lrp accumulated local effects plot ale local interpretable explanation lime anchorsglobal variable importance shapley additive explanations shap global variable interaction counterfactual explanation surrogate models could also used global explanation systems could also used global explanation reading combining integrating supplementary explanation strategies main purpose using supplementary explanation tools make underlying rationale results optimally interpretable easily intelligible use system decision recipients reason good idea think using different explanation strategies together combine explanation tools enable affected individuals make sense reasoning behind decision much clarity precision possible mind might helpful think could combine different strategies portfolio tools explanation extraction keeping mind various strategies introduced table annexe three significant layers technical rationale include portfolio visualise model works understand role variables variable interactions understand behaviours circumstances influence decision would need changed change decision questions may assist thinking integrate layers explanation extraction visualise model works might graphical tools like ale plots combination pdp ice plots make logic behind global local behaviour model clearer users implementers auditors decision recipients might tools used improve model ensure operates accordance reasonable expectations reading supplementary techniques october domain knowledge understanding use case inform insights derived visualisation techniques might knowledge inform integration visualisation techniques explanation tools effective ways visualisations presented explained users decision recipients help build mental model system works whole specific instances used enhance reasoning visualisation techniques available like heat maps interactive querying tools ann traditional tools like principle components analysis would also helpful enhance interpretability system understand role variables variable interactions global measures feature importance feature interactions utilised help users decision recipients better understand underlying logic model whole might provide reassurance model yielding results line reasonable expectations might support enhance information provided visualisation tools might measures variable importance interaction effects used confirm system operating fairly harming discriminating affected stakeholders local explanation tools like lime shap loco reliable enough context particular system useful part portfolio explanation extraction tools established model exploration testing using local explanation tools help provide meaningful information informative rather misleading inaccurate understand behaviours circumstances influence decision would need changed change decision counterfactual explanations appropriate use case application alterable features included input space provide decision recipients reasonable options change behaviour order obtain different results used solid understanding global feature importance correlations interaction effects set reasonable relevant options possible alternative outcomes explored counterfactual explanation tool october task translate rationale system results useable easily understandable reasons glance extracted rationale underlying logic model need take statistical output incorporate wider process implementers outputs system need recognise factors see legitimate determinants outcome considering part systems consider guidance produce statistical outputs based correlation rather causation therefore need check whether correlations model produces make sense case considering decision recipients able easily understand statistical result applied particular case checklist detail introduction translating rationale system results understand statistical rationale correlations identify legitimate determining factors manner integrate chosen correlations outcome determinants reasoning introduction dimension rationale explanation involves working going convey model results way clear understandable users implementers decision taken technical explanation delivered system translated reasons easily understood decision recipient used tools textual clarification visualisation media graphical representations summary tables combination present information logic system output justified incorporated statistical inferences system final decision rationale october involves presenting information logic output clearly meaningfully possible could textual clarification visualisation media graphical representations summary tables combination main thing make sure simple way implementer describe result affected individual however important remember technical rationale behind model output one component explanation process reveals statistical inferences correlations implementers must incorporate wider deliberation reach ultimate conclusions explanations integrating statistical associations wider deliberations means implementers able recognise factors see legitimate determinants outcome considering must able pick amongst model correlations associations think reasonably explain outcome given specifics case need able incorporate legitimate determining factors thinking decision explain likely need training order outlined detail task understand statistical rationale extracted explanation either inherently interpretable model supplementary tools good idea relative feature important significant feature interactions local explanation combine global picture behaviour model across cases help clarify meaningful relationship predictor response variables understanding relevant associations input variables model result statistical rationale first step moving model mathematical inferences meaningful explanation however statistical inferences direct indicators determined outcome significant insights real world general rule kinds machine learning models exploring guidance generate statistical outputs based correlational rather causal inference models set relevant input features linked target response variable established association correlation justified say components correlated unspecified way justified basis statistical inference alone say components cause direct determinant version phrase correlation imply causation need take steps assess role statistical associations play reasonable explanation given particulars case considering correlations identify legitimate determining factors manner next need determine statistical associations model results identified important legitimate reasonably explanatory case challenge simple technical tool use model prediction classification results observational rather experimental october designed minimise error rather informative causal structures means difficult draw explanation therefore need interpret analyse correlations associations consequential providing meaningful explanation drawing knowledge domain working decision recipient specific circumstances taking context sensitive approach help two things correlations relevant explanation involves ensuring correlations spurious caused hidden variables also determining applicable statistical generalisations affected individual specific circumstances example job candidate spent several years family care role eliminated model identifies strong statistical correlation long periods unemployment poor work performance suggests correlation identified may reasonably apply case recommendation weighed part process automated outcome based result challenged model implementer reviewer would whether correlation play significant role given decision recipient particular circumstances would also consider factors weighed justifying outcome identifying relevant determining factors taking context sensitive approach help pick features interactions could reasonably make difference outcome specifically applies decision recipient consideration example model predicts patient high chance developing lung cancer lifetime features interactions significantly contributed prediction include family history doctor knows patient family history lung cancer concludes given risks arising shared environmental genetic factors family history considered strong determinant patient case integrate chosen correlations outcome determinants reasoning final step involves integrating correlations identified relevant reasoning consider particular set factors influenced model result combined specific context decision recipient support overall conclusion outcome similarly implementers able make reasoning explicit intelligible affected individuals decision recipients able easily understand statistical result applied particular case implementer assessed outcome could explanation format may need able make sense october task prepare implementers deploy system glance cases decisions fully automated implementers need meaningfully involved means need appropriately trained use model results responsibly fairly training cover basics machine learning works limitations automated technologies benefits risks using systems assist particularly help humans come judgements rather replacing judgement manage cognitive biases including bias bias checklist detail introduction preparing implementers deploy human loop trained implementers understand associations correlations link input data model prediction classification interpret correlations consequential providing meaningful explanation drawing domain knowledge decision recipient specific circumstances combine chosen correlations outcome determinants know individual affected come conclusion apply model results individual case hand rather uniformly across decision recipients recognise situations bias bias occur mitigate understand strengths limitations october basics implementer training introduction human meaningfully involved deploying outcome decision fully automated make sure appropriately trained prepared use model results responsibly fairly implementer training therefore include conveying basic knowledge statistical probabilistic character machine learning limitations automated technologies training avoid anthropomorphic portrayals systems also encourage implementers view benefits risks deploying systems terms role helping humans come judgements rather replacing judgement training address cognitive judgemental biases may occur implementers use systems different settings based highlighting example results system occur known bias results occur bias cognitive biases may include overconfidence prediction based historical consistency data illusions clustering data points necessarily indicates significant insights discounting social patterns exist beyond statistical result also include situations implementer may disregard outcome system due scepticism distrust technology individuals likely expect decisions produced treat terms demographic probabilities statistics therefore apply inferences drawn model results particular circumstances decision recipient basics implementer training educate implementers cognitive biases good implementer preparation begins anticipating pitfalls potential decision support systems tend give rise training responsible implementation therefore start educating users two main types bias bias bias bias users systems may become hampered critical judgment situational awareness result overconfidence objectivity certainty system may lead automated systems results implementers may lose capacity identify respond faults errors deficiencies become complacent defer directions cues bias may also lead tendency system results implementers may defer perceived infallibility system become unable detect problems emerging use fail hold results available information october may exacerbated underlying fears concerns disagreeing going system results might create accountability liability issues wider organisational legal contexts may lead known syndrome degradation role human reason deskilling critical thinking hampers user ability complete tasks automated may reduce ability respond system failure may lead safety hazards dangers discriminatory harm bias extreme users automated system may tend disregard contributions reasoning result distrust scepticism technologies general may also importance prudence common sense human expertise failing see support may help reduce implicit cognitive biases understand complex patterns data otherwise unavailable reasoning users aversion amoral character automated systems could also lead decision subjects mistrust technologies high impact contexts healthcare transportation law combat risks bias bias certain actions take build comprehensive training preparation program implementers users explores judgment biases biases cognitive biases educate spectrum biases including examples particular misjudgements may occur people weigh statistical evidence examples latter may include overconfidence prediction based historical consistency data illusions clustering data points necessarily indicates significant insights discounting societal patterns exist beyond statistical results make explicit operationalise strong regimes accountability systems deployed order steer human act basis good reasons solid inferences critical judgment even supported results educate implementers strengths limitations systems training responsible deployment also include balanced comprehensive technical view possible limitations advantages systems means first foremost giving users working knowledge statistical probabilistic methods behind operation systems continuing education professional development area crucial ensure people using implementing systems sufficient understanding also crucial providing users realistic demystified picture models central component training identify limitations statistical probabilistic generalisation training materials trainers stress aspect uncertainty underlies statistical probabilistic reasoning help users implementers approach october results appropriately critical eye clear understanding indicators uncertainty like confidence intervals error bars training also stress variety performance error metrics available measure statistical results ways metrics may sometimes conflict depending metrics chosen educating users advantages systems training involve demonstrations capacities applied show useful informative patterns inferences drawn large amounts data may otherwise escaped human insight given time pressures well sensory cognitive limitations educating users advantages systems also involve demonstrations responsible model design support improve objectivity human equitable information processing train implementers use statistical results support reasoning another crucial part training responsible implementation preparing users able see results assisting reasoning rather replacing general rule use results statistical probabilistic analysis help guide actions done properly kind analysis offers solid basis empirically derived evidence assists exercising sound judgment matters informs good understanding factors produce result particular system means able see factors instance input features weigh heavily determining given algorithmically generated output mean result rationally acceptable train implementers understand output particular system support reasoning train grasp optimally draw determining factors lie behind logic output exercise sound judgment instance consideration training emphasise critical function played rational justification meeting reasonable expectations decision recipients desire require explanations carrying function demands users implementers offer arguments justifying outcome concern arguments make sense expressed clear understandable terms accessible enough rationally assessed affected individuals especially vulnerable disadvantaged train implementers think contextually holistically results systems based correlations derived training data therefore refer specifically actual circumstances background abilities individual decision recipient statistical generalisations picked relationships decision recipient input data patterns trends model extracted underlying distribution model original dataset reason train implementers think contextually holistically statistical generalisations apply specific situation decision recipient training involve preparing implementers work active awareness aspect implementing technologies integrative point october view train implementers apply statistical results particular case appropriate big picture sensibility means dignity show decision subjects supported interpretive understanding reasonableness empathy training materials illustrate applying judgment help implementers weigh system results unique circumstances decision recipient life situation way implementers integrate translation system rationale useable easily understandable reasons task holistic considerations reasons actually apply particular decision subject training implementers integrate task contextsensitive reasoning enable treat inferences drawn results model computation evidence supports broader rounded coherent understanding individual situations decision subject affected october task consider build present explanation glance build explanation start gathering together information gained implementing tasks review information determine provides evidence base explanations revisit contextual factors establish explanation types prioritise present explanation depends way make decisions people might expect deliver explanations make without using layer explanation proactively providing individuals first explanations prioritised making additional explanations available layers helps avoid information explanation overload think delivering explanation conversation rather process people able discuss decision competent human providing explanation right time also important increase trust awareness use proactively engage customers making information available use systems help make decisions checklist gathered information collected tasks reviewed fit within explanations introduced part considered contextual factors impact order deliver explanation types affect delivery method presented explanation layered way giving relevant explanation type upfront providing types additional layers made clear decision recipients contact would like discuss decision human provided decision recipient relevant explanation explanation type advance making decision proactively made information use available order build trust customers october detail introduction considering build present explanation gather relevant information explanation type consider contextual factors delivering explanation layer explanations explanation dialogue explanation timing proactive engagement introduction able provide explanation individual need consider build present information clear accessible manner start considering information obtained completing tasks determine much information required decision recipient consider explanations part step also consider explanation types prioritise could revisit contextual factors introduced part guidance help determine appropriate method delivery based way make decisions people might expect deliver explanations decisions make without using might verbally face face electronic format think reasonable adjustments might need make people equality act timing delivery explanations also affect way deliver explanation deliver explanations electronic form may also wish consider whether design choices help make telling people clear easy understand example addition text simple graphs diagrams may help certain explanations rationale safety performance depending size resources organisation may able draw expertise user experience user interface designers gather relevant information explanation type completing tasks documented steps took information require deliver explanation decision recipient use information build explanation ready delivery task identified relevant explanation types use case taking account contextual factors part guidance sets kinds information need extract support explanation type including information process data used train model outcome people similar position treated comparison decision recipient task discusses take account explanation types collecting october task sets key issues related extract information needed relevant explanation types especially rationale explanation model task focusses translating rationale system understandable terms also yield information support explanation types followed tasks ready consider present explanation decision recipient consider contextual factors delivering explanation building explanation revisit contextual factors introduced part guidance domain factor impact factor data factor urgency factor audience factor although relevant throughout design development deployment system consider detail deciding build present explanation domain factor important domain sector operating affect type explanation decision recipients want receive also may legislation specific sector dictates deliver explanation impact factor important impact decision individual society determine level information required explanation example decision significant impact individual may need provide detailed explanation impact low data factor helps decision recipient understand model trained data used make decision type data processed may affect deliver explanation may circumstances explanation provided gives decision recipient information affect outcome future urgency factor helps determine quickly provide explanation order providing different explanation types audience factor level understanding would expect decision recipient decision affect type language use delivering explanation layer explanations based guidance provided engagement industry think makes sense build layered explanation layered mean providing individuals prioritised explanations first layer making october additional explanations available second possibly third layer deliver explanation website use expanding sections tabs simply link webpages additional explanations purpose layered approach avoid information explanation fatigue means overload people instead provided likely relevant important information still clear easy access explanatory information wish know decision explanation dialogue however choose deliver explanations individuals important think conversation opposed process providing priority explanations initiating conversation ending individuals easy access additional explanatory information hence layered explanations also able discuss decision human ties responsibility explanation human reviewer however well able contest decisions important provide way people talk clarify explanations competent human explanation timing important provide explanations decisions individuals right time delivering explanation telling people result decision equally telling people decisions made advance explanation provide advance part provided two categories type explanation provide explanations advance specific decision addition explanations provide advance particularly related responsibility responsible taking decision supported result system reviewing implementing impact assessed potential impact model individual wider community data data input system train test validate also situations provide explanation advance decision would afterwards sectors possible run simulation model output example applied loan organisations could explain computation tell factors matter determining whether application accepted cases like distinction explanations decision less important however many situations case prioritised explanations see step provide relevant explanations decision explanations able october explanation provide decision provide full explanation decision however specific explanations able explain advance example rationale fairness safety performance system specific particular decision likely queried decision made explain underlying logic system led specific decision output whether decision recipient treated fairly compared others similar whether system functioned properly particular instance reading part basics explaining example example clinicians using system help detect cancer example explanations health care cancer diagnosis explanationresponsibility responsible ensuring system used detecting cancer works intended way rationale steps taken ensure components measurements used model make sense detecting cancer made understandable affected patients fairness measures taken ensure model fair prevents discrimination mitigates bias case may include measures taken mitigate unbalanced unrepresentative datasets possible selection biases safety performance measures taken ensure model chosen detect cancer secure accurate reliable robust tested verified validated impact measures taken ensure model negatively impact patient october important good way provide explanation individual might need also way comply law articles gdpr require proactively provide individuals information logic involved well significance envisaged consequences processing data case solely automated decisions legal similarly significant designed used data ensured source quantity quality data used train system appropriate type cancer detection utilising model explanationresponsibility responsible taking diagnosis resulting system output implementing providing explanation diagnosis came patient order query diagnosis impact design use system particular case patient impact patient example system detects cancer result false positive could significant impact mental health patient data patient data used particular instance explanationrationale whether system output detected cancerous makes sense case patient given doctor domain knowledge fairness whether model produced results consistent produced patients similar characteristics safety performance secure accurate reliable robust model patient particular case safety performance measures used test october article gdpr also gives individuals right obtain information time request also good practice systems human loop explanations rationale system explanation system impact individual fulfil requirement gdpr determine appropriate way deliver explanations choose provide however might consider direct helpful way would deliver explanations provide advance decision consider individuals likely find explanation information make decisions support systems think using platform providing advance explanation use provide ultimate decision means information individual needs one place also ensure explanation prominent make easier individuals find proactive engagement build trust proactively making information available use systems help make decisions good way increase awareness among customers help know use system works open inclusive share information increase trust customers operate build confidence organisation using help get better service primary research conducted found public looking engagement organisations awareness raising use proactive use engagement help fulfil principle transparent proactively share among things could consider sharing following helps demystify technologies involved might useful outline technologies provide couple examples used sector used reading good example animation machine learning produced researchers university oxford machine learning animation october outline different ways useful supporting tells people tools could provide examples use help make decisions benefits lay beneficial specifically individuals affected decisions make example service provider outline personalise services customers get better experience benefits cover could also explore ways tools available better traditional tools examples could help make clear risks honest wrong sector example lead discrimination misinformation mitigate helps set people expectations situation helps understand look also provide information people rights gdpr example right object challenge use right obtain human review intervention use decisions clearly comprehensively explain chosen use systems particular organisation expand general examples provided improves service offer compared approaches applicable benefits customers describe parts organisation parts process using make informative possible could also outline measures put place ensure system using areas designed way maximise benefits minimise risks particular clear whether human loop whether solely automated addition might helpful show managing system use make sure maximising interests customers individuals speak could provide email address helpline interested members public contact order get information using answering queries good knowledge using able explain clear open accessible way amount detail provide proportionate information people ask share many different ways could proactively share information customers stakeholders usual communications customers stakeholders regular newsletters customer information providing link dedicated part website outlining sections october flyers leaflets distributed offices relevant partner organisations information campaign initiative partnership organisations information distribute trade bodies communications team important role play making sure information targeted relevant customers reading ico written guidance right informed help communication task guidance right informed gdpr example annexe provide example showing tasks could relate particular case health october part explaining means organisation guidance purpose guidance guidance covers various roles policies procedures documentation put place ensure organisation set provide meaningful explanations affected individuals use guidance primarily senior executives organisation offers broad outline roles part play providing explanation decision recipient whether directly part process data protection officers dpos compliance teams well technical teams may also find documentation section useful status guidance guidance issued response commitment government sector deal statutory code practice data protection act dpa intended comprehensive guidance data protection compliance practical guidance sets good practice explaining decisions individuals made using systems processing personal data guidance ico alan turing institute ico responsible overseeing data protection alan turing institute turing national institute data science artificial intelligence october professor dame wendy hall jérôme pesenti published independent review growing industry second report recommendations support uptake ico turing april government published sector deal deal tasked ico turing framework explaining processes services decisions delivered improve transparency october independent report sector deal part ongoing efforts made national international regulators governments address wider implications transparency fairness decisions impacting individuals organisations wider together develop guidance assist explaining october organisational roles functions explaining glance anyone involved pipeline role play contributing explanation decision supported model result includes called development team well responsible governed organisation recognise every organisation different structures development governance teams smaller organisations several functions outline covered one person many organisations outsource development system case data controller primary responsibility ensuring system use capable producing explanation decision recipient checklist detail participate explanation extraction delivery use system supplied third party participate explanation extraction delivery people involved every part pipeline including model design implementation processes role play providing explanations individuals receive decision supported model result section describe various roles process providing explanation cases part process may sit within organisation example procured system external vendor information process provided later part identified people key roles across pipeline responsible contributing explanation system ensured different people along pipeline able carry role producing delivering explanations particularly development teams giving explanations decision recipients dpo compliance teams buying system third party know primarily responsibility ensuring system capable producing october roles discussed range involved initial decision use system solve problem teams building system using output system inform final decision govern done organisation depending organisation roles outlined might configured different ways concentrated one two people please note exhaustive list individuals may involved contributing explanation decision made system may roles unique organisation sector outlined roles listed main ones feel every organisation consider implementing system make decisions individuals overview roles involved providing explanation product manager defines product requirements system determines managed including explanation requirements potential impacts system use affected individuals product manager also responsible throughout system lifecycle responsible ensuring properly maintained improvements made relevant also need ensure system procured retired compliance relevant legislation including gdpr dpa development team development team performs several functions including collecting procuring analysing data input system must representative reliable relevant bringing domain expertise ensure system capable delivering types explanations required domain experts could example doctors lawyers economists engineers building maintaining data architecture infrastructure ensure system performs intended explanations extracted building training optimising models deploy system prioritising interpretable methods testing model deploying extracting explanations supporting implementers deploying system practice please note development team may sit within organisation part another organisation purchased system third party procure system third party still need ensure understand system works extract meaningful information necessary provide appropriate explanation implementer human loop decision fully automated implementer relies model developed supplement complete task everyday work life order extract explanation implementers either directly use model inherently interpretable simple use supplementary tools methods enable explanation tools methods provide implementers information represents components rationale behind model results relative feature importance implementers take information consider together evidence make decision proceed system developed third party vendor ensure provide sufficient training support implementers able understand model using support place implementers may skills knowledge deploy october system responsibly provide accurate context sensitive explanations decision recipients compliance teams including dpo ensure development use system comply regulations policies governance procedures includes compliance data protection law expectation decisions explained individuals affected decisions senior management team overall responsibility ensuring system developed used within organisation procure third party appropriately explainable decision recipient suggest compliance teams including dpo senior management expect assurances product manager system using provides appropriate level explanation decision recipients assurances give roles high level understanding systems types explanations produce additionally may occasions dpo compliance teams interact directly decision recipients example complaint made cases need detailed understanding decision reached need trained convey information appropriately affected individuals system may also subject external audit example information commissioner office ico assess whether organisation complying data protection law data protection includes expectation decisions made explained individuals affected decisions audit need produce documentation prepared testing undertaken ensure system able provide different types explanation required focus guidance providing explanations decision recipients detail however would like information documentation required provide subject gdpr audit please read auditing framework move along pipeline roles identified certain amount translation exposition required need translate reasoning behind statistical outputs system different audiences likewise organise documented innovation processes ensured system accountable safe ethical fair make accessible different audiences internally organisation means implementer dpo compliance team senior management externally means translating performed technical point view language reasoning clear easily understandable decision recipient external auditor roles roles identified generic ones fit particular case others consider roles relate decision making pipeline therefore task providing explanation reading auditing framework october use system supplied third party sourcing system significant parts third party supplier functions responsibilities may look different whether build data controller primary responsibility ensuring system use capable producing appropriate explanation decision recipient procure system third party supplier shelf contain inherent explainability may need another model alongside part explaining practice reading information supplementary models techniques explaining practice october policies procedures glance whether create new policies procedures update existing ones cover explainability considerations actions require employees concept deployment systems policies set rules place apply procedures provide directions implement rules set policies checklist detail need policies procedures explaining policies procedures cover need policies procedures explaining policies procedures important several reasons help ensure consistency standardisation clearly set rules responsibilities support adoption organisational culture highly desirable approach explaining decisions individuals may want create new policies procedures might make sense adapt extend already exist data protection information management policies broader information governance accountability frameworks choose depends unique set organisation matters clear explicit focus explaining decisions individuals necessary done help embed explainability core requirement use may policies procedures cover explainability considerations actions require employees concept deployment systems policies make clear rules around explaining decisions individuals rules place apply procedures give directions implement rules set october several current policies add case document processes accurately possible cross reference policies necessary policies procedures cover policies procedures cover explainability considerations actions require employees concept deployment systems short codify different parts guidance organisation policies set explaining decisions individuals make clear rules place apply procedures set explain decisions individuals directions implement rules set policies table summarises key areas cover policies indicates beneficial accompanying procedure guide depending already place may find important provide less detail certain areas others may also additional aspects covered table wish cover policies procedures policies procedures listed feel apply organisation sector type system implemented may need include level detail likely proportionate level risk impactful less expected processing detail likely need policies procedures documentation procure system another organisation develop may policies procedures required vendor however still data controller decisions made system responsibility ensure vendor taken necessary steps outlined table consult relevant staff drafting policies procedures ensure make sense work practice policy procedure policy objectiveexplain policy seeks achieve provision appropriate explanations decisions individuals even incorporate requirements around explaining decisions existing policy framework ensure particular objective explicitly policy rationale outline policy necessary cover broad legal requirements october requirements specific organisation sector also cover benefits organisation relevant link rationale organisation broader values goals policy scope set policy covers start clarifying types decisionmaking systems scope say departments parts organisation policy applies necessary explain policy links relevant policies organisation signposting organisational requirements around use systems within policy policy ownershipmake clear role within organisation ownership policy overarching responsibility explainability systems explain monitor enforce steps policy owner take monitor enforce use set checks make often make record work roles set specific roles organisation stake influence explainability describe responsibilities role connection explaining decisions individuals detail required interaction different roles departments appropriate reporting lines way policy impact assessmentexplain requirement explainability embedded within organisation impact assessment methodology likely legally required assessment data protection impact assessment could also form part broader risk ethical state need conduct assessment including considering explainability work begins decisionsupport system describe make necessary explainability assessments including consideration relevant explanation types suitable model context within making october decisions individuals awareness raisingexplain importance raising awareness use decisions customers service users set information communicate including use simple detail specific approach organisation takes raising awareness clarify host information customers communicate make available channels often roles departments responsible data collection underline need consider explanations earliest stages model development including data collection procurement preparation phases explain important reference benefits interpretable training steps take data collection stage enhance explainability model including assessing data quality structure feature interpretability approach labelling model selection explain considerations explainability factored selection model development stage algorithmic techniques chose use appropriate system use case potential impacts set steps took weigh model types priority interpretability system signpost ensured selected model appropriate fulfil priority explanation extractionset different types explanation outline requirements obtain information relevant various technical procedures organisation uses extract rationale explanation models use local explanation tool lime use visualisation counterfactual methods describe obtain information explanations obtain record explanation deliveryexplain need build deliver explanations way meaningful individuals decisions prioritise explanation types translate technical terminology plain language format present explanation layers assess appropriate timing delivery decision documentation clearly state necessity document justifications andset standardised method stakeholders october choices made whole process acquiring deploying system outline requirement document provision explanations individuals clarify information record urn time stamp explanation url justifications choices explain organisation keeps audit trail explanations provided individuals including accessed checked training set requirements general staff training explaining decisions individuals covering necessary done identify roles require training specific aspects explaining decisions preparing training data extracting rationale explanations october documentation glance essential document stage process behind design deployment system order provide full explanation made decision case explaining decisions includes documenting processes behind design implementation system documenting actual explanation outcome suggested areas documentation may apply organisations intended give indication might help provide evidence establish decision made key objective provide good documentation understood people varying levels technical knowledge covers whole process designing system decision make end checklist detail documentation legally required gdpr documentation provide demonstrate explainability system organise documentation documentation legally required gdpr article gdpr says controller shall responsible able demonstrate compliance paragraph accountability article gdpr requires provide information data subject concise transparent intelligible easily accessible form using clear plain also states provide information combination standardised icons order give easily visible intelligible documented required gdpr documented stage use contributes building explanation concept deployment documentation provides audit trail give explanations provide considered best organise documentation relevant information easily accessed understood providing explanations decision october clearly legible manner meaningful overview intended article gdpr requires provide dpo contact details aligns responsibility explanation purpose processing data subject personal data well legal basis processing many cases form part explanation existence automated including profiling referred article least cases meaningful information logic involved well significance envisaged consequences processing data subject must document ensure remain accountable article gdpr applies cases obtained personal data data subject directly provide data subjects following information addition required article within reasonable period obtaining personal data latest within one month regard specific circumstances personal data processed categories personal data processing source obtained personal data applicable whether came publicly accessible sources see article gdpr information required provide information data subject includes processing personal data archiving purposes public interest scientific historical research purposes statistical purposes subject certain conditions safeguards article gdpr gives data subjects additional right access personal data hold means document provide copy personal data process article gdpr gives data subjects right object time grounds relating particular situation processing personal data concerning including profiling means document ensure data subjects aware right record exercised right article gdpr gives individuals right subject solely automated decision producing legal similarly significant effects unless certain conditions apply obliges adopt suitable measures safeguard individuals including right obtain human intervention express view contest decision means need document article gdpr helps fulfil accountability principle states organisation shall record processing activities article gdpr requires organisations carry data protection impact assessment dpia something personal data particularly using new technologies likely high risks individuals dpia always required systematic extensive profiling automated evaluation individuals personal aspects used decisions produce legal similarly significant effects reconcile documentation requirements privacy notice must contain certain october lawful basis processing one bases laid article gdpr applicable legitimate interests processing interests pursued third party relying lawful basis processing article gdpr could also include link record assessment whether legitimate interests apply particular processing purpose rights available individuals regarding processing access rectification erasure restriction data portability objection rights vary depending lawful basis processing documentation reflect differences applicable existence automated including profiling certain circumstances need tell people logic involved envisaged consequences applicable source personal data relevant obtain personal data directly individual aware different documentation requirements may apply law enforcement processing part dpa intelligence services processing part act guidance focusses documentation required support explanations auditing framework covers aspects system particular framework details require documentation data protection compliance good information governance reading documentation help demonstrate explainability system list support provide explanation decision recipient maintain audit trail give explanations provide may need provide document information may obtain information vendor procure system decide information required documented information help provide explanation decision recipient policies procedures section approach help example system recommends groceries buy films watch require less detail recruitment decision use system system intended used explain decision recipient planning use ultimate decision recipient system chosen technical perspective way decisiondocumentation auditing framework external october recipient also understand specifications system determined well alternative specifications considered chosen system procured third party outsourced change retool specifications meet changing performance explainability needs time involved data subject whose data used model often also decision recipient example data subject personal data may used training system produce highly accurate model use data may data subject interest demographics background development team order aware diversity within team responsible designing deploying maintaining system may impact decision decision recipient domain using system system tested validated domain impact assessment relevant domain addition dpia mentioned people within organisation responsibility providing explanations along design implementation pipeline system explanation types supports rationale responsibility fairness safety performance impact scoping selecting explanation types processes set optimise accountability model setting sector model used bearing types explanation offer prioritised certain explanation type based system potential impact chosen handle remaining explanation types prioritised certain way set aspects explanations types offer provided depth comprehensiveness explanation given potential impacts system includes general risks deploying system risks specific person receiving decision within organisation responsible selecting appropriate type explanation explanation types supports rationale responsibility data fairness safety performance impact data collection procurement data came purpose data originally collected help explain decision recipient relevant data used decision system made components dataset together brief summary element included data representative people subject decisions make october example consideration domain expert made sure data reliable accurately measured obtained source integrity examined datasets potential inherent bias whether data recent appropriately timely given rate change underlying distribution modelling demonstrate accounted concept drift data fluctuation start rate change depend domain operating specific case considering use synthetic data provide documentation created properties helps explain justify decision recipient created data used training model appropriate risks associated using data risks whose data included individuals opt included data used either train run system explanation types supports data fairness safety performance impact data especially cases social demographic data involved ensured data produced feature space includes variables understandable relevant reasonable include variables opaque difficult understand model target variable labelled data labelled way include tagging annotating piece data reasons tag mitigated bias data techniques masking excluding features proxies using raw observed unconventional data documentation interpretively significant feature data supposed indicate individual whose data processed evidence included metadata within organisation responsible data collection explanation types supports responsibility data fairness safety performance impact model selection specific interpretability transparency standards conventions requirements domain system applied specific type application impact individuals informs type model choose types data using example social demographic data biophysical data influenced model selection regarding interpretability whether use case enables use maximally interpretable algorithmic techniques using black box models risks using provide supporting evidence team determined use case organisational capacities resources support responsible design implementation october using opaque algorithmic techniques black boxes supplementary tools use explain model provide level explainability documentation demonstrate supplementary tool mitigate potential risks using black box system use tool help provide meaningful information rationale given outcome use challenger models alongside interpretable models purpose models use explanation types supports rationale responsibility data fairness safety performance impact model building testing monitoring accuracy rate performance metrics chosen model well tuning cost ratios constrain error allocation selected able explain decision recipient choice may affect decision made relevant error rates model tuned redress significant imbalances monitored assessed potential biases model design measures taken mitigate identified tested model including test results portions data used train test model holdout data frequently monitor update model deployed real world often update training data model production deployment also document put place establish appropriate frequency updates track time model updated version changed explain decision recipient particular version model came decision might differ output subsequent prior model explanation types supports rationale data fairness safety performance tools extracting explanation using inherently interpretable models measures taken ensure optimal explainability example sparsity constraints placed feature space explanations remain human understandable using supplementary interpretability tools black box models outline local global techniques used provide explanations may form detailed specifications supplementary tools used plan combine different explanation tools produce meaningful information rationale system results responsible ensuring explanations generated supplementary tools accessible people intended inform translate statistical output model supplementary tools explanation example establishing documenting appropriate implementer training providing users comprehensive guidelines responsible october explanation types supports rationale responsibility explanation delivery prioritise certain explanation types deliver explanation affected individual given contextual factors determine relevant particular case considering prioritised remaining explanation types training provided implementers enable use model results responsibly fairly implementer presented model result including present performance metrics error rates model whole appropriate present uncertainty measures like error bars confidence intervals use visualisation tools present indicators relative variable important variable interactions case black box models present information supplementary tools well indicators limitations uncertainty levels tools reasonable adjustments make form deliver explanation required equality act information proactively share customers stakeholders able make informed choices advance engaging process decision recipients contact query decision explanation types supports rationale responsibility data fairness safety performance impact organise documentation part guidance emphasised preparing organisation explain decisions holistic activity involves demonstrating undertaken processes behind design development deployment system responsibly clarifying outcomes system clear understandable way called aspects explaining explanations whether developer building supplying applications organisation developing systems one challenges may face figuring best organise documentation innovation practices help explanations may first seem like daunting task involves documenting diverging governance activities across design deployment lifecycle consolidating information easily convey diverse range stakeholders varying needs levels technical domain expertise differentially organising provide information different stakeholders receive appropriate kinds quantities information example ensuring decision recipients overwhelmed technical details vast amounts text provided commercially october information one method organising documentation explanations building assurance cases properties model like safety fairness find details annexe however choose organise documentation way allows easily access relevant information required explanation type supported current document management system accessible within organisation provide explanations decision recipients plan procure system ensure process choose allows communicate vendor way mutually manages expectations vendor able offer evidence compliance ability explain decisions justification evidence documentation able better provide information decision recipients also able assess whether model offered vendor meets acceptable criteria standards set system readingfurther reading guidance procuring systems may wish read world economic forum government procurement guidelines although guidance primarily aimed public sector organisations large number principles contained within guidance able apply organisation ico turing consultation explaining decisions guidance summary responses ico pdf october annexe example building presenting explanation cancer diagnosis bringing together guidance following example shows healthcare organisation could use steps outlined help structure process building presenting explanation affected patient task select priority explanation types considering domain use case impact individuals first healthcare organisation familiarises explanation types guidance based healthcare setting impact cancer diagnosis patient life healthcare organisation selects explanation types determines priority provide patients subject decisions documents justification choices priority explanation types rationale justifying reasoning behind outcome system maintain accountability useful patients visualisation techniques explanation available impact due high impact situation important patients understand effects next responsibility audience likely want know query system output safety performance given data domain complexity may help reassure patients accuracy safety reliability system explanation types data simple detail input data well original dataset external validation data fairness likely biophysical data opposed social demographic data fairness issues arise areas data representativeness selection biases providing information efforts relevant may healthcare organisation formalises explanation types relevant part policy information governance information governance policy use explaining decisions patients types october rationale impact responsibility safety performance data fairness task collect data manner data healthcare organisation uses bearing impact risk assessment healthcare organisation therefore chooses data carefully considers impact ensure able provide adequate explanation decision recipient rationale information data labelled shows reasons classifying example certain images tumours responsibility information part healthcare organisation system procured part vendor organisation responsible collecting patient data transparent process end end help healthcare organisation build trust confidence use data information data used collected cleaned chosen train model details steps taken ensure data accurate consistent date balanced complete safety performance information model selected performance metrics given available data included training model healthcare organisation third party vendor chose measures also information measures taken safeguard preparation data ensures system robustness reliability harsh uncertain adversarial conditions task build system ensure able extract relevant information range explanation types healthcare organisation third party vendor decides use artificial neural network sequence extract information radiologic images model able predict existence types tumours character processing makes opaque model design team chosen supplementary salience mapping class activation mapping october help visualise critical regions images indicative malign tumours tools render visible highlighting abnormal regions images allow technicians radiologists gain clearer understanding clinical basis model cancer prediction enables ensure model output supporting medical practice model results integrated clinical evidence underwrites technicians radiologists professional judgment task translate rationale system results useable easily understandable reasons system hospital uses detect cancer produces result prediction particular area mri scan contains cancerous growth prediction comes probability particular level confidence measured percentage supplementary mapping tools subsequently provide radiologist visual representation cancerous region radiologist shares information oncologist doctors medical team along detailed information performance measures system certainty levels patient oncologist members medical team put language another format patient understand one way doctors choose visually showing patient scan supplementary visualisation tools help explain model result highlighting areas system flagged intuitive way help patient understand happening doctors also indicate much confidence system result based performance uncertainty metrics well weighing clinical evidence measures task prepare implementers deploy system technician oncologist using system work hospital decides need training use system implementer training covers interpret results system generates based understanding designed data trained understand weigh performance certainty limitations system view interpret confusion matrices confidence intervals error bars etc use result one part complement existing domain knowledge critically examine whether system result based appropriate logic rationale case prepare plan communicating system result patient role result played doctor judgement includes limitations using october task consider build present explanation explanation types healthcare organisation chosen explanation quality explanation also influenced collect prepare training test data model choose therefore collect following information explanation type rationale explanation information show system set way enables explanations underlying logic extracted directly using supplementary tools explanations meaningful patients concerned explanation information logic behind model results implementers incorporated logic includes system transforms input data outputs translated language understandable patients medical team uses model results reaching diagnosis particular case responsibility explanation information responsible within healthcare organisations third party provider managing design use model ensured model responsibly managed throughout design use explanation information responsible using system output evidence support diagnosis reviewing providing explanations diagnosis came patient order query diagnosis safety performance explanation information measures taken ensure overall safety technical performance security accuracy reliability robustness information testing verification validation done certify explanation information safety technical performance security accuracy reliability robustness model actual operation information confirming model operated securely according intended design specific patient case could include safety performance measures used impact explanation measures taken across model design use ensure negatively impact wellbeing patient explanation information actual impacts system patient healthcare organisation considers contextual factors likely effect patients want know decisions plans make cancer diagnosis draws list relevant october contextual factors domain regulated safety data urgency cancer impact high audience mostly healthcare organisation develops template delivering explanation decisions cancer diagnosis layered way layer rationale explanation impact explanation responsibility explanation safety performance explanation delivery clinician provides explanation face face patient supplemented hard email information layer data explanation fairness explanation delivery clinician gives patient additional information hard email via october annexe algorithmic techniques algorithm typebasic description possible uses interpretability linear regression makes predictions target variable summing weighted highly regulated sectors like finance credit scoring healthcare predict disease risk given lifestyle existing health conditions simpler calculate oversight high level interpretability linearity monotonicity become less interpretable increased number features high dimensionality logistic regressionextends linear regression classification problems using logistic function transform outputs probability linear regression advantageous highly regulated safetycritical sectors use cases based classification problems decisions risks credit level interpretability less features transformed logistic function related probabilistic result logarithmically rather sums regularised regression lasso ridge extends linear regression adding penalisation regularisation feature weights increase reduce linear regression advantageous highly regulated safetycritical sectors require understandable accessible transparent level interpretability due improvements sparsity model better feature selection procedures generalised linear model glm model relationships features target variables follow normal gaussian distributions glm introduces link function allows extension extension applicable use cases target variables constraints require exponential family set distributions instance target variable involves number people units time probabilities outcome result value level interpretability tracks advantages also introducing flexibility link function determining feature importance may less straightforward additive character simple degree transparency may october generalised additive model gam model relationships features target variables captured gam sums functions predictor variables like splines fitting rather simple weighted features extension applicable use cases relationship predictor response variables linear relationship changes different rates different times optimal interpretability level interpretability even presence relationships gam allows clear graphical representation effects predictor variables response variables decision tree model uses inductive branching methods split data interrelated decision nodes terminate classifications predictions moves starting root nodes terminal leaf nodes following logical decision path determined operators weighted logic produces outcomes easily understandable users depending number features method may used safetycritical situations require transparency well many use cases volume relevant features reasonably low high level interpretability kept manageably small logic followed advantage former accommodate variable interaction remaining interpretable lists setsclosely related lists sets apply series statements input features order generate predictions whereas decision lists ordered narrow logic behind output applying else rules decision sets keep individual statements unordered largely independent weighting rule voting occur generating predictions logic produces rule lists sets easily understandable users method may used safetycritical situations require transparency well many use cases clear fully transparent justification outcomes priority rule lists sets one highest degrees interpretability optimally performing algorithmic techniques however also share possibility degrees understandability lost rule lists get longer rule sets get larger reasoning cbr exemplars drawn prior human knowledge cbrcbr applicable domain uses examples drawn october prototype criticismpredicts cluster labels learning prototypes organising input features subspaces representative clusters relevance method extended use maximum mean discrepancy mmd identify criticisms slices input space model misrepresents data combination prototypes criticisms used create optimally interpretable used instance medicine treatments recommended cbr basis prior successes like cases point decision maker towards suggesting treatment extension cbr methods prototype criticism meant better facilitation understanding complex data distributions increase insight actionability interpretability data knowledge order syphon input features human recognisable representations preserves explainability model sparse features familiar prototypes supersparse linear integer model slim slim utilises learning generate simple scoring system requires users add subtract multiply numbers order make prediction slim produces sparse accessible model implemented quickly efficiently users need special training deploy system slim used medical applications require quick streamlined optimally accurate clinical version called slim riskslim applied criminal justice sector show sparse linear methods effective recidivism prediction opaque models use sparse easily understandable character slim offers optimal interpretability manually completed scoring system also ensures active engagement implements naïve bayes uses bayes rule estimate probability feature belongs given class assuming features independent classify feature naïve bayes classifier computes posterior probability classwhile technique called naïve reason unrealistic assumption independence features known effective quick calculation time scalability make good applications high dimensionalnaïve bayes classifiers highly interpretable class membership probability feature computed independently assumption conditional probabilities independent variables statistically independent however october membership feature multiplying prior probability class class conditional probability spaces common applications include spam filtering recommender systems sentiment weakness feature interactions considered neighbour knn used group data clusters purposes either classification prediction technique identifies neighbourhood nearest neighbours around data point concern either finds mean outcome prediction common class among simple intuitive versatile technique wide applications works best smaller datasets makes assumptions underlying data distribution effective data without losing interpretability common applications include recommender systems image recognition customer rating works assumption classes outcomes predicted looking proximity data points upon depend data points yielded similar classes outcomes intuition importance explanation knn results explanation convincing feature space remains small similarity instances remains accessible support vector machines svm uses special type mapping function build divider two sets features high dimensional feature space svm therefore sorts two classes maximising margin decision boundary extremely versatile complex sorting tasks used detect presence objects images face cat classify text types sports article identify genes interest level interpretability depends dimensionality feature space cases use svm supplemented secondary explanation tools artificial neural net ann family statistical techniques including recurrent convolutional deep neural nets build complex mapping functions predict classify data employing sometimes input variables throughann best suited complete wide range classification prediction tasks high dimensional feature cases large input vectors uses may range computer vision image recognition sales weather forecasting tendencies towards curviness extreme input variables produce interpretability ann considered epitome black box techniques appropriate use ann october trained networks interconnected discovery stock prediction machine translation disease diagnosis fraud secondary explanation tools random forestbuilds predictive model combining averaging results multiple sometimes thousands decision trees trained random subsets shared features training forests often used effectively boost performance individual decisions trees improve error rates mitigate overfitting popular problem areas like genomic medicine also used extensively computational linguistics econometrics predictive risk low levels interpretability may result method training ensembles decision trees bagged data randomised features number trees given forest possibility individual trees may hundreds even thousands nodes ensemble methodsas name suggests ensemble methods diverse class combines different learner models different type one bigger model predictive classificatory order decrease statistical bias lessen variance improve performance one taken methods wide range applications tracks potential uses constituent learner models may include knn random forests naïve bayes etc interpretability ensemble methods varies depending upon kinds methods used instance rationale model uses bagging techniques average together multiple estimates learners trained random subsets data may difficult explain explanation needs kinds techniques thought basis october annexe supplementary models supplementary explanation strategywhat useful limitations surrogate models build simpler interpretable model often decision tree rule list dataset predictions opaque system purpose provide understandable proxy complex model estimates model well degree opacity good assisting processes model diagnosis improvement help expose overfitting bias also represent interactions exist original approximations often fail capture full extent relationships interactions among features seemingly unavoidable need sufficiently simple understandable humans need model sufficiently complex represent intricacies mapping function black box model works whole said measurement provide good quantitative metric accuracy approximation original complex model part may used globally locally simplified proxies partial dependence plot pdp pdp calculates graphically represents marginal effect one two input features output opaque model probing dependency relation input variable interest predicted outcome across dataset averaging effect features model good visualisation tool allows clear intuitive representation nonlinear behaviour complex functions like random forests svm helpful instance showing given model interest meets monotonicity constraints across distribution pdp allow valuable access relationships predictor response variables therefore also comparisons model behaviour expectations reasonable relationships features outcomes account interactions input variables consideration may way misleading certain features interest strongly correlated model features pdp average marginal effects may also misleading features uneven effects response function across different subsets october associations output different points pdp may flatten heterogeneities mean pdp global explainers also allow deeper causal understandings behaviour opaque model visualisation insights however partial incomplete pdp unable represent feature interactions heterogenous effects unable graphically represent couple features time human spatial thinking limited dimensions two variables space easily graspable individual conditional expectations plot ice refining extending pdp ice plots graph functional relationship single feature predicted response individual instance holding features constant except feature interest ice plots represent observation given prediction changes values feature vary significantly ice plots therefore disaggregate break averaging partial feature effects generated pdp showing changes featureoutput relationship specific instance means detect interactions account uneven associations predictor response variables used combination pdp ice plots provide local information feature behaviour enhances coarser global explanations offered pdp importantly ice plots able detect interaction effects heterogeneity features remain hidden pdp virtue way compute partial dependence outputs features interest averaging effect predictor variables still although ice plots identify interactions also liable missing significant correlations features become misleading instances constructing ice plots also become challenging datasets large cases approximation techniques sampling observation binning variables employed depending adjustments size dataset unavoidable impact explanation accuracy october ice plots offer local form supplementary explanation accumulated local effects plots ale alternative approach pdp ale plots provide visualisation influence individual features predictions black box model averaging sum prediction differences instances features interest localised intervals integrating averaged effects across intervals able graph accumulated local effects features response function whole ale plots use local differences prediction computing averaged influence feature instead marginal effect pdp able better account feature interactions avoid statistical bias ability estimate represent feature influence manner advantage ale plots ale plots also computationally tractable pdp able use techniques compute effects smaller intervals chunks observations notable limitation ale plots way carve data distribution intervals largely chosen explanation designer many intervals prediction differences may become small less stably estimate influences intervals widened much graph cease sufficiently represent complexity underlying model ale plots good providing global explanations account feature correlations strengths using pdp combination ice plots also considered especially less interaction effects model explained three visualisation techniques shed light different dimensions interest explaining opaque systems appropriateness employing weighed ale plots global form supplementary explanation global variable importancethe global variable importance strategy calculates contribution input feature model output across dataset permuting thewhile permuting variables measure relative importance extent accounts interaction effects still october feature interest measuring changes prediction error changing value permuted feature increases model error feature considered important utilising global variable importance understand relative influence features performance model provide significant insight logic underlying model behaviour method also provides valuable understanding complex model explained high degree imprecision method regard variables interacting much interactions impacting performance model bigger picture limitation global variable importance comes known rashomon effect refers variety different models may fit data distribution equally well models may different sets significant features technique provide explanatory insight regard single model performance unable address wider problem variety effective explanation schemes global variable importance form global explanation global variable interaction global variable interaction strategy computes importance variable interactions across dataset measuring variance model prediction potentially interacting variables assumed independent primarily done calculating partial dependence function subtracted observed partial dependence function order compute variance prediction versatile explanation strategy employed calculate interaction effects many types complex models including ann random forests used calculatewhile basic capacity identify interaction effects complex models positive contribution global variable interaction supplementary explanatory strategy couple potential drawbacks may want pay attention first established metric method determine quantitative threshold across measured interactions become significant relative significance interactions useful information way know point interactions strong enough exercise october interactions two variables also variables response function whole effectively used example biological research identify interaction effects among computational burden explanation strategy high interaction effects calculated combinatorially across data points means number data points increase number necessary computations increase exponentially global variable interaction form global explanation sensitivity analysis relevance propagation lrp sensitivity analysis lrp supplementary explanation tools used artificial neural networks sensitivity analysis identifies relevant features input vector calculating local gradients determine data point moved change output label output sensitivity changes input values identifies relevant features lrp another method identify feature relevance downstream sensitivity analysis uses strategy moving backward layers neural net graph map patterns high activation nodes ultimately generates interpretable groupings salient input variables visually represented heat pixel attribution sensitivity analysis lrp identify important variables vastly large feature spaces neural nets explanatory techniques find visually informative patterns mathematically piecing together values individual nodes network consequence piecemeal approach offer little way account reasoning logic behind results anns data processing recently research focused methods identifying representations guiding mapping functions kinds models well interpretable cbr methods integrated ann architectures analyse images identifying prototypical parts combining representational wholes newer techniques showing significant progress made uncovering underlying logic ann october sensitivity analysis salience mapping forms local explanation although recent incorporation cbr techniques moving neural net explanations toward internal basis interpretation local interpretable explanation lime anchorslime works fitting interpretable model specific prediction classification produced opaque system sampling data points random around target prediction classification using build local approximation decision boundary account features figure prominently specific prediction classification scrutiny lime generating simple linear regression model weighting values data points produced randomly perturbing opaque model according proximity original prediction classification closest values instance explained weighted heaviest supplemental model produce explanation feature importance locally faithful instance note interpretive models like decision trees may used lime appears step right direction versatility availability many iterations useable software host issues present challenges approach remains unresolved instance crucial aspect properly define proximity measure neighbourhood local region explanation applies remains unclear small changes scale chosen measure lead greatly diverging explanations likewise explanation produced supplemental linear model quickly become unreliable even small virtually unnoticeable perturbations system attempting approximate challenges basic assumption always simplified interpretable model successfully approximates underlying model reasonably well near given data point lime creators largely acknowledged shortcomings recently offered new explanatory approach call anchors high precision rules incorporate formal structures reasonable patterns operating within underlying model implicit linguistic conventions work october sentiment prediction model establish suitable faithful boundaries explanatory coverage predictions classifications lime offers local form supplementary explanation shapley additive explanations shap shap uses concepts cooperative game theory define shapley value feature concern provides measurement influence underlying model prediction broadly value calculated averaging feature marginal contribution every possible prediction instance consideration way shap computes marginal contributions constructing two instances first instance includes feature measured second leaves substituting randomly selected variable calculating prediction instances plugging values original model result second subtracted first determine marginal contribution feature procedure repeated possible combinations features weighted average marginal contributions feature concern beof several drawbacks shap practical one procedure computationally burdensome becomes intractable beyond certain threshold note though later shap versions offer methods approximation kernel shap shapley sampling values avoid excessive computational expense methods however affect overall accuracy method another significant limitation shap method sampling values order measure marginal variable contributions assumes feature independence values sampled correlated ways might significantly affect output particular calculation consequence interaction effects engendered variables used substitutes features necessarily unaccounted conditional contributions approximated result introduction uncertainty explanation produced october computed method allows shap extension estimate shapley values input features set produce complete distribution prediction instance computationally intensive means calculation specific instance shap axiomatically guarantee consistency accuracy reckoning marginal effect feature computational robustness made shap attractive explainer wide variety complex models provide comprehensive picture relative feature influence given instance explanation multivariate interactions underlying model may sufficiently captured simplicity supplemental interpretability technique drawback sampling well certain degree arbitrariness domain definition cause shap become unreliable even minimal perturbations model approximating currently efforts made account feature dependencies shap calculations original creators technique introduced tree shap least partially include feature interactions others recently introduced extensions kernel shap shap offers local form supplementary explanation counterfactual explanationcounterfactual explanations offer information specific factors influenced algorithmic decision changed better alternatives realised recipient particular decision outcome incorporating counterfactual explanations model point delivery allows stakeholders see input variables model modified outcome could altered benefit systems assistwhile counterfactual explanation offers useful way contrastively explore feature importance may influence outcome limitations originate variety possible features may included considering alternative outcomes certain cases sheer number potentially significant features could play counterfactual explanations given result make clear direct explanation difficult obtain selected sets possible explanations seem potentially october decisions changeable human actions like loan decisions credit scoring incorporating counterfactual explanation development testing phases model development may allow incorporation actionable variables input variables afford decision subjects concise options making practical changes would improve chances obtaining desired outcome way counterfactual explanatory strategies used way incorporate reasonableness encouragement agency design implementation yet limitations types datasets functions kinds explanations applicable finally kind explanation concedes opacity algorithmic model outright less able address concerns potentially harmful feature interactions questionable covariate relationships may buried deep within model architecture good idea use counterfactual explanations concert supplementary explanation one component comprehensive explanation portfolio counterfactual explanations local form supplementary explanation strategy systems actually integrate secondary explanation tools opaque systems offer runtime explanations behaviours instance image recognition system could primary component like convolutional neural net extracts features inputs classifies secondary component like recurrent neural net mechanism translates extracted features natural language representation thatautomating explanations systems promising approach applications users benefit gaining insights rationale complex systems operating however regardless practical utility kinds secondary tools work well explanatory infrastructure actually unpacking underlying logics explanatory layer must remain accessible human evaluators understandable affected individuals systems words remain optimally interpretable october produces explanation result user research integrating interfaces continuing advance toward potentially making implementations sensitive user needs explanationforward humanly understandable moreover incorporation domain knowledge structures architectures complex models increasingly allowing better representations prototypes built formulating primary strategy supplementary explanation still part process building system capacity another potential pitfall consider systems ability mislead provide false reassurance users especially humanlike qualities incorporated delivery method avoided designing anthropomorphic qualities user interface making uncertainty error metrics explicit explanation delivered systems secondary tools utilise many different methods explanation may global local internal combination october annexe reading prov provenance standard moreau missier prov data model recommendation url huynh moreau explanations automated decisions final iaa project report url resources exploring algorithm types general hastie tibshirani friedman franklin elements statistical learning data mining inference prediction mathematical intelligencer molnar interpretable machine learning guide making black box models explainable rudin stop explaining black box machine learning models high stakes decisions use interpretable models instead nature machine intelligence regularised regression lasso ridge gaines zhou algorithms fitting constrained lasso journal computational graphical statistics tibshirani regression shrinkage selection via lasso journal royal statistical society series methodological generalised linear model glm friedman hastie tibshirani regularization paths generalized linear models via coordinate descent journal statistical software simon friedman hastie tibshirani regularization paths cox proportional hazards model via coordinate descent journal statistical software url generalised additive model gam october lou caruana gehrke intelligible models classification regression proceedings acm sigkdd international conference knowledge discovery data mining acm wood generalized additive models introduction crc press decision tree breiman friedman stone olshen classification regression trees crc press lists sets angelino alabi seltzer rudin learning certifiably optimal rule lists categorical data journal machine learning research lakkaraju bach leskovec august interpretable decision sets joint framework description prediction proceedings acm sigkdd international conference knowledge discovery data mining acm letham rudin mccormick madigan interpretable classifiers using rules bayesian analysis building better stroke prediction model annals applied statistics wang rudin falling rule lists artificial intelligence statistics reasoning cbr prototype criticism aamodt integrated approach problem solving sustained learning knowledge engineering image processing group university trondheim aamodt plaza reasoning foundational issues methodological variations system approaches communications bichindaritz marling reasoning health sciences next artificial intelligence medicine bien tibshirani prototype selection interpretable classification annals applied statistics kim khanna koyejo examples enough learn criticize criticism interpretability advances neural information processing systems october python kim rudin shah bayesian case model generative approach reasoning prototype classification advances neural information processing systems supersparse linear integer model slim jung concannon shroff goel goldstein simple rules complex decisions available ssrn rudin ustun optimized scoring systems toward trust machine learning healthcare criminal justice interfaces ustun rudin supersparse linear integer models optimized medical scoring systems machine learning optimized scoring systems classification problems python simple customizable risk scores python resources exploring supplementary explanation strategies surrogate models bastani kim bastani interpretability via model extraction arxiv preprint craven shavlik extracting representations trained networks advances neural information processing systems van assche blockeel seeing forest trees learning comprehensible model ensemble european conference machine learning springer berlin heidelberg valdes luna eaton simone ungar solberg mediboost patient stratification tool interpretable decision making era precision medicine scientific reports partial dependence plot pdp friedman greedy function approximation gradient boosting machine annals statistics october greenwell pdp package constructing partial dependence plots journal software individual conditional expectations plot ice goldstein kapelner bleich pitkin peeking inside black box visualizing statistical learning plots individual conditional expectation journal computational graphical statistics software see accumulated local effects plots ale apley zhu visualizing effects predictor variables black box supervised learning models arxiv preprint visualizing global variable importance breiman random forests machine learning casalicchio molnar bischl september visualizing feature importance black box models joint european conference machine learning knowledge discovery databases springer cham fisher rudin dominici models wrong many useful learning variable importance studying entire class prediction models simultaneously fisher rudin dominici model class reliance variable importance measures machine learning model class rashomon perspective arxiv preprint hooker mentch please stop permuting features explanation alternatives arxiv preprint zhou hooker unbiased measurement feature importance methods arxiv preprint global variable interaction friedman popescu predictive learning via rule ensembles annals applied statistics greenwell boehmke mccarthy simple effective variable importance measure arxiv preprint october hooker august discovering additive structure black box functions proceedings tenth acm sigkdd international conference knowledge discovery data mining acm local interpretable explanation lime ribeiro singh guestrin trust explaining predictions classifier proceedings acm sigkdd international conference knowledge discovery data mining acm lime python lime experiments python ribeiro singh guestrin anchors explanations aaai conference artificial intelligence anchors python anchors experiments python shapley additive explanations shap lundberg lee unified approach interpreting model predictions advances neural information processing systems software shap extensions python wrapper shap shapley value games contributions theory games counterfactual explanation wachter mittelstadt russell counterfactual explanations without opening black box automated decisions gdpr harv ustun spangher liu actionable recourse linear classification proceedings conference fairness accountability transparency acm evaluate recourse linear classification models python secondary explainers systems liu chen rudin deep learning reasoning prototypes neural network explains predictions aaai conference artificial intelligence october park hendricks akata schiele darrell rohrbach attentive explanations justifying decisions pointing evidence arxiv preprint resources supplementary explanation ibm explainability biecek burzykowski predictive models explore explain debug interpretable machine learning retrieved accompanying software dalex descriptive machine learning explanations przemysław biecek interesting resources related xai christoph molnar iml interpretable machine learning october annexe assurance cases assurance case set structured claims arguments evidence gives confidence system possess particular qualities properties need assured take example safety performance assurance case would involve providing argument supported evidence system possesses properties allow function safely securely reliably etc given challenges operational context though assurance cases historically arisen domains safety cases technologies methodology widely used reasonable way structure document anticipatory procedural approach innovation governance stands contrast older reactive prescriptive methods increasingly challenged complex rapidly evolving character emerging technologies older prescriptive approach stressed application general standards specified systems built often treated governance retrospective exercise however assurance takes different tack starts inception project plays active role stages design use lifecycle begins normative goals derived impact assessment specific application sets structured arguments demonstrating normative requirements address impacts risks associated system use specified operating environment activities undertaken across design deployment workflow assure properties system needed realisation goals appropriate monitoring measures set ensure effectiveness implemented included list background reading resources help area governance standards relate assurance cases includes consolidated standards system software assurance international standards organisation international electrotechnical commission institute electrical electronics engineers series well object management group structured assurance case metamodel sacm also includes references several main assurance platforms like goal structuring notation gsn claims arguments evidence notation cae argumentation dynamic safety cases dsc main components assurance cases beyond scope guidance cover details different methods building assurance cases may useful provide broad view main components comprehensive assurance case fit together normative goals aims goals system address risks potential harms may caused use system defined operating environment therefore need assurance context explanation include fairness october responsibility safety optimal performance beneficial impact starting normative goals building assurance case involves identifying properties qualities given system possess ensure achieves specified goal light risks challenges faces operational context claims properties qualities traits attributes need assured order normative goals realised instance fairness assurance case property target variables measurable proxies reflect underlying structural biases discrimination one several claims central component structured argumentation needs backed appropriate supporting arguments relevant activities behind system design development process ensured structural biases fact incorporated target variables corresponding evidence documented activities methods structured argumentation like gsn claims qualified context components clarify scope given claim provide definitions background information make relevant assumptions system environment explicit spell risks needs associated claim across system design operation lifecycle claims may also qualified justification components clarifications claims chosen provide solution means realisation specified normative goal general addition context justification components reinforces accuracy completeness claims allowing support goals system focus precision clarification thoroughness crucial establishing confidence development effective assurance case arguments support claims linking evidence supporting claims reasoning arguments provide warrants claims establishing inferential relationship connects proposed property body evidence argumentative backing sufficient establish rational acceptability truth example safety performance assurance case system sufficiently robust one claims possible argument might training processes included augmentation element adversarial examples perturbations employed model harsh conditions claim would backed evidentiary support actually happened design development model justified arguments always backed body evidence may also supported subordinate claims assumptions claims without backing taken true subordinate claims underwrite arguments claims support based arguments evidence structured argument often multiple levels october claims work together provide justification rational acceptability truth claims evidence collection artefacts documentation provide evidential support claims made assurance case body evidence formed objective demonstrable repeatable information recorded production use system underpins arguments justifying assurance claims instances body evidence may organised evidence repository sacm primary information accessed along secondary information evidence management interpretation evidence clarification evidentiary support underlying claims assurance case advantages approaching explanation assurance cases several advantages using assurance organise documentation innovation practices explanations assurance cases demand proactive understanding impacts risks come specific application effective execution anchored building practical controls show impacts risks appropriately managed assurance cases encourage planned integration good governance controls turn ensures goals governing development systems met deliberate method documented assurance demonstrates assurance anticipatory governance documentation processes work mutually strengthening best practices improving quality products services support assurance involves method governance practice rather set instructions allows designers developers tackle diverse range governance activities single method using structured argument assure properties meet standard requirements mitigate risks also means procedures building assurance cases uniform documentation readily standardised automated seen instance various assurance platforms like gsn sacm cae argumentation assurance enable effective communication generate confidence given application possesses desired properties basis explicit grounds done effectively assurance cases clearly precisely convey information various stakeholder groups structured arguments demonstrate specified goals achieved risks mitigated providing documentary evidence properties system needed meet goals assured solid arguments using assurance methodology enable assurance cases customised tailored relevant audiences assurance cases built structured arguments claims justifications evidence natural language readily understood technical specialists detailed technical arguments evidence may support assurance cases basis cases everyday reasoning makes especially amenable understandable summary summary assurance case provided decision recipient backed detailed version includes extended structural arguments better tailored experts independent assessors auditors likewise evidence used assurance case october organised fit audience context explanation way potentially commercially sensitive privacy impinging information comprises part body evidence may held evidence repository made accessible limited audience internal external overseers assessors auditors governing procurement practices managing stakeholder expectations tailored assurance vendors customers developers assurance may provide reasonable way govern procurement practices mutually manage expectations vendor deliberate anticipatory approach system design demanded assurance better able assure justification evidence documentation crucial properties models interested acquiring offering assurance portfolio advance vendor able demonstrate products designed appropriate normative goals mind also able assure potential customers goals realised across development processes also allow pass part explanation affected parties would also allow procurers effectively assess whether assurance portfolio meets normative criteria innovation standards looking based organisational culture domain context application interests using assurance cases also enable independent assessment audit tasks information management sharing undertaken efficiently developers users assessors auditors provide common consolidated platform explanation organises presentation details assurance cases accessibility information supports streamline communication processes across affected stakeholders preserving aspects procedural organisational transparency way reading resources exploring documentation assurance general readings documentation responsible design implementation fact sheets datasheets datasets model cards model reporting auditing framework blog understanding artificial intelligence ethics safety october relevant standards regulations assurance safety cases systems software engineering systems software assurance part concepts vocabulary systems software engineering systems software assurance part assurance case systems software engineering systems software assurance part system integrity levels systems software engineering systems software assurance part assurance life cycle object management group structured assurance case metamodel sacm version beta march ministry defence defence standard issue reliability maintainability assurance guidance part case june ministry defence defence standard part requirements safety related software defence equipment part requirements december ministry defence defence standard part requirements safety related software defence equipment part guidance august ministry defence defence standard safety management requirements defence systems part requirements issue june ministry defence defence standard safety management requirements defence systems part guidance establishing means complying part issue june caa cap guidance conduct hazard identification risk assessment production safety cases aerodrome operators air traffic service providers january offshore installations safety case regulations control major accident hazards amendment regulations health safety executive safety assessment principles nuclear facilities hse railways guided transport systems safety regulations statutory instrument directive development community railways july background readings methods assurance ankrum kromholz structured assurance cases three common standards october ninth ieee international symposium systems engineering ashmore calinescu paterson assuring machine learning lifecycle desiderata methods challenges arxiv preprint barry certware workbench safety case production analysis aerospace conference ieee bloomfield netkachova building blocks assurance cases ieee international symposium software reliability engineering workshops ieee bloomfield bishop safety assurance cases past present possible adelard perspective making systems safer springer london cârlan barner diewald tsalidis voss explicitcase integrated development system safety cases international conference computer safety reliability security springer denney pai formal basis safety case patterns international conference computer safety reliability security springer denney pai habli dynamic safety cases safety assurance ieee international conference software engineering vol ieee denney pai tool support assurance case development automated software engineering despotou extending safety case concept address dependability proceedings international system safety conference gacek backes cofer slind whalen resolute assurance case language architecture models acm sigada ada letters rijo paige kelly mcdermid introducing goal structuring notation explain decisions clinical practice procedia technology gleirscher kugele assurance system safety survey design argument patterns arxiv preprint górski jarzębowicz miler witkowicz czyżnikiewicz jar supporting assurance argument services international conference computer safety reliability security springer berlin heidelberg habli kelly july balancing formal informal safety case arguments verisure verification assurance workshop colocated verification cav hawkins habli kolovos paige kelly weaving assurance case design approach ieee international symposium high assurance systems engineering ieee health foundation evidence using safety cases industry october kelly arguing safety systematic approach managing safety cases doctoral thesis university york department computer science kelly mcdermid safety case successful arguments ieee colloquium understanding patterns application system engineering london kelly systematic approach safety case management sae international kelly weaver goal structuring safety argument notation proceedings dependable systems networks workshop assurance cases maksimov fung kokaly chechik two decades assurance case tools survey international conference computer safety reliability security springer nemouchi foster gleirscher kelly mechanised assurance cases integrated formal methods isabelle arxiv preprint netkachova netkachov bloomfield tool support assurance case building blocks international conference computer safety reliability security springer picardi hawkins paterson habli september pattern arguing assurance machine learning medical diagnosis systems international conference computer safety reliability security springer picardi paterson hawkins calinescu habli assurance argument patterns processes machine learning systems proceedings workshop artificial intelligence safety ceur workshop proceedings rushby interpretation evaluation assurance cases comp science laboratory sri international tech strunk knight essential synthesis problem frames assurance cases expert systems october
