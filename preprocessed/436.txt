Privacy and Freedom of Expression in the Age of Artificial Intelligence1/29Privacy and Freedom of Expression In the Age of Artificial Intelligence April 2018 Privacy and Freedom of Expression in the Age of Artificial IntelligenceAbout Us ARTICLE 19 is a global human rights organisation , which works around the world to protect and promote the right to freedom of expression and information ( ‘ freedom of expression ’ ) . Established in 1987 , with its international office in London , ARTICLE 19 monitors threats to freedom of expression in different regions of the world , and develops long-term strategies to address them . ARTICLE 19 is actively engaged in promoting fair , accountable , and transparent Artificial Intelligence ( AI ) , and investigates the human rights impact of algorithmic decision making through policy engagement and research . Our work on AI and freedom of expression thus far includes a policy brief on algorithms and automated decision making , several submission to the AI and ethics initiative of the Institute of Electrical and Electronics Engineering ( IEEE ) , a recent submission to the UK House of Lords Select Committee on AI , co-chairing several working groups of the IEEE initiative , membership in the Partnership on AI ( PAI ) , and guidance on the development of AI for network management in the Internet Engineering Task Force ( IETF ) . Privacy International is a non-profit , non-governmental organisation based in London , dedicated to defending the right to privacy around the world . Established in 1990 , Privacy International undertakes research and investigations into government surveillance and data exploitation in the private sector with a focus on the technologies that enable these practices . To ensure universal respect for the right to privacy , Privacy International advocates for strong national , regional and international laws that protect privacy around the world . It has litigated or intervened in cases implicating the right to privacy in the courts of the United States , the UK , and Europe , including the European Court of Human Rights and the European Court of Justice . Our work on AI and privacy thus far includes a submission to the AI and ethics initiative of the Institute of Electrical and Electronics Engineering ( IEEE ) , a recent submission and oral evidence to the UK House of Lords Select Committee on AI , as well as several submissions on profiling and automated decision-making to the Article 29 Working Party - an advisory body made up of a representative from the data protection authority of each EU Member State , the European Data Protection Supervisor and the European Commission that is drafting guidance to the EU General Data Protection Regulation . Privacy and Freedom of Expression in the Age of Artificial Intelligence01/29Contents Executive Summary Introduction What is Artificial Intelligence ? AI and the Right to Freedom of Expression Establishing the Nexus Mapping the Landscape International Human Rights Law National Frameworks Technical Standards Self-Regulation By Companies Challenges AI and Privacy Establishing the Nexus Mapping the Landscape International Human Rights Law Data Protection Sectoral Privacy Regulation Ethical Codes and Industry Standards Challenges Conclusions and Recommendations 02 04 06 08 08 11 11 12 12 14 15 17 17 20 20 21 23 24 26 28 Privacy and Freedom of Expression in the Age of Artificial Intelligence02/29Executive Summary Artificial Intelligence ( AI ) is part of our daily lives . This technology shapes how people access information , interact with devices , share personal information , and even understand foreign languages . It also transforms how individuals and groups can be tracked and identified , and dramatically alters what kinds of information can be gleaned about people from their data . AI has the potential to revolutionise societies in positive ways . However , as with any scientific or technological advancement , there is a real risk that the use of new tools by states or corporations will have a negative impact on human rights . While AI impacts a plethora of rights , ARTICLE 19 and Privacy International are particularly concerned about the impact it will have on the right to privacy and the right to freedom of expression and information . This scoping paper focuses on applications of ‘ artificial narrow intelligence ’ : in particular , machine learning and its implications for human rights . The aim of the paper is fourfold : 1 . Present key technical definitions to clarify the debate ; 2 . Examine key ways in which AI impacts the right to freedom of expression and the right to privacy and outline key challenges ; 3. Review the current landscape of AI governance , including various existing legal , technical , and corporate frameworks and industry-led AI initiatives that are relevant to freedom of expression and privacy ; and 4 . Provide initial suggestions for rights-based solutions which can be pursued by civil society organisations and other stakeholders in AI advocacy activities . We believe that policy and technology responses in this area must : • Ensure protection of human rights , in particular the right to freedom of expression and the right to privacy ; • Ensure accountability and transparency of AI ; Privacy and Freedom of Expression in the Age of Artificial Intelligence03/29• Encourage governments to review the adequacy of any legal and policy frameworks , and regulations on AI with regard to the protection of freedom of expression and privacy ; • Be informed by a holistic understanding of the impact of the technology : case studies and empirical research on the impact of AI on human rights must be collected ; and • Be developed in collaboration with a broad range of stakeholders , including civil society and expert networks . Privacy and Freedom of Expression in the Age of Artificial Intelligence04/29Introduction Artificial Intelligence ( AI ) and its applications are a part of everyday life : from curating social media feeds to mediating traffic flow in cities , and from autonomous cars to connected consumer devices like smart assistants , spam filters , voice recognition systems and search engines . The sudden rise of these applications is recent , but the study and development of AI is over half a century old : the term was coined in 1956 , though the concept goes back even further , to the late 1700s . Current momentum is fuelled by the availability of large amounts of data , affordable and accessible computational power , continued development of statistical methods , and the fact that technology is now embedded into the fabric of society . We rely on it in more ways than most are even aware of.1 If implemented responsibly , AI can benefit society . However , as is the case with most emerging technology , there is a real risk that commercial and state use has a detrimental impact on human rights . In particular , applications of these technologies frequently rely on the generation , collection , processing , and sharing of large amounts of data , both about individual and collective behaviour . This data can be used to profile individuals and predict future behaviour . While some of these uses , like spam filters or suggested items for online shopping , may seem benign , others can have more serious repercussions and may even pose unprecedented threats to the right to privacy and the right to freedom of expression and information ( ‘ freedom of expression ’ ) .2 The use of AI can also impact the exercise of a number of other rights , including the right to an effective remedy , the right to a fair trial , and the right to freedom from discrimination . The threat posed by AI thus does not take the form of a super-intelligent machine dominating humanity : instead , core problems with AI can be found in its current everyday use.3 This scoping paper focuses on applications of ‘ artificial narrow intelligence ’ , in particular machine learning , and its implications for human rights . Cath , C. , Wachter , S. , Mittelstadt , B. et al. , ‘ Artificial Intelligence and the ‘ Good Society ’ : The US , EU , and UK Approach ’ , Science and Engineering Ethics , 2017 , p. 1 – 24 . See for example , V. Dodd , Met police to use facial recognition software at Notting Hill carnival , The Guardian , 5 August 2017 ; available from : https : //www.theguardian.com/uknews/2017/aug/05/met-police-facial-recognition-software-notting-hill-carnival . ARTICLE 19 , Submission to the House of Lords Select Committee on Artificial Intelligence , 6 September 2017 , available from : https : //www.article19.org/wp-content/uploads/2017/10/ARTICLE19-Evidence-to-the-House-of-Lords-Select-Committee-AI.pdf . 1 2 3 Privacy and Freedom of Expression in the Age of Artificial Intelligence05/29The right to freedom of expression and the right to privacy are mutually reinforcing – all the more so in the digital age.4 Privacy is a prerequisite to the exercise of freedom of expression : without it , individuals lack the space to think , speak and develop their voice . Without freedom of expression , individuals would be unable to develop their sense of self . Both of these rights are therefore essential foundations for open and democratic societies and among the basic conditions for progress , as well as for each individual ’ s self-fulfilment . For democracy , accountability and good governance to thrive , freedom of expression must be respected and protected . The same is true of the right to privacy , which is a powerful bulwark against state and corporate power . While many talk about the need to think carefully about the incorporation of AI applications in the ‘ safety-critical systems ’ of societies - like electricity grids and water supplies - it is important to re-centre the larger debate on the use of AI in ‘ human rights critical contexts ’ . It is imperative that policy makers , regulators , companies , civil society , and other stakeholders working on the right to privacy and freedom of expression understand the implications , risks and potential of AI . In this scoping paper , ARTICLE 19 and Privacy International aim to contribute to such understanding . First , we present key technical definitions to clarify the debate and examine key ways in which AI impacts the right to freedom of expression and the right to privacy , and we outline key challenges . We then review the current landscape of AI governance , including various existing legal , technical , and corporate frameworks and industry-led AI initiatives relevant to freedom of expression and privacy . Finally , we also provide initial suggestions for rights-based solutions which can be pursued by civil society organisations and other stakeholders in AI advocacy activities . ARTICLE 19 , The Global Principles on Protection of Freedom of Expression and Privacy , 2017 , available at http : //article19.shorthand.com/ . 4 Privacy and Freedom of Expression in the Age of Artificial Intelligence06/29What is Artificial Intelligence ? The term ‘ AI ’ is used to refer to a diverse range of applications and techniques , at different levels of complexity , autonomy and abstraction . This broad usage encompasses machine learning ( which makes inferences , predictions and decisions about individuals ) , domain-specific AI algorithms , fully autonomous and connected objects and even the futuristic idea of an AI ‘ singularity ’ . This lack of definitional clarity is a challenge : different types of AI systems raise specific ethical and regulatory issues . From a conceptual point of view , it is important to consider the following key concepts in AI related debates : G. Kasparov , Learning to Love Intelligent Machine , The Wall Street Journal , 14 April , 2017 , available from : https : //www.wsj.com/articles/learning-to-love-intelligent-machines-1492174086 . C. Metz , ‘ What the AI behind Alpha Go can teach us about being human ’ , Wired , 19 May , 2017 , available from : https : //www.wired.com/2016/05/google-alpha-go-ai/ . L. Floridi , Should we be afraid of AI ? , Aeon , 9 May 2016 , available from : https : //aeon.co/ essays/true-ai-is-both-logically-possible-and-utterly-implausible . T. Gillespie , The relevance of algorithms , Media technologies : Essays on communication , materiality , and society , MIT Press , 2014 , p. 167.5 6 7 8 Artificial narrow intelligence is the ability of machines to resemble human capabilities in narrow domains , with different degrees of technical sophistication and autonomy . Examples include : chatbots that assist by answering specific questions ; Deep Blue , a chess-playing computer developed by IBM which famously beat world chess champion Garry Kasparov in May 1997 ; 5 or the computer system which defeated the reigning master of the Chinese board game Go in May 2017 . 6 Artificial general intelligence is the overarching , and as yet unachieved , goal of a system that displays intelligence across multiple domains , with the ability to learn new skills , and which mimic or even surpass human intelligence . It is theorised that the creation of artificial general intelligence could lead to the ‘ singularity ’ , or a period of runaway technological growth that profoundly changes human civilisation . This is still , at the very least , decades away , if not entirely implausible . 7 Algorithm can refer to any instruction , such as computer code , that carries out a set of commands : this is essential to the way computers process data . For the purposes of this paper , it refers to ‘ encoded procedures for transforming input data into the desired output , based on specific calculations. ’ 8 Privacy and Freedom of Expression in the Age of Artificial Intelligence07/29 M. Perel & N. Elkin-Koren , Accountability in algorithmic copyright enforcement , Stanford Technology Law Review , 2016 . What degree of human involvement renders a decision automated is subject to debate : Article 22 of the European General Data Protection Regulation , for instance , merely covers automated decisions that are ‘ based solely ’ on automated processing , which leaves room for interpretation . The current draft guidelines by the Article 29 Working Party , for instance , argues that human intervention has to be meaningful and can not just be a token gesture . See Article 29 Data Protection Working Party , ( 2017 ) , Guidelines on Automated individual decision-making and Profiling for the purposes of Regulation 2016/679 . H. Surden , ‘ Machine Learning and the Law ’ , 89 Washington Law Review 87 , 2014 , p. 89-90 . A. Munoz , Machine Learning and Optimisation , New York University , available from : https : // cims.nyu.edu/~munoz/files/ml_optimization.pdf . N.G . Andrew , Machine Learning , Coursera , available from : https : //www.youtube.com/ watch ? v=PPLop4L2eGk & list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN . S.J . Russell and P. Norvig , Artificial Intelligence : A Modern Approach , Third Edition , Pearson , 2015 , p. 846 . 9 10 11 12 13 14 Automated decision-making ‘ generally involves large-scale collection of data by various sensors , data processing by algorithms and subsequently , automatic performance. ’ 9 It is an efficient means of managing , organising , and analysing large amounts of data , and structuring decision-making accordingly . It may or may not rely on AI , with varying degrees of human involvement.10 It can make decisions , or generate knowledge or information , that significantly shapes or influences the exercise of human rights . Machine learning is a popular technique in the field of AI which has gained prominence in recent years . It often uses algorithms trained with vast amounts of data to improve a system ’ s performance at a task over time.11 Tasks tend to involve making decisions or recognising patterns , with many possible outputs across a range of domains and applications . Arthur Samuel , who coined the term , referred to machine learning programs as those which have ‘ the ability to learn without being explicitly programmed. ’ 12 Many of the technologies commonly referred to as AI today are , strictly speaking , machine learning systems . Supervised , unsupervised , and reinforced learning Machine learning is usually classified into these three types . Supervised machine learning forms the majority of AI application today . It seeks to teach the computer to predict an output , assuming that the input data is labelled correctly . Supervised machine learning can either be used to predict a continuous valued output through regression , or a discrete valued output through classification.13 Unsupervised learning , on the other hand , depends on the computer program to find structure within data , based on particular features . Reinforced learning is the third type , wherein the program is placed in an environment and must learn how to behave successfully within that environment , based on feedback of successes and failures.14 Privacy and Freedom of Expression in the Age of Artificial Intelligence08/29AI and the Right to Freedom of Expression Establishing the Nexus AI will significantly impact the right to freedom of expression.15 It is applied in a vast number of situations that influence how individuals access and find information online . Increasingly , online intermediaries , such as social media platforms and search engines , use AI systems to control information that users engage with in opaque and inscrutable ways.16 While some uses , for instance spam filters or suggested items for online shopping , may seem harmless , others can have more serious repercussions . AI-powered surveillance presents one such serious repercussion . The pervasive and invisible nature of AI systems , coupled with their ability to identify and track behaviour , can have a significant chilling effect on the freedom of expression . This can take place through self-censorship , altered behaviour in public spaces and private communications alike . The rise of techniques such as video surveillance , facial recognition , behaviour analysis etc. , by public authorities and private companies hinder freedom of expression and also infringe the very essence of the right to privacy.17 Mass surveillance in particular is a disproportionate interference with privacy and the freedom of expression , while targeted surveillance may only be justified when it is prescribed by law , necessary to achieve a legitimate aim , and proportionate to the aim pursued.18 Moreover , the data generated and used by online intermediaries in AI systems is another concern . To leverage the affordances of AI , large amounts of data are generated and collected . This is worrying because datasets are often built through problematic methods of collection , leading them to hold biases that reflect existing patterns of societal stereotyping.19 Even when this is not the case , data samples can be unrepresentative of the population at large . In either situation , data can lead AI applications to negatively impact freedom of expression . L. Rainie & J. Anderson , Code-Dependent : Pros and Cons of the Algorithm Age , Pew Research Center , February 2017 , available from : http : //pewrsr.ch/2BpdxYx . J. Balkin , Free Speech in the Algorithmic Society : Big Data , Private Governance , and New School Speech Regulation , 2017 , available from : https : //papers.ssrn.com/sol3/papers . cfm ? abstract_id=3038939 . ARTICLE 19 , The Global Principles on Protection of Freedom of Expression and Privacy , op.cit . International Principles on the Application of Human Rights to Communications Surveillance ( “ Necessary and Proportionate Principles ” ) , available from : https : // necessaryandproportionate.org/principles . R. Calo , Artificial Intelligence Policy : A Primer and Roadmap , 2017 , available from : https : // ssrn.com/abstract=3015350 or http : //dx.doi.org/10.2139/ssrn.3015350 .15 16 17 18 19 Privacy and Freedom of Expression in the Age of Artificial Intelligence09/29 ARTICLE 19 , The Expression Agenda Report 2016-2017 , available from : https : //www.article19 . org/wp-content/uploads/2017/12/Expression-Agenda-Report-2017-for-web-_30.11.17.pdf . R. Brauneis & E. Goodman , Algorithmic Transparency for the Smart City , Yale Journal of Law & Technology , GWU Law School Public Law Research Paper , 2 August 2017 , available from : https : // papers.ssrn.com/sol3/papers.cfm ? abstract_id=3012499 . C. Cath et al. , Media Development in the Digital Age : Five Ways to Engage in Internet Governance , 2017 , available from : https : //www.cima.ned.org/publication/media-developmentdigital-age-five-ways-engage-internet-governance/ . 20 21 22 For example , if AI content moderation systems are not trained on slang or nonstandard use of certain expression often used by minority groups it can potentially lead these systems to censor legitimate speech . Beyond surveillance , it is difficult to provide a comprehensive overview of the ways in which AI impacts the right to freedom of expression : its effects are sector- and context-specific . AI raises different issues depending on its application , i.e . to online content moderation on social media platforms or to smart homes . At this stage , ARTICLE 19 considers the importance of AI through the lens of our five key global areas of work and highlights the following issues:20 Digital : Technology shapes how people exercise their right to freedom of expression , how they access information and how they interact online . AI impacts how individuals can access information and express themselves on the Internet , including through search engines and social media . It also impacts the fundamental technical functioning of the Internet itself with the increased use of AI in Internet networking . Technical standard setting bodies like the Institute for Electrical and Electronics Engineers ( IEEE ) are also currently in the process of developing standards for ethical and safe AI systems . Civic Space : Civic space is the physical and legal place where individuals realise their rights . This space is increasingly impacted by various AI applications , from newsfeed algorithms to connected devices in smart cities . Building on these applications , AI systems will soon shape decision-making systems and spaces where people and communities organise , associate and assemble , from homes to cities.21 Media : Media pluralism and media freedom are essential for protecting and promoting freedom of expression and the public interest in an increasingly globalised , digitised , and converging media landscape . There is a danger that a limited number of digital corporations will become the central conduit for media content online . This is particularly the case if companies use opaque AI systems that rank information , whether on news sites or by filtering email , according to indicators that often remain unknown to the users . 22 Transparency : Transparency and access to information - from both public and private bodies - are crucial in ensuring democratic governance . Increasingly , decisions on access to information , traditionally made by humans , are now driven by AI applications . These systems have the ability to selectively exclude Privacy and Freedom of Expression in the Age of Artificial Intelligence10/29 For example , recent studies show that AI has the potential to privilege advertisement of high paying jobs to men over advertisement to women . See , for example , M. Day , How LinkedIn ’ s Search Engine May Reflect a Gender Bias , The Seattle Times , 31 August 2016 , available from : https : //www.seattletimes.com/business/microsoft/how-linkedins-search-enginemay-reflect-a-bias/ . AI NOW , AI Now 2017 Report , 2017 , available from : https : //ainowinstitute.org/AI_Now_2017_ Report.pdf . See , J. Liu , ’ In your Face : China ’ s all-seeing state ’ , BBC , 10 December 2017 , available at http : //www.bbc.co.uk/news/av/world-asia-china-42248056/in-your-face-china-s-all-seeing-state . See also China ’ s CCTV surveillance network took just 7 minutes to capture BBC reporter , Tech Crunch , 13 December 2017 , available at https : //techcrunch.com/2017/12/13/china-cctv-bbcreporter/ . 23 24 25or emphasise critical information,23 and can enable governments to deploy AI systems without transparency.24 Protection : Those on the frontline of defending freedom of expression and information must be supported by a strong enabling legal framework for freedom of expression , effective mechanisms for protection of the right to freedom of expression , due process of law and active networks of institutions and activists . Various applications of AI are problematic , in particular for surveillance and censorship , or targeting those who exercise their freedom of expression in a manner that is controversial in the view of governments and other powerful institutions and corporations.25 Privacy and Freedom of Expression in the Age of Artificial Intelligence11/29Mapping the Landscape International Human Rights Law The right to freedom of expression is guaranteed in Article 19 of the Universal Declaration of Human Rights ( UDHR ) 26 and the International Covenant on Civil and Political Rights ( ICCPR ) ,27 as well as in regional human rights treaties . 28 While the right to freedom of expression is a fundamental right , it is not guaranteed in absolute terms . Under international standards , in particular Article 19 para 3 of the ICCPR , restrictions on the right to freedom of expression must be strictly and narrowly tailored and may not put the right itself in jeopardy . The method of determining whether a restriction is narrowly tailored is often articulated as a three-part test . Restrictions must : ( i ) be provided by law ; ( ii ) pursue a legitimate aim ; and ( iii ) conform to the strict tests of necessity and proportionality . 29 There are no international standards that would explicitly deal with AI and the right to freedom of expression . However , there is a body of international standards which are relevant to the use of AI , particularly in relation to online intermediaries.30 For instance , states should not impose a general obligation on intermediaries to monitor the information that they transmit , store , automate or otherwise use,31 and users should have the opportunity to challenge the blocking and filtering of content.32 At the regional level , some aspects of AI applications have been addressed in the European Union ’ s new General Data Protection Regulation ( GDPR ) , although the G.A . Res . 217 ( III ) A , UDHR , art . 19 ( Dec. 10 , 1948 ) . Article 19 of the UDHR states : “ Everyone has the right to freedom of opinion and expression ; this right includes freedom to hold opinions without interference and to seek , receive and impart information and ideas through any media and regardless of frontiers. ” For interpretation of Article 19 of the ICCPR , see General Comment No 34 , CCPR/C/GC/3 . Article 9 of the African Charter on Human and Peoples ’ Rights , Article 13 of the American Convention on Human Rights , Article 10 of the European Convention on Human Rights and Article 11 of the EU Charter on Fundamental Rights . General Comment No 34 , CCPR/C/GC/3 , para . 21 , 22 . See , in particular Report of the Special Rapporteur to the Human Rights Council on the promotion and protection of the right to freedom of opinion and expression , May 16 2011 , para 47 , available from : http : //www2.ohchr.org/english/bodies/hrcouncil/docs/17session/A . HRC.17.27_en.pdf ; Regulation ( EU ) 2016/679 , 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data , and repealing Directive 95/46/EC ( General Data Protection Regulation ) , 2016 O.J . ( L 119 ) 1 . Directive 2000/31/EC June 8 , 2000 on certain legal aspects of information society services , in particular electronic commerce , in the Internal Market ( E-Commerce Directive ) . Recommendation CM/Rec ( 2008 ) 6 of the Committee of Ministers to Member states on measures to promote and respect for freedom of expression and information with regard to internet filters , s1 . 26 27 28 29 30 31 32 Privacy and Freedom of Expression in the Age of Artificial Intelligence12/29details of its bearing on the right to access to information and expression remain up for discussion . We analyse this discussion33 in detail at a later stage in this paper . National Frameworks At national levels , existing AI applications are regulated by traditional frameworks of legislation including freedom of expression , data protection , consumer protection , media and competition law , along with sectoral regulations and standards . While these frameworks cover some aspects of AI application , the question remains whether these laws are adequate to address the myriad ways in which AI will impact freedom of expression . In response to some of the specific questions raised by the use of AI systems , some countries like Japan 34 and Germany 35 have developed new frameworks applicable to specific AI issues . These exhibit an increasing tendency of governments to publish non-binding guidelines and ethical frameworks for AI , and even create advisory networks on ethics and AI.36 Going forward , governments must grapple with how existing laws can be applied to AI , and also identify the areas , sectors , and use cases where specific regulation is necessary . While proposals for national AI regulators are being made by experts in various jurisdictions,37 these have not yet been adopted.38 Technical Standards Recognition that human rights should form the basis of technical standards and protocols and the role such standards and protocols play in the exercise of human Japan ’ s Ministry of Economy , Trade and Industry , Japan ’ s Robot Strategy was compiled ’ , 23 January 2015 , available from : http : //www.meti.go.jp/english/press/2015/0123_01.html . Also see Japan ’ s Robot Policy and the Special Zone for Regulating Next Generation Robots , Robolaw Asia , available from : https : //pkurobotlaw.wordpress.com/2015/06/22/japans-robot-policy-andthe-special-zone-for-regulating-next-generation-robots . B. Bergan , Germany Drafts World ’ s First Ethical Guidelines for Self-Driving Cars , Futurism , 25 August 2017 , available from : https : //futurism.com/germany-drafts-worlds-first-ethicalguidelines-for-self-driving-cars/ . L. Kelion , UK PM Seeks ‘ safe and ethical ’ artificial intelligence , BBC , 24 January 2018 , available from : http : //www.bbc.co.uk/news/technology-42810678 . See , for example : I . Sample , AI watchdog needed to regulate automated decision making , say experts , The Guardian , 27 January 2017 . Also see similar calls in the US : R. Calo , The case for a Federal Robotics Commission , Brookings Institution Center for Technology Innovation , 1 September 2014 , available from : https : //ssrn.com/abstract=2529151 ; O. Bracha and F. Pasquale , Federal Search Commission ? Access , Fairness , and Accountability in the Law of Search , 93 Cornell L. Rev . 1149 , 2008 , available from : http : //scholarship.law.cornell.edu/ clr/vol93/iss6/11 . Most recently , in the United Kingdom . M. Burgess , The Government ’ s Report on AI Doesn ’ t Recommend Regulating It , Wired , 14 October 2017 , available from : http : //www.wired.co.uk/ article/ai-report-uk-government-money . 34 35 36 37 38 Privacy and Freedom of Expression in the Age of Artificial Intelligence13/29rights is increasingly commonplace.39 However , it is yet to be seen what this concretely means for AI . Despite this increased recognition , human rights are not explicitly referred to in the policy processes of many technical or business organisations . These actors are fast becoming the gateways to and facilitators of the exercise of freedom of expression , since they develop the majority of AI systems . In response to the ethical and legal questions posed by AI , various industry initiatives have been started . The two most prominent are : It is commendable that these initiatives are putting effort and resources into facilitating a cross-disciplinary and , at times , multi-stakeholder discussion . Ethical codes and industry standards can be an important compliance tool40 , or help organisations to go beyond compliance . It is also crucial to ensure that the technical standards and sector guidelines meet international human rights standards on freedom of expression , are accountable , and subject to public scrutiny . However , without strong institutional backing , these codes can not function effectively , and can even be counterproductive.41 In all of these , it is crucial to recognise that human rights should be the floor and not the ceiling , and that a number of established minimum principles can serve as guidance.42Global Initiative on Ethics of Autonomous and Intelligent Systems of the Institute of Electrical and Electronics Engineers ( IEEE ) . This initiative focuses on developing technical standards that embed ethics in AI systems . The initiative also aims to raise awareness in the AI community about the importance of prioritising ethical considerations in the development of technology . The Partnership on Artificial Intelligence to Benefit People and Society , originally established by Microsoft , Google , Amazon , Facebook , and IBM to ‘ study and formulate best practices on AI technologies , to advance the public ’ s understanding of AI , and to serve as an open platform for discussion and engagement about AI and its influences on people and society. ’ UN Special rapporteur on freedom of expression , Report to the Human Rights Council on Freedom of expression , states and the private sector in the digital age , 2013 , available from : http : //www.ohchr.org/EN/Issues/FreedomOpinion/Pages/Privatesectorinthedigitalage.aspx . UK Information Commissioner , Discussion paper Big Data , artificial intelligence , machine learning and data protection , available from : https : //ico.org.uk/media/for-organisations/ documents/2013559/big-data-ai-ml-and-data-protection.pdf . P. Boddington , Towards a Code of Ethics for Artificial Intelligence , Springer International Publishing , 2017 . See , the Guiding Principles on Business and Human Rights ; the Global Network Initiative Principles on Freedom of Expression and Privacy ; the European Commission ’ s ICT Sector Guide on Implementing the UN Guiding Principles on Business and Human Rights ; and the Telecommunications Industry Dialogue Guiding Principles . These encourage corporations to commit to protect human rights , undertake due diligence to ensure the positive human rights impact of their work and remediate adverse impacts of their work on human rights . 39 40 41 42 Privacy and Freedom of Expression in the Age of Artificial Intelligence14/29Self-Regulation By Companies At the level of individual companies , the likely impact of AI on freedom of expression can be understood by scrutinising their Terms of Service . Research indicates that companies increasingly rely on AI systems in enforcement of their Terms of Service : for instance , platforms currently deploy automated filtering and blocking in response to ‘ violent extremism ’ online.43 Growing pressure placed on companies by governments to police ‘ harmful ’ or illegal content could lead to the development of more sophisticated systems , capable of identifying and removing vast amounts of content with limited , or no , human intervention . This pressure also incentivises companies to err on the side of caution when it comes to content on their platforms , meaning that their limitations and restrictions on freedom of expression ( in particular in the case of social media platforms and electronic payment systems44 ) are sometimes outside the scope of internationallyrecognised legitimate limitations on freedom of expression.45 For fear of content removal , content-creators themselves then err on the side of caution in their expression , self-censoring and creating a ‘ chilling effect ’ on freedom of expression.46 The lack of transparency about AI systems used by companies is a problem in this context . This is compounded by the lack of clear complaint mechanisms to deal with inappropriate or overzealous removal of content . Users ’ ability to challenge these decisions before domestic courts is also extremely limited , which significantly undermines the right of affected parties to seek remedy.47 See , for example , S. Frenkel , Inside the Obama Administration ’ s Attempt to Bring Tech Companies into the Fight Against ISIS , BuzzFeed , 26 February 2016 , available from : https : // www.buzzfeed.com/sheerafrenkel/inside-the-obama-administrations-attempt-to-bring-techcompa ? utm_term=.eoN44ER6aM # .xoaJJExkQ8 . Also note , removals involve human interaction at various levels . For example , take-down requests originate from public scrutiny , whereas filtering systems are largely automated with human input only at the final stages of review . See , for example , EFF , Free Speech Coalition Calls on PayPal to Back Off Misguided Book Censorship Policy , March 2012 , available from : https : //www.eff.org/deeplinks/2012/03/freespeech-coalition-callspaypal-back-misguided-book-censorship-policy ; or PayPal Rains On Regretsy ’ s Secret Santa Campaign Over Use Of Wrong Button , Consumerist , December 2011 . For example , see , K.M . Hovland & D. Seetharaman , Facebook Backs Down on Censoring ‘ Napalm Girl ’ Photo , The Wall Street Journal , 9 September 2016 , available from : https : //www.wsj.com/ articles/norway-accuses-facebook-of-censorship-over-deleted-photo-of-napalm-girl-1473428032 . ARTICLE 19 , Internet Intermediaries : Dilemma of Liability , available at https : //www . article19.org/data/files/Intermediaries_ENGLISH.pdf . In particular , the legal basis for any court challenge is contract law , where the standard is generally the lack of fairness of contractual terms , i.e . a very high threshold for consumers . Moreover , social media platforms Terms of Use usually contain jurisdiction clauses forcing users to use the courts in California rather than the courts of their place of residence . 43 44 45 46 47 Privacy and Freedom of Expression in the Age of Artificial Intelligence15/29Challenges While we resist the tendency to construe AI as fundamentally different from preceding technologies , which have been at the forefront of policy debates in recent years , there are a number of unique challenges that AI poses for freedom of expression . They can be classified as follows : Lack of respect for the rule of law : Current industry initiatives around AI are narrowly focused on the development of technical standards , ethical frameworks , and concepts such as fairness , transparency , and accountability . However , these frameworks must be enforceable and comply with the rule of law . A great deal of the work currently undertaken in this area lacks such enforcement mechanisms , whether self-imposed or through voluntary regulation , limiting impact . Lack of transparency : Many companies developing critical AI systems do so in ways that are non-transparent and inscrutable . As most of AI is developed or owned by industry , critically engaging with the freedom of expression impact of these technologies is increasingly difficult for civil society actors because of trade secrets rules and high barriers to transparency around application and development , as well as the inherent complexity of these systems . Lack of accountability : The hidden nature of AI systems makes it difficult to study or analyse the impact of AI on the right to freedom of expression unless a tangible harm occurs . For example , profiling people who take part in protests will become increasingly easy , even if they cover their faces . It is not always clear when machine learning algorithms are being used , so harms arising out of the use of AI are hard to detect . Even when a potential harm is found , it can be difficult to ensure accountability for violations of those responsible . Public perception and the role of the media : Much of the popular discourse around AI focuses on the dangers of AI general intelligence instead of on current , practical , and realistic implications of AI systems . This discourse has a real impact . It misdirects attention and funding away from current problems surrounding freedom of expression and privacy to favour hypothetical dystopian scenarios . The media has a role to play in ensuring that coverage of AI is focused on the issues at hand . Data collection and use : Various freedom of expression concerns stem from the way data is collected and used in AI systems . Understanding how data use In particular , the legal basis for any court challenge is contract law , where the standard is generally the lack of fairness of contractual terms , i.e . a very high threshold for consumers . Moreover , social media platforms Terms of Use usually contain jurisdiction clauses forcing users to use the courts in California rather than the courts of their place of residence . S. Walker , Face recognition app taking Russia by storm may bring end to public anonymity , The Guardian , 17 May 2016 , available from : https : //www.theguardian.com/technology/2016/ may/17/findface-face-recognition-app-end-public-anonymity-vkontakte . 47 48 Privacy and Freedom of Expression in the Age of Artificial Intelligence16/29and quality influences AI systems is particularly pertinent to front-line defenders of human rights , and vulnerable or minority communities that will be under- or misrepresented in datasets.49 J. Angwin , et al. , Machine Bias , ProPublica , 23 May 2016 , available at https : //www . propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing . 49 Privacy and Freedom of Expression in the Age of Artificial Intelligence17/29AI and Privacy Establishing the Nexus The privacy implications of AI stem from its ability to recognise patterns and increasingly ‘ derive the intimate from the available ’ .50 This ability relies on the processing of vast amounts of data . Different applications and uses of AI can affect the right to privacy in different ways : Each of these novel interferences with privacy are significant : privacy is indispensable for the exercise of a range of human rights , such as freedom of expression , freedom of association , as well as being fundamental for the exercise of personal autonomy and freedom of choice,51 as well as broader societal norms.52 J. Angwin , et al. , Machine Bias , ProPublica , 23 May 2016 , available at https : //www . propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing . Calo , Artificial Intelligence Policy , op.cit . T. Payton and T. Claypoole , Privacy in the age of Big data : Recognizing threats , defending your rights , and protecting your family , Rowman & Littlefield , 2014 . R.C.Post , . , ‘ The social foundations of privacy : Community and self in the common law tort ’ , California Law Review , 1989 , pp . 957-1010 . Summarizing Post see T. Doyle , 2012 ; D. J. Solove , Nothing to Hide : The False Tradeoff between Privacy and Security , Yale University Press , 2011 : ‘ As the legal theorist Robert Post has argued , privacy is not merely a set of restraints on society ’ s rules and norms . Instead , privacy constitutes a society ’ s attempt to promote civility . Society protects privacy as a means of enforcing order in the community . Privacy isn ’ t the trumpeting of the individual against society ’ s interests but the protection of the individual based on society ’ s own norms and values. ’ 49 50 51 52 AI-driven consumer products and autonomous systems are frequently equipped with sensors that generate and collect vast amounts of data without the knowledge or consent of those in its proximity ; AI methods are being used to identify people who wish to remain anonymous ; AI methods are being used to infer and generate sensitive information about people from their non-sensitive data ; AI methods are being used to profile people based upon population-scale data ; and AI methods are being used to make consequential decisions using this data , some of which profoundly affect people ’ s lives . Privacy and Freedom of Expression in the Age of Artificial Intelligence18/29 A 2015 study by researchers at the French Institute for Research in Computer Science showed that 75 % of mobile phone users can be re-identified within a dataset using machine learning methods and just two smartphone apps , with the probability rising to 95 % if four apps are used . See J.P. Achara , ,G . Acs , and C. Castelluccia , ‘ On the unicity of smartphone applications ’ at the 14th ACM Workshop on Privacy in the Electronic Society , October 2015 , pp . 27-36 , available at https : //arxiv.org/pdf/1507.07851v2.pdf . Walker , ‘ Face recognition app ’ , op.cit . Electronic Privacy Information Center ( EPIC ) and 45 organisations , Letter to Senators Grassley and Leahy and Representatives Goodlatte , Chaffetz , Conyers , and Cummings regarding the FBI ’ s Use of Facial Recognition and Proposal to Exempt the Bureau ’ s Next Generation Identification Database from Privacy Act Obligations , 2016 , available from : https : //epic . org/privacy/fbi/NGI-Congressional-Oversight-Letter.pdf . C. Epp , M. Lippold & R.L . Mandryk , Identifying emotional states using keystroke dynamics ’ in Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. , May 2011 , pp . 715-724 , available from http : //hci.usask.ca/uploads/203-p715-epp.pdf . 53 54 55 56Data exploitation : Consumer products , from smart home appliances to connected cars and phone applications , are often built for data exploitation . Consumers are commonly faced with an informational asymmetry as to what kinds and how much data their devices , networks , and platforms generate , process , or share . As we bring ever-more smart and connected devices into our homes , workplaces , public spaces , and even our bodies , educating the public about such data exploitation becomes increasingly pressing . Identification and tracking : AI applications can be used to identify and thereby track individuals across different devices , in their homes , at work , and in public spaces . For example , while personal data is routinely ( pseudo- ) anonymised within datasets , AI can be employed to de-anonymise this data , challenging the distinction between personal and non-personal data , on which current data protection regulation is based.53 Facial recognition is another means by which individuals can be tracked and identified , which has the potential to transform expectations of anonymity in public space . Machine learning systems have even been able to identify around 69 % of protesters wearing caps and scarves to cover their faces.54 In the context of law enforcement , facial recognition can allow the police to identify individuals without probable cause , reasonable suspicion , or any other legal standard that might otherwise be required for law enforcement to obtain identification by traditional means.55 Inference and prediction of information : Using machine learning methods , highly sensitive information can be inferred or predicted from non-sensitive forms of data . People ’ s emotional states e.g . confidence , nervousness , sadness , and tiredness , can be predicted from typing patterns on a computer keyboard.56 When sensitive personal data , such as information about health , sexuality , ethnicity , or political beliefs can be predicted from unrelated data ( i.e . activity logs , phone metrics , location data or social media likes ) such profiling poses significant challenges to privacy and may result in discrimination . Privacy and Freedom of Expression in the Age of Artificial Intelligence19/29 P. Tucker , Refugee or Terrorist ? IBM thinks its software has the answer , Defense One , 27 January 2016 , available at http : //www.defenseone.com/technology/2016/01/refugee-or-terroristibm-thinks-its-software-has-answer/125484/ . Privacy International , ‘ Smart Cities : Utopian Vision , Dystopian Reality ’ , October 2017 , available at https : //privacyinternational.org/sites/default/files/2017-12/Smart % 20CitiesUtopian % 20Vision % 2C % 20Dystopian % 20Reality.pdf . 57 58 Profiling to sort , score , categorise , assess and rank individuals and groups : AI-driven applications are used to automatically sort , score , categorise , assess and rank people , often without their knowledge or consent , and frequently without the ability to challenge the outcomes or effectiveness of those processes . In 2016 , for instance , IBM promoted the use of AI to separate ‘ genuine ’ refugees from other types of migrants.57 Machine learning also plays a growing role in scoring systems which shape access to credit , employment , housing or social services . Decision-making : AI systems can be used to make or inform decisions about people or their environments , potentially based on profiling . An environment that knows your preferences and adapts itself according to presumed interests raises important issues around privacy , autonomy and the ethics of such adaptations . Personalisation , not only of information but also of our perception of the world , will become increasingly important as we move towards connected spaces like smart cities58 or augmented and virtual reality ( AR and VR ) . Privacy and Freedom of Expression in the Age of Artificial Intelligence20/29Mapping the Landscape Policy debates around AI and privacy are complicated by the fact that regulatory and policy discourses use the term to refer to a broad range of applications , usages and methods . Where AI is discussed in such a broad way , there is a tendency to assume that the technology poses challenges that are so radically new that all existing laws , regulations and standards are no longer applicable or appropriate . The ‘ flipside ’ of that discourse is to demand regulation of the technology itself , regardless of how and where it is applied . To avoid succumbing to any of these fallacies , there is a need to examine how existing discourses , such as human rights law , data protection , sectoral privacy regulation , and research ethics , relate to different applications and methods of AI . Below , we explain how several of these existing frameworks apply and where they fall short . We also discuss various AI-specific initiatives which have an explicit privacy focus , some of which are sectoral , others are more general . International Human Rights Law International human rights law recognises the fundamental right to privacy . Article 12 of the Universal Declaration of Human Rights ( UDHR ) , for instance , proclaims that “ [ n ] o one shall be subjected to arbitrary interference with his privacy , family , home or correspondence … . Everyone has the right to the protection of the law against such interference or attacks. ” 59 International human rights law requires that any interference with the right to privacy must not only be in accordance with law60 but must also be necessary and proportionate.61 To the extent that states develop or use AI in a manner that interferes G.A . Res . 217 ( III ) A , UDHR , art . 12 ( Dec. 10 , 1948 ) See Article 17 ( 1 ) , ICCPR ; Article 11 , ACHR ( “ 2 . No one may be the object of arbitrary or abusive interference with his private life , his family , his home , or his correspondence .. 3 . Everyone has the right to the protection of the law against such interference . . . . ” ) ; Article 8 ( 2 ) of the European Convention of Human Rights ( “ ECHR ” ) ( “ There shall be no interference by a public authority with the exercise of [ the right to respect for private and family life ] except such as is in accordance with the law … ” ) ; see also U.N. Human Rights Committee , General Comment No . 16 ( Article 17 ICCPR ) , 8 Apr . 1988 , para 3 , available at http : //tbinternet.ohchr.org/Treaties/CCPR/Shared % 20Documents/1_Global/INT_CCPR_GEC_6624_E . doc ( noting that “ [ t ] he term ‘ unlawful ’ means that no interference can take place except in cases envisaged by the law ” and that “ [ i ] nterference authorized by States can only take place on the basis of law , which itself must comply with the provisions , aims and objectives of the Covenant ” ) ; Principle 1 , International Principles on the Application of Human Rights to Communications Surveillance ( “ Necessary and Proportionate Principles ” ) , available at https : //necessaryandproportionate.org/principles . The Necessary and Proportionate Principles apply international human rights law to modern digital surveillance . They were drafted in 2013 by an international coalition of civil society , privacy and technology experts and have been endorsed by over 600 organizations around the world.59 60 Privacy and Freedom of Expression in the Age of Artificial Intelligence21/29 See U.N. Human Rights Committee , Toonen v. Australia , Comm . No . 488/1992 , U.N. Doc . CCPR/C/50/D/488/1992 ( 31 Mar . 1994 ) , para . 8.3 ( “ [ A ] ny interference with privacy must be proportional to the end sought and be necessary in the circumstances of any given case. ” ) ; Office of the U.N. High Commissioner for Human Rights , The Right to Privacy in the Digital Age , U.N. Doc . A/HRC/27/37 ( 30 June 2014 ) , para . 23 , available at https : //documents-dds-ny . un.org/doc/UNDOC/GEN/G14/088/54/PDF/G1408854.pdf ? OpenElement ( “ These authoritative sources [ HRC General Comments 16 , 27 , 29 , 31 , and 34 and the Siracusa Principles ] point to the overarching principles of legality , necessity and proportionality ... . ” ) ; U.N. Human Rights Council Resolution on the Right to Privacy in the Digital Age U.N. Doc . A/HRC/34/7 , 23 Mar . 2017 , para . 2 available at https : //documents-ddsny.un.org/doc/UNDOC/GEN/G17/086/31/ PDF/G1708631.pdf ? OpenElement ( “ Recall [ ing ] that States should ensure that any interference with the right to privacy is consistent with the principles of legality , necessity and proportionality ” ) . U.N. Human Rights Council Resolution on the Right to Privacy in the Digital Age , U.N. Doc . A/HRC/34/L,7 , 23 Mar . 2017 , para 2 . Office of the U.N. High Commissioner for Human Rights , Report on encryption , anonymity , and the human rights framework , U.N. Doc . A/HRC/29/32 ( 22 May 2015 ) , available at http : //www . ohchr.org/EN/Issues/FreedomOpinion/Pages/CallForSubmission.aspx .61 62 63 with the right to privacy , that use must be subject to the three-part test of legality , necessity and proportionality . International human rights law requires that any interference with the right to privacy must not only be in accordance with law60 but must also be necessary and proportionate.61 To the extent that states develop or use AI in a manner that interferes with the right to privacy , that use must be subject to the three-part test of legality , necessity and proportionality . Advocates and authorities using the international human rights framework are increasingly recognising and acknowledging the impact that new forms of dataprocessing have on fundamental rights , including the right to privacy . With respect to profiling , for example , which may involve the use of AI methods to derive , infer or predict information about individuals for the purpose of evaluating or assessing some aspect about them , the United Nations Human Rights Council noted with concern in March 2017 that ‘ automatic processing of personal data for individual profiling may lead to discrimination or decisions that otherwise have the potential to affect the enjoyment of human rights , including economic , social and cultural rights. ’ 62 International human rights authorities have also moved towards recognising a right to anonymity under the rights to privacy and freedom of opinion and expression . This has implications for AI used to identify individuals online , in their homes and in public spaces . The UN Special Rapporteur on Freedom of Expression , for instance , has repeatedly identified this relationship and emphasised that state interference with anonymity should be subject to the three-part test of legality , necessity , and proportionality , as is any other interference with these rights.63 Data Protection Data protection frameworks apply to research , development and application of AI to Privacy and Freedom of Expression in the Age of Artificial Intelligence22/29 See for instance UK Information Commissioner , Discussion paper Big Data , artificial intelligence , machine learning and data protection , available at https : //ico.org.uk/media/ for-organisations/documents/2013559/big-data-ai-ml-and-data-protection.pdf or the European Data Protection Supervisor ( EDPS ) ’ s Room Document for the 38th International Conference of Data Protection and Privacy Commissioners , Artificial Intelligence , Robotics , Privacy , and Data Protection , available at https : //edps.europa.eu/sites/edp/files/publication/16-10-19_ marrakesh_ai_paper_en.pdf . Article 5 of the General Data Protection Regulation ( GDPR ) - ( Regulation ( EU ) 2016/679 . Articles 13 , 14 and 22 of GDPR . Article 22 of GDPR only applies to decisions “ based solely on automated processing , including profiling , which produces legal effects concerning him or her or similarly significantly affects him or her ” . Article 25 GDPR . Article 4 ( 4 ) GDPR . See , for example , R. Binns , ‘ Data protection impact assessments : a meta-regulatory approach ’ International Data Privacy Law , 7 ( 1 ) , 2017 , pp 22-35 ; L. Edwards , & M. Veale , ‘ Enslaving the Algorithm : From a ‘ Right to an Explanation ’ to a ‘ Right to Better Decisions ’ ? ’ , IEEE Security & Privacy , 2017.64 65 66 67 68 69 70the extent that personal data ( as defined in the frameworks ) is involved.64 Thus , even without explicit reference to AI , data protection frameworks already regulate how AI systems can process personal data . Regulatory frameworks around the world are diverse , but are all designed to protect individuals ’ data and reflect a sense that such protections are an important aspect of the right to privacy . The EU General Data Protection Regulation ( GDPR ) , which takes effect on 25 May 2018 , requires a legal basis for processing data - and in addition to the principles of fairness , accountability and transparency , includes the core principles of purpose limitation and data minimisation,65 which have implications for the development , use and application of AI systems . The GDPR also limits the use of automated decision-making in certain circumstances , and requires individuals to be provided with information as to the existence of automated decision-making , the logic involved and the significance and envisaged consequences of the processing for the individual.66 The law introduces an overall prohibition ( with narrow exceptions ) to solely automated decisions when such decisions have legal or other significant effects.67 Notably , the GDPR also defines profiling as the automated processing of data to analyse or to make predictions about individuals.68 This definition recognises that personal data can be produced by machine learning applications and other forms of profiling.69 Finally , the GDPR introduces a range of provisions which encourage the design of less privacy-invasive systems , some of which have far reaching consequences for AI . The obligation to incorporate data protection by design and by default seeks to integrate data protection principles into the design of data processing operations.70 Data Privacy Impact Assessments ( DPIA ) - tools for organisations to manage privacy risks - will be mandatory for many privacy-invasive AI and machine learning Privacy and Freedom of Expression in the Age of Artificial Intelligence23/29applications that fall within the scope of data protection law and come with substantial anticipated risks , such as the processing of sensitive data . Data protection plays a crucial role in safeguarding the right to privacy71 but can not address all privacy risks that arise from different applications and uses of AI . Data protection is limited to the protection of data that relates to an identified or identifiable person ( even indirectly ) . That does not cover the privacy of groups , or other infringements on privacy that do not necessarily involve personal data.73 While provisions like those in the GDPR that deal with profiling and automated decision-making are crucial , they will only affect some uses of AI in automated decision-making74 or profiling.75 Additionally , data protection frameworks also frequently have exemptions for national security , limiting rights and safeguards in crucial privacy-invasive applications of AI , e.g . government surveillance . Sectoral Privacy Regulation In countries with data protection frameworks , sectoral privacy regulation complements data protection . The proposed ePrivacy Regulation in the EU , for instance , covers the privacy and confidentiality of communications and , as such , has implications for AI-driven consumer products , such as digital assistants . French administrative law gives a right to an explanation for administrative algorithmic decisions made about individuals.76 This provision is broader and more comprehensive than GDPR provisions on automated decision-making but only applies to administrative decisions.77 Sectoral privacy regulation also plays an important role in jurisdictions which do not have a general data protection framework , such as the United States , where all applications of AI have to comply with existing laws like the US Health Insurance Portability and Accountability Act of 1996 ( HIPPA ) .78 The city of New York introduced legislation which will establish a taskforce to examine the city ’ s ‘ automated decision systems ’ in order to make them fairer and more open to scrutiny . This will apply to In 2011 , the U.N. Special Rapporteur on the Promotion and Protection of the Right to Freedom of Opinion and Expression issued a report similarly noting that ‘ the protection of personal data represents a special form of respect for the right to privacy. ’ U.N. Doc . A/HRC/17/27 , ¶ 58 ( May 16 , 2011 ) . On the difficulty of data protection laws to protection groups see Taylor , L. , Floridi , L. , & van der Sloot , B . ( Eds . ) , Group privacy : New challenges of data technologies , vol . 126 , 2016 , Springer . An example would be automated lip reading systems if applied to images of people in public or a crowd . See Veale , M. , Edwards , L. , Bear , H. ( draft , Jan 2018 for PLSC Europe ) . Better seen and not ( over ) heard ? Automated lipreading systems and privacy in public spaces . F.Kaltheuner , & E. Bietti , ‘ Data is power : Towards additional guidance on profiling and automated decision-making in the GDPR ’ , Journal of Information Rights , Policy and Practice , vol 2 ( 2 ) , 2018 . See for instance Hildebrandt , M. and Koops , B.J. , ‘ The challenges of ambient law and legal protection in the profiling era ’ , The Modern Law Review , 73 ( 3 ) , 2010 , pp.428-460 . Loi pour une République numérique ( Digital Republic Act , Loi n 2016-132 ) . Edwards & Veale , ‘ Enslaving the Algorithm ’ , op.cit.71 72 73 74 75 76 77 78 Privacy and Freedom of Expression in the Age of Artificial Intelligence24/29 M. Hurley , & J. Adebayo , ‘ Credit Scoring in the Era of Big Data ’ , Yale JL & Tech. , 18 , 2016 , p. 148 . Permitted business models that avail themselves of the data that are generated by automated and connected driving and that are significant or insignificant to vehicle control come up against their limitations in the autonomy and data sovereignty of road users . It is the vehicle keepers and vehicle users who decide whether their vehicle data that are generated are to be forwarded and used . The voluntary nature of such data disclosure presupposes the existence of serious alternatives and practicability . Action should be taken at an early stage to counter a normative force of the factual , such as that prevailing in the case of data access by the operators of search engines or social networks. ’ See Federal Ministry of Transport and Digital Infrastructure , Ethics Commission , Automated and Connected Driving , June 2017 , available at https : //www.bmvi.de/SharedDocs/EN/Documents/G/ethic-commissionreport.pdf ? __blob=publicationFile .79 80computerised algorithms which guide the allocation of everything from police officers and firehouses to public housing and food stamps . Sectoral regulation can also play an important role in addressing more context- and domain-specific challenges of AI , for instance autonomous cars . However , not all existing sectoral privacy regulations are effective in protecting people from the new threats to privacy posed by AI applications . Many alternative credit-assessment tools that rely on machine learning methods for scoring , for instance , have been able to avoid coverage under the US Fair Credit Reporting Act ( FCRA ) .79 AI can undermine the effectiveness of purely sectoral regulation data . For instance , even strong regulation of medical records typically does not address the fact that health data can be derived , inferred or predicted from browsing histories or credit card data . Ethical Codes and Industry Standards Industry initiatives , standards bodies , and governments are currently developing ethical codes on AI , some of which are general , others sectoral . The Global Initiative on Ethics of Autonomous and Intelligent Systems of the IEEE , for instance , has dedicated a section relevant to privacy on ‘ Personal Data and Individual Access Control in Ethically Aligned Design ’ . The German Ethics Code for Automated and Connected Driving is an example of a sectoral ethic code that also contains a specific principle on data privacy which addresses the tension between business models that are based on the data generated by automated and connected driving , and limitations to the autonomy and data sovereignty of users.80 While many ethical challenges are distinctive to AI or its use in a particular domain or context , some are not necessarily unique to it . For instance , there is a rich literature on business and human rights,81 as well as the ethics of big data research,82 some of Privacy and Freedom of Expression in the Age of Artificial Intelligence25/29which can be informative to the privacy risks of AI as well . It is important to note that the international human rights framework is also relevant to non-state use of AI.83 UN Guiding principles on business and human rights : implementing the United Nations “ Protect , Respect and Remedy ” framework , 2011 . J. Metcalf , & K. Crawford , ‘ Where are human subjects in big data research ? The emerging ethics divide ’ , Big Data & Society , 3 ( 1 ) , 2016p.2053951716650211 ; Zook , M. et al , ‘ Ten simple rules for responsible big data research ’ , PLoS computational biology , 13 ( 3 ) , 2017 , p. e1005399 . As the UN Special Rapporteur on Freedom of Expression recognised in 2015 : “ Corporations in a variety of sectors play roles in advancing or interfering with privacy , opinion and expression , including ... anonymity . … [ I ] t remains important to emphasize that “ the responsibility to respect human rights applies throughout a company ’ s global operations regardless of where its users are located , and exists independently of whether the State meets its own human rights obligations ” , see Kaye , D , 2015 . A/HRC/29/32 , Report of the Special Rapporteur on the Promotion and Protection of the Right to Freedom of Opinion and Expression . UN General Assembly , May 22 . 81 82 83 Privacy and Freedom of Expression in the Age of Artificial Intelligence26/29Challenges UN Guiding principles on business and human rights : implementing the United Nations “ Protect , Respect and Remedy ” framework , 2011 . J. Metcalf , & K. Crawford , ‘ Where are human subjects in big data research ? The emerging ethics divide ’ , Big Data & Society , 3 ( 1 ) , 2016p.2053951716650211 ; Zook , M. et al , ‘ Ten simple rules for responsible big data research ’ , PLoS computational biology , 13 ( 3 ) , 2017 , p. e1005399 . As the UN Special Rapporteur on Freedom of Expression recognised in 2015 : “ Corporations in a variety of sectors play roles in advancing or interfering with privacy , opinion and expression , including ... anonymity . … [ I ] t remains important to emphasize that “ the responsibility to respect human rights applies throughout a company ’ s global operations regardless of where its users are located , and exists independently of whether the State meets its own human rights obligations ” , see Kaye , D , 2015 . A/HRC/29/32 , Report of the Special Rapporteur on the Promotion and Protection of the Right to Freedom of Opinion and Expression . UN General Assembly , May 22 . J. Burrell , ‘ How the Machine ‘ thinks ’ : Understanding Opacity in Machine Learning Algorithms ’ , Big Data and Society , 3 ( 1 ) , 2016 . A. Datta , S. Sen , & Y. Zick , ‘ Algorithmic transparency via quantitative input influence : Theory and experiments with learning systems ’ , In Security and Privacy ( SP ) , 2016 IEEE Symposium , pp . 598-617 . 81 82 83 84 85The diversity of AI applications , systems , and uses : Different types of AI and different domains of application raise distinct ethical and regulatory privacy concerns . For instance , processing data generated by autonomous cars raise different privacy challenges than the use of machine learning to identify ‘ terrorist ’ suspects . This lack of definitional clarity is a challenge , since different types of AI and different domains of application raise distinct ethical and regulatory issues . 1 . Informational asymmetry : Individuals are commonly unable to fully understand what kinds and how much data their devices , networks , and platforms generate , process , or share . As we bring ever-more smart and connected devices into people ’ s homes , workplaces , public spaces and even bodies , the need to educate the public about such data exploitation becomes increasingly pressing . In this landscape , uses of AI for purposes like profiling , or to track and identify people across devices and even in public places , amplify this asymmetry . Opacity and secrecy of profiling : Some applications of AI can be opaque to individuals , regulators , or even the designers of the system themselves , making it difficult to challenge or interrogate outcomes . In this context it is important to distinguish between three sources of opacity : ( 1 ) opacity as intentional corporate or state secrecy ; ( 2 ) opacity as technical illiteracy ; and ( 3 ) opacity that arises from the characteristics of machine learning algorithms and the scale required to apply them usefully.84 While there are technical solutions to improving the interpretability or auditability of some systems for solutions to improving the interpretability or auditability of some systems for different stakeholders,85 a key challenge remains where this is not possible and where negative outcomes are either safety-critical or human-rights-critical.2 . 3 . Privacy and Freedom of Expression in the Age of Artificial Intelligence27/29 S. Barocas , & A. Selbst , ‘ Big data ’ s disparate impact ’ , Cal . L . Rev. , 104 , 2016 , p. 671 . Discrimination , unfairness , inaccuracies , bias : AI-driven identification , profiling and automated decision-making may lead to unfair , discriminatory , or biased outcomes.86 Individuals can be misclassified , misidentified , or judged negatively , and such errors or biases may disproportionately affect certain groups of people . Accurate predictions may reveal sensitive attributes that could be used to discriminate . On the other hand , inaccurate or systematically biased data can feed into profiles , which may lead to biased or discriminatory outcomes . Re-identification and de-anonymisation : Some applications of AI , in particular uses of machine learning , blur the line between personal and nonpersonal data [ or personally identifiable information ( PII ) and non-personally identifiable information ( non-PII ) in the US ] , around which data protection and privacy laws around the world are organised . Data that is initially non-personal ( non-PII ) can become personal data ( PII ) in a different context or in different points in time , which is a particular risk for sectoral regulations . A similar challenge applies to sensitive personal data . Profiling using machine learning can derive , infer , or predict sensitive information from non-sensitive data , which might undermine additional safeguards for sensitive personal data.4 . 5 . 86 Privacy and Freedom of Expression in the Age of Artificial Intelligence28/29Conclusions and Recommendations ARTICLE 19 and Privacy International support the development and use of AI in compliance with human rights standards and regulatory standards in their respective fields . As AI systems become increasingly integrated into a larger number of critical societal processes , policy and technology responses in this area must meet the recommendations set out in this paper . We have provided an initial overview of the impact of these technologies on the freedom of expression and privacy , mapping the regulatory landscape , and delineating the roles , responsibilities , and duties that accrue to various actors in the field . Beyond this overview , we hope this paper provides a concrete step towards building strong civil society networks for action and advocacy to ensure that the organisations using , building and governing AI are held accountable and meet international human rights standards . As indicated in this paper , we believe that it is necessary to further study and monitor the impact of AI on human rights . However , at this stage , we call on states to : We also call on states and companies to : Review the adequacy of existing frameworks and regulation : Different types of AI and different domains of application raise specific ethical and regulatory human rights issues . In order to ensure that they protect individuals from the risks posed by AI , existing laws must be reviewed , and if necessary amended , to address the effects of new and emerging threats to privacy and freedom of expression . Ensure protection of international human rights standards : The development , use , research and development of AI must be subject to the minimum requirement of respecting , promoting , and protecting international human rights standards . This should include developing an understanding of what constitutes ‘ AI human rights critical systems ’ and ensuring that laws and regulations , codes of conduct , ethical codes , and self-regulatory and technical standards meet the threshold set by international human rights . Ensure accountability and transparency : Corporate , technical , and state actors must allow for meaningful multi-stakeholder participation , including civil society actors , in setting technical standards , regulation , and industry guidelines for AI systems , technology policy and industry standards to ensure transparent processes and legitimacy of outcomes . In particular , non-binding frameworks must be accompanied by strong accountability and oversight measures . Privacy and Freedom of Expression in the Age of Artificial Intelligence29/29We also call on civil society to : Engage further to ensure the mitigation of any potential negative impact on fundamental rights like freedom of expression and privacy . This will involve a detailed understanding of the technology , the actors developing it , and the context in which it is deployed . Collect and highlight case studies of ‘ human rights critical ’ AI : In understanding the myriad ways in which AI will impact human rights , it is important to collect and highlight case studies that demonstrate impact . These case studies need to include examples from across the globe . Build civil society coalitions and expertise networks : It is important to emphasise the need to develop knowledge-exchange programs and facilitate joint-strategy development between civil society organisations . So far , academia and industry have taken the lead in moving the debate on the societal impact of AI forward . While civil society actors play a crucial role in these debates , it is important to strengthen the voice of those working on technology in the public interest . Privacy and Freedom of Expression in the Age of Artificial Intelligence30/29PRIVACY INTERNATIONAL 62 Britton Street London EC1M 5UY United Kingdom Website : www.privacyinternational.org Phone : +44 20 3422 4321 Twitter : @ privacyint Registered charity number 1147471ARTICLE 19 Free Word Centre 60 Farringdon Rd London EC1R 3GA United Kingdom Website : www.article19.org Phone : +44 20 7324 2500 Twitter : @ article19org Registered charity number 327421
