appgThe New Frontier : Artificial Intelligence at Work A final report produced by the All-Party Parliamentary Group on the Future of Work November 2021 The New Frontier : Artificial Intelligence at Work Strategic research partnerChairs ’ introduction Our Inquiry Our key findings Our recommendations Recommendation 1 An Accountability for Algorithms Act Recommendation 2 Updating digital protection Recommendation 3 Enabling a partnership approach Recommendation 4 Enforcement in practice Recommendation 5 Supporting human-centred AI Our conclusion Annex 1 Endnotes Acknowledgements Report information 03 04 06 09 11 14 17 19 21 24 26 27 30 31 The APPG and IFOW would like to thank the Joseph Rowntree Charitable Trust for supporting this inquiry . The New Frontier : Artificial Intelligence at Work 03 The new National AI Strategy1 details plans to invest in innovation across the country and rightly recognises the importance of getting the governance right , at the national and international level . As the evidence we have considered shows , however , there is an urgent need to bring forward robust proposals to protect people and safeguard our fundamental values . The AI Strategy recognises the broad ethical , social and economic impacts of modern technology and the implications for British industries , labour supply and skills . Specifically , it acknowledges the need to understand and address the risks and harms to work and workers presented by AI ; and to involve people from diverse backgrounds in this process . These are pressing needs which must be met if we are to fulfil the objectives of the AI Strategy and drive a digital transformation to benefit people across the country . Our All Party Parliamentary inquiry finds that AI is transforming work and working lives across the country in ways that have plainly outpaced , or avoid , the existing regimes for regulation . With increasing reliance on technology to drive economic recovery at home , and provide a leadership role abroad , it is clear that the Government must bring forward robust proposals for AI regulation to meet these challenges . A sharp focus on the most pressing challenges faced at work , where stakes are especially high , will help translate the Government ’ s intention to shape a world of responsible technology into action . Our All Party Parliamentary inquiry offers a roadmap for the next phase of the AI Strategy . In our view , the Government must take this road if it is to meet new challenges and seize the potential of modern technology to fulfil the ambitions of the AI Strategy and improve future work and working lives across the United Kingdom in service of the public interest . David Davis MP , Clive Lewis MP , and Lord Jim Knight Chairs ’ introduction The New Frontier : Artificial Intelligence at Work 04 The All Party Parliamentary Group on the Future of Work ( ‘ the APPG ’ ) brings together parliamentarians , industry and civil society to foster understanding of the challenges and opportunities of technology and the future of work . We collaborate to develop practical solutions that will shape a future of better work across the UK . As part of our mission to advance understanding and practical solutions to shape a future of better work,2 our inquiry was established in May 2021 in response to growing public concern about AI and surveillance in the workplace and the Institute for the Future of Work ’ s ( ‘ IFOW ’ ) report ‘ The Amazonian Era ’ 3 . Our inquiry , which ran from May to July 2021 , examined the use and implications of surveillance and other AI technologies used at work ; and considered practical policy solutions to meet the challenges and opportunities we have found . This report outlines the APPG ’ s key findings and recommendations based on the evidence about AI at work that we have considered . Our recommendations are aimed at ensuring our AI ecosystem is genuinely human-centred , principles-driven and accountable to shape a future of better work . They are centred around a proposal for an Accountability for Algorithms Act ( ‘ the AAA ’ ) .4 The AAA offers an overarching , principles-driven framework for governing and regulating AI in response to the fast-changing developments in workplace technology we have explored throughout our inquiry . It incorporates updates to our existing regimes for regulation , unites them and fills their gaps , whilst enabling additional sector-based rules to be developed over time . The AAA would establish ; a clear direction to ensure AI puts people first , governance mechanisms to reaffirm human agency , and drive excellence in innovation to meet the most pressing needs faced by working people across the country . Our focus is the frontier of changes to work but our recommendations inform the wider debate about AI governance and regulation as part of the UK ’ s AI Strategy . The proposals we make are not restricted to AI alone , because it is not always possible , or helpful , to isolate AI from other forms of significant algorithmic decision-making.5 In this report , we use the term ‘ algorithmic systems ’ in recognition of the fact that both fully automated and semi-automated decision making technologies rely on wider human decision making processes to impact work.Our Inquiry Our Inquiry * ‘ It ’ s about explosive growth . It ’ s no longer just about Uber , Amazon warehouses etc , it ’ s in professional services firms , universities , every workplace you can think of. ’ Jeremias Adams-Prassl Professor in the Faculty of Law at the University of Oxford Our key findingsThe New Frontier : Artificial Intelligence at Work 06 We are living through a period of technological transformation that is already having a profound impact on the work and working lives of people across the UK.6 AI and other data-driven technologies are a primary factor of this transformation.7 Although many of these changes were taking place pre-pandemic , there has been a marked increase in the use of AI technologies in the workplace . Use of algorithmic surveillance , management and monitoring technologies that undertake new advisory functions , as well as traditional ones , has significantly increased during the pandemic.8 Before COVID-19 , the dominant impact of technology on work was considered to be the substitution of human labour by machine , but the rise of remote working has increased public concern about the impact of remote monitoring and management . The evidence we have considered , however , demonstrates that the impacts of AI on work and workers are wide ranging beyond surveillance or substitution.9 We find that the pace , depth and breadth of wider workplace transformation has accelerated . AI technologies are changing the nature of work , who does it and how it is done.10 AI offers invaluable opportunities to create new work and improve the quality of work if it is designed and deployed with this as an objective.11 However , we find that this potential is not currently being materialised . Instead , a growing body of evidence12 points to significant negative impacts on the conditions and quality of work across the country . Pervasive monitoring and target setting technologies , in particular , are associated with pronounced negative impacts on mental and physical wellbeing as workers experience the extreme pressure of constant , real-time micro-management and automated assessment . These adverse impacts span the entire range of ‘ Good Work ’ principles set out in the Good Work Charter13 ( Annex 1 ) endorsed by the APPG and incorporating the rights and freedoms protected in the European Social Charter and International Covenant on Economic , Social and Cultural Rights : access to work , fair pay , terms and conditions for work ; equality , dignity and autonomy ; support , participation and learning . Research from the IFOW and others shows that Good Work closely correlates with good health and wellbeing ; and that poor quality work correlates with poor health and wellbeing.14 The evidence we have heard indicates that adverse impacts of AI are economy-wide but that key workers in essential service sectors have been hit particularly hard.15 ‘ The dignity of workers is under assault in our emerging algorithmically driven working environment… this is now threatening some of the deeper structures that have for centuries functioned as supports for individual liberty , social freedom and collective flourishing . ’ Dr David Leslie Ethics Theme Lead at The Alan Turing Institute The New Frontier : Artificial Intelligence at Work 07 Our key findings A core source of anxiety is a pronounced sense of unfairness and lack of agency around automated decisions that determine access or fundamental aspects of work . Workers do not understand how personal , and potentially sensitive , information is used to make decisions about the work that they do ; 16 and there is a marked absence of available routes to challenge or seek redress . Low levels of trust in the ability of AI technologies to make or support decisions about work and workers follow from this.17 We find that there are even lower levels of confidence in the ability to hold the designer , developers , and users of algorithmic systems meaningfully accountable for their responsible governance.18 In spite of this , there is wide measure of optimism that policy-makers can reset this trajectory with appropriate direction and robust regulatory response . Our dedicated hearing on AI and regulation revealed that our laws have been far outpaced by magnitude and pervasive use of AI at work . We accept the evidence of Helen Mountfield QC , supported by detailed analysis in the Mind the Gap Report,19 that our existing framework of regulation is inadequate to promote innovation and fair play together.20 We find that the challenges we have identified lie between data protection , labour and equality laws . Rather than being acknowledged and caught by our existing approach to regulation , they are obscured by it , which means that many of the adverse impacts we have seen are set to be projected into the future , ‘ shaping the future in the image of the past ’ .21 Technological development is an inevitability , but there is nothing inevitable about the way AI technologies shape our working lives . It is the role of the law to shape innovation and organisational behaviours in ways which serve the public interest . And it is the role of legislators to regulate for real accountability and real AI innovation , squarely addressing the toughest challenges we face and redirecting our trajectory towards the high road : human-centred AI and the creation of better work for all . ‘ We must be intentionally inclusive otherwise , we will be unintentionally exclusive , and that ’ s when we ’ ve been seeing some of these harms . We need to regulate to consider the collective , as well as individual harm else structural inequalities will be projected into the future , and magnified . ’ Anne-Marie Imafidon MBE Founder of Stemettes and Trustee , IFOW * ‘ Where does responsibility lie at management and board levels for the harms and risks that are created in this new world ? ... If we don ’ t talk about structural inequality and structural harm , we will miss the boat. ’ Andrew Pakes Head of Research at Prospect Union The New Frontier : Artificial Intelligence at Work 09 The APPG ’ s recommendations are aimed at ensuring our AI ecosystem is human-centred and properly accountable to shape a future of Good Work . Our first and outstanding recommendation is that the Government introduce a new , cross-sector , principlesdriven regulatory framework to promote strong governance and innovation together : an Accountability for Algorithms Act ( AAA ) . The AAA would shift our emphasis to preventative action and governance in the public interest . The AAA would include new rights and responsibilities , subject to a risk-based threshold , to ensure that all significant impacts from algorithmic decision-making on work or workers are considered and that appropriate action is always taken . This approach would benefit the best of British innovators and British business as well as working people across the country . 1 An Accountability for Algorithms Act The Act would establish a simple , new corporate and public sector duty to undertake , disclose and act on pre-emptive Algorithmic Impact Assessments ( AIA ) . This duty would apply from the earliest stage of design and deployment of algorithmic systems at work and require rigorous ex ante assessment and ex post facto evaluation of risks and other impacts on work and workers . AIAs would always include a dedicated equality impact assessment . 2 Updating digital protection The AAA would raise the floor of essential protection for workers in response to specific gaps in protection from adverse impacts of powerful but invisible algorithmic systems . These would include an easy-to access right for a full explanation of purpose , outcomes and significant impacts of algorithmic systems at work , a summary AIA and means for redress . A right to be ‘ involved ’ in shaping the design and use of algorithmic systems at work would be introduced to help better manage impacts on work and workers and to safeguard the social license and democratic governance of these systems . These new rights would be set out in a dedicated schedule to the AAA : ‘ Worker Rights for the age of AI ’ .Our recommendations The New Frontier : Artificial Intelligence at Work 10 Our recommendations 3 Enabling a partnership approach To boost a partnership approach and recognise the collective dimension of data processing , some additional collective rights are needed for unions and specialist third sector organisations to exercise new duties on members or other groups ’ behalf . This could be further supported by the Government establishing an AI Partnership Fund to allow the TUC to build on and diversify the work of their AI Working Group and develop training to give working people the tools and knowledge required to interact , comprehend and challenge the use of AI at work as appropriate . Our proposed partnership approach also offers further opportunities for skills development and investment in collaboration with the private sector . 4 Enforcement in practice The joint Digital Regulation Cooperation Forum ( DRCF ) should be expanded with new powers to create certification schemes , suspend use or impose terms and issue cross-cutting statutory guidance , to supplement the work of individual regulators and sector-specific standards . The forum should be equipped and funded to run regulatory sandboxes to pilot new approaches to actively promote equality as part of the AIAs , as well as to rigorously enforce existing and new obligations . 5 Supporting human-centred AI The principles of Good Work should be recognised as fundamental values , incorporating fundamental rights and freedoms under national and international law , to guide development and application of a human-centred AI Strategy . This will ensure that the AI Strategy works to serve the public interest in vision and practice , and that its remit extends to consider the automation of work . In parallel to the AI Strategy , the Cabinet Office should initiate a Work 5.0 Strategy to squarely address the challenges and opportunities of automation as a result of AI and other modern technologies and ensure a human-centred transformation of work across the UK . The New Frontier : Artificial Intelligence at Work 11 The established principles of AI governance22 should be put on a statutory footing , together with the ethico-legal principal of equality , promoted in response to the specific challenges at work . The AAA would establish a new duty to undertake , disclose and act on pre-emptive AIA applicable across the public and private sectors . To inspire and shape the best of British innovation , this duty should apply from the earliest stage of design and deployment of algorithmic systems at work and require rigorous prior evaluation of risks and other impacts on work and workers . The duty would extend to the responsibility to make appropriate design choices23 and modifications where risks have been identified in the AIA . It must include a dedicated equality impact assessment.24 At present , corporations are not required to produce any assessment of how the AI or other algorithmic systems they are adopting could , or do impact work or their workforce . This means that adverse impacts , including significant wellbeing and equality impacts , tend to be neglected until the damage is done . Research has demonstrated that algorithmic systems are having deleterious impacts on good work across all key legal principles.25 We therefore propose that the main feature of the AAA is a new corporate duty of prior assessment and appropriate action . The public sector equality duty should be enhanced to mirror the AIA duty and extended to the private sector . Creating a new duty to produce pre-emptive AIAs would shift regulatory emphasis to active , anticipatory intervention from the more limited , retrospective evaluation of algorithmic systems through the judicial system . The uncertainty of this operating environment is as problematic for those developing algorithmic technologies and employers as it is for workers . Adopting a pre-emptive model of regulation would create a clear direction and stable environment for businesses and people . We recommend that the positive and negative impacts on Good Work are considered as part of the ex ante impact assessment before algorithmic systems are procured or deployed and that impacts are evaluated ex post facto on an ongoing basis . This approach will support human-centred technological innovation that creates value for as many people as possible , rather than extracts value. ‘ In general , the Equality Act does not impose any obligations on employers or software designers or anyone else to think about or avoid discrimination and disadvantage as a proactive duty… Human beings and organisations that use machines of this kind have to take responsibility . If we don ’ t design the future we want , the future will be designed by accident . ’ Helen Mountfield QC Expert in constitutional , human rights and equality lawRecommendation 1 An Accountability for Algorithms Act The New Frontier : Artificial Intelligence at Work 12 Recommendation 1 An Accountability for Algorithms Act Tabitha Goldstaub , Chair of the AI Council , told our inquiry that a fresh regulatory approach would be necessary in order to unlock the opportunities of AI and make the world a better place : ‘ The thinking in the UK is that companies should be required and encouraged to consider and remedy any adverse impacts as soon as possible in the innovation cycle , not post event . The opportunity is for the UK to do better , and lead globally . ’ Tabitha Goldstaub , Chair of the UK Government ’ s AI Council The new AIA duty should be subject to a risk-based , contextual threshold . The main criteria for establishing risk will be where algorithmic systems have significant impacts on work or workers , including when they determine access , terms and conditions of work . The process should integrate assessment of the inherent risks of AI with assessment of the wider impacts on work and working people , and it should be rigorous , dynamic and ongoing through the deployment and life cycle of the algorithmic system . The new duty should be accompanied by a statutory code setting out factors to be considered in the evaluation process . To be effective and meet new challenges , an AIA model must have 4 planks:26 1 Identifying individuals and communities who might be impacted by algorithmic decisions , particularly vulnerable groups , before procurement or deployment . This ‘ pinpointing ’ component will form the basis for multi-stakeholder engagement and participation throughout the process of assessment . Workers should always be treated as key stakeholders.27 2 Undertaking a risk analysis aimed at outlining potential pre-emptive actions in the context at hand . This component operates the precautionary principle and is directed at preventing individual and social injury , promoting design and deployment that is aimed at improving work and working lives . The Good Work Charter28 can be used as a checklist to consider potential impacts on work and workers and help integrate socio-technical with technical dimensions . The New Frontier : Artificial Intelligence at Work 13 Recommendation 1 An Accountability for Algorithms Act 3 Taking appropriate action in response to the analysis undertaken . Those subject to the duty across the innovation cycle and supply chain29 would be required to assess governance mechanisms and make appropriate design choices and modifications to address harms and mitigate the risks identified . Transparency about the approach taken and choices made should be mandated . 4 Ongoing impact assessment and appropriate responsive action . This plank would also ensure that the assessment process by which impacts on work and workers have been considered by those designing and deploying algorithmic systems was articulated , shared and begins at the earliest stage of innovation and then continues through its life cycle . It would also ensure a higher level of transparency about the beneficial or harmful impacts under consideration , and about the process itself . In our view , mandated AIAs are the most practical mechanism to promote good innovation , good practice , and good governance of AI used at work , if undertaken rigorously both before and after deployment.30 The law should articulate the overarching aim and basic requirements of an algorithmic assessment , but not how these requirements should be met . The AIA must be built on the 4 planks set out above and include an element of independent evaluation . Regulators and industry bodies should coordinate to provide additional guidance and ensure rigorous enforcement of the duty . Guidance at a sector level would provide detailed standards and advice on how to meet them . ‘ For the future to work for the people , the data and the power dynamics around this new superpower need to be managed to ensure that the tech does not continue to ravage our privacy , widen skills and poverty gaps , increase inequality and strengthen the structures that keep people down , no matter what they do . ’ Tabitha Goldstaub Chair of the UK Government ’ s AI Council The New Frontier : Artificial Intelligence at Work 14 The AAA should raise the floor of essential protection for workers in response to specific gaps in protection from adverse impacts of powerful but invisible algorithmic systems , many of which originate from the US . These would include an easy-to-access right to a full explanation of purpose , outcomes and significant impacts of algorithmic systems at work , including the impact assessment itself . A right to be ‘ involved ’ in shaping the design and use of algorithmic systems at work would be introduced to help understand and better manage impacts on work and workers and to safeguard the social license and democratic governance of these systems . A right to flexible working unless there is a strong business case not to do so ; incorporate the ability to disconnect outside agreed working hours ; and ensure reasonable notice for shift work so that flexible working is not used as a cover for exploitative employment practices . These rights deserve a dedicated Schedule in the Accountability for Algorithms Act : Rights for Workers in the Age of AI . Our inquiry showed numerous ways in which all stakeholders would benefit from wider engagement and increased understanding about why and how algorithmic systems were impacting work and workers . Technologists , employers and employees are often unaware of the impacts of algorithmic systems31 which impedes deliberate , better use and hampers collaborative decision-making in the longer-term interests of people and businesses . Workers are not confident of how their data is being used , and how this is making decisions about their performance,32 leading to a sense of unfairness and an absence of agency and effective remedy . This is associated with low levels of trust in the ability of AI to make fair , transparent and accountable decisions.33 For clarity and fairness , we therefore propose establishing a new , freestanding right for a full explanation of purpose and outcomes and impacts of algorithmic systems at work , which would include access to relevant AIAs.34 This right would enable workers to find out the use of , purpose for and metrics within AI technologies used to monitor , allocate work , pay and discipline workers as modelled by the new Californian Bill in the US and the subject of a new consultation on “ a Bill of Rights for an AI-Powered World ” .35 The right for an explanation would be mirrored by a new transparency duty on employers to disclose such information , alongside any AIA . Additional , sensitive information would be available to regulators on request so that they are able to perform their monitoring and enforcement functions.Recommendation 2 Updating digital protection ‘ We were given these productivity targets based on what we were told was the speed others were working at . We had no oversight of the algorithm itself and no sense that those targets other people were hitting were real . We were just told these were the rates other people were hitting and if we did not hit those , we could lose our job . ’ James Bloodworth Journalist and Author The New Frontier : Artificial Intelligence at Work 15 Recommendation 2 Updating digital protection Explanations must be clear and comprehensive to enable workers without technical knowledge of algorithms to understand a decision , and would articulate the means of redress . Concerns have been raised by developers about how a ‘ full explanation ’ duty could expose them to IP infringement and open up the algorithm to be exploited or ‘ gamed ’ by workers.36 We therefore propose that the layered approach recommended by the The Information Commissioner ’ s Office ( ICO ) and the Turing Institute37 is adopted to ensure that meaningful , legally binding explanations can be implemented in practice , while the legitimate interests to protect IP and other sensitivities are safeguarded . We believe that this model of explanation addresses concerns about the feasibility of explainability expressed by developers and would not impede innovation . A right to consultation is established in labour law and industrial practice,38 but our inquiry found a striking absence of consultation where AI and algorithmic systems were being introduced at work , even when the systems carried significant financial or wellbeing risks . Polling by the TUC and Britain Thinks revealed that only 31 % of workers agree with the statement that staff at their workplace are consulted before new technology is introduced.39 The evidence we received suggests that in non-unionised workplaces it is commonplace to have no consultation.40 This is an unnecessary obstacle to the responsible design , development and deployment of technology which points to the need for workers to have an enhanced right to meaningful consultation from the earliest stage when algorithmic systems are being considered for adoption at work . We conceive of this enhanced form of consultation as a right to be ‘ involved . ’ Survey data from the IFOW found that 49 % of USDAW union members felt that higher levels of consultation would result in better design and more effective application of algorithmic systems , better suited to their needs , as well as those of the business.41 We therefore recommend a new right for all workers to have reasonable ‘ involvement ’ in the design and deployment of algorithmic systems likely to have significant impacts on work or workers . This would address immediate challenges in the workplace and help bridge the divide between those who design , and those who feel , AI impacts . ‘ When you don ’ t understand what data is being collected about you , how would you go about rectifying a decision made with it ? ’ Emma Wright Director and Council at The Institute of AI The New Frontier : Artificial Intelligence at Work 16 Recommendation 2 Updating digital protection The evidence we have heard suggests that workers feel constantly ‘ on call ’ and unable to control their working patterns where algorithmic systems are used to direct shift allocation . In practice , the concept of ‘ flexible working ’ is often used as a cover for poor employment practices that depend on automated instructions to personal telephones made at the last-minute.42 A right to flexible working would establish a requirement that all roles would be advertised as being flexible and a presumption that reasonable requests made for flexible working would be permitted unless there was a good business case for why not . Meaningful flexibility is also closely associated with an ability to disconnect outside working hours , and to ensure reasonable notice is given for shift work , and the cancellation of shift work for planning purposes and to protect family lives . We therefore recommend new rights for flexible working , disconnect and reasonable notice , as well as rights to a full explanation and involvement , for workers in a digital age . The advantages for workers are plain but these new rights will also help ensure business models are sustainable in the longer term . “ Women are having to cancel their care responsibilities to respond to shift scheduling at the last minute , workers are no longer talking to each other to keep optimum pace , disabled workers are quitting or being let go due to an inability to perform against these standards… the impact of these systems can be seen beyond any given workforce . It is impacting communities and changing what ‘ work ’ is . ” Dr Abigail Gilbert Head of Research at the Institute for the Future of Work The New Frontier : Artificial Intelligence at Work 17 To apply the principle of collaboration in the 2021 Digital Regulation Plan , Government should facilitate and cement social partnership working within the AI ecosystem . As a first step , we recommend that new collective rights are established for unions and NGOs to exercise our new individual rights for a full explanation and involvement , with the permission of individual members . We also recommend a new , freestanding right for unions to be consulted whenever ‘ high risk ’ 43 AI tools are being introduced to workplace , as sought by the TUC in ‘ Work and the AI Revolution ’ 44 . The excellent work of the TUC Working Group should be diversified and scaled , with the support of an AI Partnership Fund , extending to the development of a worker AI training programme , bringing further opportunities for reskilling and investment in collaboration with specialist organisations and the private sector . In addition , there should be union representation on relevant governance bodies . The 2021 Digital Regulation Plan rightly states that regulation should take a ‘ collaborative approach ’ by , for example , working with business to test out new interventions and models . Partnership working applies the principle of collaboration further : it means a tripartite approach in which businesses and employees work together in a collaborative manner to address challenges and maximise opportunities for mutual benefit . The evidence we have heard points to poor levels of communication and needless divides which hamper constructive partnership working to get the best out of AI at work.45 This should start with employers informing relevant trade unions when algorithmic systems with significant impacts are adopted in a workplace so that meaningful consultation can commence . We recognise the historic role unions have played in upholding and enforcing workplace protections.46 The evidence we have heard suggests that the most egregious examples of workplace surveillance and abuse of AI are happening in workplaces that unions have been unable to access . We recommend that unions are supported in accessing physical and digital workspaces . In addition , unions should also be allowed to develop new roles within the AI ecosystem to redress a growing imbalance of information and power and help deliver genuinely human-centred AI in the public interest . The evidence we have considered shows that algorithmic systems work by making assumptions about individuals , and classifying them into groups on the basis of some shared data points.47 This is used to predict and shape future behaviour . In order to understand Recommendation 3 Enabling a partnership approach ‘ We advocate a world of work where everyone can benefit from new technology and innovation , not just employers and technology companies . In that respect , we encourage education , awareness raising , collaboration and consultation , empowering workers with knowledge about the importance of their data and information as to how technology operates . ’ Mary Towers AI Working Group Lead at the Trade Union Congress The New Frontier : Artificial Intelligence at Work 18 Recommendation 3 Enabling a partnership approach impacts on work and workers however , as the AI Strategy aims to do , group and relative outcomes must be examined . This demands a collective approach , without exclusive reliance on individual rights . In these circumstances , it is crucial to harmonise individual and collective mechanisms for accountability . Unions are well-placed to be a helpful resource throughout the process of assessing and redressing algorithmic impacts by liaising with the workforce in a straightforward , digestible manner and communicating their views to governing bodies and beyond them . Properly equipped and supported , they may be able to help run early AIA pilots , for instance via technology forums48 or dedicated technology union representatives to advance the practice of social partnership at regional and sector levels as AI is dispersed across the country . The AI Strategy focuses on attracting the best AI talent rather than boosting AI literacy among working citizens . Given the importance of AI to drive digital transformation across the UK , we therefore propose an additional role for the TUC : to develop and deliver AI training to workers . This course should be fully funded by the Government and then rolled out to a representative proportion of the non-unionised workforce.49 We recommend that the TUC AI Working Group is supported to work with independent , charitable organisations such as the Turing Institute and training programmes are designed in collaboration with employers . The partnership approach would therefore also create new opportunities for the Government to work hand in hand with employers and third sector organisations to develop and invest in upskilling the UK workforce , as well as with trade unions . ‘ We would love to see social partners involved in this which we don ’ t tend to see in the UK setting and which we know from our colleagues in unions elsewhere in Europe there is a much stronger sense of this . ’ Andrew Pakes Research Director at Prospect Union The New Frontier : Artificial Intelligence at Work 19 The Government ’ s DRCF was established with the excellent intention of ensuring greater cooperation on digital and online regulatory matters . It currently consists of the ICO , the Competition and Markets Authority ( CMA ) and the Office of Communications ( Ofcom ) . However , the expert witnesses at our inquiry session on enforcement and the law gave a very mixed picture in terms of responsibility and accountability , with multiple regulators , inspectorates and enforcement agencies involved.50 The witnesses spoke to clear gaps in the mandates and resources of our existing regulators , and difficulties in accessing current workforce protections . This is not helped by limited mechanisms for transparency . In addition , equality policy is not integrated or enforced outside the Equality and Human Rights Commission ( EHRC ) which has led to widespread confusion about the capacity of AI technologies to replicate the inequalities of the past . The evidence we have heard suggests that to make the UK a world-leader in governance as well as innovation , we need new mechanisms and resources to establish regulatory common capacity and enforce the AAA , alongside existing protections.51 The members and remit of the DRCF should be expanded to include the EHRC and new single enforcement body for employment rights . The DRCF should be supported with specialist , interdisciplinary team working horizontally to develop cross-cutting statutory guidance , joint investigations and strategic test cases , as well as work up guidance on AI for individual regulators . ‘ We need to build greater understanding of what AI is both within our institutions and in the general public . We have to do something to fill the gaps that are created as our regulatory framework doesn ’ t go far enough . If you were to put a drug on the market , it has to go through various tests . Is there a role for something like that with AI ? ’ Emma Wright Director and Council at The Institute of AIThe Government ’ s DRCF should be expanded with new powers to create certification schemes , suspend use or impose terms and issue cross-cutting statutory guidance , to supplement the work of individual regulators and sectors-specific standards . The forum should be equipped and funded to run regulatory sandboxes to pilot new approaches to promote equality as part of the AIAs , as well as to rigorously enforce existing and new obligations.Recommendation 4 Enforcement in practice The New Frontier : Artificial Intelligence at Work 20 Recommendation 4 Enforcement in practice The DRCF should be equipped to establish and run regulatory sandboxes52 to experiment with different approaches , making and enforcing modifications as result of AIAs , and options to proactively promote equality . This can start now and may inform refinement of the AAA in its passage through Parliament , as well as more detailed statutory guidance . In addition , detailed sector guidance and support can be worked up over time . We think this will be important but the challenges we have explored at work ( which is not a ‘ sector ’ ) demonstrate that regulation can not rest on a sectoral approach . Parliament should keep the work of the DRCF under close review . The Government may need to consider a specialist AI regulator in due course . ‘ Our regulatory regimes were designed before a world of machine learning and AI… You need a level playing field and a set of rules everyone abides by to ensure the responsible innovation everyone wants to see . ’ Jeremias Adams-Prassl Professor in the Faculty of Law at the University of Oxford The New Frontier : Artificial Intelligence at Work 21 The principles of Good Work should be recognised as fundamental values to guide development and application of a human-centred AI Strategy . This will ensure that the AI Strategy works to serve the public interest in vision and practice , and that its remit extends to consider the automation of work . In parallel to the AI Strategy , the Cabinet Office should initiate a Work 5.0 Strategy to squarely address the challenges and opportunities of automation as a result of AI and other modern technologies , and ensure a human-centred transformation of work across the UK . The evidence we have heard throughout our inquiry suggests that significant impacts on Good Work53 are rarely appreciated or prioritised in the design and deployment of AI at work , even though the principles of Good Work capture some of the most fundamental values and rights of our citizens . The AI Strategy purports to protect the public and our fundamental values without articulating what these are , how they will steer development of the Strategy , or how they will be applied to new mechanisms for governance . The evidence in our inquiry points to a central role for Good Work principles in Phase 2 of the Strategy . If we focus on future Good Work , this will knit the Pillars of the Strategy together , ensuring that growth and innovation go hand in hand with respect for the fundamental values and rights of our citizens . A sharper focus on Good Work for all will enable the development of human-centred AI and a human-centred AI ecosystem . This means that the Government should support new functions , funding streams and challenges for UKRI to ensure that the UK leads in the innovating for human-centred AI aimed at creating good future work . Our inquiry has highlighted the striking and often adverse impacts AI can have on work and workers , including automation . We are therefore surprised that the automation of work is only lightly referenced within the AI Strategy . We strongly support the recommendation of the Works and Pensions Committee that an overarching Work 5.0 Strategy54 is needed to shape and protect future work in the age of AI and automation . This should be initiated as soon as possible for consultation and development alongside the AI Strategy . Recommendation 5 Supporting human-centred AI ‘ We need to be principle-driven ; we need to be human centred and we need to look across the entire life cycle , not be reactive at the end . ’ Anne-Marie Imafidon MBE Trustee at the IFOW and Co-Founder of Stemettes Our inquiry has found that the challenges we have explored fall between our existing frameworks . In a similar vein , the ‘ future of work ’ risks falling between Government Departments , rather than deserving of a dedicated cabinet office with a cross-cutting remit . This is illustrated by the AI Strategy ’ s incomplete attention to automation and impacts on work , in contrast to the EU-US Inaugural Joint Statement on technology made on 29 September 2021.55 We therefore oppose that the Cabinet Office initiate and co-ordinate the development of a cross-department Work 5.0 Strategy aimed at understanding the impacts of automation on work and ensuring that new technology and innovation promote prosperity and wellbeing across the country through better work.Recommendation 5 Supporting human-centred AIThe New Frontier : Artificial Intelligence at Work 22 ‘ The UK can do better and is very well placed to lead globally if we can incorporate and build on the strengths that we have in governance and ethics , as well as AI innovation because it is really important that we own and tackle the thornier issues . Then we can lead globally , have clear rules , be trustworthy and earn the public trust . ’ Tabitha Goldstaub Chair of the UK Government 's AI Council * ‘ We need to be principle-driven ; we need to be human centred and we need to look across the entire life cycle , not be reactive at the end. ’ Anne-Marie Imafidon MBE Trustee at the Institute for the Future of Work and Co-Founder of Stemettes The New Frontier : Artificial Intelligence at Work 24 The evidence contributed to this inquiry from organisations across civil society , business , the trade union movement , and academia has made a compelling case that a fresh approach to regulation is needed to maximise the opportunities and address the challenges of fast-paced technological change at work . Our governance framework must not only keep pace with pervasive use of AI at work . It must anticipate change and shape a better future of work too . A new focus on the creation of Good Work and tackling the workplace challenges we have identified head on will ensure innovation and governance of the best , most-human centred AI working for people and the public interest . If our proposed approach is adopted , the UK is well placed to fulfil the potential of the AI Strategy and produce a gold standard template to lead globally in the innovation and governance of responsible modern technology . Our conclusion * ‘ We advocate a world of work where everyone can benefit from new technology and innovation , not just employers and technology companies. ’ Mary Towers AI Working Group Lead , Trade Union Congress The New Frontier : Artificial Intelligence at Work 26 1 Access Everyone should have access to good work 2 Fair pay Everyone should be fairly paid 3 Fair conditions Everyone should work on fair conditions set out on fair terms 4 Equality Everyone should be treated equally and without discrimination 5 Dignity Work should promote dignity 6 Autonomy Work should promote autonomy 7 Wellbeing Work should promote physical and mental wellbeing 8 Support Everyone should have access to institutions and people who can represent their interests 9 Participation Everyone should be able to take part in determining and improving working conditions 10 Learning Everyone should have access to lifelong learning and career guidance The Good Work Charter Annex 1 1 National AI Strategy : https : //www.gov.uk/government/publications/national-ai-strategy 2 APPG mission statement : https : //www.futureworkappg.org.uk/ 3 Gilbert , Abigail and Anna Thomas ( 2021 ) . ‘ The Amazonian Era : How algorithmic systems are eroding good work ’ IFOW . https : //www.ifow.org/publications/the-amazonian-era-how-algorithmic-systems-are-eroding-good-work 4 An Accountability for Algorithms Act ( AIA ) was first proposed by the Equality Task Force , as outlined in ‘ Mind the Gap : The Final Report of the Equality Task Force ’ , IFOW ( 2020 ) . https : //www.ifow.org/publications/mind-the-gap-the-final-report-of-the-equality-task-force 5 For a review of the issues in defining AI in policy , see : Krafft , P . M. , Meg Young , Michael Katell , Karen Huang , and Ghislain Bugingo . “ Defining AI in policy versus practice . ” In Proceedings of the AAAI/ACM Conference on AI , Ethics , and Society , pp . 72–78 . 2020 . 6 See for reference to the experience of change at an individual level : TUC , ( 2021 ) ‘ Technology Managing People : The Worker Experience ’ https : //www.tuc.org.uk/research-analysis/reports/technology-managing-people-worker-experience ; and Gilbert , Abigail and Anna Thomas ( 2021 ) ‘ The Amazonian Era : How algorithmic systems are eroding good work ’ IFOW https : //www.ifow.org/publications/the-amazonian-era-how-algorithmic-systems-are-eroding-good-work and at the level of labour markets : Laws , Athene Helen . “ Inequality in Labour Markets . ” PhD diss. , University of Cambridge , 2020 ; Prassl , Jeremias . Humans as a service : The promise and perils of work in the gig economy . Oxford University Press , 2018 . 7 Autor , David H. “ Wiring the labor market . ” The Journal of Economic Perspectives 15 , no . 1 ( 2001 ) : 25–40 . 8 Evidence by Abigail Gilbert , Mary Towers and Jeremias Prassl during APPG evidence sessions on the 18th May 2021 and 8th June 2021 . 9 IFOW have identified 6 types of automation impact , including substitution ( where tasks previously conducted by a worker are conducted by a machine ) telepresence ( where tasks previously conducted by a person in a specified location can be conducted remotely ) augmentation ( the improvement of work delivery through technological assistance ) creation ( the creation of new tasks and potentially new jobs as a result of technology ) transference ( where tasks previously conducted by a worker are conducted by a consumer ) and intensification ( whereby technology schedules greater density of tasks , leading to negative impacts on the worker ) . 10 Evidence by Abigail Gilbert , Mary Towers and Andrew Pakes during APPG evidence sessions on the 18th May 2021 and 13th July 2021 . Regarding distribution of work , see also literatures on Routine Biased Change and the polarisation of labour markets ; and polarisation of hours of work . See in particular for a recent analysis of UK labour markets : Laws , Athene Helen . “ Inequality in Labour Markets . ” PhD diss. , University of Cambridge , 2020 . 11 Evidence by Tabitha Goldstaub during APPG evidence session on the 13th July 2021 . See also : Cooley , Mike . “ Human-centred systems . ” In Designing human-centred technology , pp . 133–143 . Springer , London , 1989 ; Olivieri , Emily , and Loredana Isacsson . “ Exploring guidelines for human-centred design in the wake of AI capabilities : A qualitative study . ” ( 2020 ) . 12 For some literature see : Muller , Zane . “ Algorithmic Harms to Workers in the Platform Economy : The Case of Uber . ” Colum . JL & Soc . Probs . 53 ( 2019 ) : 167 ; Wood , Alex J. Algorithmic management consequences for work organisation and working conditions . No . 2021/07 . JRC Working Papers Series on Labour , Education and Technology , 2021 ; Todolí-Signes , Adrián . “ Making algorithms safe for workers : occupational risks associated with work managed by artificial intelligence . ” Transfer : European Review of Labour and Research ( 2021 ) : 10242589211035040 ; Slaughter , Rebecca Kelly , Janice Kopec , and Mohamad Batal . “ Algorithms and Economic Justice : A Taxonomy of Harms and a Path Forward for the Federal Trade Commission . ” Yale Journal of Law & Technology 23 ( 2020 ) : S1-S1 . 13 The Good Work Charter . https : //www.ifow.org/publications/the-ifow-good-work-charter 14 IFOW ( 2021 ) The Good Work Monitor . https : //www.ifow.org/resources/the-good-work-monitor 15 Evidence by Abigail Gilbert during the APPG Evidence session on the 18th May 2021 , referencing the Amazonian Era : Gilbert , Abigail and Anna Thomas ( 2021 ) ‘ The Amazonian Era : How algorithmic systems are eroding good work ’ IFOW . https : //www.ifow.org/publications/the-amazonian-era-how-algorithmic-systems-are-eroding-good-work 16 In an IFOW survey in partnership with USDAW found 67 % of workers asked ‘ If my data is used to assess or make predictions about my performance , I know how it is used to do so ’ responded that they were ‘ not at all confident ’ ( N= 974 ) , fieldwork completed between August and October , 2020 . 17 Evidence by Mary Towers during APPG evidence session on the 18th May 2021 , referencing TUC report ‘ Technology managing people – The worker experience ’ : https : //www.tuc.org.uk/AImanifesto 18 Evidence by Abigail Gilbert and Mary Towers during APPG evidence session on the 18th May 2021 . 19 IFOW ( 2021 ) ‘ Mind the Gap : The final report of the Equality Task Force ’ : https : //www.ifow.org/publications/mind-the-gap-the-final-report-of-the-equality-task-force 20 As the CDEI have acknowledged , there is a need for concerted action to address the risks of automated decision making at work . https : //www.gov.uk/government/publications/cdei-publishes-review-into-bias-in-algorithmic-decision-makingThe New Frontier : Artificial Intelligence at Work 27 Endnotes The New Frontier : Artificial Intelligence at Work 28 Endnotes 21 Evidence from Helen Mountfield QC during the APPG evidence session held on the 18th May 2021 . See also : Birhane , Abeba . “ The Impossibility of Automating Ambiguity . ” Artificial Life 27 , no . 1 ( 2021 ) : 44–61 . 22 For an overview , see Leslie , David , et al ( 2021 ) ‘ Artificial Intelligence , Human Rights , Democracy and the Rule of Law : A Primer ’ The Alan Turing Institute . https : //www.turing.ac.uk/sites/default/files/2021-03/cahai_feasibility_study_primer_final.pdf 23 For an overview of human decisions taken in the design process , see the report of the Equality Task Force ( 2021 ) ‘ Mind the Gap : The final report of the Equality Task Force ’ : https : //www.ifow.org/publications/mind-the-gap-the-final-report-of-the-equality-task-force 24 An initial proposal for an Equality Impact Assessment , developed through consultation is set out in : Graham , Logan , Abigail Gilbert , Joshua Simons , Anna Thomas ( 2020 ) Artificial Intelligence in Hiring : Assessing Impacts on Equality . IFOW . https : //uploads-ssl.webflow.com/5f57d40eb1c2ef22d8a8ca7e/5f71d338891671faa84de443_IFOW % 2B- % 2BAssessing % 2Bimpacts % 2Bon % 2Bequality.pdf 25 See Gilbert , Abigail and Anna Thomas ‘ The Amazonian Era : How Algorithmic Systems are Eroding Good Work ’ IFOW 2021 ; and ‘ Case for the Importance of Good Work Through Technology Introduction ’ Forthcoming , IFOW CIPD and Carnegie . 26 Evidence by David Leslie during APPG evidence session on the 13th July 2021 . See also Human Rights , Democracy , and the Rule of Law Assurance Framework for AI Systems , the Turing Institute , 2021 . 27 There is growing support for the involvement of consumers of technology , particularly where those consumers are citizens . See : BEIS ‘ The Use of Public engagement for Technological Innovation ’ BEIS Research Paper Number 2021/003 This principle should be equally extended to workers . 28 The Good Work Charter . https : //www.ifow.org/publications/the-ifow-good-work-charter 29 Human decisions are taken at various stages in the creation of an algorithmic system . IFOW identify 7 key stages in the mind the gap report . Such human decisions should be understood and outlined for effective transparency . Algorithmic systems , which can be ‘ imported ’ to the UK without regulatory checks or certifications easily , as non-tangible goods , can be designed without due regard to UK law . This is outlined in : Graham , Logan , Abigail Gilbert , Joshua Simons , Anna Thomas ( 2020 ) Artificial Intelligence in Hiring : Assessing Impacts on Equality IFOW . https : //uploads-ssl.webflow.com/5f57d40eb1c2ef22d8a8ca7e/5f71d338891671faa84de443_IFOW % 2B- % 2BAssessing % 2Bimpacts % 2Bon % 2Bequality.pdf 30 This approach is already being taken by various international governments . See more : Moss , Emanuel , Elizabeth Anne Watkins , Jacob Metcalf , and Madeleine Clare Elish . “ Governing with algorithmic impact assessments : six observations . ” Available at SSRN 3584818 ( 2020 ) and Ada Lovelace Institute , AI Now Institute , and Open Government Partnership ( 2021 ) ‘ Algorithmic Accountability for the Public Sector ’ https : //www.adalovelaceinstitute.org/report/algorithmic-accountability-public-sector/ with methods for co-construction of impacts outlined in : Metcalf , Jacob , Emanuel Moss , Elizabeth Anne Watkins , Ranjit Singh , and Madeleine Clare Elish . “ Algorithmic impact assessments and accountability : The co-construction of impacts . ” In Proceedings of the 2021 ACM Conference on Fairness , Accountability , and Transparency , pp . 735–746 . 2021 . 31 While many workers are often unaware of the presence of algorithmic systems in the workplace , research also finds that employers are often unaware of what data is being collected and for what purposes : In 2019 , less than a third of CEOs who admitted they collect extensive data on their workforces personally feel that their companies use the data responsibly . Ellen Sheng . Employee Privacy in The U.S. is at Stake as Corporate Surveillance Technology Monitors Workers ’ Every Move , CNBC ( Apr . 15 , 2019 ) , https : //www.cnbc.com/2019/04/15/employee-privacy-is-at-stake-as-surveillance-tech-monitors-workers.html cited in Nelson , Josephine , Management Culture and Surveillance ( December 16 , 2019 ) . 43 Seattle U. L. Rev . 2 , 631 ( 2020 ) ( Berle XI symposium on Corporate Culture ) . Available at SSRN : https : //ssrn.com/abstract=3504408 32 In an IFOW survey in partnership with USDAW found 67 % of workers asked ‘ If my data is used to assess or make predictions about my performance , I know how it is used to do so ’ responded that they were ‘ not at all confident ’ ( N= 974 ) , fieldwork completed between August and October , 2020 . 33 For a discussion of the limitations of common ‘ transparency ’ approaches in AI governance , see : Ananny , Mike , and Kate Crawford . “ Seeing without knowing : Limitations of the transparency ideal and its application to algorithmic accountability . ” new media & society 20 , no . 3 ( 2018 ) : 973–989 . 34 We note existing rights and their limitations under the GPDR as set out in Mind the Gap ; and that some key rights and/or open access to them are currently the subject of a public consultation . In the mean time , we encourage voluntary disclosure of data protection impact assessments . Please see Prospect Union ’ s Guidance on DPIAs for further information . Note that some worker protections in the GPDR are currently subject to public consultation and therefore at risk . 35 https : //www.theguardian.com/us-news/2021/sep/10/california-bill-amazon-warehouse-quotas and https : //www.wired.com/story/opinion-bill-of-rights-artificial-intelligence/ 36 See an overview of the debate in : Casey , Bryan , Ashkon Farhangi , and Roland Vogl . “ Rethinking Explainable Machines : The GDPR ’ s ‘ Right to Explanation ’ Debate and the Rise of Algorithmic Audits in Enterprise . ” Berkeley Tech . LJ 34 ( 2019 ) : 143 . The New Frontier : Artificial Intelligence at Work 29 Endnotes 37 “ Differentiating the way you are providing information in an audience-responsive manner can help you avoid creating explanation fatigue in your customers ( by saying too much ) and at the same time allow you to protect your intellectual property and safeguard your system from being gamed . ” https : //ico.org.uk/for-organisations/guide-to-data-protection/key-dp-themes/explaining-decisions-made-with-ai/ 38 For an overview of responsibilities , see : https : //www.gov.uk/informing-consulting-employees-law 39 TUC ( 2020 ) ‘ Technology managing people – The worker experience ’ . https : //www.tuc.org.uk/AImanifesto 40 Evidence by James Bloodworth during APPG evidence session on the 18th May 2021 . 41 Evidence provided by Abigail Gilbert to the evidence session on the 18th May 2021 drawing on IFOW ( 2021 ) An Amazonian Era , suggests that the deployment of some algorithmic systems without due regard to workers needs could be undermining productivity , rather than enhancing it . 42 The Amazon era provides evidence of the ‘ liquidisation ’ of the work force in Part 3 . The transformation of contracts as enabled and aligned to greater prediction of demand for labour via algorithm is also discussed in : https : //www.tuc.org.uk/AImanifesto 43 There is a growing debate around how to classify algorithmic systems , or AI , as High Risk . As noted by Jeremias Prassl in his evidence , the EU are considering all work-based applications as potentially high risk . The EU ’ s proposed AI Regulation bans applications which could cause “ physical or psychological ” harm through the use of “ subliminal techniques ” or by exploiting vulnerabilities of a “ specific group of persons due to their age , physical or mental disability . ” This would render many of the systems identified in recent research , such as The Amazonian Era , high risk . 44 Note TUC Manifesto additional proposals which could supplement our recommendations in due course . In this report we are focusing on top recommedations only : https : //www.tuc.org.uk/AImanifesto 45 We heard that the use of algorithmic systems can strategically reduce levels of communication within organisations . See for instance : Amazonian Walker , Michael Brian . “ Disrupting Precarity : An Enquiry into Worker Voice in Nonstandard Employment . ” PhD diss. , 2020 . 46 Evidence by James Bloodworth during APPG evidence session on the 18th May 2021 . 47 See more information on this process in : Soofi , Aized Amin , and Arshad Awan . “ Classification techniques in machine learning : applications and issues . ” Journal of Basic and Applied Sciences 13 ( 2017 ) : 459–465 . And an identification of issues as they relate to work , among other contexts in : https : //www.gov.uk/government/publications/cdei-publishes-review-into-bias-in-algorithmic-decision-making 48 Professor Jeremias Prassl noted in his evidence to the inquiry that the model of Works Councils in Germany proved constructive in the development and implementation of technology in the workplace . 49 CDEI review into bias in algorithmic decision-making : https : //www.gov.uk/government/publications/cdei-publishes-review-into-bias-in-algorithmic-decision-making 50 Evidence by Helen Mountfield QC , Emma Wright and Jeremias Prassl during APPG evidence session on the 18th May 2021 . 51 Evidence by Helen Mountfield QC , Emma Wright and Jeremias Prassl during APPG evidence session on the 18th May 2021 . 52 This could run in a similar format to the model developed by the ICO : https : //ico.org.uk/for-organisations/regulatory-sandbox/ 53 Good Work is defined by the Charter principles set out here : https : //www.ifow.org/publications/the-ifow-good-work-charter 54 A Work 5.0 Strategy could mirror the approach taken in the Danish Disruption Council , or German Work 4.0 strategies . For more information see : ‘ A Better Future for Work : the World after Covid-19 ’ Future of Work Commission , IFOW 2020 . 55 ‘ European Union and the United States intend to jointly undertake an economic study examining the impact of AI on the future of our workforces , with attention to outcomes in employment , wages , and the dispersion of labour market opportunities . Through this collaborative effort , we intend to inform approaches to AI consistent with an inclusive economic policy that ensures the benefits of technological gains are broadly shared by workers across the wage scale ’ . AcknowledgementsThe New Frontier : Artificial Intelligence at Work 30 With special thanks to the following experts who gave evidence during the APPG ’ s inquiry sessions : Professor Jeremias Adams-Prassl Jeremias is Professor in the Faculty of Law at the University of Oxford . Jeremias is primarily interested in Employment Law and European Union Law . He is the author of The Concept of the Employer , a co-editor of The Autonomy of Labour Law , and one of the editors of The Contract of Employment . James Bloodworth James is a writer and journalist . He is a former editor of the blog Left Foot Forward , and his work has appeared in the Guardian , Spectator , Independent and Wall Street Journal . James is the author of ‘ Hired : Six Months Undercover in Low-Wage Britain ’ ( 2018 ) , which has been longlisted for the 2019 Orwell Prize . Dr Abigail Gilbert Abby is Head of Research at IFOW and was co-author with Anna Thomas of ‘ An Amazonian Era : How Algorithmic Systems are Eroding Good Work ’ . Tabitha Goldstaub Tabitha is the Chair of the UK Government 's AI Council and a member of the TechUK board . Tabitha is the co-founder of CogX , a festival and online platform that enables thousands of thought leaders to host their own public or private live video sessions and build interactive meaningful conversations with their audience . Anne-Marie Imafidon MBE Anne-Marie is Head Stemette and co-founder of Stemettes – an awardwinning social enterprise inspiring girls and young women into Science , Technology , Engineering and Mathematics roles . Anne-Marie is a Trustee at IFOW.Dr David Leslie David is the Ethics Theme Lead at The Alan Turing Institute . He is the author of the UK Government ’ s official guidance on the responsible design and implementation of AI systems in the public sector , a co-badged guidance on AI explainability published by the ICO and The Alan Turing Institute . Helen Mountfield QC Helen is a renowned practitioner and expert in constitutional , human rights and equality law . Helen was co-chair , of the independent Future of Work Commission and chair of the IFOW ’ s Equality Task Force . Andrew Pakes Andrew is the Research Director and one of the Deputy General Secretaries at Prospect Union representing over 152,000 members across tech , specialist , engineering and professional roles . He leads Prospect ’ s work around tech , AI , data rights and the future of work . He is also a Visiting Fellow at the ESRC funded Digital Futures of Work Research Centre looking at worker experiences of digital surveillance . Mary Towers Mary is an employment rights officer at the Trade Union Congress ( TUC ) and has been leading their AI project alongside a union working group , looking at the use of AI in the employment relationship . The group published a research report in 2020 and manifesto and legal report in March 2021 . Emma Wright Emma is Director of the Institute of AI , a cross party non-profit , working with legislators across the globe . This report was commissioned by the All-Party Parliamentary Group on the Future of Work.It was researched and written with support from The Institute for the Future of Work . This is not an official publication of the House of Commons or the House of Lords . It has not been approved by either House or its committees . All-Party Parliamentary Groups are informal groups of Members of both Houses with a common interest in particular issues . The views expressed in this report are those of the group.The All Party Parliamentary Group on the Future of Work The All Party Parliamentary Group on the Future of Work brings together parliamentarians , industry and civil society to foster understanding of the challenges and opportunities of technology and the future of work . We collaborate to develop practical solutions that will shape a future of better work across the UK . The Institute for the Future of Work The Institute for the Future of Work is an independent think tank exploring how new technologies are transforming work and working lives . We research and develop practical solutions to promote people ’ s future wellbeing and prosperity . Co-founded by Nobel prize winning economist Sir Christopher Pissarides , technologist Naomi Climer CBE and employment barrister Anna Thomas , we work at the intersection of government , industry and civil society to shape a fairer future through better work . Report informationThe New Frontier : Artificial Intelligence at Work 31 Copies of the report can be downloaded from the APPG website at : www.futureworkappg.org.ukappg
