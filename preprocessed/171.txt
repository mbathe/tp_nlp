briefing legislation progress eprs european parliamentary research service author tambiama madiega members research service september artificial intelligence act overview european union lawmakers signed artificial intelligence act june act first binding worldwide horizontal regulation sets common framework use supply systems new act offers classification systems different requirements obligations tailored approach systems presenting risks prohibited wide range systems detrimental impact people health safety fundamental rights authorised subject set requi rements obligations gain access market systems posing limited risks lack transparency subject information transparency requirements systems presenting minimal risk people subject obligations regulation also lays specific rules general purpose gpai models lays stringent requirements gpai models capabilities could pose systemic risk significant impact internal market act publi shed official journal july entered force august proposal regulation european parliament council laying harmonised rules artificial intelligence artificial intelligence act amending certain union legislative acts committees responsible rapporteurs shadow rapporteurs internal market consumer protection imco civil liberties justice home affairs libe jointly rule brando benifei italy dragoş tudorache renew romania deirdre clune axel voss epp petar vitanov svenja hahn renew sergey lagodinsky kim van sparrentak rob rooken kosma złotowski ecr jean lacapelle jaak madison cornelia ernst kateřina konecna left com cod ordinary legislative procedure cod parliament council equal footing formerly procedure completed regulation eprs european parliamentary research service introduction technologies expected bring wide array economic societal benefits wide range sectors including environment health public sector finance mobility home affairs agriculture particularly useful improving prediction optimising operations resource allocation personalisi however implications systems fundamental rights protected charter fundamen tal rights well safety risks users technologies embedded products services raising concern notably systems may jeopardise fundamental rights right non freedom expression man dignity personal data protection given fast development technologies recent years regulation become central policy question european union policy pledged develop tric approach ensure europeans benefit new technologies developed functioning according values principles white paper artificial intelligence european commission committed romote uptake address risks associated ertain uses new technology initially adopted soft approach publication non ethics guidelines trustworthy policy investment recommendations european commission shifted towards legislative approach calling adoption harmonised rules development placing market use systems leading debate parliament called commission assess impact draft framework wide recommendations civil law rules robotics parliament adopted number gislative resolutions calling well two legislative resolutions asking commission establish legal framework ethical principles development eployment use robotics related technologies union harmonising legal framework civil liability claims imposition regime strict liability operators high systems past council repeatedly called adoption common rules including council called upon commission put forward concrete proposals hat take existing legislation account follow risk proportionate necessary regulatory approach commission launched broad public consultation published impact assessment regulation artificial intelligence supporting study draft proposal received feedback impact assessment commission identified several problems raised development use systems due specific characteristics namely opacity limited ability human mind understand certain systems operate complexity iii continuous adaptation unpredictability autonomous behaviour functional dependence data quality data incr easing num ber countries worldwid designing implementing governance legisla tion policies united sta initially taken lenient approach towards calls regulation recently mounting white house released blueprint bill rights set guidelines protect rights american public age president joe biden signed executive order chinese government agencies approved guidelines generative announced pro approach regulation largely regulates via existing laws international level organisation economic development oecd adopted principles unesco embraced set recommendations ethics agreed ome international guiding principles artificial intelligence council europe adopted international convention may furthermore context new established tech partnership trade technology council seek ing develop mutual understanding principles underpinning trustworthy responsible artificial intelligence act changes proposal would bring draft act designed horizontal legislative instrument applicable systems placed market used union based article article treaty functioning eur opean union tfeu following logic new legislative framework nlf approach ensuring range products comply applicable legislation placed market conformity assessments use marking commission proposed enshrining law legal definition system referring range software technologies using specific tec hniques approaches machine learning knowledge systems statistical approaches could complemented adoption delegated acts factor technological developments commission also proposed adopt approach whereby legal intervention tailored concrete level risk four categories identified first draft act proposed explicitly ban following harmful practices considered clear threat people safety livelihoods rights owing risk create systems deploy harmful manipulative techniques systems exploit specific vulnerable groups physical mental disability systems used public authorities behalf social scoring purposes remote biometric identification systems publicly accessible spaces law enforcement purposes except limited number cas second draft act proposed regulate high systems create adverse impact people safety fundamental rights draft text distinguished two categories systems systems used safety component product falling health safety harmonisation legislation toys aviation cars medical devices lifts systems deployed eight specific areas specified annex law enforcement commission could update nece ssary delegated acts risk systems would comply range requirements particularly risk management testing technical robustness data training data governance transparen human oversight cybersecurity placed market put service systems conform new harmonised standards would benefit presumption conformity draft act requirements third systems presenting limited risk systems tha interact humans chatbots emotion recognition systems biometric categorisation systems systems generate manipulate image audio video content deepfakes would subject limited set transparency obligations finally systems presenting low minimal risk could developed used without conforming additional legal obligations however proposed act envisaged creation codes conduct encourage providers non systems apply mandatory requirements high systems voluntarily proposal required member states designate one competent authorities including national supervisory authority tasked supervis ing regulation application implementation proposed establish european artificial intelligence board composed representatives member states commission level national market surveillance authorities would assess operators compliance obligations requirements systems administrative fines varying scales depending severity infringement set sanctions compliance act eprs european parliamentary research service measures tail ored foster investments commission proposed member states european data protection supervisor could establish regulatory sandbox controlled environment facilitates development testing validation innovative systems limited period time put market sandboxing would enable participants use personal data foster innovation without prejudice gdpr requi rements proposed measures tailored specifically small providers ups advisory committees european economic social committee european committee regions adopted opinions respectively nationa parliaments deadline submission reasoned opinions grounds subsidiarity september contributions received czech chamber deputies czech senate portuguese parliament polish senate german bundesrat stakeholder definitions contentious point discussion among stakeholders big data value association industry int ernational organisation stressed definition systems quite broad would cover far subj tively understood including simplest search sorting routing algorithms would consequently subject new rules furthermore asked clarification components larger systems pre components manufacturers components released separately treated amcham american chamber commerce suggested avoiding adopting narrower definition systems focusing strictly high plications extended applications high risk software general generally welcomed proposed act approach stakeholders supported wider prohibition regulation systems civil rig hts organisations called ban indiscriminate arbitrarily targeted use biometrics public publicly accessible spaces restrictions uses systems including border control predictive policing european enterprises alliance stressed general uncertai nty roles responsibilities different actors value chain developers providers users systems particularly challenging companies providing general purpose applicatio programming interfaces open models specifically intended high systems nevertheless used third parties manner could considered high risk also called redefined based measurable harm potenti impact algorithmwatch underlined applicability specific rules depend type tech nology impact individuals society called new rules defined according impact systems recommend every operator conduct impact assessment assesses system risk levels case basis climate change called climate change mitigation adaptatio taken account classification rules high systems impose environmental protection requirements european consumer organisation beuc stressed proposal required substantial improvement guarantee consumer protection organisation argued proposal broader scope impose basic principles obligations fairness accou ntability transparency upon systems well prohibiting comprehensively harmful practices private entities use social scoring remote biometric identification systems public spaces furthermore consumers granted strong set rights effective remedies redress mechanisms including collective redress artificial intelligence act opposing views impact proposed regulation investment study centre data innovation representing large online platforms highlighted compliance costs incurred proposed act would likely provoke chilling effect investment europe could particularly deter medium enterprises smes developing systems according study act would cost european economy billion next five years reduce investments almost however estimates ompliance costs challenged experts centre european policy studies well economists european digital sme alliance warned overly stringent conformity requirements asked effective sme representation standards procedures mandatory sandboxes member states academic views generally supporting commission pro posal critics called amendments including revising systems definition ensuring better allocation responsibility strengthening enforcement mechanisms fostering democratic among main issues systems defi nition legal definition systems contained proposed act heavily criticised smuha warned definition lacks clarity may lead legal uncertaint especially systems would qualify systems draft text use may adverse impact fundamental address issue authors proposed broaden legislation scope include explicitl computational systems used identified high domains regardless whether considered ebers consider scope systems overly broad may lead legal uncertainty developers operators users systems ultimately called law exempt systems developed used research purposes open software oss regulation commentators questioned whether proposed definition systems truly technology neutral refers primarily oftware omitting potential future developments approach academics also called amendments warning risk approach proposed commission would ensure high level protection fundamental rights smuha argued proposal always accurately recognise wrongs harms associated different kinds systems therefore appropriately allocate responsibility among things recommended adding procedure enables commission broaden list prohibited systems proposed banning existing manipulative systems deepfakes social scoring biometrics ebers called detailed classification risks facilitate industry self support well prohibiting systems biometrics including context priv ate use furthermore highlighted draft legislation address systemic sustainability risks created especially area climate environmental one major concerns raised rules prohibited high practices might prove ineffective practice risk assessment proposed left provider self assessment veale zuiderveen borgesius warned providers arbitrarily classify high systems adhering rules using self procedures alone smuha recommended exploring whether certain high systems would benefit conformity assessment carried independent entity prior deployment eprs european parliamentary research service biometrics regulation study commissioned european parliament recommended inter alia empower commission adapt list prohibited practices periodically und supervision european parliament adoption comprehensive list applications comprising remote biometric identification without limitation law enforcement purposes regulation facial recognition technologies frts one contentious european data protection supervisor edps european data protection board edpb called general ban uses automated recognition human features publicly accessible spaces governance structure enforcement redress mechanisms ebers stressed act lacks effective enforcement structures commission proposed leave preliminary risk assessment including qualification high providers self also raised concerns excessive delegation regulatory power private european standardisation organisations esos due lack democratic oversight impossibility stakeholders civil society organisations consumer associations influence dev elopment standards lack judicial means control adopted instead recommended act codify set legally binding requirements high systems esos may specify harmonised andards commentators regretted crucial gap act lack provision provide individu enforcement rights ebers stressed individuals affected systems civi rights organisations right complain market surveillance authorities sue provider user failure comply requirements similarly veale zuiderveen borgesius rned provisions draft legislation aim impose obligations systems users mechanism complaint judicial redress available smuha recommended amending proposal include inter alia explicit right redress individuals consultation participation citizens regarding decision amend list high risk systems annex iii also stressed text proposed commission lacked proper coordination mechanisms authorities particular concerning cross infringement furthermore guidance would desirable ensure compliance transparency information requirements simultaneously protecting intell ectual property rights trade secrets least avoid diverging practices member states artificial intelligence act legislative process negotiation phase council adopted common position december parliament file assigned jointl rule committee internal market consumer protection imco committee civil liberties justice home affairs libe brando benifei italy dragoş tudorache renew romania appointed rapporteurs par liament adopted negotiating position june substantial amendments commission text trilogue meetings took place june july septem ber october december following protracted negotiations council presidency european parliament negotiators reached provisional agreement act december regulation adopt parliament march council may act formally signed june published official journal july enter force august final text definitions act enshrines law definition systems aligned revised definition agreed oecd system machine system designed operate varying evels autonomy may exhibit adaptiveness deployment explicit implicit objectives infers input receives generate outputs predictions content recommendations decisions influence hysical virtual environments definition intended cover simpler traditional software systems programming approaches commission tasked develop guidelines application act also contains definition general purpose artificial intelligence gpai models trained large amount data using self scale display generality competently perform wide range distinct tasks integrated variety downstream systems applications furthermore act defines general systems systems based gpai model capability serve variety purposes direct use well integra tion systems scope application act applies primarily providers deployers putting systems gpai models service placing market place establishment located well deployers providers systems established third country output produced systems used however systems placed market put service used public private entities military defence national security purposes excluded scope similarly act apply systems models including output specifically developed put service sole purpose scientific research development furthermore matter principle regulation apply prior systems models put service placed market sandboxing rules may apply case eprs european parliamentary research service act approach data source european commission act adopts approach classifies systems several risk categories different degrees regulation applying prohibited practices final text prohibits wider range practices originally proposed commission harmful impact systems using subliminal manipulative deceptive techniques distort people group people behaviour impair informed decision making leading significant harm systems exploiting vulnerabilities due age disability social economic situations causing significant harm biometric categorisation systems inferring race political opinions trade union membership religious philosophical beliefs sex life sexual orientation except lawful labelling filtering law purposes systems evaluating classifying individuals oups based social behaviour personal characteristics leading detrimental disproportionate treatment unrelated contexts unjustified disproportionate behaviour remote biometric identification public spaces law enforcement except specific necessary objectives searching victims abduction sexual exploitation missing persons preventing certain substantial imminent threats safety identifying suspects serious crimes syst ems assessing risk individuals committing criminal offences based solely profiling personality traits characteristics except supporting human assessments based objective verifiable facts linked criminal activity artificial intelligence act systems creating expanding facial recognition databases untargeted scraping internet cctv footage systems inferring emotions workplaces educational institutions except medical safety reasons high systems act identifies number use cases systems considered high risk potentially create adverse impact people health safety fundamental rights risk classification based intended purpose system function performed system specific purpose modalities system used key determine system high high systems safety components products cover sectoral law medical devices systems matter principle considered high risk used specific areas listed annex commission tasked maintaining database high systems listed annex new test enshrined parliament request provision according systems considered high risk hey pose significant risk harm health safety fundamental rights natural however system always considered high risk system performs profiling natural persons providers high systems run conformit assessment procedure products sold used need comply range requirements including testing data training cybersecurity cases cond uct fundamental rights impact assessment ensure systems comply law conformity assessment carried either based internal control self involvement notified body biometrics complian european harmonised standard developed grant high systems providers presumption conformity systems placed market providers must implement post monitoring take corrective actions nece ssary transparency risk certain systems intended interact natural persons generate content may pose specific risks impersonation deception irrespective whether qualify risk systems systems subje information transparency requirements users must made aware interact chatbots deployers systems generate manipulate image audio video content deep fakes must disclose content artific ially generated manipulated except limited cases used prevent criminal offence providers systems generate large quantities synthetic content must implement sufficiently reliable interoperable effective robust techniques methods watermarks enable marking detection output generated manipulated system human employers deploy systems workplace must inform workers representatives inimal risks systems presenting minimal risk people spam filters subject obligations beyond current applicable legislation gdpr eneral gpai regulation provides specific rules general purpose models general models pose systemic risks gpai system transparency requirements gpai models draw maintain technical documentation make information documentation available downstream providers systems providers gpai models put policy place respect union copyright law including state technologies eprs european parliamentary research service watermarking carry lawful data exceptio envisaged copyright directive furthermore gpais must draw make publicly available sufficiently detailed summary content used training gpai models according template provided finally located outside appoint representative however models made accessible free open source exempt obligations disclosure technical documentation given principle positive effects research innovation systemic gpai obligations gpai models capabilities could pose systemic risk significant impact internal market due reach actual reasonably foreseeable negative effects public health safety public security fundamental rights society whole gpa providers must therefore notify european commission model trained using total computing power exceeding flops floating operations per second threshold met presumption model gpa model posing systemic risks addition requirements transparency copyright protection falling gpai models providers systemic gpai models required constantly assess mitigate risks pose ensure cybersecurity protection requires inter alia keep ing track document ing report ing serious incidents violations fundamental rights implement ing corrective measures codes practice presumption conformity gpai model provi ders able rely codes practice demonstrate compliance obligations set act means implementing acts commission may decide approve code practice give general validity within alterna tively provide common rules implement ing relevant obligations compliance european harmonised standard grants gpai providers presumption conformity providers gpai models systemic risks adhere approved code practice required demonstrate adequate alternative means compliance sandboxing real testing measures support investment systems strengthened national authorities must establish least one regulatory sandbox national level facilitate development testing innovative systems strict regulatory regulatory sandbox provide controlled environment fosters innovation facilitates development training testing validation innovative systems limited time placement market entry service regulatory sandbox must enable appropriate testing systems real conditions outside laboratory limited period subject compliance data protection law rules principles furthermore accelerate development placing market high systems providers prospective providers systems may also test conditions even without participating regulatory sandbox respect guarantees conditions ask specific consent submit real testing plan market surveillance authority enforcement institutional setting implementation act responsibility number national actors member states must establish designate least one market surveillance authority least one notifying authority ensure application implementation act heavy fines fall level range actors including commission board artificial intelligence act office standardisation bodies cen cenelec advisory forum scientific panel independent experts support implementation act office established provide advice implementation new rules particular regards gpai models develop codes practice support proper application act force timelines prohibited systems must phased within months act entry force provisions concerning gpai penalties apply months act enters force concerning high systems apply months entry force months aft entry force systems covered existing product legislation codes practice env isaged must ready latest nine months act enters force implementation act requires number steps taken coming months commission expected issue various implementing delegated acts guidelines codes practices related oversee standardisation process required implementing obligations parliament exercise scrutiny powers implementing phase reactivation intergroup artificial intelligence digital adoptin formal objections harmonised standards article regulation commission delegated implementing acts rule rule parliament rules procedure latest issues olicy debate academics raised several questions regard ing act final text implementation challenges lying ahead hacker welcomes final act stresses inter alia alignment existing sectoral regulation incomplete results unnecessary ighly detrimental red tape compliance costs substantial especially smes developing narrow models threshold flops default categori sation systemic risk models high european supervision monitoring remote biometric identification needed avoid risk member states circumvent rules enshrined kutterer argues act implementation require robust taxonomy setting correlation risk classification model capabilities asses sing developments open sources helberger act complemented additional set exercisable rights protect citizens rom harm additional legislation cont rol potential environmental impact training models protect worker rights define set requirements research organisations must comply benefit research furthermore argue act far enough preventing mitigating specific risks associated chatbots timely standardisation key ensur ing adequate impl ementation act instance ensure robustness high systems watermarking generated content meantime fostering adoption voluntary codes conduct pact mitigate potential downsides generative academics warn standardisation codification processes might inc lude representative groups stakeholders adequately address fundamental rights impact assessment fria ensuring international harmonisation governance become key topic policymakers cooperation aligning governance seen crucial democratic gover key questions setting common terminology addressing dual use military applications ave raised respect finally generative seen disruptive technology likely mean amending laws regulation lawmakers considering whether legislate areas workplace competition generative much uncertainty regarding openness generative energy sustainability course intellectual property right possible revision copyright directive eprs european parliamentary research service european parliament supporting analysis eprs repository stoa centre artificial intelligence wendehorst duller biometric recognition behavioural detection policy department citizens rights constitutional affairs european parliament dalli artificial intelligence act initial appraisal european commission impact assessment eprs european parliament dumbrava artificial intelligence borders overview applications key issues eprs european parliament madiega artificial intelligence act regulatory sandboxes eprs european parliament march madiega general artificial intelligence eprs european parliament march madiega generative watermarking eprs european parliament december madiega ilnicki investment global indicators eprs european parliament madiega mildebrath regulating facial recognition eprs european parliament sources artificial int elligence act european parliament legislative observatory oeil hacker comments final trilogue version act novelli generative law liability privacy intellectual property cybersecurity endnotes see european commission proposal regulation european parliament council laying harmonised rules artificial intelligence artificial intelligence act cod explanatory memorandum see instance high expert group ethics guidelines trustworthy see inter alia recommendations intellectual property criminal law education culture audiovisual areas regarding civil military uses overview dalli artificial intelligence act proposed allow frts targeted search potential victims crime including missing children prevent specific substantial imminent threat life physical safety persons terrorist attack iii detection localisation identification prosecution perpetrator individual suspected criminal offence referred european arrest warrant framework decision section aims provide flavour debate intended exhaustive account different views proposal additional inf ormation found publications listed analysis analysis proposals recommendations amendments see smuha achieve legally trustworthy esponse european commission proposal artificial intelligence act elsevier august ebers european commission posal rtificial intelligence ritical assessment embers robotics law society rails vol october smuha veale zuiderveen demystifying draft act vol computer law review international july see ebers see galaz artificial intelligence systemic risks sustainability vol technology society overview see madiega mildebrath regulating facial recognition act applies private organisations well public authorities annex refers systems used areas critical infrastructures road traffic education vocational training employment worker management access self access essential private public services benefits creditworthiness evaluation law enfo rcement border control administration justice democratic processes biometric identification categorisation emotion recognition systems outside prohibited categories system considered high one following criteria fulfilled system intended perform narrow procedural task system intended improve result previously completed human activity iii system intended detect decision patterns deviations prior decision patterns meant replace influence previously completed human assessment without proper human review system intended perform preparatory task assessment relevant purpose use cases listed annex iii artificial intelligence act stablished european commissi decision january office enter force february furthermore open models must comply int egrated prohibited practices high systems considered present systemic risk flops floating operations per second measure computer processing speed threshold adjusted time reflect technological industrial changes moreover commission entitled take individual decisions designating gpai model posing systemic risk found model capabilities impa equivalent captured flop threshold basis overall assessment criteria quality size training data set number business end users degree autonomy scalability president biden executive order set flops threshold odels need reported government details training capabilities security additional regulatory sandboxes regional local levels jointly member states competent authorities may also establishe european data protection supervisor may also establish regulatory sandbox institutions bodies agencie instance million total worldwide annual turnover preceding financial year whichev higher infringements prohibited practices non related requirements data implementing acts must adopted commission stablish common specifications req uirements high systems pprove codes practice enerated manipulated content specify common rules implementation codes practice deemed adequate delegated acts need adopted identify onditions system considered high pecify update criteria gpai posing systemic risk inter alia office draw codes practice gpai providers commis sion mandated european standardisation organisations cen deliver series european standards implement act january see hacker comments inal trilogue version see kutterer regulati foundation models act igh systemic risk see helberger amsterdam paper recommendations technical finalisation regulation gpai act see also chavez challenge balancing pen closed systems see engler diverge regulation transatlantic comparison steps alignment disclaimer copyr ight document prepared addressed members staff european parliament background material assist parliamentary work content document sole responsibility author opinions expressed herein taken represent official position parliament reproduction translation non purposes authorised provided source acknowledged european parliament given prior notice sent copy european union eprs contact intranet internet blog fourth edition legislation progress briefings updated key stages legislative procedure
