iEveryday Ethics for Artificial Intelligence ii iiiIBM , the IBM logo and ibm.com are trademarks of International Business Machines Corp. , registered in many jurisdictions worldwide . Other product and service names might be trademarks of IBM or other companies . A current list of IBM trademarks is available on the Web at “ Copyright and trademark information ” at www.ibm.com/legal/us/en/copytrade.shtml This document is current as of the initial date of publication and may be changed by IBM at any time . Not all offerings are available in every country in which IBM operates . The information in this document is provided “ as-is ” without any warranty , express or implied , including without any warranties of merchantability , fitness for a particular purpose and any warranty or condition of noninfringement . IBM products are warranted according to the terms and conditions of the agreements under which they are provided . This report is intended for general guidance only . It is not intended to be a substitute for detailed research or the exercise of professional judgment . IBM shall not be responsible for any loss whatsoever sustained by any organization or person who relies on this publication.© Copyright IBM Corp. 2014 , 2015 , 2016 , 2017 , 2018 , 2019 , 2020 , 2021 , 2022 iv vFrancesca Rossi AI Ethics Global Leader , IBM Fellow IBM Research Noah Treviño IBM Design Program Office Visual Designer Almas Ahmed IBM Blue Studio DesignerAcknowledgementsEveryday Ethics for Artificial Intelligence IBM Design Program Office vi viiIf you have questions , comments or suggestions please email edethics @ us.ibm.com to contribute to this effort . Adam Cutler IBM Distinguished Designer , IBM Design for AI Milena Pribić Senior Designer , IBM Design for AITable of Contents Using this Document Introduction Five Practices of Everyday Ethics Consider outcomes Align with norms and values Minimize bias and improve inclusivity Ensure explainability Protect user data Closing References08 10 12 16 22 28 36 42 48 50 8 9Ethics must be embedded in the design and development process from the very beginning of AI creation . Everyday Ethics for AI is meant to guide team discussions and daily practices. “ You can use an eraser on the drafting table or a sledgehammer on the construction site. ” Frank Lloyd Wright– IBM embraces five foundational pillars of trustworthy AI : Explainability , Fairness , Robustness , Transparency , and Privacy.1 These pillars underpin the development , deployment and use of AI systems . This document and IBM ’ s trustworthy AI pillars are meant to help you align on both process and outcomes . This is a living document . Please experiment , play , use , and break what you find here and send us your feedback.Designers and developers of AI systems are encouraged to be aware of these concepts and seize opportunities to put these ideas into practice . As you work with your team and others , please share this guide with them . Introduction Ethical decision-making isn ’ t just another form of technical problem solving . As AI designers and developers , we hold a vast share of the collective influence . We are creating systems that will impact millions of people . AI is rapidly growing in capability , impact and influence . As designers and developers of AI systems , it is an imperative to understand the ethical considerations of our work . A technology-centric focus that solely revolves around improving the capabilities of an intelligent system doesn ’ t sufficiently consider human needs . A trustworthy , human-centric AI system must be designed and developed in a manner that is aligned with the values and principles of the society or community it affects . Ethics is a set of moral principles which help us discern between right and wrong . AI ethics is a set of guidelines that advise on the design , development , and use of artificial intelligence.2 To create and foster trust between humans and machines , you must understand the ethical resources and standards available for reference during the Specific virtues and practices to promote . Guidance for designers and developers building and training AI.This guide provides discussion points concerning : – – design , building , and maintenance of AI . The large-scale focus on AI ethics by groups like the World Economic Forum , the Future of Privacy Forum , the Partnership on AI , and the IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems , should be mirrored in businesses and working groups of all sizes . The criteria and metrics for trustworthy AI systems will ultimately depend on the industry and use case they operate within . We hope this document serves as a central source that helps teams establish best practices . Designers and developers should never work in a vacuum and must stay in tune with users ’ needs and concerns . Constant improvement and assessment is key to ensuring that design and development teams address users ’ concerns . This document provides teams with a starting point and will surely evolve as AI capabilities continue to grow . 10 11 Five Practices of Everyday Ethics Five Practices of Everyday EthicsIt ’ s our collective responsibility to understand and evolve these ethical practices as AI capabilities increase over time . These practices provide an intentional framework for building and using AI systems alongside IBM ’ s five pillars of trustworthy AI . Take accountability for the outcomes of your AI system in the real world , no matter your role . Be sensitive to a wide range of cultural norms and values , not just your own . Work with your team to identify and address biases and promote inclusive representation . Ensure humans can perceive , detect , and understand an AI decision process . Preserve and fortify users ’ power over their own data and its uses . Designers and developers of AI who want to go deeper into these practices should consider IBM ’ s Team Essentials for AI course that trains practitioners on relevant design thinking methods.3 In addition , IBM Research has made their Trustworthy AI toolkits publicly available for use by developers and data scientists.4 They include : 01 AI Explainability 360 : This open source toolkit includes an extensive set of techniques as well as guidance on how to choose the explainability algorithm that ’ s right for your use case . 02 AI Fairness 360 : This is an open source software toolkit that enables developers to use state-of-the-art algorithms to regularly check for unwanted biases from entering their machine learning pipeline and to mitigate any biases that are discovered.03 AI FactSheets 360 : Similar to nutrition labels for food or information sheets for appliances , this project increases transparency so that AI consumers better understand how the AI model or service was created . 04 Adversarial Robustness Toolbox : These tools enable developers and researchers to evaluate and defend machine learning models and applications against the adversarial threats of evasion , poisoning , extraction , and inference . 05 AI Privacy 360 : This toolbox includes several tools to support the assessment of privacy risks of AI-based solutions , and to help them adhere to any relevant privacy requirements . Tradeoffs between privacy , accuracy , and performance can be explored at different stages in the ML lifecycle . 13 12 14 15Running Example Five Practices of Everyday EthicsAgentive-style assistance . Introduction to their room and services in their preferred language . Control of room facilities through natural language . Sending a request directly to the service team through the in-room virtual assistant.A hotel chain wants to embed AI into an in-room virtual assistant/concierge to augment and personalize their users ’ stays . We ’ ll use the project team in charge of this effort as an example throughout the document . This conversational agent will include capabilities such as : – –– – Five Practices of Everyday EthicsConsider outcomes Human judgment plays a role throughout a seemingly objective system of logical decisions . It is humans who write algorithms , who define success or failure , who make decisions about the uses of systems and who may be affected by a system ’ s outcomes . Our level of accountability is also related to AI transparency , meaning everyone involved should be aware of what data is collected , how it ’ s used and stored , and who has access to it . Every person involved in the creation of AI at any step is accountable for considering the system ’ s impact in the world , as are the companies invested in its development . “ AI recommendations give data points for managers to consider , but the decision-making and accountability remains with people. ” –Responsible Use of Technology : The IBM Case Study , WEF5 17 16Take accountability for the outcomes of your AI system in the real world , no matter your role . 18 1902 Understand where the responsibility of the company/software ends . You may not have control over how data or a tool will be used by a user , client , or other external source.01 Make company policies clear and accessible to design and development teams from day one so that no one is confused about issues of responsibility or accountability . As an AI designer or developer , it is your responsibility to know . 04 Adhere to your company ’ s business conduct guidelines . Also , understand national and international laws , regulations , and guidelines6 that your AI system may have to work within . You can find other related resources in the IEEE Ethically Aligned Design document.7Recommended actions to take 03 Keep detailed records of your design processes and decision making . Determine a strategy for keeping records during the design and development process to encourage best practices and iteration . Five Practices of Everyday EthicsTo consider Understand the workings of your AI system even if you ’ re not personally developing and monitoring its algorithms . The entire team should work together to choose robust components that minimize risks and enable users ’ confidence in system outcomes.8 Refer to secondary research by sociologists , linguists , behaviorists , and other professionals to understand ethical issues in a holistic context.Questions for your team How does accountability change according to the levels of user influence over an AI system ? Is the AI to be embedded in a human decision-making process , is it making decisions on its own , or is it a hybrid ? How will our team keep records of our process ? How do we keep track of ethical design choices and considerations after the launch of the AI system ? Will others new to our effort be able to understand our records ? 20 21– – The team utilizes design researchers to contact real guests in the hotels to understand their wants and needs through face-to-face user interviews.The team considers their own responsibility when the hotel assistant ’ s feedback does not meet the needs or expectations of guests . They have implemented a feedback learning loop to better understand preferences and have highlighted the ability for a guest to turn off the AI assistant at any point during their stay . Five Practices of Everyday EthicsRunning Example Align with norms and values Be sensitive to a wide range of cultural norms and values , not just your own . AI works alongside diverse , human interests . People make decisions based on any number of contextual factors , including their experiences , memories , upbringing , and cultural norms . These factors allow us to have a fundamental understanding of “ right and wrong ” in a wide range of contexts , at home , in the office , or elsewhere . This is second nature for humans , as we have a wealth of experiences to draw upon . Today ’ s AI systems do not have these types of experiences to draw upon , so it is the responsibility of designers and developers to collaborate with each other in order to ensure consideration of existing values . Care is required to ensure sensitivity to a wide range of cultural norms and values . Companies advancing AI have an obligation to address these issues proactively . As daunting as it may seem to take value systems into account , the common core of universal principles is that they are a cooperative phenomenon . Successful teams already understand that cooperation and collaboration leads to the best outcomes . Five Practices of Everyday Ethics “ With trust as the cornerstone of our leadership in AI innovation , IBM is the partner that businesses need right now as they look to use AI as a force for positive change . And at this moment in the long arc of human progress , that matters not just for our company , but for our customers and society at large. ” –Principles and Practices for Building More Trustworthy AI9 22 23 24 2502 Work with design researchers to understand and reflect your users ’ values . You can find out more about this process on IBM ’ s Design Research site.1001 Consider the culture that establishes the value systems you ’ re designing within . Whenever possible , bring in policymakers and academics that can help your team articulate relevant perspectives . 03 Consider mapping out your understanding of your users ’ values and aligning the AI system ’ s actions accordingly with an Ethics Canvas.11 Values will be specific to certain use cases and affected communities . Alignment will allow users to better understand your AI system ’ s actions and intents.Recommended actions to take Five Practices of Everyday EthicsTo consider If you need somewhere to start , consider IBM ’ s five pillars of trustworthy AI , Principles of Trust and Transparency , Standards of Corporate Responsibility12 or use your company ’ s standards documentation . Values are subjective and differ globally . Global companies must take into account linguistic barriers and cultural differences . Well-meaning values can create unintended consequences . e.g . a tailored political newsfeed provides users with news that aligns with their beliefs but does not holistically represent the gestalt.Questions for your team Which group ’ s values are expressed by our AI system and why ? How do we agree on which values to consider as a team ? How do we change or adjust the values reflected by our AI system as our values evolve over time ? 26 27 Five Practices of Everyday EthicsThe team understands that for a voice-activated assistant to work properly , it must be “ always listening ” for a wake word . The team makes it clear to guests that the AI assistant is designed to not keep any data , or monitor guests , in both cases without their knowledge , even if it is listening for a wake word . The audio collected while listening for a wake word is auto-deleted every 5 seconds . Even if a guest opts in , the AI assistant does not actively listen in on guests unless it is called upon.The team knows that this agent will be used in hotels across the world , which will require different languages and customs . They consult with linguists to ensure the AI assistant will be able to speak in guests ’ respective languages and respect applicable customs.– – –Running Example Minimize bias and improve inclusivity Work with your team to identify and address biases and promote inclusive representation . AI provides deeper insight into our personal lives when interacting with our sensitive data . As humans are inherently vulnerable to biases , and are responsible for building AI , there are chances for human bias to be embedded in the systems we create . Bias can be present both in the algorithm of the AI system and in the data used to train and test it . It can emerge as a result of cultural , social , or institutional expectations . Although bias can never be fully eliminated , it is the role of a responsible team to minimize algorithmic bias through ongoing research and responsible data collection representative of a diverse population . Five Practices of Everyday Ethics “ AI systems do not operate in isolation . They help people make decisions that directly affect other people ’ s lives . If we are to develop trustworthy AI systems , we need to consider all the factors that can chip away at the public ’ s trust in AI. ” –Reva Schwartz , NIST13 29 28 30 3102 Design and develop without intentional biases and schedule team reviews to avoid unintentional biases . Unintentional biases can include stereotyping , confirmation bias , and sunk cost bias ( see pages 34 and 35 ) . 01 Real-time analysis of AI brings to light both intentional and unintentional biases . When bias in data becomes apparent , the team must investigate and understand where it originated and how it can be mitigated.03 Utilize a feedback mechanism or open dialogue with users to raise awareness of user-identified biases or issues.Recommended actions to take Five Practices of Everyday EthicsTo consider Diverse teams help to represent a wider variation of experiences to minimize bias . Embrace team members of different ages , ethnicities , genders , educational disciplines , and cultural perspectives . Your AI system may be susceptible to different types of bias based on the type of data it ingests . Monitor training and results in order to quickly respond to issues . Test early and often for model robustness and performance.Questions for your team How can we identify and audit unintentional biases that we run into during the design and development of our AI system ? The status quo changes over time . How do we instill methods to reflect that change in our ongoing data collection ? How do we best collect feedback from users in order to correct unintentional bias in design or decision-making ? 32 33 Five Practices of Everyday EthicsThe team ensures members of the hotel ’ s global management that the data collected about a user ’ s race , gender , etc . in combination with their usage of AI , will not be used to market to or exclude certain demographics . The team inherited a set of data about guests from the hotel . After analyzing this data and implementing it into a build of the agent , they realize that it has a degree of algorithmic bias from the data . The team starts over and retrains the model on a bigger , more diverse set of data.– –Running Example Shortcut Biases I don ’ t have the time or energy to think about this. ” Unconscious Bias Definitions Availability Bias Overestimating events with greater “ availability “ in memory— influenced by how recent , unusual , or emotionally charged the memories may be . Base Rate Fallacy The tendency to ignore general information and focus on specific information ( a certain case ) . Congruence Bias The tendency to test hypotheses exclusively through direct testing , instead of testing alternative hypotheses . Empathy Gap Bias The tendency to underestimate the influence or strength of feelings , in either ones ’ self or others . Stereotyping Expecting a member of a group to have certain characteristics without having actual information about that individual . Five Practices of Everyday EthicsThe average knowledge worker is unaware of the many different types of biases . While this list is not all-encompassing , these biases are some of the more common types to be consciously aware of when designing and developing for AI. “ Impartiality Biases I know I ’ m wrong sometimes , but I ’ m right about this . ” Self-Interest Biases We contributed the most . They weren ’ t very cooperative. ” “ Anchoring Bias To rely too much on one trait or piece of information when making decisions ( usually the first piece of information that we acquire on that subject ) . Bandwagon Bias The tendency to do or believe things because many other people do ( groupthink ) . Bias Blind Spot The tendency to see oneself as less biased than others , or to be able to identify more cognitive biases in others than in oneself . Confirmation Bias The tendency to search for , interpret , or focus on information in a way that confirms one ’ s preconceptions . Halo Effect The tendency of an overall impression to influence the observer . Positive feelings in one area causes ambiguous or neutral traits to be viewed positively . Ingroup / Outgroup Bias The tendency or pattern of favoring members of one ’ s ingroup over outgroup members . Sunk Cost Bias The tendency to justify past choices , even though they no longer seem valid . Status Quo Bias The tendency to maintain the current situation — even when better alternatives exist . Not Invented Here Bias Aversion to contact with or use of products , research , standards , or knowledge developed outside a group . Self-Serving Bias The tendency to focus on strengths/achievements and overlook faults/failures . To take more responsibility for their group ’ s work that they give to other groups . “ 35 34 Ensure explainability Ensure humans can perceive , detect , and understand an AI decision process . While transparency communicates the purpose and characteristics of an AI system , simple and straightforward explanations show users how and why a system arrived at a particular conclusion . In general , we don ’ t blindly trust those who can ’ t explain their reasoning . The same goes for AI , perhaps even more so.14 As an AI system increases in capabilities and achieves a greater range of impact , its decision-making process should be explainable in terms people can understand . Explainability is key for users interacting with AI to understand its conclusions and recommendations . Your users should always be aware that they are interacting with AI . Good design does not sacrifice transparency and explainability while creating a seamless experience . Imperceptible AI is not ethical AI . Five Practices of Everyday Ethics “ Any AI system on the market that is making determinations or recommendations with potentially significant implications for individuals should be able to explain and contextualize how and why it arrived at a particular conclusion. ” –IBM ’ s Explainability Pillar15 37 36 38 3902 Decision-making processes must be reviewable , especially if the AI system is working with highly sensitive personal information data like personally identifiable information , protected health information , and/or biometric data.01 Allow for questions . A user should be able to ask why an AI system is doing what it ’ s doing on an ongoing basis . This should be clear and up front in the user interface at all times.03 When an AI system is assisting users with making any highly sensitive decisions , it must be able to provide them with a sufficient explanation of recommendations , the data used , and the reasoning behind the recommendations.Recommended actions to take Five Practices of Everyday Ethics04 Teams should have and maintain access to a record of an AI system ’ s decision processes and be amenable to verification of those decision processes.To consider Explainability is needed to build public confidence in disruptive technology , to promote safer practices , and to facilitate broader societal adoption . There are situations where users may not have access to the full decision process that an AI system might go through , e.g. , financial investment algorithms . Ensure an AI system ’ s level of transparency is clear . Users should stay generally informed on the AI ’ s intent even when they can ’ t access a breakdown of the AI ’ s process.Questions for your team How do we build explainability into our experience without detracting from user experience or distracting from the task at hand ? Do certain processes or pieces of information need to be hidden from users for security or IP reasons ? How is this explained to users ? Which segments of the AI system ’ s decision processes can be articulated for users in an easily digestible and explainable fashion ? 40 41 Five Practices of Everyday EthicsPer GDPR ( General Data Protection Regulation ) 16 , a guest must explicitly opt in to use the hotel room assistant . Additionally , they will be provided with a transparent UI in their room to show how the voice AI makes its recommendations and suggestions . A researcher on the team , through interviews with hotel guests , learns that the guests want a way to opt into having their personal information stored . The team provides consent mechanisms so that guests ( through voice or graphic UI ) can allow the system to store pieces of information.With permission , the AI assistant offers recommendations for places to visit during their stay . Guests can ask why these recommendations are made and which set of data is being utilized to make them.– – –Running Example Protect user data Preserve and fortify users ’ power over their own data and its uses . It ’ s your team ’ s responsibility to keep users empowered with control over their interactions and data . In addition , AI must be robust to outside attacks . Pew Research found that 79 % of Americans are concerned about the way their data is being used by companies.17 Organizations have a responsibility to use AI ethically as the technology matures . We should be fully compliant with the applicable portions of EU ’ s GDPR and any comparable regulations in other countries , to make sure users understand that AI is working in their best interests . AI should be used to amplify our privacy , rather than undermine it . Five Practices of Everyday Ethics “ 81 % of consumers say they became more concerned over the prior year with how companies use their data , and 75 % percent are now less likely to trust organizations with their personal information. ” – Advancing AI ethics beyond compliance18 43 42 44 4502 Users ’ data should be protected from theft , misuse , or data corruption . AI systems must ensure privacy at every turn , not only with raw data , but with the insights gained from that data.01 Users should always maintain control over what data is being used and in what context . They can deny access to personal data that they may find compromising or unfit for an AI system to know or use . 03 Provide full disclosure on how the personal information is being used or shared.Recommended actions to take Five Practices of Everyday Ethics04 Allow users to deny service or data by having the AI system ask for permission before an interaction or providing the option during an interaction . Privacy settings and permissions should be clear , findable , and adjustable . 05 Forbid use of another company ’ s data without permission when creating a new AI service . 06 Recognize and adhere to applicable national and international rights laws when designing for an AI system ’ s acceptable user data access permissions.To consider Employ security practices including encryption , access control methodologies , and proprietary consent management modules to restrict access to authorized users and to de-identify data in accordance with user preferences . It ’ s your responsibility to work with your team to address any lack of these practices.Questions for your team What types of sensitive personal data does the AI system utilize and how will this data be protected ? What contractual agreements are necessary for data usage and what are the local and international laws that are applicable to our AI system ? How do we create the best user experience with the minimum amount of required user data ? 46 47 Five Practices of Everyday EthicsThe hotel provides guests with a consent agreement to utilize the hotel ’ s AI assistant before they begin using its services . This agreement clearly outlines to guests that the hotel does not own their data and the guests have the right to purge this data from the system at any time , even after checkout.During user interviews , the design researchers find that the guests feel they should be provided with a summary of the information that was acquired from them during their stay . At checkout , they can instruct the hotel to remove this information from the system if they wish.– –Running Example Closing Designers and developers of AI can help mitigate bias and disenfranchisement through these five practices . Good intentions and general statements aren ’ t enough . In order to ensure our AI systems are trustworthy , we must tie our trustworthy AI pillars to our practices . AI systems must remain flexible enough to undergo constant maintenance and improvement as ethical challenges are discovered and remediated . By adopting the five practices covered in this document , designers and developers can become more ethically aware , mitigate biases within these systems , and instill responsibility and accountability in those who work with AI . As much of what we do related to AI is new territory for all of us , individuals and groups will need to further define criteria and metrics for evaluation to better allow for the detection and mitigation of any issues . This is an ongoing project : we welcome and encourage feedback so the guide can develop and mature over time . We hope it contributes to the dialogue and debate about the implications of these technologies for humanity and allows designers and developers to embed ethics into the AI solutions they work on . 49 48 50 51References 01 https : / /www.ibm.com/artificial-intelligence/ethics 02 https : / /www.ibm.com/cloud/learn/ai-ethics 03 https : / /www.ibm.com/design/thinking/page/badges/ai 04 https : / /research.ibm.com/topics/trustworthy-ai 05 https : / /www.weforum.org/whitepapers/responsible-use-of-technology-the-ibm- case-study/ 06 https : / /www.ncsl.org/research/telecommunications-and-information-technolo gy/2020-legislation-related-to-artificial-intelligence.aspx 07 https : / /standards.ieee.org/wp-content/uploads/import/documents/other/ead_v2.pdf 08 https : / /research.ibm.com/blog/securing-ai-workflows-with-adversarial-robustness 09 https : / /newsroom.ibm.com/Principles-and-Practices-for-Building-More-Trustworthy-AI 10 https : / /www.ibm.com/design/research/ 11 https : / /www.ethicscanvas.org/ 12 https : / /www.ibm.com/trust 13 https : / /www.nist.gov/news-events/news/2022/03/theres-more-ai-bias-biased-datanist-report-highlights 14 https : / /newsroom.ibm.com/Principles-and-Practices-for-Building-More-Trustworthy-AI 15 https : / /www.ibm.com/artificial-intelligence/ai-ethics-focus-areas 16 https : / /gdpr-info.eu/ 17 “ Americans and Privacy : Concerned , Confused and Feeling Lack of Control Over Their Personal Information. ” Pew Research Center , Washington , D.C. ( 2019 ) https : / / www.pewresearch.org/internet/2019/11/15/americans-and-privacy-concerned-con fused-and-feeling-lack-of-control-over-their-personal-information/ 18 https : / /www.ibm.com/thought-leadership/institute-business-value/report/ai-ethics 52IBM Design for AI Download the latest version here : ibm.biz/everydayethics
