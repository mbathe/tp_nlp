facial recognition technology growing power artificial intelligence report standing committee access information privacy ethics pat kelly chair october parliament session published authority speaker house commons speaker permission proceedings house commons committees hereby made available provide greater public access parliamentary privilege house commons control publication broadcast proceedings house commons committees nonetheless reserved copyrights therein also reserved reproducti proceedings house commons committees whole part medium hereby permitted provided reproduction accurate presented official permission extend reproduction distribution use commercial purpose financial gain reproduction use outside permission without authorization may treated copyright infringement accordance copyright act authorization may obtained written applicatio office speaker house commons reproduction accordance permission constitute publication authority house commons absolute privilege applies proceedings house commons extend permitted reproductions reproduction includes briefs standing committee house commons authorization reproduction may required authors accordance copyright act nothing thi permission abrogates derogates privileges powers immunities rights house commons committees greater certainty permission affect prohibition impeaching questioning proceedings house commons courts otherwise house commons retains right privilege find users contempt parliament reproduction use accordance permission also available house commons website following address facial recognition technology growing power artificial intelligence report standing committee access information privacy ethics pat kelly chair october parliament session notice reader reports committee presented house commons presenting report house way committee makes public findings recommendations particular topic substantive reports subject study usually contain synopsis testimony heard recommendations made committee well reasons recommendations assist reader list abbreviations used report available page iii standing committee access information privacy ethics chair pat kelly vice iqra khalid rené villemure members parm bains james bezan hon greg fergus matthew green lisa hepfner damien kurek ara saks ryan williams members parliament participated richard bragdon iqwinder gaheer jean garon leah gazan majid jowhari arielle kayabaga jennifer connell brad redekopp francesco sorbara joanne thompson anita vandenbeld dominique vien cathay wagantall clerk committee nancy vohl library parliament parliamentary information education research service sabrina charland analyst alexandra savoie analyst standing committee access information privacy ethics honour present sixth report pursuant mandate standing order committee studied use impact facial recognition technolog agreed report following vii table contents list acronyms summary list recommendations facial recognition technology growing power artificial intelligence introduction background structure report chapter facial recognition technology facial recognition technology works facial recognition technology benefits facial recognition technology concerns facial recognition technology misidentification algorithmic bias concerns chapter uses related risks use facial recognition police forces criticism risk mass surveillance police forces use royal canadian mounted police use toronto police service use facial recognition federal agencies use facial recognition border authorities use facial recogniti public spaces use facial recognition workplace viii use facial recognition political parties committee observations recommendations chapter accountability procurement public investment accountability transparency governance accountability procurement public partnerships procurement police forces public investment example accountability action microsoft committee observations recommendati ons chapter regulating facial recognition technology artificial intelligence moratoriums bans measures privacy guidance facial recognition police agencies legislation legislative framework public private sector legislative framework police services best practices jurisdictions committee observations recommendations conclusion appendix list witnesses appendix list briefs request government response list acronyms aclu american civil liberties union artificial intelligence aia algorithmic impact assessment bipa biometric information privacy act cai commission accès information québec cbsa canada border services agency ccla canadian civil liberties association cippic samuelson canadian internet policy public interest clinic csis canadian security intelligence service facial recognition frt facial recognition technology iclmg international civil libe rties monitoring group nccm national council canadian muslims ncecc national child exploitation crime centre nist national institute standards technology ntop national technologies onboarding program oecd organisation economic development opc office privacy commissioner canada pipeda personal information protection electronic documents act rcmp royal canadian mounted police tps toronto police service tpsb toronto police services boar summary rise artificial intelligence growing use facial recognition technology frt well recent investigations office privacy commissioner opc frt led committee study frt growing power report looks benefits risks frt use specific contexts law enforcement explores governance issues procurement public investment area also looks legislat ive solutions reassure canadians use frt tools canada done responsibly respects rights taking account witness testimony committee makes several recommendations improve federal legislative framework applies frt technologies including recommendation impose moratorium frt canada recommended majority witnesses list recommendations result deliberations committees may make recommendations include reports consideration house commons government recommendations related study listed recommendation government canada amend section privacy act require government institution ensure practices third party obtains personal information lawful recommendation government canada ensure airports industries publicly disclose use facial recognition technology including limited signage prominently displaye observation area website recommendation government canada refer use facial recognition technology military intelligence operations uses facial recognition technology tate national security implications national security intelligence committee parliamentarians study review recommendation committee report findings recommendation government creation regulatory framework around use facial recognition technology set clear penalties violations police recommendation government canada amend procurement policies require government institutions acquire facial recognition technology algorithmic tools including free trials make acquisition public subject national security concerns recommendation government canada create public registry algorithmic tools used entity operating canada listed subject national security concerns recommendation government canada enhance treasury board directive automated decision ensure participation ivil society groups algorithmic impact assessments impose specific requirements ongoing monitoring artificial intelligence systems recommendation government canada increase investment initiatives study impact artificial intelligence various demographic groups increase digital literacy educate canadians privacy rights recommendation government canada ensure full transparent disclosure racial age unconscious biases may exist facial recognition technology used government soon bias found context testing scenarios live applications technology subject national security concerns recommendat ion government canada establish robust policy measures within public sector use facial recognition technology could include immediate advance public notice public comment consultation marginalized groups independent oversight mechanisms recommendation government define appropriate legislation acceptable uses facial recognition technology algorithmic technologies prohibit uses including mass surveillance recom mendation government canada amend privacy act require prior adoption creation use facial recognition technology government agencies seek advice recommendations privacy commissioner file impact assessments office recommendation government canada update canadian human rights act ensure applies discrimination caused use facial recognition technology artificial intelligence technologies recommendation government canada implement right erasure right forgotten requiring service providers social media platforms online entities operating canada delete users personal inform ation set period following users termination use including limited uploaded photographs payment information address contact information posts survey entries recommendation government canada implement requirement collection biometric information private sector entities prohibit entities making provision goods services contingent providing biometric information recommendation governmen canada strengthen ability privacy commissioner levy meaningful penalties government institutions private entities whose use facial recognition technology violates privacy act personal information protection elect ronic documents act deter future abuse technology recommendation government canada amend privacy act personal information protection electronic documents act prohibit practice capturing images canadians internet public spaces purpose populating facial recognition technology databases artificial intelligence algorithms recommendation government canada impose federal moratorium use facial cognition technology federal policing services canadian industries unless implemented confirmed consultation office privacy commissioner judicial authorization government actively develop regulatory framew ork concerning uses prohibitions oversight privacy facial recognition technology oversight include proactive engagement measures program level authorization advance notification use powers audit make ord ers recommendation federal government ensure appropriate privacy protections put place mitigate risks individuals including measures addressing accuracy retention transparency facial recognition initiatives wel comprehensive strategy around informed consent canadians use private information facial recognition technology growing power artificial intelligence introduction background artificial intelligence omnipresent society facial recognition technology frt relies also becoming popular canada frt recently subject joint investigation office privacy commissioner canada opc provincial counterparts alberta british columbia quebec case involving clearview february opc released report joint investigation concluded clearview failed comply personal information protection electronic documents act pipeda engaging mass collection images thout consent inappropriate opc also conducted investigation use clearview technology royal canadian mounted police rcmp special report parliament released june opc concluded rcmp failed comply privacy act collecting personal information third party clearview illegally collected light december committee unanimously adopted motion study use impacts frt growing power office privacy commissioner canada opc joint investigation clearview office priva commissioner canada commission accès information québec information privacy commissioner british columbia information privacy commissioner alberta february opc report clearview opc concluded clearview exempt obtaining consent pipeda publicly available personal information exemption limited publicly available personal information identified regulations specifying publicly available information opc police use facial recognition technology canada way forward special report parliament opc investigation rcmp use clearview draft joint guidance law enforcement agencies considering use facial recognition technology june special repo rcmp rcmp challenged opc findings see chapter report committee held nine public meetings heard witnesses also received eight briefs committee thanks participated study structure report report divided four chapters chapter explains frt presence market provides overview benefits risks chapter focuses specific uses frt cluding law enforcement chapter discusses stakeholder accountability respect using developing frt issues related procurement public investment finally chapter focuses regulation frt chapter cial recognition technology like technologies frt used responsibly offer significant benefits society however also extremely intrusive enable widespread surveillance provide biased results erode human rights including right participate freely without surveillance democratic daniel therrien privacy commissioner canada appeared committee may facial recognition technology works carole piovesan managing partner inq law said frt uses highly sensitive biometric facial data identify verify individual brenda mcphail director privacy technology surveillance program canadian civil liberties association ccla said frt thought facial fingerprinting facial recognition process identifying face digital image video frt deployed real time static images uses computer pattern recognition find commonalities images depicting human faces frt used confirm identity known person identify unknown person also allow categorization profiling person time based facial facial recognition technology growing power artificial intelligence words frt used verification identification general however frt systems fall two categories used verify person identity one used identify individual one one system compares user image multiple images single person authenticate verify person known identity one system compares age database different faces terrorist watchlist mugshot database uniquely identify individual among group people often live real elizabeth anne watkins postdoctoral research associate princeton university described facial verification follows whereas facial recognitio system means finds identifies individuals camera feeds typically viewing large numbers faces usually without knowledge individuals facial verification hand built similar recogniti technology distinct used facial verification matching system much intimate close person face directly front camera matched face already associated device digital account logging system see face predict match face already associated device account permitted log match verified remain locked use fac iphone example already used facial verification angelina wang graduate researcher computer science princeton unive rsity explained technical standpoint frt machine model rather applying hand rules model given large dataset faces annotations annotations include labels noting hich images person location face image wang said data models typically collected crow dsourcing platforms like amazon mechanical turk said known centre media technology democracy cybersecure policy exchange brief ethi committee study use impact facial recognition technology june cmtd cpe brief christelle tessono brief ethi committee study use impact facial recognition technology may tessono brief cmtd cpe brief angelina wang gave example hand rule saying two people likely coloured eyes homogeneous worker populations unfavourable working conditions simply scraped internet websites like datasets vary size images millions images facial recognition technology many witnesses said frt increasingly present market society example piovesan said frt becoming much extensively used public private sectors alike said according study published grand review research global market size frt expected reach billion said expansion due considerable investments advancements use frt around world added discussions frt tend focus security surveillance various sectors using technology including retail telecommunications information technology health care presents growing economic opportunity developers users nestor maslej research associate institute human artificial intelligence stanford university shared following statistics institute index government agencies used technologies departments digital access cybersecurity six creating leads criminal investigations five physical security moreover departments noted hoped broaden use gures admittedly paint picture widely governments use tools towards end since also total billion invested globally funding start dedicated facial recognition however million investment gone towards canadian frt start time period amount invested frt technologies increased suggests business interest frt example nestor maslej research associate institute human artificial intelligence stanford university explained résumé system developed amazon using machine learning found discriminatory system trained data résumés amazon already received overwhelming majority men system never used make hiring decisions grand view research facial recognition market size share trends analysis report technology facial analytics application access control security surveillance end region segment forecasts stanford university human artificial intelligence institute artificial intelligence index report see also nestor maslej brief ethi committee study use impact facial recognition technology june facial recognition technology growing power artificial intelligence also growing estimates also show frt funded area focus areas several witnesses mentioned already widespread use frt example watkins said used uber drivers amazon delivery drivers home care providers electronically verify visit many police departments across united states using frt except cities bans moratoriums wang said frt used interviewing platforms like hirevue rob jenkins professor psychology university york united kingdom said number countries use frt border controls processes like passport renewal specific uses frt canada disc ussed chapter report diane poitras president commission accès information québec cai said addition ide ntity verification term sometimes used designate derivatives technology used corporate purposes shopping centres example goal identify individuals rather characteristics like sex time spent window sanjay khanna strategic advisor foresight expert part alluded future frt could used sentiment analysis example commercial manipulation purposes embedded security robots gambling however wang said following respect type frt worth noting also lots pseudoscience kinds facial recognition tasks gender prediction emotion prediction even sexual orientation prediction criminality prediction warranted backlash criticism work predicting attributes visually discernible benefits facial recognition technology many witnesses acknowledged uses frt could benefit example piovesan said frt facilitate quick secure payment checkout help save patient life said frt used health care monitor patients make sure condition change said frt useful ethi evidence diane poitras ethi evidence alex laplante ethi evidence carole piovesan ethi evidence françoy labonté ethi evidence daniel therrien ethi evidence sanjay khanna ethi evidence owen larter ethi evidence rob jenkins verifying person identity access bank phone frt also useful conducting financial transactions françoys labonté chief executive officer computer research institute montréal said generally speaking people favour using facial recognit ion technology specific clearly applications easy understand benefits data mcphail mentio ned convenient widespread use facial verification unlock phones appropriate built protections may pose relatively little privacy risk owen larter director responsible artificial intelligence public policy microsoft said frt lot benefits among mentioned identity verification using person phone computer noted beneficial applications frt accessibility context stating organizations research use help people blind low vision better understand interact world around one project called project tokyo uses headset individual blind scan room identify people consented part system enabling identify person start conversation larter also mentioned appli cation aims help people alzheimer similar diseases recognize friends loved khanna said frt beneficial used prevent industrial accidents example preventing employees falling asleep alert lack attention dubi anengisser senior advisor strategic analysis governance toronto police services board tpsb said another tool used law enforcement carry duties identifying perpetrators victims daniel therrien former privacy commissioner canada said used serious crimes missing children compelling state purposes border context ensure people concern identified without impeding flow travellers country kristen tho masen law professor university british columbia emphasized however privacy social good benefits everyone includes women children often cited narrative one beneficial uses microsoft project tokyo facial recognition technology growing power artificial intelligence prote marginalized victimized groups certain contexts human trafficking child abuse agreed beneficial uses frt acknowledged nuancing narrative considerably erosion privacy social good also harm women children stated frt consolidates perfects surveillance perfect surveillance means greater privac harm inequity thomasen stressed frt inevitable pointing beneficial use cases sufficient imit thinking around potential harms arise widespread use technology ana brandusescu artificial intelligence gove rnance expert poitras also cautioned trivializing risks frt poses popularity convenient concerns facial recognition technology misidentification algorithmic bias biggest concern use frt potentia misidentification example cynthia khoo research fellow center privacy technology georgetown law school washington citizen lab university toronto said researchers found frt times likely misidentify black asian individuals misidentifies one three darker skinned women acc urate white men however wang noted although models developed asia also lots biases hey different set bia ses models developed canadians americans brandusescu presented statistics similar provided khoo frt better distinguishing white male faces black brown indigenous trans faces know groundbreaking work scholars like joy buolamwini timnit gebru study found darker skinned females misclassified group error rates maximum error rate lighter males witnesses referred study conducted national institute standards technology nist found algorithms perform worse certain demographic report found algorithms developed false positive rates highest asians african americans compared caucasians domestic law enforcement images highest false positive rates wer indigenous peoples report also found false positive rates higher women men higher elderly children piovesan also raised concerns accuracy bias system outputs unlawful indiscriminate surveillance black box technology inaccessible lawmakers restricting freedom putting risk fundamental values enshrined canadian charter rights freedoms alex laplante senior director product business development borealis made similar comments tating take care adequately assess application development governance adverse effects end perpetuate even amplify discrimination bias towards racialized communities women lead unet hical usage data breaches privacy rights watkins said technologies machine learning algorithmic technologies bas data gathered years decades reflect human biases like institutional racism sexism processes conservative old fashioned perpetuating biases society ought figure however witnesses said frt come long way example jenkins said impressive progress made past five years well systems identify faces maslej noted top facial recognition algorithms error rates anywhere roughly certain frvt facial recognition ndor test datasets none posted error rate greater top performing models registering error rate meaning every one thousand faces models correctly identify despite progress tnesses said frt would still raise concerns even worked example khoo said even frt worked perfectly ethi evidence alex laplante international civil liberties monitoring group brief ethi committee study use impact facial recognition technology april iclmg brief national institute standards technology nist face recognition vendor test frvt part demographic effects december ethi evidence kristen thomasen ethi evidence tim mcsorley ethi evidence cynthia khoo ethi evidence brenda mcphail ethi evidence angelina wang facial recognition technology growing power artificial intelligence might used detriment social groups fall along historical lines systemic oppression mcphail made similar comments technology fixed becomes accurate faces across spectrums gender race may become even dangerous know law enforcement contexts surveillance gaze disproportionately falls thos people know often suffers discrimination private sector applications people cases perfect identification groups members groups already experience systemic discrimination look like carries potential facilitate simply perfectly targeted discriminatory actions thomasen said facial surveillance must considered within historical trajectory emerged eugenics white supremacist ideologies also cautioned personal use facial surveillance damaging respect harassment doxing forms technology violence technical perspective wang explained machine learning models try identify patterns data frequently amplify biases exist data illustrated point using following example predictive policing communities colour different neighbourhoods higher proportions black citizens may higher levels crime predictive policing models may communities future likely crime even true compared base rate correlation actually also pointed even bias problems across demographic groups resolved two problems would remain brittleness known ways bad actors manipulate model circumvent trick interpretability extremely difficult discover precise set rules model using make concerns tim mcsorley national coordinator international civil liberties monitoring group iclmg raised three main concerns frt biased inaccurate algorithms reinforce systemic racism racial profiling facial cognition allows indiscriminate warrantless mass surveillance lack regulation transparency accountability law enforcement intelligence agencies ethi evidence angelina wang see also iclmg brief patricia kosseim ontario information privacy commissioner said respect use frt greatest concern commissioners across canada mass surveillance whether done third private sector company behalf police police service mcphail noted addition equality rights ools could allow ubiquitous identification would negative impacts full range rights protected canadian charter rights freedoms laws including freedom association assembly freedom expression right free unreasonable search seizure state presumption innocence ultimately rights liberty security person another concern frt people always aware face part dataset used frt clearview case example situation wang said individuals whose faces included dataset generally know images used purpose may consider privacy according jenkins image incl uded frt algorithms becomes impossible eliminate influence image algorithm also explained concept intraperso nal variability one face appearance constantly varies principle important factor facial recognition since involves natural aging face also factors angle lightin person facial expression intrapersonal variability causes lot variation difficult overcome using frt jenkin also noted human oversight catch egregious errors however said human face recognition infallible therefore also introduce errors poitras brought privacy risks biometric databases noting databases created one purpose may used purposes without individual knowledge adequate assessment risks associated purposes witnesses also raised concerns security weaknesses data see also rob jenkins brief ethi committee study use impact facial recognition technology april ligue des droits libertés brief ethi committee study use impact facial recognition technology april ligue des droits libertés brief tessono brief facial recognition technology growing power artificial intelligence finally many witnesses fact facial traits permanent changed like passwords makes frt particularly chapter uses related risks facial reco gnition technology bear legal moral responsibility humans might otherwise abdicate vulnerable people lives freedom cynthia khoo research fellow appeared committee march individual beyond general observations regards frt witnesses also commented specific uses frt watkins said use frt government organizations police agencies border authorities government general high isk said technologies unreliable also presume social constructs like race gender machine person face opinion simply added technologies like clearview yet accurate enough used high scenarios lives livelihoods line one high scenario discussed witnesses use frt police forces use facial recognition police forces criticism according khoo one key problems law enforcement use frt lack transparency public often learns technology use media leaked documents freedom information requests mcsorley mcphail also noted lack transparency law enforcement ada mcphail described situation canada real crisis accountability comes police use ethi evidence angelina wang ethi evidence daniel therrien ethi evidence diane poitras jenkins criticized reliability frt compared identification methods used police forces fingerprinting demonstrate existence reliable techniques certain circumstances explained traditional methods number technical problems frt presents changes facial appearance lighting conditions distance face camera lens jenkins said main concerns mistaken identity idea innocent person could apprehended accused even sentenced crime also recognized important avoid opposite error failing apprehend someone could great danger khoo brandusescu mcphail wang mentioned cases misidentification black men led wrongful arrests khoo gave robert williams nijeer parks michael olivier examples three black men wrongful arrested police relying facial recognition technology endured lost jobs traumatized children broken relationships mention blow personal dignity human costs false confidence unconstitutional uses facial recognition technology however mcphail said aware examples misidentification individua led criminal charges canada said police forces canada cautious measured adopting technology using relatively limited ways khoo said racial justice activists colleagues talked context research conducted citizen lab report consider use algorithmic technologies police state violence done pen paper done computers brandusescu said systemic racism policing canada noting acknowledged house commons standing committee public safety national security view frt exacerbates systemic racism citizen lab kate robertson cyn thia khoo yolanda song surveil predict human rights analysis algorithmic policing canada september standing committee public saf ety national security secu systemic racism policing canada june facial recognition technology growing power artificial intelligence mcphail said police use frt mugshot databases inherently problematic since issues bias discrimination iclmg made similar sharon polsky president privacy access council canada consulted police forces use believes poli officers like canadians really understand compliance requirements frt actually risk mass surveillance police forces witnesses raised possibility police activities lead mass mcsorley gave specific example rcmp example rcmp scrape information individuals online keep databases know beyond facial recognition would argue right collect information whereas others challenging saying form mass surveillance eeds regulated gordon sage director general rcmp sensitive specialized investigative services said believe mere use frt constitutes mass surveillance even respect use clearview technology matched images database three billion publicly sourced images paul boudreau acting deputy commissioner rcmp specialized policing services said rcmp use frt active surveillance capturing mass protests however mustafa farooq president ceo national council canadian muslims nccm said organization gets calls time people undergoing surveillanc canadian security intelligence service csis rcmp rallies protests sage rcmp denied allegation assuring committee rcmp use frt mass surveillance added frt used rcmp clearview stopped july iclmg brief see also privacy access council canada facial recognition use law enforcement canada realities reservations recommendations october ethi evidence brenda mcphail ethi evidence tim mcsorley therrien said reason doubt rcmp statement conduct mass surveillance use frt although found definition circumstances use rather ambiguous colin stairs chief information officer toronto police service tps assured committee tps conduct mass surveillance take photos protesters practice therefore run types photos added tps uses frt investigative tool surveillance reconnaissance tool would infringe privacy example explained tps use taking crime scene photos gathered cameras would recording street regardless taking still comparing mug shot database similar witnesses giving testimony significant change similarly kanengisser said anything falls mass surveillance unreasonable use frt example tracking people masse indiscriminately would unacceptable tpsb would use technology shown inaccurate leading significant misidentification potential harm example person getting arres ted misidentified software confirmed human would unacceptable following sections discuss use frt rcmp tps including use clearview frt use royal canadian mou nted police according mcsorley rcmp used different forms past years without public acknowledgement debate clear oversight boudreau said using facial recognition within organization rcmp long time comes new frt clearview using type sage also said rcmp currently use frt facial recognition technology growing power artificial intelligence rcmp clarified testimony regarding use frt letter committee july however rcmp admitted using learview frt past sage boudreau confirmed two licences purchased october used july clearview withdrew canadian market sage said believed licence first obtained investigator working national child exploitation crime centre ncecc added director general time aware purchase made also noted employee question never investigated boudreau also confirmed rcmp officer reprimanded regarding use clearview frt boudreau explained rcmp constantly looking new technologies whether types technologies different divisions look evaluate new technologies however said rcmp learned limited number rcmp programs services begun using clearview internal investigation launched sage said policy effect time licence obtained members ground able obtain licences saw sage added analysis technology compliance charter took place time rcmp also confirmed ethics review done using clearview roch séguin director strategic services branch technical operations said rcmp approached department justice regarding use frts investigations internal rcmp sage explained clearview frt tested lot rcmp members using either photos profiles social media photos celebrities royal mounted police canada letter committee july letter clarifies rcmp testimony use facial recognition technology frt indicates rcmp uses certain frt pre viously highlighted namely spotlight traffic jam tools use facial recognition components help law enforcement identify victims sexual exploitation human trafficking missing persons risk exploitat ion conducting searches open websites none tools yet evaluated national technologies onboarding program letter also provides list rcmp use frt list likely future use new technologies describes approval process purchasing licences clearview royal canadian mounted police confidential letter committee june found technology always effect ive identification problems result became one many tools requiring human intervention sage said frt used rcmp investigations three occasions ncecc used two occasions identify victims serious crime provide safeguards protect victims located canada used third occasion track fugitive abroad coo peration police forces assured committee rcmp use frt never resulted prosecutions boudreau also said human intervention must always used analyzing results however opc report use clearview frt found searches clearview appeared linked ncecc victim identification approximately accounted rcmp according sage searches three cases mentioned abov remaining used test technology therrien explained result investigation opc found rcmp taken measures verify legality clearview collection information lacked system ensure new technologies deployed lawfully opc ultimately determined clearview use frt unlawful becaus relied illegal collection use facial images business partner opc also found serious systemic failings rcmp ensure compliance act collected information clearview broadly novel collection personal information therrien noted words used report refer fact time investigation rcmp verification approval process place ensure new technology used officers technology respects law privacy rights therrien explained rcmp disagreed opc findings failed comply section privacy act using clearview technology noted rcmp argued section explicitly require government example gordon sage said frt successful identifying finding child victim sexual exploitation traditional methods past years failed special opc report rcmp para para facial recognition technology growing power artificial intelligence institution verify legality business partner practices public sector uses therrien agreed requirement explicit said exists implicitly secti privacy act otherwise federal institution could contracting private sector engage practices engage directly recommended ambiguity privacy act removed explicitly requiring gove rnment institutions ensure buying lawful contract private sector boudreau sage confirmed rcmp agree findings opc report supports recommendations therrien noted despite rcmp position making good progress cooperation opc better verification system new technologies new technologies appearance said rcmp unlikely able implement opc recommendations recommended deadline said believed rcmp making genuine effort séguin said opc recommendations led natio nal technologies onboarding strategy march national technologies onboarding program ntop since rcmp made significant progress implementing ntop ensure technologies assessed used operation investigation said ntop expected place june within months recommended opc staff training may given time séguin described key pillars ntop regard key pillars national technology onboarding program stakeholder outrea partnership includes training obviously policy review development identify gaps existing policy modify update new ones technology assessment portion built full intake process thr ough series questionnaires also implementing technology clearview challenged opc findings orders made provincial commissioners federal commissioner power make orders see ethi evidence brenda mcphail ethi evidence diane poitras quebec clearview challenging decision commi ssion accès québec cai court including cai jurisdiction company royal mounted police canada letter committee july july new technologies submitted revi national technologies onboarding program ntop preliminary operational state letter describes ntop details inventory awareness oversight last component going public awareness transparency boudreau said ntop provides opportunity look new technologies legal ethical privacy perspective added rcmp believes use must targeted time subject verification trained experts used confirm identity rather considered investigational aid results must confirmed human according rcmp officials rcmp partner follow séguin also assured committee rom public awareness transparency piece built part communications strategy relieve categories technology rcmp leveraging sage added ntop assesses risks ethical issues technology includes privacy assessment said part rcmp efforts velop new ways forward rcmp member located within opc office asking one employees office order strengthen knowledge boudreau added rcmp looks technologies frt looked lens legal privacy gender analysis bias perspective human ntervention well future use frt rcmp sage said unfortunate frt used child exploitation cases identify victims said urgent file said waiting decision national technical operations required ntop rocess assessment use frt assessment done hopes permission use frt victims risk despite actions taken rcmp rizwan mohammad advocacy officer nccm said nccm shocked blasé attitude rcmp taken approaching issue use clearview noted rcmp initially denied using cle arview frt confirmed using software claiming use frt widely known within rcmp rcmp use frt also raised witnesses example mcsorley said rcmp contracted intelcenter private terrorist facial recognition system provides access acial recognition tools ethi evidence gordon sage ethi evidence roch séguin facial recognition technology growing power artificial intelligence database images people associated company says acquires images scraping online like clearview said law enforcement use intelcenter great concern adds extra stigma saying know people associated terrorism oversight terms came determination information used law enforcement however sage said intelcenter software acquired rcmp internal trial basis tested used national security investigation operational capacity added march rcmp learned intelcenter service software approved operational use use division lastly sage said project arachnid program run canadian centre child protection artnership ncecc use frt uses hashtag search dna image crawl use toronto police service colin stairs confirmed tps uses frt compare probe photos uncovered investigations photos intellibook tps mugshot database stairs assured committee body camera images used tps mugshot database connection body cameras intellibook system automated said tps operates identification criminals act therefore uses mugshots come arrests processing clearview anomaly regard tps use publicly sourced facial images facial recognition program stairs acknowledged known set issues around face analysis different training sets explained tps selected frt uses basis minimizing racial bias recognizing biases embedded photographic systems bias towards lighter faces compared darker faces reason tps uses hurdle rate tps consider match match considered identity identity corroborated methods canadian centre child protection project arachnid see also ethi ensuring protection privacy reputation platforms pornhub june report discusses project arachnid stairs said frts helpful unknown witness subject involved violent crime significant issue however usefulness lim ited scope tps mugshot database restrictions imposed criminal code canadian charter rights freedoms stairs confirmed tps use frt always accompanied human analysis forensic identification service stating technician takes image runs system looks said believes information related tps use frt investigation shared arrest court defendant february tpsb adopted use artificial intelligence technology policy policy kanengisser explained policy use frt biometric technology considered high considerable reviews advance adoption deployment technology therefore follow technology also done least two years examine impact including unintended consequences kanengisser said policy includes guiding princip les deciding whether technology approved include issues fairness reliability legality use requirement human intervention times stairs said tps drafting procedure implement policy adopted tpsb consultations similar conducted develop policy held stakeho lders terms hoped outcomes said part problem insufficient visibility guidance frontline officers approach new result tps looking create framework allows filter indicate tpsb public types technologies intends use stairs explained policy levels risk evaluating technologies extreme risk high risk medium risk low risk low risk extreme risk would banned added high extreme risk level must involve human intervention said policy also requires technology must toronto police services board use artificial intelligence technology policy february ethi evidence opening remarks dubi kanengisser toronto police service tps needs demonstrate real need mitigation plan address risks bias infringement privacy rights order adopt new high tool ensur governance structure allows effective auditing policy also places emphasis training tps members facial recognition technology growing power artificial intelligence posted evaluated framework except low low risk technologies otherwise load tps would high kosseim said office information privacy commissioner ontario consulted policy said offic recommendations adopted within policy adopted within procedures implement vance lockton senior technology policy advisor commissioner office said example one commissioner recommendations would include procedures better definitions risk levels oversight used tps exercised according thomasen tps policy still weaknesses example still treats algorithmic policing technologies inevitable net benefit whose risks mitigated believes right framework address technologies given harms cause social context introduced use facial recognition federal agencies group privacy human rights civil liberties advocates including iclmg wrote letter minister public safety calling ban use facial recognition surveillance federal law enforcement intell igence letter mcsorley attended listening session director policy minister office told canada border services agency cbsa use real mcsorley added information shared csis use technology clear commitment given minister office take action referring patchwork legislation around frt mcsorley said lack discussion lack forthcomingness federal agencies discuss use facial recognition technology raises deep concerns could engaging forms surveillance unlawful otherwise would considered unlawful patchwork egislation mcsorley said csis refused confirm whether uses frt work stating obligation international civil liberties monitoring group open letter canadian government must ban use facial recognition federal law enforcement intelligence agencies mohammad said number national security policing agencies well government agencies said use surveillance done ways constitutionally sound proportionate case demonstrated cases maher arar abdullah almaki mohamedou ould said agencies lied canadian people surveilling muslim communities coming argue mass survei llance happening frt used responsibly farooq brought example recent federal court decision crit icized csis habit trying mislead noted government appealing decision added going done challenge national security agencies mislead people remains open question use fac ial recognition border authorities september samuelson canadian internet policy public interest clinic cippic released report use tamir israel lawyer cippic outlined report key findings acial recognition adopted border without due consideration harms would cause without much external ersight often without regard existing policies treasury board policy artificial intelligence supposed bring external guidance adopting intrusive technologies like adopted often ets repurposed quickly reasons beyond narrow reasons context developed see secu review findings recommendations internal inquiry actions canadian officials relation abdullah almalki ahmad abou muayyed nureddin iacobucci inquiry report commission inquiry actions canadian officials relation maher arar connor quiry june canadian security intelligence services act canlii canlii judge found canadian security intelligen service breached duty candour duty candour legal concept applies parte warrant application requires party making application demonstrate utmost good faith presenting case warrant samue canadian internet policy public interest clinic cippic facial recognition crossroads transformation borders beyond september facial recognition technology growing power artificial intelligence last one often provides link digital physical presences ways allow automation application many automated assessment tools problematic israel made following comment emergence frt borde proposals around world automate screening process walk screen get facial recognition scan assessment profile pulled digitally automatically get channelled gate high medium low line israel said different types systems decentralized system best describes technology used passport control centralized system images held one spot whereas decentralized system encoded digital image passport photo compared photo taken passpor user airport security digital radio device encoded passport breached one passport breached several witnesses said use frt biometric technologies airports borders present hig esha bhandari deputy director american civil liberties union aclu expressed concern expansion biomet ric technology airports explained concern mandatory requirement agree use frt provide iris scans access essential services going airport crossing border contexts difficult opt due coercive nature environment view regulations provide people meaningful opt forced provide iris scan israel raised lack explicit opt saying even necessarily aware subjected gave example customs screening mechanisms toro nto pearson airport travellers necessarily realize scan happening said requiring least opt clear notification perhaps even opt would useful ethi evidence tamir israel ethi evidence esha bhanda ethi evidence petra molnar refugee law lab brief ethi committee study use impact facial recognition technology april refugee law lab brief refugee law lab iris scans also used refugee camps example jordan witnesses also rais concerns discrimination racial profiling example israel said lists long problem proposals create lists comparable objectives would problematic molnar pointed frt highly discriminatory black brown faces algorithmic decision often relies bia sed datasets concerns jenkins use frt airports even margin error massive explained think around passengers per day travel heathrow airport accuracy context talking misidentifications per day soon adds seem sustainable furthermore research jenkins found border law enforcement officials better identifying unfamiliar faces despite professional raining many years experience said percentage human errors made experts passport officers compared frt softwa errors vary depending specifics task example passport staff well trained many years experience error rates computer systems difficult predict accurate error rates since results reported vendors often based ideal conditions allow reliable analysis real noise complexity taken account molnar also shared concerns use frt border authorities purpose implementing biometric mass surveillance migration border management view fully understand impacts various migrat ion management border technologies lie detectors biometric mass surveillance various automated decision tools important consider broader ecosystem technologies develop ecosystem incr easingly replete criminalization migration anti sentiments border practices leading thousands deaths europe also borders since molnar visited borders aro und world recently mexico border ukrainian border said borders easily become testing grounds new technologies migration border enforcement already make opaque discretionary decision space one life decisions rendered decision little ethi evidence mustafa farooq ethi evidence tamir israel facial recognition technology growing power artificial intelligence oversight accountability system vast power differentials etween affected technology wielding refugee determinations particular said mistakes made someone wrongly deported country fleeing ramifications moreover molnar said surveillance smart border technologies deter people making dangerous crossings rather force change routes towards less inhabited terrain leading loss life gave example family found dead manitoba bord molnar therefore believes replacing human decision automated decision increasing surveillance muddies already discretionary space immigration refugee processing decision added border enforcement immigration ecision structures underpinned intersecting systemic racism historical discrimination people migrating technology impacts people human rights real witnesses also discussed specific frt programs proj ects borders example bhandari said aclu concerned expansion airports including programs like nexus israel said frt programs used canadian borders like nexus still voluntary pressure get border used encour age travellers sign types systems also gave example world economic forum known traveller digital identity progra pilot project canada example piloted program netherlands one developed world economic forum basically digital identity housed phone lot passport information additional social identity verific ation program information idea see could used replacement passport order facilitate border crossings facial recognition technology built system end vision system explicit tting travellers voluntarily sign avoid delays border gives access faster security processing however later becomes available banks molnar gave example saw sonoran desert border various automated surveillance towers sweeping desert molnar referred following report citizen lab petra molnar lex gill bots gate human rights analysis automated decision canada immigration refugee system september telecommunication companies entities well similar iden tity verification israel expressed concern government canada participation pilot project interrupted pandemic said concerned idea using pinpoint travel experience encourage people opt create types profiles knowing going used border control contexts many marginalized communities already massive disadvantage abroad countries end implement ing system intended global system also idea systems going used private sector fraud detection identity management interactions private companies molnar farooq also mentioned cbsa pilot roject airports test technology called avatar use facial emotional recognition technologies discern whether person lying already banned jurisdictions molnar questioned detector deal religious ethnic differences someone may reticent make eye contact may nervous may memory trauma nccm expressed concerns technology weaponized profile people potenti terrorism molnar raised following question whose priorities really matter choose create lie detectors bord instead using identify racist border guards lastly israel said recently cbsa announced try implement biometric study hub within infrastructure much seen going yet use facial recognition public spaces khoo said use frt public violates privacy preserved anonymity daily life said would likely induce chilling effects freedom expression public protests injustice also promises exacerbate gender based violence abuse facilitating stalking women witnesses also reminded ethi evidence tamir israel government canada government canada test cutting technologies support secure seamless global travel air passengers news release january facial recognition technology growing power artificial intelligence committee supreme court canada ruled individuals retain right privacy even public watkins said use frt public spaces could affect right freedom movement mcs orley said even significant problems bias accuracy resolved surveillance systems would continue subject people intrusive indiscriminate surveillance whether people walking public square activists protest farooq said organization received formal human rights complaints related technology including frt mentio ned however nccm sometimes hears concerns around people attending peaceful rallies vancouver hamilton pictures taken law enforcement specified nccm necessarily know done collected data large part lack disclosure view lack complaints due lack disclosure frt also used semi spaces commercial establishments labonté drew parallel using frt retail store shopping centre even users connected account cookies nevertheless leave behind traces time web cookies used send targeted advertising basis preferences bhandari gave example companies walgreens use frt pick customer age gender show tailored ads products said invasive tactic could lead concerns consumers steered products based gender stereotypes could segregate society mcphail mentioned opc investigation cadillac fairview mall said investigation revealed non private sector use facial analytics discovered due glitch technology view example shows almost every facial recognition vendor advertises help private sector bodies leverage personal data improve market iclmg brief ligue des droits libertés brief spencer scc investigation opc found cadi llac fairview collected used personal information including sensitive biometric information anonymous video analytics without valid consent visitors canadian examples given witnesses show frt surveillance conducted public spaces without people knowledge use facial recognition workplace watkins expressed concerns private industry use facial verification workers said acial verification increasingly used work contexts particular gig work precarious according watkins systems often place guarantee worker privacy prevent fraud protect security needs alternatives place give workers options said workers consulted better understand kinds technology would prefer comply provide alternatives opt technologies yet still access means livelihood explained research gathered data workers describing variety harms worried long faces stored stored shared cases workers forced take photos system recognize match cases erroneously forbidden logging account ystem match spend time visiting customer service centres wait sometimes hours sometimes days human oversight fix errors cases still workers described forced step cars dark parking lots crouch front headlights get enough light system see facial verification breaks workers ones create maintain conditions produce judgment watkins said ultimately frt currently reliable enough used high risk scenarios like workplace however acknowledged workers advocate various reasons opc joint investigation cadillac fairview corporation limited privacy commissioner canada information privacy commissioner alberta information privacy commissioner british columbia october facial recognition technology growing power artificial intelligence use facial recognition political parties according mcphail use political parties also poses risk democracy mentioned liberal party canada recent use similar one matching facial recognition tool nomination voting process prior last federal said case much risky use potentially aulty discriminatory technology took place process heart grassroots committee observations recommendations committee view rcmp officials reluctant provide complete answer committee questions particular respect use clearview technology many members voiced concern rcmp testimony witnesses evasive responses considering privacy commissioner comments section privacy act many concerns use frt various contexts explored chapter committee recommends recommendation government canada amend section privacy act require government institution ensure practices third party obtains personal information lawful recommendation government canada ensure airports industries publicly disclose use faci recognition technology including limited signage prominently displayed observation area website recommendation government canada refer use facial recognition technology military intelligence operations uses facial recognition technology state national security implications national security intelligence committee parliamentarians study review recommendation comm ittee report findings recommendation government creation regulatory framework around use facial recognition technolog set clear penalties violations police chapter accountability procurement publi investment little money time resources dealing mess technologies create harm ana brandusescu artificial intelligence governance expert appeared individual march accountability transparency respect transparency frt works wang said models trained using machine learning perform tasks currently diffic ult interpret since clear patterns models relying hand explaining model necessarily solution brandusescu said explainable computational solution make sure frt forward explanation depends audience audience usually comprised computer scientists politicians said trying derstand black box important explanation mean technology used piovesan also raised importa nce able explain technology understanding algorithms operate output provide independent verification ensure output accurate reliable also noted importance meaningful iscussion variety stakeholders technologies used implications rolled said one way achieve goal apply adopt concept radical transparency piovesan explained radical transparency speaks entire disclosure process encourages organizations use advanced technology let people know facial recognition technology growing power artificial intelligence vendors uses collecting data use radical transparency seeks engage public rather foster secretive environment undermines people trust jenkins also emphasized transparency important public needs understand technologies used effective may affect auditing use frt making public example would help transparency said transparency also portant component ethical system mcsorley said needs pressure greater transparency accountability gover nment said federal agencies required conduct privacy impact assessments new technology private projects undertaken assessments often done kept example said national security intelligence review agency undertaking review use biometric surveillance could take couple years made argued lack transparency accountability means technology adopted without public knowledge let alone public debate independent farooq made complementary comments said hard eng age government agencies basic facts acknowledged example csis refuses confirm whether uses frt hard get sense accountability khoo said case police policies governing use even black box algorithms said said lack transparency gives rise severe due process deficits criminal cases recommended robust transparency accountability measures established brandusescu sugges ted treasury board involved creating registry especially used law enforcement national security purposes said registry would useful researchers academics investigative journalists inform public government canada directive privacy impact assessme effect since applies government institutions subject section privacy act national security intelligence review agency national security ntelligence review agency departmental plan departmental plan states agency conducting ongoing review use biometrics watkins said better insight needed technology tools like used data stored decisions made whether humans involved short transparency needed governance accountability laplante said since biometric data sensitive security data must ensured collected used stored according frt like high system undergo extensive validation limitations properly understood taken consideration applied real world respect governance laplante said overnance requirements proportional risk materiality impact assessments common practice context oversight issues technical robustness safety privacy data governance fairness accou ntability oversight end system production instead continue lifetime system requiring regular performance monitoring testing validation root bias technology laplante recommended committee look concept ethics design involves taking ethical considerations account throughout development cycle initial data collection algorithm development production monitoring systems labonté explained system biased means initial data samples equal representative equal way said essential regulate data harvesting noting competitive players moment ones collected enormous amounts data use training models maslej said cases data provided model likely contain biased data data proactively filtered models likely behave problematic ways explained filtering data used train model could fix problem would likely affect model ability perform optimally wang said correct bias problems frt results providers collect diverse inclusive data sets perform disaggregated analyses accuracy rates across different demographic groups rather looking one overall accuracy metric noted however collection data sets may exploitative marginalized groups violating privacy facial recognition technology growing power artificial intelligence brandusescu also suggested prioritizing accountability example public sector said rcmp required publish report explaining use frt practice could applied federal departments agencies federal institutions already required comply treasury board directive automated decision federal directive requires among things algorithmic impact assessment aia completed prior production automated decision system depending impact level different accountability mechanisms required peer review human involvement directive also imposes transparency quality assurance obligations making aia public however brandusescu said federal directive needs improved believes public information government use technology like frt get updates example suggested treasury board publish recent government involvement website procuremen new technologies frt also recommended specific ongoing monitoring requirements systems initial aia use impact system changes brandusescu also noted non stakeholders consulted aias published government since federal directive came effect suggested aias could improved engaging civil society argued engaging companies limits input canadians affected groups digital rights organizations civil society bodies brandusescu recommended privacy commissioner demand report commissioner currently order powers bill act enact consumer privacy protection act personal information data protection tribunal act artificial intelli gence data act make consequential related amendments acts introduced house commons june passed current form would give commissioner power issue orders enforcement federal privacy legislation applies private sector privacy act applies public sector including rcmp directive automated decision requires dependi level impact automated decision system peer review conducted one following groups means qualified expert federal provincial territorial municipal government institution qualified members faculty post institution qualified researchers relevant non organization contracted third vendor related specialization publishing specifications automated decision system peer journal data automation advisory board specified treasury board secretariat watkins said need ensure accountability build kinds relationships government private actors public interest address needs vulnerable brandusescu also noted need increase expertise agencies understand technology buying vein jenkins recommended attention human operators design implementation facial recognition systems transparency development expert workforce facial though added human oversight provides important safeguards mechanism accountability however also imposes upper limit accuracy tha face recognition systems could achieve words whenever human oversight risk human error mitigate risk important ensure people involved decisions highly procurement public partnerships brandusescu said issue relating technologies like frt data protection priva conversation private sector involvement public governance said people concerned private sector king government policy development regulate frt public partnerships key element procuring deploying developing using technologies said recent report colleague argued taxpayers essentially paying surveilled companies like clearview exploit public sector technology procurement processes lack regulatory example perceived flaws procurement process brandusescu raised fact palantir technologies federal government list pre suppliers despite reports tha company committed human rights violations elsewhere immigration mass arrests separation children parents said companies linked human rights abuses removed government list ethi evidence rob jenkins centre media technology democracy stevens ana brandusescu weak privacy weak procurement state facial recognition canada april gover nment canada treasury board secretariat list interested artifi cial intelligence suppliers amnesty international failing right urgent need palantir respect human rights ethi evidence ana brandusescu facial recognition technology growing power artificial intelligence moreover brandusescu said sometimes evade procurement policies offering free software trials case clearview said improve publ procurement policy proactive disclosure free software trials used law enforcement government created well public registry would make black box glass molnar urged committee consider private sector often gets determine canada innovates public partnerships states increasingly keen make today global arms race reiterated need pay careful attention particular actors involved ecosystem technologies develop according none neutral political khoo thomasen raised emergence amazon ring partnerships example surveillance infrastructure using publ partnership mcsorley noted without proper regulation many companies proposing technology law enforcement agencies hard know whether even using accurate technology using accessible ones targeted marketed towards law enforcement believes lack regulation allowed rcmp use clearview frt months without public knowledge neither israel bhandari aware centralized registry companies offering frt said states require data brokers register bhandari said requiring kind transparency companies selling algorithmic tools would allow private right action regulators know hould monitoring thomasen suggested systems developed using data legally sourced informed consent thro ugh processes ensure dignity individuals whose data processed systems could designed used specific use cases opposed commercial systems take account specific social context frt used special report rcmp para opc reported rcmp confirmed purchased licenses use clearview services rcmp members also used clearview technology via free trial accounts procurement police forces regard police procurement technology khoo explained strict legal safeguar must place ensure police reliance private sector companies create way around people rights liberty protection unreasonable search seizure example software companies like clearview amazon rekognition nec corporation typically protected trade secret laws procured basis behind lobbying khoo says circumstance results secretive public private surveillance partnerships strip defendants due process rights subject public inscrutable layers mass surveillance address situation recommended commercial technology vendor collects personal data law enforcement contractually bound otherwise held standards privacy disclosure khoo made three specific recommendations law enforcement procurement process protect privacy ensure accountability law enforcement acquisition frt algorithmic policing technology done without eng aging commercial vendor beholden proprietary interests developing frt procurement must commercial vendor strict procurement conditions put place waiving trade secrets independ ent auditing ensure less secrecy around contracts people know prior signed rather leaks freedom information requests investigations journalists piovesan agreed khoo recommendations public investment khoo said private companies collect vast quantities data capitalize often funded government grants whether guise innovation khoo gave example lab saskatchewan saskatchewan police predictive analytics lab publicly funded collaboration municipal police force university saskatchewan built frt facial recognition technology growing power artificial intelligence lobbying said essenti ally government private companies working hand hand build network brandusescu said bigger questi canada military complex surveillance technologies like frt come believes canada needs reflect tech solutionism means much money put tech innovation funding groups work hard social issues understand technology create public awareness education brandusescu believes government fund frt instead fund civil society digital rights groups community groups studying frt involve conversation government decides fund said think push back tech inevitability say technology also requires funding resources education around technologies lot contracts made behind closed doors industry government relationships public partnerships sometimes involve universities labs always private interest focus want fund technologies build use think consequences little money time resources dealing mess technologies create harm create polsky said canadians fully aware privacy rights raised idea developing education programs schools acknowledged education provincial jurisdiction said media organizations privacy commissioners across country developed courses programs mandatory suggeste opc given education mandate funding awareness example accountability action microsoft microsoft shared internal frt practices portraying example responsible provider private sector larter said microsoft broad responsible program three main components compa governance team includes multiple stakeholders including world researchers standard ensures teams federal priv acy commissioner already educational mandate section personal information protection electronic documents act requires commissioner develop conduct information programs foster public understanding recog nition purposes obligation remains proposed consumer privacy protection act bill similar provision found privacy act developing deploying systems way meets principles sensitive review larter explained sensitive use review done potential development deployment system hits one three triggers system used way affects person legal opportunities legal standing potential psychological physical harm implication human rights cases microsoft governance team ets reviews whether company move forward particular respect frt larter said microsoft published trans parency note face application programming interface api note explains plain language frt works capabilities limitations factors affect performance said microsoft developing frt mindful representative datasets technology perform accurately including across different demographic groups larter said testing really important given wide gap best performing facial recognition systems least well systems said vendors allow systems tested independent third parties reasonable fashion required address material performance microsoft allows systems tested also said need robust cybersecurity around technology committee observations recommendations committee believes government transparent abou use frt well procurement process also invest studying impact raising awareness privacy rights therefore committee recommends ibid microsoft putting principles practice microsoft microsoft standard consists series requirements related six principles fairness reliability safety privacy security inclusiveness transparenc accountability ibid ethi evidence owen larter according larter testing requirement organizations deploying frt make sure system working accurately environment going used facial recognition technology growing power artificial intelligence recommendation government canada amend procurement policies require government institutions acquire facial recognition technology algorithmic tools including free trials make acquisition public subject national security concerns recommendation government canada create public registry algorithmic tools used entity operating canada listed subject national security concerns recommendation government canada enhance treasury board directive automated decision ensure participation civil society groups algorithmic impact assessments impose specific requirements ongoing monitoring artificial intelligence systems recommendation overnment canada increase investment initiatives study impact artificial intelligence various demographic groups increase digital literacy educate canadians privacy rights recommendation government nada ensure full transparent disclosure racial age unconscious biases may exist facial recognition technology used government soon bias found context testing scenarios live applications technology subject national security concerns recommendation government canada establish robust policy measures within public sector use facial recognition technolog could include immediate advance public notic public comment consultation marginalized groups independent oversight mechanisms chapter regulating facial recognition technology artificial intelligence frts need regulated scalpel axe carole piovesan managing partner inq law appeared committee march polsky pointed supreme court canada recognized long ago privacy essential well individual rounded man physical moral autonomy privacy essential well however given place frt already society committee wondered late intervene witnesses said others said proliferation frt spell end individual therrien also felt late intervene explained heard ask certain witnesses committee late never late actually fact certain practices currently occurring reason prevent right hing regulating technology way respects rights canadians living completely part world self led certain unacceptable practices routine banal continue authorized witnesses suggested number ways address shortcomings current legislative regime moratoriums bans measures given risks frt stakeholders recommended moratorium particularly law enforcement appropriate regulatory framework place dyment scr para justice forest ethi evidence cynthia khoo ethi evidence carole piovesan ethi evidence rob jenkins ethi evidence daniel therrien ethi evidence esha bhandari ethi evidence tamir israe ethi evidence cynthia khoo ethi evidence ana brandusescu ethi evidence sanjay khanna ethi evidence rob jenkins facial recognition technology growing power artificial intelligence research consultation use technology impacts example khoo said moratorium national pause use frt law enforcement shown reliable also necessary proportionate legitimate aims far rep ercussions use may rule potential ban use frt cities case khoo said mor atorium use frt law enforcement give time research determine whether appropriate use safeguards transparency adequate oversight mechanisms disclosure requirements called moratorium frt algorithmic policing technologies also proposed moratorium national commission judic ial inquiry constitutional human rights analysis determine appropriate mcsorley thomasen recommende moratorium federal government hold consultations use regulation frt example decide uses prohibited mcphail said one purpose moratorium would give government chance rectify major gap federal privacy regime fact commissioner enforcement powers said moratorium law enforcement particularly important situations consequences error life general moratorium would also ethi evidence cynthia khoo ethi evidence kristen thomasen ethi evidence brenda mcphail ethi evidence sanjay khanna ethi evidence elizabeth anne watkins ethi evidence angelina wang ethi evidence tim mcsorley ethi evidence rizwan mohammad ethi evidence mustafa farooq ethi evidence sharon polsky ethi evidence tamir israel cmtd cpe brief iclmg brief tessono brief ligue des droits libertés brief canadian human rights commission brief ethi committee study use impact facial recognition technology april chrc brief ethi evidence cynthia khoo ethi evidence esha bhandari according bhandari least cities halted law enforcement government use facial recognition technology see also cmtd cpe brief tessono brief ethi evidence cynthia khoo citizen lab report khoo defines algorithmic policing new technologies use automated mathematical formula support supplement police decision beneficial given private sector vendors selling technologies public sector khoo also said moratorium sectors would appropriate witnesses idea moratorium example larter said microsoft believes instead investing time effort imposing moratorium police use frt regulated said microsoft supports frt regulation protects human rights prohibits mass surveillance advan ces transparency accountability view regulatory framework would build public trust use frt larter noted however microsoft imposed moratorium sale frt police forces said ban apply canada unli canada federal privacy framework broad privacy stairs tps believe moratorium use frt police forces imposed technology regulated view balance public security safety benefits frt human rights challenges technology important thing deploy technology tps major crimes major cases therrien also said favour complete moratorium said moratorium imposed legislation commissioner power impose moratorium position federal provincial territorial privacy commissioners legislation prescribe used legitimate helpful purposes social good investigating serious crimes finding missing children legitimate uses defined narrowly law also prescribe prohibited uses ban would rtial moratorium use frt therrien said believes use frt compelling circumstances said rcmp frt according new policy targeted time use subject verification trained experts investigational aid confirm ethi evidence brenda mcphail mcphail gave example bill place moratorium government use facial recognition technology rules governing use place text congress ethical use facial recognition act february bill referred senate committee made progress ethi evidence owen larter facial recognition technology growing power artificial intelligence identity would also form voluntary partial moratorium legislation respect bans mcphail said ccla supports complete ban mass surveillance uses molnar said ongoing discussions europe outright ban biometric mass surveillance high frt lie detectors migration border nagement said canada ban high use frt border farooq said use real frt airports borders banned bhandari recommended banning government law enforcement use frt israel recommended permanent ban use automated live biometric recognition police public spaces addition moratorium ban khanna suggested adopting digital charter rights canadians would recognize sanctity personal data like facial data charter could align canadian charter rights freedoms said would allow canadians portable secure form biometric data considered sac rosanct also encouraged legislators use scenario planning inform resilient strategy public policy face digital advances privacy guidance facial recognition police agencies may federal privacy commissioner provincial territorial counterparts issued guidance facial recognition police therrien explained guidance meant assist police ensuring use frt complies law minimizes privacy risks respects privacy rights said guidance developed following national public consultation broad range people stakeholders agreed current laws inadequate however consensus content new ethi evidenc daniel therrien see also ligue des droits libertés brief organization believes three uses frt immediately prohibited legislation mass surveillance public places mass online surveillance use image banks created public gencies departments opc privacy guidance facial recognition police agencies may stakeholders representing civil society min ority groups police participated consultation therrien met number times royal canadian mounted police canadian association chiefs police colleagues also met provincial equivalents therrien noted laws amended guidance offers advice police use frt current laws hopes guidance mitigate risks therrien also acknowledged stakeholders anted guidance provided commissioners include advice use cases agreed need advice particular uses different contexts said commissioners thought important relevant general guidance augmented use cases developed kosseim said may take several years jurisprudence frt charter commissioners recommend adoption legislative framework interim developed guidance help mitigate risks kosseim presented five key elements guidance first using facial recognition purpose police agencies must establish lawfully authorized given assumed second police agencies must establish strong accountability measures includes designing privacy every stage facial recognition initiative conducting privacy impact assessment pia assess mitigate risks advance implementation third poli agencies must ensure quality accuracy personal information used part facial recognition system avoid false positives reduce potential bias prevent harms individuals groups fourth police agencies retain per sonal information longer necessary fifth policy agencies must address transparency public engagement direct notice use facial recognition may always possible context specific police investigation however transparency program level certainly possible kosseim also made clear communication public two way said key stakeholders particularly representatives groups consulted design police service program added given importance reconciliation canada must inc lude input indigenous groups communities kosseim said basic principles advanced guidance apply regardless sector necessary adjustments contexts range risks play since specifically designed police services facial recognition technology growing power artificial intelligence therrien made similar comments noting common factor applies horizontally stakeholders would like use frt whether police services businesses government principle necessity proportionality example police services use frt extremely serious consequences resulting even loss freedom total prohibition use police services certain circumstances might necessarily apply stakeholders confirmed recommendations made commissioners apply use frt public spaces well legislation respect regulating frt witnesses agreed current legislative framework provides protections insufficient example therrien said patchwork laws govern canadian charter rights freedoms common law certain laws including privacy problem says patchwork laws used many ways believes current rules vague give necessary level trust citizens collection information public private sector piovesan made similar comments aid protections current federal privacy laws privacy act pipeda apply use frt example said pipeda requires companies obtain consent collect highly sensitive data public actors regulation common law govern certain information collected stored retained however said comprehensive really focused law around frt thomasen explained facial surveillance systems socio systems understood looking system built one must also look interact people people affected social environments added part socio context facial surveillance introduced includes gaps application underlying theories laws general application laws adequately protect misuses technology cmtd cpe brief iclmg brief stakeholders also referred canada obligations article universal declaration human rights articles international covenant civil political rights committee notes bill act enact consumer privacy protection act personal information data protection tribunal act artificial intelligence data act make consequential related amendments acts introduced house commons june passed current form could address certain gaps current privacy legislative framework may appl frt however since bill yet passed committee making recommendations based legislative framework place legislative framework public private sector shape relatively comprehensive regulat ory framework frt mitigates threat technology poses takes advantage real beneficial possibilities piovesan said canada consider four principles align organisation economic development oecd leading international guidance responsible oecd principles technical robustness accountabi lity lawfulness fairness example said respect technical robustness questions inform regulation include wha specific technical criteria ought associated frt use cases whether independent third parties engaged oversight assess frt technical perspective terms accountability questions include administrative contr ols required impact assessment controls determined stakeholders consulted respect lawfulness questions include oversight needed promote alignment frt uses soci etal values law finally respect fairness questions adverse effects frt rights freedoms ways minimize effects must committee notes witnesses proposed various legislative measures would address many issues raised piovesan legisinfo bill act enact consumer privacy protection act personal information data protection tribunal act artificial intelligence data act make consequential related amendments acts parliament session bill bill introduced house commons june sabrina charland alexandra savoie ryan van den berg legislative summary bill act enact consumer privacy protection act perso nal information data protection tribunal act artificial intelligence data act make consequential related amendments acts publication july organisation economic development oecd oecd principles overview ethi evidence carole piovesan facial recognition technology growing power artificial intelligence respect enforcement several witnesses recommended granting federal privacy commissioner greater powers including power make orders impose stiff fines found general data protection regulation gdpr european therrien said powers office strengthened make decisions consent piovesan said although depends use case consent thrown requirement immutable biometric data said aving appropriate notice ability individual make decisions share information collected really khoo also agreed canadians must able give prior informed consent data collected laplante said regulations need provide frt developers deployers users clear requirements obligations regarding specific uses technology including requirement gain affirmed consent collection use biometr data well purpose limitation avoid function added however regulations seek take balanced approach reduces administrative financial burdens public private entities possible israel recommended privacy act pipeda amended collection use disclosure biometric information requires express cons ent contexts also recommended biometric information defined sensitive case quebec bhandari said consent requirement biometrics captured critical labonté said people need aware data going used give informed consent however poitras said obtaining consent people context always appropriate power asymmetry whether citizen state citizen major corporation like web explained ethi evidence cynthia khoo ethi evidence carole piovesan ethi evidence tim mcsorley ethi evidence brenda mcphail ethi evidence tamir israel iclmg brief bill passed current form would grant privacy commis sioner power make binding orders however would grant commissioner power impose fines penalties power would granted new tribunal established bill see sections proposed consumer privacy rotection act cppa see also cmtd cpe brief stakeholders also recommended federal privacy laws amended provide special protection biometric information including notice consent prior use legislative permi ssion see also ethi evidence elizabeth anne watkins way mitigate consent legally authorize acceptable uses prohibit others uses even consent authorization appropriate democratic society mcsorley recommended private sector privacy laws based human rights necessity proportionality regulations clear rules consent rules apply oversight development private laplante also said frt legislation based principles necessity proportionality respect public sector mcsorley recommended clear establishment zones clear rules around ssuance privacy impact assessments also recommended mandatory review algorithmic biometric surveillance tools used law enforcement assess human rights impact accuracy bias polsky said laws must enacted requiring everyone creates purchases uses technology demonstrate clear correct grasp canadian laws privacy rights way vehicles foods must meet stringent government regulations allowed sale use creators technologies subject laws requiring technologies undergo comprehensive independent examination privacy cess algorithmic integrity well bias polsky suggested technology tested neutral sandbox run privacy commissioner involving civil society groups approve allowed sale canada centre media technology democracy cybersecure policy exchange recommended privacy act pipeda harmoni zed federal government directive automated decision israel suggested similar approach argued onus government justify use frt recommended privacy act pipeda amended legally require companies government agencies file impact assessments ibid ibid section artificial intelligence data act created bill authorizes minister designated act order minister reasonable grounds believe person contravened requirements act organization conduct audit possible contravention engage independent auditor conduct audit provide report minister audit would done product commercialized obligations artificial intelligence data act would apply government institutions cmtd cpe brief facial recognition technology growing power artificial intelligence privacy commissioner prior adopting intrusive technologies commissioner empowered review technologies public regulatory process put place usage limitations even moratoria necessary israel also said important legislate man decision loop technologies although noted human intervention solve bias problems said sing facial recognition systems tendency trust automated results assume accurate match end embedding cognitive biases farooq also agreed human checks important said law enforcement example given problem systemic racism bias within police agencies courts place get checks balances understa nding mohammad recommended government put forth clear privacy legislation severely curtails frt used non consum context according nccm law impose blanket ban frt government without judicial authorization particularly national security agencies also set clear penalties agencies violate privacy rules farooq said process using frt similar process police must follow obtain search warrant appear judge put forward argument clear documentation evidence respect pipeda therrien explained principles techno logyneutral legislation private sector makes sense starting point however said frt shows limits virtues prin ciples approach approach leaves lot discretion example police exercise broad principles way suits interests risks frt therrien said ought specific provisi ons prohibit uses except certain bill proposes create artificial intelligence data act act imposes certain requirements high impact artificial intelligence systems privacy commissioner responsible administration act responsibility rest minister industry minister designated act minister may designate senior official department whi minister presides called artificial intelligence data commissioner explicit requirement privacy impact assessments proposed act ethi evidence mustafa farooq said commissioners recommend legislation define allowable prohibited uses part mcphail told committee attention must paid technical privacy protections also contextually relevant protections full set rights engaged technology recommended cross data protection law grounded human rights framework noted targeted laws governing biometrics algorithmically driven technologies ould even better fit purpose comprehensive effective legislation applies frt provide clear legal framework use frt rigorous accountability transparency provisions independent oversight effective means enforcement failure comply therrien also noted frt brings rights privacy play right equality democratic rights said therefore possible number regulatory agencies including opc responsible oversight example canadian human rights commission provincial equivalents could responsible cases discrimination khanna said legislation frt based research insight racialized minorities first nations children anyone vulnerable sort exploitation example recommended consulting unicef policy guidance also underscored need draw people know within industry equalize create proper symmetry legislators know companies using technology know polsky hand said standards set without direct indirect influence input also suggested replacing fragmented legislation federal provincial territorial levels one overarching piece legislation covers public sector private sector non sector political rties bill passed current form creates artificial intelligence data act regulates international interprovincial trade commerce artificial intelligence system establishing common requirements applicable across canada design development use systems act would also prohibit certain conduct relation artificial intelligence systems may result serious harm individuals harm interests unicef policy guidance children report highlights toys interact chi ldren risks pose around children security privacy ethi evidence sharon polsky facial recognition technology growing power artificial intelligence finally witnesses suggested changes could also made non legislation example therrien said certain circumstances required court warrant use frt amendments criminal code may required israel recommended amending criminal code limit law enforcement use frt investigations serious crimes absence reasonable grounds believe farooq mentioned possibility amendments royal canadian mounted police act canadian security intelligence service act specify provisions amended legislative framework police services kosseim said commissioners main recommendation police agencies establish comprehensive statutory regime governing use frt clear guardrails rce law necessary ensure police agencies make use frt grounded transparent framework capable earning public enduring trust therrien explained colleagues believe legislative framework apply use frt police agencies based four elements first recommend law clearly explicitly defin purposes police would authorized use facial recognition technology prohibit uses authorized purposes compelling proportionate high risks technology second since realistic law anticipate circumstances important addition limitations authorized purposes law also require police use facial recognition necessary proportionate given deployment tec hnology third recommend police use facial recognition subject strong independent oversight oversight include proactive engagement measures privacy impact assessments pias program level authorization advanc notification use powers audit make orders finally recommend appropriate privacy protections put place mitigate risks individuals including measures addressing accuracy retention transparency facial recogn ition initiatives therrien raised possibility example police force program use frt require privacy commissioner autho rization suggested technology adopted actually used oversight include authority investigate complaints make orders lawfulness use technology given case canadian human rights com mission indicated legal framework police use frt take human approach integrates protections children youth approach uses international human rights best practices juris dictions poitras said quebec biometric databases use biometrics identification purposes governed act esta blish legal framework information technology privacy statutes applicable public private act creation every biometric database must reported cai september reporting also required every instance biometrics used identification purposes poitras said quebec act could improved expand ing scope act establishes obligations biometrics including frt used verify identity however frt used purposes poitras explained quebec iometrics may used identification purposes without express consent person concerned biometric characteristic may recorded without person knowledge minimum number biometric characteristics may recorded used information may discovered based characteristics may used preserved lastly biometric information note concerning information must destroyed purpose verification confirmation identity achieved commission broad authority may make order respecting biometric banks including authority suspend prohibit bringing service order destruction general privacy protection rules also apply addit ion specific provisions means example use facial recognition must necessary proportionate objective pursued chrc brief five elements human approach legality non participation empowerment accountability quebec act establish legal framework inform ation technology chapter quebec act respecting access documents held public bodies protection personal information quebec public sector act chapter uebec act respecting protection personal information private sector chapter quebec private sector act facial recognition technology growing power artificial intelligence poitras added privacy impact assessment mandatory quebec september biometric information expressly designated sensitive personal larter said washington state passed legislation lays important transparency accountability measures use frt including testing requirement oversight appropriately trained utah bill entitled governmental use facial recognition technology passed requires government entities notify ndividuals whenever capturing images could used conjunction frt provide days prior notice proposed illinois passed biometric information privacy act bipa act prohibits companies selling otherwise profiting consumers biometric watkins said bipa allowed lawsuit filed facebook using facial recognition photo identification bhandari added act also allowed aclu file lawsuit clearview resulted settlement settlement company longer provide access database containing hundreds millions face rints private entities across exceptions banned selling technology illinois law enforcement five bhandari advocated adoption legislation like illinois bipa updates said biometric privacy law early require companies obtain notice written consent collecting using disclosing person identifier prohibit companies withholding services people choose national assembly quebec bill act modernize legislative provisions regards protection personal information passed september bill amends quebec public sector act quebec private sector act include obligation exceptions provisions bill come force september washington state legislature concerning use facial recognition services bill washington state local agencies including law enforcement use plan use facial recognition technology must meet certai reporting deployment requirements opc letter committee may ibid committee invited facebook appear part study declined stating facebook longer uses facial recognition technolo meta update use face recognition november google also invited declined amazon accepted invitation testify could appear ter change schedule none companies submitted brief aclu big win settlement ensures clearview complies groundbreaking illinois biometric privacy law may news release consent also require businesses delete biometric identifiers one year individual last interaction bhandari named two models follow maine proposed act regulate use biometric identifiers would require private entities obtain express consent individuals collect use disclose biometric identifiers law would also prohibit sale biometric data impose limits data storage maryland bill entitled biometric data privacy act introduced seeks create framework similar one therrien mentioned federal laws proposed including fourth amendment sale act would stop data brokers selling personal information law enforcement agencies without court oversight would ban use data illegally obtained public algorithmic accountability act would require private organizations conduct assessments automated cision systems algorithmic bias respect europe several witnesses said gdpr model data gdpr biometrics including facial images considered special category data prohibited unless controller rely upon legal ground ground piovesan said gdpr includes right recourse right objection profiling solely automatic also said gdpr fines imposed use data european residents even actual activity bill passed current form contains right opt section new cppa aclu biometric identifiers fact sheet document submitted ethi committee june maine bill aclu biometric data privacy act amendment recommendations fact sheet maryland document submitted ethi committee june maryland bill aclu said several amendments made text original bill maryland house representatives weakened bill opc letter committee may identical bill introduced senate fourth amendment sale act opc letter committee may identical bill introduced senate algorithmic accountability act ethi evidence ana brandusescu ethi evidence elizabeth anne watkins european union eur regulation european parliament council april protection natural persons regard processing personal data free movement data repealing directive general data protection regulation text eea relevance opc letter committee may noted similar right exists quebec law well facial recognition technology growing power artificial intelligence take place european jurisdiction gdpr therefore extra appl icability watkins said gdpr contains right explanation ensures example companies provide workers insights decisions made automated european union directive protection individuals regard processing personal data competent authorities purposes prevention investigation detection prosecution criminal offences execution criminal penalties free movement data also raised forbids law enforcement processing biometric data purpose uniquely identifying person except authorized law making decisions based solely automated processing including profiling unless european union domestic law provides appropriate safeguards individual rights finally witnesses brought european union proposed artificial intelligence therrien explained act adopted would outlaw public private sectors using harmful applications among things manipulate individuals exploit vulnerabilities individuals due certain personal characteristics non applications high including use biometrics identification categorization subject specific legal requirements risk management easures systems logging record keeping general human oversight accurate representative data training ante conformity assessments demonstrable therrien said european proposal protects constituti onal human rights kosseim poitras agreed bill passed current form contains right explanation sections cppa directive european parliament council april protection natural persons regard processing personal data competent authorities purposes prevention investigation detection prosecution criminal offences execution criminal penal ties free movement data repealing council framework decision official journal european union cmtd cpe brief european commission proposal regulation european parliament council laying harmonised rules artificial intelligence artificial intelligence act amending certain union legislative acts ethi evidence petra molnar ethi evidence cynthia khoo ethi evidence alex laplante opc letter committee may piovesan said risk approach regulation european proposal seen risdictions european proposal would also prohibit use real frt public spaces law enforcement molnar said proposal recognizes individual risk assessments purposes immigration refugee processing high bans assessments used profiling strengthening systemic discrimination respect united king dom jenkins brought surveillance camera code practice provides guidance appropriate use surveillance camera systems local authorities police code states use frt always involve human intervention decision taken affect individual biometrics surveillance camera commissioner independent monitoring body encourages compliance code scotland also biometrics commissioner since published draft code practice april committee observations recommendations committee found witnesses clearly demonstrated inadequacy current legislative framework regulation frt committee ther efore makes following recommendations recommendation government define appropriate legislation acceptable uses facial recognition technology algorithmic technologies prohibit uses including mass surveillance ethi written response submitted committee sharon polsky june european parliamentary research service stoa study diverging obligations facing public private sector applications artificial intelligence united kingdom home office surveillance camera code practice united kingdom biometrics surveillance camera commissioner see also ethi written response submitted committee sharon polsky june scotland scottish biometrics commissioner united kingdom scottish biometrics commissioner act see also ethi written response submitted committee sharon polsky june april scottish commissioner published draft code practice acquisition retention use destruction biometric data criminal justice police purposes scotland facial recognition technology growing power artificial intelligence reco mmendation government canada amend privacy act require prior adoption creation use facial recognition technolog government agencies seek advice recommendations privacy commissioner file impact assessments office recommendation government canada update canadian human rights act ensure applies discrimination caused use facial recognition technology artificial intelligence technologies recommendation government canada implement right erasure right forgotten requiring service providers social media platforms online entities operating canada delete users personal infor mation set period following users termination use including limited uploaded photographs payment information address contact information posts survey entries recommendation government canada implement requirement collection biometric information private sector entities prohibit entities making provision goods services contingent providing biometric information recommendation government canada strengthen ability privacy commissioner levy meaningful penalties government institutions private entities whose use facial recognition technology violates privacy act personal information protection electronic documents act deter future abuse technology recommendation government canada amend privacy act personal information protection electronic documents act prohibit practice capturing images canadians fro internet public spaces purpose populating facial recognition technology databases artificial intelligence algorithms recommendation government canada impose federal moratorium use facial recognition techno logy federal policing services canadian industries unless implemented confirmed consultation office privacy commissioner judicial authorization overnment actively develop regulatory framework concerning ses prohibitions oversight privacy facial recognition technolog oversight include proactive engagement measures program level authorization advance notification use powers audit make orders recommendat ion federal government ensure appropriate privacy protections put place mitigate risks individuals including measures addressing accuracy retention transparency facial recognition initiatives well comprehensiv strategy around informed consent canadians use private information conclusion committee study confirmed canada current legislative framework adequately regulate frt without appropriate framework frt tools could cause irreparable harm individuals committee therefore view frt technology used must used responsibly within robust legislative framework protects canadians privacy rights civil liberties since legislative framework exist time national pause imposed use frt particularly respect police services committee strongly encourages government canada plement recommendations quickly possible appendix list witnesses following table lists witnesses appeared committee meetings related report transcripts public meetings related report available committee webpage study organizations individuals date meeting individual ana brandusescu artificial intelligence governance expert cynthia khoo research fellow citizen lab munk school global affairs public policy university toronto kristen thomasen professor peter allard school law university british columbia inq law carole piovesan managing partner refugee law petra molnar lawyer york university borealis alex laplante senior director product business engagement canadian civil liberties association brenda mcphail director privacy technology surveillance program computer research institute montréal françoys labonté chief executive officer international civil liberties monitoring group tim mcsorley national coordinator organizations individuals date meeting individual rob jenkins professor university york sanjay khanna strategic advisor foresight expert angelina wang computer science graduate researcher princeton university elizabeth anne watkins postdoctoral research associate princeton university royal canadian mounted police andré boileau officer charge national child exploitation crime centre paul boudreau acting deputy commissioner specialized pol icing services toronto police service colin stairs chief information officer toronto police services board dubi kanengisser senior advisor strategic analysis governance commission québec diane poitras president office information privacy commissioner ontario patricia kosseim commissioner vance lockton senior technology policy advisor office privacy commi ssioner canada daniel therrien privacy commissioner canada david weinkauf senior information technology research analyst microsoft owen larter director responsible artificial intelligence public policy national council canadian muslims mustafa farooq chief executive officer rizwan mohammad advocacy officer organizations individuals date meeting royal canadian mounted police andré boileau officer charge national child exploitation crime centre gordon sage director general sensitive specialized investigative services roch séguin director strategic services branch technical operations toronto police service colin stairs chief information officer individual nestor maslej research associate institute human artificial intelligence stanford university privacy access council canada sharon polsky president american civil liberties union esha bhandari deputy director samuelson canadian internet policy public interest clinic tamir israel staff lawyer appendix list briefs following alphabetical list organizations individuals submitted briefs committee related report information please consult committee webpage study canadian human rights commission centre media technology democracy cybersecure policy exchange jenkins rob international civil liberties monitoring group ligue des droits libertés maslej nestor refugee law lab tessono christelle request government response pursuant standing order committee requests government table comprehensive response report copy relevant minutes proceedings meetings nos tabled respectfully submitted pat kelly chair
