<!DOCTYPE html>
<!--[if lt IE 9]><html class="lte-ie8 govuk-template" lang="en"><![endif]--><!--[if gt IE 8]><!--><html class="govuk-template" lang="en">
<!--<![endif]-->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta property="og:description" content="">
<meta property="og:title" content="Ambitious, safe, responsible: our approach to the delivery of AI-enabled capability in Defence">
<meta property="og:url" content="https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence">
<meta property="og:type" content="article">
<meta property="og:site_name" content="GOV.UK">
<meta name="twitter:card" content="summary">
<meta name="govuk:organisations" content="&lt;D17&gt;">
<meta name="govuk:ga4-publishing-government" content="2019 to 2022 Johnson Conservative government">
<meta name="govuk:ga4-political-status" content="historic">
<meta name="govuk:primary-publishing-organisation" content="Ministry of Defence">
<meta name="govuk:public-updated-at" content="2022-06-15T11:10:00+01:00">
<meta name="govuk:updated-at" content="2024-09-13T11:40:23+01:00">
<meta name="govuk:first-published-at" content="2022-06-15T11:10:10+01:00">
<meta name="govuk:content-id" content="92515224-56e7-43fd-bdda-299aa9736e68">
<meta name="govuk:schema-name" content="html_publication">
<meta name="govuk:rendering-app" content="government-frontend">
<meta name="govuk:publishing-app" content="whitehall">
<meta name="govuk:format" content="html_publication">
    <meta charset="utf-8">
    <title lang="en">
      Ambitious, safe, responsible: our approach to the delivery of AI-enabled capability in Defence - GOV.UK
  </title>

    <script src="/assets/static/govuk_publishing_components/vendor/lux/lux-measurer-db6c8505a6690974922b8578eb1f2208d3073807f98d9a048efe9991f8dfc92d.js" async="async"></script>
    <script src="/assets/static/govuk_publishing_components/rum-loader-a65b10e18ceeba3bd8a2eac507c7f2c513cdc82f35097df903fdea87f1dc2e33.js" async="async" data-lux-reporter-script="/assets/static/govuk_publishing_components/vendor/lux/lux-reporter-41a67efb7d0fa046d3da8e9d207661e2b88f1b47260f803fa9da2d8167f18e5c.js"></script>

    <meta name="govuk:components_gem_version" content="44.0.0">
    <script src="/assets/static/govuk_publishing_components/load-analytics-da466517f0c7c6cbcaa54a0d645fd3ddae99ec7a77cf8d30fa7d98cdad81fec9.js" type="module"></script>

    

    <link rel="stylesheet" href="/assets/static/application-cc0ecde743cdf51832782158798b3883f7adb3c4a19e7f9efde97c6d68e74e89.css" media="all">
    <link rel="icon" sizes="48x48" href="/assets/static/favicon-f54816fc15997bd42cd90e4c50b896a1fc098c0c32957d4e5effbfa9f9b35e53.ico">
    <link rel="icon" sizes="any" href="/assets/static/favicon-50144c9d83e59584c45b249ad9e9abfdd23689876c33f28457df13bbdd9c8688.svg" type="image/svg+xml">
    <link rel="mask-icon" href="/assets/static/govuk-icon-mask-cdf4265165f8d7f9eec54aa2c1dfbb3d8b6d297c5d7919f0313e0836a5804bb6.svg" color="#0b0c0c">
    <link rel="apple-touch-icon" href="/assets/static/govuk-icon-180-d2d7399ff2ba05372b6b2018cc67053e458a748cceea1a550d804dbec401e3ed.png">

    <meta name="theme-color" content="#0b0c0c">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://www.gov.uk/assets/static/govuk-opengraph-image-03837e1cec82f217cf32514635a13c879b8c400ae3b1c207c5744411658c7635.png">

    
  <link rel="stylesheet" href="/assets/government-frontend/application-c357aabf79c6236777c898194d9ab6cc820429fa50731a1ad9185441b1a72cbb.css" media="all">
<link rel="canonical" href="https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence">
<link rel="stylesheet" href="/assets/government-frontend/views/_html-publication-54225470c08fed56e0d5cc1185153e371967e24e1dc8639e2d8fad2b5cde4191.css">
<link rel="stylesheet" href="/assets/government-frontend/govuk_publishing_components/components/_organisation-logo-e50cf3b768494bc327ac55c6e79d98e63e828afe2099865f838f2b6a0ff0a86d.css">
<link rel="stylesheet" href="/assets/government-frontend/govuk_publishing_components/components/_inverse-header-3442c1a6bfce27a32679e8a05897b0d3c17a318e4a6f8d5f0ece82972818b176.css">
<link rel="stylesheet" href="/assets/government-frontend/govuk_publishing_components/components/_notice-ba5c9ca444a3fdf9d6107c30753707c5bdb724d62c2e103de8c50447bd655cad.css">
<link rel="stylesheet" href="/assets/government-frontend/govuk_publishing_components/components/_contents-list-61bcb99066ecefd96290d0112159064ee0c8f2e25891dca636a65d325bc7ebc0.css">
<link rel="stylesheet" href="/assets/government-frontend/govuk_publishing_components/components/_print-link-98446ac1b56886e6bd275df832312c44f45ede0264f8d8ecf98750450fb2c0d4.css">
<link rel="stylesheet" href="/assets/government-frontend/govuk_publishing_components/components/_govspeak-html-publication-f10529fb2cd130eab9e7974ad868351a3018ef733e38a1a8155bfb23d2484aa9.css">
<link rel="stylesheet" href="/assets/government-frontend/govuk_publishing_components/components/_govspeak-1fa5e58ce5e0ff477cd8fc42cc5d9cd1c272824fb8a794582341649deada91d0.css">
<link rel="stylesheet" href="/assets/government-frontend/components/_back-to-top-8d10a933dd34f1162faf988b7cf81c36c44ba29948683b0cdb2b654df304c32c.css">
<meta name="govuk:rendering-application" content="government-frontend">
</head>
  <body class="gem-c-layout-for-public govuk-template__body">
    <script nonce="8bULL1bqak7DTu7I/zZM/Q==">
//<![CDATA[
      document.body.className += ' js-enabled' + ('noModule' in HTMLScriptElement.prototype ? ' govuk-frontend-supported' : '');

//]]>
</script>    
<div id="global-cookie-message" data-module="cookie-banner" data-nosnippet="" aria-label="Cookies on GOV.UK" class="gem-c-cookie-banner govuk-clearfix govuk-cookie-banner js-banner-wrapper" role="region" hidden="hidden">
  <div class="govuk-cookie-banner__message govuk-width-container">
    <div class="govuk-grid-row">
      <div class="govuk-grid-column-two-thirds">
        <h2 class="govuk-cookie-banner__heading govuk-heading-m">Cookies on GOV.UK</h2>
        <div tabindex="-1" class="govuk-cookie-banner__content gem-c-cookie-banner__confirmation">
          <span class="gem-c-cookie-banner__content"><p class="govuk-body">We use some essential cookies to make this website work.</p>
<p class="govuk-body">Weâ€™d like to set additional cookies to understand how you use GOV.UK, remember your settings and improve government services.</p>
<p class="govuk-body">We also use cookies set by other sites to help us deliver content from their services.</p></span>
          <p class="gem-c-cookie-banner__confirmation-message--accepted govuk-body" hidden data-ga4-cookie-banner data-module="ga4-link-tracker" data-ga4-track-links-only data-ga4-set-indexes data-ga4-link='{"event_name":"navigation","type":"cookie banner","section":"You have accepted additional cookies"}'>You have accepted additional cookies. <span class="gem-c-cookie-banner__confirmation-message">You can <a class="govuk-link" href="/help/cookies">change your cookie settings</a> at any time.</span></p>
          <p class="gem-c-cookie-banner__confirmation-message--rejected govuk-body" hidden>You have rejected additional cookies. <span class="gem-c-cookie-banner__confirmation-message">You can <a class="govuk-link" href="/help/cookies">change your cookie settings</a> at any time.</span></p>
        </div>
      </div>
    </div>
    <div class="js-confirmation-buttons govuk-button-group">
        


  <button class="gem-c-button govuk-button" type="submit" data-accept-cookies="true" data-cookie-types="all">Accept additional cookies</button>


        


  <button class="gem-c-button govuk-button" type="submit" data-reject-cookies="true">Reject additional cookies</button>


        <a class="govuk-link" href="/help/cookies">View cookies</a>
    </div>
    <div hidden class="js-hide-button govuk-button-group">
      <button class="gem-c-cookie-banner__hide-button govuk-button" data-hide-cookie-banner="true" data-module="ga4-event-tracker" data-ga4-event='{"event_name":"select_content","type":"cookie banner","action":"closed","section":"You have accepted additional cookies"}'>
          Hide this message
        </button>
    </div>
  </div>
</div>
    <a class="gem-c-skip-link govuk-skip-link govuk-!-display-none-print" data-module="govuk-skip-link" href="#content">Skip to main content</a>

          <header role="banner" class="gem-c-layout-super-navigation-header" data-module="ga4-event-tracker ga4-link-tracker" data-ga4-expandable="">
  <div class="gem-c-layout-super-navigation-header__container govuk-clearfix">
    <div class="govuk-width-container">
      <div class="gem-c-layout-super-navigation-header__header-logo">
        <a class="govuk-header__link govuk-header__link--homepage" data-ga4-link='{"event_name":"navigation","type":"header menu bar","external":"false","text":"GOV.UK","section":"Logo","index_link":1,"index_section":0,"index_section_count":2,"index_total":1}' id="logo" aria-label="Go to the GOV.UK homepage" href="https://www.gov.uk">
          
  <svg focusable="false" role="img" class="govuk-header__logotype" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 148 30" height="30" width="148" aria-label="GOV.UK">
  <title>GOV.UK</title>
  <path d="M22.6 10.4c-1 .4-2-.1-2.4-1-.4-.9.1-2 1-2.4.9-.4 2 .1 2.4 1s-.1 2-1 2.4m-5.9 6.7c-.9.4-2-.1-2.4-1-.4-.9.1-2 1-2.4.9-.4 2 .1 2.4 1s-.1 2-1 2.4m10.8-3.7c-1 .4-2-.1-2.4-1-.4-.9.1-2 1-2.4.9-.4 2 .1 2.4 1s0 2-1 2.4m3.3 4.8c-1 .4-2-.1-2.4-1-.4-.9.1-2 1-2.4.9-.4 2 .1 2.4 1s-.1 2-1 2.4M17 4.7l2.3 1.2V2.5l-2.3.7-.2-.2.9-3h-3.4l.9 3-.2.2c-.1.1-2.3-.7-2.3-.7v3.4L15 4.7c.1.1.1.2.2.2l-1.3 4c-.1.2-.1.4-.1.6 0 1.1.8 2 1.9 2.2h.7c1-.2 1.9-1.1 1.9-2.1 0-.2 0-.4-.1-.6l-1.3-4c-.1-.2 0-.2.1-.3m-7.6 5.7c.9.4 2-.1 2.4-1 .4-.9-.1-2-1-2.4-.9-.4-2 .1-2.4 1s0 2 1 2.4m-5 3c.9.4 2-.1 2.4-1 .4-.9-.1-2-1-2.4-.9-.4-2 .1-2.4 1s.1 2 1 2.4m-3.2 4.8c.9.4 2-.1 2.4-1 .4-.9-.1-2-1-2.4-.9-.4-2 .1-2.4 1s0 2 1 2.4m14.8 11c4.4 0 8.6.3 12.3.8 1.1-4.5 2.4-7 3.7-8.8l-2.5-.9c.2 1.3.3 1.9 0 2.7-.4-.4-.8-1.1-1.1-2.3l-1.2 4c.7-.5 1.3-.8 2-.9-1.1 2.5-2.6 3.1-3.5 3-1.1-.2-1.7-1.2-1.5-2.1.3-1.2 1.5-1.5 2.1-.1 1.1-2.3-.8-3-2-2.3 1.9-1.9 2.1-3.5.6-5.6-2.1 1.6-2.1 3.2-1.2 5.5-1.2-1.4-3.2-.6-2.5 1.6.9-1.4 2.1-.5 1.9.8-.2 1.1-1.7 2.1-3.5 1.9-2.7-.2-2.9-2.1-2.9-3.6.7-.1 1.9.5 2.9 1.9l.4-4.3c-1.1 1.1-2.1 1.4-3.2 1.4.4-1.2 2.1-3 2.1-3h-5.4s1.7 1.9 2.1 3c-1.1 0-2.1-.2-3.2-1.4l.4 4.3c1-1.4 2.2-2 2.9-1.9-.1 1.5-.2 3.4-2.9 3.6-1.9.2-3.4-.8-3.5-1.9-.2-1.3 1-2.2 1.9-.8.7-2.3-1.2-3-2.5-1.6.9-2.2.9-3.9-1.2-5.5-1.5 2-1.3 3.7.6 5.6-1.2-.7-3.1 0-2 2.3.6-1.4 1.8-1.1 2.1.1.2.9-.3 1.9-1.5 2.1-.9.2-2.4-.5-3.5-3 .6 0 1.2.3 2 .9l-1.2-4c-.3 1.1-.7 1.9-1.1 2.3-.3-.8-.2-1.4 0-2.7l-2.9.9C1.3 23 2.6 25.5 3.7 30c3.7-.5 7.9-.8 12.3-.8m28.3-11.6c0 .9.1 1.7.3 2.5.2.8.6 1.5 1 2.2.5.6 1 1.1 1.7 1.5.7.4 1.5.6 2.5.6.9 0 1.7-.1 2.3-.4s1.1-.7 1.5-1.1c.4-.4.6-.9.8-1.5.1-.5.2-1 .2-1.5v-.2h-5.3v-3.2h9.4V28H55v-2.5c-.3.4-.6.8-1 1.1-.4.3-.8.6-1.3.9-.5.2-1 .4-1.6.6s-1.2.2-1.8.2c-1.5 0-2.9-.3-4-.8-1.2-.6-2.2-1.3-3-2.3-.8-1-1.4-2.1-1.8-3.4-.3-1.4-.5-2.8-.5-4.3s.2-2.9.7-4.2c.5-1.3 1.1-2.4 2-3.4.9-1 1.9-1.7 3.1-2.3 1.2-.6 2.6-.8 4.1-.8 1 0 1.9.1 2.8.3.9.2 1.7.6 2.4 1s1.4.9 1.9 1.5c.6.6 1 1.3 1.4 2l-3.7 2.1c-.2-.4-.5-.9-.8-1.2-.3-.4-.6-.7-1-1-.4-.3-.8-.5-1.3-.7-.5-.2-1.1-.2-1.7-.2-1 0-1.8.2-2.5.6-.7.4-1.3.9-1.7 1.5-.5.6-.8 1.4-1 2.2-.3.8-.4 1.9-.4 2.7zM71.5 6.8c1.5 0 2.9.3 4.2.8 1.2.6 2.3 1.3 3.1 2.3.9 1 1.5 2.1 2 3.4s.7 2.7.7 4.2-.2 2.9-.7 4.2c-.4 1.3-1.1 2.4-2 3.4-.9 1-1.9 1.7-3.1 2.3-1.2.6-2.6.8-4.2.8s-2.9-.3-4.2-.8c-1.2-.6-2.3-1.3-3.1-2.3-.9-1-1.5-2.1-2-3.4-.4-1.3-.7-2.7-.7-4.2s.2-2.9.7-4.2c.4-1.3 1.1-2.4 2-3.4.9-1 1.9-1.7 3.1-2.3 1.2-.5 2.6-.8 4.2-.8zm0 17.6c.9 0 1.7-.2 2.4-.5s1.3-.8 1.7-1.4c.5-.6.8-1.3 1.1-2.2.2-.8.4-1.7.4-2.7v-.1c0-1-.1-1.9-.4-2.7-.2-.8-.6-1.6-1.1-2.2-.5-.6-1.1-1.1-1.7-1.4-.7-.3-1.5-.5-2.4-.5s-1.7.2-2.4.5-1.3.8-1.7 1.4c-.5.6-.8 1.3-1.1 2.2-.2.8-.4 1.7-.4 2.7v.1c0 1 .1 1.9.4 2.7.2.8.6 1.6 1.1 2.2.5.6 1.1 1.1 1.7 1.4.6.3 1.4.5 2.4.5zM88.9 28 83 7h4.7l4 15.7h.1l4-15.7h4.7l-5.9 21h-5.7zm28.8-3.6c.6 0 1.2-.1 1.7-.3.5-.2 1-.4 1.4-.8.4-.4.7-.8.9-1.4.2-.6.3-1.2.3-2v-13h4.1v13.6c0 1.2-.2 2.2-.6 3.1s-1 1.7-1.8 2.4c-.7.7-1.6 1.2-2.7 1.5-1 .4-2.2.5-3.4.5-1.2 0-2.4-.2-3.4-.5-1-.4-1.9-.9-2.7-1.5-.8-.7-1.3-1.5-1.8-2.4-.4-.9-.6-2-.6-3.1V6.9h4.2v13c0 .8.1 1.4.3 2 .2.6.5 1 .9 1.4.4.4.8.6 1.4.8.6.2 1.1.3 1.8.3zm13-17.4h4.2v9.1l7.4-9.1h5.2l-7.2 8.4L148 28h-4.9l-5.5-9.4-2.7 3V28h-4.2V7zm-27.6 16.1c-1.5 0-2.7 1.2-2.7 2.7s1.2 2.7 2.7 2.7 2.7-1.2 2.7-2.7-1.2-2.7-2.7-2.7z"></path>
</svg>


</a>
</div>    </div>
    <nav aria-labelledby="super-navigation-menu-heading" class="gem-c-layout-super-navigation-header__content govuk-!-display-none-print" data-module="super-navigation-mega-menu">
      <h2 id="super-navigation-menu-heading" class="govuk-visually-hidden">
        Navigation menu
      </h2>


      <div class="govuk-width-container gem-c-layout-super-navigation-header__button-width-container">
        <div class="gem-c-layout-super-navigation-header__button-container">
          <div class="gem-c-layout-super-navigation-header__navigation-item">
            <a class="gem-c-layout-super-navigation-header__navigation-item-link" href="/browse"><span class="gem-c-layout-super-navigation-header__navigation-item-link-inner">                Menu
</span></a>
            <button aria-controls="super-navigation-menu" aria-expanded="false" aria-label="Show navigation menu" class="gem-c-layout-super-navigation-header__navigation-top-toggle-button" data-text-for-hide="Hide navigation menu" data-text-for-show="Show navigation menu" data-toggle-desktop-group="top" data-toggle-mobile-group="top" data-tracking-key="menu" data-ga4-event='{"event_name":"select_content","type":"header menu bar","text":"Menu","index_section":1,"index_section_count":2,"section":"Menu"}' hidden="hidden" id="super-navigation-menu-toggle" type="button">
              <span class="gem-c-layout-super-navigation-header__navigation-top-toggle-button-inner">Menu</span>
</button>          </div>

          <div class="gem-c-layout-super-navigation-header__search-item">
            <button id="super-search-menu-toggle" class="gem-c-layout-super-navigation-header__search-toggle-button" aria-controls="super-search-menu" aria-expanded="true" aria-label="Hide search menu" data-text-for-hide="Hide search menu" data-text-for-show="Show search menu" data-toggle-mobile-group="top" data-toggle-desktop-group="top" data-tracking-key="search" data-ga4-event='{"event_name":"select_content","type":"header menu bar","text":"Search","index_section":2,"index_section_count":2,"section":"Search"}' hidden="hidden" type="button">
              <span class="govuk-visually-hidden">
                Search GOV.UK
              </span>
              
<svg class="gem-c-layout-super-navigation-header__search-toggle-button-link-icon" width="27" height="27" viewbox="0 0 27 27" fill="none" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false">
  <circle cx="12.0161" cy="11.0161" r="8.51613" stroke="currentColor" stroke-width="3"></circle>
  <line x1="17.8668" y1="17.3587" x2="26.4475" y2="25.9393" stroke="currentColor" stroke-width="3"></line>
</svg>
              <span aria-hidden="true" class="gem-c-layout-super-navigation-header__navigation-top-toggle-close-icon" focusable="false">
                Ã—
              </span>
</button>
            <a class="gem-c-layout-super-navigation-header__search-item-link" href="/search">
              <span class="govuk-visually-hidden">
                Search GOV.UK
              </span>
              
<svg class="gem-c-layout-super-navigation-header__search-item-link-icon" width="27" height="27" viewbox="0 0 27 27" fill="none" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false">
  <circle cx="12.0161" cy="11.0161" r="8.51613" stroke="currentColor" stroke-width="3"></circle>
  <line x1="17.8668" y1="17.3587" x2="26.4475" y2="25.9393" stroke="currentColor" stroke-width="3"></line>
</svg>
</a>          </div>
</div>      </div>

      <div id="super-navigation-menu" hidden="hidden" class="gem-c-layout-super-navigation-header__navigation-dropdown-menu">
        <div class="govuk-width-container">
          <div class="govuk-grid-row gem-c-layout-super-navigation-header__navigation-items">


              <div class="govuk-grid-column-two-thirds-from-desktop gem-c-layout-super-navigation-header__column--services-and-information">
                <h3 class="govuk-heading-m gem-c-layout-super-navigation-header__column-header">
                  Services and information
                </h3>
                <ul class="gem-c-layout-super-navigation-header__navigation-second-items gem-c-layout-super-navigation-header__navigation-second-items--services-and-information">
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":1,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/benefits">Benefits</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":2,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/births-deaths-marriages">Births, death, marriages and care</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":3,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/business">Business and self-employed</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":4,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/childcare-parenting">Childcare and parenting</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":5,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/citizenship">Citizenship and living in the UK</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":6,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/justice">Crime, justice and the law</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":7,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/disabilities">Disabled people</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":8,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/driving">Driving and transport</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":9,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/education">Education and learning</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":10,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/employing-people">Employing people</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":11,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/environment-countryside">Environment and countryside</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":12,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/housing-local-services">Housing and local services</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":13,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/tax">Money and tax</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":14,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/abroad">Passports, travel and living abroad</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":15,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/visas-immigration">Visas and immigration</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":16,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/working">Working, jobs and pensions</a>
                        
                      </li>
                </ul>
              </div>

              <div class="govuk-grid-column-one-third-from-desktop gem-c-layout-super-navigation-header__column--government-activity">
                <h3 class="govuk-heading-m gem-c-layout-super-navigation-header__column-header">
                  Government activity
                </h3>
                <ul class="gem-c-layout-super-navigation-header__navigation-second-items gem-c-layout-super-navigation-header__navigation-second-items--government-activity">
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link gem-c-layout-super-navigation-header__navigation-second-item-link--with-description" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":2,"index_link":1,"index_section_count":3,"index_total":6,"section":"Government activity"}' href="https://www.gov.uk/government/organisations">Departments</a>
                        <p class="gem-c-layout-super-navigation-header__navigation-second-item-description">Departments, agencies and public bodies</p>
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link gem-c-layout-super-navigation-header__navigation-second-item-link--with-description" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":2,"index_link":2,"index_section_count":3,"index_total":6,"section":"Government activity"}' href="https://www.gov.uk/search/news-and-communications">News</a>
                        <p class="gem-c-layout-super-navigation-header__navigation-second-item-description">News stories, speeches, letters and notices</p>
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link gem-c-layout-super-navigation-header__navigation-second-item-link--with-description" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":2,"index_link":3,"index_section_count":3,"index_total":6,"section":"Government activity"}' href="https://www.gov.uk/search/guidance-and-regulation">Guidance and regulation</a>
                        <p class="gem-c-layout-super-navigation-header__navigation-second-item-description">Detailed guidance, regulations and rules</p>
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link gem-c-layout-super-navigation-header__navigation-second-item-link--with-description" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":2,"index_link":4,"index_section_count":3,"index_total":6,"section":"Government activity"}' href="https://www.gov.uk/search/research-and-statistics">Research and statistics</a>
                        <p class="gem-c-layout-super-navigation-header__navigation-second-item-description">Reports, analysis and official statistics</p>
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link gem-c-layout-super-navigation-header__navigation-second-item-link--with-description" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":2,"index_link":5,"index_section_count":3,"index_total":6,"section":"Government activity"}' href="https://www.gov.uk/search/policy-papers-and-consultations">Policy papers and consultations</a>
                        <p class="gem-c-layout-super-navigation-header__navigation-second-item-description">Consultations and strategy</p>
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link gem-c-layout-super-navigation-header__navigation-second-item-link--with-description" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":2,"index_link":6,"index_section_count":3,"index_total":6,"section":"Government activity"}' href="https://www.gov.uk/search/transparency-and-freedom-of-information-releases">Transparency</a>
                        <p class="gem-c-layout-super-navigation-header__navigation-second-item-description">Data, Freedom of Information releases and corporate reports</p>
                      </li>
                </ul>
              </div>
          </div>
        </div>
</div>
      <div id="super-search-menu" hidden="hidden" class="gem-c-layout-super-navigation-header__navigation-dropdown-menu">
        <div class="govuk-width-container gem-c-layout-super-navigation-header__search-container gem-c-layout-super-navigation-header__search-items">
          <h3 class="govuk-visually-hidden">
            Search
          </h3>
          <div class="govuk-grid-row">
            <div class="govuk-grid-column-full">
              <form class="gem-c-layout-super-navigation-header__search-form" id="search" data-module="ga4-form-tracker" data-ga4-form='{"event_name":"search","type":"header menu bar","section":"Search GOV.UK","action":"search","url":"/search/all","index_section":3,"index_section_count":3}' data-ga4-form-include-text data-ga4-form-no-answer-undefined action="https://www.gov.uk/search" method="get" role="search" aria-label="Site-wide">
                <div class="gem-c-search govuk-!-display-none-print  govuk-!-margin-bottom-0 gem-c-search--large gem-c-search--on-white gem-c-search--separate-label" data-module="gem-toggle-input-class-on-focus">
    <label for="search-main-10c7bc8c" class="govuk-label govuk-label--m gem-c-layout-super-navigation-header__search-label--large-navbar">Search GOV.UK</label>
  <div class="gem-c-search__item-wrapper">
    <div class="js-search-input-wrapper">
      <input enterkeyhint="search" class="gem-c-search__item gem-c-search__input js-class-toggle" id="search-main-10c7bc8c" name="q" title="Search" type="search" value="" autocorrect="off" autocapitalize="off">
    </div>
    <div class="gem-c-search__item gem-c-search__submit-wrapper">
      <button class="gem-c-search__submit" type="submit" enterkeyhint="search">
        Search
        
<svg class="gem-c-search__icon" width="27" height="27" viewbox="0 0 27 27" fill="none" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false">
  <circle cx="12.0161" cy="11.0161" r="8.51613" stroke="currentColor" stroke-width="3"></circle>
  <line x1="17.8668" y1="17.3587" x2="26.4475" y2="25.9393" stroke="currentColor" stroke-width="3"></line>
</svg>
</button>    </div>
  </div>
</div>

              </form>
            </div>
          </div>
        </div>
</div>    </nav>
  </div>
</header>

    

      <div class="">
        <div class="gem-c-layout-for-public__blue-bar govuk-width-container"></div>
</div>

      <div id="wrapper" class="direction-ltr govuk-width-container">

        
<div class="gem-c-contextual-breadcrumbs">
    <div class="govuk-!-display-none-print">
      


<nav data-module="ga4-link-tracker" aria-label="Breadcrumb" class="gem-c-breadcrumbs govuk-breadcrumbs govuk-breadcrumbs--collapse-on-mobile">
  <ol class="govuk-breadcrumbs__list">
        <li class="govuk-breadcrumbs__list-item">
          <a data-ga4-link='{"event_name":"navigation","type":"breadcrumb","index_link":"1","index_total":"3"}' class="govuk-breadcrumbs__link" href="/">Home</a>
        </li>
        <li class="govuk-breadcrumbs__list-item">
          <a data-ga4-link='{"event_name":"navigation","type":"breadcrumb","index_link":"2","index_total":"3"}' class="govuk-breadcrumbs__link" href="/defence-and-armed-forces">Defence and armed forces</a>
        </li>
        <li class="govuk-breadcrumbs__list-item">
          <a data-ga4-link='{"event_name":"navigation","type":"breadcrumb","index_link":"3","index_total":"3"}' class="govuk-breadcrumbs__link" href="/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence">Ambitious, safe, responsible: our approach to the delivery of AI-enabled capability in Defence</a>
        </li>
  </ol>
</nav>
    </div>
</div>


    

    <main role="main" id="content" class="html-publication" lang="en">
      <span id="Top"></span>
          

  <div class="publication-external">
    <ul class="organisation-logos">
        <li class="organisation-logos__logo">
          
<div class="gem-c-organisation-logo brand--ministry-of-defence">
    <a class="gem-c-organisation-logo__container gem-c-organisation-logo__link gem-c-organisation-logo__crest gem-c-organisation-logo__crest--mod brand__border-color" href="/government/organisations/ministry-of-defence">
      <span class="gem-c-organisation-logo__name">Ministry<br>of Defence</span>
</a>
</div>
        </li>
    </ul>
  </div>

  <header class="gem-c-inverse-header  gem-c-inverse-header--padding-top ">
    
  

<div class="gem-c-title gem-c-title--inverse govuk-!-margin-top-3 govuk-!-margin-bottom-0">
      <span class="govuk-caption-xl gem-c-title__context">
    Policy paper
  </span>


  <h1 class="gem-c-title__text govuk-heading-xl">
    Ambitious, safe, responsible: our approach to the delivery of AI-enabled capability in Defence
  </h1>
</div>
  <p class="publication-header__last-changed">Published 15 June 2022</p>

  </header>

    <section class="govuk-notification-banner gem-c-notice govuk-!-margin-bottom-8" aria-label="Notice" role="region">
        <div class="govuk-notification-banner__content">
      
      <span class="gem-c-notice__title govuk-notification-banner__heading">This was published under the <span lang="en" dir="ltr">2019 to 2022 Johnson Conservative government</span></span>
      

      
</div></section>


<div id="contents">
  <div class="govuk-grid-row gem-print-columns-none">
      <div class="govuk-grid-column-one-quarter-from-desktop contents-list-container">
          <nav data-module="ga4-link-tracker" aria-label="Contents" class="gem-c-contents-list" role="navigation">
    <h2 class="gem-c-contents-list__title">
      Contents
</h2>
    <ol class="gem-c-contents-list__list">
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <span aria-hidden="true"></span>
          <a class="gem-c-contents-list__link govuk-link gem-print-link govuk-link--no-underline" data-ga4-link='{"event_name":"select_content","section":"Contents","type":"contents list","index_total":13,"index_link":1}' href="#executive-summary">Executive Summary</a>
        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <span aria-hidden="true"></span>
          <a class="gem-c-contents-list__link govuk-link gem-print-link govuk-link--no-underline" data-ga4-link='{"event_name":"select_content","section":"Contents","type":"contents list","index_total":13,"index_link":2}' href="#ambitious-delivery-of-capability">Ambitious delivery of capability</a>
        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <span aria-hidden="true"></span>
          <a class="gem-c-contents-list__link govuk-link gem-print-link govuk-link--no-underline" data-ga4-link='{"event_name":"select_content","section":"Contents","type":"contents list","index_total":13,"index_link":3}' href="#our-approach-and-ai-enabled-weapons">Our approach and AI-enabled weapons</a>
        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <span aria-hidden="true"></span>
          <a class="gem-c-contents-list__link govuk-link gem-print-link govuk-link--no-underline" data-ga4-link='{"event_name":"select_content","section":"Contents","type":"contents list","index_total":13,"index_link":4}' href="#key-challenges-to-defence-ai-adoption">Key challenges to Defence AI Adoption</a>
        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <span aria-hidden="true"></span>
          <a class="gem-c-contents-list__link govuk-link gem-print-link govuk-link--no-underline" data-ga4-link='{"event_name":"select_content","section":"Contents","type":"contents list","index_total":13,"index_link":5}' href="#using-ai-safely">Using AI Safely</a>
        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <span aria-hidden="true"></span>
          <a class="gem-c-contents-list__link govuk-link gem-print-link govuk-link--no-underline" data-ga4-link='{"event_name":"select_content","section":"Contents","type":"contents list","index_total":13,"index_link":6}' href="#using-ai-legally">Using AI Legally</a>
        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <span aria-hidden="true"></span>
          <a class="gem-c-contents-list__link govuk-link gem-print-link govuk-link--no-underline" data-ga4-link='{"event_name":"select_content","section":"Contents","type":"contents list","index_total":13,"index_link":7}' href="#using-ai-ethically">Using AI Ethically</a>
        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <span aria-hidden="true"></span>
          <a class="gem-c-contents-list__link govuk-link gem-print-link govuk-link--no-underline" data-ga4-link='{"event_name":"select_content","section":"Contents","type":"contents list","index_total":13,"index_link":8}' href="#partnerships-and-consultation">Partnerships and Consultation</a>
        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <span aria-hidden="true"></span>
          <a class="gem-c-contents-list__link govuk-link gem-print-link govuk-link--no-underline" data-ga4-link='{"event_name":"select_content","section":"Contents","type":"contents list","index_total":13,"index_link":9}' href="#governance">Governance</a>
        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <span aria-hidden="true"></span>
          <a class="gem-c-contents-list__link govuk-link gem-print-link govuk-link--no-underline" data-ga4-link='{"event_name":"select_content","section":"Contents","type":"contents list","index_total":13,"index_link":10}' href="#implementation--building-justified-trust">Implementation â€“ building justified trust</a>
        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <span aria-hidden="true"></span>
          <a class="gem-c-contents-list__link govuk-link gem-print-link govuk-link--no-underline" data-ga4-link='{"event_name":"select_content","section":"Contents","type":"contents list","index_total":13,"index_link":11}' href="#annex-a-ethical-principles-for-ai-in-defence">Annex A: Ethical Principles for AI in Defence</a>
        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <span aria-hidden="true"></span>
          <a class="gem-c-contents-list__link govuk-link gem-print-link govuk-link--no-underline" data-ga4-link='{"event_name":"select_content","section":"Contents","type":"contents list","index_total":13,"index_link":12}' href="#annex-b-the-ministry-of-defence-ai-ethics-advisory-panel">Annex B: The Ministry of Defence AI Ethics Advisory Panel</a>
        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <span aria-hidden="true"></span>
          <a class="gem-c-contents-list__link govuk-link gem-print-link govuk-link--no-underline" data-ga4-link='{"event_name":"select_content","section":"Contents","type":"contents list","index_total":13,"index_link":13}' href="#annex-c-lethal-autonomous-weapon-systems-laws">ANNEX C: Lethal Autonomous Weapon Systems (LAWS)</a>
        </li>
    </ol>
</nav>

        
<div class="gem-c-print-link govuk-!-display-none-print govuk-!-margin-top-0 govuk-!-margin-bottom-6">
    <button class="govuk-link govuk-body-s gem-c-print-link__button" data-module="print-link">Print this page</button>
</div>
      </div>

    <div class="print-wrapper">
      <div class="meta-data meta-data--display-print">
        <p>
  <img class="meta-data-licence" src="/assets/government-frontend/open-government-licence-min-93b6a51b518ff99714a1aa2a7d2162735c155ec3cb073c75fb88b2a332fa83d3.png">
</p>
<p>
  Â© Crown copyright 2022
</p>
<p>
  This publication is licensed under the terms of the Open Government Licence v3.0 except where otherwise stated. To view this licence, visit <a href="https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3">nationalarchives.gov.uk/doc/open-government-licence/version/3</a> or write to the Information Policy Team, The National Archives, Kew, London TW9 4DU, or email: <a href="mailto:psi@nationalarchives.gov.uk">psi@nationalarchives.gov.uk</a>.
</p>
<p>
  Where we have identified any third party copyright information you will need to obtain permission from the copyright holders concerned.
</p>
<p>
  This publication is available at https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence
</p>


      </div>
    </div>

    <div class="govuk-grid-column-three-quarters-from-desktop contents-container">
      <div class="gem-c-govspeak-html-publication">
  
<div class="gem-c-govspeak govuk-govspeak direction-ltr" data-module="govspeak">
    
    
        <div class="govspeak">
<p>This policy statement should be read in conjunction with the Defence AI Strategy 2022</p>

<h2 id="executive-summary">Executive Summary</h2>

<div class="call-to-action">
  <h3 id="defining-artificial-intelligence">Defining Artificial Intelligence</h3>

  <p>Defence understands Artificial Intelligence (AI) as a family of general-purpose technologies, any of which may enable machines to perform tasks normally requiring human or biological intelligence, especially when the machines learn from data how to do those tasks.</p>
</div>

<p>The Defence AI Strategy sets out our view of the strategic opportunities and challenge presented by the emergence of AI as a transformative and disruptive new technology. Realising the benefits of AI â€“ and countering threats and challenges associated with the use of AI by others â€“ is one of the most critical strategic challenges of our time.</p>

<p>AI will enable our people to make powerful use of previously unimaginable quantities of data. It will improve decision-making and the delivery of operational effect. There is a strong case for the development and use of an AI system where it would be demonstrably beneficial or result in a more ethical outcome. In an era of increasing global competition and given resource limitations, it is imperative that we deliver maximum effectiveness and efficiency using AI across the spectrum of Defence activities.</p>

<p>We also recognise that the nature of AI gives rise to risks and concerns about possible impact on humans. These can be particularly acute in a Defence context. If we do not address them, we risk losing public consent, seeing our ability to operate undermined, and exacerbating the irresponsible behaviour of others â€“ not to mention undermining our ability to deliver Defence capability.</p>

<div class="call-to-action">
  <p>We believe that a broad â€˜systemsâ€™ perspective will ensure AI-related issues are addressed systematically and effectively. By focusing on outcomes, delivered through clear frameworks &amp; processes , and guided by our conviction that AI can be a powerful force for good, we will ensure that we:</p>

  <ul>
    <li>
      <p>are ambitious, in terms of the tools and operational effects we seek to deliver</p>
    </li>
    <li>
      <p>enable â€“ rather than constrain â€“ the delivery of those tools and effects</p>
    </li>
    <li>
      <p>deliver and use AI-enabled capability in a safe and responsible manner</p>
    </li>
  </ul>
</div>

<p>Within Defence, this will be achieved through a number of overlapping approaches. We will:</p>

<ul>
  <li>
    <p>set clear organisational intent and ambition for the adoption and exploitation of AI, backed up with defined roles and responsibilities, as set out in the Defence AI Strategy;</p>
  </li>
  <li>
    <p>continue to apply our robust safety and regulation regimes;</p>
  </li>
  <li>
    <p>always comply with our national and international legal obligations; and</p>
  </li>
  <li>
    <p>set out a clear framework and processes for ensuring ethical adoption of the technology.</p>
  </li>
</ul>

<p>This is a positive blueprint for effective, innovative and responsible AI adoption. Fundamentally, the best way to develop AI systems for Defence which serve our operational needs and reflect the values of those we serve is to: set ambitious direction; ensure clarity and certainty around our approaches; and provide assurance to colleagues in Defence, industry and wider society â€“ thereby demonstrating trustworthiness.</p>

<h2 id="ambitious-delivery-of-capability">Ambitious delivery of capability</h2>

<p>We aspire to exploit AI comprehensively, accelerating â€˜best in classâ€™ AI-enabled capabilities into service in order to make all parts of Defence significantly more efficient and effective. To do this, we must ensure that we are always ambitious in the ways in which we incorporate AI into Defence capabilities where AI is the appropriate tool to adopt. We will not adopt AI for its own sake; it is not an â€˜endâ€™ in itself.</p>

<p>We intend that our approach will enable â€“ rather than constrain â€“ the adoption and exploitation of AI-enabled solutions and capabilities across Defence. We will empower teams developing and delivering concepts, technologies and solutions to explore ambitious ideas and use cases. We will provide them with clear frameworks to support the early identification and resolution of safety, legal and ethical risks; this will give them the confidence to explore the full potential of the technology while complying with policy and other essential requirements. We will encourage them to identify wider factors impeding their progress â€“ such as policy or process â€“ in the expectation that appropriate solutions will be identified and implemented rapidly.</p>

<p>We want to harness the creativity and innovation found across Defence and the private sector. This includes the necessary problem-solving approaches to bring those ambitious use-cases to life in an appropriate way. Since risks and challenges may exist in respect of any part of the â€˜system of systemsâ€™ across the full lifecycle of the capability, we are clear that solutions may similarly be found across the full â€˜system of systemsâ€™ and lifecycle.</p>

<p>In other words, the issue may not lie in â€˜whatâ€™ the capability is designed to do, but â€˜howâ€™ it does it, and how we ensure that AI is used effectively and appropriately within it. We will ensure that suitable methods are adopted across our enterprise to â€˜design outâ€™ problems, and that we rigorously test AI-enabled solutions. Further information can be found in the Defence AI Strategy.</p>

<p>As a general enabling technology, AI has been dubbed â€˜the new electricityâ€™.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="govuk-link" rel="footnote">[footnote 1]</a></sup> Clearly there are important differences. One useful point of comparison, is that initial planning to deliver a major system (ultimately to be powered by electricity) would focus on the desired outcome and level of ambition. Discussion might be mainly about vision and willingness to push boundaries, although planners would also consider possible delivery routes and likely be aware of engineering limitations.</p>

<p>Initial planning would not normally hinge on discussions about whether the likely incorporation of electricity meant that the system could be delivered safely and responsibly. These issues would be addressed systematically through design, manufacture, use in service and disposal, even if this necessitated changes in operational approaches, or additional Research &amp; Development to provide technical solutions.</p>

<p>This is similar to the way we think about AI. We start from the belief that AI is a powerful tool, and that we must be confident in our vision for AI-enabled capability. Safe and responsible outcomes are then a function of Defence-wide processes, rather than of early self-imposed limitations which would risk being arbitrary, constraining and habitually out-dated, given the speed of technological advances.</p>

<h2 id="our-approach-and-ai-enabled-weapons">Our approach and AI-enabled weapons</h2>

<p>We will focus on outcomes, exploring ambitious options rather than filtering out ideas or concepts when they are still on the drawing board. We do not rule out incorporating AI within weapon systems. In practice, however, some concepts and capabilities may prove impossible to deliver in a safe and responsible manner â€“ and we are very clear that there must be context-appropriate human involvement in weapons which identify, select and attack targets. This could mean some form of real-time human supervision, or control exercised through the setting of a systemâ€™s operational parameters.</p>

<p>We believe that AI can substantially augment the performance of our people and significantly enhance our capabilities. However, given concerns about the ethics and risks of delegating certain decisions to AI, it is also important to state that we do not believe that â€˜more autonomousâ€™ necessarily means â€˜more capableâ€™. We believe that Human-Machine Teaming<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="govuk-link" rel="footnote">[footnote 2]</a></sup> delivers the best outcomes, in terms of overall effectiveness, optimal use of resources, the practicalities of integration and the ease with which we can address issues arising; it is therefore our default approach to AI adoption.</p>

<p>The appropriate degree of system â€˜autonomyâ€™ and type of â€˜human controlâ€™ need to be considered carefully on a case-by-case basis.</p>

<p>Looking at AI-enabled systems from a technological perspective: the precise degree of AI-enabled autonomy needed within any given capability or component will depend on the specific nature of the system or the concept for its use. Operational outcomes typically depend on speed and accuracy, in terms of assessment and then action. These can be enabled to a very high degree without the requirement to delegate problematic levels of discretion or judgement to the AI.</p>

<p>Looking at the same systems from a People perspective: we can exert satisfactory and rigorous human control over AI-enabled systems without always requiring some form of real-time human supervision. Indeed, doing so may act as an unnecessary and inappropriate constraint on operational performance. For example, to defend a maritime platform against hypersonic weapons we may need defensive systems which can detect incoming threats and open fire faster than a human could react.</p>

<p>Another crucial point is that all new weapons, means and methods of warfare are subject to a rigorous review process for compliance with International Humanitarian Law and other applicable international law. Determinations as to the necessary scope and application of context-appropriate human involvement will be done similarly systematically. We also adjust our operating procedures to ensure that we stay within the boundaries of the law that applies at the time.</p>

<p>This approach is reflected in our policy with regards to international debates on â€˜Lethal Autonomous Weapon Systems, set out in more detail at Annex C.</p>

<h2 id="key-challenges-to-defence-ai-adoption">Key challenges to Defence AI Adoption</h2>

<p>The use of AI in a Defence context raises a number of interlinked issues and challenges, which development teams and users will need to take into consideration. These include:</p>

<ul>
  <li>
    <p>Algorithmic Bias: the risk that biased datasets used to train AI systems could result in discriminatory outcomes and disproportionate harms for certain groups of users;</p>
  </li>
  <li>
    <p>Responsibility &amp; Accountability: the need to ensure that delegation of tasks or decisions to AI systems does not lead to a â€˜responsibility gapâ€™ between systems that take decisions or make recommendations, and the human commanders responsible for them;</p>
  </li>
  <li>
    <p>Unpredictability: the risk that some AI systems may behave unpredictably, particularly in new or complex environments, or as they learn and adapt over time;</p>
  </li>
  <li>
    <p>Unintended Consequences and Incentives: the potential for AI-enabled systems to have unintended side-effects on human behaviour, through enabling certain incentives, or influencing other systems beyond their intended effect;</p>
  </li>
  <li>
    <p>People Implications: the need to think differently about what is expected of people, and the impact of AI on people, as AI-enabled systems create opportunities to automate â€˜dull, dirty or dangerousâ€™ tasks; and;</p>
  </li>
  <li>
    <p>Human Control: when using AI-enabled systems for Defence purposes, the need to understand the appropriate form of human involvement required for any given application or context.</p>
  </li>
</ul>

<p>These issues may be encountered individually or in combination. Some create safety issues, requiring us to ensure that our AI does not cause inadvertent harm or danger as a part of its use. Some give rise to ethical issues, requiring us to ensure that our use of the technology aligns with our values, and those of the society we represent.  Some are important elements in ensuring that the particular capability complies with our domestic and international legal obligations (e.g. relating to data protection, privacy or International Humanitarian Law).</p>

<p>In handling these issues properly, we must maintain the trust and goodwill of our key stakeholders - including our service personnel - allies, and partners in the private sector. Without this, we risk slowing innovation, losing important opportunities to collaborate â€“ and reduced public consent for the use of these technologies.</p>

<p>By adopting a safe and responsible approach to AI, we also have an opportunity to set a positive example to others, encouraging the safe and responsible use of AI globally.</p>

<p>To achieve these outcomes, we are establishing a clear framework which will provide support and clarity to the teams within Defence and beyond who are developing and operating our AI-enabled systems.</p>

<h2 id="using-ai-safely">Using AI Safely</h2>

<p>A number of the key challenges associated with adopting AI for Defence pose particular issues for safety.</p>

<p>The unpredictability of some AI systems, particularly when applied to new and challenging environments, increase the risks that unforeseen issues may arise with their use. The relative difficulties with interpreting how some forms of AI systems learn and make decisions present new challenges for the testing, evaluation and certification of such systems. In addition, the high potential impact of AI-enabled systems for Defence raises the stakes for potential side effects or unintended consequences, particularly when they could cause harms for those interacting with them.</p>

<p>Broadly, this is not a new challenge for the Department. Defence is bound by UK law and has a robust regime for compliance. Defence activities also include those that are inherently dangerous and require additional risk management beyond that of our statutory obligations.</p>

<p>Where Defence has certain derogations, exemptions or disapplicationâ€™s from UK legislation and regulations, it is the Departmentâ€™s policy and practice to maintain arrangements that produce outcomes that are, so far as practicable, at least as good as those required by UK legislation. This is reflected in Health, Safety and Environmental Protection (HS&amp;EP) in Defence â€“ Policy statement by the Secretary of State for Defence.</p>

<p>A strict compliance with safety rules is therefore essential to Defenceâ€™s use of any new technology.</p>

<p>The Defence Safety Authority (DSA) contributes to Defence capability, reputation and effectiveness through the setting, and enforcement of Defence Regulations for Health, Safety and Environmental Protection and supports the Ministry of Defence by providing independent, evidence-based assurance.</p>

<p>The DSA conducts horizon scanning activity with regards to the development in AI capability. The DSA will continue to set Defence Regulation and conduct enforcement activity across in-service capability and will examine how AI capability can be assured in future.</p>

<p>Within the DSA, the Defence Accident Investigation Branch (DAIB) provides Defence with an accident and incident investigation capability conducting impartial and expert no-blame safety investigations across all domains, with a focus on the identification and understanding of all accident factors. This may include accidents related to AI capability.</p>

<h2 id="using-ai-legally">Using AI Legally</h2>

<p>Defenceâ€™s activities are governed by a range of legislative provisions which ensure our work is undertaken in accordance with the law. This legislation protects fundamental freedoms and human rights, while giving the MOD the powers it needs to keep citizens safe and secure in the modern world</p>

<p>Defence always seeks to abide by its legal obligations across the full range of activities from employment law, to privacy and procurement, and the law of armed conflict, also known as International Humanitarian Law (IHL). It has robust practices and processes in place to ensure its activities and its people abide by the law. These practices and processes are being â€“ and will continue to be â€“ applied to AI-enabled capabilities.</p>

<p>Deployment of AI-enabled capabilities in armed conflict needs to comply fully with IHL, satisfying the four core principles of distinction, necessity, humanity and proportionality. We are very clear that use of any system or weapon which does not satisfy these fundamental principles would constitute a breach of international law.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="govuk-link" rel="footnote">[footnote 3]</a></sup></p>

<p>Article 36 legal reviews ensure that commanders, service personnel, politicians, the UK public and our allies can be assured that UK weapons are lawful. Additional Protocol 1 of the Geneva Convention, requires â€˜in the study, development, acquisition or adoption of a new weapon, means or method of warfare . . . to determine whether its employment would, in some or all circumstances, be prohibited by [Additional Protocol I] or by any other [applicable] rule of international lawâ€™.</p>

<p>As with any new and emerging technology, the Ministry of Defence is therefore conscious of the need to be aware of any legal issues that may arise with the use of AI in Defence, whether as a means or method of warfare or in a â€˜back officeâ€™ system, and has robust review processes in place.</p>

<div class="call-to-action">
  <p>Our development and use of AI technologies will always be in accordance with the body of applicable UK and international law.</p>
</div>

<h2 id="using-ai-ethically">Using AI Ethically</h2>

<p>The MOD is dedicated to the protection of UK people, territories, values and interests at home and overseas. We must be ethical â€“ and be seen to ethical â€“ in our AI development and use to protect UK values and retain the trust and support of our citizens, key stakeholders, allies and partners. This includes recognising the potential for cases where AI could be an important tool helping us to promote ethical outcomes and where it might be unethical not to use AI.</p>

<p>We have therefore developed ethical principles for AI in Defence (Annex A), designed to lead our overall approach to AI-enabled technologies and systems across the full range of possible use cases, from back office to decision support and battlespace capabilities.<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="govuk-link" rel="footnote">[footnote 4]</a></sup> They will apply to our development and use of AI across their lifecycle, and also to AI-enabled systems: platforms, processes or systems of which AI forms some part. These principles will:</p>

<ul>
  <li>steer our approach to the key challenges of AI, in particular providing direction around responsible development, training and use (see implementation section)</li>
  <li>form the core of the UKâ€™s approach to creating agreed norms for AI in Defence internationally, working with partners and allies to shape the global development of AI in the direction of freedom, openness and democracy</li>
  <li>provide characteristics for AI systems which teams across Defence will be expected to follow in the development of new AI-enabled systems</li>
</ul>

<p>Setting out the principles is a key step towards ensuring a responsible and safe approach to the technology. Effective implementation and evolution of the principles will be required to ensure that our development of AI matches our requirement for safe and responsible innovation.</p>

<h2 id="partnerships-and-consultation">Partnerships and Consultation</h2>

<p>ToÂ develop these Principles, the MOD workedÂ inÂ partnership with the CentreÂ forÂ Data Ethics and Innovation (CDEI). The firstÂ inÂ the world of its kind, the CDEI leads the UK Governmentâ€™s workÂ toÂ enable trustworthy innovation using data and AI. Guided by an advisory body ofÂ internationally-recognised experts, the Centre works with partners across the public sector,Â industry and academia,Â inÂ the UK and internationally,Â toÂ identify and tackle barriersÂ toÂ responsible innovation. The MOD Principles are the result of over 18 months of consultation with over 100 expert stakeholders from around the world.<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="govuk-link" rel="footnote">[footnote 5]</a></sup></p>

<p>As part of the consultation process, the MOD has convened an AI Ethics Advisory Panel, a group of experts in computer science, AI ethics and military ethics. This Panel ensured MOD benefitted from specialist insight and challenge, and played a crucial role supporting the development of the Principles. Further details on its role and current membership are available at Annex B.</p>

<p>Going forward into implementation of these approaches, our commitment to transparency and consultation with industry and allies will continue. We will continue to work with the CDEI as this area evolves to ensure that our ongoing approach matches responsible best practice. We will also continue to engage proactively with leading experts from academia and industry, including the Ethics Advisory Panel.</p>

<h2 id="governance">Governance</h2>

<p>This policy statement should be read in conjunction with the Defence AI Strategy 2021, which provides more detail across the breadth of AI issues and activities relevant to Defence.</p>

<p>In line with the governance model set out in the Strategy:</p>

<ul>
  <li>
    <p>the 2nd Permanent Secretary (2nd PUS) and the Vice Chief of the Defence Staff will oversee and drive AI-related activity across Defence</p>
  </li>
  <li>
    <p>2nd PUS has specific responsibility for AI policy across Defence, including oversight of our ethical framework and responsibility for taking forward measures within the delegated model to ensure effective implementation</p>
  </li>
  <li>
    <p>the Permanent Secretary (PUS) remains responsible for health, safety and environmental protection, supported by the Chief Operating Officer (COO) and the Director Health Safety &amp; Environmental Protection</p>
  </li>
  <li>
    <p>2nd PUS (and other senior officials as required) will be supported (in terms of policy development) by the Defence AI &amp; Autonomy Unit (DAU), part of Defence Science &amp; Technology (DST), and advised by the AI Ethics Advisory Panel. Scientific and technical advice will be provided by the MOD Chief Scientific Adviser (supported by DST and the Defence Science &amp; Technology Laboratory (Dstl)) and the Chief Information Officer (supported by Defence Digital). Independent technical advice and review will be provided by the Defence Science Expert Committee (DSEC)</p>
  </li>
  <li>
    <p>Top Level Budget (TLB) dutyÂ holders and trading fund agency chief executives are senior duty holders for safety and are responsible for designating the duty holders in their organisation who manage activities which could be a risk to life. Each TLB organisation will have an accountable officer responsible for AI Ethics implementation</p>
  </li>
</ul>

<h2 id="implementation--building-justified-trust">Implementation â€“ building justified trust</h2>

<p>Having set out our overall approach to adopting AI ambitiously, safely and responsibly in this document, effective implementation will be critical. We must maximise the benefit we extract from AI while also demonstrating trustworthiness, both in terms of the breadth of our portfolio of AI-enabled tools and capabilities and the specifics of individual use cases. These two goals are linked. Ensuring our use of AI is safe, reliable and responsible doesnâ€™t impede innovation; itâ€™s key to collaboration and ensuring systems deliver the outcomes we need.</p>

<p>Our approach will therefore be:</p>

<ul>
  <li>
    <p>outward-facing: we will be transparent, engaging consistently with and welcoming challenge from industry, academia, civil society, international partners and allies;</p>
  </li>
  <li>
    <p>applied across the entire AI system lifecycle: Defence teams will be able to articulate how a safe and responsible approach is being followed across an AI systemâ€™s full lifecycle, covering all Defence Lines of Development;</p>
  </li>
  <li>
    <p>context-specific: the vast range of potential use cases for AI across Defence means that application of policy approaches cannot be uniform or technology-specific, but must take into consideration the particular requirements of each project.</p>
  </li>
</ul>

<h2 id="annex-a-ethical-principles-for-ai-in-defence">Annex A: Ethical Principles for AI in Defence</h2>

<h3 id="preamble-our-intent-for-the-ethical-use-of-ai-in-defence">Preamble: Our intent for the ethical use of AI in Defence</h3>

<p>The MOD is committed to developing and deploying AI-enabled systems responsibly, in ways that build trust and consensus, setting international standards for the ethical use of AI for Defence. The MOD will develop and deploy AI-enabled systems for purposes that are demonstrably beneficial: driving operational improvements, supporting the Defence Purpose, and upholding human rights and democratic values.</p>

<p>The MODâ€™s existing obligations under UK law and international law, including as applicable international humanitarian law (IHL) and international human rights law, act as a foundation for Defenceâ€™s development, deployment and operation of AI-enabled systems. These ethical principles do not affect or supersede existing legal obligations. Instead, they set out an ethical framework which will guide Defenceâ€™s approach to adopting AI, in line with rigorous existing codes of conduct and regulations.</p>

<p>These principles are applicable across the full spectrum of use cases for AI in Defence, from battlespace to back office, and across the entire lifecycle of these systems.</p>

<h3 id="first-principle-human-centricity">First principle: Human-Centricity</h3>

<p>The impact of AI-enabled systems on humans must be assessed and considered, for a full range of effects both positive and negative across the entire system lifecycle.</p>

<p>Whether they are MOD personnel, civilians, or targets of military action, humans interacting with or affected by AI-enabled systems for Defence must be treated with respect. This means assessing and carefully considering the effects on humans of AI-enabled systems, taking full account of human diversity, and ensuring those effects are as positive as possible. These effects should prioritise human life and wellbeing, as well as wider concerns for human kind such as environmental impacts, while taking account of military necessity. This applies across all uses of AI-enabled systems, from the back office to the battlefield.</p>

<p>The choice to develop and deploy AI systems is an ethical one, which must be taken with human implications in mind. It may be unethical to use certain systems where negative human impacts outweigh the benefits. Conversely, there may be a strong ethical case for the development and use of an AI system where it would be demonstrably beneficial or result in a more ethical outcome.</p>

<h3 id="second-principle-responsibility">Second principle: Responsibility</h3>

<p>Human responsibility for AI-enabled systems must be clearly established, ensuring accountability for their outcomes, with clearly defined means by which human control is exercised throughout their lifecycles.</p>

<p>The increased speed, complexity and automation of AI-enabled systems may complicate our understanding of pre-existing concepts of human control, responsibility and accountability. This may occur through the sorting and filtering of information presented to decision-makers, the automation of previously human-led processes, or processes by which AI-enabled systems learn and evolve after their initial deployment. Nevertheless, as unique moral agents, humans must always be responsible for the ethical use of AI in Defence.</p>

<p>Human responsibility for the use of AI-enabled systems in Defence must be underpinned by a clear and consistent articulation of the means by which human control is exercised, and the nature and limitations of that control. While the level of human control will vary according to the context and capabilities of each AI-enabled system, the ability to exercise human judgement over their outcomes is essential.</p>

<p>Irrespective of the use case, Responsibility for each element of an AI-enabled system, and an articulation of risk ownership, must be clearly defined from development, through deployment â€“ including redeployment in new contexts â€“ to decommissioning. This includes cases where systems are complex amalgamations of AI and non-AI components, from multiple different suppliers. In this way, certain aspects of responsibility may reach beyond the team deploying a particular system, to other functions within the MOD, or beyond, to the third parties which build or integrate AI-enabled systems for Defence.</p>

<p>Collectively, these articulations of human control, responsibility and risk ownership must enable clear accountability for the outcomes of any AI-enabled system in Defence. There must be no deployment or use without clear lines of responsibility and accountability, which should not be accepted by the designated duty holder unless they are satisfied that they can exercise control commensurate with the various risks.</p>

<h3 id="third-principle-understanding">Third principle: Understanding</h3>

<p>AI-enabled systems, and their outputs, must be appropriately understood by relevant individuals, with mechanisms to enable this understanding made an explicit part of system design.</p>

<p>Effective and ethical decision-making in Defence, from the frontline of combat to back-office operations, is always underpinned by appropriate understanding of context by those making decisions. Defence personnel must have an appropriate, context-specific understanding of the AI-enabled systems they operate and work alongside.</p>

<p>This level of understanding will naturally differ depending on the knowledge required to act ethically in a given role and with a given system. It may include an understanding of the general characteristics, benefits and limitations of AI systems. It may require knowledge of a systemâ€™s purposes and correct environment for use, including scenarios where a system should not be deployed or used. It may also demand an understanding of system performance and potential fail states. Our people must be suitably trained and competent to operate or understand these tools.</p>

<p>To enable this understanding, we must be able to verify that our AI-enabled systems work as intended. While the â€˜black boxâ€™ nature of some machine learning systems means that they are difficult to fully explain, we must be able to audit either the systems or their outputs to a level that satisfies those who are duly and formally responsible and accountable. Mechanisms to interpret and understand our systems must be a crucial and explicit part of system design across the entire lifecycle.</p>

<p>This requirement for context-specific understanding based on technically understandable systems must also reach beyond the MOD, to commercial suppliers, allied forces and civilians. Whilst absolute transparency as to the workings of each AI-enabled system is neither desirable nor practicable, public consent and collaboration depend on context-specific shared understanding. What our systems do, how we intend to use them, and our processes for ensuring beneficial outcomes result from their use should be as transparent as possible, within the necessary constraints of the national security context.</p>

<h3 id="fourth-principle-bias-and-harm-mitigation">Fourth principle: Bias and Harm Mitigation</h3>

<p>Those responsible for AI-enabled systems must proactively mitigate the risk of unexpected or unintended biases or harms resulting from these systems, whether through their original rollout, or as they learn, change or are redeployed.</p>

<p>AI-enabled systems offer significant benefits for Defence. However, the use of AI-enabled systems may also cause harms (beyond those already accepted under existing ethical and legal frameworks) to those using them or affected by their deployment. These may range from harms caused by a lack of suitable privacy for personal data, to unintended military harms due to system unpredictability. Such harms may change over time as systems learn and evolve, or as they are deployed beyond their original setting. Of particular concern is the risk of discriminatory outcomes resulting from algorithmic bias or skewed data sets. Defence must ensure that its AI-enabled systems do not result in unfair bias or discrimination, in line with the MODâ€™s ongoing strategies for diversity and inclusion.</p>

<p>A principle of bias and harm mitigation requires the assessment and, wherever possible, the mitigation of these biases or harms. This includes addressing bias in algorithmic decision-making, carefully curating and managing datasets, setting safeguards and performance thresholds throughout the system lifecycle, managing environmental effects, and applying strict development criteria for new systems, or existing systems being applied to a new context.</p>

<h3 id="fifth-principle-reliability">Fifth principle: Reliability</h3>

<p>AI-enabled systems must be demonstrably reliable, robust and secure.</p>

<p>The MODâ€™s AI-enabled systems must be suitably reliable; they must fulfil their intended design and deployment criteria and perform as expected, within acceptable performance parameters. Those parameters must be regularly reviewed and tested for reliability to be assured on an ongoing basis, particularly as AI-enabled systems learn and evolve over time, or are deployed in new contexts.</p>

<p>Given Defenceâ€™s unique operational context and the challenges of the information environment, this principle also requires AI-enabled systems to be secure, and a robust approach to cybersecurity, data protection and privacy.</p>

<p>MOD personnel working with or alongside AI-enabled systems can build trust in those systems by ensuring that they have a suitable level of understanding of the performance and parameters of those systems, as articulated in the principle of understanding.</p>

<h2 id="annex-b-the-ministry-of-defence-ai-ethics-advisory-panel">Annex B: The Ministry of Defence AI Ethics Advisory Panel</h2>

<p>The MOD AI Ethics Advisory panel is an informal advisory board to the 2nd Permanent Secretary for Defence in his role as senior responsible owner for AI Ethics in the department.</p>

<p>The panelâ€™s purpose is to convene a combination of expert voices from Defence, academia, industry and civil society to advise the 2nd Permanent Secretary on the development of policy relating to safe and responsible development and use of AI.</p>

<p>The panel is advisory only, and has no formal decision-making powers, but willÂ beÂ responsible for scrutinising the MODâ€™s ongoing approach to responsible and ethical AI. Panellists were appointed by the MOD on the basis of their expertise across the subjects of AI development, AI ethics, military ethics and international law.</p>

<p>As of the date of publication, the current panel has met three times, and has served a key role in providing scrutiny and advice on the crafting of the ethical principles and potential methods of implementation. The panel has not been involved in the creation of policy related to Lethal Autonomous Weapons Systems, nor the departmentâ€™s policy on AI safety.</p>

<p>The current panel membership is as follows:</p>

<p>Laurence Lee,Â 2ndÂ Permanent Secretary for Defence (Chair)</p>

<p>Professor Dapo Akande, Director of the Oxford Institute for Ethics, Law and Armed Conflict</p>

<p>Professor Nick Colosimo, Global Engineering Fellow &amp; Technologist, BAE systemsÂ and Visiting Professor, Cranfield University (Centre for Autonomous &amp; Cyber-Physical Systems).</p>

<p>Dr Merel Ekelhof, Foreign Exchange OfficerÂ at the USÂ DoDÂ Joint AIÂ Center and formerÂ Lead Researcher on AI and Autonomy at UNIDIR,Â attending the panel in her personal capacity.</p>

<p>Tabitha Goldstaub, Founder ofÂ CognitionXÂ and chair of the AI Council</p>

<p>Dr Darrell Jaya-Ratnam, Managing Director, DIEM Analytics</p>

<p>Professor Peter Lee, Professor of Applied Ethics, University of Portsmouth</p>

<p>Professor Dame Angela McLean, Chief Scientific Advisor at the Ministry of Defence</p>

<p>Richard Moyes, Managing Director and co-founder, Article 36</p>

<p>Professor Gopal Ramchurn, Director, UKRI Trustworthy Autonomous Systems Hub and the University of Southampton</p>

<p>Polly Scully, DirectorÂ for Strategy at the Ministry of Defence</p>

<p>Professor Mariarosaria Taddeo, Associate Professor and Senior Research Fellow, Oxford Internet Institute, University of Oxford; Dstl Ethics Fellow, Alan Turing Institute.</p>

<p>Lt GenÂ RolyÂ Walker, Deputy Chief of the Defence Staff for Military Strategy and Operations</p>

<p>Professor David Whetham, Professor of Ethics and the Military Profession, Kings College London</p>

<p>Dominic Wilson, Director General for Security Policy, Ministry of Defence</p>

<h2 id="annex-c-lethal-autonomous-weapon-systems-laws">ANNEX C: Lethal Autonomous Weapon Systems (LAWS)</h2>

<div class="call-to-action">
  <p>One of the most significant concerns around the use of AI in Defence is around introducing elements of autonomy to the use of weapons systems. This subject has already been the source of significant international debate, particularly under the UNâ€™s Group of Government Experts on LAWS. The following section sets out the UKâ€™s position on this potential use case for AI-enabled systems.</p>

  <p>AI can enable systems â€“ including weapons â€“ to exhibit some measure of autonomy: deciding and acting to accomplish desired goals, within defined parameters, based on acquired knowledge and an evolving situational awareness. This potentially could lead to weapons that identify, select and attack targets without context-appropriate human involvement. That is not acceptable â€“ the United Kingdom does not possess fully autonomous weapon systems and has no intention of developing them.</p>

  <p>We strongly believe that AI within weapon systems can and must be used lawfully and ethically. Sharing the concerns of Governments and AI experts around the world, we therefore oppose the creation and use of systems that would operate without meaningful and context-appropriate human involvement throughout their lifecycle. The use of such weapons could not satisfy fundamental principles of International Humanitarian Law, nor our own values and standards as expressed in our AI Ethical Principles. Human responsibility and accountability cannot be removed â€“ irrespective of the level of AI or autonomy in a system. The UK will always clearly establish authorities, thus human responsibility, and accountabilities whenever UK forces deploy weapon systems which incorporate AI.</p>

  <p>We will continue to work closely with international allies and partners to address the opportunities and risks around autonomy in weapons systems. Global governance for such systems is a difficult task. It will be challenging to reach international agreement on definitions for full or partial autonomy on a technical or systems level. It is also important to ensure any approach allows for rapid technological advancement, and doesnâ€™t become redundant or isnâ€™t able to be circumvented as technology develops. Such international processes must be inclusive, and involve all key actors in this space if they are to be effective.</p>

  <p>We believe the best approach is to focus on building norms of use and positive obligations to demonstrate how degrees of autonomy in weapons systems can be used in accordance with international humanitarian law â€“ with suitable levels of human control, accountability and responsibility. Setting out those characteristics that would make it inherently impossible for a system to comply with international humanitarian law is key to this, and we will continue to engage actively in the international arena to reach consensus on them. The UN Group of Government Experts on LAWS under the Convention for Certain Conventional Weapons will continue to be our primary avenue for such discussions. Our own approach, driven by the AI Ethical principles, is to build understanding, best practice and codes of conduct through which we can achieve ethical outcomes in our use of AI.</p>
</div>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Andrew Ng: Why AI Is the New Electricity, <a rel="external" href="http://www.gsb.stanford.edu/insights/Andrew-ng-why-ai-new-electricity" class="govuk-link">gsb.stanford.edu/insights/Andrew-ng-why-ai-new-electricity</a>Â <a href="#fnref:1" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">â†©</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p><a rel="external" href="https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/709359/20180517-concepts_uk_human_machine_teaming_jcn_1_18.pdf" class="govuk-link">Joint Concept Note 1/18 â€“ Human Machine Teaming</a>Â <a href="#fnref:2" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">â†©</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>For an explanation of how these legal and our ethical principles apply to discussions around Lethal Autonomous Weapon Systems see Annex C.Â <a href="#fnref:3" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">â†©</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>For an explanation of how these ethical principles and also the legal principles of International Humanitarian Law apply to discussions around Lethal Autonomous Weapon Systems, see Annex C.Â <a href="#fnref:4" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">â†©</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>Our joint methodology comprised desk and interview-based research exploring key issues, including the unique ethical challenges posed by AI in Defence. We deployed a range of methods to test and iterate the principles, including one-to-one and group interviews, roundtables and workshops with experts from across Defence, industry, academia, civil society, law, government and frontline military personnel. We also tested the principles against a range of hypothetical Defence AI use cases, and against a typical Defence AI system lifecycle. Further details on the process will be outlined in a joint MoD-CDEI report which we intend to publish in 2022.Â <a href="#fnref:5" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">â†©</a></p>
    </li>
  </ol>
</div>
</div>


</div>
</div>
    </div>
  </div>

  <div class="govuk-grid-row">
    <a class="govuk-link app-c-back-to-top govuk-!-display-none-print" href="#contents">
    <svg class="app-c-back-to-top__icon" xmlns="http://www.w3.org/2000/svg" width="13" height="17" viewbox="0 0 13 17" aria-hidden="true" focusable="false">
      <path fill="currentColor" d="M6.5 0L0 6.5 1.4 8l4-4v12.7h2V4l4.3 4L13 6.4z"></path>
    </svg>
    Back to top
</a>

  </div>
</div>


    </main>
  </div>

      <div class="govuk-width-container">
        
<div class="gem-c-feedback govuk-!-display-none-print" data-module="feedback ga4-event-tracker">
  
<div class="gem-c-feedback__prompt gem-c-feedback__js-show js-prompt" tabindex="-1">
  <div class="gem-c-feedback__prompt-content">
    <div class="gem-c-feedback__prompt-questions js-prompt-questions" hidden>
      <div class="gem-c-feedback__prompt-question-answer">
        <h2 class="gem-c-feedback__prompt-question">Is this page useful?</h2>
        <ul class="gem-c-feedback__option-list">
          <li class="gem-c-feedback__option-list-item govuk-visually-hidden" hidden>
            <a class="gem-c-feedback__prompt-link" role="button" hidden="hidden" aria-hidden="true" href="/contact/govuk">
              Maybe
</a>          </li>
          <li class="gem-c-feedback__option-list-item">
            <button class="govuk-button gem-c-feedback__prompt-link js-page-is-useful" data-ga4-event='{"event_name":"form_submit","type":"feedback","text":"Yes","section":"Is this page useful?","tool_name":"Is this page useful?"}'>
              Yes <span class="govuk-visually-hidden">this page is useful</span>
</button>          </li>
          <li class="gem-c-feedback__option-list-item">

            <button class="govuk-button gem-c-feedback__prompt-link js-toggle-form js-page-is-not-useful" aria-controls="page-is-not-useful" aria-expanded="false" data-ga4-event='{"event_name":"form_submit","type":"feedback","text":"No","section":"Is this page useful?","tool_name":"Is this page useful?"}'>
              No <span class="govuk-visually-hidden">this page is not useful</span>
</button>          </li>
        </ul>
      </div>
    </div>

    <div class="gem-c-feedback__prompt-questions gem-c-feedback__prompt-success js-prompt-success" role="alert" hidden>
      Thank you for your feedback
    </div>

    <div class="gem-c-feedback__prompt-questions gem-c-feedback__prompt-questions--something-is-wrong js-prompt-questions" hidden>
      <button class="govuk-button gem-c-feedback__prompt-link js-toggle-form js-something-is-wrong" aria-expanded="false" aria-controls="something-is-wrong" data-ga4-event='{"event_name":"form_submit","type":"feedback","text":"Report a problem with this page","section":"Is this page useful?","tool_name":"Is this page useful?"}'>
        Report a problem with this page
</button>    </div>
  </div>
</div>

  
<form action="https://www.gov.uk/contact/govuk/problem_reports" id="something-is-wrong" class="gem-c-feedback__form js-feedback-form" method="post" hidden>

  <div class="govuk-grid-row">
    <div class="govuk-grid-column-two-thirds">
      <div class="gem-c-feedback__error-summary gem-c-feedback__js-show js-errors" tabindex="-1" hidden></div>

      <input type="hidden" name="url" value="https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence">

      <h3 class="gem-c-feedback__form-heading">Help us improve GOV.UK</h3>
      <p id="feedback_explanation" class="gem-c-feedback__form-paragraph">Donâ€™t include personal or financial information like your National Insurance number or credit card details.</p>

      <div class="govuk-visually-hidden" aria-hidden="true">
        <label for="giraffe">This field is for robots only. Please leave blank</label>
        <input id="giraffe" name="giraffe" type="text" pattern=".{0}" tabindex="-1" autocomplete="off">
      </div>

      
<div class="gem-c-textarea govuk-form-group govuk-!-margin-bottom-6">
    
  <label for="textarea-61e5ba10" class="gem-c-label govuk-label">What were you doing?</label>





  <textarea name="what_doing" class="govuk-textarea" id="textarea-61e5ba10" rows="3" spellcheck="true" aria-describedby="feedback_explanation">
</textarea>
    
</div>

      
<div class="gem-c-textarea govuk-form-group govuk-!-margin-bottom-6">
    
  <label for="textarea-73757c92" class="gem-c-label govuk-label">What went wrong?</label>





  <textarea name="what_wrong" class="govuk-textarea" id="textarea-73757c92" rows="3" spellcheck="true">
</textarea>
    
</div>


      


  <button class="gem-c-button govuk-button" type="submit" data-ga4-event='{"event_name":"form_submit","type":"feedback","text":"Send","section":"Help us improve GOV.UK","tool_name":"Help us improve GOV.UK"}'>Send</button>



      <button class="govuk-button govuk-button--secondary gem-c-feedback__close gem-c-feedback__js-show js-close-form" aria-controls="something-is-wrong" aria-expanded="true">
        Cancel
      </button>
    </div>
  </div>
</form>


<script nonce="8bULL1bqak7DTu7I/zZM/Q==">
//<![CDATA[
  document.addEventListener("DOMContentLoaded", function () {
    var input = document.querySelector("#giraffe"),
      form = document.querySelector("#something-is-wrong")

    form.addEventListener("submit", spamCapture);

    function spamCapture(e) {
      if (input.value.length !== 0) return;
      e.preventDefault();
    }
  });

//]]>
</script>
  
<div id="page-is-not-useful" class="gem-c-feedback__form gem-c-feedback__form--email gem-c-feedback__js-show js-feedback-form">
  <div class="govuk-grid-row">
    <div class="govuk-grid-column-two-thirds" id="survey-wrapper">
      <div class="gem-c-feedback__error-summary js-errors" tabindex="-1" hidden></div>

      <h3 class="gem-c-feedback__form-heading">Help us improve GOV.UK</h3>
      <p id="survey_explanation" class="gem-c-feedback__form-paragraph">
        To help us improve GOV.UK, weâ€™d like to know more about your visit today.
        <a href="https://www.smartsurvey.co.uk/s/gov-uk-banner/?c=no-js" class="govuk-link" target="_blank" rel="noopener noreferrer external">Please fill in this survey (opens in a new tab)</a>.
      </p>
      <button class="govuk-button govuk-button--secondary js-close-form" aria-controls="page-is-not-useful" aria-expanded="true" hidden>
        Cancel
      </button>
    </div>
  </div>
</div>

</div>

      </div>

      <footer class="gem-c-layout-footer govuk-footer gem-c-layout-footer--border" role="contentinfo" data-module="ga4-link-tracker">
  <div class="govuk-width-container">
      <div class="govuk-footer__navigation">
            <div class="govuk-grid-column-two-thirds govuk-!-display-none-print">
              <h2 class="govuk-footer__heading govuk-heading-m">Services and information</h2>
                <ul class="govuk-footer__list govuk-footer__list--columns-2">
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"1","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/benefits">Benefits</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"2","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/births-deaths-marriages">Births, death, marriages and care</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"3","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/business">Business and self-employed</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"4","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/childcare-parenting">Childcare and parenting</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"5","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/citizenship">Citizenship and living in the UK</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"6","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/justice">Crime, justice and the law</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"7","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/disabilities">Disabled people</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"8","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/driving">Driving and transport</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"9","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/education">Education and learning</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"10","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/employing-people">Employing people</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"11","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/environment-countryside">Environment and countryside</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"12","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/housing-local-services">Housing and local services</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"13","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/tax">Money and tax</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"14","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/abroad">Passports, travel and living abroad</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"15","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/visas-immigration">Visas and immigration</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"16","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/working">Working, jobs and pensions</a>
                      </li>
                </ul>
            </div>
            <div class="govuk-grid-column-one-third govuk-!-display-none-print">
              <h2 class="govuk-footer__heading govuk-heading-m">Government activity</h2>
                <ul class="govuk-footer__list govuk-footer__list--columns-1">
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"1","index_section":"2","index_section_count":"5","index_total":"8","section":"Government activity"}' href="https://www.gov.uk/government/organisations">Departments</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"2","index_section":"2","index_section_count":"5","index_total":"8","section":"Government activity"}' href="https://www.gov.uk/search/news-and-communications">News</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"3","index_section":"2","index_section_count":"5","index_total":"8","section":"Government activity"}' href="https://www.gov.uk/search/guidance-and-regulation">Guidance and regulation</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"4","index_section":"2","index_section_count":"5","index_total":"8","section":"Government activity"}' href="https://www.gov.uk/search/research-and-statistics">Research and statistics</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"5","index_section":"2","index_section_count":"5","index_total":"8","section":"Government activity"}' href="https://www.gov.uk/search/policy-papers-and-consultations">Policy papers and consultations</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"6","index_section":"2","index_section_count":"5","index_total":"8","section":"Government activity"}' href="https://www.gov.uk/search/transparency-and-freedom-of-information-releases">Transparency</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"7","index_section":"2","index_section_count":"5","index_total":"8","section":"Government activity"}' href="https://www.gov.uk/government/how-government-works">How government works</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"8","index_section":"2","index_section_count":"5","index_total":"8","section":"Government activity"}' href="https://www.gov.uk/government/get-involved">Get involved</a>
                      </li>
                </ul>
            </div>
      </div>

      <hr class="govuk-footer__section-break govuk-!-display-none-print">
    <div class="govuk-footer__meta">
      <div class="govuk-footer__meta-item govuk-footer__meta-item--grow">
          <h2 class="govuk-visually-hidden">Support links</h2>
          <ul class="govuk-footer__inline-list govuk-!-display-none-print">
              <li class="govuk-footer__inline-list-item">
                <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"1","index_section":"3","index_section_count":"5","index_total":"8","section":"Support links"}' href="https://www.gov.uk/help">Help</a>
              </li>
              <li class="govuk-footer__inline-list-item">
                <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"2","index_section":"3","index_section_count":"5","index_total":"8","section":"Support links"}' href="https://www.gov.uk/help/privacy-notice">Privacy</a>
              </li>
              <li class="govuk-footer__inline-list-item">
                <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"3","index_section":"3","index_section_count":"5","index_total":"8","section":"Support links"}' href="https://www.gov.uk/help/cookies">Cookies</a>
              </li>
              <li class="govuk-footer__inline-list-item">
                <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"4","index_section":"3","index_section_count":"5","index_total":"8","section":"Support links"}' href="https://www.gov.uk/help/accessibility-statement">Accessibility statement</a>
              </li>
              <li class="govuk-footer__inline-list-item">
                <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"5","index_section":"3","index_section_count":"5","index_total":"8","section":"Support links"}' href="https://www.gov.uk/contact">Contact</a>
              </li>
              <li class="govuk-footer__inline-list-item">
                <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"6","index_section":"3","index_section_count":"5","index_total":"8","section":"Support links"}' href="https://www.gov.uk/help/terms-conditions">Terms and conditions</a>
              </li>
              <li class="govuk-footer__inline-list-item">
                <a class="govuk-footer__link" lang="cy" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"7","index_section":"3","index_section_count":"5","index_total":"8","section":"Support links"}' href="https://www.gov.uk/cymraeg">Rhestr o Wasanaethau Cymraeg</a>
              </li>
              <li class="govuk-footer__inline-list-item">
                <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"8","index_section":"3","index_section_count":"5","index_total":"8","section":"Support links"}' href="https://www.gov.uk/government/organisations/government-digital-service">Government Digital Service</a>
              </li>
          </ul>
        <svg aria-hidden="true" focusable="false" class="govuk-footer__licence-logo" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 483.2 195.7" height="17" width="41">
          <path fill="currentColor" d="M421.5 142.8V.1l-50.7 32.3v161.1h112.4v-50.7zm-122.3-9.6A47.12 47.12 0 0 1 221 97.8c0-26 21.1-47.1 47.1-47.1 16.7 0 31.4 8.7 39.7 21.8l42.7-27.2A97.63 97.63 0 0 0 268.1 0c-36.5 0-68.3 20.1-85.1 49.7A98 98 0 0 0 97.8 0C43.9 0 0 43.9 0 97.8s43.9 97.8 97.8 97.8c36.5 0 68.3-20.1 85.1-49.7a97.76 97.76 0 0 0 149.6 25.4l19.4 22.2h3v-87.8h-80l24.3 27.5zM97.8 145c-26 0-47.1-21.1-47.1-47.1s21.1-47.1 47.1-47.1 47.2 21 47.2 47S123.8 145 97.8 145"></path>
        </svg>
        <span class="govuk-footer__licence-description" data-ga4-track-links-only data-ga4-link='{"event_name":"navigation","section":"Licence","index_section":"4","index_link":"1","index_section_count":"5","text":"Open Government Licence v3.0","index_total":"1","type":"footer"}'>
          All content is available under the <a class="govuk-footer__link" href="https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/" rel="license">Open Government Licence v3.0</a>, except where otherwise stated
        </span>
      </div>
      <div class="govuk-footer__meta-item" data-ga4-link='{"event_name":"navigation","section":"Copyright","index_section":"5","index_link":"1","index_section_count":"5","text":"Â© Crown copyright","index_total":"1","type":"footer"}'>
        <a class="govuk-footer__link govuk-footer__copyright-logo" href="https://www.nationalarchives.gov.uk/information-management/re-using-public-sector-information/uk-government-licensing-framework/crown-copyright/">Â© Crown copyright</a>
      </div>
    </div>
  </div>
</footer>
    <script src="/assets/static/application-7d6d614311ebcb5137ebd31f0d2ae7933e79a5b7ae1c45d22c74de8c51550173.js" type="module"></script>
<script src="/assets/government-frontend/application-da84cd5045ffdd4664d3c3ead0965a61ec77c4065afae4aa0cbd3c562406ef80.js" type="module"></script><script type="application/ld+json">
  {
  "@context": "http://schema.org",
  "@type": "FAQPage",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence"
  },
  "name": "Ambitious, safe, responsible: our approach to the delivery of AI-enabled capability in Defence",
  "datePublished": "2022-06-15T11:10:10+01:00",
  "dateModified": "2022-06-15T11:10:00+01:00",
  "text": null,
  "publisher": {
    "@type": "Organization",
    "name": "GOV.UK",
    "url": "https://www.gov.uk",
    "logo": {
      "@type": "ImageObject",
      "url": "https://www.gov.uk/assets/government-frontend/govuk_publishing_components/govuk-logo-b15a4d254746d1642b8187217576d1e8fe50b51352d352fda13eee55d3c1c80a.png"
    }
  },
  "image": [
    "https://www.gov.uk/assets/government-frontend/govuk_publishing_components/govuk-schema-placeholder-1x1-c3d38c0d4fc00005df38a71e1db7097276681d6917bca58f0dc8336a252e1bb3.png",
    "https://www.gov.uk/assets/government-frontend/govuk_publishing_components/govuk-schema-placeholder-4x3-edc38c137a14ecfc3fc83f404090e20dab806dad345c96a1df6a163ee2d1e3aa.png",
    "https://www.gov.uk/assets/government-frontend/govuk_publishing_components/govuk-schema-placeholder-16x9-5dc2d0ea1eb72cd94e66db210ef41b22ce364e7ed09d63a3acc28fda09e27864.png"
  ],
  "author": {
    "@type": "Organization",
    "name": "Ministry of Defence",
    "url": "https://www.gov.uk/government/organisations/ministry-of-defence"
  },
  "mainEntity": [
    {
      "@type": "Question",
      "name": "Executive Summary",
      "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#executive-summary",
      "acceptedAnswer": {
        "@type": "Answer",
        "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#executive-summary",
        "text": "\u003cdiv class=\"call-to-action\"\u003e\n  \u003ch3 id=\"defining-artificial-intelligence\"\u003eDefining Artificial Intelligence\u003c/h3\u003e\n\n  \u003cp\u003eDefence understands Artificial Intelligence (AI) as a family of general-purpose technologies, any of which may enable machines to perform tasks normally requiring human or biological intelligence, especially when the machines learn from data how to do those tasks.\u003c/p\u003e\n\u003c/div\u003e\u003cp\u003eThe Defence AI Strategy sets out our view of the strategic opportunities and challenge presented by the emergence of AI as a transformative and disruptive new technology. Realising the benefits of AI â€“ and countering threats and challenges associated with the use of AI by others â€“ is one of the most critical strategic challenges of our time.\u003c/p\u003e\u003cp\u003eAI will enable our people to make powerful use of previously unimaginable quantities of data. It will improve decision-making and the delivery of operational effect. There is a strong case for the development and use of an AI system where it would be demonstrably beneficial or result in a more ethical outcome. In an era of increasing global competition and given resource limitations, it is imperative that we deliver maximum effectiveness and efficiency using AI across the spectrum of Defence activities.\u003c/p\u003e\u003cp\u003eWe also recognise that the nature of AI gives rise to risks and concerns about possible impact on humans. These can be particularly acute in a Defence context. If we do not address them, we risk losing public consent, seeing our ability to operate undermined, and exacerbating the irresponsible behaviour of others â€“ not to mention undermining our ability to deliver Defence capability.\u003c/p\u003e\u003cdiv class=\"call-to-action\"\u003e\n  \u003cp\u003eWe believe that a broad â€˜systemsâ€™ perspective will ensure AI-related issues are addressed systematically and effectively. By focusing on outcomes, delivered through clear frameworks \u0026amp; processes , and guided by our conviction that AI can be a powerful force for good, we will ensure that we:\u003c/p\u003e\n\n  \u003cul\u003e\n    \u003cli\u003e\n      \u003cp\u003eare ambitious, in terms of the tools and operational effects we seek to deliver\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli\u003e\n      \u003cp\u003eenable â€“ rather than constrain â€“ the delivery of those tools and effects\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli\u003e\n      \u003cp\u003edeliver and use AI-enabled capability in a safe and responsible manner\u003c/p\u003e\n    \u003c/li\u003e\n  \u003c/ul\u003e\n\u003c/div\u003e\u003cp\u003eWithin Defence, this will be achieved through a number of overlapping approaches. We will:\u003c/p\u003e\u003cul\u003e\n  \u003cli\u003e\n    \u003cp\u003eset clear organisational intent and ambition for the adoption and exploitation of AI, backed up with defined roles and responsibilities, as set out in the Defence AI Strategy;\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003econtinue to apply our robust safety and regulation regimes;\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003ealways comply with our national and international legal obligations; and\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003eset out a clear framework and processes for ensuring ethical adoption of the technology.\u003c/p\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\u003cp\u003eThis is a positive blueprint for effective, innovative and responsible AI adoption. Fundamentally, the best way to develop AI systems for Defence which serve our operational needs and reflect the values of those we serve is to: set ambitious direction; ensure clarity and certainty around our approaches; and provide assurance to colleagues in Defence, industry and wider society â€“ thereby demonstrating trustworthiness.\u003c/p\u003e"
      }
    },
    {
      "@type": "Question",
      "name": "Ambitious delivery of capability",
      "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#ambitious-delivery-of-capability",
      "acceptedAnswer": {
        "@type": "Answer",
        "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#ambitious-delivery-of-capability",
        "text": "\u003cp\u003eWe aspire to exploit AI comprehensively, accelerating â€˜best in classâ€™ AI-enabled capabilities into service in order to make all parts of Defence significantly more efficient and effective. To do this, we must ensure that we are always ambitious in the ways in which we incorporate AI into Defence capabilities where AI is the appropriate tool to adopt. We will not adopt AI for its own sake; it is not an â€˜endâ€™ in itself.\u003c/p\u003e\u003cp\u003eWe intend that our approach will enable â€“ rather than constrain â€“ the adoption and exploitation of AI-enabled solutions and capabilities across Defence. We will empower teams developing and delivering concepts, technologies and solutions to explore ambitious ideas and use cases. We will provide them with clear frameworks to support the early identification and resolution of safety, legal and ethical risks; this will give them the confidence to explore the full potential of the technology while complying with policy and other essential requirements. We will encourage them to identify wider factors impeding their progress â€“ such as policy or process â€“ in the expectation that appropriate solutions will be identified and implemented rapidly.\u003c/p\u003e\u003cp\u003eWe want to harness the creativity and innovation found across Defence and the private sector. This includes the necessary problem-solving approaches to bring those ambitious use-cases to life in an appropriate way. Since risks and challenges may exist in respect of any part of the â€˜system of systemsâ€™ across the full lifecycle of the capability, we are clear that solutions may similarly be found across the full â€˜system of systemsâ€™ and lifecycle.\u003c/p\u003e\u003cp\u003eIn other words, the issue may not lie in â€˜whatâ€™ the capability is designed to do, but â€˜howâ€™ it does it, and how we ensure that AI is used effectively and appropriately within it. We will ensure that suitable methods are adopted across our enterprise to â€˜design outâ€™ problems, and that we rigorously test AI-enabled solutions. Further information can be found in the Defence AI Strategy.\u003c/p\u003e\u003cp\u003eAs a general enabling technology, AI has been dubbed â€˜the new electricityâ€™.\u003csup id=\"fnref:1\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:1\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 1]\u003c/a\u003e\u003c/sup\u003e Clearly there are important differences. One useful point of comparison, is that initial planning to deliver a major system (ultimately to be powered by electricity) would focus on the desired outcome and level of ambition. Discussion might be mainly about vision and willingness to push boundaries, although planners would also consider possible delivery routes and likely be aware of engineering limitations.\u003c/p\u003e\u003cp\u003eInitial planning would not normally hinge on discussions about whether the likely incorporation of electricity meant that the system could be delivered safely and responsibly. These issues would be addressed systematically through design, manufacture, use in service and disposal, even if this necessitated changes in operational approaches, or additional Research \u0026amp; Development to provide technical solutions.\u003c/p\u003e\u003cp\u003eThis is similar to the way we think about AI. We start from the belief that AI is a powerful tool, and that we must be confident in our vision for AI-enabled capability. Safe and responsible outcomes are then a function of Defence-wide processes, rather than of early self-imposed limitations which would risk being arbitrary, constraining and habitually out-dated, given the speed of technological advances.\u003c/p\u003e"
      }
    },
    {
      "@type": "Question",
      "name": "Our approach and AI-enabled weapons",
      "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#our-approach-and-ai-enabled-weapons",
      "acceptedAnswer": {
        "@type": "Answer",
        "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#our-approach-and-ai-enabled-weapons",
        "text": "\u003cp\u003eWe will focus on outcomes, exploring ambitious options rather than filtering out ideas or concepts when they are still on the drawing board. We do not rule out incorporating AI within weapon systems. In practice, however, some concepts and capabilities may prove impossible to deliver in a safe and responsible manner â€“ and we are very clear that there must be context-appropriate human involvement in weapons which identify, select and attack targets. This could mean some form of real-time human supervision, or control exercised through the setting of a systemâ€™s operational parameters.\u003c/p\u003e\u003cp\u003eWe believe that AI can substantially augment the performance of our people and significantly enhance our capabilities. However, given concerns about the ethics and risks of delegating certain decisions to AI, it is also important to state that we do not believe that â€˜more autonomousâ€™ necessarily means â€˜more capableâ€™. We believe that Human-Machine Teaming\u003csup id=\"fnref:2\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:2\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 2]\u003c/a\u003e\u003c/sup\u003e delivers the best outcomes, in terms of overall effectiveness, optimal use of resources, the practicalities of integration and the ease with which we can address issues arising; it is therefore our default approach to AI adoption.\u003c/p\u003e\u003cp\u003eThe appropriate degree of system â€˜autonomyâ€™ and type of â€˜human controlâ€™ need to be considered carefully on a case-by-case basis.\u003c/p\u003e\u003cp\u003eLooking at AI-enabled systems from a technological perspective: the precise degree of AI-enabled autonomy needed within any given capability or component will depend on the specific nature of the system or the concept for its use. Operational outcomes typically depend on speed and accuracy, in terms of assessment and then action. These can be enabled to a very high degree without the requirement to delegate problematic levels of discretion or judgement to the AI.\u003c/p\u003e\u003cp\u003eLooking at the same systems from a People perspective: we can exert satisfactory and rigorous human control over AI-enabled systems without always requiring some form of real-time human supervision. Indeed, doing so may act as an unnecessary and inappropriate constraint on operational performance. For example, to defend a maritime platform against hypersonic weapons we may need defensive systems which can detect incoming threats and open fire faster than a human could react.\u003c/p\u003e\u003cp\u003eAnother crucial point is that all new weapons, means and methods of warfare are subject to a rigorous review process for compliance with International Humanitarian Law and other applicable international law. Determinations as to the necessary scope and application of context-appropriate human involvement will be done similarly systematically. We also adjust our operating procedures to ensure that we stay within the boundaries of the law that applies at the time.\u003c/p\u003e\u003cp\u003eThis approach is reflected in our policy with regards to international debates on â€˜Lethal Autonomous Weapon Systems, set out in more detail at Annex C.\u003c/p\u003e"
      }
    },
    {
      "@type": "Question",
      "name": "Key challenges to Defence AI Adoption",
      "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#key-challenges-to-defence-ai-adoption",
      "acceptedAnswer": {
        "@type": "Answer",
        "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#key-challenges-to-defence-ai-adoption",
        "text": "\u003cp\u003eThe use of AI in a Defence context raises a number of interlinked issues and challenges, which development teams and users will need to take into consideration. These include:\u003c/p\u003e\u003cul\u003e\n  \u003cli\u003e\n    \u003cp\u003eAlgorithmic Bias: the risk that biased datasets used to train AI systems could result in discriminatory outcomes and disproportionate harms for certain groups of users;\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003eResponsibility \u0026amp; Accountability: the need to ensure that delegation of tasks or decisions to AI systems does not lead to a â€˜responsibility gapâ€™ between systems that take decisions or make recommendations, and the human commanders responsible for them;\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003eUnpredictability: the risk that some AI systems may behave unpredictably, particularly in new or complex environments, or as they learn and adapt over time;\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003eUnintended Consequences and Incentives: the potential for AI-enabled systems to have unintended side-effects on human behaviour, through enabling certain incentives, or influencing other systems beyond their intended effect;\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003ePeople Implications: the need to think differently about what is expected of people, and the impact of AI on people, as AI-enabled systems create opportunities to automate â€˜dull, dirty or dangerousâ€™ tasks; and;\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003eHuman Control: when using AI-enabled systems for Defence purposes, the need to understand the appropriate form of human involvement required for any given application or context.\u003c/p\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\u003cp\u003eThese issues may be encountered individually or in combination. Some create safety issues, requiring us to ensure that our AI does not cause inadvertent harm or danger as a part of its use. Some give rise to ethical issues, requiring us to ensure that our use of the technology aligns with our values, and those of the society we represent.  Some are important elements in ensuring that the particular capability complies with our domestic and international legal obligations (e.g. relating to data protection, privacy or International Humanitarian Law).\u003c/p\u003e\u003cp\u003eIn handling these issues properly, we must maintain the trust and goodwill of our key stakeholders - including our service personnel - allies, and partners in the private sector. Without this, we risk slowing innovation, losing important opportunities to collaborate â€“ and reduced public consent for the use of these technologies.\u003c/p\u003e\u003cp\u003eBy adopting a safe and responsible approach to AI, we also have an opportunity to set a positive example to others, encouraging the safe and responsible use of AI globally.\u003c/p\u003e\u003cp\u003eTo achieve these outcomes, we are establishing a clear framework which will provide support and clarity to the teams within Defence and beyond who are developing and operating our AI-enabled systems.\u003c/p\u003e"
      }
    },
    {
      "@type": "Question",
      "name": "Using AI Safely",
      "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#using-ai-safely",
      "acceptedAnswer": {
        "@type": "Answer",
        "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#using-ai-safely",
        "text": "\u003cp\u003eA number of the key challenges associated with adopting AI for Defence pose particular issues for safety.\u003c/p\u003e\u003cp\u003eThe unpredictability of some AI systems, particularly when applied to new and challenging environments, increase the risks that unforeseen issues may arise with their use. The relative difficulties with interpreting how some forms of AI systems learn and make decisions present new challenges for the testing, evaluation and certification of such systems. In addition, the high potential impact of AI-enabled systems for Defence raises the stakes for potential side effects or unintended consequences, particularly when they could cause harms for those interacting with them.\u003c/p\u003e\u003cp\u003eBroadly, this is not a new challenge for the Department. Defence is bound by UK law and has a robust regime for compliance. Defence activities also include those that are inherently dangerous and require additional risk management beyond that of our statutory obligations.\u003c/p\u003e\u003cp\u003eWhere Defence has certain derogations, exemptions or disapplicationâ€™s from UK legislation and regulations, it is the Departmentâ€™s policy and practice to maintain arrangements that produce outcomes that are, so far as practicable, at least as good as those required by UK legislation. This is reflected in Health, Safety and Environmental Protection (HS\u0026amp;EP) in Defence â€“ Policy statement by the Secretary of State for Defence.\u003c/p\u003e\u003cp\u003eA strict compliance with safety rules is therefore essential to Defenceâ€™s use of any new technology.\u003c/p\u003e\u003cp\u003eThe Defence Safety Authority (DSA) contributes to Defence capability, reputation and effectiveness through the setting, and enforcement of Defence Regulations for Health, Safety and Environmental Protection and supports the Ministry of Defence by providing independent, evidence-based assurance.\u003c/p\u003e\u003cp\u003eThe DSA conducts horizon scanning activity with regards to the development in AI capability. The DSA will continue to set Defence Regulation and conduct enforcement activity across in-service capability and will examine how AI capability can be assured in future.\u003c/p\u003e\u003cp\u003eWithin the DSA, the Defence Accident Investigation Branch (DAIB) provides Defence with an accident and incident investigation capability conducting impartial and expert no-blame safety investigations across all domains, with a focus on the identification and understanding of all accident factors. This may include accidents related to AI capability.\u003c/p\u003e"
      }
    },
    {
      "@type": "Question",
      "name": "Using AI Legally",
      "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#using-ai-legally",
      "acceptedAnswer": {
        "@type": "Answer",
        "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#using-ai-legally",
        "text": "\u003cp\u003eDefenceâ€™s activities are governed by a range of legislative provisions which ensure our work is undertaken in accordance with the law. This legislation protects fundamental freedoms and human rights, while giving the MOD the powers it needs to keep citizens safe and secure in the modern world\u003c/p\u003e\u003cp\u003eDefence always seeks to abide by its legal obligations across the full range of activities from employment law, to privacy and procurement, and the law of armed conflict, also known as International Humanitarian Law (IHL). It has robust practices and processes in place to ensure its activities and its people abide by the law. These practices and processes are being â€“ and will continue to be â€“ applied to AI-enabled capabilities.\u003c/p\u003e\u003cp\u003eDeployment of AI-enabled capabilities in armed conflict needs to comply fully with IHL, satisfying the four core principles of distinction, necessity, humanity and proportionality. We are very clear that use of any system or weapon which does not satisfy these fundamental principles would constitute a breach of international law.\u003csup id=\"fnref:3\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:3\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 3]\u003c/a\u003e\u003c/sup\u003e\u003c/p\u003e\u003cp\u003eArticle 36 legal reviews ensure that commanders, service personnel, politicians, the UK public and our allies can be assured that UK weapons are lawful. Additional Protocol 1 of the Geneva Convention, requires â€˜in the study, development, acquisition or adoption of a new weapon, means or method of warfare . . . to determine whether its employment would, in some or all circumstances, be prohibited by [Additional Protocol I] or by any other [applicable] rule of international lawâ€™.\u003c/p\u003e\u003cp\u003eAs with any new and emerging technology, the Ministry of Defence is therefore conscious of the need to be aware of any legal issues that may arise with the use of AI in Defence, whether as a means or method of warfare or in a â€˜back officeâ€™ system, and has robust review processes in place.\u003c/p\u003e\u003cdiv class=\"call-to-action\"\u003e\n  \u003cp\u003eOur development and use of AI technologies will always be in accordance with the body of applicable UK and international law.\u003c/p\u003e\n\u003c/div\u003e"
      }
    },
    {
      "@type": "Question",
      "name": "Using AI Ethically",
      "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#using-ai-ethically",
      "acceptedAnswer": {
        "@type": "Answer",
        "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#using-ai-ethically",
        "text": "\u003cp\u003eThe MOD is dedicated to the protection of UK people, territories, values and interests at home and overseas. We must be ethical â€“ and be seen to ethical â€“ in our AI development and use to protect UK values and retain the trust and support of our citizens, key stakeholders, allies and partners. This includes recognising the potential for cases where AI could be an important tool helping us to promote ethical outcomes and where it might be unethical not to use AI.\u003c/p\u003e\u003cp\u003eWe have therefore developed ethical principles for AI in Defence (Annex A), designed to lead our overall approach to AI-enabled technologies and systems across the full range of possible use cases, from back office to decision support and battlespace capabilities.\u003csup id=\"fnref:4\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:4\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 4]\u003c/a\u003e\u003c/sup\u003e They will apply to our development and use of AI across their lifecycle, and also to AI-enabled systems: platforms, processes or systems of which AI forms some part. These principles will:\u003c/p\u003e\u003cul\u003e\n  \u003cli\u003esteer our approach to the key challenges of AI, in particular providing direction around responsible development, training and use (see implementation section)\u003c/li\u003e\n  \u003cli\u003eform the core of the UKâ€™s approach to creating agreed norms for AI in Defence internationally, working with partners and allies to shape the global development of AI in the direction of freedom, openness and democracy\u003c/li\u003e\n  \u003cli\u003eprovide characteristics for AI systems which teams across Defence will be expected to follow in the development of new AI-enabled systems\u003c/li\u003e\n\u003c/ul\u003e\u003cp\u003eSetting out the principles is a key step towards ensuring a responsible and safe approach to the technology. Effective implementation and evolution of the principles will be required to ensure that our development of AI matches our requirement for safe and responsible innovation.\u003c/p\u003e"
      }
    },
    {
      "@type": "Question",
      "name": "Partnerships and Consultation",
      "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#partnerships-and-consultation",
      "acceptedAnswer": {
        "@type": "Answer",
        "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#partnerships-and-consultation",
        "text": "\u003cp\u003eToÂ develop these Principles, the MOD workedÂ inÂ partnership with the CentreÂ forÂ Data Ethics and Innovation (CDEI). The firstÂ inÂ the world of its kind, the CDEI leads the UK Governmentâ€™s workÂ toÂ enable trustworthy innovation using data and AI. Guided by an advisory body ofÂ internationally-recognised experts, the Centre works with partners across the public sector,Â industry and academia,Â inÂ the UK and internationally,Â toÂ identify and tackle barriersÂ toÂ responsible innovation. The MOD Principles are the result of over 18 months of consultation with over 100 expert stakeholders from around the world.\u003csup id=\"fnref:5\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:5\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 5]\u003c/a\u003e\u003c/sup\u003e\u003c/p\u003e\u003cp\u003eAs part of the consultation process, the MOD has convened an AI Ethics Advisory Panel, a group of experts in computer science, AI ethics and military ethics. This Panel ensured MOD benefitted from specialist insight and challenge, and played a crucial role supporting the development of the Principles. Further details on its role and current membership are available at Annex B.\u003c/p\u003e\u003cp\u003eGoing forward into implementation of these approaches, our commitment to transparency and consultation with industry and allies will continue. We will continue to work with the CDEI as this area evolves to ensure that our ongoing approach matches responsible best practice. We will also continue to engage proactively with leading experts from academia and industry, including the Ethics Advisory Panel.\u003c/p\u003e"
      }
    },
    {
      "@type": "Question",
      "name": "Governance",
      "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#governance",
      "acceptedAnswer": {
        "@type": "Answer",
        "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#governance",
        "text": "\u003cp\u003eThis policy statement should be read in conjunction with the Defence AI Strategy 2021, which provides more detail across the breadth of AI issues and activities relevant to Defence.\u003c/p\u003e\u003cp\u003eIn line with the governance model set out in the Strategy:\u003c/p\u003e\u003cul\u003e\n  \u003cli\u003e\n    \u003cp\u003ethe 2nd Permanent Secretary (2nd PUS) and the Vice Chief of the Defence Staff will oversee and drive AI-related activity across Defence\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e2nd PUS has specific responsibility for AI policy across Defence, including oversight of our ethical framework and responsibility for taking forward measures within the delegated model to ensure effective implementation\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003ethe Permanent Secretary (PUS) remains responsible for health, safety and environmental protection, supported by the Chief Operating Officer (COO) and the Director Health Safety \u0026amp; Environmental Protection\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e2nd PUS (and other senior officials as required) will be supported (in terms of policy development) by the Defence AI \u0026amp; Autonomy Unit (DAU), part of Defence Science \u0026amp; Technology (DST), and advised by the AI Ethics Advisory Panel. Scientific and technical advice will be provided by the MOD Chief Scientific Adviser (supported by DST and the Defence Science \u0026amp; Technology Laboratory (Dstl)) and the Chief Information Officer (supported by Defence Digital). Independent technical advice and review will be provided by the Defence Science Expert Committee (DSEC)\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003eTop Level Budget (TLB) dutyÂ holders and trading fund agency chief executives are senior duty holders for safety and are responsible for designating the duty holders in their organisation who manage activities which could be a risk to life. Each TLB organisation will have an accountable officer responsible for AI Ethics implementation\u003c/p\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e"
      }
    },
    {
      "@type": "Question",
      "name": "Implementation â€“ building justified trust",
      "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#implementation--building-justified-trust",
      "acceptedAnswer": {
        "@type": "Answer",
        "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#implementation--building-justified-trust",
        "text": "\u003cp\u003eHaving set out our overall approach to adopting AI ambitiously, safely and responsibly in this document, effective implementation will be critical. We must maximise the benefit we extract from AI while also demonstrating trustworthiness, both in terms of the breadth of our portfolio of AI-enabled tools and capabilities and the specifics of individual use cases. These two goals are linked. Ensuring our use of AI is safe, reliable and responsible doesnâ€™t impede innovation; itâ€™s key to collaboration and ensuring systems deliver the outcomes we need.\u003c/p\u003e\u003cp\u003eOur approach will therefore be:\u003c/p\u003e\u003cul\u003e\n  \u003cli\u003e\n    \u003cp\u003eoutward-facing: we will be transparent, engaging consistently with and welcoming challenge from industry, academia, civil society, international partners and allies;\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003eapplied across the entire AI system lifecycle: Defence teams will be able to articulate how a safe and responsible approach is being followed across an AI systemâ€™s full lifecycle, covering all Defence Lines of Development;\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003econtext-specific: the vast range of potential use cases for AI across Defence means that application of policy approaches cannot be uniform or technology-specific, but must take into consideration the particular requirements of each project.\u003c/p\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e"
      }
    },
    {
      "@type": "Question",
      "name": "Annex A: Ethical Principles for AI in Defence",
      "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#annex-a-ethical-principles-for-ai-in-defence",
      "acceptedAnswer": {
        "@type": "Answer",
        "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#annex-a-ethical-principles-for-ai-in-defence",
        "text": "\u003ch3 id=\"preamble-our-intent-for-the-ethical-use-of-ai-in-defence\"\u003ePreamble: Our intent for the ethical use of AI in Defence\u003c/h3\u003e\u003cp\u003eThe MOD is committed to developing and deploying AI-enabled systems responsibly, in ways that build trust and consensus, setting international standards for the ethical use of AI for Defence. The MOD will develop and deploy AI-enabled systems for purposes that are demonstrably beneficial: driving operational improvements, supporting the Defence Purpose, and upholding human rights and democratic values.\u003c/p\u003e\u003cp\u003eThe MODâ€™s existing obligations under UK law and international law, including as applicable international humanitarian law (IHL) and international human rights law, act as a foundation for Defenceâ€™s development, deployment and operation of AI-enabled systems. These ethical principles do not affect or supersede existing legal obligations. Instead, they set out an ethical framework which will guide Defenceâ€™s approach to adopting AI, in line with rigorous existing codes of conduct and regulations.\u003c/p\u003e\u003cp\u003eThese principles are applicable across the full spectrum of use cases for AI in Defence, from battlespace to back office, and across the entire lifecycle of these systems.\u003c/p\u003e\u003ch3 id=\"first-principle-human-centricity\"\u003eFirst principle: Human-Centricity\u003c/h3\u003e\u003cp\u003eThe impact of AI-enabled systems on humans must be assessed and considered, for a full range of effects both positive and negative across the entire system lifecycle.\u003c/p\u003e\u003cp\u003eWhether they are MOD personnel, civilians, or targets of military action, humans interacting with or affected by AI-enabled systems for Defence must be treated with respect. This means assessing and carefully considering the effects on humans of AI-enabled systems, taking full account of human diversity, and ensuring those effects are as positive as possible. These effects should prioritise human life and wellbeing, as well as wider concerns for human kind such as environmental impacts, while taking account of military necessity. This applies across all uses of AI-enabled systems, from the back office to the battlefield.\u003c/p\u003e\u003cp\u003eThe choice to develop and deploy AI systems is an ethical one, which must be taken with human implications in mind. It may be unethical to use certain systems where negative human impacts outweigh the benefits. Conversely, there may be a strong ethical case for the development and use of an AI system where it would be demonstrably beneficial or result in a more ethical outcome.\u003c/p\u003e\u003ch3 id=\"second-principle-responsibility\"\u003eSecond principle: Responsibility\u003c/h3\u003e\u003cp\u003eHuman responsibility for AI-enabled systems must be clearly established, ensuring accountability for their outcomes, with clearly defined means by which human control is exercised throughout their lifecycles.\u003c/p\u003e\u003cp\u003eThe increased speed, complexity and automation of AI-enabled systems may complicate our understanding of pre-existing concepts of human control, responsibility and accountability. This may occur through the sorting and filtering of information presented to decision-makers, the automation of previously human-led processes, or processes by which AI-enabled systems learn and evolve after their initial deployment. Nevertheless, as unique moral agents, humans must always be responsible for the ethical use of AI in Defence.\u003c/p\u003e\u003cp\u003eHuman responsibility for the use of AI-enabled systems in Defence must be underpinned by a clear and consistent articulation of the means by which human control is exercised, and the nature and limitations of that control. While the level of human control will vary according to the context and capabilities of each AI-enabled system, the ability to exercise human judgement over their outcomes is essential.\u003c/p\u003e\u003cp\u003eIrrespective of the use case, Responsibility for each element of an AI-enabled system, and an articulation of risk ownership, must be clearly defined from development, through deployment â€“ including redeployment in new contexts â€“ to decommissioning. This includes cases where systems are complex amalgamations of AI and non-AI components, from multiple different suppliers. In this way, certain aspects of responsibility may reach beyond the team deploying a particular system, to other functions within the MOD, or beyond, to the third parties which build or integrate AI-enabled systems for Defence.\u003c/p\u003e\u003cp\u003eCollectively, these articulations of human control, responsibility and risk ownership must enable clear accountability for the outcomes of any AI-enabled system in Defence. There must be no deployment or use without clear lines of responsibility and accountability, which should not be accepted by the designated duty holder unless they are satisfied that they can exercise control commensurate with the various risks.\u003c/p\u003e\u003ch3 id=\"third-principle-understanding\"\u003eThird principle: Understanding\u003c/h3\u003e\u003cp\u003eAI-enabled systems, and their outputs, must be appropriately understood by relevant individuals, with mechanisms to enable this understanding made an explicit part of system design.\u003c/p\u003e\u003cp\u003eEffective and ethical decision-making in Defence, from the frontline of combat to back-office operations, is always underpinned by appropriate understanding of context by those making decisions. Defence personnel must have an appropriate, context-specific understanding of the AI-enabled systems they operate and work alongside.\u003c/p\u003e\u003cp\u003eThis level of understanding will naturally differ depending on the knowledge required to act ethically in a given role and with a given system. It may include an understanding of the general characteristics, benefits and limitations of AI systems. It may require knowledge of a systemâ€™s purposes and correct environment for use, including scenarios where a system should not be deployed or used. It may also demand an understanding of system performance and potential fail states. Our people must be suitably trained and competent to operate or understand these tools.\u003c/p\u003e\u003cp\u003eTo enable this understanding, we must be able to verify that our AI-enabled systems work as intended. While the â€˜black boxâ€™ nature of some machine learning systems means that they are difficult to fully explain, we must be able to audit either the systems or their outputs to a level that satisfies those who are duly and formally responsible and accountable. Mechanisms to interpret and understand our systems must be a crucial and explicit part of system design across the entire lifecycle.\u003c/p\u003e\u003cp\u003eThis requirement for context-specific understanding based on technically understandable systems must also reach beyond the MOD, to commercial suppliers, allied forces and civilians. Whilst absolute transparency as to the workings of each AI-enabled system is neither desirable nor practicable, public consent and collaboration depend on context-specific shared understanding. What our systems do, how we intend to use them, and our processes for ensuring beneficial outcomes result from their use should be as transparent as possible, within the necessary constraints of the national security context.\u003c/p\u003e\u003ch3 id=\"fourth-principle-bias-and-harm-mitigation\"\u003eFourth principle: Bias and Harm Mitigation\u003c/h3\u003e\u003cp\u003eThose responsible for AI-enabled systems must proactively mitigate the risk of unexpected or unintended biases or harms resulting from these systems, whether through their original rollout, or as they learn, change or are redeployed.\u003c/p\u003e\u003cp\u003eAI-enabled systems offer significant benefits for Defence. However, the use of AI-enabled systems may also cause harms (beyond those already accepted under existing ethical and legal frameworks) to those using them or affected by their deployment. These may range from harms caused by a lack of suitable privacy for personal data, to unintended military harms due to system unpredictability. Such harms may change over time as systems learn and evolve, or as they are deployed beyond their original setting. Of particular concern is the risk of discriminatory outcomes resulting from algorithmic bias or skewed data sets. Defence must ensure that its AI-enabled systems do not result in unfair bias or discrimination, in line with the MODâ€™s ongoing strategies for diversity and inclusion.\u003c/p\u003e\u003cp\u003eA principle of bias and harm mitigation requires the assessment and, wherever possible, the mitigation of these biases or harms. This includes addressing bias in algorithmic decision-making, carefully curating and managing datasets, setting safeguards and performance thresholds throughout the system lifecycle, managing environmental effects, and applying strict development criteria for new systems, or existing systems being applied to a new context.\u003c/p\u003e\u003ch3 id=\"fifth-principle-reliability\"\u003eFifth principle: Reliability\u003c/h3\u003e\u003cp\u003eAI-enabled systems must be demonstrably reliable, robust and secure.\u003c/p\u003e\u003cp\u003eThe MODâ€™s AI-enabled systems must be suitably reliable; they must fulfil their intended design and deployment criteria and perform as expected, within acceptable performance parameters. Those parameters must be regularly reviewed and tested for reliability to be assured on an ongoing basis, particularly as AI-enabled systems learn and evolve over time, or are deployed in new contexts.\u003c/p\u003e\u003cp\u003eGiven Defenceâ€™s unique operational context and the challenges of the information environment, this principle also requires AI-enabled systems to be secure, and a robust approach to cybersecurity, data protection and privacy.\u003c/p\u003e\u003cp\u003eMOD personnel working with or alongside AI-enabled systems can build trust in those systems by ensuring that they have a suitable level of understanding of the performance and parameters of those systems, as articulated in the principle of understanding.\u003c/p\u003e"
      }
    },
    {
      "@type": "Question",
      "name": "Annex B: The Ministry of Defence AI Ethics Advisory Panel",
      "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#annex-b-the-ministry-of-defence-ai-ethics-advisory-panel",
      "acceptedAnswer": {
        "@type": "Answer",
        "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#annex-b-the-ministry-of-defence-ai-ethics-advisory-panel",
        "text": "\u003cp\u003eThe MOD AI Ethics Advisory panel is an informal advisory board to the 2nd Permanent Secretary for Defence in his role as senior responsible owner for AI Ethics in the department.\u003c/p\u003e\u003cp\u003eThe panelâ€™s purpose is to convene a combination of expert voices from Defence, academia, industry and civil society to advise the 2nd Permanent Secretary on the development of policy relating to safe and responsible development and use of AI.\u003c/p\u003e\u003cp\u003eThe panel is advisory only, and has no formal decision-making powers, but willÂ beÂ responsible for scrutinising the MODâ€™s ongoing approach to responsible and ethical AI. Panellists were appointed by the MOD on the basis of their expertise across the subjects of AI development, AI ethics, military ethics and international law.\u003c/p\u003e\u003cp\u003eAs of the date of publication, the current panel has met three times, and has served a key role in providing scrutiny and advice on the crafting of the ethical principles and potential methods of implementation. The panel has not been involved in the creation of policy related to Lethal Autonomous Weapons Systems, nor the departmentâ€™s policy on AI safety.\u003c/p\u003e\u003cp\u003eThe current panel membership is as follows:\u003c/p\u003e\u003cp\u003eLaurence Lee,Â 2ndÂ Permanent Secretary for Defence (Chair)\u003c/p\u003e\u003cp\u003eProfessor Dapo Akande, Director of the Oxford Institute for Ethics, Law and Armed Conflict\u003c/p\u003e\u003cp\u003eProfessor Nick Colosimo, Global Engineering Fellow \u0026amp; Technologist, BAE systemsÂ and Visiting Professor, Cranfield University (Centre for Autonomous \u0026amp; Cyber-Physical Systems).\u003c/p\u003e\u003cp\u003eDr Merel Ekelhof, Foreign Exchange OfficerÂ at the USÂ DoDÂ Joint AIÂ Center and formerÂ Lead Researcher on AI and Autonomy at UNIDIR,Â attending the panel in her personal capacity.\u003c/p\u003e\u003cp\u003eTabitha Goldstaub, Founder ofÂ CognitionXÂ and chair of the AI Council\u003c/p\u003e\u003cp\u003eDr Darrell Jaya-Ratnam, Managing Director, DIEM Analytics\u003c/p\u003e\u003cp\u003eProfessor Peter Lee, Professor of Applied Ethics, University of Portsmouth\u003c/p\u003e\u003cp\u003eProfessor Dame Angela McLean, Chief Scientific Advisor at the Ministry of Defence\u003c/p\u003e\u003cp\u003eRichard Moyes, Managing Director and co-founder, Article 36\u003c/p\u003e\u003cp\u003eProfessor Gopal Ramchurn, Director, UKRI Trustworthy Autonomous Systems Hub and the University of Southampton\u003c/p\u003e\u003cp\u003ePolly Scully, DirectorÂ for Strategy at the Ministry of Defence\u003c/p\u003e\u003cp\u003eProfessor Mariarosaria Taddeo, Associate Professor and Senior Research Fellow, Oxford Internet Institute, University of Oxford; Dstl Ethics Fellow, Alan Turing Institute.\u003c/p\u003e\u003cp\u003eLt GenÂ RolyÂ Walker, Deputy Chief of the Defence Staff for Military Strategy and Operations\u003c/p\u003e\u003cp\u003eProfessor David Whetham, Professor of Ethics and the Military Profession, Kings College London\u003c/p\u003e\u003cp\u003eDominic Wilson, Director General for Security Policy, Ministry of Defence\u003c/p\u003e"
      }
    },
    {
      "@type": "Question",
      "name": "ANNEX C: Lethal Autonomous Weapon Systems (LAWS)",
      "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#annex-c-lethal-autonomous-weapon-systems-laws",
      "acceptedAnswer": {
        "@type": "Answer",
        "url": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence#annex-c-lethal-autonomous-weapon-systems-laws",
        "text": "\u003cdiv class=\"call-to-action\"\u003e\n  \u003cp\u003eOne of the most significant concerns around the use of AI in Defence is around introducing elements of autonomy to the use of weapons systems. This subject has already been the source of significant international debate, particularly under the UNâ€™s Group of Government Experts on LAWS. The following section sets out the UKâ€™s position on this potential use case for AI-enabled systems.\u003c/p\u003e\n\n  \u003cp\u003eAI can enable systems â€“ including weapons â€“ to exhibit some measure of autonomy: deciding and acting to accomplish desired goals, within defined parameters, based on acquired knowledge and an evolving situational awareness. This potentially could lead to weapons that identify, select and attack targets without context-appropriate human involvement. That is not acceptable â€“ the United Kingdom does not possess fully autonomous weapon systems and has no intention of developing them.\u003c/p\u003e\n\n  \u003cp\u003eWe strongly believe that AI within weapon systems can and must be used lawfully and ethically. Sharing the concerns of Governments and AI experts around the world, we therefore oppose the creation and use of systems that would operate without meaningful and context-appropriate human involvement throughout their lifecycle. The use of such weapons could not satisfy fundamental principles of International Humanitarian Law, nor our own values and standards as expressed in our AI Ethical Principles. Human responsibility and accountability cannot be removed â€“ irrespective of the level of AI or autonomy in a system. The UK will always clearly establish authorities, thus human responsibility, and accountabilities whenever UK forces deploy weapon systems which incorporate AI.\u003c/p\u003e\n\n  \u003cp\u003eWe will continue to work closely with international allies and partners to address the opportunities and risks around autonomy in weapons systems. Global governance for such systems is a difficult task. It will be challenging to reach international agreement on definitions for full or partial autonomy on a technical or systems level. It is also important to ensure any approach allows for rapid technological advancement, and doesnâ€™t become redundant or isnâ€™t able to be circumvented as technology develops. Such international processes must be inclusive, and involve all key actors in this space if they are to be effective.\u003c/p\u003e\n\n  \u003cp\u003eWe believe the best approach is to focus on building norms of use and positive obligations to demonstrate how degrees of autonomy in weapons systems can be used in accordance with international humanitarian law â€“ with suitable levels of human control, accountability and responsibility. Setting out those characteristics that would make it inherently impossible for a system to comply with international humanitarian law is key to this, and we will continue to engage actively in the international arena to reach consensus on them. The UN Group of Government Experts on LAWS under the Convention for Certain Conventional Weapons will continue to be our primary avenue for such discussions. Our own approach, driven by the AI Ethical principles, is to build understanding, best practice and codes of conduct through which we can achieve ethical outcomes in our use of AI.\u003c/p\u003e\n\u003c/div\u003e\u003cdiv class=\"footnotes\" role=\"doc-endnotes\"\u003e\n  \u003col\u003e\n    \u003cli id=\"fn:1\" role=\"doc-endnote\"\u003e\n      \u003cp\u003eAndrew Ng: Why AI Is the New Electricity, \u003ca rel=\"external\" href=\"http://www.gsb.stanford.edu/insights/Andrew-ng-why-ai-new-electricity\" class=\"govuk-link\"\u003egsb.stanford.edu/insights/Andrew-ng-why-ai-new-electricity\u003c/a\u003eÂ \u003ca href=\"#fnref:1\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003eâ†©\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:2\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca rel=\"external\" href=\"https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/709359/20180517-concepts_uk_human_machine_teaming_jcn_1_18.pdf\" class=\"govuk-link\"\u003eJoint Concept Note 1/18 â€“ Human Machine Teaming\u003c/a\u003eÂ \u003ca href=\"#fnref:2\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003eâ†©\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:3\" role=\"doc-endnote\"\u003e\n      \u003cp\u003eFor an explanation of how these legal and our ethical principles apply to discussions around Lethal Autonomous Weapon Systems see Annex C.Â \u003ca href=\"#fnref:3\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003eâ†©\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:4\" role=\"doc-endnote\"\u003e\n      \u003cp\u003eFor an explanation of how these ethical principles and also the legal principles of International Humanitarian Law apply to discussions around Lethal Autonomous Weapon Systems, see Annex C.Â \u003ca href=\"#fnref:4\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003eâ†©\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:5\" role=\"doc-endnote\"\u003e\n      \u003cp\u003eOur joint methodology comprised desk and interview-based research exploring key issues, including the unique ethical challenges posed by AI in Defence. We deployed a range of methods to test and iterate the principles, including one-to-one and group interviews, roundtables and workshops with experts from across Defence, industry, academia, civil society, law, government and frontline military personnel. We also tested the principles against a range of hypothetical Defence AI use cases, and against a typical Defence AI system lifecycle. Further details on the process will be outlined in a joint MoD-CDEI report which we intend to publish in 2022.Â \u003ca href=\"#fnref:5\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003eâ†©\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n  \u003c/ol\u003e\n\u003c/div\u003e"
      }
    }
  ]
}
</script><script type="application/ld+json">
  {
  "@context": "http://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position": 1,
      "item": {
        "name": "Home",
        "@id": "https://www.gov.uk/"
      }
    },
    {
      "@type": "ListItem",
      "position": 2,
      "item": {
        "name": "Defence and armed forces",
        "@id": "https://www.gov.uk/defence-and-armed-forces"
      }
    },
    {
      "@type": "ListItem",
      "position": 3,
      "item": {
        "name": "Ambitious, safe, responsible: our approach to the delivery of AI-enabled capability in Defence",
        "@id": "https://www.gov.uk/government/publications/ambitious-safe-responsible-our-approach-to-the-delivery-of-ai-enabled-capability-in-defence"
      }
    }
  ]
}
</script>
</body>
</html>
