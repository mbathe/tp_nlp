<!DOCTYPE html>
<!--[if lt IE 9]><html class="lte-ie8 govuk-template" lang="en"><![endif]--><!--[if gt IE 8]><!--><html class="govuk-template" lang="en">
<!--<![endif]-->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta property="og:description" content="">
<meta property="og:title" content="Establishing a pro-innovation approach to regulating AI">
<meta property="og:url" content="https://www.gov.uk/government/publications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement">
<meta property="og:type" content="article">
<meta property="og:site_name" content="GOV.UK">
<meta name="twitter:card" content="summary">
<meta name="govuk:organisations" content="&lt;D1381&gt;&lt;OT1278&gt;&lt;D5&gt;&lt;D1198&gt;">
<meta name="govuk:ga4-publishing-government" content="2019 to 2022 Johnson Conservative government">
<meta name="govuk:ga4-political-status" content="historic">
<meta name="govuk:primary-publishing-organisation" content="Department for Science, Innovation and Technology">
<meta name="govuk:public-updated-at" content="2022-07-20T14:11:12+01:00">
<meta name="govuk:updated-at" content="2024-10-08T08:44:26+01:00">
<meta name="govuk:first-published-at" content="2022-07-18T10:30:05+01:00">
<meta name="govuk:content-id" content="7e26040b-629e-478f-9bf9-302da9d68685">
<meta name="govuk:schema-name" content="html_publication">
<meta name="govuk:rendering-app" content="government-frontend">
<meta name="govuk:publishing-app" content="whitehall">
<meta name="govuk:format" content="html_publication">
    <meta charset="utf-8">
    <title lang="en">
      Establishing a pro-innovation approach to regulating AI - GOV.UK
  </title>

    <script src="/assets/static/govuk_publishing_components/vendor/lux/lux-measurer-db6c8505a6690974922b8578eb1f2208d3073807f98d9a048efe9991f8dfc92d.js" async="async"></script>
    <script src="/assets/static/govuk_publishing_components/rum-loader-a65b10e18ceeba3bd8a2eac507c7f2c513cdc82f35097df903fdea87f1dc2e33.js" async="async" data-lux-reporter-script="/assets/static/govuk_publishing_components/vendor/lux/lux-reporter-41a67efb7d0fa046d3da8e9d207661e2b88f1b47260f803fa9da2d8167f18e5c.js"></script>

    <meta name="govuk:components_gem_version" content="44.0.0">
    <script src="/assets/static/govuk_publishing_components/load-analytics-da466517f0c7c6cbcaa54a0d645fd3ddae99ec7a77cf8d30fa7d98cdad81fec9.js" type="module"></script>

    

    <link rel="stylesheet" href="/assets/static/application-cc0ecde743cdf51832782158798b3883f7adb3c4a19e7f9efde97c6d68e74e89.css" media="all">
    <link rel="icon" sizes="48x48" href="/assets/static/favicon-f54816fc15997bd42cd90e4c50b896a1fc098c0c32957d4e5effbfa9f9b35e53.ico">
    <link rel="icon" sizes="any" href="/assets/static/favicon-50144c9d83e59584c45b249ad9e9abfdd23689876c33f28457df13bbdd9c8688.svg" type="image/svg+xml">
    <link rel="mask-icon" href="/assets/static/govuk-icon-mask-cdf4265165f8d7f9eec54aa2c1dfbb3d8b6d297c5d7919f0313e0836a5804bb6.svg" color="#0b0c0c">
    <link rel="apple-touch-icon" href="/assets/static/govuk-icon-180-d2d7399ff2ba05372b6b2018cc67053e458a748cceea1a550d804dbec401e3ed.png">

    <meta name="theme-color" content="#0b0c0c">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://www.gov.uk/assets/static/govuk-opengraph-image-03837e1cec82f217cf32514635a13c879b8c400ae3b1c207c5744411658c7635.png">

    
  <link rel="stylesheet" href="/assets/government-frontend/application-c357aabf79c6236777c898194d9ab6cc820429fa50731a1ad9185441b1a72cbb.css" media="all">
<link rel="canonical" href="https://www.gov.uk/government/publications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement">
<link rel="stylesheet" href="/assets/government-frontend/views/_html-publication-54225470c08fed56e0d5cc1185153e371967e24e1dc8639e2d8fad2b5cde4191.css">
<link rel="stylesheet" href="/assets/government-frontend/govuk_publishing_components/components/_organisation-logo-e50cf3b768494bc327ac55c6e79d98e63e828afe2099865f838f2b6a0ff0a86d.css">
<link rel="stylesheet" href="/assets/government-frontend/govuk_publishing_components/components/_inverse-header-3442c1a6bfce27a32679e8a05897b0d3c17a318e4a6f8d5f0ece82972818b176.css">
<link rel="stylesheet" href="/assets/government-frontend/govuk_publishing_components/components/_notice-ba5c9ca444a3fdf9d6107c30753707c5bdb724d62c2e103de8c50447bd655cad.css">
<link rel="stylesheet" href="/assets/government-frontend/govuk_publishing_components/components/_contents-list-61bcb99066ecefd96290d0112159064ee0c8f2e25891dca636a65d325bc7ebc0.css">
<link rel="stylesheet" href="/assets/government-frontend/govuk_publishing_components/components/_print-link-98446ac1b56886e6bd275df832312c44f45ede0264f8d8ecf98750450fb2c0d4.css">
<link rel="stylesheet" href="/assets/government-frontend/govuk_publishing_components/components/_govspeak-html-publication-f10529fb2cd130eab9e7974ad868351a3018ef733e38a1a8155bfb23d2484aa9.css">
<link rel="stylesheet" href="/assets/government-frontend/govuk_publishing_components/components/_govspeak-1fa5e58ce5e0ff477cd8fc42cc5d9cd1c272824fb8a794582341649deada91d0.css">
<link rel="stylesheet" href="/assets/government-frontend/components/_back-to-top-8d10a933dd34f1162faf988b7cf81c36c44ba29948683b0cdb2b654df304c32c.css">
<meta name="govuk:rendering-application" content="government-frontend">
</head>
  <body class="gem-c-layout-for-public govuk-template__body">
    <script nonce="dzhAn4qEyLpall3k5dxYdg==">
//<![CDATA[
      document.body.className += ' js-enabled' + ('noModule' in HTMLScriptElement.prototype ? ' govuk-frontend-supported' : '');

//]]>
</script>    
<div id="global-cookie-message" data-module="cookie-banner" data-nosnippet="" aria-label="Cookies on GOV.UK" class="gem-c-cookie-banner govuk-clearfix govuk-cookie-banner js-banner-wrapper" role="region" hidden="hidden">
  <div class="govuk-cookie-banner__message govuk-width-container">
    <div class="govuk-grid-row">
      <div class="govuk-grid-column-two-thirds">
        <h2 class="govuk-cookie-banner__heading govuk-heading-m">Cookies on GOV.UK</h2>
        <div tabindex="-1" class="govuk-cookie-banner__content gem-c-cookie-banner__confirmation">
          <span class="gem-c-cookie-banner__content"><p class="govuk-body">We use some essential cookies to make this website work.</p>
<p class="govuk-body">We’d like to set additional cookies to understand how you use GOV.UK, remember your settings and improve government services.</p>
<p class="govuk-body">We also use cookies set by other sites to help us deliver content from their services.</p></span>
          <p class="gem-c-cookie-banner__confirmation-message--accepted govuk-body" hidden data-ga4-cookie-banner data-module="ga4-link-tracker" data-ga4-track-links-only data-ga4-set-indexes data-ga4-link='{"event_name":"navigation","type":"cookie banner","section":"You have accepted additional cookies"}'>You have accepted additional cookies. <span class="gem-c-cookie-banner__confirmation-message">You can <a class="govuk-link" href="/help/cookies">change your cookie settings</a> at any time.</span></p>
          <p class="gem-c-cookie-banner__confirmation-message--rejected govuk-body" hidden>You have rejected additional cookies. <span class="gem-c-cookie-banner__confirmation-message">You can <a class="govuk-link" href="/help/cookies">change your cookie settings</a> at any time.</span></p>
        </div>
      </div>
    </div>
    <div class="js-confirmation-buttons govuk-button-group">
        


  <button class="gem-c-button govuk-button" type="submit" data-accept-cookies="true" data-cookie-types="all">Accept additional cookies</button>


        


  <button class="gem-c-button govuk-button" type="submit" data-reject-cookies="true">Reject additional cookies</button>


        <a class="govuk-link" href="/help/cookies">View cookies</a>
    </div>
    <div hidden class="js-hide-button govuk-button-group">
      <button class="gem-c-cookie-banner__hide-button govuk-button" data-hide-cookie-banner="true" data-module="ga4-event-tracker" data-ga4-event='{"event_name":"select_content","type":"cookie banner","action":"closed","section":"You have accepted additional cookies"}'>
          Hide this message
        </button>
    </div>
  </div>
</div>
    <a class="gem-c-skip-link govuk-skip-link govuk-!-display-none-print" data-module="govuk-skip-link" href="#content">Skip to main content</a>

          <header role="banner" class="gem-c-layout-super-navigation-header" data-module="ga4-event-tracker ga4-link-tracker" data-ga4-expandable="">
  <div class="gem-c-layout-super-navigation-header__container govuk-clearfix">
    <div class="govuk-width-container">
      <div class="gem-c-layout-super-navigation-header__header-logo">
        <a class="govuk-header__link govuk-header__link--homepage" data-ga4-link='{"event_name":"navigation","type":"header menu bar","external":"false","text":"GOV.UK","section":"Logo","index_link":1,"index_section":0,"index_section_count":2,"index_total":1}' id="logo" aria-label="Go to the GOV.UK homepage" href="https://www.gov.uk">
          
  <svg focusable="false" role="img" class="govuk-header__logotype" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 148 30" height="30" width="148" aria-label="GOV.UK">
  <title>GOV.UK</title>
  <path d="M22.6 10.4c-1 .4-2-.1-2.4-1-.4-.9.1-2 1-2.4.9-.4 2 .1 2.4 1s-.1 2-1 2.4m-5.9 6.7c-.9.4-2-.1-2.4-1-.4-.9.1-2 1-2.4.9-.4 2 .1 2.4 1s-.1 2-1 2.4m10.8-3.7c-1 .4-2-.1-2.4-1-.4-.9.1-2 1-2.4.9-.4 2 .1 2.4 1s0 2-1 2.4m3.3 4.8c-1 .4-2-.1-2.4-1-.4-.9.1-2 1-2.4.9-.4 2 .1 2.4 1s-.1 2-1 2.4M17 4.7l2.3 1.2V2.5l-2.3.7-.2-.2.9-3h-3.4l.9 3-.2.2c-.1.1-2.3-.7-2.3-.7v3.4L15 4.7c.1.1.1.2.2.2l-1.3 4c-.1.2-.1.4-.1.6 0 1.1.8 2 1.9 2.2h.7c1-.2 1.9-1.1 1.9-2.1 0-.2 0-.4-.1-.6l-1.3-4c-.1-.2 0-.2.1-.3m-7.6 5.7c.9.4 2-.1 2.4-1 .4-.9-.1-2-1-2.4-.9-.4-2 .1-2.4 1s0 2 1 2.4m-5 3c.9.4 2-.1 2.4-1 .4-.9-.1-2-1-2.4-.9-.4-2 .1-2.4 1s.1 2 1 2.4m-3.2 4.8c.9.4 2-.1 2.4-1 .4-.9-.1-2-1-2.4-.9-.4-2 .1-2.4 1s0 2 1 2.4m14.8 11c4.4 0 8.6.3 12.3.8 1.1-4.5 2.4-7 3.7-8.8l-2.5-.9c.2 1.3.3 1.9 0 2.7-.4-.4-.8-1.1-1.1-2.3l-1.2 4c.7-.5 1.3-.8 2-.9-1.1 2.5-2.6 3.1-3.5 3-1.1-.2-1.7-1.2-1.5-2.1.3-1.2 1.5-1.5 2.1-.1 1.1-2.3-.8-3-2-2.3 1.9-1.9 2.1-3.5.6-5.6-2.1 1.6-2.1 3.2-1.2 5.5-1.2-1.4-3.2-.6-2.5 1.6.9-1.4 2.1-.5 1.9.8-.2 1.1-1.7 2.1-3.5 1.9-2.7-.2-2.9-2.1-2.9-3.6.7-.1 1.9.5 2.9 1.9l.4-4.3c-1.1 1.1-2.1 1.4-3.2 1.4.4-1.2 2.1-3 2.1-3h-5.4s1.7 1.9 2.1 3c-1.1 0-2.1-.2-3.2-1.4l.4 4.3c1-1.4 2.2-2 2.9-1.9-.1 1.5-.2 3.4-2.9 3.6-1.9.2-3.4-.8-3.5-1.9-.2-1.3 1-2.2 1.9-.8.7-2.3-1.2-3-2.5-1.6.9-2.2.9-3.9-1.2-5.5-1.5 2-1.3 3.7.6 5.6-1.2-.7-3.1 0-2 2.3.6-1.4 1.8-1.1 2.1.1.2.9-.3 1.9-1.5 2.1-.9.2-2.4-.5-3.5-3 .6 0 1.2.3 2 .9l-1.2-4c-.3 1.1-.7 1.9-1.1 2.3-.3-.8-.2-1.4 0-2.7l-2.9.9C1.3 23 2.6 25.5 3.7 30c3.7-.5 7.9-.8 12.3-.8m28.3-11.6c0 .9.1 1.7.3 2.5.2.8.6 1.5 1 2.2.5.6 1 1.1 1.7 1.5.7.4 1.5.6 2.5.6.9 0 1.7-.1 2.3-.4s1.1-.7 1.5-1.1c.4-.4.6-.9.8-1.5.1-.5.2-1 .2-1.5v-.2h-5.3v-3.2h9.4V28H55v-2.5c-.3.4-.6.8-1 1.1-.4.3-.8.6-1.3.9-.5.2-1 .4-1.6.6s-1.2.2-1.8.2c-1.5 0-2.9-.3-4-.8-1.2-.6-2.2-1.3-3-2.3-.8-1-1.4-2.1-1.8-3.4-.3-1.4-.5-2.8-.5-4.3s.2-2.9.7-4.2c.5-1.3 1.1-2.4 2-3.4.9-1 1.9-1.7 3.1-2.3 1.2-.6 2.6-.8 4.1-.8 1 0 1.9.1 2.8.3.9.2 1.7.6 2.4 1s1.4.9 1.9 1.5c.6.6 1 1.3 1.4 2l-3.7 2.1c-.2-.4-.5-.9-.8-1.2-.3-.4-.6-.7-1-1-.4-.3-.8-.5-1.3-.7-.5-.2-1.1-.2-1.7-.2-1 0-1.8.2-2.5.6-.7.4-1.3.9-1.7 1.5-.5.6-.8 1.4-1 2.2-.3.8-.4 1.9-.4 2.7zM71.5 6.8c1.5 0 2.9.3 4.2.8 1.2.6 2.3 1.3 3.1 2.3.9 1 1.5 2.1 2 3.4s.7 2.7.7 4.2-.2 2.9-.7 4.2c-.4 1.3-1.1 2.4-2 3.4-.9 1-1.9 1.7-3.1 2.3-1.2.6-2.6.8-4.2.8s-2.9-.3-4.2-.8c-1.2-.6-2.3-1.3-3.1-2.3-.9-1-1.5-2.1-2-3.4-.4-1.3-.7-2.7-.7-4.2s.2-2.9.7-4.2c.4-1.3 1.1-2.4 2-3.4.9-1 1.9-1.7 3.1-2.3 1.2-.5 2.6-.8 4.2-.8zm0 17.6c.9 0 1.7-.2 2.4-.5s1.3-.8 1.7-1.4c.5-.6.8-1.3 1.1-2.2.2-.8.4-1.7.4-2.7v-.1c0-1-.1-1.9-.4-2.7-.2-.8-.6-1.6-1.1-2.2-.5-.6-1.1-1.1-1.7-1.4-.7-.3-1.5-.5-2.4-.5s-1.7.2-2.4.5-1.3.8-1.7 1.4c-.5.6-.8 1.3-1.1 2.2-.2.8-.4 1.7-.4 2.7v.1c0 1 .1 1.9.4 2.7.2.8.6 1.6 1.1 2.2.5.6 1.1 1.1 1.7 1.4.6.3 1.4.5 2.4.5zM88.9 28 83 7h4.7l4 15.7h.1l4-15.7h4.7l-5.9 21h-5.7zm28.8-3.6c.6 0 1.2-.1 1.7-.3.5-.2 1-.4 1.4-.8.4-.4.7-.8.9-1.4.2-.6.3-1.2.3-2v-13h4.1v13.6c0 1.2-.2 2.2-.6 3.1s-1 1.7-1.8 2.4c-.7.7-1.6 1.2-2.7 1.5-1 .4-2.2.5-3.4.5-1.2 0-2.4-.2-3.4-.5-1-.4-1.9-.9-2.7-1.5-.8-.7-1.3-1.5-1.8-2.4-.4-.9-.6-2-.6-3.1V6.9h4.2v13c0 .8.1 1.4.3 2 .2.6.5 1 .9 1.4.4.4.8.6 1.4.8.6.2 1.1.3 1.8.3zm13-17.4h4.2v9.1l7.4-9.1h5.2l-7.2 8.4L148 28h-4.9l-5.5-9.4-2.7 3V28h-4.2V7zm-27.6 16.1c-1.5 0-2.7 1.2-2.7 2.7s1.2 2.7 2.7 2.7 2.7-1.2 2.7-2.7-1.2-2.7-2.7-2.7z"></path>
</svg>


</a>
</div>    </div>
    <nav aria-labelledby="super-navigation-menu-heading" class="gem-c-layout-super-navigation-header__content govuk-!-display-none-print" data-module="super-navigation-mega-menu">
      <h2 id="super-navigation-menu-heading" class="govuk-visually-hidden">
        Navigation menu
      </h2>


      <div class="govuk-width-container gem-c-layout-super-navigation-header__button-width-container">
        <div class="gem-c-layout-super-navigation-header__button-container">
          <div class="gem-c-layout-super-navigation-header__navigation-item">
            <a class="gem-c-layout-super-navigation-header__navigation-item-link" href="/browse"><span class="gem-c-layout-super-navigation-header__navigation-item-link-inner">                Menu
</span></a>
            <button aria-controls="super-navigation-menu" aria-expanded="false" aria-label="Show navigation menu" class="gem-c-layout-super-navigation-header__navigation-top-toggle-button" data-text-for-hide="Hide navigation menu" data-text-for-show="Show navigation menu" data-toggle-desktop-group="top" data-toggle-mobile-group="top" data-tracking-key="menu" data-ga4-event='{"event_name":"select_content","type":"header menu bar","text":"Menu","index_section":1,"index_section_count":2,"section":"Menu"}' hidden="hidden" id="super-navigation-menu-toggle" type="button">
              <span class="gem-c-layout-super-navigation-header__navigation-top-toggle-button-inner">Menu</span>
</button>          </div>

          <div class="gem-c-layout-super-navigation-header__search-item">
            <button id="super-search-menu-toggle" class="gem-c-layout-super-navigation-header__search-toggle-button" aria-controls="super-search-menu" aria-expanded="true" aria-label="Hide search menu" data-text-for-hide="Hide search menu" data-text-for-show="Show search menu" data-toggle-mobile-group="top" data-toggle-desktop-group="top" data-tracking-key="search" data-ga4-event='{"event_name":"select_content","type":"header menu bar","text":"Search","index_section":2,"index_section_count":2,"section":"Search"}' hidden="hidden" type="button">
              <span class="govuk-visually-hidden">
                Search GOV.UK
              </span>
              
<svg class="gem-c-layout-super-navigation-header__search-toggle-button-link-icon" width="27" height="27" viewbox="0 0 27 27" fill="none" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false">
  <circle cx="12.0161" cy="11.0161" r="8.51613" stroke="currentColor" stroke-width="3"></circle>
  <line x1="17.8668" y1="17.3587" x2="26.4475" y2="25.9393" stroke="currentColor" stroke-width="3"></line>
</svg>
              <span aria-hidden="true" class="gem-c-layout-super-navigation-header__navigation-top-toggle-close-icon" focusable="false">
                ×
              </span>
</button>
            <a class="gem-c-layout-super-navigation-header__search-item-link" href="/search">
              <span class="govuk-visually-hidden">
                Search GOV.UK
              </span>
              
<svg class="gem-c-layout-super-navigation-header__search-item-link-icon" width="27" height="27" viewbox="0 0 27 27" fill="none" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false">
  <circle cx="12.0161" cy="11.0161" r="8.51613" stroke="currentColor" stroke-width="3"></circle>
  <line x1="17.8668" y1="17.3587" x2="26.4475" y2="25.9393" stroke="currentColor" stroke-width="3"></line>
</svg>
</a>          </div>
</div>      </div>

      <div id="super-navigation-menu" hidden="hidden" class="gem-c-layout-super-navigation-header__navigation-dropdown-menu">
        <div class="govuk-width-container">
          <div class="govuk-grid-row gem-c-layout-super-navigation-header__navigation-items">


              <div class="govuk-grid-column-two-thirds-from-desktop gem-c-layout-super-navigation-header__column--services-and-information">
                <h3 class="govuk-heading-m gem-c-layout-super-navigation-header__column-header">
                  Services and information
                </h3>
                <ul class="gem-c-layout-super-navigation-header__navigation-second-items gem-c-layout-super-navigation-header__navigation-second-items--services-and-information">
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":1,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/benefits">Benefits</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":2,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/births-deaths-marriages">Births, death, marriages and care</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":3,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/business">Business and self-employed</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":4,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/childcare-parenting">Childcare and parenting</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":5,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/citizenship">Citizenship and living in the UK</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":6,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/justice">Crime, justice and the law</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":7,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/disabilities">Disabled people</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":8,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/driving">Driving and transport</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":9,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/education">Education and learning</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":10,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/employing-people">Employing people</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":11,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/environment-countryside">Environment and countryside</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":12,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/housing-local-services">Housing and local services</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":13,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/tax">Money and tax</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":14,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/abroad">Passports, travel and living abroad</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":15,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/visas-immigration">Visas and immigration</a>
                        
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":1,"index_link":16,"index_section_count":3,"index_total":16,"section":"Services and information"}' href="https://www.gov.uk/browse/working">Working, jobs and pensions</a>
                        
                      </li>
                </ul>
              </div>

              <div class="govuk-grid-column-one-third-from-desktop gem-c-layout-super-navigation-header__column--government-activity">
                <h3 class="govuk-heading-m gem-c-layout-super-navigation-header__column-header">
                  Government activity
                </h3>
                <ul class="gem-c-layout-super-navigation-header__navigation-second-items gem-c-layout-super-navigation-header__navigation-second-items--government-activity">
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link gem-c-layout-super-navigation-header__navigation-second-item-link--with-description" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":2,"index_link":1,"index_section_count":3,"index_total":6,"section":"Government activity"}' href="https://www.gov.uk/government/organisations">Departments</a>
                        <p class="gem-c-layout-super-navigation-header__navigation-second-item-description">Departments, agencies and public bodies</p>
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link gem-c-layout-super-navigation-header__navigation-second-item-link--with-description" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":2,"index_link":2,"index_section_count":3,"index_total":6,"section":"Government activity"}' href="https://www.gov.uk/search/news-and-communications">News</a>
                        <p class="gem-c-layout-super-navigation-header__navigation-second-item-description">News stories, speeches, letters and notices</p>
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link gem-c-layout-super-navigation-header__navigation-second-item-link--with-description" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":2,"index_link":3,"index_section_count":3,"index_total":6,"section":"Government activity"}' href="https://www.gov.uk/search/guidance-and-regulation">Guidance and regulation</a>
                        <p class="gem-c-layout-super-navigation-header__navigation-second-item-description">Detailed guidance, regulations and rules</p>
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link gem-c-layout-super-navigation-header__navigation-second-item-link--with-description" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":2,"index_link":4,"index_section_count":3,"index_total":6,"section":"Government activity"}' href="https://www.gov.uk/search/research-and-statistics">Research and statistics</a>
                        <p class="gem-c-layout-super-navigation-header__navigation-second-item-description">Reports, analysis and official statistics</p>
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link gem-c-layout-super-navigation-header__navigation-second-item-link--with-description" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":2,"index_link":5,"index_section_count":3,"index_total":6,"section":"Government activity"}' href="https://www.gov.uk/search/policy-papers-and-consultations">Policy papers and consultations</a>
                        <p class="gem-c-layout-super-navigation-header__navigation-second-item-description">Consultations and strategy</p>
                      </li>
                      <li class="gem-c-layout-super-navigation-header__dropdown-list-item">
                        <a class="govuk-link gem-c-layout-super-navigation-header__navigation-second-item-link gem-c-layout-super-navigation-header__navigation-second-item-link--with-description" data-ga4-link='{"event_name":"navigation","type":"header menu bar","index_section":2,"index_link":6,"index_section_count":3,"index_total":6,"section":"Government activity"}' href="https://www.gov.uk/search/transparency-and-freedom-of-information-releases">Transparency</a>
                        <p class="gem-c-layout-super-navigation-header__navigation-second-item-description">Data, Freedom of Information releases and corporate reports</p>
                      </li>
                </ul>
              </div>
          </div>
        </div>
</div>
      <div id="super-search-menu" hidden="hidden" class="gem-c-layout-super-navigation-header__navigation-dropdown-menu">
        <div class="govuk-width-container gem-c-layout-super-navigation-header__search-container gem-c-layout-super-navigation-header__search-items">
          <h3 class="govuk-visually-hidden">
            Search
          </h3>
          <div class="govuk-grid-row">
            <div class="govuk-grid-column-full">
              <form class="gem-c-layout-super-navigation-header__search-form" id="search" data-module="ga4-form-tracker" data-ga4-form='{"event_name":"search","type":"header menu bar","section":"Search GOV.UK","action":"search","url":"/search/all","index_section":3,"index_section_count":3}' data-ga4-form-include-text data-ga4-form-no-answer-undefined action="https://www.gov.uk/search" method="get" role="search" aria-label="Site-wide">
                <div class="gem-c-search govuk-!-display-none-print  govuk-!-margin-bottom-0 gem-c-search--large gem-c-search--on-white gem-c-search--separate-label" data-module="gem-toggle-input-class-on-focus">
    <label for="search-main-6bf89ef6" class="govuk-label govuk-label--m gem-c-layout-super-navigation-header__search-label--large-navbar">Search GOV.UK</label>
  <div class="gem-c-search__item-wrapper">
    <div class="js-search-input-wrapper">
      <input enterkeyhint="search" class="gem-c-search__item gem-c-search__input js-class-toggle" id="search-main-6bf89ef6" name="q" title="Search" type="search" value="" autocorrect="off" autocapitalize="off">
    </div>
    <div class="gem-c-search__item gem-c-search__submit-wrapper">
      <button class="gem-c-search__submit" type="submit" enterkeyhint="search">
        Search
        
<svg class="gem-c-search__icon" width="27" height="27" viewbox="0 0 27 27" fill="none" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false">
  <circle cx="12.0161" cy="11.0161" r="8.51613" stroke="currentColor" stroke-width="3"></circle>
  <line x1="17.8668" y1="17.3587" x2="26.4475" y2="25.9393" stroke="currentColor" stroke-width="3"></line>
</svg>
</button>    </div>
  </div>
</div>

              </form>
            </div>
          </div>
        </div>
</div>    </nav>
  </div>
</header>

    

      <div class="">
        <div class="gem-c-layout-for-public__blue-bar govuk-width-container"></div>
</div>

      <div id="wrapper" class="direction-ltr govuk-width-container">

        
<div class="gem-c-contextual-breadcrumbs">
    <div class="govuk-!-display-none-print">
      


<nav data-module="ga4-link-tracker" aria-label="Breadcrumb" class="gem-c-breadcrumbs govuk-breadcrumbs govuk-breadcrumbs--collapse-on-mobile">
  <ol class="govuk-breadcrumbs__list">
        <li class="govuk-breadcrumbs__list-item">
          <a data-ga4-link='{"event_name":"navigation","type":"breadcrumb","index_link":"1","index_total":"5"}' class="govuk-breadcrumbs__link" href="/">Home</a>
        </li>
        <li class="govuk-breadcrumbs__list-item">
          <a data-ga4-link='{"event_name":"navigation","type":"breadcrumb","index_link":"2","index_total":"5"}' class="govuk-breadcrumbs__link" href="/business-and-industry">Business and industry</a>
        </li>
        <li class="govuk-breadcrumbs__list-item">
          <a data-ga4-link='{"event_name":"navigation","type":"breadcrumb","index_link":"3","index_total":"5"}' class="govuk-breadcrumbs__link" href="/business-and-industry/science-and-innovation">Science and innovation</a>
        </li>
        <li class="govuk-breadcrumbs__list-item">
          <a data-ga4-link='{"event_name":"navigation","type":"breadcrumb","index_link":"4","index_total":"5"}' class="govuk-breadcrumbs__link" href="/business-and-industry/artificial-intelligence">Artificial intelligence</a>
        </li>
        <li class="govuk-breadcrumbs__list-item">
          <a data-ga4-link='{"event_name":"navigation","type":"breadcrumb","index_link":"5","index_total":"5"}' class="govuk-breadcrumbs__link" href="/government/publications/establishing-a-pro-innovation-approach-to-regulating-ai">Establishing a pro-innovation approach to regulating AI</a>
        </li>
  </ol>
</nav>
    </div>
</div>


    

    <main role="main" id="content" class="html-publication" lang="en">
      <span id="Top"></span>
          

  <div class="publication-external">
    <ul class="organisation-logos">
        <li class="organisation-logos__logo">
          
<div class="gem-c-organisation-logo brand--department-for-science-innovation-and-technology">
    <a class="gem-c-organisation-logo__container gem-c-organisation-logo__link gem-c-organisation-logo__crest gem-c-organisation-logo__crest--single-identity brand__border-color" href="/government/organisations/department-for-science-innovation-and-technology">
      <span class="gem-c-organisation-logo__name">Department for<br>Science, Innovation<br>&amp; Technology</span>
</a>
</div>
        </li>
        <li class="organisation-logos__logo">
          
<div class="gem-c-organisation-logo brand--cabinet-office">
    <a class="gem-c-organisation-logo__container gem-c-organisation-logo__link gem-c-organisation-logo__crest gem-c-organisation-logo__crest--single-identity brand__border-color" href="/government/organisations/office-for-artificial-intelligence">
      <span class="gem-c-organisation-logo__name">Office for Artificial Intelligence</span>
</a>
</div>
        </li>
        <li class="organisation-logos__logo">
          
<div class="gem-c-organisation-logo brand--department-for-culture-media-sport">
    <a class="gem-c-organisation-logo__container gem-c-organisation-logo__link gem-c-organisation-logo__crest gem-c-organisation-logo__crest--single-identity brand__border-color" href="/government/organisations/department-for-digital-culture-media-sport">
      <span class="gem-c-organisation-logo__name">Department for<br>Digital, Culture,<br>Media &amp; Sport</span>
</a>
</div>
        </li>
        <li class="organisation-logos__logo">
          
<div class="gem-c-organisation-logo brand--department-for-business-innovation-skills">
    <a class="gem-c-organisation-logo__container gem-c-organisation-logo__link gem-c-organisation-logo__crest gem-c-organisation-logo__crest--single-identity brand__border-color" href="/government/organisations/department-for-business-energy-and-industrial-strategy">
      <span class="gem-c-organisation-logo__name">Department for<br>Business, Energy<br>&amp; Industrial Strategy</span>
</a>
</div>
        </li>
    </ul>
  </div>

  <header class="gem-c-inverse-header  gem-c-inverse-header--padding-top ">
    
  

<div class="gem-c-title gem-c-title--inverse govuk-!-margin-top-3 govuk-!-margin-bottom-0">
      <span class="govuk-caption-xl gem-c-title__context">
    Policy paper
  </span>


  <h1 class="gem-c-title__text govuk-heading-xl">
    Establishing a pro-innovation approach to regulating AI
  </h1>
</div>
  <p class="publication-header__last-changed">Updated 20 July 2022</p>

  </header>

    <section class="govuk-notification-banner gem-c-notice govuk-!-margin-bottom-8" aria-label="Notice" role="region">
        <div class="govuk-notification-banner__content">
      
      <span class="gem-c-notice__title govuk-notification-banner__heading">This was published under the <span lang="en" dir="ltr">2019 to 2022 Johnson Conservative government</span></span>
      

      
</div></section>


<div id="contents">
  <div class="govuk-grid-row gem-print-columns-none">
      <div class="govuk-grid-column-one-quarter-from-desktop contents-list-container">
          <nav data-module="ga4-link-tracker" aria-label="Contents" class="gem-c-contents-list" role="navigation">
    <h2 class="gem-c-contents-list__title">
      Contents
</h2>
    <ol class="gem-c-contents-list__list">
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <span aria-hidden="true"></span>
          <a class="gem-c-contents-list__link govuk-link gem-print-link govuk-link--no-underline" data-ga4-link='{"event_name":"select_content","section":"Contents","type":"contents list","index_total":9,"index_link":1}' href="#ministerial-foreword-by-the-secretary-of-state-for-digital-culture-media-and-sport">Ministerial foreword by the Secretary of State for Digital, Culture, Media and Sport</a>
        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <span aria-hidden="true"></span>
          <a class="gem-c-contents-list__link govuk-link gem-print-link govuk-link--no-underline" data-ga4-link='{"event_name":"select_content","section":"Contents","type":"contents list","index_total":9,"index_link":2}' href="#ministerial-foreword-by-the-secretary-of-state-for-business-energy-and-industrial-strategy">Ministerial foreword by the Secretary of State for Business, Energy and Industrial Strategy</a>
        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <span aria-hidden="true"></span>
          <a class="gem-c-contents-list__link govuk-link gem-print-link govuk-link--no-underline" data-ga4-link='{"event_name":"select_content","section":"Contents","type":"contents list","index_total":9,"index_link":3}' href="#executive-summary">Executive summary</a>
        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <span aria-hidden="true"></span>
          <a class="gem-c-contents-list__link govuk-link gem-print-link govuk-link--no-underline" data-ga4-link='{"event_name":"select_content","section":"Contents","type":"contents list","index_total":9,"index_link":4}' href="#context">Context</a>
        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <span aria-hidden="true"></span>
          <a class="gem-c-contents-list__link govuk-link gem-print-link govuk-link--no-underline" data-ga4-link='{"event_name":"select_content","section":"Contents","type":"contents list","index_total":9,"index_link":5}' href="#the-scope">The scope</a>
        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <span aria-hidden="true"></span>
          <a class="gem-c-contents-list__link govuk-link gem-print-link govuk-link--no-underline" data-ga4-link='{"event_name":"select_content","section":"Contents","type":"contents list","index_total":9,"index_link":6}' href="#a-new-pro-innovation-approach">A new pro-innovation approach</a>
        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <span aria-hidden="true"></span>
          <a class="gem-c-contents-list__link govuk-link gem-print-link govuk-link--no-underline" data-ga4-link='{"event_name":"select_content","section":"Contents","type":"contents list","index_total":9,"index_link":7}' href="#putting-our-approach-into-practice">Putting our approach into practice</a>
        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <span aria-hidden="true"></span>
          <a class="gem-c-contents-list__link govuk-link gem-print-link govuk-link--no-underline" data-ga4-link='{"event_name":"select_content","section":"Contents","type":"contents list","index_total":9,"index_link":8}' href="#next-steps">Next steps</a>
        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <span aria-hidden="true"></span>
          <a class="gem-c-contents-list__link govuk-link gem-print-link govuk-link--no-underline" data-ga4-link='{"event_name":"select_content","section":"Contents","type":"contents list","index_total":9,"index_link":9}' href="#share-your-views">Share your views</a>
        </li>
    </ol>
</nav>

        
<div class="gem-c-print-link govuk-!-display-none-print govuk-!-margin-top-0 govuk-!-margin-bottom-6">
    <button class="govuk-link govuk-body-s gem-c-print-link__button" data-module="print-link">Print this page</button>
</div>
      </div>

    <div class="print-wrapper">
      <div class="meta-data meta-data--display-print">
        <p>
  <img class="meta-data-licence" src="/assets/government-frontend/open-government-licence-min-93b6a51b518ff99714a1aa2a7d2162735c155ec3cb073c75fb88b2a332fa83d3.png">
</p>
<p>
  © Crown copyright 2022
</p>
<p>
  This publication is licensed under the terms of the Open Government Licence v3.0 except where otherwise stated. To view this licence, visit <a href="https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3">nationalarchives.gov.uk/doc/open-government-licence/version/3</a> or write to the Information Policy Team, The National Archives, Kew, London TW9 4DU, or email: <a href="mailto:psi@nationalarchives.gov.uk">psi@nationalarchives.gov.uk</a>.
</p>
<p>
  Where we have identified any third party copyright information you will need to obtain permission from the copyright holders concerned.
</p>
<p>
  This publication is available at https://www.gov.uk/government/publications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement
</p>


      </div>
    </div>

    <div class="govuk-grid-column-three-quarters-from-desktop contents-container">
      <div class="gem-c-govspeak-html-publication">
  
<div class="gem-c-govspeak govuk-govspeak direction-ltr" data-module="govspeak">
    
    
        <div class="govspeak">
<p>Presented to Parliament by the Secretary of State for Digital, Culture, Media and Sport by Command of Her Majesty. Laid on Monday 18 July 2022.</p>

<p>Command Paper: CP 728</p>

<p>© Crown copyright 2022</p>

<p>ISBN: 978-1-5286-3639-1</p>

<figure class="image embedded"><div class="img"><img src="https://assets.publishing.service.gov.uk/media/62d53e20d3bf7f285c94b2d9/National_AI_Reg_1.jpg" alt="Policy Paper"></div></figure>

<h2 id="ministerial-foreword-by-the-secretary-of-state-for-digital-culture-media-and-sport">Ministerial foreword by the Secretary of State for Digital, Culture, Media and Sport</h2>

<figure class="image embedded"><div class="img"><img src="https://assets.publishing.service.gov.uk/media/62d7e2edd3bf7f2861b893fc/Nadine_Dorries.jpg" alt=""></div></figure>

<p>Across the world, AI is unlocking enormous opportunities, and the UK is at the forefront of these developments. As Secretary of State for the Department of Digital, Culture, Media and Sport, I want the UK to be the best place in the world to found and grow an AI business and to strengthen the UK’s position so we translate AI’s tremendous potential into growth and societal benefits across the UK.</p>

<p>Our regulatory approach will be a key tool in reaching this ambition. A regulatory framework that is proportionate, light-touch and forward-looking is essential to keep pace with the speed of developments in these technologies. Such an approach will drive innovation by offering businesses the clarity and confidence they need to grow while making sure we boost public trust.</p>

<p>Getting this right is necessary for a thriving AI ecosystem and will be a source of international competitive advantage. We will continue to advocate internationally for our vision for a pro-innovation approach to AI regulation recognising that both the opportunities and challenges presented by AI are fundamentally global in nature.</p>

<p>I am therefore pleased to publish this paper which sets out our emerging thinking on our approach to regulating AI. We welcome views on our proposals from across business, civil society, academia and beyond ahead of publishing a White Paper later in the year.<br><br><br></p>

<p><a href="https://www.gov.uk/government/people/nadine-dorries" class="govuk-link"><strong>Rt Hon Nadine Dorries MP</strong></a>
<br>
Secretary of State for Digital, Culture, Media and Sport</p>

<h2 id="ministerial-foreword-by-the-secretary-of-state-for-business-energy-and-industrial-strategy">Ministerial foreword by the Secretary of State for Business, Energy and Industrial Strategy</h2>

<figure class="image embedded"><div class="img"><img src="https://assets.publishing.service.gov.uk/media/62d7e2eee90e071e7a074972/KK.jpg" alt=""></div></figure>

<p>The UK is already a global superpower in many aspects of AI, from our world-leading academic institutions, to a well-established business environment that supports AI businesses of all sizes. AI is catalysing innovation across sectors from healthcare to agriculture, and is driving forward new research, scientific breakthroughs, and growth across the nation.</p>

<p>But we must not be complacent. It is essential that we maximise the full opportunities which AI can bring to the UK, including by meeting our target of total R&amp;D investment in the UK reaching 2.4% of GDP by 2027. We must achieve this while ensuring that we can build consumer, citizen and investor confidence in our regulatory framework for the ethical and responsible use of AI in our society and economy.</p>

<p>Our ambition is to support responsible innovation in AI - unleashing the full potential of new technologies, while keeping people safe and secure. This policy paper sets out how the government intends to strike this balance: by developing a pro-innovation, light-touch and coherent regulatory framework, which creates clarity for businesses and drives new investment. We want this framework to be adaptable to AI’s vast range of uses across different industries, and support our world-class regulators in addressing new challenges in a way that catalyses innovation and growth.</p>

<p>We welcome views from AI practitioners and disruptors across the business landscape so that we can take full advantage of AI’s revolutionary potential and continue driving global leadership on AI regulation.<br><br><br></p>

<p><a href="https://www.gov.uk/government/people/kwasi-kwarteng" class="govuk-link"><strong>Rt Hon Kwasi Kwarteng MP</strong></a>
<br>
Secretary of State for Business, Energy and Industrial Strategy</p>

<h2 id="executive-summary">Executive summary</h2>

<p>In the <a href="https://www.gov.uk/government/publications/national-ai-strategy" class="govuk-link">National AI Strategy</a>, the government set out an ambitious ten-year plan for the UK to remain a global AI superpower. The UK is already a leader in many aspects of AI, with a thriving ecosystem and a strong track record of innovation. But there is more to do to harness the enormous economic and societal benefits of AI while also addressing the complex challenges it presents.</p>

<p>Establishing clear, innovation-friendly and flexible approaches to regulating AI will be core to achieving our ambition to unleash growth and innovation while safeguarding our fundamental values and keeping people safe and secure. Our approach will drive business confidence, promote investment, boost public trust and ultimately drive productivity across the economy.</p>

<p>The UK has a world leading regulatory regime - known for its effective rule of law and support for innovation. We need to make sure that our regulatory regime is able to keep pace with and respond to the new and distinct challenges and opportunities posed by AI. This is key to remaining internationally competitive.</p>

<p>We are therefore proposing to establish a pro-innovation framework for regulating AI which is underpinned by a set of cross-sectoral principles tailored to the specific characteristics of AI, and is:</p>

<ul>
  <li>
<strong>Context-specific.</strong> We propose to regulate AI based on its use and the impact it has on individuals, groups and businesses within a particular context, and to delegate responsibility for designing and implementing proportionate regulatory responses to regulators. This will ensure that our approach is targeted and supports innovation.</li>
  <li>
<strong>Pro-innovation and risk-based.</strong> We propose to focus on addressing issues where there is clear evidence of real risk or missed opportunities. We will ask that regulators focus on high risk concerns rather than hypothetical or low risks associated with AI. We want to encourage innovation and avoid placing unnecessary barriers in its way.</li>
  <li>
<strong>Coherent.</strong> We propose to establish a set of cross-sectoral principles tailored to the distinct characteristics of AI, with regulators asked to interpret, prioritise and implement these principles within their sectors and domains. In order to achieve coherence and support innovation by making the framework as easy as possible to navigate, we will look for ways to support and encourage regulatory coordination - for example, by working closely with the Digital Regulation Cooperation Forum (DRCF) and other regulators and stakeholders.</li>
  <li>
<strong>Proportionate and adaptable.</strong> We propose to set out the cross-sectoral principles on a non-statutory basis in the first instance so our approach remains adaptable - although we will keep this under review. We will ask that regulators consider lighter touch options, such as guidance or voluntary measures, in the first instance. As far as possible, we will also seek to work with existing processes rather than create new ones.</li>
</ul>

<p>The approach outlined above is aligned with the regulatory principles set out in the Better Regulation Framework, which emphasise proportionate regulation. It is also aligned with the government’s vision set out through the Plan for Digital Regulation. It describes how we will take a pro-innovation approach to regulating digital technologies, which will deliver on the UK’s desire to establish a more nimble regulatory framework now that we have left the EU.</p>

<p>We recognise the cross-border nature of the digital ecosystem and the importance of the international AI market, and will continue to work closely with key partners on the global stage to shape global approaches to AI regulation. We will support cooperation on key issues, including through the Council of Europe, OECD working groups and the Global Partnership on AI and through global standards bodies such as ISO and IEC.</p>

<p><strong>We welcome stakeholders’ views on our proposed approach to regulating AI.</strong> Ahead of setting out further detail on our framework and implementation plans through the forthcoming White Paper, we are keen to seek reflections from across the AI ecosystem, wider industry, civil society, academia and beyond on the approach set out here to inform how we best shape the rules that will form part of the wider approach to how we regulate AI.</p>

<h2 id="context">Context</h2>

<p>The UK has a thriving AI ecosystem. In 2021, the UK was first in Europe and third in the world for private investment in AI companies ($4.65 billion) and newly funded AI companies (49).<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="govuk-link" rel="footnote">[footnote 1]</a></sup> The UK is also first in Europe for the number of AI publications in 2021, and only topped by China, the USA and India.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="govuk-link" rel="footnote">[footnote 2]</a></sup></p>

<p>AI is unlocking huge benefits across our economy and society. In Glasgow AI is being used to track asbestos cancer tumours,<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="govuk-link" rel="footnote">[footnote 3]</a></sup> in the Southeast to help people facing fuel poverty,<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="govuk-link" rel="footnote">[footnote 4]</a></sup> in Belfast to improve animal welfare on dairy farms,<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="govuk-link" rel="footnote">[footnote 5]</a></sup> and across the country by HM Land Registry to compare property transfer deeds.<sup id="fnref:6" role="doc-noteref"><a href="#fn:6" class="govuk-link" rel="footnote">[footnote 6]</a></sup> AI is also being applied to fundamental challenges in biology that will revolutionise drug discovery,<sup id="fnref:7" role="doc-noteref"><a href="#fn:7" class="govuk-link" rel="footnote">[footnote 7]</a></sup> and is set to impact the future of mobility<sup id="fnref:8" role="doc-noteref"><a href="#fn:8" class="govuk-link" rel="footnote">[footnote 8]</a></sup> and an accelerated reduction in emissions.<sup id="fnref:9" role="doc-noteref"><a href="#fn:9" class="govuk-link" rel="footnote">[footnote 9]</a></sup></p>

<p>Alongside the benefits that AI brings, it also creates a range of new and accelerated risks, such as those associated with the use of AI in critical infrastructure to algorithmic bias. It also presents new questions for governments and society; for example, how should we protect existing rights in the context of systems that use facial recognition, or from large language models trained on content harvested from the web? How do we ensure commercial customers can confidently buy ‘off the shelf’ systems that are evidenced, tested and robust?</p>

<p>The answer to these questions will ultimately rely on actions by governments, regulators, technical standards bodies<sup id="fnref:10" role="doc-noteref"><a href="#fn:10" class="govuk-link" rel="footnote">[footnote 10]</a></sup> and industry. Together these form an overall approach to AI regulation.<sup id="fnref:11" role="doc-noteref"><a href="#fn:11" class="govuk-link" rel="footnote">[footnote 11]</a></sup></p>

<h3 id="overview-of-the-existing-regulatory-landscape">Overview of the existing regulatory landscape</h3>

<p>The success of our AI ecosystem is in part down to the UK’s reputation for the quality of its regulators and its rule of law. This includes the transparency of the UK’s regulatory regime, the detailed scrutiny that proposed regulation receives and comprehensive impact assessments. This certainty around how new regulation will evolve has promoted private investment in the UK for developing new technologies and has allowed AI innovation to thrive.<sup id="fnref:12" role="doc-noteref"><a href="#fn:12" class="govuk-link" rel="footnote">[footnote 12]</a></sup>,<sup id="fnref:13" role="doc-noteref"><a href="#fn:13" class="govuk-link" rel="footnote">[footnote 13]</a></sup> To maintain our leading regulatory approach, we must make sure that the rules that govern the development and use of AI keep pace with the evolving implications of the technologies.</p>

<p>While there are no UK laws that were explicitly written to regulate AI, it is partially regulated through a patchwork of legal and regulatory requirements built for other purposes which now also capture uses of AI technologies. For example,<sup id="fnref:14" role="doc-noteref"><a href="#fn:14" class="govuk-link" rel="footnote">[footnote 14]</a></sup> UK data protection law includes specific requirements around ‘automated decision-making’ and the broader processing of personal data,<sup id="fnref:15" role="doc-noteref"><a href="#fn:15" class="govuk-link" rel="footnote">[footnote 15]</a></sup> which also covers processing for the purpose of developing and training AI technologies. The upcoming Online Safety Bill also has provisions specifically concerning the design and use of algorithms.</p>

<p>Some UK regulators are also starting to take action to support the responsible use of AI. For example:</p>

<ul>
  <li>the Information Commissioner’s Office (ICO) has issued multiple pieces of guidance, such as Guidance on AI and Data Protection<sup id="fnref:16" role="doc-noteref"><a href="#fn:16" class="govuk-link" rel="footnote">[footnote 16]</a></sup>, Explaining decisions made with AI,<sup id="fnref:17" role="doc-noteref"><a href="#fn:17" class="govuk-link" rel="footnote">[footnote 17]</a></sup>AI and Data Protection Risk Toolkit,<sup id="fnref:18" role="doc-noteref"><a href="#fn:18" class="govuk-link" rel="footnote">[footnote 18]</a></sup> AI Auditing Framework and AI blog resources<sup id="fnref:19" role="doc-noteref"><a href="#fn:19" class="govuk-link" rel="footnote">[footnote 19]</a></sup>
</li>
  <li>the Equality and Human Rights Commission has identified AI as a strategic priority in its Strategic Plan 2022-2025, and has committed to providing guidance on how the Equality Act applies to the use of new technologies, such as AI, in automated decision-making<sup id="fnref:20" role="doc-noteref"><a href="#fn:20" class="govuk-link" rel="footnote">[footnote 20]</a></sup>
</li>
  <li>the Medicines and Healthcare products Regulatory Agency has launched a Software and AI as a Medical Device Change Programme<sup id="fnref:21" role="doc-noteref"><a href="#fn:21" class="govuk-link" rel="footnote">[footnote 21]</a></sup> and consulted on possible changes to the regulatory framework<sup id="fnref:22" role="doc-noteref"><a href="#fn:22" class="govuk-link" rel="footnote">[footnote 22]</a></sup> to ensure the requirements provide a high degree of assurance that these devices are acceptably safe and function as intended.</li>
  <li>the Health and Safety Executive committed to develop collaborative research with industry and academia in its Science and Evidence Delivery Plan 2020-2023, to determine a clear understanding of the health and safety implications of AI in the workplace<sup id="fnref:23" role="doc-noteref"><a href="#fn:23" class="govuk-link" rel="footnote">[footnote 23]</a></sup>
</li>
</ul>

<p>Regulators are also working together to understand the impact AI technologies could have on our economy and society. The Digital Regulation Cooperation Forum (DRCF)<sup id="fnref:24" role="doc-noteref"><a href="#fn:24" class="govuk-link" rel="footnote">[footnote 24]</a></sup> has been exploring the impact of algorithms across their industries and regulatory remits. It recently published the outputs of its first two research projects looking at the harms and benefits posed by algorithmic processing (including the use of AI), and at the merits of algorithmic auditing.<sup id="fnref:25" role="doc-noteref"><a href="#fn:25" class="govuk-link" rel="footnote">[footnote 25]</a></sup> In addition, the Bank of England and the Financial Conduct Authority established the Artificial Intelligence Public-Private Forum (AIPPF) to further dialogue on AI innovation in financial services between the public and private sectors. It recently published its report of this work.<sup id="fnref:26" role="doc-noteref"><a href="#fn:26" class="govuk-link" rel="footnote">[footnote 26]</a></sup></p>

<p>Standards can also play a key part in developing a coherent regulatory approach, and the government is also already taking steps to develop world leading AI standards in the UK. In January 2022, the Department for Digital, Culture, Media and Sport (DCMS) <a href="https://www.gov.uk/government/news/new-uk-initiative-to-shape-global-standards-for-artificial-intelligence" class="govuk-link">announced</a> the pilot of an AI Standards Hub to increase UK engagement in the development of global technical standards for AI. Multiple global standards development organisations (SDOs) have already published AI-specific standards, and more are under development. The Hub will create practical tools and bring the UK’s multi-stakeholder AI community together to ensure that global AI standards are shaped by a wide range of experts, to deliver the tools needed for AI governance, in line with our values. <sup id="fnref:27" role="doc-noteref"><a href="#fn:27" class="govuk-link" rel="footnote">[footnote 27]</a></sup> In November 2021, the Central Digital and Data Office<sup id="fnref:28" role="doc-noteref"><a href="#fn:28" class="govuk-link" rel="footnote">[footnote 28]</a></sup> (CDDO) <a href="https://www.gov.uk/government/news/uk-government-publishes-pioneering-standard-for-algorithmic-transparency" class="govuk-link">also published</a> one of the world’s first national algorithmic transparency standards to strengthen trust in government use of algorithms and AI.</p>

<p>Assurance also plays an important role in complementing our regulatory approach. The UK’s Centre for Data Ethics and Innovation (CDEI) highlighted the need for robust AI assurance tools and services to ensure that stakeholders can understand the performance, risk and compliance of AI. In December 2021, the CDEI <a href="https://www.gov.uk/government/publications/the-roadmap-to-an-effective-ai-assurance-ecosystem" class="govuk-link">published</a> a roadmap towards building a world-leading AI assurance ecosystem in the UK, and is now delivering a programme to ensure that the UK capitalises on its strengths in professional and legal services to lead the growth of this nascent industry.</p>

<h3 id="key-challenges">Key Challenges</h3>

<p>The proliferation of activity; voluntary, regulatory and quasi-regulatory, introduces new challenges that we must take action to address. Examples include:</p>

<ul>
  <li>
<strong>A lack of clarity:</strong> Stakeholders<sup id="fnref:29" role="doc-noteref"><a href="#fn:29" class="govuk-link" rel="footnote">[footnote 29]</a></sup> often highlight the ambiguity of the UK’s legal frameworks and application of regulatory bodies to AI, given these have not been developed specifically with AI technologies and its applications in mind. The extent to which UK laws apply to AI is often a matter of interpretation, making them hard to navigate. This is particularly an issue for smaller businesses who may not have any legal support.</li>
  <li>
<strong>Overlaps:</strong> Stakeholders also note the risk that laws and regulators’ remits may regulate the same issue for the same reason and this can exacerbate this lack of clarity. This could lead to unnecessary, contradictory or confusing layers of regulation when multiple regulators oversee an organisation’s use of the same AI for the same purpose.</li>
  <li>
<strong>Inconsistency:</strong> There are differences between the powers of regulators to address the use of AI within their remit<sup id="fnref:30" role="doc-noteref"><a href="#fn:30" class="govuk-link" rel="footnote">[footnote 30]</a></sup> as well as the extent to which they have started to do so. AI technologies used in different sectors are therefore subject to different controls. While in some instances there will be a clear rationale for this, it can further compound an overall lack of clarity.</li>
  <li>
<strong>Gaps in our approach:</strong> As current UK legislation has not been developed with AI in mind, there may be current risks that are already inadequately addressed, and future risks associated with widespread use of AI that we need to prepare for. For example, around the need for improved transparency and explainability in relation to decisions made by AI, incentivising developers to prioritise safety and robustness of AI systems, and clarifying actors’ responsibilities. There is also concern that AI will amplify wider systemic and societal risks, for instance AI’s impact on public debate and democracy, with its ability to create synthetic media such as deepfakes.</li>
</ul>

<p>These issues across the regulatory landscape risk undermining consumer trust, harming business confidence and ultimately limiting growth and innovation across the AI ecosystem, including in the public sector.<sup id="fnref:31" role="doc-noteref"><a href="#fn:31" class="govuk-link" rel="footnote">[footnote 31]</a></sup>,<sup id="fnref:32" role="doc-noteref"><a href="#fn:32" class="govuk-link" rel="footnote">[footnote 32]</a></sup>,<sup id="fnref:33" role="doc-noteref"><a href="#fn:33" class="govuk-link" rel="footnote">[footnote 33]</a></sup> By taking action to improve clarity and coherence, we have an opportunity to establish an internationally competitive regulatory approach that drives innovation and cements the UK’s position as an AI leader.</p>

<h2 id="the-scope">The scope</h2>

<p>To develop a clear framework for regulating AI, it will be critical to clarify its scope. However, there is currently little consensus on a general definition of AI, either within the scientific community or across national or international organisations.</p>

<p>AI is a general purpose technology like electricity, the internet and the combustion engine. As AI evolves, it will touch on many areas of life with transformative implications - although the precise impact of this technology will vary greatly according to its context and application.</p>

<p>The EU has grounded its approach in the product safety regulation of the Single Market, and as such has set out a relatively fixed definition in its legislative proposals.<sup id="fnref:34" role="doc-noteref"><a href="#fn:34" class="govuk-link" rel="footnote">[footnote 34]</a></sup> Whilst such an approach can support efforts to harmonise rules across multiple countries, we do not believe this approach is right for the UK. We do not think that it captures the full application of AI and its regulatory implications. Our concern is that this lack of granularity could hinder innovation.</p>

<p>An alternative approach would be to put no boundaries on what constitutes AI, and leave regulators or relevant bodies to decide what technology and systems are in scope as they see fit. While such an approach would offer maximum flexibility, it raises the risk that businesses and the public would not have a consistent view of what is and is not the subject of regulation. A further risk is that any scope becomes defined via case law in the absence of a definition, which may vary by sector - and could add to further confusion.</p>

<p>Our preferred approach therefore is to set out the core characteristics of AI to inform the scope of the AI regulatory framework but allow regulators to set out and evolve more detailed definitions of AI according to their specific domains or sectors. This is in line with the government’s view that we should regulate the use of AI rather than the technology itself - and a detailed universally applicable definition is therefore not needed. Rather, by setting out these core characteristics, developers and users can have greater certainty about scope and the nature of UK regulatory concerns while still enabling flexibility - recognising that AI may take forms we cannot easily define today - while still supporting coordination and coherence.</p>

<h3 id="defining-the-core-characteristics-of-ai">Defining the core characteristics of AI</h3>

<p>AI can have a wider number of characteristics and capabilities, depending on the techniques used and specifics of the use case. However, in terms of regulation, there are two key characteristics which underlie distinct regulatory issues which existing regulation may not be fully suited to address, and form the basis of the scope of this work:</p>

<h4 id="the-adaptiveness-of-the-technology---explaining-intent-or-logic">The ‘adaptiveness’ of the technology - explaining intent or logic</h4>

<p>AI systems often partially operate on the basis of instructions which have not been expressly programmed with human intent, having instead been ‘learnt’ on the basis of a variety of techniques;</p>

<p>AI systems are often ‘trained’ - once or continually - on data, and execute according to patterns and connections which are not easily discernible to humans. This ability underscores the power of modern AI, enabling it to produce incredibly intricate artwork based on a paragraph of text input,<sup id="fnref:35" role="doc-noteref"><a href="#fn:35" class="govuk-link" rel="footnote">[footnote 35]</a></sup> diagnose illness in medical scans which are imperceptible to a human,<sup id="fnref:36" role="doc-noteref"><a href="#fn:36" class="govuk-link" rel="footnote">[footnote 36]</a></sup> or complete missing elements of ancient texts.<sup id="fnref:37" role="doc-noteref"><a href="#fn:37" class="govuk-link" rel="footnote">[footnote 37]</a></sup></p>

<p>For regulatory purposes this means that the logic or intent behind the output of systems can often be extremely hard to explain, or errors and undesirable issues within the training data are replicated. This has potentially serious implications, such as when decisions are being made relating to an individual’s health, wealth or longer term prospects, or when there is an expectation that a decision should be justifiable in easily understood terms - such as legal dispute.</p>

<h4 id="the-autonomy-of-the-technology---assigning-responsibility-for-action">The ‘autonomy’ of the technology - assigning responsibility for action</h4>

<p>AI often demonstrates a high degree of autonomy, operating in dynamic and fast-moving environments by automating complex cognitive tasks. Whether that is playing a video game or navigating on public roads, this ability to strategise and react is what fundamentally makes a system ‘intelligent’, but it also means that decisions can be made without express intent or the ongoing control of a human.</p>

<p>While AI systems vary greatly, we propose that it is this combination of core characteristics which demands a bespoke regulatory response and informs the scope of our approach to regulating AI.</p>

<div class="call-to-action">
  <p>To ensure our system can capture current and future applications of AI, in a way that remains clear, we propose that the government should not set out a universally applicable definition of AI. Instead, we will set out the core characteristics and capabilities of AI and guide regulators to set out more detailed definitions at the level of application.</p>
</div>

<h4 id="table-1-example-case-studies-the-regulatory-implications-of-ais-adaptive--autonomous-characteristics">Table 1. Example case studies: The regulatory implications of AI’s adaptive &amp; autonomous characteristics</h4>

<table>
  <thead>
    <tr>
      <th scope="col"><strong>Case study   scenario</strong></th>
      <th scope="col"><strong>How it is   Adaptive</strong></th>
      <th scope="col"><strong>How it is   Autonomous</strong></th>
      <th scope="col"><strong>Potential   AI related regulatory implications</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Transformer   Language Model used to output text-based, or image-based content</strong></td>
      <td>Transformer models have a large number of   parameters, often derived from data from the public internet. This can   harness the collective creativity and knowledge present online, and enable the   creation of stories and rich, highly-specific images on the basis of a short   textual prompt.</td>
      <td>These models generate their output automatically,   based on the text input, and produce impressive multimedia with next to no   detailed instruction or ongoing oversight from the user.</td>
      <td>- Security and privacy concerns from inferred   training data     - Inappropriate or harmful language or content   output     - Reproduction of biases or stereotyping in training   data</td>
    </tr>
    <tr>
      <td><strong>Self-driving   car control system</strong></td>
      <td>These systems use computer vision as well as   iteratively learning from real time driving data to create a model which is   capable of understanding the road environment, and what actions to take in   given circumstances.</td>
      <td>These models directly control the speed, motion and   direction of a vehicle.</td>
      <td>- Safety and control risks if presented with   unfamiliar input     - Assignation of liability for decisions in an   accident/dispute     - Opacity regarding decision-making and   corresponding lack of public trust</td>
    </tr>
  </tbody>
</table>

<h2 id="a-new-pro-innovation-approach">A new pro-innovation approach</h2>

<p>Often the transformative effects of AI will be rapid and - at times - unexpected. There is therefore an important need to establish a clear framework which sets out how the government will respond to these opportunities as well as new and accelerated risks. This will offer greater clarity regarding how we intend to drive growth while also protecting our safety, security and fundamental values. In order to promote innovation and to support our thriving AI ecosystem, our approach will be:</p>

<ul>
  <li>
<strong>Context-specific</strong> - we will acknowledge that AI is a dynamic, general purpose technology and that the risks arising from it depend principally on the context of its application.</li>
  <li>
<strong>Pro-innovation and risk-based</strong> - we will ask regulators to focus on applications of AI that result in real, identifiable, unacceptable levels of risk, rather than seeking to impose controls on uses of AI that pose low or hypothetical risk so we avoid stifling innovation</li>
  <li>
<strong>Coherent</strong> - we will ensure the system is simple, clear, predictable and stable.</li>
  <li>
<strong>Proportionate and adaptable</strong> - we will ask that regulators consider lighter touch options, such as guidance or voluntary measures, in the first instance.</li>
</ul>

<p>A context-based approach allows AI related risk to be identified and assessed at the application level. This will enable a targeted and nuanced response to risk because an assessment can be made by the appropriate regulator of the actual impact on individuals and groups in a particular context. This also allows domains that have existing and distinct approaches to AI regulation such as defence to continue to develop appropriate mechanisms according to context. Relying on our existing regulatory structures also provides the flexibility to identify and adapt according to emerging risks since it is unlikely that new risks will develop in a consistent way across the entire economy.</p>

<p>Our approach will also be risk-based and proportionate. We anticipate that regulators will establish risk-based criteria and thresholds at which additional requirements come into force. Through our engagement with regulators, we will seek to ensure that proportionality is at the heart of implementation and enforcement of our framework, eliminating burdensome or excessive administrative compliance obligations. We will also seek to ensure that regulators consider the need to support innovation and competition as part of their approach to implementation and enforcement of the framework.</p>

<p>We think this is preferable to a single framework with a fixed, central list of risks and mitigations. Such a framework applied across all sectors would limit the ability to respond in a proportionate manner by failing to allow for different levels of risk presented by seemingly similar applications of AI in different contexts.<a href="#_ftn1" class="govuk-link">[38]</a> This could lead to unnecessary regulation and stifle innovation. A fixed list of risks also could quickly become outdated and does not offer flexibility. A centralised approach would also not benefit from the expertise of our experienced regulators who are best placed to identify and respond to the emerging risks through the increased use of AI technologies within their domains.</p>

<p>We do, however, acknowledge that a context-driven approach offers less uniformity than a centralised approach - by its nature, it varies according to circumstance. That is why we wish to complement our context-based approach with a set of overarching principles to make sure that we approach common cross-cutting challenges in a coherent and streamlined way.</p>

<div class="call-to-action">
  <p>We are taking an actively pro-innovation approach. AI is a rapidly evolving technology with scope of application and depth of capability expanding at pace. Therefore, we do not think the government should establish rigid, inflexible requirements right now. Instead, our framework will ensure that regulators are responsive in protecting the public, by focusing on the specific context in which AI is being used, and taking a proportionate, risk-based response. We will engage with regulators to ensure that they proactively embed considerations of innovation, competition and proportionality through their implementation and any subsequent enforcement of the framework.</p>
</div>

<h3 id="cross-sectoral-principles">Cross-sectoral principles</h3>

<p>While context is critical, AI technologies feature a range of underlying issues and risks which require a coherent response, such as a perceived lack of explainability when high-impact decisions are made about people using AI. We propose to address this by developing a set of cross-sectoral principles tailored to the distinct characteristics of these technologies. Regulators would be tasked with interpreting and implementing these cross-sectoral principles within their regulatory remits in line with their existing roles and remits. Our expectation is that our cross-sectoral principles will also provide a basis for coordination with our global partners and will support our implementation of the global principles that the UK has already helped to develop.</p>

<div class="call-to-action">
  <p>We propose developing a set of cross-sectoral principles that regulators will develop into sector or domain-specific AI regulation measures.</p>
</div>

<h3 id="early-proposals-for-our-cross-sectoral-principles">Early proposals for our cross-sectoral principles</h3>

<p>Our proposed cross-sectoral principles build on the OECD Principles on Artificial Intelligence<a href="#_ftn2" class="govuk-link">[39]</a> and demonstrate the UK’s commitment to them. Our principles will provide a clear foundation for our framework, tailored to the UK’s values and ambitions, and will be delivered within existing regulatory regimes. The principles will complement existing regulation, with our vision being to increase clarity and reduce friction for businesses operating in the AI lifecycle.</p>

<p>Our principles are deliberately ‘values’ focused - we want to make sure AI-driven growth and innovation is aligned with the UK’s broader values given the vital role AI plays in shaping outcomes that affect our society. They are not, however, intended to create an extensive new framework of rights for individuals. The principles describe what we think well governed AI use should look like on a cross-cutting basis, but taken as part of our broader context-based, pro-innovation approach. For example, we expect well governed AI to be used with due consideration to concepts of fairness and transparency. Similarly, we expect all actors in the AI lifecycle to appropriately manage risks to safety and to provide for strong accountability.</p>

<p>Our proposal is that the principles will be interpreted and implemented in practice by our existing regulators. We are examining how the government can offer a strong steer to regulators to adopt a proportionate and risk-based approach (for example through government-issued guidance to regulators). The principles will ultimately apply to any actor in the AI lifecycle whose activities create risk that the regulators consider should be managed through the context-based operationalisation of each of the principles. For example, regulators will be tasked with deciding what ‘fairness’ or ‘transparency’ means for AI development or use in the context of their sector or domain. Regulators will then decide if, when and how their regulated entities will need to implement measures to demonstrate that these principles have been considered or complied with depending on the relevant context. We are also exploring ways to ensure that regulators can coordinate effectively to ensure coherence between their respective approaches to the principles, including where possible by working together to interpret or implement the principles on a joint or cross-sectoral basis.</p>

<p>Below we set out our early proposals for these cross-sectoral principles.</p>

<div class="call-to-action">
  <h3 id="cross-sectoral-principles-for-ai-regulation">Cross-sectoral principles for AI regulation</h3>

  <h4 id="ensure-that-ai-is-used-safely">Ensure that AI is used safely</h4>

  <p>The breadth of uses for AI can include functions that have a significant impact on safety - and while this risk is more apparent in certain sectors such as healthcare or critical infrastructure, there is the potential for previously unforeseen safety implications to materialise in other areas.</p>

  <p>As such, whilst safety will be a core consideration for some regulators, it will be important for all regulators to take a context-based approach in assessing the likelihood that AI could pose a risk to safety in their sector or domain, and take a proportionate approach to managing this risk. Ensuring safety in AI will require new ways of thinking and new approaches, however we would expect the requirements to remain commensurate with actual risk - comparable with non-AI use cases.</p>

  <h4 id="ensure-that-ai-is-technically-secure-and-functions-as-designed">Ensure that AI is technically secure and functions as designed</h4>

  <p>AI is rapidly bringing new capabilities online and reducing the costs of existing business functions and processes. Ensuring that consumers and the public have confidence in the proper functioning of systems is vital to guaranteeing that the research and commercialisation of AI can continue apace.</p>

  <p>AI systems should be technically secure and under conditions of normal use they should reliably do what they intend and claim to do. Subject to considerations of context and proportionality, the functioning, resilience and security of a system should be tested and proven, and the data used in training and in deployment should be relevant, high quality, representative and contextualised.</p>

  <h4 id="make-sure-that-ai-is-appropriately-transparent-and-explainable">Make sure that AI is appropriately transparent and explainable</h4>

  <p>Achieving explainability of AI systems at a technical level remains an important research and development challenge. Presently, the logic and decision making in AI systems cannot always be meaningfully explained in an intelligible way, although in most settings this poses no substantial risk. However, in some settings the public, consumers and businesses may expect and benefit from transparency requirements that improve understanding of AI decision-making. In some high risk circumstances, regulators may deem that decisions which cannot be explained should be prohibited entirely - for instance in a tribunal where you have a right to challenge the logic of an accusation.</p>

  <p>Taking into account considerations of the need to protect confidential information and intellectual property rights, example transparency requirements could include requirements to proactively or retrospectively provide information relating to: (a) the nature and purpose of the AI in question including information relating to any specific outcome, (b) the data being used and information relating to training data, (c) the logic and process used and where relevant information to support explainability of decision making and outcomes, (d) accountability for the AI and any specific outcomes.</p>

  <h4 id="embed-considerations-of-fairness-into-ai">Embed considerations of fairness into AI</h4>

  <p>In many contexts, the outcomes of the use of AI can have a significant impact on people’s lives - such as insurance, credit scoring or job applications. Such high-impact outcomes - and the data points used to reach them - should be justifiable and not arbitrary.</p>

  <p>In order to ensure proportionate and pro-innovation regulation, it will be important to let regulators continue to define fairness. However, in any sector or domain we would expect regulators to:</p>

  <ul>
    <li>interpret and articulate ‘fairness’ as relevant to their sector or domain,</li>
    <li>decide in which contexts and specific instances fairness is important and relevant (which it may not always be), and</li>
    <li>design, implement and enforce appropriate governance requirements for ‘fairness’ as applicable to the entities that they regulate.</li>
  </ul>

  <h4 id="define-legal-persons-responsibility-for-ai-governance">Define legal persons’ responsibility for AI governance</h4>

  <p>AI systems can operate with a high level of autonomy, making decisions about how to achieve a certain goal or outcome in a way which has not been explicitly programmed or even foreseen - which can raise secondary issues and externalities. This is ultimately what makes them intelligent systems.</p>

  <p>Therefore, accountability for the outcomes produced by AI and legal liability must always rest with an identified or identifiable legal person - whether corporate or natural.<sup id="fnref:40" role="doc-noteref"><a href="#fn:40" class="govuk-link" rel="footnote">[footnote 40]</a></sup></p>

  <h4 id="clarify-routes-to-redress-or-contestability">Clarify routes to redress or contestability</h4>

  <p>AI systems can be used in ways which may result in a material impact on people’s lives, or in situations where people would normally expect the reasoning behind an outcome to be set out clearly in a way that they can understand and contest - for example, when their existing rights have been affected. Using AI can increase speed, capacity and access to services, as well as improve the quality of outcomes. However it can also introduce risks, for example that the relevant training data reproduces biases or other quality concerns into an outcome.</p>

  <p>Subject to considerations of context and proportionality, the use of AI should not remove an affected individual or group’s ability to contest an outcome. We would therefore expect regulators to implement proportionate measures to ensure the contestability of the outcome of the use of AI in relevant regulated situations.</p>
</div>

<div class="call-to-action">
  <h3 id="case-study-how-our-principles-could-apply-to-an-ai-start-up">Case study: How our principles could apply to an AI start-up</h3>

  <p>An AI-first startup has created a platform that can automate complex customer-facing processes such as providing advice, sales and customer services, built on top of a Large Language Model.<sup id="fnref:40:1" role="doc-noteref"><a href="#fn:40" class="govuk-link" rel="footnote">[footnote 40]</a></sup> On their product roadmap, the company has plans to expand into multiple regulated domains, using their technology to offer legal advice, financial advice and potentially even medical advice.</p>

  <p>As a business, they have strong technical expertise and want to develop products to enter and expand into these sectors, but are holding back from investing time and resource in market development activities because of the uncertainty that comes with regulatory compliance. The business leaders assume the costs of regulatory compliance to be high, making the justification for investment difficult.</p>

  <h4 id="our-proposed-framework-will-bridge-this-gap-and-provide-the-clarity-that-this-company-needs">Our proposed framework will bridge this gap and provide the clarity that this company needs:</h4>

  <ul>
    <li>the specific measures introduced by the regulators to implement each of our cross-sectoral principles will communicate clearly and in a coherent way to businesses what expectations are around the technical, internal processes and likely regulatory requirements</li>
    <li>relevant regulators could issue guidance to highlight relevant regulatory requirements such as sector-specific licences, standards or the need for named individuals to assume particular responsibilities (they would do this either jointly or in a coordinated way to minimise the risk of confusion or excessive burdens)</li>
  </ul>

  <p>As a result this company can integrate these requirements into their product roadmap, understand the rules more easily and spend more time and resource on product development or fundamental AI research, and less on legal costs. The UK benefits both from the increased investment but also from the disruptive power of new technology-led business models increasing access to financial or legal advice.</p>
</div>

<h2 id="putting-our-approach-into-practice">Putting our approach into practice</h2>

<p>We are still at the early stages of considering how best to put our approach into practice, and will set out fuller details through the forthcoming white paper.</p>

<p>We propose initially putting the cross-sectoral principles on a non-statutory footing. This is so that we can monitor, evaluate and if necessary update our approach and so that it remains agile enough to respond to the rapid pace of change in the way that AI impacts upon society. This position would be kept under review as part of an ongoing process of monitoring and evaluating the effectiveness of the framework, including the principles and existing regulatory structures.</p>

<p>We propose that regulators will lead the process of identifying, assessing, prioritising and contextualising the specific risks addressed by the principles. We anticipate that the government may issue supplementary or supporting guidance, for example focused on the interpretation of terms used within the principles, risk and proportionality, to support regulators in their application of the principles. These principles provide clear steers for regulators, but will not necessarily translate into mandatory obligations. Indeed we will encourage regulators to consider lighter touch options in the first instance - for example, through a voluntary or guidance-based approach for uses of AI that fall within their remit. This approach will also complement and support regulators’ formal legal and enforcement obligations using the powers available to in order to enforce requirements set out in statute.</p>

<p>Many regulators will have the flexibility within their regulatory powers to translate and implement our proposed principles, but not all. There are also differences between the types of rules regulators can make when translating these principles, and the enforcement action regulators can take where the underlying legal rules are broken. We need to consider if there is a need to update the powers and remits of some individual regulators. However we do not consider that equal powers or uniformity of approach across all regulators to be necessary.</p>

<p>Regulatory coordination will be important for our approach to work and to avoid contradictory or very different approaches across regulators. It will also be important to maintain a clear overview of how coherently the regulatory landscape as a whole is operating and to be able to anticipate issues arising from the implementation of our framework. We will look for ways to support collaboration between regulators to ensure a streamlined approach. For example, we will seek to ensure that organisations do not have to navigate multiple sets of guidance from multiple regulators all addressing the same principle. To do this, we will need to ensure we have the right institutional architecture in place. The UK already benefits from close cooperation between some of its regulators at a statutory level, and - in the digital space - from the ground-breaking work of the Digital Regulation Cooperation Forum, whose members have already begun to think actively about their shared priorities and areas of interest in relation to AI regulation.<sup id="fnref:41" role="doc-noteref"><a href="#fn:41" class="govuk-link" rel="footnote">[footnote 41]</a></sup> We need to identify what further mechanisms, if any, are needed to ensure that this existing infrastructure can successfully support our goals for a coherent, decentralised framework.</p>

<p>We also need to ensure that UK regulators have access to the right skills and expertise to effectively regulate AI. While some have been able to make significant and rapid investment in their AI capabilities in recent years, not all regulators have access to the necessary skills and expertise required. We will need to consider how we can address these disparities in a proportionate and innovative way; this could include consideration of the role that ‘pooled capabilities’ can play, as well as the effectiveness of secondments from industry and academia.</p>

<p>While we currently do not see a need for legislation at this stage, we cannot rule out that legislation may be required as part of making sure our regulators are able to implement the framework. For example, legislation may be necessary to ensure that regulators are able to take a coordinated and coherent approach. This could be relevant in the context of enabling and supporting regulatory coordination, or to make updates to regulatory powers. Alongside this, we may need to consider specific new powers or capabilities for regulators where risks associated with particular applications arise. However, we expect to pursue this approach by exception where it is the only viable option to address a high-impact risk</p>

<div class="call-to-action">
  <p>At this stage, we are considering implementing the principles on a non-statutory basis which could be supplemented by clear guidance from the government. This approach would be kept under review. We cannot, however, rule out the need for legislation as part of the delivery and implementation of the principles. For example, in order to enhance regulatory powers, ensure regulatory coordination, or to create new institutional architecture.</p>
</div>

<h3 id="the-international-landscape">The international landscape</h3>

<p>The inherent cross-border nature of the digital ecosystem and scientific collaboration as well as the importance of facilitating cross-border trade means it is imperative we work closely with partners. This is in order to prevent a fragmented global market, ensure interoperability and promote the responsible development of AI internationally.</p>

<p>We will continue to pursue an inclusive multi-stakeholder approach, to bring in relevant voices and expertise to help address these issues. We will also protect against efforts to adopt and apply these technologies in the service of authoritarianism and repression. To support this, the UK will continue to be an active player in organisations such as GPAI and the OECD, as well as acting as a pragmatic pro-innovation voice in ongoing Council of Europe negotiations. We will ensure that UK industry’s interests are well represented in international standardisation - both to encourage interoperability and to embed British values.</p>

<p>We will promote a pro-innovation international governance and regulatory environment for AI which fosters openness, liberty and democracy. We will work with partners around the world to ensure international agreements embed our values so that progress in AI is achieved responsibly, according to democratic norms and the rule of law. We will reject efforts to adopt and apply AI technologies to support authoritarianism or discrimination.</p>

<h2 id="next-steps">Next steps</h2>

<p>This paper sets out our overall pro-innovation direction of travel on regulating AI. Over the coming months, we will be considering how best to implement and refine our approach to drive innovation, boost consumer and investor confidence and support the development and adoption of new AI systems. Specifically we will be considering:</p>

<ul>
  <li>
    <p><strong>The proposed framework</strong> and whether it adequately addresses our prioritised AI-specific risks in a way tailored to the UK’s values and ambitions while also enabling effective coordination with other international approaches. This includes considering whether any gaps exist in the existing regulator coverage that require a more targeted solution.</p>
  </li>
  <li>
    <p><strong>How we put our approach into practice.</strong> This includes considering the roles, powers, remits and capabilities of regulators; the need for coordination and how this should be delivered across the range of regulators (statutory and non-statutory) involved in AI regulation; and whether new institutional architecture is needed to oversee the functioning of the landscape as a whole and anticipate future challenges. This includes the role of technical standards and assurance mechanisms as potential tools for implementing principles in practice, supporting industry, and enabling international trade. We will also consider if there are any areas of high risk that demand an agreed timeline for regulators to interpret the principles into sector or domain specific guidance. We will work with key regulators such as the Information Commissioner’s Office, Competition and Markets Authority, Ofcom, Medicine and Healthcare Regulatory Authority and Equality and Human Rights Commission - as well as other stakeholders - to examine these questions.<sup id="fnref:43" role="doc-noteref"><a href="#fn:43" class="govuk-link" rel="footnote">[footnote 43]</a></sup></p>
  </li>
  <li>
    <p><strong>Monitoring of the framework</strong> to ensure it delivers our vision for regulating AI in the UK and that it is capable of foreseeing future developments, mitigating future risks and maximising the benefits of future opportunities. This includes designing a suitable monitoring and evaluation framework to monitor progress against our vision as well as criteria for future updates to the framework to ensure a robust approach to identifying and addressing evolving risks. This will be undertaken on two levels, both at the overall system level and at the individual regulator level. Our approach will also require consideration of how to ensure an effective and holistic horizon scanning function so we ensure our approach is suitable to address both immediate and long-term risks.</p>
  </li>
</ul>

<p>We will set out our position on these topics through the forthcoming White Paper and public consultation, which we plan to publish in late 2022.</p>

<h2 id="share-your-views">Share your views</h2>

<p>Through this paper, we want to invite stakeholder views about how the UK can best set the rules for regulating AI in a way that drives innovation and growth while also protecting our fundamental values. This will inform the development of the forthcoming white paper.</p>

<p>We therefore welcome reflections on our proposed approach and we would like to specifically invite views and any supporting evidence that you can share with regard to the following questions:</p>

<ol class="steps">
<li>
<p>What are the most important challenges with our existing approach to regulating AI? Do you have views on the most important gaps, overlaps or contradictions?</p>
</li>
<li>
<p>Do you agree with the context-driven approach delivered through the UK’s established regulators set out in this paper? What do you see as the benefits of this approach? What are the disadvantages?</p>
</li>
<li>
<p>Do you agree that we should establish a set of cross-sectoral principles to guide our overall approach? Do the proposed cross-sectoral principles cover the common issues and risks posed by AI technologies? What, if anything, is missing?</p>
</li>
<li>
<p>Do you have any early views on how we best implement our approach? In your view, what are some of the key practical considerations? What will the regulatory system need to deliver on our approach? How can we best streamline and coordinate guidance on AI from regulators?</p>
</li>
<li>
<p>Do you anticipate any challenges for businesses operating across multiple jurisdictions? Do you have any early views on how our approach could help support cross-border trade and international cooperation in the most effective way?</p>
</li>
<li>
<p>Are you aware of any robust data sources to support monitoring the effectiveness of our approach, both at an individual regulator and system level?</p>
</li>
</ol>
<p>The call for views and evidence will be open for 10 weeks, closing on 26 September 2022, to allow time for your consideration and response.</p>

<p>You can send your views on this to: <a href="mailto:evidence@officeforai.gov.uk" class="govuk-link">evidence@officeforai.gov.uk</a>. You can also write to us at:</p>

<div class="address"><div class="adr org fn"><p>

Office for Artificial Intelligence
<br>DCMS
<br>100 Parliament Street
<br>London
<br>SW1A 2BQ
<br>
</p></div></div>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p><a rel="external" href="https://aiindex.stanford.edu/wp-content/uploads/2022/03/2022-AI-Index-Report_Master.pdf" class="govuk-link">Artificial Intelligence Index Report</a>, Stanford (2022) <a href="#fnref:1" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p><a rel="external" href="https://oecd.ai/en/data?selectedArea=ai-research&amp;selectedVisualization=top-countries-in-ai-scientific-publications-in-time-from-scopus" class="govuk-link">OECD AI Policy Observatory - Live data</a>, OECD (2022) <a href="#fnref:2" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p><a rel="external" href="https://www.bbc.co.uk/news/uk-scotland-56734407" class="govuk-link">AI technology used to track asbestos tumours</a>, BBC (April 2021) <a href="#fnref:3" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p><a rel="external" href="https://es.catapult.org.uk/news/artificial-intelligence-project-to-help-people-facing-fuel-poverty/" class="govuk-link">Artificial intelligence project to help people facing fuel poverty</a>, Energy Systems Catapult (2022) <a href="#fnref:4" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p><a rel="external" href="https://www.bbc.co.uk/news/business-59635186" class="govuk-link">Why cows may be hiding something but AI can spot it</a>, BBC (February [2022]) <a href="#fnref:5" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:6" role="doc-endnote">
      <p><a rel="external" href="https://kainos-prod-assets.s3.amazonaws.com/uploads/2021/02/HMLR-Case-Study-2021.pdf" class="govuk-link">HM Land Registry: Using AI for intelligence document comparison</a>, Kainos <a href="#fnref:6" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:7" role="doc-endnote">
      <p><a rel="external" href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology" class="govuk-link">AlphaFold: a solution to a 50-year-old grand challenge in biology</a>, DeepMind (2020) <a href="#fnref:7" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:8" role="doc-endnote">
      <p><a rel="external" href="https://wayve.ai/blog/a-new-approach-to-self-driving-av2-0/" class="govuk-link">A new approach to self-driving: AV2.0</a>, Wayve (2021) <a href="#fnref:8" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:9" role="doc-endnote">
      <p><a rel="external" href="https://www.bcg.com/publications/2021/ai-to-reduce-carbon-emissions" class="govuk-link">Reduce carbon costs with the power of AI</a>, BCG (2021) <a href="#fnref:9" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:10" role="doc-endnote">
      <p>This includes the International Organisation for Standardization (ISO), International Electrotechnical Commission (IEC) and Institute of Electrical and Electronics Engineers Standards Association (IEEE SA) <a href="#fnref:10" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:11" role="doc-endnote">
      <p>The following is taken from the government’s <a href="https://www.gov.uk/government/publications/digital-regulation-driving-growth-and-unlocking-innovation/digital-regulation-driving-growth-and-unlocking-innovation" class="govuk-link">Plan for Digital Regulation</a>, published in July 2021: “‘Digital regulation’ refers to the range of regulatory tools that the government, regulators, businesses, and other bodies use to manage the impact that digital technologies and activities can have on individuals, companies, the economy and society. These include norms, self-regulation, statutory codes of conduct, and rules in primary legislation. We use these tools to promote outcomes that the market alone cannot achieve efficiently. Non-regulatory tools can complement or provide alternatives to ‘traditional’ regulation. This includes industry-led technical standards, which benefit from global technical expertise and best practice.” <a href="#fnref:11" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:12" role="doc-endnote">
      <p>The World Bank in its <a rel="external" href="https://rulemaking.worldbank.org/en/data/explorecountries/united-kingdom" class="govuk-link">Global Indicators of Regulatory Governance</a> analysis gives the UK a score of 5/5. <a href="#fnref:12" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:13" role="doc-endnote">
      <p>The 2021 edition of the <a rel="external" href="https://www.globalinnovationindex.org/gii-2021-report" class="govuk-link">Global Innovation Index</a> (GII) gives the UK a score of 92.4/100 for ‘Regulatory Environment’. <a href="#fnref:13" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:14" role="doc-endnote">
      <p>Other examples include equality law, which would apply where the use of AI produces discriminatory outcomes. Sector specific regulation such as for financial services and medical research may also capture the use of AI in these sectors. <a href="#fnref:14" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:15" role="doc-endnote">
      <p>UK GDPR and Data Protection Act 2018 <a href="#fnref:15" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:16" role="doc-endnote">
      <p><a rel="external" href="https://ico.org.uk/for-organisations/guide-to-data-protection/key-dp-themes/guidance-on-ai-and-data-protection/" class="govuk-link">Guidance on AI and data protection</a>, ICO <a href="#fnref:16" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:17" role="doc-endnote">
      <p><a rel="external" href="https://ico.org.uk/for-organisations/guide-to-data-protection/key-dp-themes/explaining-decisions-made-with-ai/" class="govuk-link">Explaining decisions made with AI</a>, ICO <a href="#fnref:17" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:18" role="doc-endnote">
      <p><a rel="external" href="https://ico.org.uk/for-organisations/guide-to-data-protection/key-dp-themes/guidance-on-ai-and-data-protection/ai-and-data-protection-risk-toolkit/" class="govuk-link">AI and data protection risk toolkit</a>, ICO <a href="#fnref:18" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:19" role="doc-endnote">
      <p><a rel="external" href="https://ico.org.uk/about-the-ico/ico-and-stakeholder-consultations/ico-consultation-on-the-draft-ai-auditing-framework-guidance-for-organisations/" class="govuk-link">I CO consultation (now closed) on the AI auditing framework</a>, ICO (February 2020) <a href="#fnref:19" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:20" role="doc-endnote">
      <p><a rel="external" href="https://www.equalityhumanrights.com/sites/default/files/about-us-strategic-plan-2022-2025.pdf" class="govuk-link">Strategic Plan 2022-2025</a>, Equality and Human Rights Commission (March 2022) <a href="#fnref:20" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:21" role="doc-endnote">
      <p><a href="https://www.gov.uk/government/publications/software-and-ai-as-a-medical-device-change-programme/software-and-ai-as-a-medical-device-change-programme" class="govuk-link">Software and AI as a medical device change programme</a>, Medicines and Healthcare products Regulatory Agency (September 2021) <a href="#fnref:21" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:22" role="doc-endnote">
      <p><a href="https://www.gov.uk/government/consultations/consultation-on-the-future-regulation-of-medical-devices-in-the-united-kingdom" class="govuk-link">Consultation (now closed) on the future regulation of medical devices in the UK</a>, Medicines and Healthcare products Regulatory Agency (October/November 2021) <a href="#fnref:22" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:23" role="doc-endnote">
      <p><a rel="external" href="https://www.hse.gov.uk/research/content/science-evidence-delivery-20-23.pdf" class="govuk-link">Science and Evidence Delivery Plan 2020-2023</a>, Health and Safety Executive <a href="#fnref:23" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:24" role="doc-endnote">
      <p>The <a href="https://www.gov.uk/government/collections/the-digital-regulation-cooperation-forum" class="govuk-link">Digital Regulation Cooperation Forum</a> (DRCF) comprises the Competition and Markets Authority (CMA), the Information Commissioner’s Office (ICO), the Office for Communications (Ofcom) and the Financial Conduct Authority (FCA). It was established to build on the strong working relationships between these organisations and to establish a greater level of cooperation, given the distinctive challenges posed by digital regulation. <a href="#fnref:24" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:25" role="doc-endnote">
      <p><a href="https://www.gov.uk/government/publications/findings-from-the-drcf-algorithmic-processing-workstream-spring-2022" class="govuk-link">Findings from the DRCF algorithmic processing workstream - Spring 2022</a>, DRCF (April 2022) <a href="#fnref:25" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:26" role="doc-endnote">
      <p><a rel="external" href="https://www.bankofengland.co.uk/research/fintech/ai-public-private-forum" class="govuk-link">The AI Public-Private Forum: Final Report</a>, Bank of England and Financial Conduct Authority’s Artificial Intelligence Public-Private Forum (February 2022) <a href="#fnref:26" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:27" role="doc-endnote">
      <p>Standards are often used as “soft law” in codes of conduct/practice and binding/non-binding guidance, but it can also be designated as voluntary tools to show legal compliance. See <a href="https://www.gov.uk/guidance/designated-standards" class="govuk-link">Designated standards guidance</a>. <a href="#fnref:27" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:28" role="doc-endnote">
      <p><a href="https://www.gov.uk/government/organisations/central-digital-and-data-office" class="govuk-link">Central Digital and Data Office (CDDO)</a> <a href="#fnref:28" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:29" role="doc-endnote">
      <p><a href="https://www.gov.uk/government/publications/ai-barometer-2021/ai-barometer-part-1-summary-of-findings" class="govuk-link">AI Barometer Part 1 - Summary of Findings</a>, Centre for Data Ethics and Innovation (December 2021) <a href="#fnref:29" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:30" role="doc-endnote">
      <p>For example, while the Information Commissioner’s Office has the power to issue fines on parties that breach data protection law, the Equality and Human Rights Commission cannot issue fines on parties that breach equality law. The Equality and Human Rights Commission can, however, pursue damages in judicial review proceedings. <a href="#fnref:30" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:31" role="doc-endnote">
      <p>70% of surveyed businesses said they “desired more information to help them navigate the often complex legal requirements around data collection, use and sharing”. <a href="https://www.gov.uk/government/publications/ai-barometer-2021" class="govuk-link">AI Barometer 2021</a>, Centre for Data Ethics and Innovation (2021) <a href="#fnref:31" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:32" role="doc-endnote">
      <p>31% of respondents feel concerned that the benefits of data and AI use will not be felt equally across society. Public attitudes to data and <a href="https://www.gov.uk/government/publications/public-attitudes-to-data-and-ai-tracker-survey" class="govuk-link">AI: Tracker Survey</a>, Centre for Data Ethics and Innovation (2022) <a href="#fnref:32" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:33" role="doc-endnote">
      <p>In November 2021, Meta (previously known as Facebook) announced it was “shutting down the Facial Recognition system on Facebook” citing unclear rules from regulators. Similarly, IBM is to stop offering its own facial recognition software for certain activities including mass surveillance. <a href="#fnref:33" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:34" role="doc-endnote">
      <p><a rel="external" href="https://digital-strategy.ec.europa.eu/en/library/proposal-regulation-laying-down-harmonised-rules-artificial-intelligence" class="govuk-link">Proposal for a Regulation laying down harmonised rules on artificial intelligence</a>, European Commission (April 2021) <a href="#fnref:34" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:35" role="doc-endnote">
      <p><a rel="external" href="https://openai.com/dall-e-2/" class="govuk-link">DALL.E 2</a>, Open AI <a href="#fnref:35" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:36" role="doc-endnote">
      <p><a rel="external" href="https://www.nature.com/articles/d41586-020-03157-9" class="govuk-link">Artificial intelligence is improving the detection of lung cancer</a>, Nature (November 2020) <a href="#fnref:36" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:37" role="doc-endnote">
      <p><a rel="external" href="https://www.nature.com/articles/s41586-022-04448-z" class="govuk-link">Restoring and attributing ancient texts using deep neural networks</a>, Nature (March 2022) <a href="#fnref:37" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:40" role="doc-endnote">
      <p>For example, the <a rel="external" href="https://www.lawcom.gov.uk/project/automated-vehicles/" class="govuk-link">Law Commission</a> recommends that self-driving vehicles will represent a shift in responsibility from driver to manufacturer and operators. <a href="#fnref:40" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a> <a href="#fnref:40:1" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced 2">↩<sup>2</sup></a></p>
    </li>
    <li id="fn:41" role="doc-endnote">
      <p>A Large Language Model (LLM) is an AI model which is trained on vast amounts of data - often with billions of parameters - which can produce content, such as text or visual output, on the basis of a short prompt from a user. Some examples are Open AI’s GPT-3, DeepMind’s Chinchilla, and Google’s LaMDA. <a href="#fnref:41" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
    <li id="fn:43" role="doc-endnote">
      <p>For example, the DCMS Secretary of State has already written to the Digital Regulation Cooperation Forum requesting their insights on AI governance. <a href="#fnref:43" class="govuk-link" role="doc-backlink" aria-label="go to where this is referenced">↩</a></p>
    </li>
  </ol>
</div>
</div>


</div>
</div>
    </div>
  </div>

  <div class="govuk-grid-row">
    <a class="govuk-link app-c-back-to-top govuk-!-display-none-print" href="#contents">
    <svg class="app-c-back-to-top__icon" xmlns="http://www.w3.org/2000/svg" width="13" height="17" viewbox="0 0 13 17" aria-hidden="true" focusable="false">
      <path fill="currentColor" d="M6.5 0L0 6.5 1.4 8l4-4v12.7h2V4l4.3 4L13 6.4z"></path>
    </svg>
    Back to top
</a>

  </div>
</div>


    </main>
  </div>

      <div class="govuk-width-container">
        
<div class="gem-c-feedback govuk-!-display-none-print" data-module="feedback ga4-event-tracker">
  
<div class="gem-c-feedback__prompt gem-c-feedback__js-show js-prompt" tabindex="-1">
  <div class="gem-c-feedback__prompt-content">
    <div class="gem-c-feedback__prompt-questions js-prompt-questions" hidden>
      <div class="gem-c-feedback__prompt-question-answer">
        <h2 class="gem-c-feedback__prompt-question">Is this page useful?</h2>
        <ul class="gem-c-feedback__option-list">
          <li class="gem-c-feedback__option-list-item govuk-visually-hidden" hidden>
            <a class="gem-c-feedback__prompt-link" role="button" hidden="hidden" aria-hidden="true" href="/contact/govuk">
              Maybe
</a>          </li>
          <li class="gem-c-feedback__option-list-item">
            <button class="govuk-button gem-c-feedback__prompt-link js-page-is-useful" data-ga4-event='{"event_name":"form_submit","type":"feedback","text":"Yes","section":"Is this page useful?","tool_name":"Is this page useful?"}'>
              Yes <span class="govuk-visually-hidden">this page is useful</span>
</button>          </li>
          <li class="gem-c-feedback__option-list-item">

            <button class="govuk-button gem-c-feedback__prompt-link js-toggle-form js-page-is-not-useful" aria-controls="page-is-not-useful" aria-expanded="false" data-ga4-event='{"event_name":"form_submit","type":"feedback","text":"No","section":"Is this page useful?","tool_name":"Is this page useful?"}'>
              No <span class="govuk-visually-hidden">this page is not useful</span>
</button>          </li>
        </ul>
      </div>
    </div>

    <div class="gem-c-feedback__prompt-questions gem-c-feedback__prompt-success js-prompt-success" role="alert" hidden>
      Thank you for your feedback
    </div>

    <div class="gem-c-feedback__prompt-questions gem-c-feedback__prompt-questions--something-is-wrong js-prompt-questions" hidden>
      <button class="govuk-button gem-c-feedback__prompt-link js-toggle-form js-something-is-wrong" aria-expanded="false" aria-controls="something-is-wrong" data-ga4-event='{"event_name":"form_submit","type":"feedback","text":"Report a problem with this page","section":"Is this page useful?","tool_name":"Is this page useful?"}'>
        Report a problem with this page
</button>    </div>
  </div>
</div>

  
<form action="https://www.gov.uk/contact/govuk/problem_reports" id="something-is-wrong" class="gem-c-feedback__form js-feedback-form" method="post" hidden>

  <div class="govuk-grid-row">
    <div class="govuk-grid-column-two-thirds">
      <div class="gem-c-feedback__error-summary gem-c-feedback__js-show js-errors" tabindex="-1" hidden></div>

      <input type="hidden" name="url" value="https://www.gov.uk/government/publications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement">

      <h3 class="gem-c-feedback__form-heading">Help us improve GOV.UK</h3>
      <p id="feedback_explanation" class="gem-c-feedback__form-paragraph">Don’t include personal or financial information like your National Insurance number or credit card details.</p>

      <div class="govuk-visually-hidden" aria-hidden="true">
        <label for="giraffe">This field is for robots only. Please leave blank</label>
        <input id="giraffe" name="giraffe" type="text" pattern=".{0}" tabindex="-1" autocomplete="off">
      </div>

      
<div class="gem-c-textarea govuk-form-group govuk-!-margin-bottom-6">
    
  <label for="textarea-aebb5032" class="gem-c-label govuk-label">What were you doing?</label>





  <textarea name="what_doing" class="govuk-textarea" id="textarea-aebb5032" rows="3" spellcheck="true" aria-describedby="feedback_explanation">
</textarea>
    
</div>

      
<div class="gem-c-textarea govuk-form-group govuk-!-margin-bottom-6">
    
  <label for="textarea-3c2cd451" class="gem-c-label govuk-label">What went wrong?</label>





  <textarea name="what_wrong" class="govuk-textarea" id="textarea-3c2cd451" rows="3" spellcheck="true">
</textarea>
    
</div>


      


  <button class="gem-c-button govuk-button" type="submit" data-ga4-event='{"event_name":"form_submit","type":"feedback","text":"Send","section":"Help us improve GOV.UK","tool_name":"Help us improve GOV.UK"}'>Send</button>



      <button class="govuk-button govuk-button--secondary gem-c-feedback__close gem-c-feedback__js-show js-close-form" aria-controls="something-is-wrong" aria-expanded="true">
        Cancel
      </button>
    </div>
  </div>
</form>


<script nonce="dzhAn4qEyLpall3k5dxYdg==">
//<![CDATA[
  document.addEventListener("DOMContentLoaded", function () {
    var input = document.querySelector("#giraffe"),
      form = document.querySelector("#something-is-wrong")

    form.addEventListener("submit", spamCapture);

    function spamCapture(e) {
      if (input.value.length !== 0) return;
      e.preventDefault();
    }
  });

//]]>
</script>
  
<div id="page-is-not-useful" class="gem-c-feedback__form gem-c-feedback__form--email gem-c-feedback__js-show js-feedback-form">
  <div class="govuk-grid-row">
    <div class="govuk-grid-column-two-thirds" id="survey-wrapper">
      <div class="gem-c-feedback__error-summary js-errors" tabindex="-1" hidden></div>

      <h3 class="gem-c-feedback__form-heading">Help us improve GOV.UK</h3>
      <p id="survey_explanation" class="gem-c-feedback__form-paragraph">
        To help us improve GOV.UK, we’d like to know more about your visit today.
        <a href="https://www.smartsurvey.co.uk/s/gov-uk-banner/?c=no-js" class="govuk-link" target="_blank" rel="noopener noreferrer external">Please fill in this survey (opens in a new tab)</a>.
      </p>
      <button class="govuk-button govuk-button--secondary js-close-form" aria-controls="page-is-not-useful" aria-expanded="true" hidden>
        Cancel
      </button>
    </div>
  </div>
</div>

</div>

      </div>

      <footer class="gem-c-layout-footer govuk-footer gem-c-layout-footer--border" role="contentinfo" data-module="ga4-link-tracker">
  <div class="govuk-width-container">
      <div class="govuk-footer__navigation">
            <div class="govuk-grid-column-two-thirds govuk-!-display-none-print">
              <h2 class="govuk-footer__heading govuk-heading-m">Services and information</h2>
                <ul class="govuk-footer__list govuk-footer__list--columns-2">
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"1","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/benefits">Benefits</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"2","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/births-deaths-marriages">Births, death, marriages and care</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"3","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/business">Business and self-employed</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"4","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/childcare-parenting">Childcare and parenting</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"5","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/citizenship">Citizenship and living in the UK</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"6","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/justice">Crime, justice and the law</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"7","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/disabilities">Disabled people</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"8","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/driving">Driving and transport</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"9","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/education">Education and learning</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"10","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/employing-people">Employing people</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"11","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/environment-countryside">Environment and countryside</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"12","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/housing-local-services">Housing and local services</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"13","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/tax">Money and tax</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"14","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/abroad">Passports, travel and living abroad</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"15","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/visas-immigration">Visas and immigration</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"16","index_section":"1","index_section_count":"5","index_total":"16","section":"Services and information"}' href="https://www.gov.uk/browse/working">Working, jobs and pensions</a>
                      </li>
                </ul>
            </div>
            <div class="govuk-grid-column-one-third govuk-!-display-none-print">
              <h2 class="govuk-footer__heading govuk-heading-m">Government activity</h2>
                <ul class="govuk-footer__list govuk-footer__list--columns-1">
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"1","index_section":"2","index_section_count":"5","index_total":"8","section":"Government activity"}' href="https://www.gov.uk/government/organisations">Departments</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"2","index_section":"2","index_section_count":"5","index_total":"8","section":"Government activity"}' href="https://www.gov.uk/search/news-and-communications">News</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"3","index_section":"2","index_section_count":"5","index_total":"8","section":"Government activity"}' href="https://www.gov.uk/search/guidance-and-regulation">Guidance and regulation</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"4","index_section":"2","index_section_count":"5","index_total":"8","section":"Government activity"}' href="https://www.gov.uk/search/research-and-statistics">Research and statistics</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"5","index_section":"2","index_section_count":"5","index_total":"8","section":"Government activity"}' href="https://www.gov.uk/search/policy-papers-and-consultations">Policy papers and consultations</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"6","index_section":"2","index_section_count":"5","index_total":"8","section":"Government activity"}' href="https://www.gov.uk/search/transparency-and-freedom-of-information-releases">Transparency</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"7","index_section":"2","index_section_count":"5","index_total":"8","section":"Government activity"}' href="https://www.gov.uk/government/how-government-works">How government works</a>
                      </li>
                      <li class="govuk-footer__list-item">
                        <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"8","index_section":"2","index_section_count":"5","index_total":"8","section":"Government activity"}' href="https://www.gov.uk/government/get-involved">Get involved</a>
                      </li>
                </ul>
            </div>
      </div>

      <hr class="govuk-footer__section-break govuk-!-display-none-print">
    <div class="govuk-footer__meta">
      <div class="govuk-footer__meta-item govuk-footer__meta-item--grow">
          <h2 class="govuk-visually-hidden">Support links</h2>
          <ul class="govuk-footer__inline-list govuk-!-display-none-print">
              <li class="govuk-footer__inline-list-item">
                <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"1","index_section":"3","index_section_count":"5","index_total":"8","section":"Support links"}' href="https://www.gov.uk/help">Help</a>
              </li>
              <li class="govuk-footer__inline-list-item">
                <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"2","index_section":"3","index_section_count":"5","index_total":"8","section":"Support links"}' href="https://www.gov.uk/help/privacy-notice">Privacy</a>
              </li>
              <li class="govuk-footer__inline-list-item">
                <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"3","index_section":"3","index_section_count":"5","index_total":"8","section":"Support links"}' href="https://www.gov.uk/help/cookies">Cookies</a>
              </li>
              <li class="govuk-footer__inline-list-item">
                <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"4","index_section":"3","index_section_count":"5","index_total":"8","section":"Support links"}' href="https://www.gov.uk/help/accessibility-statement">Accessibility statement</a>
              </li>
              <li class="govuk-footer__inline-list-item">
                <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"5","index_section":"3","index_section_count":"5","index_total":"8","section":"Support links"}' href="https://www.gov.uk/contact">Contact</a>
              </li>
              <li class="govuk-footer__inline-list-item">
                <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"6","index_section":"3","index_section_count":"5","index_total":"8","section":"Support links"}' href="https://www.gov.uk/help/terms-conditions">Terms and conditions</a>
              </li>
              <li class="govuk-footer__inline-list-item">
                <a class="govuk-footer__link" lang="cy" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"7","index_section":"3","index_section_count":"5","index_total":"8","section":"Support links"}' href="https://www.gov.uk/cymraeg">Rhestr o Wasanaethau Cymraeg</a>
              </li>
              <li class="govuk-footer__inline-list-item">
                <a class="govuk-footer__link" data-ga4-link='{"event_name":"navigation","type":"footer","index_link":"8","index_section":"3","index_section_count":"5","index_total":"8","section":"Support links"}' href="https://www.gov.uk/government/organisations/government-digital-service">Government Digital Service</a>
              </li>
          </ul>
        <svg aria-hidden="true" focusable="false" class="govuk-footer__licence-logo" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 483.2 195.7" height="17" width="41">
          <path fill="currentColor" d="M421.5 142.8V.1l-50.7 32.3v161.1h112.4v-50.7zm-122.3-9.6A47.12 47.12 0 0 1 221 97.8c0-26 21.1-47.1 47.1-47.1 16.7 0 31.4 8.7 39.7 21.8l42.7-27.2A97.63 97.63 0 0 0 268.1 0c-36.5 0-68.3 20.1-85.1 49.7A98 98 0 0 0 97.8 0C43.9 0 0 43.9 0 97.8s43.9 97.8 97.8 97.8c36.5 0 68.3-20.1 85.1-49.7a97.76 97.76 0 0 0 149.6 25.4l19.4 22.2h3v-87.8h-80l24.3 27.5zM97.8 145c-26 0-47.1-21.1-47.1-47.1s21.1-47.1 47.1-47.1 47.2 21 47.2 47S123.8 145 97.8 145"></path>
        </svg>
        <span class="govuk-footer__licence-description" data-ga4-track-links-only data-ga4-link='{"event_name":"navigation","section":"Licence","index_section":"4","index_link":"1","index_section_count":"5","text":"Open Government Licence v3.0","index_total":"1","type":"footer"}'>
          All content is available under the <a class="govuk-footer__link" href="https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/" rel="license">Open Government Licence v3.0</a>, except where otherwise stated
        </span>
      </div>
      <div class="govuk-footer__meta-item" data-ga4-link='{"event_name":"navigation","section":"Copyright","index_section":"5","index_link":"1","index_section_count":"5","text":"© Crown copyright","index_total":"1","type":"footer"}'>
        <a class="govuk-footer__link govuk-footer__copyright-logo" href="https://www.nationalarchives.gov.uk/information-management/re-using-public-sector-information/uk-government-licensing-framework/crown-copyright/">© Crown copyright</a>
      </div>
    </div>
  </div>
</footer>
    <script src="/assets/static/application-7d6d614311ebcb5137ebd31f0d2ae7933e79a5b7ae1c45d22c74de8c51550173.js" type="module"></script>
<script src="/assets/government-frontend/application-da84cd5045ffdd4664d3c3ead0965a61ec77c4065afae4aa0cbd3c562406ef80.js" type="module"></script><script type="application/ld+json">
  {
  "@context": "http://schema.org",
  "@type": "FAQPage",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://www.gov.uk/government/publications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement"
  },
  "name": "Establishing a pro-innovation approach to regulating AI",
  "datePublished": "2022-07-18T10:30:05+01:00",
  "dateModified": "2022-07-20T14:11:12+01:00",
  "text": null,
  "publisher": {
    "@type": "Organization",
    "name": "GOV.UK",
    "url": "https://www.gov.uk",
    "logo": {
      "@type": "ImageObject",
      "url": "https://www.gov.uk/assets/government-frontend/govuk_publishing_components/govuk-logo-b15a4d254746d1642b8187217576d1e8fe50b51352d352fda13eee55d3c1c80a.png"
    }
  },
  "image": [
    "https://www.gov.uk/assets/government-frontend/govuk_publishing_components/govuk-schema-placeholder-1x1-c3d38c0d4fc00005df38a71e1db7097276681d6917bca58f0dc8336a252e1bb3.png",
    "https://www.gov.uk/assets/government-frontend/govuk_publishing_components/govuk-schema-placeholder-4x3-edc38c137a14ecfc3fc83f404090e20dab806dad345c96a1df6a163ee2d1e3aa.png",
    "https://www.gov.uk/assets/government-frontend/govuk_publishing_components/govuk-schema-placeholder-16x9-5dc2d0ea1eb72cd94e66db210ef41b22ce364e7ed09d63a3acc28fda09e27864.png"
  ],
  "author": {
    "@type": "Organization",
    "name": "Department for Science, Innovation and Technology",
    "url": "https://www.gov.uk/government/organisations/department-for-science-innovation-and-technology"
  },
  "mainEntity": [
    {
      "@type": "Question",
      "name": "Ministerial foreword by the Secretary of State for Digital, Culture, Media and Sport",
      "url": "https://www.gov.uk/government/publications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement#ministerial-foreword-by-the-secretary-of-state-for-digital-culture-media-and-sport",
      "acceptedAnswer": {
        "@type": "Answer",
        "url": "https://www.gov.uk/government/publications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement#ministerial-foreword-by-the-secretary-of-state-for-digital-culture-media-and-sport",
        "text": "\u003cfigure class=\"image embedded\"\u003e\u003cdiv class=\"img\"\u003e\u003cimg src=\"https://assets.publishing.service.gov.uk/media/62d7e2edd3bf7f2861b893fc/Nadine_Dorries.jpg\" alt=\"\"\u003e\u003c/div\u003e\u003c/figure\u003e\u003cp\u003eAcross the world, AI is unlocking enormous opportunities, and the UK is at the forefront of these developments. As Secretary of State for the Department of Digital, Culture, Media and Sport, I want the UK to be the best place in the world to found and grow an AI business and to strengthen the UK’s position so we translate AI’s tremendous potential into growth and societal benefits across the UK.\u003c/p\u003e\u003cp\u003eOur regulatory approach will be a key tool in reaching this ambition. A regulatory framework that is proportionate, light-touch and forward-looking is essential to keep pace with the speed of developments in these technologies. Such an approach will drive innovation by offering businesses the clarity and confidence they need to grow while making sure we boost public trust.\u003c/p\u003e\u003cp\u003eGetting this right is necessary for a thriving AI ecosystem and will be a source of international competitive advantage. We will continue to advocate internationally for our vision for a pro-innovation approach to AI regulation recognising that both the opportunities and challenges presented by AI are fundamentally global in nature.\u003c/p\u003e\u003cp\u003eI am therefore pleased to publish this paper which sets out our emerging thinking on our approach to regulating AI. We welcome views on our proposals from across business, civil society, academia and beyond ahead of publishing a White Paper later in the year.\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://www.gov.uk/government/people/nadine-dorries\" class=\"govuk-link\"\u003e\u003cstrong\u003eRt Hon Nadine Dorries MP\u003c/strong\u003e\u003c/a\u003e\n\u003cbr\u003e\nSecretary of State for Digital, Culture, Media and Sport\u003c/p\u003e"
      }
    },
    {
      "@type": "Question",
      "name": "Ministerial foreword by the Secretary of State for Business, Energy and Industrial Strategy",
      "url": "https://www.gov.uk/government/publications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement#ministerial-foreword-by-the-secretary-of-state-for-business-energy-and-industrial-strategy",
      "acceptedAnswer": {
        "@type": "Answer",
        "url": "https://www.gov.uk/government/publications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement#ministerial-foreword-by-the-secretary-of-state-for-business-energy-and-industrial-strategy",
        "text": "\u003cfigure class=\"image embedded\"\u003e\u003cdiv class=\"img\"\u003e\u003cimg src=\"https://assets.publishing.service.gov.uk/media/62d7e2eee90e071e7a074972/KK.jpg\" alt=\"\"\u003e\u003c/div\u003e\u003c/figure\u003e\u003cp\u003eThe UK is already a global superpower in many aspects of AI, from our world-leading academic institutions, to a well-established business environment that supports AI businesses of all sizes. AI is catalysing innovation across sectors from healthcare to agriculture, and is driving forward new research, scientific breakthroughs, and growth across the nation.\u003c/p\u003e\u003cp\u003eBut we must not be complacent. It is essential that we maximise the full opportunities which AI can bring to the UK, including by meeting our target of total R\u0026amp;D investment in the UK reaching 2.4% of GDP by 2027. We must achieve this while ensuring that we can build consumer, citizen and investor confidence in our regulatory framework for the ethical and responsible use of AI in our society and economy.\u003c/p\u003e\u003cp\u003eOur ambition is to support responsible innovation in AI - unleashing the full potential of new technologies, while keeping people safe and secure. This policy paper sets out how the government intends to strike this balance: by developing a pro-innovation, light-touch and coherent regulatory framework, which creates clarity for businesses and drives new investment. We want this framework to be adaptable to AI’s vast range of uses across different industries, and support our world-class regulators in addressing new challenges in a way that catalyses innovation and growth.\u003c/p\u003e\u003cp\u003eWe welcome views from AI practitioners and disruptors across the business landscape so that we can take full advantage of AI’s revolutionary potential and continue driving global leadership on AI regulation.\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://www.gov.uk/government/people/kwasi-kwarteng\" class=\"govuk-link\"\u003e\u003cstrong\u003eRt Hon Kwasi Kwarteng MP\u003c/strong\u003e\u003c/a\u003e\n\u003cbr\u003e\nSecretary of State for Business, Energy and Industrial Strategy\u003c/p\u003e"
      }
    },
    {
      "@type": "Question",
      "name": "Executive summary",
      "url": "https://www.gov.uk/government/publications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement#executive-summary",
      "acceptedAnswer": {
        "@type": "Answer",
        "url": "https://www.gov.uk/government/publications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement#executive-summary",
        "text": "\u003cp\u003eIn the \u003ca href=\"https://www.gov.uk/government/publications/national-ai-strategy\" class=\"govuk-link\"\u003eNational AI Strategy\u003c/a\u003e, the government set out an ambitious ten-year plan for the UK to remain a global AI superpower. The UK is already a leader in many aspects of AI, with a thriving ecosystem and a strong track record of innovation. But there is more to do to harness the enormous economic and societal benefits of AI while also addressing the complex challenges it presents.\u003c/p\u003e\u003cp\u003eEstablishing clear, innovation-friendly and flexible approaches to regulating AI will be core to achieving our ambition to unleash growth and innovation while safeguarding our fundamental values and keeping people safe and secure. Our approach will drive business confidence, promote investment, boost public trust and ultimately drive productivity across the economy.\u003c/p\u003e\u003cp\u003eThe UK has a world leading regulatory regime - known for its effective rule of law and support for innovation. We need to make sure that our regulatory regime is able to keep pace with and respond to the new and distinct challenges and opportunities posed by AI. This is key to remaining internationally competitive.\u003c/p\u003e\u003cp\u003eWe are therefore proposing to establish a pro-innovation framework for regulating AI which is underpinned by a set of cross-sectoral principles tailored to the specific characteristics of AI, and is:\u003c/p\u003e\u003cul\u003e\n  \u003cli\u003e\n\u003cstrong\u003eContext-specific.\u003c/strong\u003e We propose to regulate AI based on its use and the impact it has on individuals, groups and businesses within a particular context, and to delegate responsibility for designing and implementing proportionate regulatory responses to regulators. This will ensure that our approach is targeted and supports innovation.\u003c/li\u003e\n  \u003cli\u003e\n\u003cstrong\u003ePro-innovation and risk-based.\u003c/strong\u003e We propose to focus on addressing issues where there is clear evidence of real risk or missed opportunities. We will ask that regulators focus on high risk concerns rather than hypothetical or low risks associated with AI. We want to encourage innovation and avoid placing unnecessary barriers in its way.\u003c/li\u003e\n  \u003cli\u003e\n\u003cstrong\u003eCoherent.\u003c/strong\u003e We propose to establish a set of cross-sectoral principles tailored to the distinct characteristics of AI, with regulators asked to interpret, prioritise and implement these principles within their sectors and domains. In order to achieve coherence and support innovation by making the framework as easy as possible to navigate, we will look for ways to support and encourage regulatory coordination - for example, by working closely with the Digital Regulation Cooperation Forum (DRCF) and other regulators and stakeholders.\u003c/li\u003e\n  \u003cli\u003e\n\u003cstrong\u003eProportionate and adaptable.\u003c/strong\u003e We propose to set out the cross-sectoral principles on a non-statutory basis in the first instance so our approach remains adaptable - although we will keep this under review. We will ask that regulators consider lighter touch options, such as guidance or voluntary measures, in the first instance. As far as possible, we will also seek to work with existing processes rather than create new ones.\u003c/li\u003e\n\u003c/ul\u003e\u003cp\u003eThe approach outlined above is aligned with the regulatory principles set out in the Better Regulation Framework, which emphasise proportionate regulation. It is also aligned with the government’s vision set out through the Plan for Digital Regulation. It describes how we will take a pro-innovation approach to regulating digital technologies, which will deliver on the UK’s desire to establish a more nimble regulatory framework now that we have left the EU.\u003c/p\u003e\u003cp\u003eWe recognise the cross-border nature of the digital ecosystem and the importance of the international AI market, and will continue to work closely with key partners on the global stage to shape global approaches to AI regulation. We will support cooperation on key issues, including through the Council of Europe, OECD working groups and the Global Partnership on AI and through global standards bodies such as ISO and IEC.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe welcome stakeholders’ views on our proposed approach to regulating AI.\u003c/strong\u003e Ahead of setting out further detail on our framework and implementation plans through the forthcoming White Paper, we are keen to seek reflections from across the AI ecosystem, wider industry, civil society, academia and beyond on the approach set out here to inform how we best shape the rules that will form part of the wider approach to how we regulate AI.\u003c/p\u003e"
      }
    },
    {
      "@type": "Question",
      "name": "Context",
      "url": "https://www.gov.uk/government/publications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement#context",
      "acceptedAnswer": {
        "@type": "Answer",
        "url": "https://www.gov.uk/government/publications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement#context",
        "text": "\u003cp\u003eThe UK has a thriving AI ecosystem. In 2021, the UK was first in Europe and third in the world for private investment in AI companies ($4.65 billion) and newly funded AI companies (49).\u003csup id=\"fnref:1\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:1\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 1]\u003c/a\u003e\u003c/sup\u003e The UK is also first in Europe for the number of AI publications in 2021, and only topped by China, the USA and India.\u003csup id=\"fnref:2\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:2\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 2]\u003c/a\u003e\u003c/sup\u003e\u003c/p\u003e\u003cp\u003eAI is unlocking huge benefits across our economy and society. In Glasgow AI is being used to track asbestos cancer tumours,\u003csup id=\"fnref:3\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:3\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 3]\u003c/a\u003e\u003c/sup\u003e in the Southeast to help people facing fuel poverty,\u003csup id=\"fnref:4\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:4\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 4]\u003c/a\u003e\u003c/sup\u003e in Belfast to improve animal welfare on dairy farms,\u003csup id=\"fnref:5\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:5\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 5]\u003c/a\u003e\u003c/sup\u003e and across the country by HM Land Registry to compare property transfer deeds.\u003csup id=\"fnref:6\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:6\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 6]\u003c/a\u003e\u003c/sup\u003e AI is also being applied to fundamental challenges in biology that will revolutionise drug discovery,\u003csup id=\"fnref:7\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:7\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 7]\u003c/a\u003e\u003c/sup\u003e and is set to impact the future of mobility\u003csup id=\"fnref:8\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:8\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 8]\u003c/a\u003e\u003c/sup\u003e and an accelerated reduction in emissions.\u003csup id=\"fnref:9\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:9\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 9]\u003c/a\u003e\u003c/sup\u003e\u003c/p\u003e\u003cp\u003eAlongside the benefits that AI brings, it also creates a range of new and accelerated risks, such as those associated with the use of AI in critical infrastructure to algorithmic bias. It also presents new questions for governments and society; for example, how should we protect existing rights in the context of systems that use facial recognition, or from large language models trained on content harvested from the web? How do we ensure commercial customers can confidently buy ‘off the shelf’ systems that are evidenced, tested and robust?\u003c/p\u003e\u003cp\u003eThe answer to these questions will ultimately rely on actions by governments, regulators, technical standards bodies\u003csup id=\"fnref:10\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:10\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 10]\u003c/a\u003e\u003c/sup\u003e and industry. Together these form an overall approach to AI regulation.\u003csup id=\"fnref:11\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:11\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 11]\u003c/a\u003e\u003c/sup\u003e\u003c/p\u003e\u003ch3 id=\"overview-of-the-existing-regulatory-landscape\"\u003eOverview of the existing regulatory landscape\u003c/h3\u003e\u003cp\u003eThe success of our AI ecosystem is in part down to the UK’s reputation for the quality of its regulators and its rule of law. This includes the transparency of the UK’s regulatory regime, the detailed scrutiny that proposed regulation receives and comprehensive impact assessments. This certainty around how new regulation will evolve has promoted private investment in the UK for developing new technologies and has allowed AI innovation to thrive.\u003csup id=\"fnref:12\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:12\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 12]\u003c/a\u003e\u003c/sup\u003e,\u003csup id=\"fnref:13\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:13\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 13]\u003c/a\u003e\u003c/sup\u003e To maintain our leading regulatory approach, we must make sure that the rules that govern the development and use of AI keep pace with the evolving implications of the technologies.\u003c/p\u003e\u003cp\u003eWhile there are no UK laws that were explicitly written to regulate AI, it is partially regulated through a patchwork of legal and regulatory requirements built for other purposes which now also capture uses of AI technologies. For example,\u003csup id=\"fnref:14\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:14\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 14]\u003c/a\u003e\u003c/sup\u003e UK data protection law includes specific requirements around ‘automated decision-making’ and the broader processing of personal data,\u003csup id=\"fnref:15\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:15\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 15]\u003c/a\u003e\u003c/sup\u003e which also covers processing for the purpose of developing and training AI technologies. The upcoming Online Safety Bill also has provisions specifically concerning the design and use of algorithms.\u003c/p\u003e\u003cp\u003eSome UK regulators are also starting to take action to support the responsible use of AI. For example:\u003c/p\u003e\u003cul\u003e\n  \u003cli\u003ethe Information Commissioner’s Office (ICO) has issued multiple pieces of guidance, such as Guidance on AI and Data Protection\u003csup id=\"fnref:16\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:16\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 16]\u003c/a\u003e\u003c/sup\u003e, Explaining decisions made with AI,\u003csup id=\"fnref:17\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:17\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 17]\u003c/a\u003e\u003c/sup\u003eAI and Data Protection Risk Toolkit,\u003csup id=\"fnref:18\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:18\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 18]\u003c/a\u003e\u003c/sup\u003e AI Auditing Framework and AI blog resources\u003csup id=\"fnref:19\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:19\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 19]\u003c/a\u003e\u003c/sup\u003e\n\u003c/li\u003e\n  \u003cli\u003ethe Equality and Human Rights Commission has identified AI as a strategic priority in its Strategic Plan 2022-2025, and has committed to providing guidance on how the Equality Act applies to the use of new technologies, such as AI, in automated decision-making\u003csup id=\"fnref:20\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:20\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 20]\u003c/a\u003e\u003c/sup\u003e\n\u003c/li\u003e\n  \u003cli\u003ethe Medicines and Healthcare products Regulatory Agency has launched a Software and AI as a Medical Device Change Programme\u003csup id=\"fnref:21\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:21\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 21]\u003c/a\u003e\u003c/sup\u003e and consulted on possible changes to the regulatory framework\u003csup id=\"fnref:22\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:22\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 22]\u003c/a\u003e\u003c/sup\u003e to ensure the requirements provide a high degree of assurance that these devices are acceptably safe and function as intended.\u003c/li\u003e\n  \u003cli\u003ethe Health and Safety Executive committed to develop collaborative research with industry and academia in its Science and Evidence Delivery Plan 2020-2023, to determine a clear understanding of the health and safety implications of AI in the workplace\u003csup id=\"fnref:23\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:23\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 23]\u003c/a\u003e\u003c/sup\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\u003cp\u003eRegulators are also working together to understand the impact AI technologies could have on our economy and society. The Digital Regulation Cooperation Forum (DRCF)\u003csup id=\"fnref:24\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:24\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 24]\u003c/a\u003e\u003c/sup\u003e has been exploring the impact of algorithms across their industries and regulatory remits. It recently published the outputs of its first two research projects looking at the harms and benefits posed by algorithmic processing (including the use of AI), and at the merits of algorithmic auditing.\u003csup id=\"fnref:25\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:25\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 25]\u003c/a\u003e\u003c/sup\u003e In addition, the Bank of England and the Financial Conduct Authority established the Artificial Intelligence Public-Private Forum (AIPPF) to further dialogue on AI innovation in financial services between the public and private sectors. It recently published its report of this work.\u003csup id=\"fnref:26\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:26\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 26]\u003c/a\u003e\u003c/sup\u003e\u003c/p\u003e\u003cp\u003eStandards can also play a key part in developing a coherent regulatory approach, and the government is also already taking steps to develop world leading AI standards in the UK. In January 2022, the Department for Digital, Culture, Media and Sport (DCMS) \u003ca href=\"https://www.gov.uk/government/news/new-uk-initiative-to-shape-global-standards-for-artificial-intelligence\" class=\"govuk-link\"\u003eannounced\u003c/a\u003e the pilot of an AI Standards Hub to increase UK engagement in the development of global technical standards for AI. Multiple global standards development organisations (SDOs) have already published AI-specific standards, and more are under development. The Hub will create practical tools and bring the UK’s multi-stakeholder AI community together to ensure that global AI standards are shaped by a wide range of experts, to deliver the tools needed for AI governance, in line with our values. \u003csup id=\"fnref:27\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:27\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 27]\u003c/a\u003e\u003c/sup\u003e In November 2021, the Central Digital and Data Office\u003csup id=\"fnref:28\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:28\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 28]\u003c/a\u003e\u003c/sup\u003e (CDDO) \u003ca href=\"https://www.gov.uk/government/news/uk-government-publishes-pioneering-standard-for-algorithmic-transparency\" class=\"govuk-link\"\u003ealso published\u003c/a\u003e one of the world’s first national algorithmic transparency standards to strengthen trust in government use of algorithms and AI.\u003c/p\u003e\u003cp\u003eAssurance also plays an important role in complementing our regulatory approach. The UK’s Centre for Data Ethics and Innovation (CDEI) highlighted the need for robust AI assurance tools and services to ensure that stakeholders can understand the performance, risk and compliance of AI. In December 2021, the CDEI \u003ca href=\"https://www.gov.uk/government/publications/the-roadmap-to-an-effective-ai-assurance-ecosystem\" class=\"govuk-link\"\u003epublished\u003c/a\u003e a roadmap towards building a world-leading AI assurance ecosystem in the UK, and is now delivering a programme to ensure that the UK capitalises on its strengths in professional and legal services to lead the growth of this nascent industry.\u003c/p\u003e\u003ch3 id=\"key-challenges\"\u003eKey Challenges\u003c/h3\u003e\u003cp\u003eThe proliferation of activity; voluntary, regulatory and quasi-regulatory, introduces new challenges that we must take action to address. Examples include:\u003c/p\u003e\u003cul\u003e\n  \u003cli\u003e\n\u003cstrong\u003eA lack of clarity:\u003c/strong\u003e Stakeholders\u003csup id=\"fnref:29\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:29\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 29]\u003c/a\u003e\u003c/sup\u003e often highlight the ambiguity of the UK’s legal frameworks and application of regulatory bodies to AI, given these have not been developed specifically with AI technologies and its applications in mind. The extent to which UK laws apply to AI is often a matter of interpretation, making them hard to navigate. This is particularly an issue for smaller businesses who may not have any legal support.\u003c/li\u003e\n  \u003cli\u003e\n\u003cstrong\u003eOverlaps:\u003c/strong\u003e Stakeholders also note the risk that laws and regulators’ remits may regulate the same issue for the same reason and this can exacerbate this lack of clarity. This could lead to unnecessary, contradictory or confusing layers of regulation when multiple regulators oversee an organisation’s use of the same AI for the same purpose.\u003c/li\u003e\n  \u003cli\u003e\n\u003cstrong\u003eInconsistency:\u003c/strong\u003e There are differences between the powers of regulators to address the use of AI within their remit\u003csup id=\"fnref:30\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:30\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 30]\u003c/a\u003e\u003c/sup\u003e as well as the extent to which they have started to do so. AI technologies used in different sectors are therefore subject to different controls. While in some instances there will be a clear rationale for this, it can further compound an overall lack of clarity.\u003c/li\u003e\n  \u003cli\u003e\n\u003cstrong\u003eGaps in our approach:\u003c/strong\u003e As current UK legislation has not been developed with AI in mind, there may be current risks that are already inadequately addressed, and future risks associated with widespread use of AI that we need to prepare for. For example, around the need for improved transparency and explainability in relation to decisions made by AI, incentivising developers to prioritise safety and robustness of AI systems, and clarifying actors’ responsibilities. There is also concern that AI will amplify wider systemic and societal risks, for instance AI’s impact on public debate and democracy, with its ability to create synthetic media such as deepfakes.\u003c/li\u003e\n\u003c/ul\u003e\u003cp\u003eThese issues across the regulatory landscape risk undermining consumer trust, harming business confidence and ultimately limiting growth and innovation across the AI ecosystem, including in the public sector.\u003csup id=\"fnref:31\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:31\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 31]\u003c/a\u003e\u003c/sup\u003e,\u003csup id=\"fnref:32\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:32\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 32]\u003c/a\u003e\u003c/sup\u003e,\u003csup id=\"fnref:33\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:33\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 33]\u003c/a\u003e\u003c/sup\u003e By taking action to improve clarity and coherence, we have an opportunity to establish an internationally competitive regulatory approach that drives innovation and cements the UK’s position as an AI leader.\u003c/p\u003e"
      }
    },
    {
      "@type": "Question",
      "name": "The scope",
      "url": "https://www.gov.uk/government/publications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement#the-scope",
      "acceptedAnswer": {
        "@type": "Answer",
        "url": "https://www.gov.uk/government/publications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement#the-scope",
        "text": "\u003cp\u003eTo develop a clear framework for regulating AI, it will be critical to clarify its scope. However, there is currently little consensus on a general definition of AI, either within the scientific community or across national or international organisations.\u003c/p\u003e\u003cp\u003eAI is a general purpose technology like electricity, the internet and the combustion engine. As AI evolves, it will touch on many areas of life with transformative implications - although the precise impact of this technology will vary greatly according to its context and application.\u003c/p\u003e\u003cp\u003eThe EU has grounded its approach in the product safety regulation of the Single Market, and as such has set out a relatively fixed definition in its legislative proposals.\u003csup id=\"fnref:34\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:34\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 34]\u003c/a\u003e\u003c/sup\u003e Whilst such an approach can support efforts to harmonise rules across multiple countries, we do not believe this approach is right for the UK. We do not think that it captures the full application of AI and its regulatory implications. Our concern is that this lack of granularity could hinder innovation.\u003c/p\u003e\u003cp\u003eAn alternative approach would be to put no boundaries on what constitutes AI, and leave regulators or relevant bodies to decide what technology and systems are in scope as they see fit. While such an approach would offer maximum flexibility, it raises the risk that businesses and the public would not have a consistent view of what is and is not the subject of regulation. A further risk is that any scope becomes defined via case law in the absence of a definition, which may vary by sector - and could add to further confusion.\u003c/p\u003e\u003cp\u003eOur preferred approach therefore is to set out the core characteristics of AI to inform the scope of the AI regulatory framework but allow regulators to set out and evolve more detailed definitions of AI according to their specific domains or sectors. This is in line with the government’s view that we should regulate the use of AI rather than the technology itself - and a detailed universally applicable definition is therefore not needed. Rather, by setting out these core characteristics, developers and users can have greater certainty about scope and the nature of UK regulatory concerns while still enabling flexibility - recognising that AI may take forms we cannot easily define today - while still supporting coordination and coherence.\u003c/p\u003e\u003ch3 id=\"defining-the-core-characteristics-of-ai\"\u003eDefining the core characteristics of AI\u003c/h3\u003e\u003cp\u003eAI can have a wider number of characteristics and capabilities, depending on the techniques used and specifics of the use case. However, in terms of regulation, there are two key characteristics which underlie distinct regulatory issues which existing regulation may not be fully suited to address, and form the basis of the scope of this work:\u003c/p\u003e\u003ch4 id=\"the-adaptiveness-of-the-technology---explaining-intent-or-logic\"\u003eThe ‘adaptiveness’ of the technology - explaining intent or logic\u003c/h4\u003e\u003cp\u003eAI systems often partially operate on the basis of instructions which have not been expressly programmed with human intent, having instead been ‘learnt’ on the basis of a variety of techniques;\u003c/p\u003e\u003cp\u003eAI systems are often ‘trained’ - once or continually - on data, and execute according to patterns and connections which are not easily discernible to humans. This ability underscores the power of modern AI, enabling it to produce incredibly intricate artwork based on a paragraph of text input,\u003csup id=\"fnref:35\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:35\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 35]\u003c/a\u003e\u003c/sup\u003e diagnose illness in medical scans which are imperceptible to a human,\u003csup id=\"fnref:36\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:36\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 36]\u003c/a\u003e\u003c/sup\u003e or complete missing elements of ancient texts.\u003csup id=\"fnref:37\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:37\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 37]\u003c/a\u003e\u003c/sup\u003e\u003c/p\u003e\u003cp\u003eFor regulatory purposes this means that the logic or intent behind the output of systems can often be extremely hard to explain, or errors and undesirable issues within the training data are replicated. This has potentially serious implications, such as when decisions are being made relating to an individual’s health, wealth or longer term prospects, or when there is an expectation that a decision should be justifiable in easily understood terms - such as legal dispute.\u003c/p\u003e\u003ch4 id=\"the-autonomy-of-the-technology---assigning-responsibility-for-action\"\u003eThe ‘autonomy’ of the technology - assigning responsibility for action\u003c/h4\u003e\u003cp\u003eAI often demonstrates a high degree of autonomy, operating in dynamic and fast-moving environments by automating complex cognitive tasks. Whether that is playing a video game or navigating on public roads, this ability to strategise and react is what fundamentally makes a system ‘intelligent’, but it also means that decisions can be made without express intent or the ongoing control of a human.\u003c/p\u003e\u003cp\u003eWhile AI systems vary greatly, we propose that it is this combination of core characteristics which demands a bespoke regulatory response and informs the scope of our approach to regulating AI.\u003c/p\u003e\u003cdiv class=\"call-to-action\"\u003e\n  \u003cp\u003eTo ensure our system can capture current and future applications of AI, in a way that remains clear, we propose that the government should not set out a universally applicable definition of AI. Instead, we will set out the core characteristics and capabilities of AI and guide regulators to set out more detailed definitions at the level of application.\u003c/p\u003e\n\u003c/div\u003e\u003ch4 id=\"table-1-example-case-studies-the-regulatory-implications-of-ais-adaptive--autonomous-characteristics\"\u003eTable 1. Example case studies: The regulatory implications of AI’s adaptive \u0026amp; autonomous characteristics\u003c/h4\u003e\u003ctable\u003e\n  \u003cthead\u003e\n    \u003ctr\u003e\n      \u003cth scope=\"col\"\u003e\u003cstrong\u003eCase study   scenario\u003c/strong\u003e\u003c/th\u003e\n      \u003cth scope=\"col\"\u003e\u003cstrong\u003eHow it is   Adaptive\u003c/strong\u003e\u003c/th\u003e\n      \u003cth scope=\"col\"\u003e\u003cstrong\u003eHow it is   Autonomous\u003c/strong\u003e\u003c/th\u003e\n      \u003cth scope=\"col\"\u003e\u003cstrong\u003ePotential   AI related regulatory implications\u003c/strong\u003e\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003ctd\u003e\u003cstrong\u003eTransformer   Language Model used to output text-based, or image-based content\u003c/strong\u003e\u003c/td\u003e\n      \u003ctd\u003eTransformer models have a large number of   parameters, often derived from data from the public internet. This can   harness the collective creativity and knowledge present online, and enable the   creation of stories and rich, highly-specific images on the basis of a short   textual prompt.\u003c/td\u003e\n      \u003ctd\u003eThese models generate their output automatically,   based on the text input, and produce impressive multimedia with next to no   detailed instruction or ongoing oversight from the user.\u003c/td\u003e\n      \u003ctd\u003e- Security and privacy concerns from inferred   training data     - Inappropriate or harmful language or content   output     - Reproduction of biases or stereotyping in training   data\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd\u003e\u003cstrong\u003eSelf-driving   car control system\u003c/strong\u003e\u003c/td\u003e\n      \u003ctd\u003eThese systems use computer vision as well as   iteratively learning from real time driving data to create a model which is   capable of understanding the road environment, and what actions to take in   given circumstances.\u003c/td\u003e\n      \u003ctd\u003eThese models directly control the speed, motion and   direction of a vehicle.\u003c/td\u003e\n      \u003ctd\u003e- Safety and control risks if presented with   unfamiliar input     - Assignation of liability for decisions in an   accident/dispute     - Opacity regarding decision-making and   corresponding lack of public trust\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e"
      }
    },
    {
      "@type": "Question",
      "name": "A new pro-innovation approach",
      "url": "https://www.gov.uk/government/publications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement#a-new-pro-innovation-approach",
      "acceptedAnswer": {
        "@type": "Answer",
        "url": "https://www.gov.uk/government/publications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement#a-new-pro-innovation-approach",
        "text": "\u003cp\u003eOften the transformative effects of AI will be rapid and - at times - unexpected. There is therefore an important need to establish a clear framework which sets out how the government will respond to these opportunities as well as new and accelerated risks. This will offer greater clarity regarding how we intend to drive growth while also protecting our safety, security and fundamental values. In order to promote innovation and to support our thriving AI ecosystem, our approach will be:\u003c/p\u003e\u003cul\u003e\n  \u003cli\u003e\n\u003cstrong\u003eContext-specific\u003c/strong\u003e - we will acknowledge that AI is a dynamic, general purpose technology and that the risks arising from it depend principally on the context of its application.\u003c/li\u003e\n  \u003cli\u003e\n\u003cstrong\u003ePro-innovation and risk-based\u003c/strong\u003e - we will ask regulators to focus on applications of AI that result in real, identifiable, unacceptable levels of risk, rather than seeking to impose controls on uses of AI that pose low or hypothetical risk so we avoid stifling innovation\u003c/li\u003e\n  \u003cli\u003e\n\u003cstrong\u003eCoherent\u003c/strong\u003e - we will ensure the system is simple, clear, predictable and stable.\u003c/li\u003e\n  \u003cli\u003e\n\u003cstrong\u003eProportionate and adaptable\u003c/strong\u003e - we will ask that regulators consider lighter touch options, such as guidance or voluntary measures, in the first instance.\u003c/li\u003e\n\u003c/ul\u003e\u003cp\u003eA context-based approach allows AI related risk to be identified and assessed at the application level. This will enable a targeted and nuanced response to risk because an assessment can be made by the appropriate regulator of the actual impact on individuals and groups in a particular context. This also allows domains that have existing and distinct approaches to AI regulation such as defence to continue to develop appropriate mechanisms according to context. Relying on our existing regulatory structures also provides the flexibility to identify and adapt according to emerging risks since it is unlikely that new risks will develop in a consistent way across the entire economy.\u003c/p\u003e\u003cp\u003eOur approach will also be risk-based and proportionate. We anticipate that regulators will establish risk-based criteria and thresholds at which additional requirements come into force. Through our engagement with regulators, we will seek to ensure that proportionality is at the heart of implementation and enforcement of our framework, eliminating burdensome or excessive administrative compliance obligations. We will also seek to ensure that regulators consider the need to support innovation and competition as part of their approach to implementation and enforcement of the framework.\u003c/p\u003e\u003cp\u003eWe think this is preferable to a single framework with a fixed, central list of risks and mitigations. Such a framework applied across all sectors would limit the ability to respond in a proportionate manner by failing to allow for different levels of risk presented by seemingly similar applications of AI in different contexts.\u003ca href=\"#_ftn1\" class=\"govuk-link\"\u003e[38]\u003c/a\u003e This could lead to unnecessary regulation and stifle innovation. A fixed list of risks also could quickly become outdated and does not offer flexibility. A centralised approach would also not benefit from the expertise of our experienced regulators who are best placed to identify and respond to the emerging risks through the increased use of AI technologies within their domains.\u003c/p\u003e\u003cp\u003eWe do, however, acknowledge that a context-driven approach offers less uniformity than a centralised approach - by its nature, it varies according to circumstance. That is why we wish to complement our context-based approach with a set of overarching principles to make sure that we approach common cross-cutting challenges in a coherent and streamlined way.\u003c/p\u003e\u003cdiv class=\"call-to-action\"\u003e\n  \u003cp\u003eWe are taking an actively pro-innovation approach. AI is a rapidly evolving technology with scope of application and depth of capability expanding at pace. Therefore, we do not think the government should establish rigid, inflexible requirements right now. Instead, our framework will ensure that regulators are responsive in protecting the public, by focusing on the specific context in which AI is being used, and taking a proportionate, risk-based response. We will engage with regulators to ensure that they proactively embed considerations of innovation, competition and proportionality through their implementation and any subsequent enforcement of the framework.\u003c/p\u003e\n\u003c/div\u003e\u003ch3 id=\"cross-sectoral-principles\"\u003eCross-sectoral principles\u003c/h3\u003e\u003cp\u003eWhile context is critical, AI technologies feature a range of underlying issues and risks which require a coherent response, such as a perceived lack of explainability when high-impact decisions are made about people using AI. We propose to address this by developing a set of cross-sectoral principles tailored to the distinct characteristics of these technologies. Regulators would be tasked with interpreting and implementing these cross-sectoral principles within their regulatory remits in line with their existing roles and remits. Our expectation is that our cross-sectoral principles will also provide a basis for coordination with our global partners and will support our implementation of the global principles that the UK has already helped to develop.\u003c/p\u003e\u003cdiv class=\"call-to-action\"\u003e\n  \u003cp\u003eWe propose developing a set of cross-sectoral principles that regulators will develop into sector or domain-specific AI regulation measures.\u003c/p\u003e\n\u003c/div\u003e\u003ch3 id=\"early-proposals-for-our-cross-sectoral-principles\"\u003eEarly proposals for our cross-sectoral principles\u003c/h3\u003e\u003cp\u003eOur proposed cross-sectoral principles build on the OECD Principles on Artificial Intelligence\u003ca href=\"#_ftn2\" class=\"govuk-link\"\u003e[39]\u003c/a\u003e and demonstrate the UK’s commitment to them. Our principles will provide a clear foundation for our framework, tailored to the UK’s values and ambitions, and will be delivered within existing regulatory regimes. The principles will complement existing regulation, with our vision being to increase clarity and reduce friction for businesses operating in the AI lifecycle.\u003c/p\u003e\u003cp\u003eOur principles are deliberately ‘values’ focused - we want to make sure AI-driven growth and innovation is aligned with the UK’s broader values given the vital role AI plays in shaping outcomes that affect our society. They are not, however, intended to create an extensive new framework of rights for individuals. The principles describe what we think well governed AI use should look like on a cross-cutting basis, but taken as part of our broader context-based, pro-innovation approach. For example, we expect well governed AI to be used with due consideration to concepts of fairness and transparency. Similarly, we expect all actors in the AI lifecycle to appropriately manage risks to safety and to provide for strong accountability.\u003c/p\u003e\u003cp\u003eOur proposal is that the principles will be interpreted and implemented in practice by our existing regulators. We are examining how the government can offer a strong steer to regulators to adopt a proportionate and risk-based approach (for example through government-issued guidance to regulators). The principles will ultimately apply to any actor in the AI lifecycle whose activities create risk that the regulators consider should be managed through the context-based operationalisation of each of the principles. For example, regulators will be tasked with deciding what ‘fairness’ or ‘transparency’ means for AI development or use in the context of their sector or domain. Regulators will then decide if, when and how their regulated entities will need to implement measures to demonstrate that these principles have been considered or complied with depending on the relevant context. We are also exploring ways to ensure that regulators can coordinate effectively to ensure coherence between their respective approaches to the principles, including where possible by working together to interpret or implement the principles on a joint or cross-sectoral basis.\u003c/p\u003e\u003cp\u003eBelow we set out our early proposals for these cross-sectoral principles.\u003c/p\u003e\u003cdiv class=\"call-to-action\"\u003e\n  \u003ch3 id=\"cross-sectoral-principles-for-ai-regulation\"\u003eCross-sectoral principles for AI regulation\u003c/h3\u003e\n\n  \u003ch4 id=\"ensure-that-ai-is-used-safely\"\u003eEnsure that AI is used safely\u003c/h4\u003e\n\n  \u003cp\u003eThe breadth of uses for AI can include functions that have a significant impact on safety - and while this risk is more apparent in certain sectors such as healthcare or critical infrastructure, there is the potential for previously unforeseen safety implications to materialise in other areas.\u003c/p\u003e\n\n  \u003cp\u003eAs such, whilst safety will be a core consideration for some regulators, it will be important for all regulators to take a context-based approach in assessing the likelihood that AI could pose a risk to safety in their sector or domain, and take a proportionate approach to managing this risk. Ensuring safety in AI will require new ways of thinking and new approaches, however we would expect the requirements to remain commensurate with actual risk - comparable with non-AI use cases.\u003c/p\u003e\n\n  \u003ch4 id=\"ensure-that-ai-is-technically-secure-and-functions-as-designed\"\u003eEnsure that AI is technically secure and functions as designed\u003c/h4\u003e\n\n  \u003cp\u003eAI is rapidly bringing new capabilities online and reducing the costs of existing business functions and processes. Ensuring that consumers and the public have confidence in the proper functioning of systems is vital to guaranteeing that the research and commercialisation of AI can continue apace.\u003c/p\u003e\n\n  \u003cp\u003eAI systems should be technically secure and under conditions of normal use they should reliably do what they intend and claim to do. Subject to considerations of context and proportionality, the functioning, resilience and security of a system should be tested and proven, and the data used in training and in deployment should be relevant, high quality, representative and contextualised.\u003c/p\u003e\n\n  \u003ch4 id=\"make-sure-that-ai-is-appropriately-transparent-and-explainable\"\u003eMake sure that AI is appropriately transparent and explainable\u003c/h4\u003e\n\n  \u003cp\u003eAchieving explainability of AI systems at a technical level remains an important research and development challenge. Presently, the logic and decision making in AI systems cannot always be meaningfully explained in an intelligible way, although in most settings this poses no substantial risk. However, in some settings the public, consumers and businesses may expect and benefit from transparency requirements that improve understanding of AI decision-making. In some high risk circumstances, regulators may deem that decisions which cannot be explained should be prohibited entirely - for instance in a tribunal where you have a right to challenge the logic of an accusation.\u003c/p\u003e\n\n  \u003cp\u003eTaking into account considerations of the need to protect confidential information and intellectual property rights, example transparency requirements could include requirements to proactively or retrospectively provide information relating to: (a) the nature and purpose of the AI in question including information relating to any specific outcome, (b) the data being used and information relating to training data, (c) the logic and process used and where relevant information to support explainability of decision making and outcomes, (d) accountability for the AI and any specific outcomes.\u003c/p\u003e\n\n  \u003ch4 id=\"embed-considerations-of-fairness-into-ai\"\u003eEmbed considerations of fairness into AI\u003c/h4\u003e\n\n  \u003cp\u003eIn many contexts, the outcomes of the use of AI can have a significant impact on people’s lives - such as insurance, credit scoring or job applications. Such high-impact outcomes - and the data points used to reach them - should be justifiable and not arbitrary.\u003c/p\u003e\n\n  \u003cp\u003eIn order to ensure proportionate and pro-innovation regulation, it will be important to let regulators continue to define fairness. However, in any sector or domain we would expect regulators to:\u003c/p\u003e\n\n  \u003cul\u003e\n    \u003cli\u003einterpret and articulate ‘fairness’ as relevant to their sector or domain,\u003c/li\u003e\n    \u003cli\u003edecide in which contexts and specific instances fairness is important and relevant (which it may not always be), and\u003c/li\u003e\n    \u003cli\u003edesign, implement and enforce appropriate governance requirements for ‘fairness’ as applicable to the entities that they regulate.\u003c/li\u003e\n  \u003c/ul\u003e\n\n  \u003ch4 id=\"define-legal-persons-responsibility-for-ai-governance\"\u003eDefine legal persons’ responsibility for AI governance\u003c/h4\u003e\n\n  \u003cp\u003eAI systems can operate with a high level of autonomy, making decisions about how to achieve a certain goal or outcome in a way which has not been explicitly programmed or even foreseen - which can raise secondary issues and externalities. This is ultimately what makes them intelligent systems.\u003c/p\u003e\n\n  \u003cp\u003eTherefore, accountability for the outcomes produced by AI and legal liability must always rest with an identified or identifiable legal person - whether corporate or natural.\u003csup id=\"fnref:40\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:40\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 40]\u003c/a\u003e\u003c/sup\u003e\u003c/p\u003e\n\n  \u003ch4 id=\"clarify-routes-to-redress-or-contestability\"\u003eClarify routes to redress or contestability\u003c/h4\u003e\n\n  \u003cp\u003eAI systems can be used in ways which may result in a material impact on people’s lives, or in situations where people would normally expect the reasoning behind an outcome to be set out clearly in a way that they can understand and contest - for example, when their existing rights have been affected. Using AI can increase speed, capacity and access to services, as well as improve the quality of outcomes. However it can also introduce risks, for example that the relevant training data reproduces biases or other quality concerns into an outcome.\u003c/p\u003e\n\n  \u003cp\u003eSubject to considerations of context and proportionality, the use of AI should not remove an affected individual or group’s ability to contest an outcome. We would therefore expect regulators to implement proportionate measures to ensure the contestability of the outcome of the use of AI in relevant regulated situations.\u003c/p\u003e\n\u003c/div\u003e\u003cdiv class=\"call-to-action\"\u003e\n  \u003ch3 id=\"case-study-how-our-principles-could-apply-to-an-ai-start-up\"\u003eCase study: How our principles could apply to an AI start-up\u003c/h3\u003e\n\n  \u003cp\u003eAn AI-first startup has created a platform that can automate complex customer-facing processes such as providing advice, sales and customer services, built on top of a Large Language Model.\u003csup id=\"fnref:40:1\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:40\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 40]\u003c/a\u003e\u003c/sup\u003e On their product roadmap, the company has plans to expand into multiple regulated domains, using their technology to offer legal advice, financial advice and potentially even medical advice.\u003c/p\u003e\n\n  \u003cp\u003eAs a business, they have strong technical expertise and want to develop products to enter and expand into these sectors, but are holding back from investing time and resource in market development activities because of the uncertainty that comes with regulatory compliance. The business leaders assume the costs of regulatory compliance to be high, making the justification for investment difficult.\u003c/p\u003e\n\n  \u003ch4 id=\"our-proposed-framework-will-bridge-this-gap-and-provide-the-clarity-that-this-company-needs\"\u003eOur proposed framework will bridge this gap and provide the clarity that this company needs:\u003c/h4\u003e\n\n  \u003cul\u003e\n    \u003cli\u003ethe specific measures introduced by the regulators to implement each of our cross-sectoral principles will communicate clearly and in a coherent way to businesses what expectations are around the technical, internal processes and likely regulatory requirements\u003c/li\u003e\n    \u003cli\u003erelevant regulators could issue guidance to highlight relevant regulatory requirements such as sector-specific licences, standards or the need for named individuals to assume particular responsibilities (they would do this either jointly or in a coordinated way to minimise the risk of confusion or excessive burdens)\u003c/li\u003e\n  \u003c/ul\u003e\n\n  \u003cp\u003eAs a result this company can integrate these requirements into their product roadmap, understand the rules more easily and spend more time and resource on product development or fundamental AI research, and less on legal costs. The UK benefits both from the increased investment but also from the disruptive power of new technology-led business models increasing access to financial or legal advice.\u003c/p\u003e\n\u003c/div\u003e"
      }
    },
    {
      "@type": "Question",
      "name": "Putting our approach into practice",
      "url": "https://www.gov.uk/government/publications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement#putting-our-approach-into-practice",
      "acceptedAnswer": {
        "@type": "Answer",
        "url": "https://www.gov.uk/government/publications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement#putting-our-approach-into-practice",
        "text": "\u003cp\u003eWe are still at the early stages of considering how best to put our approach into practice, and will set out fuller details through the forthcoming white paper.\u003c/p\u003e\u003cp\u003eWe propose initially putting the cross-sectoral principles on a non-statutory footing. This is so that we can monitor, evaluate and if necessary update our approach and so that it remains agile enough to respond to the rapid pace of change in the way that AI impacts upon society. This position would be kept under review as part of an ongoing process of monitoring and evaluating the effectiveness of the framework, including the principles and existing regulatory structures.\u003c/p\u003e\u003cp\u003eWe propose that regulators will lead the process of identifying, assessing, prioritising and contextualising the specific risks addressed by the principles. We anticipate that the government may issue supplementary or supporting guidance, for example focused on the interpretation of terms used within the principles, risk and proportionality, to support regulators in their application of the principles. These principles provide clear steers for regulators, but will not necessarily translate into mandatory obligations. Indeed we will encourage regulators to consider lighter touch options in the first instance - for example, through a voluntary or guidance-based approach for uses of AI that fall within their remit. This approach will also complement and support regulators’ formal legal and enforcement obligations using the powers available to in order to enforce requirements set out in statute.\u003c/p\u003e\u003cp\u003eMany regulators will have the flexibility within their regulatory powers to translate and implement our proposed principles, but not all. There are also differences between the types of rules regulators can make when translating these principles, and the enforcement action regulators can take where the underlying legal rules are broken. We need to consider if there is a need to update the powers and remits of some individual regulators. However we do not consider that equal powers or uniformity of approach across all regulators to be necessary.\u003c/p\u003e\u003cp\u003eRegulatory coordination will be important for our approach to work and to avoid contradictory or very different approaches across regulators. It will also be important to maintain a clear overview of how coherently the regulatory landscape as a whole is operating and to be able to anticipate issues arising from the implementation of our framework. We will look for ways to support collaboration between regulators to ensure a streamlined approach. For example, we will seek to ensure that organisations do not have to navigate multiple sets of guidance from multiple regulators all addressing the same principle. To do this, we will need to ensure we have the right institutional architecture in place. The UK already benefits from close cooperation between some of its regulators at a statutory level, and - in the digital space - from the ground-breaking work of the Digital Regulation Cooperation Forum, whose members have already begun to think actively about their shared priorities and areas of interest in relation to AI regulation.\u003csup id=\"fnref:41\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:41\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 41]\u003c/a\u003e\u003c/sup\u003e We need to identify what further mechanisms, if any, are needed to ensure that this existing infrastructure can successfully support our goals for a coherent, decentralised framework.\u003c/p\u003e\u003cp\u003eWe also need to ensure that UK regulators have access to the right skills and expertise to effectively regulate AI. While some have been able to make significant and rapid investment in their AI capabilities in recent years, not all regulators have access to the necessary skills and expertise required. We will need to consider how we can address these disparities in a proportionate and innovative way; this could include consideration of the role that ‘pooled capabilities’ can play, as well as the effectiveness of secondments from industry and academia.\u003c/p\u003e\u003cp\u003eWhile we currently do not see a need for legislation at this stage, we cannot rule out that legislation may be required as part of making sure our regulators are able to implement the framework. For example, legislation may be necessary to ensure that regulators are able to take a coordinated and coherent approach. This could be relevant in the context of enabling and supporting regulatory coordination, or to make updates to regulatory powers. Alongside this, we may need to consider specific new powers or capabilities for regulators where risks associated with particular applications arise. However, we expect to pursue this approach by exception where it is the only viable option to address a high-impact risk\u003c/p\u003e\u003cdiv class=\"call-to-action\"\u003e\n  \u003cp\u003eAt this stage, we are considering implementing the principles on a non-statutory basis which could be supplemented by clear guidance from the government. This approach would be kept under review. We cannot, however, rule out the need for legislation as part of the delivery and implementation of the principles. For example, in order to enhance regulatory powers, ensure regulatory coordination, or to create new institutional architecture.\u003c/p\u003e\n\u003c/div\u003e\u003ch3 id=\"the-international-landscape\"\u003eThe international landscape\u003c/h3\u003e\u003cp\u003eThe inherent cross-border nature of the digital ecosystem and scientific collaboration as well as the importance of facilitating cross-border trade means it is imperative we work closely with partners. This is in order to prevent a fragmented global market, ensure interoperability and promote the responsible development of AI internationally.\u003c/p\u003e\u003cp\u003eWe will continue to pursue an inclusive multi-stakeholder approach, to bring in relevant voices and expertise to help address these issues. We will also protect against efforts to adopt and apply these technologies in the service of authoritarianism and repression. To support this, the UK will continue to be an active player in organisations such as GPAI and the OECD, as well as acting as a pragmatic pro-innovation voice in ongoing Council of Europe negotiations. We will ensure that UK industry’s interests are well represented in international standardisation - both to encourage interoperability and to embed British values.\u003c/p\u003e\u003cp\u003eWe will promote a pro-innovation international governance and regulatory environment for AI which fosters openness, liberty and democracy. We will work with partners around the world to ensure international agreements embed our values so that progress in AI is achieved responsibly, according to democratic norms and the rule of law. We will reject efforts to adopt and apply AI technologies to support authoritarianism or discrimination.\u003c/p\u003e"
      }
    },
    {
      "@type": "Question",
      "name": "Next steps",
      "url": "https://www.gov.uk/government/publications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement#next-steps",
      "acceptedAnswer": {
        "@type": "Answer",
        "url": "https://www.gov.uk/government/publications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement#next-steps",
        "text": "\u003cp\u003eThis paper sets out our overall pro-innovation direction of travel on regulating AI. Over the coming months, we will be considering how best to implement and refine our approach to drive innovation, boost consumer and investor confidence and support the development and adoption of new AI systems. Specifically we will be considering:\u003c/p\u003e\u003cul\u003e\n  \u003cli\u003e\n    \u003cp\u003e\u003cstrong\u003eThe proposed framework\u003c/strong\u003e and whether it adequately addresses our prioritised AI-specific risks in a way tailored to the UK’s values and ambitions while also enabling effective coordination with other international approaches. This includes considering whether any gaps exist in the existing regulator coverage that require a more targeted solution.\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e\u003cstrong\u003eHow we put our approach into practice.\u003c/strong\u003e This includes considering the roles, powers, remits and capabilities of regulators; the need for coordination and how this should be delivered across the range of regulators (statutory and non-statutory) involved in AI regulation; and whether new institutional architecture is needed to oversee the functioning of the landscape as a whole and anticipate future challenges. This includes the role of technical standards and assurance mechanisms as potential tools for implementing principles in practice, supporting industry, and enabling international trade. We will also consider if there are any areas of high risk that demand an agreed timeline for regulators to interpret the principles into sector or domain specific guidance. We will work with key regulators such as the Information Commissioner’s Office, Competition and Markets Authority, Ofcom, Medicine and Healthcare Regulatory Authority and Equality and Human Rights Commission - as well as other stakeholders - to examine these questions.\u003csup id=\"fnref:43\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:43\" class=\"govuk-link\" rel=\"footnote\"\u003e[footnote 43]\u003c/a\u003e\u003c/sup\u003e\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e\u003cstrong\u003eMonitoring of the framework\u003c/strong\u003e to ensure it delivers our vision for regulating AI in the UK and that it is capable of foreseeing future developments, mitigating future risks and maximising the benefits of future opportunities. This includes designing a suitable monitoring and evaluation framework to monitor progress against our vision as well as criteria for future updates to the framework to ensure a robust approach to identifying and addressing evolving risks. This will be undertaken on two levels, both at the overall system level and at the individual regulator level. Our approach will also require consideration of how to ensure an effective and holistic horizon scanning function so we ensure our approach is suitable to address both immediate and long-term risks.\u003c/p\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\u003cp\u003eWe will set out our position on these topics through the forthcoming White Paper and public consultation, which we plan to publish in late 2022.\u003c/p\u003e"
      }
    },
    {
      "@type": "Question",
      "name": "Share your views",
      "url": "https://www.gov.uk/government/publications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement#share-your-views",
      "acceptedAnswer": {
        "@type": "Answer",
        "url": "https://www.gov.uk/government/publications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement#share-your-views",
        "text": "\u003cp\u003eThrough this paper, we want to invite stakeholder views about how the UK can best set the rules for regulating AI in a way that drives innovation and growth while also protecting our fundamental values. This will inform the development of the forthcoming white paper.\u003c/p\u003e\u003cp\u003eWe therefore welcome reflections on our proposed approach and we would like to specifically invite views and any supporting evidence that you can share with regard to the following questions:\u003c/p\u003e\u003col class=\"steps\"\u003e\n\u003cli\u003e\n\u003cp\u003eWhat are the most important challenges with our existing approach to regulating AI? Do you have views on the most important gaps, overlaps or contradictions?\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eDo you agree with the context-driven approach delivered through the UK’s established regulators set out in this paper? What do you see as the benefits of this approach? What are the disadvantages?\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eDo you agree that we should establish a set of cross-sectoral principles to guide our overall approach? Do the proposed cross-sectoral principles cover the common issues and risks posed by AI technologies? What, if anything, is missing?\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eDo you have any early views on how we best implement our approach? In your view, what are some of the key practical considerations? What will the regulatory system need to deliver on our approach? How can we best streamline and coordinate guidance on AI from regulators?\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eDo you anticipate any challenges for businesses operating across multiple jurisdictions? Do you have any early views on how our approach could help support cross-border trade and international cooperation in the most effective way?\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eAre you aware of any robust data sources to support monitoring the effectiveness of our approach, both at an individual regulator and system level?\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\u003cp\u003eThe call for views and evidence will be open for 10 weeks, closing on 26 September 2022, to allow time for your consideration and response.\u003c/p\u003e\u003cp\u003eYou can send your views on this to: \u003ca href=\"mailto:evidence@officeforai.gov.uk\" class=\"govuk-link\"\u003eevidence@officeforai.gov.uk\u003c/a\u003e. You can also write to us at:\u003c/p\u003e\u003cdiv class=\"address\"\u003e\u003cdiv class=\"adr org fn\"\u003e\u003cp\u003e\n\nOffice for Artificial Intelligence\n\u003cbr\u003eDCMS\n\u003cbr\u003e100 Parliament Street\n\u003cbr\u003eLondon\n\u003cbr\u003eSW1A 2BQ\n\u003cbr\u003e\n\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"footnotes\" role=\"doc-endnotes\"\u003e\n  \u003col\u003e\n    \u003cli id=\"fn:1\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca rel=\"external\" href=\"https://aiindex.stanford.edu/wp-content/uploads/2022/03/2022-AI-Index-Report_Master.pdf\" class=\"govuk-link\"\u003eArtificial Intelligence Index Report\u003c/a\u003e, Stanford (2022) \u003ca href=\"#fnref:1\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:2\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca rel=\"external\" href=\"https://oecd.ai/en/data?selectedArea=ai-research\u0026amp;selectedVisualization=top-countries-in-ai-scientific-publications-in-time-from-scopus\" class=\"govuk-link\"\u003eOECD AI Policy Observatory - Live data\u003c/a\u003e, OECD (2022) \u003ca href=\"#fnref:2\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:3\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca rel=\"external\" href=\"https://www.bbc.co.uk/news/uk-scotland-56734407\" class=\"govuk-link\"\u003eAI technology used to track asbestos tumours\u003c/a\u003e, BBC (April 2021) \u003ca href=\"#fnref:3\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:4\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca rel=\"external\" href=\"https://es.catapult.org.uk/news/artificial-intelligence-project-to-help-people-facing-fuel-poverty/\" class=\"govuk-link\"\u003eArtificial intelligence project to help people facing fuel poverty\u003c/a\u003e, Energy Systems Catapult (2022) \u003ca href=\"#fnref:4\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:5\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca rel=\"external\" href=\"https://www.bbc.co.uk/news/business-59635186\" class=\"govuk-link\"\u003eWhy cows may be hiding something but AI can spot it\u003c/a\u003e, BBC (February [2022]) \u003ca href=\"#fnref:5\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:6\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca rel=\"external\" href=\"https://kainos-prod-assets.s3.amazonaws.com/uploads/2021/02/HMLR-Case-Study-2021.pdf\" class=\"govuk-link\"\u003eHM Land Registry: Using AI for intelligence document comparison\u003c/a\u003e, Kainos \u003ca href=\"#fnref:6\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:7\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca rel=\"external\" href=\"https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology\" class=\"govuk-link\"\u003eAlphaFold: a solution to a 50-year-old grand challenge in biology\u003c/a\u003e, DeepMind (2020) \u003ca href=\"#fnref:7\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:8\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca rel=\"external\" href=\"https://wayve.ai/blog/a-new-approach-to-self-driving-av2-0/\" class=\"govuk-link\"\u003eA new approach to self-driving: AV2.0\u003c/a\u003e, Wayve (2021) \u003ca href=\"#fnref:8\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:9\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca rel=\"external\" href=\"https://www.bcg.com/publications/2021/ai-to-reduce-carbon-emissions\" class=\"govuk-link\"\u003eReduce carbon costs with the power of AI\u003c/a\u003e, BCG (2021) \u003ca href=\"#fnref:9\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:10\" role=\"doc-endnote\"\u003e\n      \u003cp\u003eThis includes the International Organisation for Standardization (ISO), International Electrotechnical Commission (IEC) and Institute of Electrical and Electronics Engineers Standards Association (IEEE SA) \u003ca href=\"#fnref:10\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:11\" role=\"doc-endnote\"\u003e\n      \u003cp\u003eThe following is taken from the government’s \u003ca href=\"https://www.gov.uk/government/publications/digital-regulation-driving-growth-and-unlocking-innovation/digital-regulation-driving-growth-and-unlocking-innovation\" class=\"govuk-link\"\u003ePlan for Digital Regulation\u003c/a\u003e, published in July 2021: “‘Digital regulation’ refers to the range of regulatory tools that the government, regulators, businesses, and other bodies use to manage the impact that digital technologies and activities can have on individuals, companies, the economy and society. These include norms, self-regulation, statutory codes of conduct, and rules in primary legislation. We use these tools to promote outcomes that the market alone cannot achieve efficiently. Non-regulatory tools can complement or provide alternatives to ‘traditional’ regulation. This includes industry-led technical standards, which benefit from global technical expertise and best practice.” \u003ca href=\"#fnref:11\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:12\" role=\"doc-endnote\"\u003e\n      \u003cp\u003eThe World Bank in its \u003ca rel=\"external\" href=\"https://rulemaking.worldbank.org/en/data/explorecountries/united-kingdom\" class=\"govuk-link\"\u003eGlobal Indicators of Regulatory Governance\u003c/a\u003e analysis gives the UK a score of 5/5. \u003ca href=\"#fnref:12\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:13\" role=\"doc-endnote\"\u003e\n      \u003cp\u003eThe 2021 edition of the \u003ca rel=\"external\" href=\"https://www.globalinnovationindex.org/gii-2021-report\" class=\"govuk-link\"\u003eGlobal Innovation Index\u003c/a\u003e (GII) gives the UK a score of 92.4/100 for ‘Regulatory Environment’. \u003ca href=\"#fnref:13\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:14\" role=\"doc-endnote\"\u003e\n      \u003cp\u003eOther examples include equality law, which would apply where the use of AI produces discriminatory outcomes. Sector specific regulation such as for financial services and medical research may also capture the use of AI in these sectors. \u003ca href=\"#fnref:14\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:15\" role=\"doc-endnote\"\u003e\n      \u003cp\u003eUK GDPR and Data Protection Act 2018 \u003ca href=\"#fnref:15\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:16\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca rel=\"external\" href=\"https://ico.org.uk/for-organisations/guide-to-data-protection/key-dp-themes/guidance-on-ai-and-data-protection/\" class=\"govuk-link\"\u003eGuidance on AI and data protection\u003c/a\u003e, ICO \u003ca href=\"#fnref:16\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:17\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca rel=\"external\" href=\"https://ico.org.uk/for-organisations/guide-to-data-protection/key-dp-themes/explaining-decisions-made-with-ai/\" class=\"govuk-link\"\u003eExplaining decisions made with AI\u003c/a\u003e, ICO \u003ca href=\"#fnref:17\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:18\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca rel=\"external\" href=\"https://ico.org.uk/for-organisations/guide-to-data-protection/key-dp-themes/guidance-on-ai-and-data-protection/ai-and-data-protection-risk-toolkit/\" class=\"govuk-link\"\u003eAI and data protection risk toolkit\u003c/a\u003e, ICO \u003ca href=\"#fnref:18\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:19\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca rel=\"external\" href=\"https://ico.org.uk/about-the-ico/ico-and-stakeholder-consultations/ico-consultation-on-the-draft-ai-auditing-framework-guidance-for-organisations/\" class=\"govuk-link\"\u003eI CO consultation (now closed) on the AI auditing framework\u003c/a\u003e, ICO (February 2020) \u003ca href=\"#fnref:19\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:20\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca rel=\"external\" href=\"https://www.equalityhumanrights.com/sites/default/files/about-us-strategic-plan-2022-2025.pdf\" class=\"govuk-link\"\u003eStrategic Plan 2022-2025\u003c/a\u003e, Equality and Human Rights Commission (March 2022) \u003ca href=\"#fnref:20\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:21\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca href=\"https://www.gov.uk/government/publications/software-and-ai-as-a-medical-device-change-programme/software-and-ai-as-a-medical-device-change-programme\" class=\"govuk-link\"\u003eSoftware and AI as a medical device change programme\u003c/a\u003e, Medicines and Healthcare products Regulatory Agency (September 2021) \u003ca href=\"#fnref:21\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:22\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca href=\"https://www.gov.uk/government/consultations/consultation-on-the-future-regulation-of-medical-devices-in-the-united-kingdom\" class=\"govuk-link\"\u003eConsultation (now closed) on the future regulation of medical devices in the UK\u003c/a\u003e, Medicines and Healthcare products Regulatory Agency (October/November 2021) \u003ca href=\"#fnref:22\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:23\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca rel=\"external\" href=\"https://www.hse.gov.uk/research/content/science-evidence-delivery-20-23.pdf\" class=\"govuk-link\"\u003eScience and Evidence Delivery Plan 2020-2023\u003c/a\u003e, Health and Safety Executive \u003ca href=\"#fnref:23\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:24\" role=\"doc-endnote\"\u003e\n      \u003cp\u003eThe \u003ca href=\"https://www.gov.uk/government/collections/the-digital-regulation-cooperation-forum\" class=\"govuk-link\"\u003eDigital Regulation Cooperation Forum\u003c/a\u003e (DRCF) comprises the Competition and Markets Authority (CMA), the Information Commissioner’s Office (ICO), the Office for Communications (Ofcom) and the Financial Conduct Authority (FCA). It was established to build on the strong working relationships between these organisations and to establish a greater level of cooperation, given the distinctive challenges posed by digital regulation. \u003ca href=\"#fnref:24\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:25\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca href=\"https://www.gov.uk/government/publications/findings-from-the-drcf-algorithmic-processing-workstream-spring-2022\" class=\"govuk-link\"\u003eFindings from the DRCF algorithmic processing workstream - Spring 2022\u003c/a\u003e, DRCF (April 2022) \u003ca href=\"#fnref:25\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:26\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca rel=\"external\" href=\"https://www.bankofengland.co.uk/research/fintech/ai-public-private-forum\" class=\"govuk-link\"\u003eThe AI Public-Private Forum: Final Report\u003c/a\u003e, Bank of England and Financial Conduct Authority’s Artificial Intelligence Public-Private Forum (February 2022) \u003ca href=\"#fnref:26\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:27\" role=\"doc-endnote\"\u003e\n      \u003cp\u003eStandards are often used as “soft law” in codes of conduct/practice and binding/non-binding guidance, but it can also be designated as voluntary tools to show legal compliance. See \u003ca href=\"https://www.gov.uk/guidance/designated-standards\" class=\"govuk-link\"\u003eDesignated standards guidance\u003c/a\u003e. \u003ca href=\"#fnref:27\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:28\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca href=\"https://www.gov.uk/government/organisations/central-digital-and-data-office\" class=\"govuk-link\"\u003eCentral Digital and Data Office (CDDO)\u003c/a\u003e \u003ca href=\"#fnref:28\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:29\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca href=\"https://www.gov.uk/government/publications/ai-barometer-2021/ai-barometer-part-1-summary-of-findings\" class=\"govuk-link\"\u003eAI Barometer Part 1 - Summary of Findings\u003c/a\u003e, Centre for Data Ethics and Innovation (December 2021) \u003ca href=\"#fnref:29\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:30\" role=\"doc-endnote\"\u003e\n      \u003cp\u003eFor example, while the Information Commissioner’s Office has the power to issue fines on parties that breach data protection law, the Equality and Human Rights Commission cannot issue fines on parties that breach equality law. The Equality and Human Rights Commission can, however, pursue damages in judicial review proceedings. \u003ca href=\"#fnref:30\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:31\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e70% of surveyed businesses said they “desired more information to help them navigate the often complex legal requirements around data collection, use and sharing”. \u003ca href=\"https://www.gov.uk/government/publications/ai-barometer-2021\" class=\"govuk-link\"\u003eAI Barometer 2021\u003c/a\u003e, Centre for Data Ethics and Innovation (2021) \u003ca href=\"#fnref:31\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:32\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e31% of respondents feel concerned that the benefits of data and AI use will not be felt equally across society. Public attitudes to data and \u003ca href=\"https://www.gov.uk/government/publications/public-attitudes-to-data-and-ai-tracker-survey\" class=\"govuk-link\"\u003eAI: Tracker Survey\u003c/a\u003e, Centre for Data Ethics and Innovation (2022) \u003ca href=\"#fnref:32\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:33\" role=\"doc-endnote\"\u003e\n      \u003cp\u003eIn November 2021, Meta (previously known as Facebook) announced it was “shutting down the Facial Recognition system on Facebook” citing unclear rules from regulators. Similarly, IBM is to stop offering its own facial recognition software for certain activities including mass surveillance. \u003ca href=\"#fnref:33\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:34\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca rel=\"external\" href=\"https://digital-strategy.ec.europa.eu/en/library/proposal-regulation-laying-down-harmonised-rules-artificial-intelligence\" class=\"govuk-link\"\u003eProposal for a Regulation laying down harmonised rules on artificial intelligence\u003c/a\u003e, European Commission (April 2021) \u003ca href=\"#fnref:34\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:35\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca rel=\"external\" href=\"https://openai.com/dall-e-2/\" class=\"govuk-link\"\u003eDALL.E 2\u003c/a\u003e, Open AI \u003ca href=\"#fnref:35\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:36\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca rel=\"external\" href=\"https://www.nature.com/articles/d41586-020-03157-9\" class=\"govuk-link\"\u003eArtificial intelligence is improving the detection of lung cancer\u003c/a\u003e, Nature (November 2020) \u003ca href=\"#fnref:36\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:37\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca rel=\"external\" href=\"https://www.nature.com/articles/s41586-022-04448-z\" class=\"govuk-link\"\u003eRestoring and attributing ancient texts using deep neural networks\u003c/a\u003e, Nature (March 2022) \u003ca href=\"#fnref:37\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:40\" role=\"doc-endnote\"\u003e\n      \u003cp\u003eFor example, the \u003ca rel=\"external\" href=\"https://www.lawcom.gov.uk/project/automated-vehicles/\" class=\"govuk-link\"\u003eLaw Commission\u003c/a\u003e recommends that self-driving vehicles will represent a shift in responsibility from driver to manufacturer and operators. \u003ca href=\"#fnref:40\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e \u003ca href=\"#fnref:40:1\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced 2\"\u003e↩\u003csup\u003e2\u003c/sup\u003e\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:41\" role=\"doc-endnote\"\u003e\n      \u003cp\u003eA Large Language Model (LLM) is an AI model which is trained on vast amounts of data - often with billions of parameters - which can produce content, such as text or visual output, on the basis of a short prompt from a user. Some examples are Open AI’s GPT-3, DeepMind’s Chinchilla, and Google’s LaMDA. \u003ca href=\"#fnref:41\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:43\" role=\"doc-endnote\"\u003e\n      \u003cp\u003eFor example, the DCMS Secretary of State has already written to the Digital Regulation Cooperation Forum requesting their insights on AI governance. \u003ca href=\"#fnref:43\" class=\"govuk-link\" role=\"doc-backlink\" aria-label=\"go to where this is referenced\"\u003e↩\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n  \u003c/ol\u003e\n\u003c/div\u003e"
      }
    }
  ]
}
</script><script type="application/ld+json">
  {
  "@context": "http://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position": 1,
      "item": {
        "name": "Home",
        "@id": "https://www.gov.uk/"
      }
    },
    {
      "@type": "ListItem",
      "position": 2,
      "item": {
        "name": "Business and industry",
        "@id": "https://www.gov.uk/business-and-industry"
      }
    },
    {
      "@type": "ListItem",
      "position": 3,
      "item": {
        "name": "Science and innovation",
        "@id": "https://www.gov.uk/business-and-industry/science-and-innovation"
      }
    },
    {
      "@type": "ListItem",
      "position": 4,
      "item": {
        "name": "Artificial intelligence",
        "@id": "https://www.gov.uk/business-and-industry/artificial-intelligence"
      }
    },
    {
      "@type": "ListItem",
      "position": 5,
      "item": {
        "name": "Establishing a pro-innovation approach to regulating AI",
        "@id": "https://www.gov.uk/government/publications/establishing-a-pro-innovation-approach-to-regulating-ai"
      }
    }
  ]
}
</script>
</body>
</html>
